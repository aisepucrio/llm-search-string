@inproceedings{10.1007/978-3-030-90785-3_16,
author = {Wang, Baoping and Wang, Wennan and Zhu, Linkai and Liu, Wenjian},
title = {Research on Cross-Project Software Defect Prediction Based on Machine Learning},
year = {2021},
isbn = {978-3-030-90784-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90785-3_16},
doi = {10.1007/978-3-030-90785-3_16},
abstract = {In recent years, machine learning technology has developed vigorously. The research on software defect prediction in the field of software engineering is increasingly adopting various algorithms of machine learning. This article has carried out a systematic literature review on the field of defect prediction. First, this article studies the development process of defect prediction, from correlation to prediction model. then this article studies the development process of cross-project defect prediction based on machine learning algorithms (naive Bayes, decision tree, random forest, neural network, etc.). Finally, this paper looks forward to the research difficulties and future directions of software defect prediction, such as imbalance in classification, cost of data labeling, and cross-project data distribution.},
booktitle = {Advances in Web-Based Learning – ICWL 2021: 20th International Conference, ICWL 2021, Macau, China, November 13–14, 2021, Proceedings},
pages = {160–165},
numpages = {6},
keywords = {Metric, Software defect prediction model, Machine learning},
location = {Macau, China}
}

@inproceedings{10.1145/3368926.3369711,
author = {Ha, Duy-An and Chen, Ting-Hsuan and Yuan, Shyan-Ming},
title = {Unsupervised methods for Software Defect Prediction},
year = {2019},
isbn = {9781450372459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368926.3369711},
doi = {10.1145/3368926.3369711},
abstract = {Software Defect Prediction (SDP) aims to assess software quality by using machine learning techniques. Recently, by proposing the connectivity-based unsupervised learning method, Zhang et al. have been proven that unsupervised classification has great potential to apply to this problem. Inspiring by this idea, in our work we try to replicate the results of Zhang et al.'s experiment and attempt to improve the performance by examining different techniques at each step of the approach using unsupervised learning methods to solve the SDP problem. Specifically, we try to follow the steps of the experiment described in their work strictly and examine three other clustering methods with four other ways for feature selection besides using all. To the best of our knowledge, these methods are first applied in SDP to evaluate their predictive power. For replicating the results, generally results in our experiments are not as good as the previous work. It may be due to we do not know which features are used in their experiment exactly. Fluid clustering and spectral clustering give better results than Newman clustering and CNM clustering in our experiments. Additionally, the experiments also show that using Kernel Principal Component Analysis (KPCA) or Non-Negative Matrix Factorization (NMF) for feature selection step gives better performance than using all features in the case of unlabeled data. Lastly, to make replicating our work easy, a lightweight framework is created and released on Github.},
booktitle = {Proceedings of the 10th International Symposium on Information and Communication Technology},
pages = {49–55},
numpages = {7},
keywords = {Unsupervised Learning, Software Engineering, Software Defect Prediction, Machine Learning, Community Structure Detection},
location = {Hanoi, Ha Long Bay, Viet Nam},
series = {SoICT '19}
}

@inproceedings{10.1145/3474198.3478215,
author = {Du, Xiaozhi and Yue, Hehe and Dong, Honglei},
title = {Software Defect Prediction Method based on Hybrid Sampling},
year = {2022},
isbn = {9781450390149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474198.3478215},
doi = {10.1145/3474198.3478215},
abstract = {Software defect prediction is an essential technology to provide guidance and assistance for software testers and developers. However, the problem of imbalanced data sets limits the effect and application of the software defect prediction. To address this issue, this paper proposes a software defect prediction method based on hybrid sampling, which combines the strategies of over-sampling with under-sampling. For minority class, over-sampling uses k-means to cluster samples, then adopts SMOTE to generate artificial data based on safe areas of the clustering outcome. For majority class, under-sampling uses logistic regression classifier to get the misclassification probability of each sample and its instance hardness value. Then the samples, whose instance hardness values are lower than the threshold, are removed from the datasets. The experimental results show that our method is superior to the previous methods. Compared with SMOTE-kNN, SMOTE-Tomek, SMOTE and DBSMOTE, the accuracy of our method is improved by 17.60%, 6.99%, 8.66% and 26.18% on average respectively.},
booktitle = {International Conference on Frontiers of Electronics, Information and Computation Technologies},
articleno = {93},
numpages = {9},
keywords = {Software defect prediction, Hybrid sampling, Data imbalance},
location = {Changsha, China},
series = {ICFEICT 2021}
}

@inproceedings{10.1145/3416508.3417114,
author = {Aljamaan, Hamoud and Alazba, Amal},
title = {Software defect prediction using tree-based ensembles},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417114},
doi = {10.1145/3416508.3417114},
abstract = {Software defect prediction is an active research area in software engineering. Accurate prediction of software defects assists software engineers in guiding software quality assurance activities. In machine learning, ensemble learning has been proven to improve the prediction performance over individual machine learning models. Recently, many Tree-based ensembles have been proposed in the literature, and their prediction capabilities were not investigated in defect prediction. In this paper, we will empirically investigate the prediction performance of seven Tree-based ensembles in defect prediction. Two ensembles are classified as bagging ensembles: Random Forest and Extra Trees, while the other five ensembles are boosting ensembles: Ada boost, Gradient Boosting, Hist Gradient Boosting, XGBoost and CatBoost. The study utilized 11 publicly available MDP NASA software defect datasets. Empirical results indicate the superiority of Tree-based bagging ensembles: Random Forest and Extra Trees ensembles over other Tree-based boosting ensembles. However, none of the investigated Tree-based ensembles was significantly lower than individual decision trees in prediction performance. Finally, Adaboost ensemble was the worst performing ensemble among all Tree-based ensembles.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {1–10},
numpages = {10},
keywords = {Bagging, Boosting, Classification, Ensemble Learning, Machine Learning, Prediction, Software Defect},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@article{10.1007/s00521-020-04960-1,
author = {Wang, Kechao and Liu, Lin and Yuan, Chengjun and Wang, Zhifei},
title = {Software defect prediction model based on LASSO–SVM},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {14},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04960-1},
doi = {10.1007/s00521-020-04960-1},
abstract = {A software defect report is a bug in the software system that developers and users submit to the software defect library during software development and maintenance. Managing a software defect report that is overwhelming is a challenging task. The traditional method is manual identification, which is time-consuming and laborious and delays the repair of important software defects. Based on the above background, the purpose of this paper is to study the software defect prediction (SDP) model based on LASSO–SVM. In this paper, the problem of poor prediction accuracy of most SDP models is proposed. A SDP model combining minimum absolute value compression and selection method and support vector machine algorithm is proposed. Firstly, the feature selection ability of the minimum absolute value compression and selection method is used to reduce the dimension of the original data set, and the data set not related to SDP is removed. Then, the optimal value of SVM is obtained by using the parameter optimization ability of cross-validation algorithm. Finally, the SDP is completed by the nonlinear computing ability of SVM. The accuracy of simulation results is 93.25% and 66.67%, recall rate is 78.04%, and f-metric is 72.72%. The results show that the proposed defect prediction model has higher prediction accuracy than the traditional defect prediction model, and the prediction speed is faster.},
journal = {Neural Comput. Appl.},
month = jul,
pages = {8249–8259},
numpages = {11},
keywords = {Cross-validation, Support vector machine, Feature selection, Software defect prediction}
}

@inproceedings{10.1145/3387940.3391463,
author = {Omri, Safa and Sinz, Carsten},
title = {Deep Learning for Software Defect Prediction: A Survey},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391463},
doi = {10.1145/3387940.3391463},
abstract = {Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {209–214},
numpages = {6},
keywords = {software testing, software quality assurance, software defect prediction, machine learning, deep learning},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@article{10.1016/j.infsof.2021.106664,
author = {Yao, Jingxiu and Shepperd, Martin},
title = {The impact of using biased performance metrics on software defect prediction research},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106664},
doi = {10.1016/j.infsof.2021.106664},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {14},
keywords = {Classification metrics, Computational experiment, Software defect prediction, Machine learning, Software engineering}
}

@article{10.1007/s11063-020-10355-z,
author = {Niu, Liang and Wan, Jianwu and Wang, Hongyuan and Zhou, Kaiwei},
title = {Cost-sensitive Dictionary Learning for Software Defect Prediction},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {3},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-020-10355-z},
doi = {10.1007/s11063-020-10355-z},
abstract = {In recent years, software defect prediction has been recognized as a cost-sensitive learning problem. To deal with the unequal misclassification losses resulted by different classification errors, some cost-sensitive dictionary learning methods have been proposed recently. Generally speaking, these methods usually define the misclassification costs to measure the unequal losses and then propose to minimize the cost-sensitive reconstruction loss by embedding the cost information into the reconstruction function of dictionary learning. Although promising performance has been achieved, their cost-sensitive reconstruction functions are not well-designed. In addition, no sufficient attentions are paid to the coding coefficients which can also be helpful to reduce the reconstruction loss. To address these issues, this paper proposes a new cost-sensitive reconstruction loss function and introduces an additional cost-sensitive discrimination regularization for the coding coefficients. Both the two terms are jointly optimized in a unified cost-sensitive dictionary learning framework. By doing so, we can achieve the minimum reconstruction loss and thus obtain a more cost-sensitive dictionary for feature encoding of test data. In the experimental part, we have conducted extensive experiments on twenty-five software projects from four benchmark datasets of NASA, AEEEM, ReLink and Jureczko. The results, in comparison with ten state-of-the-art software defect prediction methods, demonstrate the effectiveness of learned cost-sensitive dictionary for software defect prediction.},
journal = {Neural Process. Lett.},
month = dec,
pages = {2415–2449},
numpages = {35},
keywords = {Discrimination, Dictionary learning, Cost-sensitive, Software defect prediction}
}

@article{10.1007/s11334-021-00399-2,
author = {Suresh Kumar, P. and Behera, H. S. and Nayak, Janmenjoy and Naik, Bighnaraj},
title = {Bootstrap aggregation ensemble learning-based reliable approach for software defect prediction by using characterized code feature},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-021-00399-2},
doi = {10.1007/s11334-021-00399-2},
abstract = {To ensure software quality, software defect prediction plays a prominent role for the software developers and practitioners. Software defect prediction can assist us with distinguishing software defect modules and enhance the software quality. In present days, many supervised machine learning algorithms have proved their efficacy to identify defective modules. However, those are limited to prove their major significance due to the limitations such as the adaptation of parameters with the environment and complexity. So, it is important to develop a key methodology to improve the efficiency of the prediction module. In this paper, an ensemble learning technique called&nbsp;Bootstrap&nbsp;aggregating has been proposed for software defect prediction object-oriented modules. The proposed method's accuracy, recall, precision, F-measure, and AUC-ROC efficiency were compared to those of many qualified machine learning algorithms. Simulation results and performance comparison are evident that the proposed method outperformed well compared to other approaches.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {355–379},
numpages = {25},
keywords = {Machine learning, Software reliability, Software defect prediction, Ensemble learning}
}

@inproceedings{10.1007/978-3-030-58817-5_45,
author = {Balogun, Abdullateef O. and Lafenwa-Balogun, Fatimah B. and Mojeed, Hammed A. and Adeyemo, Victor E. and Akande, Oluwatobi N. and Akintola, Abimbola G. and Bajeh, Amos O. and Usman-Hamza, Fatimah E.},
title = {SMOTE-Based Homogeneous Ensemble Methods for Software Defect Prediction},
year = {2020},
isbn = {978-3-030-58816-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58817-5_45},
doi = {10.1007/978-3-030-58817-5_45},
abstract = {Class imbalance is a prevalent problem in machine learning which affects the prediction performance of classification algorithms. Software Defect Prediction (SDP) is no exception to this latent problem. Solutions such as data sampling and ensemble methods have been proposed to address the class imbalance problem in SDP. This study proposes a combination of Synthetic Minority Oversampling Technique (SMOTE) and homogeneous ensemble (Bagging and Boosting) methods for predicting software defects. The proposed approach was implemented using Decision Tree (DT) and Bayesian Network (BN) as base classifiers on defects datasets acquired from NASA software corpus. The experimental results showed that the proposed approach outperformed other experimental methods. High accuracy of 86.8% and area under operating receiver characteristics curve value of 0.93% achieved by the proposed technique affirmed its ability to differentiate between the defective and non-defective labels without bias.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part VI},
pages = {615–631},
numpages = {17},
keywords = {Ensemble methods, Data sampling, Class imbalance, Software Defect Prediction},
location = {Cagliari, Italy}
}

@article{10.1016/j.jss.2021.111038,
author = {Eken, Beyza and Tosun, Ayse},
title = {Investigating the performance of personalized models for software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {181},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111038},
doi = {10.1016/j.jss.2021.111038},
journal = {J. Syst. Softw.},
month = nov,
numpages = {17},
keywords = {Software recommendation systems, Defect prediction, Change-level, Personalized}
}

@article{10.1016/j.neucom.2019.11.067,
author = {Qiao, Lei and Li, Xuesong and Umer, Qasim and Guo, Ping},
title = {Deep learning based software defect prediction},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {385},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.11.067},
doi = {10.1016/j.neucom.2019.11.067},
journal = {Neurocomput.},
month = apr,
pages = {100–110},
numpages = {11},
keywords = {Robustness evaluation, Software metrics, Software quality, Deep learning, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-37352-8_13,
author = {Cui, Mengtian and Huang, Yameng and Luo, Jing},
title = {Software Defect Prediction Model Based on GA-BP Algorithm},
year = {2019},
isbn = {978-3-030-37351-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37352-8_13},
doi = {10.1007/978-3-030-37352-8_13},
abstract = {The novel software defect prediction model based on GA-BP algorithm was proposed in the paper considering the disadvantage of traditional BP (abbreviated for Back Propagation) neural network, which has the problem of easy to fall into local optimization when constructing software defect prediction model, and finally affects the prediction accuracy. Firstly, the optimization ability of GA (abbreviated for Genetic Algorithms) is introduced to optimize the weights and thresholds of Back Propagation neural network. Then the prediction model was constructed based on the GA-BP. Meanwhile the public dataset MDP from NASA was selected and the tool WEKA was used to clean the data and format conversion and as the result, four datasets is available. In the end, experimental results show that the proposed method in the paper is effective for software defect prediction.},
booktitle = {Cyberspace Safety and Security: 11th International Symposium, CSS 2019, Guangzhou, China, December 1–3, 2019, Proceedings, Part II},
pages = {151–161},
numpages = {11},
keywords = {BP neural network, Genetic Algorithms, Machine learning, Software defect prediction},
location = {Guangzhou, China}
}

@article{10.4018/IJDSST.2020070105,
author = {Kakkar, Misha and Jain, Sarika and Bansal, Abhay and Grover, P. S.},
title = {Nonlinear Geometric Framework for Software Defect Prediction},
year = {2020},
issue_date = {Jul 2020},
publisher = {IGI Global},
address = {USA},
volume = {12},
number = {3},
issn = {1941-6296},
url = {https://doi.org/10.4018/IJDSST.2020070105},
doi = {10.4018/IJDSST.2020070105},
abstract = {Humans use the software in every walk of life thus it is essential to have the best quality software. Software defect prediction models assist in identifying defect prone modules with the help of historical data, which in turn improves software quality. Historical data consists of data related to modules /files/classes which are labeled as buggy or clean. As the number of buggy artifacts as less as compared to clean artifacts, the nature of historical data becomes imbalance. Due to this uneven distribution of the data, it difficult for classification algorithms to build highly effective SDP models. The objective of this study is to propose a new nonlinear geometric framework based on SMOTE and ensemble learning to improve the performance of SDP models. The study combines the traditional SMOTE algorithm and the novel ensemble Support Vector Machine (SVM) is used to develop the proposed framework called SMEnsemble. SMOTE algorithm handles the class imbalance problem by generating synthetic instances of the minority class. Ensemble learning generates multiple classification models to select the best performing SDP model. For experimentation, datasets from three different software repositories that contain both open source as well as proprietary projects are used in the study. The results show that SMEnsemble performs better than traditional methods for identifying the minority class i.e. buggy artifacts. Also, the proposed model performance is better than the latest state of Art SDP model- SMOTUNED. The proposed model is capable of handling imbalance classes when compared with traditional methods. Also, by carefully selecting the number of ensembles high performance can be achieved in less time.},
journal = {Int. J. Decis Support Syst. Technol.},
month = jul,
pages = {85–100},
numpages = {16},
keywords = {Software Defect Prediction, SMOTE, Preprocessing, Imbalanced Data, Ensemble Learning, Data Analytics For Software Engineering, Classification}
}

@article{10.1049/iet-sen.2019.0149,
author = {Deng, Jiehan and Lu, Lu and Qiu, Shaojian},
title = {Software defect prediction via LSTM},
year = {2020},
issue_date = {August 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {4},
url = {https://doi.org/10.1049/iet-sen.2019.0149},
doi = {10.1049/iet-sen.2019.0149},
abstract = {Software quality plays an important role in the software lifecycle. Traditional software defect prediction approaches mainly focused on using hand‐crafted features to detect defects. However, like human languages, programming languages contain rich semantic and structural information, and the cause of defective code is closely related to its context. Failing to catch this significant information, the performance of traditional approaches is far from satisfactory. In this study, the authors leveraged a long short‐term memory (LSTM) network to automatically learn the semantic and contextual features from the source code. Specifically, they first extract the program's Abstract Syntax Trees (ASTs), which is made up of AST nodes, and then evaluate what and how much information they can preserve for several node types. They traverse the AST of each file and fed them into the LSTM network to automatically the semantic and contextual features of the program, which is then used to determine whether the file is defective. Experimental results on several opensource projects showed that the proposed LSTM method is superior to the state‐of‐the‐art methods.},
journal = {IET Software},
month = aug,
pages = {443–450},
numpages = {8},
keywords = {word embedding techniques, numerical vectors, open source projects, long short-term memory network, defective code, structural information, human languages, programming languages, machine learning techniques, software defect prediction approaches, software lifecycle, software quality, LSTM, contextual features, semantic features, AST node sequence, program abstract syntax trees, trees (mathematics), recurrent neural nets, software quality, program debugging, program diagnostics, public domain software, learning (artificial intelligence), feature extraction}
}

@inproceedings{10.1145/3352411.3352412,
author = {Li, Ran and Zhou, Lijuan and Zhang, Shudong and Liu, Hui and Huang, Xiangyang and Sun, Zhong},
title = {Software Defect Prediction Based on Ensemble Learning},
year = {2019},
isbn = {9781450371414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352411.3352412},
doi = {10.1145/3352411.3352412},
abstract = {Software defect prediction is one of the important ways to guarantee the quality of software systems. Combining various algorithms in machine learning to predict software defects has become a hot topic in the current study. The paper uses the datasets of MDP as the experimental research objects and takes ensemble learning as research focus to construct software defect prediction model. With experimenting five different types of ensemble algorithms and analyzing the features and procedures, this paper discusses the best ensemble algorithm which is Random Forest through experimental comparison. Then we utilize the SMOTE over-sampling and Resample methods to improve the quality of datasets to build a complete new software defect prediction model. Therefore, the results show that the model can improve defect classification performance effectively.},
booktitle = {Proceedings of the 2019 2nd International Conference on Data Science and Information Technology},
pages = {1–6},
numpages = {6},
keywords = {Under-sampling, Software defect prediction, Over-sampling, Ensemble algorithm},
location = {Seoul, Republic of Korea},
series = {DSIT 2019}
}

@article{10.1016/j.eswa.2021.114637,
author = {Jin, Cong},
title = {Cross-project software defect prediction based on domain adaptation learning and optimization},
year = {2021},
issue_date = {Jun 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {171},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114637},
doi = {10.1016/j.eswa.2021.114637},
journal = {Expert Syst. Appl.},
month = jun,
numpages = {14},
keywords = {Improved quantum particle swarm optimization, Cross-project defect prediction, Domain adaptation, Optimization, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-62463-7_33,
author = {Lei, Tianwei and Xue, Jingfeng and Han, Weijie},
title = {Cross-Project Software Defect Prediction Based on Feature Selection and Transfer Learning},
year = {2020},
isbn = {978-3-030-62462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62463-7_33},
doi = {10.1007/978-3-030-62463-7_33},
abstract = {Cross-project software defect prediction solves the problem that traditional defect prediction can’t get enough data, but how to apply the model learned from the data of different mechanisms to the target data set is a new problem. At the same time, there is the problem that information redundancy in the training process leads to low accuracy. Based on the difference of projects, this paper uses MIC to filter features to solve the problem of information redundancy. At the same time, combined with the TrAdaboost algorithm, which is based on the idea of aggravating multiple classification error samples, this paper proposes a cross-project software prediction method based on feature selection and migration learning. Experimental results show that the algorithm proposed in this paper has better experimental results on AUC and F1.},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part III},
pages = {363–371},
numpages = {9},
keywords = {Cross-project software defect prediction, MIC, TrAdaboost, Transfer learning},
location = {Guangzhou, China}
}

@inproceedings{10.1007/978-3-030-86472-9_28,
author = {Shakhovska, Natalya and Yakovyna, Vitaliy},
title = {Feature Selection and Software Defect Prediction by Different Ensemble Classifiers},
year = {2021},
isbn = {978-3-030-86471-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86472-9_28},
doi = {10.1007/978-3-030-86472-9_28},
abstract = {Software defect prediction can improve its quality and is actively studied during the last decade. This paper focuses on the improvement of software defect prediction accuracy by proper feature selection techniques and using ensemble classifier. The software code metrics were used to predict the defective modules. JM1 public NASA dataset from PROMISE Software Engineering Repository was used in this study. Boruta, ACE, regsubsets and simple correlation are used for feature selection. The results of selection are formed based on hard voting of all features selectors. A new stacking classifier for software defects prediction is presented in this paper. The stacking classifier for defects prediction algorithm is based on combination of 5 weak classifiers. Random forest algorithm is used to combine the predictions. The obtained prediction accuracy was up to 96.26%.},
booktitle = {Database and Expert Systems Applications: 32nd International Conference, DEXA 2021, Virtual Event, September 27–30, 2021, Proceedings, Part I},
pages = {307–313},
numpages = {7},
keywords = {Ensemble of classifiers, Feature selection, Software defect analysis}
}

@article{10.1002/smr.2362,
author = {Guo, Shikai and Dong, Jian and Li, Hui and Wang, Jiahui},
title = {Software defect prediction with imbalanced distribution by radius‐synthetic minority over‐sampling technique},
year = {2021},
issue_date = {July 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {7},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2362},
doi = {10.1002/smr.2362},
abstract = {Software defect prediction, which can identify the defect‐prone modules, is an effective technology to ensure the quality of software products. Due to the importance in software maintenance, many learning‐based software defect prediction models are presented in recent years. Actually, the defects usually occupy a very small proportions in software source codes; thus, the imbalanced distributions between defect‐prone modules and non‐defect‐prone modules increase the learning difficulty of the classification task. To address this issue, we present a random over‐sampling mechanism used to generate minority‐class samples from high‐dimensional sampling space to deal with the imbalanced distributions in software defect prediction, in which two constraints are applied to provide a robust way to generate new synthetic samples, that is, scaling the random over‐sampling scope to a reasonable area and distinguishing the majority‐class samples in a critical region. Based on nine open datasets of software projects, we experimentally verify that our presented method is effective on predict the defect‐prone modules, and the effect is superior to the traditional imbalanced processing methods.},
journal = {J. Softw. Evol. Process},
month = jul,
numpages = {21},
keywords = {software quality, software defect prediction, imbalanced learning}
}

@article{10.1007/s11219-016-9353-3,
author = {Bowes, David and Hall, Tracy and Petri\'{c}, Jean},
title = {Software defect prediction: do different classifiers find the same defects?},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9353-3},
doi = {10.1007/s11219-016-9353-3},
abstract = {During the last 10 years, hundreds of different defect prediction models have been published. The performance of the classifiers used in these models is reported to be similar with models rarely performing above the predictive performance ceiling of about 80% recall. We investigate the individual defects that four classifiers predict and analyse the level of prediction uncertainty produced by these classifiers. We perform a sensitivity analysis to compare the performance of Random Forest, Na\"{\i}ve Bayes, RPart and SVM classifiers when predicting defects in NASA, open source and commercial datasets. The defect predictions that each classifier makes is captured in a confusion matrix and the prediction uncertainty of each classifier is compared. Despite similar predictive performance values for these four classifiers, each detects different sets of defects. Some classifiers are more consistent in predicting defects than others. Our results confirm that a unique subset of defects can be detected by specific classifiers. However, while some classifiers are consistent in the predictions they make, other classifiers vary in their predictions. Given our results, we conclude that classifier ensembles with decision-making strategies not based on majority voting are likely to perform best in defect prediction.},
journal = {Software Quality Journal},
month = jun,
pages = {525–552},
numpages = {28},
keywords = {Software defect prediction, Prediction modelling, Machine learning}
}

@article{10.1016/j.neucom.2019.05.100,
author = {Huo, Xuan and Li, Ming},
title = {On cost-effective software defect prediction: Classification or ranking?},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {363},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.05.100},
doi = {10.1016/j.neucom.2019.05.100},
journal = {Neurocomput.},
month = oct,
pages = {339–350},
numpages = {12},
keywords = {Classification model, Ranking model, Software defect prediction, Software mining}
}

@inproceedings{10.1007/978-3-030-58802-1_25,
author = {Ronchieri, Elisabetta and Canaparo, Marco and Belgiovine, Mauro},
title = {Software Defect Prediction on Unlabelled Datasets: A Comparative Study},
year = {2020},
isbn = {978-3-030-58801-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58802-1_25},
doi = {10.1007/978-3-030-58802-1_25},
abstract = {Background: Defect prediction on unlabelled datasets is a challenging and widespread problem in software engineering. Machine learning is of great value in this context because it provides techniques - called unsupervised - that are applicable to unlabelled datasets. Objective: This study aims at comparing various approaches employed over the years on unlabelled datasets to predict the defective modules, i.e. the ones which need more attention in the testing phase. Our comparison is based on the measurement of performance metrics and on the real defective information derived from software archives. Our work leverages a new dataset that has been obtained by extracting and preprocessing its metrics from a C++ software. Method: Our empirical study has taken advantage of CLAMI with its improvement CLAMI+ that we have applied on high energy physics software datasets. Furthermore, we have used clustering techniques such as the K-means algorithm to find potentially critical modules. Results: Our experimental analysis have been carried out on 1 open source project with 34 software releases. We have applied 17 ML techniques to the labelled datasets obtained by following the CLAMI and CLAMI+ approaches. The two approaches have been evaluated by using different performance metrics, our results show that CLAMI+ performs better than CLAMI. The predictive average accuracy metric is around 95% for 4 ML techniques (4 out of 17) that show a Kappa statistic greater than 0.80. We applied K-means on the same dataset and obtained 2 clusters labelled according to the output of CLAMI and CLAMI+. Conclusion: Based on the results of the different statistical tests, we conclude that no significant performance differences have been found in the selected classification techniques.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part II},
pages = {333–353},
numpages = {21},
keywords = {Machine learning, Unsupervised methods, Defect prediction, Unlabelled dataset},
location = {Cagliari, Italy}
}

@article{10.1007/s00500-020-05159-1,
author = {Jin, Cong},
title = {Software defect prediction model based on distance metric learning},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {1},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05159-1},
doi = {10.1007/s00500-020-05159-1},
abstract = {Software defect prediction (SDP) is a very important way for analyzing software quality and reducing development costs. The data during software lifecycle can be used to predict software defect. Currently, many SDP models have been proposed; however, their performance was not always ideal. In many existing prediction models based on machine learning, the distance metric between samples has significant impact on the performance of the SDP model. In addition, most samples are usually class imbalanced. To solve these issues, in this paper, a novel distance metric learning based on cost-sensitive learning (CSL) is proposed for reducing the impact of class imbalance of samples, which is then applied to the large margin distribution machine (LDM) to substitute the traditional kernel function. Further, the improvement and optimization of LDM based on CSL are also studied, and the improved LDM is used as the SDP model, called as CS-ILDM. Subsequently, the proposed CS-ILDM is applied to five publicly available data sets from the NASA Metrics Data Program repository and its performance is compared to other existing SDP models. The experimental results confirm that the proposed CS-ILDM not only has good prediction performance, but also can reduce the misprediction cost and avoid the impact of class imbalance of samples.},
journal = {Soft Comput.},
month = jan,
pages = {447–461},
numpages = {15},
keywords = {Class imbalance of samples, Misprediction cost, Cost-sensitive learning, Distance metric learning, Software attributes, Software defect prediction}
}

@phdthesis{10.5555/AAI28389525,
author = {Rahman, Ashiqur},
advisor = {R, Cordy, James},
title = {Software Defect Prediction Using Rich Contextualized Language Use Vectors},
year = {2020},
isbn = {9798708779250},
publisher = {Queen's University (Canada)},
abstract = {Context. Software defect prediction aims to find defect prone source code, and thus reduce the effort, time and cost involved with ensuring the quality of software systems. Both code and non-code metrics are commonly used in this process to train machine learning algorithms to predict software defects. Studies have shown that such metrics-based approaches are failing to give satisfactory results, and have reached a performance ceiling. This thesis explores the idea of using code profiles as an alternative to traditional metrics to predict software defects. This code profile-based method proves to be more promising than traditional metrics-based approaches.Aims. This thesis aims to improve software defect prediction using code profiles as feature variables in place of traditional metrics. Software code profiles encode the density of language feature use and the context of such use in Rich Contextualized Language Use Vectors (RCLUVs) by analysing the parse tree of the source code. This thesis explores whether code profiles can be used to train machine learning algorithms, and compares the performance of the derived models to traditional metrics-based approaches.Methods. To achieve these aims the learning curves of several machine learning algorithms are analyzed, and the performance of the derived models are evaluated against traditional metrics-based approaches. Two benchmark bug datasets, the Eclipse bug dataset and the Github bug database, are used to train the models.Results. The learning curves of the models show machine learning algorithms can learn from RCLUV-based code profiles. Performance evaluation against existing metrics-based approaches reveals that the code profile-based approach is more promising than traditional metrics-based approaches. However, the predictive performance of both metrics and code profile-based approaches drops in cross-version predictions.Conclusions. Unlike traditional metrics-based approaches, this thesis uses vectors generated by analyzing language feature use from the parse trees of source code as feature variables to train machine learning algorithms. Experimental results using learning algorithms encourages us to use software code profiles as an alternative to traditional metrics to predict software defects.},
note = {AAI28389525}
}

@article{10.1016/j.jss.2018.06.025,
author = {\"{O}zak\i{}nc\i{}, Rana and Tarhan, Ay\c{c}a},
title = {Early software defect prediction: A systematic map and review},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.06.025},
doi = {10.1016/j.jss.2018.06.025},
journal = {J. Syst. Softw.},
month = oct,
pages = {216–239},
numpages = {24},
keywords = {Systematic literature review, Systematic mapping, Prediction model, Software quality, Software defect, Early defect prediction}
}

@article{10.1007/s10515-016-0194-x,
author = {Zhang, Zhi-Wu and Jing, Xiao-Yuan and Wang, Tie-Jian},
title = {Label propagation based semi-supervised learning for software defect prediction},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-016-0194-x},
doi = {10.1007/s10515-016-0194-x},
abstract = {Software defect prediction can automatically predict defect-prone software modules for efficient software test in software engineering. When the previous defect labels of modules are limited, predicting the defect-prone modules becomes a challenging problem. In static software defect prediction, there exist the similarity among software modules, a software module can be approximated by a sparse representation of the other part of the software modules, and class-imbalance problem, the number of defect-free modules is much larger than that of defective ones. In this paper, we propose to use graph based semi-supervised learning technique to predict software defect. By using Laplacian score sampling strategy for the labeled defect-free modules, we construct a class-balance labeled training dataset firstly. And then, we use a nonnegative sparse algorithm to compute the nonnegative sparse weights of a relationship graph which serve as clustering indicators. Lastly, on the nonnegative sparse graph, we use a label propagation algorithm to iteratively predict the labels of unlabeled software modules. We thus propose a nonnegative sparse graph based label propagation approach for software defect classification and prediction, which uses not only few labeled data but also abundant unlabeled ones to improve the generalization capability. We vary the size of labeled software modules from 10 to 30 % of all the datasets in the widely used NASA projects. Experimental results show that the NSGLP outperforms several representative state-of-the-art semi-supervised software defect prediction methods, and it can fully exploit the characteristics of static code metrics and improve the generalization capability of the software defect prediction model.},
journal = {Automated Software Engg.},
month = mar,
pages = {47–69},
numpages = {23},
keywords = {Software defect prediction, Semi-supervised learning, Nonnegative sparse graph based label propagation (NSGLP), Nonnegative sparse graph, Label propagation}
}

@article{10.1155/2021/2323100,
author = {Liu, Wenjian and Wang, Baoping and Wang, Wennan and Ni, Tongguang},
title = {Deep Learning Software Defect Prediction Methods for Cloud Environments Research},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/2323100},
doi = {10.1155/2021/2323100},
abstract = {This paper provides an in-depth study and analysis of software defect prediction methods in a cloud environment and uses a deep learning approach to justify software prediction. A cost penalty term is added to the supervised part of the deep ladder network; that is, the misclassification cost of different classes is added to the model. A cost-sensitive deep ladder network-based software defect prediction model is proposed, which effectively mitigates the negative impact of the class imbalance problem on defect prediction. To address the problem of lack or insufficiency of historical data from the same project, a flow learning-based geodesic cross-project software defect prediction method is proposed. Drawing on data information from other projects, a migration learning approach was used to embed the source and target datasets into a Gaussian manifold. The kernel encapsulates the incremental changes between the differences and commonalities between the two domains. To this point, the subspace is the space of two distributional approximations formed by the source and target data transformations, with traditional in-project software defect classifiers used to predict labels. It is found that real-time defect prediction is more practical because it has a smaller amount of code to review; only individual changes need to be reviewed rather than entire files or packages while making it easier for developers to assign fixes to defects. More importantly, this paper combines deep belief network techniques with real-time defect prediction at a fine-grained level and TCA techniques to deal with data imbalance and proposes an improved deep belief network approach for real-time defect prediction, while trying to change the machine learning classifier underlying DBN for different experimental studies, and the results not only validate the effectiveness of using TCA techniques to solve the data imbalance problem but also show that the defect prediction model learned by the improved method in this paper has better prediction performance.},
journal = {Sci. Program.},
month = jan,
numpages = {11}
}

@article{10.1016/j.infsof.2021.106662,
author = {Feng, Shuo and Keung, Jacky and Yu, Xiao and Xiao, Yan and Zhang, Miao},
title = {Investigation on the stability of SMOTE-based oversampling techniques in software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106662},
doi = {10.1016/j.infsof.2021.106662},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {14},
keywords = {Empirical Software Engineering, SMOTE, Oversampling, Class imbalance, Software defect prediction}
}

@article{10.1016/j.jss.2021.111026,
author = {Zhu, Kun and Ying, Shi and Zhang, Nana and Zhu, Dandan},
title = {Software defect prediction based on enhanced metaheuristic feature selection optimization and a hybrid deep neural network},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111026},
doi = {10.1016/j.jss.2021.111026},
journal = {J. Syst. Softw.},
month = oct,
numpages = {25},
keywords = {Kernel extreme learning machine, Convolutional neural network, Whale optimization algorithm, Metaheuristic feature selection, Software defect prediction}
}

@article{10.1007/s11277-017-5117-z,
author = {Zhou, Lijuan and Li, Ran and Zhang, Shudong and Wang, Hua},
title = {Imbalanced Data Processing Model for Software Defect Prediction},
year = {2018},
issue_date = {Sep 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {2},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-5117-z},
doi = {10.1007/s11277-017-5117-z},
abstract = {In the field of software engineering, software defect prediction is the hotspot of the researches which can effectively guarantee the quality during software development. However, the problem of class imbalanced datasets will affect the accuracy of overall classification of software defect prediction, which is the key issue to be solved urgently today. In order to better solve this problem, this paper proposes a model named ASRA which combines attribute selection, sampling technologies and ensemble algorithm. The model adopts the Chi square test of attribute selection and then utilizes the combined sampling technique which includes SMOTE over-sampling and under-sampling to remove the redundant attributes and make the datasets balance. Afterwards, the model ASRA is eventually established by ensemble algorithm named Adaboost with basic classifier J48 decision tree. The data used in the experiments comes from UCI datasets. It can draw the conclusion that the effect of software defect prediction classification which using this model is improved and better than before by comparing the precision P, F-measure and AUC values from the results of the experiments.},
journal = {Wirel. Pers. Commun.},
month = sep,
pages = {937–950},
numpages = {14},
keywords = {Software defect prediction, Sampling, Ensemble algorithm, Class imbalance, Attribute selection}
}

@article{10.1007/s10515-021-00289-8,
author = {Ali, Aftab and Khan, Naveed and Abu-Tair, Mamun and Noppen, Joost and McClean, Sally and McChesney, Ian},
title = {Discriminating features-based cost-sensitive approach for software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-021-00289-8},
doi = {10.1007/s10515-021-00289-8},
abstract = {Correlated quality metrics extracted from a source code repository can be utilized to design a model to automatically predict defects in a software system. It is obvious that the extracted metrics will result in a highly unbalanced data, since the number of defects in a good quality software system should be far less than the number of normal instances. It is also a fact that the selection of the best discriminating features significantly improves the robustness and accuracy of a prediction model. Therefore, the contribution of this paper is twofold, first it selects the best discriminating features that help in accurately predicting a defect in a software component. Secondly, a cost-sensitive logistic regression and decision tree ensemble-based prediction models are applied to the best discriminating features for precisely predicting a defect in a software component. The proposed models are compared with the most recent schemes in the literature in terms of accuracy, area under the curve, and recall. The models are evaluated using 11 datasets and it is evident from the results and analysis that the performance of the proposed prediction models outperforms the schemes in the literature.},
journal = {Automated Software Engg.},
month = nov,
numpages = {18},
keywords = {Recall, AUC, Cost-sensitivity, Discriminating features, Machine learning models, Software bugs/defects}
}

@article{10.1016/j.neucom.2021.05.043,
author = {Harzevili, Nima Shiri and Alizadeh, Sasan H.},
title = {Analysis and modeling conditional mutual dependency of metrics in software defect prediction using latent variables},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {460},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.05.043},
doi = {10.1016/j.neucom.2021.05.043},
journal = {Neurocomput.},
month = oct,
pages = {309–330},
numpages = {22},
keywords = {99–00, 00–01, Latent variable, Naive Bayes classifier, Software defect prediction Software metrics}
}

@article{10.1007/s10664-020-09861-4,
author = {Morasca, Sandro and Lavazza, Luigi},
title = {On the assessment of software defect prediction models via ROC curves},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09861-4},
doi = {10.1007/s10664-020-09861-4},
abstract = {Software defect prediction models are classifiers often built by setting a threshold t on a defect proneness model, i.e., a scoring function. For instance, they classify a software module non-faulty if its defect proneness is below t and positive otherwise. Different values of t may lead to different defect prediction models, possibly with very different performance levels. Receiver Operating Characteristic (ROC) curves provide an overall assessment of a defect proneness model, by taking into account all possible values of t and thus all defect prediction models that can be built based on it. However, using a defect proneness model with a value of t is sensible only if the resulting defect prediction model has a performance that is at least as good as some minimal performance level that depends on practitioners’ and researchers’ goals and needs. We introduce a new approach and a new performance metric (the Ratio of Relevant Areas) for assessing a defect proneness model by taking into account only the parts of a ROC curve corresponding to values of t for which defect proneness models have higher performance than some reference value. We provide the practical motivations and theoretical underpinnings for our approach, by: 1) showing how it addresses the shortcomings of existing performance metrics like the Area Under the Curve and Gini’s coefficient; 2) deriving reference values based on random defect prediction policies, in addition to deterministic ones; 3) showing how the approach works with several performance metrics (e.g., Precision and Recall) and their combinations; 4) studying misclassification costs and providing a general upper bound for the cost related to the use of any defect proneness model; 5) showing the relationships between misclassification costs and performance metrics. We also carried out a comprehensive empirical study on real-life data from the SEACRAFT repository, to show the differences between our metric and the existing ones and how more reliable and less misleading our metric can be.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3977–4019},
numpages = {43},
keywords = {Gini, AUC, Thresholds, ROC, Software defect proneness, Software defect prediction model}
}

@inproceedings{10.1109/ASE.2019.00071,
author = {Gong, Lina and Jiang, Shujuan and Wang, Rongcun and Jiang, Li},
title = {Empirical evaluation of the impact of class overlap on software defect prediction},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00071},
doi = {10.1109/ASE.2019.00071},
abstract = {Software defect prediction (SDP) utilizes the learning models to detect the defective modules in project, and their performance depends on the quality of training data. The previous researches mainly focus on the quality problems of class imbalance and feature redundancy. However, training data often contains some instances that belong to different class but have similar values on features, and this leads to class overlap to affect the quality of training data. Our goal is to investigate the impact of class overlap on software defect prediction. At the same time, we propose an improved K-Means clustering cleaning approach (IKMCCA) to solve both the class overlap and class imbalance problems. Specifically, we check whether K-Means clustering cleaning approach (KMCCA) or neighborhood cleaning learning (NCL) or IKMCCA is feasible to improve defect detection performance for two cases (i) within-project defect prediction (WPDP) (ii) cross-project defect prediction (CPDP). To have an objective estimate of class overlap, we carry out our investigations on 28 open source projects, and compare the performance of state-of-the-art learning models for the above-mentioned cases by using IKMCCA or KMCCA or NCL VS. without cleaning data. The experimental results make clear that learning models obtain significantly better performance in terms of balance, Recall and AUC for both WPDP and CPDP when the overlapping instances are removed. Moreover, it is better to consider both class overlap and class imbalance.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {698–709},
numpages = {12},
keywords = {software defect prediction, machine learning, class overlap, K-Means clustering},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3474124.3474127,
author = {Rajnish, Kumar and Bhattacharjee, Vandana and Chandrabanshi, Vishnu},
title = {Applying Cognitive and Neural Network Approach over Control Flow Graph for Software Defect Prediction},
year = {2021},
isbn = {9781450389204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474124.3474127},
doi = {10.1145/3474124.3474127},
booktitle = {Proceedings of the 2021 Thirteenth International Conference on Contemporary Computing},
pages = {13–17},
numpages = {5},
keywords = {Software Defect Prediction, Neural Network, Graph Convolutional Network, Cognitive Measures, Cognitive Complexity, CFGs},
location = {Noida, India},
series = {IC3-2021}
}

@inproceedings{10.1145/3377811.3380389,
author = {Chen, Jinyin and Hu, Keke and Yu, Yue and Chen, Zhuangzhi and Xuan, Qi and Liu, Yi and Filkov, Vladimir},
title = {Software visualization and deep transfer learning for effective software defect prediction},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380389},
doi = {10.1145/3377811.3380389},
abstract = {Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort. Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules. Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models.To bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools. To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction. Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction. Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {578–589},
numpages = {12},
keywords = {cross-project defect prediction, deep transfer learning, self-attention, software visualization, within-project defect prediction},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1007/978-3-031-08421-8_41,
author = {Giorgio, Lazzarinetti and Nicola, Massarenti and Fabio, Sgr\`{o} and Andrea, Salafia},
title = {Continuous Defect Prediction in CI/CD Pipelines: A Machine Learning-Based Framework},
year = {2021},
isbn = {978-3-031-08420-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-08421-8_41},
doi = {10.1007/978-3-031-08421-8_41},
abstract = {Recent advances in information technology has led to an increasing number of applications to be developed and maintained daily by product teams. Ensuring that a software application works as expected and that it is absent of bugs requires a lot of time and resources. Thanks to the recent adoption of DevOps methodologies, it is often the case where code commits and application builds are centralized and standardized. Thanks to this new approach, it is now possible to retrieve log and build data to ease the development and management operations of product teams. However, even if such approaches include code control to detect unit or integration errors, they do not check for the presence of logical bugs that can raise after code builds. For such reasons in this work we propose a framework for continuous defect prediction based on machine learning algorithms trained on a publicly available dataset. The framework is composed of a machine learning model for detecting the presence of logical bugs in code on the basis of the available data generated by DevOps tools and a dashboard to monitor the software projects status. We also describe the serverless architecture we designed for hosting the aforementioned framework.},
booktitle = {AIxIA 2021 – Advances in Artificial Intelligence: 20th International Conference of the Italian Association for Artificial Intelligence, Virtual Event, December 1–3, 2021, Revised Selected Papers},
pages = {591–606},
numpages = {16},
keywords = {Continuous integration, DevOps, Machine learning, Continuous defect prediction}
}

@inproceedings{10.1145/3374549.3374553,
author = {Zong, Liang},
title = {Classification Based Software Defect Prediction Model for Finance Software System - An Industry Study},
year = {2020},
isbn = {9781450376495},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374549.3374553},
doi = {10.1145/3374549.3374553},
abstract = {Automated software defect prediction is an important and fundamental activity in the domain of software development. Successful software defect prediction can save testing effort thus reduce the time and cost for software development. However, software systems for finance company are inherently large and complex with numerous interfaces with other systems. Thus, identifying and selecting a good model and a set of features is important but challenging problem. In our paper, we first define the problem we want to solve. Then we propose a prediction model based on binary classification and a set of novel features, which is more specific for finance software systems. We collected 15 months real production data and labelled it as our dataset. The experiment shows our model and features can give a better prediction accuracy for finance systems. In addition, we demonstrate how our prediction model helps improve our production quality further. Unlike other research papers, our proposal focuses to solve problem in real finance industry.},
booktitle = {Proceedings of the 2019 3rd International Conference on Software and E-Business},
pages = {60–65},
numpages = {6},
keywords = {Software defect prediction, Machine learning, Finance system, Faulty change},
location = {Tokyo, Japan},
series = {ICSEB '19}
}

@article{10.1504/ijcat.2020.110428,
author = {Bai, Xue and Zhou, Hua and Yang, Hongji and Wang, Dong},
title = {Connecting historical changes for cross-version software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {63},
number = {4},
issn = {0952-8091},
url = {https://doi.org/10.1504/ijcat.2020.110428},
doi = {10.1504/ijcat.2020.110428},
abstract = {In the whole software life cycle, software defects are inevitable and increase the cost of software development and evolution. Cross-Version Software Defect Prediction (CVSDP) aims at learning the defect patterns from the historical data of previous software versions to distinguish buggy software modules from clean ones. In CVSDP, metrics are intrinsic properties associated with the external manifestation of defects. However, traditional software defect measures ignore the sequential information of changes during software evolution process which may play a crucial role in CVSDP. Therefore, researchers tried to connect traditional metrics across versions as a new kind of evolution metrics. This study proposes a new way to connect historical sequence of metrics based on change sequence named HCSM and designs a novel deep learning algorithm GDNN as a classifier to process it. Compared to the traditional metrics approaches and other relevant approaches, the proposed approach fits in projects with stable and orderly defect control trend.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {371–383},
numpages = {12},
keywords = {gate recurrent unit, deep neural networks, DNN, deep learning, historical change sequences, software metrics, cross-version defect prediction, software testing}
}

@article{10.1007/s00500-021-06096-3,
author = {Pandey, Sushant Kumar and Tripathi, Anil Kumar},
title = {An empirical study toward dealing with noise and class imbalance issues in software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {21},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06096-3},
doi = {10.1007/s00500-021-06096-3},
abstract = {The quality of the defect datasets is a critical issue in the domain of software defect prediction (SDP). These datasets are obtained through the mining of software repositories. Recent studies claim over the quality of the defect dataset. It is because of inconsistency between bug/clean fix keyword in fault reports and the corresponding link in the change management logs. Class Imbalance (CI) problem is also a big challenging issue in SDP models. The defect prediction method trained using noisy and imbalanced data leads to inconsistent and unsatisfactory results. Combined analysis over noisy instances and CI problem needs to be required. To the best of our knowledge, there are insufficient studies that have been done over such aspects. In this paper, we deal with the impact of noise and CI problem on five baseline SDP models; we manually added the various noise level (0–80%) and identified its impact on the performance of those SDP models. Moreover, we further provide guidelines for the possible range of tolerable noise for baseline models. We have also suggested the SDP model, which has the highest noise tolerable ability and outperforms over other classical methods. The True Positive Rate (TPR) and False Positive Rate (FPR) values of the baseline models reduce between 20–30% after adding 10–40% noisy instances. Similarly, the ROC (Receiver Operating Characteristics) values of SDP models reduce to 40–50%. The suggested model leads to avoid noise between 40–60% as compared to other traditional models.},
journal = {Soft Comput.},
month = nov,
pages = {13465–13492},
numpages = {28},
keywords = {Fault proneness, Software metrics, Machine learning, Noisy instance, Class imbalance, Software fault prediction, Software testing}
}

@article{10.1007/s10586-018-1730-1,
author = {Jayanthi, R. and Florence, Lilly},
title = {Software defect prediction techniques using metrics based on neural network classifier},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-018-1730-1},
doi = {10.1007/s10586-018-1730-1},
abstract = {Software industries strive for software quality improvement by consistent bug prediction, bug removal and prediction of fault-prone module. This area has attracted researchers due to its significant involvement in software industries. Various techniques have been presented for software defect prediction. Recent researches have recommended data-mining using machine learning as an important paradigm for software bug prediction. state-of-art software defect prediction task suffer from various issues such as classification accuracy. However, software defect datasets are imbalanced in nature and known fault prone due to its huge dimension. To address this issue, here we present a combined approach for software defect prediction and prediction of software bugs. Proposed approach delivers a concept of feature reduction and artificial intelligence where feature reduction is carried out by well-known principle component analysis (PCA) scheme which is further improved by incorporating maximum-likelihood estimation for error reduction in PCA data reconstruction. Finally, neural network based classification technique is applied which shows prediction results. A framework is formulated and implemented on NASA software dataset where four datasets i.e., KC1, PC3, PC4 and JM1 are considered for performance analysis using MATLAB simulation tool. An extensive experimental study is performed where confusion, precision, recall, classification accuracy etc. parameters are computed and compared with existing software defect prediction techniques. Experimental study shows that proposed approach can provide better performance for software defect prediction.},
journal = {Cluster Computing},
month = jan,
pages = {77–88},
numpages = {12},
keywords = {Software metrics, Software defect prediction, Machine learning techniques, Defect prediction models}
}

@inproceedings{10.1145/3238147.3240469,
author = {Qu, Yu and Liu, Ting and Chi, Jianlei and Jin, Yangxu and Cui, Di and He, Ancheng and Zheng, Qinghua},
title = {node2defect: using network embedding to improve software defect prediction},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240469},
doi = {10.1145/3238147.3240469},
abstract = {Network measures have been proved to be useful in predicting software defects. Leveraging the dependency relationships between software modules, network measures can capture various structural features of software systems. However, existing studies have relied on user-defined network measures (e.g., degree statistics or centrality metrics), which are inflexible and require high computation cost, to describe the structural features. In this paper, we propose a new method called node2defect which uses a newly proposed network embedding technique, node2vec, to automatically learn to encode dependency network structure into low-dimensional vector spaces to improve software defect prediction. Specifically, we firstly construct a program's Class Dependency Network. Then node2vec is used to automatically learn structural features of the network. After that, we combine the learned features with traditional software engineering features, for accurate defect prediction. We evaluate our method on 15 open source programs. The experimental results show that in average, node2defect improves the state-of-the-art approach by 9.15% in terms of F-measure.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {844–849},
numpages = {6},
keywords = {software metrics, network embedding, defect prediction, Software defect},
location = {Montpellier, France},
series = {ASE '18}
}

@article{10.1007/s11219-016-9342-6,
author = {Chen, Lin and Fang, Bin and Shang, Zhaowei and Tang, Yuanyan},
title = {Tackling class overlap and imbalance problems in software defect prediction},
year = {2018},
issue_date = {March     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9342-6},
doi = {10.1007/s11219-016-9342-6},
abstract = {Software defect prediction (SDP) is a promising solution to save time and cost in the software testing phase for improving software quality. Numerous machine learning approaches have proven effective in SDP. However, the unbalanced class distribution in SDP datasets could be a problem for some conventional learning methods. In addition, class overlap increases the difficulty for the predictors to learn the defective class accurately. In this study, we propose a new SDP model which combines class overlap reduction and ensemble imbalance learning to improve defect prediction. First, the neighbor cleaning method is applied to remove the overlapping non-defective samples. The whole dataset is then randomly under-sampled several times to generate balanced subsets so that multiple classifiers can be trained on these data. Finally, these individual classifiers are assembled with the AdaBoost mechanism to build the final prediction model. In the experiments, we investigated nine highly unbalanced datasets selected from a public software repository and confirmed that the high rate of overlap between classes existed in SDP data. We assessed the performance of our proposed model by comparing it with other state-of-the-art methods including conventional SDP models, imbalance learning and data cleaning methods. Test results and statistical analysis show that the proposed model provides more reasonable defect prediction results and performs best in terms of G-mean and AUC among all tested models.},
journal = {Software Quality Journal},
month = mar,
pages = {97–125},
numpages = {29},
keywords = {Software defect prediction, Machine learning, Class overlap, Class imbalance}
}

@article{10.1504/ijcse.2020.106871,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {A benchmarking framework using nonlinear manifold detection techniques for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {21},
number = {4},
issn = {1742-7185},
url = {https://doi.org/10.1504/ijcse.2020.106871},
doi = {10.1504/ijcse.2020.106871},
abstract = {Prediction of software defects in time improves quality and helps in locating the defect-prone areas accurately. Although earlier considerable methods were applied, actually none of those measures was found to be fool-proof and accurate. Hence, a newer framework includes nonlinear manifold detection model, and its algorithm originated for defect prediction using different techniques of nonlinear manifold detection (nonlinear MDs) along with 14 different machine learning techniques (MLTs) on eight defective software datasets. A critical analysis cum exhaustive comparative estimation revealed that nonlinear manifold detection model has a more accurate and effective impact on defect prediction as compared to feature selection techniques. The outcome of the experiment was statistically tested by Friedman and post hoc analysis using Nemenyi test, which validates that hidden Markov model (HMM) along with nonlinear manifold detection model outperforms and is significantly different from MLTs.},
journal = {Int. J. Comput. Sci. Eng.},
month = jan,
pages = {593–614},
numpages = {21},
keywords = {post hoc analysis, software defect prediction, nonlinear manifold detection, Nemenyi test, machine learning, Friedman test, feature selection, dimensionality reduction}
}

@inproceedings{10.1109/IRI.2018.00047,
author = {Xu, Ling and Wang, Bei and Liu, Ling and Zhou, Mo and Liao, Shengping and Yan, Meng},
title = {Misclassification Cost-Sensitive Software Defect Prediction},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IRI.2018.00047},
doi = {10.1109/IRI.2018.00047},
abstract = {Software defect prediction helps developers focus on defective modules for efficient software quality assurance. A common goal shared by existing software defect prediction methods is to attain low classification error rates. These proposals suffer from two practical problems: (i) Most of the prediction methods rely on a large number of labeled training data. However, collecting labeled data is a difficult and expensive task. It is hard to obtain classification labels over new software projects or existing projects without historical defect data. (ii) Software defect datasets are highly imbalanced. In many real-world applications, the misclassification cost of defective modules is generally several times higher than that of non-defective ones. In this paper, we present a misclassification Cost-sensitive approach to Software Defect Prediction (CSDP). The CSDP approach is novel in two aspects: First, CSDP addresses the problem of unlabeled software detect datasets by combining an unsupervised sampling method with a domain specific misclassification cost model. This preprocessing step selectively samples a small percentage of modules through estimating their classification labels. Second, CSDP builds a cost-sensitive support vector machine model to predict defect-proneness of the rest of modules with both overall classification error rate and domain specific misclassification cost as quality metrics. CSDP is evaluated on four NASA projects. Experimental results highlight three interesting observations: (1) CSDP achieves higher Normalized Expected Cost of Misclassification (NECM) compared with state-of-art supervised learning models under imbalanced training data with limited labeling. (2) CSDP outperforms state-of-art semi-supervised learning methods, which disregards classification costs, especially in recall rate. (3) CSDP enhanced through unsupervised sampling as a preprocessing step prior to training and prediction outperforms the baseline CSDP without the sampling process.},
booktitle = {2018 IEEE International Conference on Information Reuse and Integration (IRI)},
pages = {256–263},
numpages = {8},
location = {Salt Lake City, UT, USA}
}

@article{10.5555/2684939.2684969,
author = {Ma, Ying and Pan, Weiwei and Zhu, Shunzhi and Yin, Huayi and Luo, Jian},
title = {An improved semi-supervised learning method for software defect prediction},
year = {2014},
issue_date = {September 2014},
publisher = {IOS Press},
address = {NLD},
volume = {27},
number = {5},
issn = {1064-1246},
abstract = {This paper presents an improved semi-supervised learning approach for defect prediction involving class imbalanced and limited labeled data problem. This approach employs random under-sampling technique to resample the original training set and updating training set in each round for co-train style algorithm. It makes the defect predictor more practical for real applications, by combating these problems. In comparison with conventional machine learning approaches, our method has significant superior performance. Experimental results also show that with the proposed learning approach, it is possible to design better method to tackle the class imbalanced problem in semi-supervised learning.},
journal = {J. Intell. Fuzzy Syst.},
month = sep,
pages = {2473–2480},
numpages = {8},
keywords = {Semi-Supervised Learning, Random Sampling, Defect Prediction, Co-Train, Class Imbalance}
}

@inproceedings{10.1007/978-3-030-34885-4_27,
author = {Ali, Aftab and Abu-Tair, Mamun and Noppen, Joost and McClean, Sally and Lin, Zhiwei and McChesney, Ian},
title = {Contributing Features-Based Schemes for Software Defect Prediction},
year = {2019},
isbn = {978-3-030-34884-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-34885-4_27},
doi = {10.1007/978-3-030-34885-4_27},
abstract = {Automated defect prediction of large and complex software systems is a challenging task. However, by utilising correlated quality metrics, a defect prediction model can be devised to automatically predict the defects in a software system. The robustness and accuracy of a prediction model is highly dependent on the selection of contributing and non-contributing features. Hence, in this regard, the contribution of this paper is twofold, first it separates those features which are contributing towards the development of a defect in a software component from those which are non-contributing features. Secondly, a logistic regression and Ensemble Bagged Trees-based prediction model are applied on the contributing features for accurately predicting a defect in a software component. The proposed models are compared with the most recent scheme in the literature in terms of accuracy and area under the curve (AUC). It is evident from the results and analysis that the performance of the proposed prediction models outperforms the schemes in the literature.},
booktitle = {Artificial Intelligence XXXVI: 39th SGAI International Conference on Artificial Intelligence, AI 2019, Cambridge, UK, December 17–19, 2019, Proceedings},
pages = {350–361},
numpages = {12},
keywords = {Prediction models, Intelligent information retrieval, Machine learning},
location = {Cambridge, United Kingdom}
}

@article{10.1016/j.neucom.2019.03.076,
author = {Zhao, Linchang and Shang, Zhaowei and Zhao, Ling and Zhang, Taiping and Tang, Yuan Yan},
title = {Software defect prediction via cost-sensitive Siamese parallel fully-connected neural networks},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {352},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.03.076},
doi = {10.1016/j.neucom.2019.03.076},
journal = {Neurocomput.},
month = aug,
pages = {64–74},
numpages = {11},
keywords = {Software defect prediction, Few-shot learning, Deep learning, Cost-sensitive learning, Siamese parallel fully-connected networks}
}

@article{10.1049/iet-sen.2017.0148,
author = {Li, Zhiqiang and Jing, Xiao-Yuan and Zhu, Xiaoke},
title = {Progress on approaches to software defect prediction},
year = {2018},
issue_date = {June 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2017.0148},
doi = {10.1049/iet-sen.2017.0148},
abstract = {Software defect prediction is one of the most popular research topics in software engineering. It aims to predict defect‐prone software modules before defects are discovered, therefore it can be used to better prioritise software quality assurance effort. In recent years, especially for recent 3 years, many new defect prediction studies have been proposed. The goal of this study is to comprehensively review, analyse and discuss the state‐of‐the‐art of defect prediction. The authors survey almost 70 representative defect prediction papers in recent years (January 2014–April 2017), most of which are published in the prominent software engineering journals and top conferences. The selected defect prediction papers are summarised to four aspects: machine learning‐based prediction algorithms, manipulating the data, effort‐aware prediction and empirical studies. The research community is still facing a number of challenges for building methods and many research opportunities exist. The identified challenges can give some practical guidelines for both software engineering researchers and practitioners in future software defect prediction.},
journal = {IET Software},
month = jun,
pages = {161–175},
numpages = {15},
keywords = {empirical studies, effort-aware prediction, data manipulation, machine learning-based prediction algorithms, software quality assurance, defect-prone software modules, software engineering journals, software defect prediction, research and development, quality assurance, software reliability, software quality}
}

@inproceedings{10.1007/978-3-030-29551-6_23,
author = {Miholca, Diana-Lucia and Czibula, Gabriela},
title = {Software Defect Prediction Using a Hybrid Model Based on Semantic Features Learned from the Source Code},
year = {2019},
isbn = {978-3-030-29550-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-29551-6_23},
doi = {10.1007/978-3-030-29551-6_23},
abstract = {Software defect prediction has extensive applicability thus being a very active research area in Search-Based Software Engineering. A high proportion of the software defects are caused by violated couplings. In this paper, we investigate the relevance of semantic coupling in assessing the software proneness to defects. We propose a hybrid classification model combining Gradual Relational Association Rules with Artificial Neural Networks, which detects the defective software entities based on semantic features automatically learned from the source code. The experiments we have performed led to results that confirm the interplay between conceptual coupling and software defects proneness.},
booktitle = {Knowledge Science, Engineering and Management: 12th International Conference, KSEM 2019, Athens, Greece, August 28–30, 2019, Proceedings, Part I},
pages = {262–274},
numpages = {13},
keywords = {Conceptual coupling, Machine learning, Software defect prediction},
location = {Athens, Greece}
}

@article{10.1007/s10515-020-00277-4,
author = {Esteves, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
title = {Understanding machine learning software defect predictions},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3–4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-020-00277-4},
doi = {10.1007/s10515-020-00277-4},
abstract = {Software defects are well-known in software development and might cause several problems for users and developers aside. As a result, researches employed distinct techniques to mitigate the impacts of these defects in the source code. One of the most notable techniques focuses on defect prediction using machine learning methods, which could support developers in handling these defects before they are introduced in the production environment. These studies provide alternative approaches to predict the likelihood of defects. However, most of these works concentrate on predicting defects from a vast set of software features. Another key issue with the current literature is the lack of a satisfactory explanation of the reasons that drive the software to a defective state. Specifically, we use a tree boosting algorithm (XGBoost) that receives as input a training set comprising records of easy-to-compute characteristics of each module and outputs whether the corresponding module is defect-prone. To exploit the link between predictive power and model explainability, we propose a simple model sampling approach that finds accurate models with the minimum set of features. Our principal idea is that features not contributing to increasing the predictive power should not be included in the model. Interestingly, the reduced set of features helps to increase model explainability, which is important to provide information to developers on features related to each module of the code which is more defect-prone. We evaluate our models on diverse projects within Jureczko datasets, and we show that (i) features that contribute most for finding best models may vary depending on the project and (ii) it is possible to find effective models that use few features leading to better understandability. We believe our results are useful to developers as we provide the specific software features that influence the defectiveness of selected projects.},
journal = {Automated Software Engg.},
month = dec,
pages = {369–392},
numpages = {24},
keywords = {SHAP values, Jureczko datasets, Explainable models, Software defects}
}

@article{10.1007/s11227-019-03051-w,
author = {NezhadShokouhi, Mohammad Mahdi and Majidi, Mohammad Ali and Rasoolzadegan, Abbas},
title = {Software defect prediction using over-sampling and feature extraction based on Mahalanobis distance},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {1},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-019-03051-w},
doi = {10.1007/s11227-019-03051-w},
abstract = {As the size of software projects becomes larger, software defect prediction (SDP) will play a key role in allocating testing resources reasonably, reducing testing costs, and speeding up the development process. Most SDP methods have used machine learning techniques based on common software metrics such as Halstead and McCabe’s cyclomatic. Datasets produced by these metrics usually do not follow Gaussian distribution, and also, they have overlaps in defect and non-defect classes. In addition, in many of software defect datasets, the number of defective modules (minority class) is considerably less than non-defective modules (majority class). In this situation, the performance of machine learning methods is reduced dramatically. Therefore, we first need to create a balance between minority and majority classes and then transfer the samples into a new space in which pair samples with same class (must-link set) are near to each other as close as possible and pair samples with different classes (cannot-link) stay as far as possible. To achieve the mentioned objectives, in this paper, Mahalanobis distance in two manners will be used. First, the minority class is oversampled based on the Mahalanobis distance such that generated synthetic data are more diverse from other minority data, and minority class distribution is not changed significantly. Second, a feature extraction method based on Mahalanobis distance metric learning is used which try to minimize distances of sample pairs in must-links and maximize the distance of sample pairs in cannot-links. To demonstrate the effectiveness of the proposed method, we performed some experiments on 12 publicly available datasets which are collected NASA repositories and compared its result by some powerful previous methods. The performance is evaluated in F-measure, G-Mean, and Matthews correlation coefficient. Generally, the proposed method has better performance as compared to the mentioned methods.},
journal = {J. Supercomput.},
month = jan,
pages = {602–635},
numpages = {34},
keywords = {Feature extraction, Over-sampling, Mahalanobis distance, Software metrics, Software defect prediction}
}

@article{10.1155/2019/6230953,
author = {Fan, Guisheng and Diao, Xuyang and Yu, Huiqun and Yang, Kang and Chen, Liqiong and Vitiello, Autilia},
title = {Software Defect Prediction via Attention-Based Recurrent Neural Network},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1058-9244},
url = {https://doi.org/10.1155/2019/6230953},
doi = {10.1155/2019/6230953},
abstract = {In order to improve software reliability, software defect prediction is applied to the process of software maintenance to identify potential bugs. Traditional methods of software defect prediction mainly focus on designing static code metrics, which are input into machine learning classifiers to predict defect probabilities of the code. However, the characteristics of these artificial metrics do not contain the syntactic structures and semantic information of programs. Such information is more significant than manual metrics and can provide a more accurate predictive model. In this paper, we propose a framework called defect prediction via attention-based recurrent neural network (DP-ARNN). More specifically, DP-ARNN first parses abstract syntax trees (ASTs) of programs and extracts them as vectors. Then it encodes vectors which are used as inputs of DP-ARNN by dictionary mapping and word embedding. After that, it can automatically learn syntactic and semantic features. Furthermore, it employs the attention mechanism to further generate significant features for accurate defect prediction. To validate our method, we choose seven open-source Java projects in Apache, using F1-measure and area under the curve (AUC) as evaluation criteria. The experimental results show that, in average, DP-ARNN improves the F1-measure by 14% and AUC by 7% compared with the state-of-the-art methods, respectively.},
journal = {Sci. Program.},
month = jan,
numpages = {14}
}

@article{10.1007/s10515-015-0179-1,
author = {Wang, Tiejian and Zhang, Zhiwu and Jing, Xiaoyuan and Zhang, Liqiang},
title = {Multiple kernel ensemble learning for software defect prediction},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-015-0179-1},
doi = {10.1007/s10515-015-0179-1},
abstract = {Software defect prediction aims to predict the defect proneness of new software modules with the historical defect data so as to improve the quality of a software system. Software historical defect data has a complicated structure and a marked characteristic of class-imbalance; how to fully analyze and utilize the existing historical defect data and build more precise and effective classifiers has attracted considerable researchers' interest from both academia and industry. Multiple kernel learning and ensemble learning are effective techniques in the field of machine learning. Multiple kernel learning can map the historical defect data to a higher-dimensional feature space and make them express better, and ensemble learning can use a series of weak classifiers to reduce the bias generated by the majority class and obtain better predictive performance. In this paper, we propose to use the multiple kernel learning to predict software defect. By using the characteristics of the metrics mined from the open source software, we get a multiple kernel classifier through ensemble learning method, which has the advantages of both multiple kernel learning and ensemble learning. We thus propose a multiple kernel ensemble learning (MKEL) approach for software defect classification and prediction. Considering the cost of risk in software defect prediction, we design a new sample weight vector updating strategy to reduce the cost of risk caused by misclassifying defective modules as non-defective ones. We employ the widely used NASA MDP datasets as test data to evaluate the performance of all compared methods; experimental results show that MKEL outperforms several representative state-of-the-art defect prediction methods.},
journal = {Automated Software Engg.},
month = dec,
pages = {569–590},
numpages = {22},
keywords = {Software defect prediction, Multiple kernel learning, Multiple kernel ensemble learning (MKEL), Ensemble learning}
}

@article{10.1007/s11219-018-9436-4,
author = {Ji, Haijin and Huang, Song and Wu, Yaning and Hui, Zhanwei and Zheng, Changyou},
title = {A new weighted naive Bayes method based on information diffusion for software defect prediction},
year = {2019},
issue_date = {Sep 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9436-4},
doi = {10.1007/s11219-018-9436-4},
abstract = {Software defect prediction (SDP) plays a significant part in identifying the most defect-prone modules before software testing and allocating limited testing resources. One of the most commonly used classifiers in SDP is naive Bayes (NB). Despite the simplicity of the NB classifier, it can often perform better than more complicated classification models. In NB, the features are assumed to be equally important, and the numeric features are assumed to have a normal distribution. However, the features often do not contribute equivalently to the classification, and they usually do not have a normal distribution after performing a Kolmogorov-Smirnov test; this may harm the performance of the NB classifier. Therefore, this paper proposes a new weighted naive Bayes method based on information diffusion (WNB-ID) for SDP. More specifically, for the equal importance assumption, we investigate six weight assignment methods for setting the feature weights and then choose the most suitable one based on the F-measure. For the normal distribution assumption, we apply the information diffusion model (IDM) to compute the probability density of each feature instead of the acquiescent probability density function of the normal distribution. We carry out experiments on 10 software defect data sets of three types of projects in three different programming languages provided by the PROMISE repository. Several well-known classifiers and ensemble methods are included for comparison. The final experimental results demonstrate the effectiveness and practicability of the proposed method.},
journal = {Software Quality Journal},
month = sep,
pages = {923–968},
numpages = {46},
keywords = {Information diffusion, Feature weighting, Naive Bayes, Software defect prediction}
}

@article{10.1016/j.neucom.2018.04.090,
author = {Malhotra, Ruchika and Kamal, Shine},
title = {An empirical study to investigate oversampling methods for improving software defect prediction using imbalanced data},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {343},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.04.090},
doi = {10.1016/j.neucom.2018.04.090},
journal = {Neurocomput.},
month = may,
pages = {120–140},
numpages = {21},
keywords = {Procedural metrics, Machine learning techniques, MetaCost learners, Oversampling methods, Imbalanced data, Defect prediction}
}

@article{10.1504/ijista.2019.102667,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {Statistical assessment of nonlinear manifold detection-based software defect prediction techniques},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {6},
issn = {1740-8865},
url = {https://doi.org/10.1504/ijista.2019.102667},
doi = {10.1504/ijista.2019.102667},
abstract = {Prediction of software defects has immense importance for obtaining desired outcome at minimised cost and so attracted researchers working on this topic applying various techniques, which were not found fully effective. Software datasets comprise of redundant features that hinder effective application of techniques resulting inappropriate defect prediction. Hence, it requires newer application of nonlinear manifold detection techniques (nonlinear MDTs) that has been examined for accurate prediction of defects at lesser time and cost using different classification techniques. In this work, we analysed and tested the effect of nonlinear MDTs to find out accurate and best classification technique for all datasets. Comparison has been made between the results of without or with nonlinear MDTs and paired two-tailed T-test has been performed for statistical testing and verifying the performance of classifiers using nonlinear MDTs on all datasets. Outcome revealed that among all nonlinear MDTs, FastMVU makes most accurate prediction of software defects.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {579–605},
numpages = {26},
keywords = {software defect prediction, promise repository, nonlinear, manifold detection, machine learning, FastMVU, fast maximum variance unfolding, dimensionality reduction}
}

@article{10.1049/iet-sen.2017.0198,
author = {Zhang, Zhi-Wu and Jing, Xiao-Yuan and Wu, Fei},
title = {Low‐rank representation for semi‐supervised software defect prediction},
year = {2018},
issue_date = {December 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {6},
url = {https://doi.org/10.1049/iet-sen.2017.0198},
doi = {10.1049/iet-sen.2017.0198},
abstract = {Software defect prediction based on machine learning is an active research topic in the field of software engineering. The historical defect data in software repositories may contain noises because automatic defect collection is based on modified logs and defect reports. When the previous defect labels of modules are limited, predicting the defect‐prone modules becomes a challenging problem. In this study, the authors propose a graph‐based semi‐supervised defect prediction approach to solve the problems of insufficient labelled data and noisy data. Graph‐based semi‐supervised learning methods used the labelled and unlabelled data simultaneously and consider them as the nodes of the graph at the training phase. Therefore, they solve the problem of insufficient labelled samples. To improve the stability of noisy defect data, a powerful clustering method, low‐rank representation (LRR), and neighbourhood distance are used to construct the relationship graph of samples. Therefore, they propose a new semi‐supervised defect prediction approach, named low‐rank representation‐based semi‐supervised software defect prediction (LRRSSDP). The widely used datasets from NASA projects and noisy datasets are employed as test data to evaluate the performance. Experimental results show that (i) LRRSSDP outperforms several representative state‐of‐the‐art semi‐supervised defect prediction methods; and (ii) LRRSSDP can maintain robustness in noisy environments.},
journal = {IET Software},
month = dec,
pages = {527–535},
numpages = {9},
keywords = {LRRSSDP, low-rank representation, noisy defect data, insufficient labelled samples, unlabelled data, noisy data, insufficient labelled data, semisupervised defect prediction approach, defect-prone modules, defect reports, automatic defect collection, software repositories, historical defect data, software engineering, semisupervised software defect prediction, program diagnostics, graph theory, pattern clustering, learning (artificial intelligence), software engineering}
}

@article{10.1016/j.asoc.2016.06.023,
author = {Mesquita, Diego P.P. and Rocha, Lincoln S. and Gomes, Joo Paulo P. and Rocha Neto, Ajalmar R.},
title = {Classification with reject option for software defect prediction},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.06.023},
doi = {10.1016/j.asoc.2016.06.023},
abstract = {Graphical abstractDisplay Omitted HighlightsWe propose the use of classification with reject option for software defect prediction (SDP) as a way to incorporate additional knowledge in the SDP process.We propose two variants of the extreme learning machine with reject option.It is proposed an ELM with reject option for imbalanced datasets.The proposed method is tested on five real world software datasets.An example is shown to illustrate how the rejected software modules can be further analyzed to improve the final SDP accuracy. ContextSoftware defect prediction (SDP) is an important task in software engineering. Along with estimating the number of defects remaining in software systems and discovering defect associations, classifying the defect-proneness of software modules plays an important role in software defect prediction. Several machine-learning methods have been applied to handle the defect-proneness of software modules as a classification problem. This type of yes or no decision is an important drawback in the decision-making process and if not precise may lead to misclassifications. To the best of our knowledge, existing approaches rely on fully automated module classification and do not provide a way to incorporate extra knowledge during the classification process. This knowledge can be helpful in avoiding misclassifications in cases where system modules cannot be classified in a reliable way. ObjectiveWe seek to develop a SDP method that (i) incorporates a reject option in the classifier to improve the reliability in the decision-making process; and (ii) makes it possible postpone the final decision related to rejected modules for an expert analysis or even for another classifier using extra domain knowledge. MethodWe develop a SDP method called rejoELM and its variant, IrejoELM. Both methods were built upon the weighted extreme learning machine (ELM) with reject option that makes it possible postpone the final decision of non-classified modules, the rejected ones, to another moment. While rejoELM aims to maximize the accuracy for a rejection rate, IrejoELM maximizes the F-measure. Hence, IrejoELM becomes an alternative for classification with reject option for imbalanced datasets. ResultsrejoEM and IrejoELM are tested on five datasets of source code metrics extracted from real world open-source software projects. Results indicate that rejoELM has an accuracy for several rejection rates that is comparable to some state-of-the-art classifiers with reject option. Although IrejoELM shows lower accuracies for several rejection rates, it clearly outperforms all other methods when the F-measure is used as a performance metric. ConclusionIt is concluded that rejoELM is a valid alternative for classification with reject option problems when classes are nearly equally represented. On the other hand, IrejoELM is shown to be the best alternative for classification with reject option on imbalanced datasets. Since SDP problems are usually characterized as imbalanced learning problems, the use of IrejoELM is recommended.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1085–1093},
numpages = {9},
keywords = {Software defect prediction, Extreme learning machines, Classification with reject option}
}

@article{10.1007/s42979-020-0119-4,
author = {Khuat, Thanh Tung and Le, My Hanh},
title = {Evaluation of Sampling-Based Ensembles of Classifiers on Imbalanced Data for Software Defect Prediction Problems},
year = {2020},
issue_date = {Mar 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {2},
url = {https://doi.org/10.1007/s42979-020-0119-4},
doi = {10.1007/s42979-020-0119-4},
abstract = {Defect prediction in software projects plays a crucial role to reduce quality-based risk and increase the capability of detecting faulty program modules. Hence, classification approaches to anticipate software defect proneness based on static code characteristics have become a hot topic with a great deal of attention in recent years. While several novel studies show that the use of a single classifier causes the performance bottleneck, ensembles of classifiers might effectively enhance classification performance compared to a single classifier. However, the class imbalance property of software defect data severely hinders the classification efficiency of ensemble learning. To cope with this problem, resampling methods are usually combined into ensemble models.
This paper empirically assesses the importance of sampling with regard to ensembles of various classifiers on imbalanced data in software defect prediction problems. Extensive experiments with the combination of seven different kinds of classification algorithms, three sampling methods, and two balanced data learning schemata were conducted over ten datasets. Empirical results indicated the positive effects of combining sampling techniques and the ensemble learning model on the performance of defect prediction regarding datasets with imbalanced class distributions.},
journal = {SN Comput. Sci.},
month = mar,
numpages = {16},
keywords = {Imbalanced data, Ensemble learning, Data balancing, SMOTE, Random oversampling, Random undersampling, Software defect prediction}
}

@article{10.4018/IJOSSP.2017100102,
author = {Akour, Mohammed and Melhem, Wasen Yahya},
title = {Software Defect Prediction Using Genetic Programming and Neural Networks},
year = {2017},
issue_date = {October 2017},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {4},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2017100102},
doi = {10.4018/IJOSSP.2017100102},
abstract = {This article describes how classification methods on software defect prediction is widely researched due to the need to increase the software quality and decrease testing efforts. However, findings of past researches done on this issue has not shown any classifier which proves to be superior to the other. Additionally, there is a lack of research that studies the effects and accuracy of genetic programming on software defect prediction. To find solutions for this problem, a comparative software defect prediction experiment between genetic programming and neural networks are performed on four datasets from the NASA Metrics Data repository. Generally, an interesting degree of accuracy is detected, which shows how the metric-based classification is useful. Nevertheless, this article specifies that the application and usage of genetic programming is highly recommended due to the detailed analysis it provides, as well as an important feature in this classification method which allows the viewing of each attributes impact in the dataset.},
journal = {Int. J. Open Source Softw. Process.},
month = oct,
pages = {32–51},
numpages = {20},
keywords = {Testing, Software Defect Prediction, Neural Networks, Nasa Metrics, Machine learning, Genetic Programming, Genetic Algorithm, Classification}
}

@inproceedings{10.1145/3239576.3239622,
author = {Yang, Zhao and Qian, Hongbing},
title = {Automated Parameter Tuning of Artificial Neural Networks for Software Defect Prediction},
year = {2018},
isbn = {9781450364607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239576.3239622},
doi = {10.1145/3239576.3239622},
abstract = {Defect prediction can help predict defect-prone software modules and improve the efficiency and accuracy of defect location and repair, which plays an extremely important role in software quality assurance. Artificial Neural Networks (ANNs), a family of powerful machine learning regression or classification models, have been widely applied for defect prediction. However, the performance of these models will be degraded if they use suboptimal default parameter settings (e.g., the number of units in the hidden layer). This paper utilizes an automated parameter tuning technique-Caret to optimize parameter settings. In our study, 30 datasets are downloaded from the Tera-PROMISE Repository. According to the characteristics of the datasets, we select key features (metrics) as predictors to train defect prediction models. The experiment applies feed-forward, single hidden layer artificial neural network as classifier to build different defect prediction models respectively with optimized parameter settings and with default parameter settings. Confusion matrix and ROC curve are used for evaluating the quality of the models above. The results show that the models trained with optimized parameter settings outperform the models trained with default parameter settings. Hence, we suggest that researchers should pay attention to tuning parameter settings by Caret for ANNs instead of using suboptimal default settings if they select ANNs for training models in the future defect prediction studies.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
pages = {203–209},
numpages = {7},
keywords = {Software defect prediction, Metrics, Automated Parameter Tuning, Artificial Neural Networks},
location = {Chengdu, China},
series = {ICAIP '18}
}

@inproceedings{10.1145/3342999.3343010,
author = {Cui, Mengtian and Sun, Yue and Lu, Yang and Jiang, Yue},
title = {Study on the Influence of the Number of Features on the Performance of Software Defect Prediction Model},
year = {2019},
isbn = {9781450371605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342999.3343010},
doi = {10.1145/3342999.3343010},
abstract = {The software defect prediction model based on machine learning technology is the key to improve the reliability of software. The influence of the number of features on the performance of different software defect prediction models was proposed in this paper. First, a new data sets was built, which is increasing by the number of features based on the NASA public data sets. Then, the eight predictive models are experimented based on these data sets. Next, the influence of the number of features on the performance of different prediction models was analyzed based on the experimental results. Next, the AUC values obtained from the experiment were used to evaluate the performance of different prediction models, and the coefficient of variation C·V values was used to evaluate the performance stability of different prediction models while the number of features changed. In the end, the experiments show that the performance of the predictive model C4.5 is highly susceptible to changes in the number of features, while the performance of the predictive model SMO is relatively stable.},
booktitle = {Proceedings of the 2019 3rd International Conference on Deep Learning Technologies},
pages = {32–37},
numpages = {6},
keywords = {software defect prediction, number of features, machine learning, feature selection},
location = {Xiamen, China},
series = {ICDLT '19}
}

@article{10.1016/j.knosys.2015.09.035,
author = {Li, Weiwei and Huang, Zhiqiu and Li, Qing},
title = {Three-way decisions based software defect prediction},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {91},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.09.035},
doi = {10.1016/j.knosys.2015.09.035},
abstract = {Based on a two-stage classification method and a two-stage ranking method on three-way decisions, this paper introduces a three-way decisions framework for cost-sensitive software defect prediction. For the classification problem in software defect prediction, traditional two-way decisions methods usually generate a higher classification error and more decision cost. Here, a two-stage classification method that integrates three-way decisions and ensemble learning to predict software defect is proposed. Experimental results on NASA data sets show that our method can obtain a higher accuracy and a lower decision cost. For the ranking problem in software defect prediction, a two-stage ranking method is introduced. In the first stage, all software modules are classified into three different regions based on three-way decisions. A dominance relation rough set based ranking algorithm is next applied to rank the modules in each region. Comparison experiments with 6 other ranking methods present that our proposed method can obtain a better result on FPA measure.},
journal = {Know.-Based Syst.},
month = jan,
pages = {263–274},
numpages = {12},
keywords = {Three-way decisions, Software defect ranking, Software defect classification}
}

@inproceedings{10.1145/3377811.3380403,
author = {Tabassum, Sadia and Minku, Leandro L. and Feng, Danyi and Cabral, George G. and Song, Liyan},
title = {An investigation of cross-project learning in online just-in-time software defect prediction},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380403},
doi = {10.1145/3377811.3380403},
abstract = {Just-In-Time Software Defect Prediction (JIT-SDP) is concerned with predicting whether software changes are defect-inducing or clean based on machine learning classifiers. Building such classifiers requires a sufficient amount of training data that is not available at the beginning of a software project. Cross-Project (CP) JIT-SDP can overcome this issue by using data from other projects to build the classifier, achieving similar (not better) predictive performance to classifiers trained on Within-Project (WP) data. However, such approaches have never been investigated in realistic online learning scenarios, where WP software changes arrive continuously over time and can be used to update the classifiers. It is unknown to what extent CP data can be helpful in such situation. In particular, it is unknown whether CP data are only useful during the very initial phase of the project when there is little WP data, or whether they could be helpful for extended periods of time. This work thus provides the first investigation of when and to what extent CP data are useful for JIT-SDP in a realistic online learning scenario. For that, we develop three different CP JIT-SDP approaches that can operate in online mode and be updated with both incoming CP and WP training examples over time. We also collect 2048 commits from three software repositories being developed by a software company over the course of 9 to 10 months, and use 19,8468 commits from 10 active open source GitHub projects being developed over the course of 6 to 14 years. The study shows that training classifiers with incoming CP+WP data can lead to improvements in G-mean of up to 53.90% compared to classifiers using only WP data at the initial stage of the projects. For the open source projects, which have been running for longer periods of time, using CP data to supplement WP data also helped the classifiers to reduce or prevent large drops in predictive performance that may occur over time, leading to up to around 40% better G-Mean during such periods. Such use of CP data was shown to be beneficial even after a large number of WP data were received, leading to overall G-means up to 18.5% better than those of WP classifiers.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {554–565},
numpages = {12},
keywords = {class imbalance, concept drift, cross-project learning, online learning, software defect prediction, transfer learning, verification latency},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1155/2021/4997459,
author = {Li, Zhen and Li, Tong and Wu, YuMei and Yang, Liu and Miao, Hong and Wang, DongSheng and Precup, Radu-Emil},
title = {Software Defect Prediction Based on Hybrid Swarm Intelligence and Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/4997459},
doi = {10.1155/2021/4997459},
abstract = {In order to improve software quality and testing efficiency, this paper implements the prediction of software defects based on deep learning. According to the respective advantages and disadvantages of the particle swarm algorithm and the wolf swarm algorithm, the two algorithms are mixed to realize the complementary advantages of the algorithms. At the same time, the hybrid algorithm is used in the search of model hyperparameter optimization, the loss function of the model is used as the fitness function, and the collaborative search ability of the swarm intelligence population is used to find the global optimal solution in multiple local solution spaces. Through the analysis of the experimental results of six data sets, compared with the traditional hyperparameter optimization method and a single swarm intelligence algorithm, the model using the hybrid algorithm has higher and better indicators. And, under the processing of the autoencoder, the performance of the model has been further improved.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {17}
}

@inproceedings{10.1145/3180374.3181331,
author = {Li, Yuting and Su, Jianmin and Yang, Xiaoxing},
title = {Multi-Objective vs. Single-Objective Approaches for Software Defect Prediction},
year = {2018},
isbn = {9781450354318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180374.3181331},
doi = {10.1145/3180374.3181331},
abstract = {Software defect prediction employs attributes of software modules to identify defect-prone modules and thus improves software reliability by allocating testing resources more efficiently. Realizing that single-objective methods might be insufficient for solving defect prediction problems, some researchers have proposed multi-objective learning approaches, and proved better performance of multi-objective than single-objective methods. However, existing compared single-objective methods optimize a completely different goal from goals of multi-objective approaches, which might lead to bias. In this paper, we compare a multi-objective approach that optimizes two objectives and a single-objective approach that directly optimizes a trade-off of the two objectives, in order to further investigate the comparison of multi-objective and single-objective approaches. The conclusion will help to appropriately choose multi-objective or single-objective learning approaches for defect prediction.},
booktitle = {Proceedings of the 2018 2nd International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {122–127},
numpages = {6},
keywords = {software defect prediction, single-objective learning, effectiveness, cost, Multi-objective learning},
location = {Wuhan, China},
series = {ICMSS 2018}
}

@article{10.1007/s10515-011-0092-1,
author = {Li, Ming and Zhang, Hongyu and Wu, Rongxin and Zhou, Zhi-Hua},
title = {Sample-based software defect prediction with active and semi-supervised learning},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0092-1},
doi = {10.1007/s10515-011-0092-1},
abstract = {Software defect prediction can help us better understand and control software quality. Current defect prediction techniques are mainly based on a sufficient amount of historical project data. However, historical data is often not available for new projects and for many organizations. In this case, effective defect prediction is difficult to achieve. To address this problem, we propose sample-based methods for software defect prediction. For a large software system, we can select and test a small percentage of modules, and then build a defect prediction model to predict defect-proneness of the rest of the modules. In this paper, we describe three methods for selecting a sample: random sampling with conventional machine learners, random sampling with a semi-supervised learner and active sampling with active semi-supervised learner. To facilitate the active sampling, we propose a novel active semi-supervised learning method ACoForest which is able to sample the modules that are most helpful for learning a good prediction model. Our experiments on PROMISE datasets show that the proposed methods are effective and have potential to be applied to industrial practice.},
journal = {Automated Software Engg.},
month = jun,
pages = {201–230},
numpages = {30},
keywords = {Software defect prediction, Sampling, Quality assurance, Machine learning, Active semi-supervised learning}
}

@article{10.1007/s10664-021-09991-3,
author = {Tahir, Amjed and Bennin, Kwabena E. and Xiao, Xun and MacDonell, Stephen G.},
title = {Does class size matter? An in-depth assessment of the effect of class size in software defect prediction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09991-3},
doi = {10.1007/s10664-021-09991-3},
abstract = {In the past 20 years, defect prediction studies have generally acknowledged the effect of class size on software prediction performance. To quantify the relationship between object-oriented (OO) metrics and defects, modelling has to take into account the direct, and potentially indirect, effects of class size on defects. However, some studies have shown that size cannot be simply controlled or ignored, when building prediction models. As such, there remains a question whether, and when, to control for class size. This study provides a new in-depth examination of the impact of class size on the relationship between OO metrics and software defects or defect-proneness. We assess the impact of class size on the number of defects and defect-proneness in software systems by employing a regression-based mediation (with bootstrapping) and moderation analysis to investigate the direct and indirect effect of class size in count and binary defect prediction. Our results show that the size effect is not always significant for all metrics. Of the seven OO metrics we investigated, size consistently has significant mediation impact only on the relationship between Coupling Between Objects (CBO) and defects/defect-proneness, and a potential moderation impact on the relationship between Fan-out and defects/defect-proneness. Other metrics show mixed results, in that they are significant for some systems but not for others. Based on our results we make three recommendations. One, we encourage researchers and practitioners to examine the impact of class size for the specific data they have in hand and through the use of the proposed statistical mediation/moderation procedures. Two, we encourage empirical studies to investigate the indirect effect of possible additional variables in their models when relevant. Three, the statistical procedures adopted in this study could be used in other empirical software engineering research to investigate the influence of potential mediators/moderators.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {38},
keywords = {Software quality, Metrics, Class size, Defect prediction}
}

@inproceedings{10.1145/3106237.3106257,
author = {Fu, Wei and Menzies, Tim},
title = {Revisiting unsupervised learning for defect prediction},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106257},
doi = {10.1145/3106237.3106257},
abstract = {Collecting quality data from software projects can be time-consuming and expensive. Hence, some researchers explore "unsupervised" approaches to quality prediction that does not require labelled data. An alternate technique is to use "supervised" approaches that learn models from project data labelled with, say, "defective" or "not-defective". Most researchers use these supervised models since, it is argued, they can exploit more knowledge of the projects. At FSE-16, Yang et al. reported startling results where unsupervised defect predictors outperformed supervised predictors for effort-aware just-in-time defect prediction. If confirmed, these results would lead to a dramatic simplification of a seemingly complex task (data mining) that is widely explored in the software engineering literature. This paper repeats and refutes those results as follows. (1) There is much variability in the efficacy of the Yang et al. predictors so even with their approach, some supervised data is required to prune weaker predictors away. (2) Their findings were grouped across N projects. When we repeat their analysis on a project-by-project basis, supervised predictors are seen to work better. Even though this paper rejects the specific conclusions of Yang et al., we still endorse their general goal. In our our experiments, supervised predictors did not perform outstandingly better than unsupervised ones for effort-aware just-in-time defect prediction. Hence, they may indeed be some combination of unsupervised learners to achieve comparable performance to supervised ones. We therefore encourage others to work in this promising area.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {72–83},
numpages = {12},
keywords = {software repository mining, empirical studies, defect prediction, data analytics for software engineering},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1145/3028842.3028859,
author = {Gao, Yan and Yang, Chunhui},
title = {Software defect prediction based on manifold learning in subspace selection},
year = {2016},
isbn = {9781450347990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3028842.3028859},
doi = {10.1145/3028842.3028859},
abstract = {Software defects will lead to software running error and system crashes. In order to detect software defect as early as possible at early stage of software development, a series of machine learning approaches have been studied and applied to predict defects in software modules. Unfortunately, the imbalanceof software defect datasets brings great challenge to software defect prediction model training. In this paper, a new manifold learning based subspace learning algorithm, Discriminative Locality Alignment(DLA), is introduced into software defects prediction. Experimental results demonstrate that DLA is consistently superior to LDA (Linear Discriminant Analysis) and PCA (Principal Component Analysis) in terms of discriminate information extraction and prediction performance. In addition, DLA reveals some attractive intrinsic properties for numeric calculation, e.g. it can overcome the matrix singular problem and small sample size problem in software defect prediction.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Information Processing},
articleno = {17},
numpages = {6},
keywords = {support vector machine, software defect prediction, manifold learning, discriminative locality alignment},
location = {Wuhan, China},
series = {ICIIP '16}
}

@inproceedings{10.1145/2896387.2900324,
author = {Rahman, Md. Habibur and Sharmin, Sadia and Sarwar, Sheikh Muhammad and Shoyaib, Mohammad},
title = {Software Defect Prediction Using Feature Space Transformation},
year = {2016},
isbn = {9781450340632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896387.2900324},
doi = {10.1145/2896387.2900324},
abstract = {In software quality estimation research, software defect prediction is a key topic. A defect prediction model is generally constructed using a variety of software attributes and each attribute may have positive, negative or neutral effect on a specific model. Selection of an optimal set of attributes for model development remains a vital yet unexplored issue. In this paper, we have introduced a new feature space transformation process with a normalization technique to improve the defect prediction accuracy. We proposed a feature space transformation technique and classify the instances using Support Vector Machine (SVM) with its histogram intersection kernel. The proposed method is evaluated using the data sets from NASA metric data repository and its application demonstrates acceptable accuracy.},
booktitle = {Proceedings of the International Conference on Internet of Things and Cloud Computing},
articleno = {72},
numpages = {6},
keywords = {Software defect prediction, Feature space transformation, Attribute selection},
location = {Cambridge, United Kingdom},
series = {ICC '16}
}

@article{10.1016/j.procs.2018.05.012,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {A Nonlinear Manifold Detection based Model for Software Defect Prediction},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.012},
doi = {10.1016/j.procs.2018.05.012},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {581–594},
numpages = {14},
keywords = {Feature Selection techniques, Friedman test, Nonlinear Manifold Detection techniques, Paired two-tailed T-test, Software Defect Prediction}
}

@article{10.1016/j.asoc.2015.04.045,
author = {Arar, \"{O}mer Faruk and Ayan, K\"{u}r\c{s}at},
title = {Software defect prediction using cost-sensitive neural network},
year = {2015},
issue_date = {August 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {33},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.04.045},
doi = {10.1016/j.asoc.2015.04.045},
abstract = {Software defect prediction model was built by Artificial Neural Network (ANN).ANN connection weights were optimized by Artificial Bee Colony (ABC).Parametric cost-sensitivity feature was added to ANN by using a new error function.Model was applied to five publicly available datasets from the NASA repository.Results were compared with other cost-sensitive and non-cost-sensitive studies. The software development life cycle generally includes analysis, design, implementation, test and release phases. The testing phase should be operated effectively in order to release bug-free software to end users. In the last two decades, academicians have taken an increasing interest in the software defect prediction problem, several machine learning techniques have been applied for more robust prediction. A different classification approach for this problem is proposed in this paper. A combination of traditional Artificial Neural Network (ANN) and the novel Artificial Bee Colony (ABC) algorithm are used in this study. Training the neural network is performed by ABC algorithm in order to find optimal weights. The False Positive Rate (FPR) and False Negative Rate (FNR) multiplied by parametric cost coefficients are the optimization task of the ABC algorithm. Software defect data in nature have a class imbalance because of the skewed distribution of defective and non-defective modules, so that conventional error functions of the neural network produce unbalanced FPR and FNR results. The proposed approach was applied to five publicly available datasets from the NASA Metrics Data Program repository. Accuracy, probability of detection, probability of false alarm, balance, Area Under Curve (AUC), and Normalized Expected Cost of Misclassification (NECM) are the main performance indicators of our classification approach. In order to prevent random results, the dataset was shuffled and the algorithm was executed 10 times with the use of n-fold cross-validation in each iteration. Our experimental results showed that a cost-sensitive neural network can be created successfully by using the ABC optimization algorithm for the purpose of software defect prediction.},
journal = {Appl. Soft Comput.},
month = aug,
pages = {263–277},
numpages = {15},
keywords = {Software quality, Software defect prediction, Machine learning, Cost-sensitive classification, Artificial Neural Network, Artificial Bee Colony}
}

@article{10.1155/2019/2384706,
author = {Yang, Xingguang and Yu, Huiqun and Fan, Guisheng and Shi, Kai and Chen, Liqiong and Tramontana, Emiliano},
title = {Local versus Global Models for Just-In-Time Software Defect Prediction},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1058-9244},
url = {https://doi.org/10.1155/2019/2384706},
doi = {10.1155/2019/2384706},
abstract = {Just-in-time software defect prediction (JIT-SDP) is an active topic in software defect prediction, which aims to identify defect-inducing changes. Recently, some studies have found that the variability of defect data sets can affect the performance of defect predictors. By using local models, it can help improve the performance of prediction models. However, previous studies have focused on module-level defect prediction. Whether local models are still valid in the context of JIT-SDP is an important issue. To this end, we compare the performance of local and global models through a large-scale empirical study based on six open-source projects with 227417 changes. The experiment considers three evaluation scenarios of cross-validation, cross-project-validation, and timewise-cross-validation. To build local models, the experiment uses the k-medoids to divide the training set into several homogeneous regions. In addition, logistic regression and effort-aware linear regression (EALR) are used to build classification models and effort-aware prediction models, respectively. The empirical results show that local models perform worse than global models in the classification performance. However, local models have significantly better effort-aware prediction performance than global models in the cross-validation and cross-project-validation scenarios. Particularly, when the number of clusters k is set to 2, local models can obtain optimal effort-aware prediction performance. Therefore, local models are promising for effort-aware JIT-SDP.},
journal = {Sci. Program.},
month = jan,
numpages = {13}
}

@article{10.1016/j.procs.2015.02.161,
author = {Arora, Ishani and Tetarwal, Vivek and Saha, Anju},
title = {Open Issues in Software Defect Prediction},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.161},
doi = {10.1016/j.procs.2015.02.161},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {906–912},
numpages = {7},
keywords = {software testing, software quality, machine learning, defect prediction, data mining}
}

@article{10.1016/j.ins.2018.02.027,
author = {Miholca, Diana-Lucia and Czibula, Gabriela and Czibula, Istvan Gergely},
title = {A novel approach for software defect prediction through hybridizing gradual relational association rules with artificial neural networks},
year = {2018},
issue_date = {May 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {441},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2018.02.027},
doi = {10.1016/j.ins.2018.02.027},
abstract = {The growing complexity of software projects requires increasing consideration of their analysis and testing. Identifying defective software entities is essential for software quality assurance and it also improves activities related to software testing. In this study, we developed a novel supervised classification method called HyGRAR for software defect prediction. HyGRAR is a non-linear hybrid model that combines gradual relational association rule mining and artificial neural networks to discriminate between defective and non-defective software entities. Experiments performed based on 10 open-source data sets demonstrated the excellent performance of the HYGRAR classifier. HyGRAR performed better than most of the previously proposed approaches for software defect prediction in performance evaluations using the same data sets.},
journal = {Inf. Sci.},
month = may,
pages = {152–170},
numpages = {19},
keywords = {Software defect prediction, Machine learning, Gradual relational association rule, Artificial neural network}
}

@article{10.1504/ijcat.2019.100297,
author = {Jayanthi, R. and Florence, M. Lilly},
title = {Improved Bayesian regularisation using neural networks based on feature selection for software defect prediction},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {60},
number = {3},
issn = {0952-8091},
url = {https://doi.org/10.1504/ijcat.2019.100297},
doi = {10.1504/ijcat.2019.100297},
abstract = {Demand for software-based applications has grown drastically in various real-time applications. However, software testing schemes have been developed which include manual and automatic testing. Manual testing requires human effort and chances of error may still affect the quality of software. To overcome this issue, automatic software testing techniques based on machine learning techniques have been developed. In this work, we focus on the machine learning scheme for early prediction of software defects using Levenberg-Marquardt algorithm (LM), Back Propagation (BP) and Bayesian Regularisation (BR) techniques. Bayesian regularisation achieves better performance in terms of bug prediction. However, this performance can be enhanced further. Hence, we developed a novel approach for attribute selection-based feature selection technique to improve the performance of BR classification. An extensive study is carried out with the PROMISE repository where we considered KC1 and JM1 datasets. Experimental study shows that the proposed approach achieves better performance in predicting the defects in software.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {225–241},
numpages = {16},
keywords = {adaptive computation process, cross entropy error function, feature subset selection, gradient-based approach, gradient descent optimisation, software metrics, software defect prediction, machine learning techniques, defect prediction model}
}

@article{10.1016/j.infsof.2017.11.008,
author = {Tong, Haonan and Liu, Bin and Wang, Shihai},
title = {Software defect prediction using stacked denoising autoencoders and two-stage ensemble learning},
year = {2018},
issue_date = {Apr 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {96},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.11.008},
doi = {10.1016/j.infsof.2017.11.008},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {94–111},
numpages = {18},
keywords = {Deep learning, Software metrics, Ensemble learning, Stacked denoising autoencoders, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-59003-1_27,
author = {Shakhovska, Natalya and Yakovyna, Vitaliy and Kryvinska, Natalia},
title = {An Improved Software Defect Prediction Algorithm Using Self-organizing Maps Combined with Hierarchical Clustering and Data Preprocessing},
year = {2020},
isbn = {978-3-030-59002-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59003-1_27},
doi = {10.1007/978-3-030-59003-1_27},
abstract = {An improved software defects prediction algorithm based on combination of Kohonen map and hierarchical clustering is presented in this paper. The need for software reliability assessment and analysis growths rapidly due to increasing dependence of our day-to-day life on software-controlled devices and systems. Software reliability prediction is the only tool available at early stage of software development lifecycle when the debugging cost risk of faulty operation is minimal. Artificial intelligence and machine learning in particular are promising techniques to solve this task. Various classification methods have been used previously to build software defect prediction models, ranging from simple, like logistic regression, to advanced methods, e.g. multivariate adaptive regression splicing. However, the available literature still does not allow to make unambiguous conclusion concerning the choice of the best classifier and trying different dimensions to overcome potential bias is suggested. The purpose of the paper is to analyze the software code metrics to find dependences be-tween software module’s defect-proneness and its metrics. JM1 public NASA dataset from PROMISE Software Engineering Repository was used in this study. To increase the classification accuracy, we combine self-organizing maps with hierarchical clustering and data preprocessing.},
booktitle = {Database and Expert Systems Applications: 31st International Conference, DEXA 2020, Bratislava, Slovakia, September 14–17, 2020, Proceedings, Part I},
pages = {414–424},
numpages = {11},
keywords = {Prediction algorithm, Hierarchical clustering, Software defect analysis},
location = {Bratislava, Slovakia}
}

@article{10.1016/j.jss.2019.03.012,
author = {Ni, Chao and Chen, Xiang and Wu, Fangfang and Shen, Yuxiang and Gu, Qing},
title = {An empirical study on pareto based multi-objective feature selection for software defect prediction},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.03.012},
doi = {10.1016/j.jss.2019.03.012},
journal = {J. Syst. Softw.},
month = jun,
pages = {215–238},
numpages = {24},
keywords = {Empirical study, Multi-Objective optimization, Feature selection, Search based software engineering, Software defect prediction, xx-xx, xx-xx}
}

@inproceedings{10.1109/ICSE.2019.00076,
author = {Cabral, George G. and Minku, Leandro L. and Shihab, Emad and Mujahid, Suhaib},
title = {Class imbalance evolution and verification latency in just-in-time software defect prediction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00076},
doi = {10.1109/ICSE.2019.00076},
abstract = {Just-in-Time Software Defect Prediction (JIT-SDP) is an SDP approach that makes defect predictions at the software change level. Most existing JIT-SDP work assumes that the characteristics of the problem remain the same over time. However, JIT-SDP may suffer from class imbalance evolution. Specifically, the imbalance status of the problem (i.e., how much underrepresented the defect-inducing changes are) may be intensified or reduced over time. If occurring, this could render existing JIT-SDP approaches unsuitable, including those that rebuild classifiers over time using only recent data. This work thus provides the first investigation of whether class imbalance evolution poses a threat to JIT-SDP. This investigation is performed in a realistic scenario by taking into account verification latency - the often overlooked fact that labeled training examples arrive with a delay. Based on 10 GitHub projects, we show that JIT-SDP suffers from class imbalance evolution, significantly hindering the predictive performance of existing JIT-SDP approaches. Compared to state-of-the-art class imbalance evolution learning approaches, the predictive performance of JIT-SDP approaches was up to 97.2% lower in terms of g-mean. Hence, it is essential to tackle class imbalance evolution in JIT-SDP. We then propose a novel class imbalance evolution approach for the specific context of JIT-SDP. While maintaining top ranked g-means, this approach managed to produce up to 63.59% more balanced recalls on the defect-inducing and clean classes than state-of-the-art class imbalance evolution approaches. We thus recommend it to avoid overemphasizing one class over the other in JIT-SDP.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {666–676},
numpages = {11},
keywords = {verification latency, software defect prediction, online learning, ensembles, concept drift, class imbalance},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1016/j.infsof.2019.07.003,
author = {Zhou, Tianchi and Sun, Xiaobing and Xia, Xin and Li, Bin and Chen, Xiang},
title = {Improving defect prediction with deep forest},
year = {2019},
issue_date = {Oct 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {114},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.07.003},
doi = {10.1016/j.infsof.2019.07.003},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {204–216},
numpages = {13},
keywords = {Empirical evaluation, Cascade strategy, Deep forest, Software defect prediction}
}

@inproceedings{10.4108/icst.bict.2014.257871,
author = {Malhotra, Ruchika and Raje, Rajeev},
title = {An empirical comparison of machine learning techniques for software defect prediction},
year = {2014},
isbn = {9781631900532},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.bict.2014.257871},
doi = {10.4108/icst.bict.2014.257871},
abstract = {Software systems are exposed to various types of defects. The timely identification of defective classes is essential in early phases of software development to reduce the cost of testing the software. This will guide the software practitioners and researchers for planning of the proper allocation of testing resources. Software metrics can be used in conjunction with defect data to develop models for predicting defective classes. There have been various machine learning techniques proposed in the literature for analyzing complex relationships and extracting useful information from problems in less time. However, more studies comparing these techniques are needed to provide evidence so that confidence is established on the performance of one technique over the other. In this paper we address four issues (i) comparison of the machine learning techniques over unpopular used data sets (ii) use of inappropriate performance measures for measuring the performance of defect prediction models (iii) less use of statistical tests and (iv) validation of models from the same data set from which they are trained. To resolve these issues, in this paper, we compare 18 machine learning techniques for investigating the effect of Object-Oriented metrics on defective classes. The results are validated on six releases of the 'MMS' application package of recent widely used mobile operating system -- Android. The overall results of the study indicate the predictive capability of the machine learning techniques and an endorsement of one particular ML technique to predict defects.},
booktitle = {Proceedings of the 8th International Conference on Bioinspired Information and Communications Technologies},
pages = {320–327},
numpages = {8},
keywords = {object-oriented metrics, machine learning, empirical validation, defect prediction},
location = {Boston, Massachusetts},
series = {BICT '14}
}

@article{10.1002/stvr.1610,
author = {Wang, Tiejian and Zhang, Zhiwu and Jing, Xiaoyuan and Liu, Yanli},
title = {Non-negative sparse-based SemiBoost for software defect prediction},
year = {2016},
issue_date = {November 2016},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {26},
number = {7},
issn = {0960-0833},
url = {https://doi.org/10.1002/stvr.1610},
doi = {10.1002/stvr.1610},
abstract = {Software defect prediction is an important decision support activity in software quality assurance. The limitation of the labelled modules usually makes the prediction difficult, and the class-imbalance characteristic of software defect data leads to negative influence on decision of classifiers. Semi-supervised learning can build high-performance classifiers by using large amount of unlabelled modules together with the labelled modules. Ensemble learning achieves a better prediction capability for class-imbalance data by using a series of weak classifiers to reduce the bias generated by the majority class. In this paper, we propose a new semi-supervised software defect prediction approach, non-negative sparse-based SemiBoost learning. The approach is capable of exploiting both labelled and unlabelled data and is formulated in a boosting framework. In order to enhance the prediction ability, we design a flexible non-negative sparse similarity matrix, which can fully exploit the similarity of historical data by incorporating the non-negativity constraint into sparse learning for better learning the latent clustering relationship among software modules. The widely used datasets from NASA projects are employed as test data to evaluate the performance of all compared methods. Experimental results show that non-negative sparse-based SemiBoost learning outperforms several representative state-of-the-art semi-supervised software defect prediction methods. Copyright © 2016 John Wiley &amp; Sons, Ltd.},
journal = {Softw. Test. Verif. Reliab.},
month = nov,
pages = {498–515},
numpages = {18},
keywords = {software defect prediction, semi-supervised learning, non-negative sparse based SemiBoost NSSB, ensemble learning}
}

@article{10.4018/IJOSSP.2018010101,
author = {Kakkar, Misha and Jain, Sarika and Bansal, Abhay and Grover, P.S.},
title = {Combining Data Preprocessing Methods With Imputation Techniques for Software Defect Prediction},
year = {2018},
issue_date = {January 2018},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {1},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2018010101},
doi = {10.4018/IJOSSP.2018010101},
abstract = {Software Defect Prediction SDP models are used to predict, whether software is clean or buggy using the historical data collected from various software repositories. The data collected from such repositories may contain some missing values. In order to estimate missing values, imputation techniques are used, which utilizes the complete observed values in the dataset. The objective of this study is to identify the best-suited imputation technique for handling missing values in SDP dataset. In addition to identifying the imputation technique, the authors have investigated for the most appropriate combination of imputation technique and data preprocessing method for building SDP model. In this study, four combinations of imputation technique and data preprocessing methods are examined using the improved NASA datasets. These combinations are used along with five different machine-learning algorithms to develop models. The performance of these SDP models are then compared using traditional performance indicators. Experiment results show that among different imputation techniques, linear regression gives the most accurate imputed value. The combination of linear regression with correlation based feature selector outperforms all other combinations. To validate the significance of data preprocessing methods with imputation the findings are applied to open source projects. It was concluded that the result is in consistency with the above conclusion.},
journal = {Int. J. Open Source Softw. Process.},
month = jan,
pages = {1–19},
numpages = {19},
keywords = {Software Defect Prediction, Missing Value Imputation, Instance Selection, Feature Selection}
}

@article{10.1007/s00500-021-06254-7,
author = {Sotto-Mayor, Bruno and Kalech, Meir},
title = {Cross-project smell-based defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {22},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06254-7},
doi = {10.1007/s00500-021-06254-7},
abstract = {Defect prediction is a technique introduced to optimize the testing phase of the software development pipeline by predicting which components in the software may contain defects. Its methodology trains a classifier with data regarding a set of features measured on each component from the target software project to predict whether the component may be defective or not. However, suppose the defective information is not available in the training set. In that case, we need to rely on an alternate approach that uses the training set of external projects to train the classifier. This approached is called cross-project defect prediction. Bad code smells are a category of features that have been previously explored in defect prediction and have been shown to be a good predictor of defects. Code smells are patterns of poor development in the code and indicate flaws in its design and implementation. Although they have been previously studied in the context of defect prediction, they have not been studied as features for cross-project defect prediction. In our experiment, we train defect prediction models for 100 projects to evaluate the predictive performance of the bad code smells. We implemented four cross-project approaches known in the literature and compared the performance of 37 smells with 56 code metrics, commonly used for defect prediction. The results show that the cross-project defect prediction models trained with code smells significantly improved 6.50% on the ROC AUC compared against the code metrics.},
journal = {Soft Comput.},
month = nov,
pages = {14171–14181},
numpages = {11},
keywords = {Software engineering, Software quality, Mining software repositories, Code smell, Defect prediction, Cross-project defect prediction}
}

@article{10.1007/s00607-016-0538-1,
author = {Gupta, Shivani and Gupta, Atul},
title = {A set of measures designed to identify overlapped instances in software defect prediction},
year = {2017},
issue_date = {September 2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {99},
number = {9},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-016-0538-1},
doi = {10.1007/s00607-016-0538-1},
abstract = {The performance of the learning models will intensely rely on the characteristics of the training data. The previous outcomes recommend that the overlapping between classes and the presence of noise have the most grounded impact on the performance of learning algorithm, and software defect datasets are no exceptions. The class overlap problem is concerned with the performance of machine learning classifiers critical problem is class overlap in which data samples appear as valid examples of more than one class which may be responsible for the presence of noise in datasets. We aim to investigate how the presence of overlapped instances in a dataset influences the classifier's performance, and how to deal with class overlapping problem. To have a close estimate of class overlapping, we have proposed four different measures namely, nearest enemy ratio, subconcept ratio, likelihood ratio and soft margin ratio. We performed our investigations using 327 binary defect classification datasets obtained from 54 software projects, where we first identified overlapped datasets using three data complexity measures proposed in the literature. We also include treatment effort into the prediction process. Subsequently, we used our proposed measures to find overlapped instances in the identified overlapped datasets. Our results indicated that by training a classifier on a training data free from overlapped instances led to an improved classifier performance on the test data containing overlapped instances. The classifiers perform significantly better when the evaluation measure takes the effort into account.},
journal = {Computing},
month = sep,
pages = {889–914},
numpages = {26},
keywords = {Software defect prediction, Machine learning, Data mining, Data complexity measures, Class overlapping}
}

@article{10.1155/2021/5069016,
author = {Balogun, Abdullateef O. and Basri, Shuib and Mahamad, Saipunidzam and Capretz, Luiz Fernando and Imam, Abdullahi Abubakar and Almomani, Malek A. and Adeyemo, Victor E. and Kumar, Ganesh and Dourado, Ant\'{o}nio},
title = {A Novel Rank Aggregation-Based Hybrid Multifilter Wrapper Feature Selection Method in Software Defect Prediction},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/5069016},
doi = {10.1155/2021/5069016},
abstract = {The high dimensionality of software metric features has long been noted as a data quality problem that affects the performance of software defect prediction (SDP) models. This drawback makes it necessary to apply feature selection (FS) algorithm(s) in SDP processes. FS approaches can be categorized into three types, namely, filter FS (FFS), wrapper FS (WFS), and hybrid FS (HFS). HFS has been established as superior because it combines the strength of both FFS and WFS methods. However, selecting the most appropriate FFS (filter rank selection problem) for HFS is a challenge because the performance of FFS methods depends on the choice of datasets and classifiers. In addition, the local optima stagnation and high computational costs of WFS due to large search spaces are inherited by the HFS method. Therefore, as a solution, this study proposes a novel rank aggregation-based hybrid multifilter wrapper feature selection (RAHMFWFS) method for the selection of relevant and irredundant features from software defect datasets. The proposed RAHMFWFS is divided into two stepwise stages. The first stage involves a rank aggregation-based multifilter feature selection (RMFFS) method that addresses the filter rank selection problem by aggregating individual rank lists from multiple filter methods, using a novel rank aggregation method to generate a single, robust, and non-disjoint rank list. In the second stage, the aggregated ranked features are further preprocessed by an enhanced wrapper feature selection (EWFS) method based on a dynamic reranking strategy that is used to guide the feature subset selection process of the HFS method. This, in turn, reduces the number of evaluation cycles while amplifying or maintaining its prediction performance. The feasibility of the proposed RAHMFWFS was demonstrated on benchmarked software defect datasets with Na\"{\i}ve Bayes and Decision Tree classifiers, based on accuracy, the area under the curve (AUC), and F-measure values. The experimental results showed the effectiveness of RAHMFWFS in addressing filter rank selection and local optima stagnation problems in HFS, as well as the ability to select optimal features from SDP datasets while maintaining or enhancing the performance of SDP models. To conclude, the proposed RAHMFWFS achieved good performance by improving the prediction performances of SDP models across the selected datasets, compared to existing state-of-the-arts HFS methods.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {19}
}

@inproceedings{10.1145/3028842.3028858,
author = {Gao, Yan and Yang, Chunhui and Liang, Lixin},
title = {Pseudo-samples generation in Gaussian mixture distribution for software defect prediction},
year = {2016},
isbn = {9781450347990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3028842.3028858},
doi = {10.1145/3028842.3028858},
abstract = {In this paper, we present GCRF method based on pseudo-samples generation and conditional random field (CRF) for software defect prediction in Gaussian Mixture Distribution. In the proposed method, firstly, we leverage Gaussian Mixture Distribution (GMM) to generate pseudo-samples, which can increase the samples of minority class for balancing the train dataset. Secondly, we propose to apply CRF model in the balanced train dataset because the CRF model can handle complex features in nonlinear high dimensional subspace. Moreover, in order to avoid explicit modeling of the observed data, the proposed method can incorporate the classification of software defect data with different statistics characteristics into a unified probabilistic framework. Interestingly, the experiments show that the GCRF method achieves much better prediction performance than the other approach as shown in the software defect data classification task.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Information Processing},
articleno = {16},
numpages = {6},
keywords = {software defect prediction, imbalance distribution, gaussian mixture distribution, conditional random field},
location = {Wuhan, China},
series = {ICIIP '16}
}

@article{10.1049/sfw2.12012,
author = {Zou, Quanyi and Lu, Lu and Qiu, Shaojian and Gu, Xiaowei and Cai, Ziyi},
title = {Correlation feature and instance weights transfer learning for cross project software defect prediction},
year = {2021},
issue_date = {February 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {15},
number = {1},
url = {https://doi.org/10.1049/sfw2.12012},
doi = {10.1049/sfw2.12012},
abstract = {Due to the differentiation between training and testing data in the feature space, cross‐project defect prediction (CPDP) remains unaddressed within the field of traditional machine learning. Recently, transfer learning has become a research hot‐spot for building classifiers in the target domain using the data from the related source domains. To implement better CPDP models, recent studies focus on either feature transferring or instance transferring to weaken the impact of irrelevant cross‐project data. Instead, this work proposes a dual weighting mechanism to aid the learning process, considering both feature transferring and instance transferring. In our method, a local data gravitation between source and target domains determines instance weight, while features that are highly correlated with the learning task, uncorrelated with other features and minimizing the difference between the domains are rewarded with a higher feature weight. Experiments on 25 real‐world datasets indicate that the proposed approach outperforms the existing CPDP methods in most cases. By assigning weights based on the different contribution of features and instances to the predictor, the proposed approach is able to build a better CPDP model and demonstrates substantial improvements over the state‐of‐the‐art CPDP models.},
journal = {IET Software},
month = jan,
pages = {55–74},
numpages = {20},
keywords = {software reliability, pattern classification, learning (artificial intelligence)}
}

@article{10.1155/2020/8852705,
author = {Zheng, Shang and Gai, Jinjing and Yu, Hualong and Zou, Haitao and Gao, Shang and Briola, Daniela},
title = {Software Defect Prediction Based on Fuzzy Weighted Extreme Learning Machine with Relative Density Information},
year = {2020},
issue_date = {2020},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2020},
issn = {1058-9244},
url = {https://doi.org/10.1155/2020/8852705},
doi = {10.1155/2020/8852705},
abstract = {To identify software modules that are more likely to be defective, machine learning has been used to construct software defect prediction (SDP) models. However, several previous works have found that the imbalanced nature of software defective data can decrease the model performance. In this paper, we discussed the issue of how to improve imbalanced data distribution in the context of SDP, which can benefit software defect prediction with the aim of finding better methods. Firstly, a relative density was introduced to reflect the significance of each instance within its class, which is irrelevant to the scale of data distribution in feature space; hence, it can be more robust than the absolute distance information. Secondly, a K-nearest-neighbors-based probability density estimation (KNN-PDE) alike strategy was utilised to calculate the relative density of each training instance. Furthermore, the fuzzy memberships of sample were designed based on relative density in order to eliminate classification error coming from noise and outlier samples. Finally, two algorithms were proposed to train software defect prediction models based on the weighted extreme learning machine. This paper compared the proposed algorithms with traditional SDP methods on the benchmark data sets. It was proved that the proposed methods have much better overall performance in terms of the measures including G-mean, AUC, and Balance. The proposed algorithms are more robust and adaptive for SDP data distribution types and can more accurately estimate the significance of each instance and assign the identical total fuzzy coefficients for two different classes without considering the impact of data scale.},
journal = {Sci. Program.},
month = jan,
numpages = {18}
}

@inproceedings{10.1145/3220267.3220286,
author = {El-Shorbagy, Sara Adel and El-Gammal, Wael Mohamed and Abdelmoez, Walid M.},
title = {Using SMOTE and Heterogeneous Stacking in Ensemble learning for Software Defect Prediction},
year = {2018},
isbn = {9781450364690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220267.3220286},
doi = {10.1145/3220267.3220286},
abstract = {Nowadays, there are a lot of classifications models used for predictions in the software engineering field such as effort estimation and defect prediction. One of these models is the ensemble learning machine that improves model performance by combining multiple models in different ways to get a more powerful model.One of the problems facing the prediction model is the misclassification of the minority samples. This problem mainly appears in the case of defect prediction. Our aim is the classification of defects which are considered minority samples during the training phase. This can be improved by implementing the Synthetic Minority Over-Sampling Technique (SMOTE) before the implementation of the ensemble model which leads to over-sample the minority class instances.In this paper, our work propose applying a new ensemble model by combining the SMOTE technique with the heterogeneous stacking ensemble to get the most benefit and performance in training a dataset that focus on the minority subset as in the software prediction study. Our proposed model shows better performance that overcomes other techniques results applied on the minority samples of the defect prediction.},
booktitle = {Proceedings of the 7th International Conference on Software and Information Engineering},
pages = {44–47},
numpages = {4},
keywords = {Stacking, Software Engineering, SMOTE, Machine Learning, Heterogeneous, Ensemble, Defect Prediction, Classification},
location = {Cairo, Egypt},
series = {ICSIE '18}
}

@inproceedings{10.1145/2568225.2568320,
author = {Jing, Xiao-Yuan and Ying, Shi and Zhang, Zhi-Wu and Wu, Shan-Shan and Liu, Jin},
title = {Dictionary learning based software defect prediction},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568320},
doi = {10.1145/2568225.2568320},
abstract = {In order to improve the quality of a software system, software defect prediction aims to automatically identify defective software modules for efficient software test. To predict software defect, those classification methods with static code attributes have attracted a great deal of attention. In recent years, machine learning techniques have been applied to defect prediction. Due to the fact that there exists the similarity among different software modules, one software module can be approximately represented by a small proportion of other modules. And the representation coefficients over the pre-defined dictionary, which consists of historical software module data, are generally sparse. In this paper, we propose to use the dictionary learning technique to predict software defect. By using the characteristics of the metrics mined from the open source software, we learn multiple dictionaries (including defective module and defective-free module sub-dictionaries and the total dictionary) and sparse representation coefficients. Moreover, we take the misclassification cost issue into account because the misclassification of defective modules generally incurs much higher risk cost than that of defective-free ones. We thus propose a cost-sensitive discriminative dictionary learning (CDDL) approach for software defect classification and prediction. The widely used datasets from NASA projects are employed as test data to evaluate the performance of all compared methods. Experimental results show that CDDL outperforms several representative state-of-the-art defect prediction methods.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {414–423},
numpages = {10},
keywords = {sparse representation, dictionary learning, cost-sensitive discriminative dictionary learning (CDDL), Software defect prediction},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{10.5555/3432601.3432619,
author = {Jahanshahi, Hadi and Cevik, Mucahit and Ba\c{s}ar, Ay\c{s}e},
title = {Moving from cross-project defect prediction to heterogeneous defect prediction: a partial replication study},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software defect prediction heavily relies on the metrics collected from software projects. Earlier studies often used machine learning techniques to build, validate, and improve bug prediction models using either a set of metrics collected within a project or across different projects. However, techniques applied and conclusions derived by those models are restricted by how identical those metrics are. Knowledge coming from those models will not be extensible to a target project if no sufficient overlapping metrics have been collected in the source projects. To explore the feasibility of transferring knowledge across projects without common labeled metrics, we systematically integrated Heterogeneous Defect Prediction (HDP) by replicating and validating the obtained results. Our main goal is to extend prior research and explore the feasibility of HDP and finally to compare its performance with that of its predecessor, Cross-Project Defect Prediction. We construct an HDP model on different publicly available datasets. Moreover, we propose a new ensemble voting approach in the HDP context to utilize the predictive power of multiple available datasets. The result of our experiment is comparable to that of the original study. However, we also explored the feasibility of HDP in real cases. Our results shed light on the infeasibility of many cases for the HDP algorithm due to its sensitivity to the parameter selection. In general, our analysis gives a deep insight into why and how to perform transfer learning from one domain to another, and in particular, provides a set of guidelines to help researchers and practitioners to disseminate knowledge to the defect prediction domain.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {133–142},
numpages = {10},
keywords = {transfer learning, software quality, heterogeneous metrics, defect prediction},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@inproceedings{10.1145/3239576.3239607,
author = {Du, Yuntao and Zhang, Lu and Shi, Jiahao and Tang, Jingjuan and Yin, Ying},
title = {Feature-Grouping-Based Two Steps Feature Selection Algorithm in Software Defect Prediction},
year = {2018},
isbn = {9781450364607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239576.3239607},
doi = {10.1145/3239576.3239607},
abstract = {In order to improve the effect of software defect prediction, many algorithms including feature selection, have been proposed. Based on Wrapper and Filter hybrid framework, a feature-grouping-based feature selection algorithm is proposed in this paper. The algorithm is composed of two steps. In the first step, in order to remove the redundant features, we group the features according to the redundancy between the features. The symmetry uncertainty is used as the constant indicator of the correlation and the FCBF-based grouping algorithm is used to group the features. In the second step, a subset of the features are selected from each group to form the final subset of features. Many classical methods select the representative feature from each group. We consider that when the number of intra-group features is large, the representative features are not enough to reflect the information in this group. Therefore, we require that at least one feature be selected within each group, in this step, the PSO algorithm is used for Searching Randomly from each group. We tested on the open source NASA and PROMISE data sets. Using three kinds of classifier. Compared to the other methods tested in this article, our method resulted in 90% improvement in the predictive performance of 30 sets of results on 10 data sets. Compared with the algorithms without feature selection, the AUC values of this method in the Logistic regression, Naive Bayesian, and K-neighbor classifiers are improved by 5.94% and 4.69% And 8.05%. The FCBF algorithm can also be regarded as a kind of first performing feature grouping. Compared with the FCBF algorithm, the AUC values of this method are improved by 4.78%, 6.41% and 4.4% on the basis of Logistic regression, Naive Bayes and K-neighbor. We can also see that for the FCBF-based grouping algorithm, it could be better to choose a characteristic cloud from each group than to choose a representative one.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
pages = {173–178},
numpages = {6},
keywords = {Software defect prediction, PSO, Intra-group feature selection, Feature grouping, FCBF-based grouping algorithm},
location = {Chengdu, China},
series = {ICAIP '18}
}

@inproceedings{10.5555/3432601.3432618,
author = {Grigoriou, Marios-Stavros and Kontogiannis, Kostas and Giammaria, Alberto and Brealey, Chris},
title = {Report on evaluation experiments using different machine learning techniques for defect prediction},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {With the emergence of AI, it is of no surprise that the application of Machine Learning techniques has attracted the attention of numerous software maintenance groups around the world. For defect proneness classification in particular, the use of Machine Learning classifiers has been touted as a promising approach. As a consequence, a large volume of research works has been published in the related research literature, utilizing either proprietary data sets or the PROMISE data repository which, for the purposes of this study, focuses only on the use of source code metrics as defect prediction training features. It has been argued though by several researchers, that process metrics may provide a better option as training features than source code metrics. For this paper, we have conducted a detailed extraction of GitHub process metrics from 148 open source systems, and we report on the findings of experiments conducted by using different Machine Learning classification algorithms for defect proneness classification. The main purpose of the paper is not to propose yet another Machine Learning technique for defect proneness classification, but to present to the community a very large data set using process metrics as opposed to source code metrics, and draw some initial interesting conclusions from this statistically significant data set.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {123–132},
numpages = {10},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@article{10.1016/j.asoc.2017.05.043,
author = {Arar, mer Faruk and Ayan, Krat},
title = {A feature dependent Naive Bayes approach and its application to the software defect prediction problem},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {59},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.05.043},
doi = {10.1016/j.asoc.2017.05.043},
abstract = {Display Omitted In Naive Bayes, features are assumed to be independent and have equal weight. But, In practice, features are interrelated.In this study, features are included for calculation as pairs using the proposed Feature Dependent Naive Bayes (FDNB) method.Eight data sets from the NASA PROMISE repository were used for the software defect prediction problem.Results were compared with other modified NBs. Increased classification performance was found after use of the proposed FDNB. Naive Bayes is one of the most widely used algorithms in classification problems because of its simplicity, effectiveness, and robustness. It is suitable for many learning scenarios, such as image classification, fraud detection, web mining, and text classification. Naive Bayes is a probabilistic approach based on assumptions that features are independent of each other and that their weights are equally important. However, in practice, features may be interrelated. In that case, such assumptions may cause a dramatic decrease in performance. In this study, by following preprocessing steps, a Feature Dependent Naive Bayes (FDNB) classification method is proposed. Features are included for calculation as pairs to create dependence between one another. This method was applied to the software defect prediction problem and experiments were carried out using widely recognized NASA PROMISE data sets. The obtained results show that this new method is more successful than the standard Naive Bayes approach and that it has a competitive performance with other feature-weighting techniques. A further aim of this study is to demonstrate that to be reliable, a learning model must be constructed by using only training data, as otherwise misleading results arise from the use of the entire data set.},
journal = {Appl. Soft Comput.},
month = oct,
pages = {197–209},
numpages = {13},
keywords = {Software defect prediction, Naive Bayes, Feature independence, Discretization, Data mining}
}

@inproceedings{10.1145/2591062.2591151,
author = {Jing, Xiao-Yuan and Zhang, Zhi-Wu and Ying, Shi and Wang, Feng and Zhu, Yang-Ping},
title = {Software defect prediction based on collaborative representation classification},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591151},
doi = {10.1145/2591062.2591151},
abstract = {In recent years, machine learning techniques have been successfully applied into software defect prediction. Although they can yield reasonably good prediction results, there still exists much room for improvement on the aspect of prediction accuracy. Sparse representation is one of the most advanced machine learning techniques. It performs well with respect to signal compression and classification, but suffers from its time-consuming sparse coding. Compared with sparse representation, collaborative representation classification (CRC) can yield significantly lower computational complexity and competitive classification performance in pattern recognition domains. To achieve better defect prediction results, we introduce the CRC technique in this paper and propose a CRC based software defect prediction (CSDP) approach. We first design a CRC based learner to build a prediction model, whose computational burden is low. Then, we design a CRC based predictor to classify whether the query software modules are defective or defective-free. Experimental results on the widely used NASA datasets demonstrate the effectiveness and efficiency of the proposed approach.},
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {632–633},
numpages = {2},
keywords = {Software defect prediction, Prediction model, Machine learning, Collaborative representation classification},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@article{10.1007/s00500-018-3546-6,
author = {Khuat, Thanh Tung and Le, My Hanh},
title = {Binary teaching–learning-based optimization algorithm with a new update mechanism for sample subset optimization in software defect prediction},
year = {2019},
issue_date = {Oct 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {20},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-018-3546-6},
doi = {10.1007/s00500-018-3546-6},
abstract = {Software defect prediction has gained considerable attention in recent years. A broad range of computational methods has been developed for accurate prediction of faulty modules based on code and design metrics. One of the challenges in training classifiers is the highly imbalanced class distribution in available datasets, leading to an undesirable bias in the prediction performance for the minority class. Data sampling is a widespread technique to tackle this problem. However, traditional sampling methods, which depend mainly on random resampling from a given dataset, do not take advantage of useful information available in training sets, such as sample quality and representative instances. To cope with this limitation, evolutionary undersampling methods are usually used for identifying an optimal sample subset for the training dataset. This paper proposes a binary teaching–learning- based optimization algorithm employing a distribution-based solution update rule, namely BTLBOd, to generate a balanced subset of highly valuable examples. This subset is then applied to train a classifier for reliable prediction of potentially defective modules in a software system. Each individual in BTLBOd includes two vectors: a real-valued vector generated by the distribution-based update mechanism, and a binary vector produced from the corresponding real vector by a proposed mapping function. Empirical results showed that the optimal sample subset produced by BTLBOd might ameliorate the classification accuracy of the predictor on highly imbalanced software defect data. Obtained results also demonstrated the superior performance of the proposed sampling method compared to other popular sampling techniques.},
journal = {Soft Comput.},
month = oct,
pages = {9919–9935},
numpages = {17},
keywords = {Software defect prediction, Imbalanced learning, Sample subset optimization, Distribution-based update, Binary teaching–learning-based optimization, Teaching–learning-based optimization}
}

@inproceedings{10.1145/2351676.2351734,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {Software defect prediction using semi-supervised learning with dimension reduction},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351734},
doi = {10.1145/2351676.2351734},
abstract = {Accurate detection of fault prone modules offers the path to high quality software products while minimizing non essential assurance expenditures. This type of quality modeling requires the availability of software modules with known fault content developed in similar environment. Establishing whether a module contains a fault or not can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics. Our results show that the semi-supervised learning algorithm with dimension-reduction preforms significantly better than one of the best performing supervised learning algorithms, random forest, in situations when few modules with known fault content are available for training.},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {314–317},
numpages = {4},
keywords = {software metrics, semi-supervised learning, dimension reduction, Software fault prediction},
location = {Essen, Germany},
series = {ASE '12}
}

@article{10.1016/j.knosys.2015.10.009,
author = {Rana, Zeeshan Ali and Mian, M. Awais and Shamail, Shafay},
title = {Improving Recall of software defect prediction models using association mining},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {90},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.10.009},
doi = {10.1016/j.knosys.2015.10.009},
abstract = {Use of software product metrics in defect prediction studies highlights the utility of these metrics. Public availability of software defect data based on the product metrics has resulted in the development of defect prediction models. These models experience a limitation in learning Defect-prone (D) modules because the available datasets are imbalanced. Most of the datasets are dominated by Not Defect-prone (ND) modules as compared to D modules. This affects the ability of classification models to learn the D modules more accurately. This paper presents an association mining based approach that allows the defect prediction models to learn D modules in imbalanced datasets. The proposed algorithm preprocesses data by setting specific metric values as missing and improves the prediction of D modules. The proposed algorithm has been evaluated using 5 public datasets. A Naive Bayes (NB) classifier has been developed before and after the proposed preprocessing. It has been shown that Recall of the classifier after the proposed preprocessing has improved. Stability of the approach has been tested by experimenting the algorithm with different number of bins. The results show that the algorithm has resulted in up to 40% performance gain.},
journal = {Know.-Based Syst.},
month = dec,
pages = {1–13},
numpages = {13},
keywords = {Software defect prediction, PROMISE repository, Naive Bayes, Improving Recall, Imbalanced data, Association mining}
}

@article{10.1016/j.asoc.2017.01.050,
author = {Maua, Goran and Galinac Grbac, Tihana},
title = {Co-evolutionary multi-population genetic programming for classification in software defect prediction},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {55},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.01.050},
doi = {10.1016/j.asoc.2017.01.050},
abstract = {Evolving diverse ensembles using genetic programming has recently been proposed for classification problems with unbalanced data. Population diversity is crucial for evolving effective algorithms. Multilevel selection strategies that involve additional colonization and migration operations have shown better performance in some applications. Therefore, in this paper, we are interested in analysing the performance of evolving diverse ensembles using genetic programming for software defect prediction with unbalanced data by using different selection strategies. We use colonization and migration operators along with three ensemble selection strategies for the multi-objective evolutionary algorithm. We compare the performance of the operators for software defect prediction datasets with varying levels of data imbalance. Moreover, to generalize the results, gain a broader view and understand the underlying effects, we replicated the same experiments on UCI datasets, which are often used in the evolutionary computing community. The use of multilevel selection strategies provides reliable results with relatively fast convergence speeds and outperforms the other evolutionary algorithms that are often used in this research area and investigated in this paper. This paper also presented a promising ensemble strategy based on a simple convex hull approach and at the same time it raised the question whether ensemble strategy based on the whole population should also be investigated.},
journal = {Appl. Soft Comput.},
month = jun,
pages = {331–351},
numpages = {21},
keywords = {Software defect prediction, Genetic programming, Coevolution, Classification}
}

@inproceedings{10.1145/3382025.3414960,
author = {Str\"{u}der, Stefan and Mukelabai, Mukelabai and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Feature-oriented defect prediction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414960},
doi = {10.1145/3382025.3414960},
abstract = {Software errors are a major nuisance in software development and can lead not only to reputation damages, but also to considerable financial losses for companies. Therefore, numerous techniques for predicting software defects, largely based on machine learning methods, have been developed over the past decades. These techniques usually rely on code and process metrics in order to predict defects at the granularity of typical software assets, such as subsystems, components, and files. In this paper, we present the first systematic investigation of feature-oriented defect prediction: the prediction of defects at the granularity of features---domain-oriented entities abstractly representing (and often cross-cutting) typical software assets. Feature-oriented prediction can be beneficial, since: (i) particular features might be more error-prone than others, (ii) characteristics of features known as defective might be useful to predict other error-prone features, (iii) feature-specific code might be especially prone to faults arising from feature interactions. We present a dataset derived from 12 software projects and introduce two metric sets for feature-oriented defect prediction. We evaluated seven machine learning classifiers with three different attribute sets each, using our two new metric sets as well as an existing metric set from the literature. We observe precision and recall values of around 85% and better robustness when more diverse metrics sets with richer feature information are used.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {21},
numpages = {12},
keywords = {prediction, feature, defect, classification},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1007/978-3-030-91452-3_12,
author = {Amasaki, Sousuke and Aman, Hirohisa and Yokogawa, Tomoyuki},
title = {Searching for Bellwether Developers for Cross-Personalized Defect Prediction},
year = {2021},
isbn = {978-3-030-91451-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91452-3_12},
doi = {10.1007/978-3-030-91452-3_12},
abstract = {Context: Recent progress in the use of commit data for software defect prediction has driven research on personalized defect prediction. An idea applying one personalized model to another developer came in for seeking an alternative model predicting better than one’s own model. A question arose whether such exemplary developer (bellwether) existed as observed in traditional defect prediction. Objective: To investigate whether bellwether developers existed and how they behaved. Method: Experiments were conducted on 9 OSS projects. Models based on active developers in a project were compared with each other to seek bellwethers, whose models beaten models of the other active developers. Their performance was evaluated with new unseen data from the other active developers and the remaining non-active developers. Results: Bellwether developers were identified in all nine projects. Their performance on new unseen data from the other active developers was not higher than models learned by those developers. The bellwether was only a practical choice for the non-active developers. Conclusion: Bellwethers were a useful prediction model for the non-active developers but not for the other active developers.},
booktitle = {Product-Focused Software Process Improvement: 22nd International Conference, PROFES 2021, Turin, Italy, November 26, 2021, Proceedings},
pages = {183–198},
numpages = {16},
keywords = {Bellwether effect, Transfer learning, Personalized defect prediction},
location = {Turin, Italy}
}

@inproceedings{10.1109/MSR.2019.00017,
author = {Dam, Hoa Khanh and Pham, Trang and Ng, Shien Wee and Tran, Truyen and Grundy, John and Ghose, Aditya and Kim, Taeksu and Kim, Chul-Joo},
title = {Lessons learned from using a deep tree-based model for software defect prediction in practice},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00017},
doi = {10.1109/MSR.2019.00017},
abstract = {Defects are common in software systems and cause many problems for software users. Different methods have been developed to make early prediction about the most likely defective modules in large codebases. Most focus on designing features (e.g. complexity metrics) that correlate with potentially defective code. Those approaches however do not sufficiently capture the syntax and multiple levels of semantics of source code, a potentially important capability for building accurate prediction models. In this paper, we report on our experience of deploying a new deep learning tree-based defect prediction model in practice. This model is built upon the tree-structured Long Short Term Memory network which directly matches with the Abstract Syntax Tree representation of source code. We discuss a number of lessons learned from developing the model and evaluating it on two datasets, one from open source projects contributed by our industry partner Samsung and the other from the public PROMISE repository.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {46–57},
numpages = {12},
keywords = {defect prediction, deep learning},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/2961111.2962610,
author = {Petri\'{c}, Jean and Bowes, David and Hall, Tracy and Christianson, Bruce and Baddoo, Nathan},
title = {Building an Ensemble for Software Defect Prediction Based on Diversity Selection},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962610},
doi = {10.1145/2961111.2962610},
abstract = {Background: Ensemble techniques have gained attention in various scientific fields. Defect prediction researchers have investigated many state-of-the-art ensemble models and concluded that in many cases these outperform standard single classifier techniques. Almost all previous work using ensemble techniques in defect prediction rely on the majority voting scheme for combining prediction outputs, and on the implicit diversity among single classifiers. Aim: Investigate whether defect prediction can be improved using an explicit diversity technique with stacking ensemble, given the fact that different classifiers identify different sets of defects. Method: We used classifiers from four different families and the weighted accuracy diversity (WAD) technique to exploit diversity amongst classifiers. To combine individual predictions, we used the stacking ensemble technique. We used state-of-the-art knowledge in software defect prediction to build our ensemble models, and tested their prediction abilities against 8 publicly available data sets. Conclusion: The results show performance improvement using stacking ensembles compared to other defect prediction models. Diversity amongst classifiers used for building ensembles is essential to achieving these performance improvements.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {46},
numpages = {10},
keywords = {stacking, software faults, ensembles of learning machines, diversity, Software defect prediction},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@inproceedings{10.1145/2810146.2810150,
author = {Mahmood, Zaheed and Bowes, David and Lane, Peter C. R. and Hall, Tracy},
title = {What is the Impact of Imbalance on Software Defect Prediction Performance?},
year = {2015},
isbn = {9781450337151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810146.2810150},
doi = {10.1145/2810146.2810150},
abstract = {Software defect prediction performance varies over a large range. Menzies suggested there is a ceiling effect of 80% Recall [8]. Most of the data sets used are highly imbalanced. This paper asks, what is the empirical effect of using different datasets with varying levels of imbalance on predictive performance? We use data synthesised by a previous meta-analysis of 600 fault prediction models and their results. Four model evaluation measures (the Mathews Correlation Coefficient (MCC), F-Measure, Precision and Recall) are compared to the corresponding data imbalance ratio. When the data are imbalanced, the predictive performance of software defect prediction studies is low. As the data become more balanced, the predictive performance of prediction models increases, from an average MCC of 0.15, until the minority class makes up 20% of the instances in the dataset, where the MCC reaches an average value of about 0.34. As the proportion of the minority class increases above 20%, the predictive performance does not significantly increase. Using datasets with more than 20% of the instances being defective has not had a significant impact on the predictive performance when using MCC. We conclude that comparing the results of defect prediction studies should take into account the imbalance of the data.},
booktitle = {Proceedings of the 11th International Conference on Predictive Models and Data Analytics in Software Engineering},
articleno = {4},
numpages = {4},
keywords = {Data Imbalance, Defect Prediction, Machine Learning},
location = {Beijing, China},
series = {PROMISE '15}
}

@article{10.1016/j.ins.2013.12.031,
author = {Czibula, Gabriela and Marian, Zsuzsanna and Czibula, Istvan Gergely},
title = {Software defect prediction using relational association rule mining},
year = {2014},
issue_date = {April, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {264},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2013.12.031},
doi = {10.1016/j.ins.2013.12.031},
abstract = {This paper focuses on the problem of defect prediction, a problem of major importance during software maintenance and evolution. It is essential for software developers to identify defective software modules in order to continuously improve the quality of a software system. As the conditions for a software module to have defects are hard to identify, machine learning based classification models are still developed to approach the problem of defect prediction. We propose a novel classification model based on relational association rules mining. Relational association rules are an extension of ordinal association rules, which are a particular type of association rules that describe numerical orderings between attributes that commonly occur over a dataset. Our classifier is based on the discovery of relational association rules for predicting whether a software module is or it is not defective. An experimental evaluation of the proposed model on the open source NASA datasets, as well as a comparison to similar existing approaches is provided. The obtained results show that our classifier overperforms, for most of the considered evaluation measures, the existing machine learning based techniques for defect prediction. This confirms the potential of our proposal.},
journal = {Inf. Sci.},
month = apr,
pages = {260–278},
numpages = {19},
keywords = {Software engineering, Defect prediction, Data mining, Association rule}
}

@article{10.1016/j.asoc.2021.107870,
author = {Kabir, Md Alamgir and Keung, Jacky and Turhan, Burak and Bennin, Kwabena Ebo},
title = {Inter-release defect prediction with feature selection using temporal chunk-based learning: An empirical study},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {113},
number = {PA},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107870},
doi = {10.1016/j.asoc.2021.107870},
journal = {Appl. Soft Comput.},
month = dec,
numpages = {17},
keywords = {Feature selection, Inter-release defect prediction, Software defect prediction}
}

@article{10.1002/smr.2330,
author = {Shi, Ke and Lu, Yang and Liu, Guangliang and Wei, Zhenchun and Chang, Jingfei},
title = {MPT‐embedding: An unsupervised representation learning of code for software defect prediction},
year = {2021},
issue_date = {April 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {4},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2330},
doi = {10.1002/smr.2330},
abstract = {Software project defect prediction can help developers allocate debugging resources. Existing software defect prediction models are usually based on machine learning methods, especially deep learning. Deep learning‐based methods tend to build end‐to‐end models that directly use source code‐based abstract syntax trees (ASTs) as input. They do not pay enough attention to the front‐end data representation. In this paper, we propose a new framework to represent source code called multiperspective tree embedding (MPT‐embedding), which is an unsupervised representation learning method. MPT‐embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on both cross‐project defect prediction (CPDP) and within‐project defect prediction (WPDP) show that, on average, MPT‐embedding provides improvements over the state‐of‐the‐art method.Source code‐based automatic representations are more objective and accurate than traditional handcrafted metrics. This article proposed a new framework to represent code called multiperspective tree embedding (MPT‐embedding), which is an unsupervised representation learning method. MPT‐embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on the tasks of defect prediction show the effectiveness of the model.


image
image},
journal = {J. Softw. Evol. Process},
month = apr,
numpages = {20},
keywords = {tree embedding, representation learning, defect prediction, deep learning}
}

@article{10.1007/s10664-021-09984-2,
author = {Ulan, Maria and L\"{o}we, Welf and Ericsson, Morgan and Wingkvist, Anna},
title = {Weighted software metrics aggregation and its application to defect prediction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09984-2},
doi = {10.1007/s10664-021-09984-2},
abstract = {It is a well-known practice in software engineering to aggregate software metrics to assess software artifacts for various purposes, such as their maintainability or their proneness to contain bugs. For different purposes, different metrics might be relevant. However, weighting these software metrics according to their contribution to the respective purpose is a challenging task. Manual approaches based on experts do not scale with the number of metrics. Also, experts get confused if the metrics are not independent, which is rarely the case. Automated approaches based on supervised learning require reliable and generalizable training data, a ground truth, which is rarely available. We propose an automated approach to weighted metrics aggregation that is based on unsupervised learning. It sets metrics scores and their weights based on probability theory and aggregates them. To evaluate the effectiveness, we conducted two empirical studies on defect prediction, one on ca. 200 000 code changes, and another ca. 5 000 software classes. The results show that our approach can be used as an agnostic unsupervised predictor in the absence of a ground truth.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {34},
keywords = {Weighting, Aggregation, Software metrics, Defect prediction, Quantitative methods, Software assessment}
}

@article{10.3233/KES-210061,
author = {Shatnawi, Raed},
title = {Software fault prediction using machine learning techniques with metric thresholds},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {25},
number = {2},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-210061},
doi = {10.3233/KES-210061},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {159–172},
numpages = {14},
keywords = {machine learning, threshold values, software metrics, Fault prediction}
}

@inproceedings{10.1145/3460319.3464819,
author = {Zeng, Zhengran and Zhang, Yuqun and Zhang, Haotian and Zhang, Lingming},
title = {Deep just-in-time defect prediction: how far are we?},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464819},
doi = {10.1145/3460319.3464819},
abstract = {Defect prediction aims to automatically identify potential defective code with minimal human intervention and has been widely studied in the literature. Just-in-Time (JIT) defect prediction focuses on program changes rather than whole programs, and has been widely adopted in continuous testing. CC2Vec, state-of-the-art JIT defect prediction tool, first constructs a hierarchical attention network (HAN) to learn distributed vector representations of both code additions and deletions, and then concatenates them with two other embedding vectors representing commit messages and overall code changes extracted by the existing DeepJIT approach to train a model for predicting whether a given commit is defective. Although CC2Vec has been shown to be the state of the art for JIT defect prediction, it was only evaluated on a limited dataset and not compared with all representative baselines. Therefore, to further investigate the efficacy and limitations of CC2Vec, this paper performs an extensive study of CC2Vec on a large-scale dataset with over 310,370 changes (8.3 X larger than the original CC2Vec dataset). More specifically, we also empirically compare CC2Vec against DeepJIT and representative traditional JIT defect prediction techniques. The experimental results show that CC2Vec cannot consistently outperform DeepJIT, and neither of them can consistently outperform traditional JIT defect prediction. We also investigate the impact of individual traditional defect prediction features and find that the added-line-number feature outperforms other traditional features. Inspired by this finding, we construct a simplistic JIT defect prediction approach which simply adopts the added-line-number feature with the logistic regression classifier. Surprisingly, such a simplistic approach can outperform CC2Vec and DeepJIT in defect prediction, and can be 81k X/120k X faster in training/testing. Furthermore, the paper also provides various practical guidelines for advancing JIT defect prediction in the near future.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {427–438},
numpages = {12},
keywords = {Software Defect Prediction, Just-In-Time Prediction, Deep Learning},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1145/3410352.3410747,
author = {Almaghairbe, Rafig and Roper, Marc and Almabruk, Tahani},
title = {Machine Learning Techniques for Automated Software Fault Detection via Dynamic Execution Data: Empirical Evaluation Study},
year = {2020},
isbn = {9781450377362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410352.3410747},
doi = {10.1145/3410352.3410747},
abstract = {The biggest obstacle of automated software testing is the construction of test oracles. Today, it is possible to generate enormous amount of test cases for an arbitrary system that reach a remarkably high level of coverage, but the effectiveness of test cases is limited by the availability of test oracles that can distinguish failing executions. Previous work by the authors has explored the use of unsupervised and semi-supervised learning techniques to develop test oracles so that the correctness of software outputs and behaviours on new test cases can be predicated [1], [2], [10], and experimental results demonstrate the promise of this approach. In this paper, we present an evaluation study for test oracles based on machine-learning approaches via dynamic execution data (firstly, input/output pairs and secondly, amalgamations of input/output pairs and execution traces) by comparing their effectiveness with existing techniques from the specification mining domain (the data invariant detector Daikon [5]). The two approaches are evaluated on a range of mid-sized systems and compared in terms of their fault detection ability and false positive rate. The empirical study also discuss the major limitations and the most important properties related to the application of machine learning techniques as test oracles in practice. The study also gives a road map for further research direction in order to tackle some of discussed limitations such as accuracy and scalability. The results show that in most cases semi-supervised learning techniques performed far better as an automated test classifier than Daikon (especially in the case that input/output pairs were augmented with their execution traces). However, there is one system for which our strategy struggles and Daikon performed far better. Furthermore, unsupervised learning techniques performed on a par when compared with Daikon in several cases particularly when input/output pairs were used together with execution traces.},
booktitle = {Proceedings of the 6th International Conference on Engineering &amp; MIS 2020},
articleno = {15},
numpages = {12},
keywords = {Automated Testing Oracles, Empirical Study, Machine Learning Techniques, Specification Mining},
location = {Almaty, Kazakhstan},
series = {ICEMIS'20}
}

@article{10.5555/3324436.3324448,
title = {A statistical comparison for evaluating the effectiveness of linear and nonlinear manifold detection techniques for software defect prediction},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {3–4},
issn = {1755-0386},
abstract = {Most of the software systems are released without predicting defects and therefore, this paper presents a new effective technique-manifold detection technique MDT is essential and different than earlier applied defect prediction methods like regression, feature selection methods, etc. In this paper, performance of classifiers has been compared with or without MDTs to evaluate the effectiveness of different MDTs linear and nonlinear by reducing the dimensions of software datasets. In this process, eight classifiers were applied to four PROMISE datasets to determine the best performing classifier with respect to prediction performance measuring factors accuracy, precision, recall, F-measure, AUC, misclassification error with or without MDTs. The experimental results statistically tested by paired two-tailed t-test proved that FastMVU is the most accurate result producing technique as compared to all other nonlinear MDTs and Bayesian network BN is the most effective technique for software defect prediction using with or without MDTs.},
journal = {Int. J. Adv. Intell. Paradigms},
month = jan,
pages = {370–391},
numpages = {22}
}

@inproceedings{10.1007/978-3-030-78609-0_28,
author = {Sun, Ying and Sun, Yanfei and Wu, Fei and Jing, Xiao-Yuan},
title = {Deep Adversarial Learning Based Heterogeneous Defect Prediction},
year = {2021},
isbn = {978-3-030-78608-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78609-0_28},
doi = {10.1007/978-3-030-78609-0_28},
abstract = {Cross-project defect prediction (CPDP) is a hot study that predicts defects in the new project by utilizing the model trained on the data from other projects. However, existing CPDP methods usually assume that source and target projects have the same metrics. Heterogeneous defect prediction (HDP) is proposed and has attracted increasing attention, which refers to the metric sets from source and target projects are different in CPDP. HDP conducts prediction model using the instances with heterogeneous metrics from external projects and then use this model to predict defect-prone software instances in source project. However, building HDP methods is challenging including the distribution difference between source and target projects with heterogeneous metrics. In this paper, we propose a Deep adversarial learning based HDP (DHDP) approach. DHDP leverages deep neural network to learn nonlinear transformation for each project to obtain common feature represent, which the heterogeneous data from different projects can be compared directly. DHDP consists of two parts: a discriminator and a classifier that compete with each other. A classifier tries to minimize the similarity across classes and maximize the inter-class similarity. A discriminator tries to distinguish the source of instances that is source or target project on the common feature space. Expensive experiments are performed on 10 public projects from two datasets in terms of F-measure and G-measure. The experimental results show that DHDP gains superior prediction performance improvement compared to a range of competing methods.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part I},
pages = {326–337},
numpages = {12},
keywords = {Heterogeneous defect prediction, Metric learning, Adversarial learning},
location = {Dublin, Ireland}
}

@article{10.1016/j.jss.2016.09.001,
author = {Andreou, Andreas S. and Chatzis, Sotirios P.},
title = {Software defect prediction using doubly stochastic Poisson processes driven by stochastic belief networks},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.09.001},
doi = {10.1016/j.jss.2016.09.001},
abstract = {This research aims at better addressing the challenges related with software defect prediction.We develop a novel Bayesian inference approach driven from appropriate metrics.Formulation of our method is based on a doubly stochastic homogeneous Poisson process.Our model better learns from data with multiple modes in their distributions.We evaluate generalization across software classes, subsequent releases, and projects. Accurate prediction of software defects is of crucial importance in software engineering. Software defect prediction comprises two major procedures: (i) Design of appropriate software metrics to represent characteristic software system properties; and (ii) development of effective regression models for count data, allowing for accurate prediction of the number of software defects. Although significant research effort has been devoted to software metrics design, research in count data regression has been rather limited. More specifically, most used methods have not been explicitly designed to tackle the problem of metrics-driven software defect counts prediction, thus postulating irrelevant assumptions, such as (log-)linearity of the modeled data. In addition, a lack of simple and efficient algorithms for posterior computation has made more elaborate hierarchical Bayesian approaches appear unattractive in the context of software defect prediction. To address these issues, in this paper we introduce a doubly stochastic Poisson process for count data regression, the failure log-rate of which is driven by a novel latent space stochastic feedforward neural network. Our approach yields simple and efficient updates for its complicated conditional distributions by means of sampling importance resampling and error backpropagation. We exhibit the efficacy of our approach using publicly available and benchmark datasets.},
journal = {J. Syst. Softw.},
month = dec,
pages = {72–82},
numpages = {11},
keywords = {Stochastic belief network, Software defect prediction, Sampling importance resampling, Doubly stochastic Poisson process}
}

@article{10.1007/s10664-012-9218-8,
author = {Okutan, Ahmet and Y\i{}ld\i{}z, Olcay Taner},
title = {Software defect prediction using Bayesian networks},
year = {2014},
issue_date = {February  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-012-9218-8},
doi = {10.1007/s10664-012-9218-8},
abstract = {There are lots of different software metrics discovered and used for defect prediction in the literature. Instead of dealing with so many metrics, it would be practical and easy if we could determine the set of metrics that are most important and focus on them more to predict defectiveness. We use Bayesian networks to determine the probabilistic influential relationships among software metrics and defect proneness. In addition to the metrics used in Promise data repository, we define two more metrics, i.e. NOD for the number of developers and LOCQ for the source code quality. We extract these metrics by inspecting the source code repositories of the selected Promise data repository data sets. At the end of our modeling, we learn the marginal defect proneness probability of the whole software system, the set of most effective metrics, and the influential relationships among metrics and defectiveness. Our experiments on nine open source Promise data repository data sets show that response for class (RFC), lines of code (LOC), and lack of coding quality (LOCQ) are the most effective metrics whereas coupling between objects (CBO), weighted method per class (WMC), and lack of cohesion of methods (LCOM) are less effective metrics on defect proneness. Furthermore, number of children (NOC) and depth of inheritance tree (DIT) have very limited effect and are untrustworthy. On the other hand, based on the experiments on Poi, Tomcat, and Xalan data sets, we observe that there is a positive correlation between the number of developers (NOD) and the level of defectiveness. However, further investigation involving a greater number of projects is needed to confirm our findings.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {154–181},
numpages = {28},
keywords = {Defect prediction, Bayesian networks}
}

@phdthesis{10.5555/AAI29159899,
author = {Arar, \"{O}mer Faruk and undefinedBrahim, \"{O}Z\c{c}elik, and G\"{u}ltekin, \c{C}agil, and Pakize, Erdogmu\c{s}, and Onay, Durdu, Pinar},
advisor = {K\"{u}r\c{s}at, Ayan,},
title = {Makine \"{o}\u{g}renme algoritmalar\i{} kullan\i{}larak yaz\i{}l\i{}m Hata Kestiriminin iyile\c{s}tirilmesi / Using Machine Learning Algorithms to Improve Software Defect Prediction},
year = {2016},
isbn = {9798835589593},
publisher = {Sakarya Universitesi (Turkey)},
abstract = {Yaz\i{}l\i{}m sistemleri g\"{u}nl\"{u}k ya\c{s}ant\i{}m\i{}zda \c{c}ok \"{o}nemli bir role sahiptir ve her ge\c{c}en g\"{u}n kullan\i{}m\i{} daha da yayg\i{}nla\c{s}maktad\i{}r. Makinelerin ve servislerin b\"{u}y\"{u}k \c{c}o\u{g}unlu\u{g}u kendi i\c{c}lerinde farkl\i{} t\"{u}rde yaz\i{}l\i{}m i\c{c}erirler. Yaz\i{}l\i{}m geli\c{s}tiriciler, g\"{u}nl\"{u}k kullan\i{}m\i{}n\i{} yayg\i{}nla\c{s}t\i{}rmak ve rekabette geri kalmamak i\c{c}in m\"{u}mk\"{u}n oldu\u{g}unca h\i{}zl\i{} bir \c{s}ekilde yaz\i{}l\i{}mlar\i{} geli\c{s}tirmektedirler. Yaz\i{}l\i{}m ya\c{s}am d\"{o}ng\"{u}s\"{u}; genellikle analiz, tasar\i{}m, kodlama, test ve kurulum safhalar\i{}ndan olu\c{s}tur. Son kullan\i{}c\i{}ya hatadan ar\i{}nd\i{}r\i{}lm\i{}\c{s} bir yaz\i{}l\i{}m sunabilmek i\c{c}in test safhas\i{} etkili olarak y\"{u}r\"{u}t\"{u}lmelidir. Yaz\i{}l\i{}m metrikleri, kaynak kodun kalitesini yans\i{}tmay\i{} ama\c{c}larlar ve i\c{c}eri\u{g}i ile ilgili niceliksel bilgi verirler. Her bir metrik kodun farkl\i{} bir y\"{o}n\"{u}n\"{u} de\u{g}erlendirir. Kaynak kodun kalitesi seviyesi ile risk seviyesi aras\i{}nda bir ili\c{s}ki vard\i{}r. Son 20 y\i{}ll\i{}k d\"{o}nemde, akademisyenler, yaz\i{}l\i{}m hata kestirimi problemine giderek artan bir ilgi g\"{o}stermi\c{s}ler, daha g\"{u}rb\"{u}z bir kestirim i\c{c}in \c{c}e\c{s}itli makine \"{o}\u{g}renmesi yakla\c{s}\i{}mlar\i{} uygulanm\i{}\c{s}t\i{}r. Bu \c{c}al\i{}\c{s}mada da bu problem i\c{c}in \c{c}e\c{s}itli makine \"{o}\u{g}renmesi modelleri \"{o}nerilmi\c{s}tir. Yapay Sinir A\u{g}\i{} ve Yapay Ar\i{} Kolonisi kombinasyonu, Lojistik Regresyon-tabanl\i{} Bender Metot ve Naive Bayes bu \c{c}al\i{}\c{s}mada kullan\i{}lan algoritmalard\i{}r. \"{O}nerilen yakla\c{s}\i{}mlar, herkese a\c{c}\i{}k NASA Metrik Veri Program\i{} ve PROMISE havuzunda bulunan veri setlerine uygulanm\i{}\c{s}t\i{}r. undefinedstatistiki olarak g\"{u}venilir sonu\c{c}lar elde etmek ve \"{o}rneklem yanl\i{}l\i{}\u{g}\i{}n\i{} azaltmak i\c{c}in deneyler n-k\"{u}me \c{c}apraz validasyon ile kurgulanm\i{}\c{s}t\i{}r. Performans\i{} artt\i{}rmak i\c{c}in \"{o}nerilen modellere \"{o}zellik se\c{c}imi, normalizasyon ve ayr\i{}kla\c{s}t\i{}rma gibi \c{c}e\c{s}itli veri \"{o}n i\c{s}leme teknikleri uygulanm\i{}\c{s}t\i{}r. Deneylerden elde edilen sonu\c{c}lar di\u{g}er \c{c}al\i{}\c{s}malar ile kar\c{s}\i{}la\c{s}t\i{}r\i{}lm\i{}\c{s}t\i{}r. Bu \c{c}al\i{}\c{s}ma, \"{o}zellikle, yaz\i{}l\i{}m geli\c{s}tiricileri ve test personelinin kullan\i{}m\i{} y\"{o}n\"{u}yle katk\i{} yapmaktad\i{}r. Yaz\i{}l\i{}m geli\c{s}tiricileri, d\"{u}zenlemeye ihtiya\c{c} duyulan s\i{}n\i{}f veya mod\"{u}lleri g\"{o}r\"{u}rler; dolay\i{}s\i{}yla, bu mod\"{u}llerin kalitesinin artt\i{}r\i{}lmas\i{}na ve risk seviyelerinin azalt\i{}lmas\i{}na katk\i{} yapm\i{}\c{s} olurlar. Test personeli, daha \c{c}ok test yo\u{g}unla\c{s}mas\i{} gerektiren mod\"{u}lleri tespit eder ve bunun neticesinde mod\"{u}llerin \"{o}nceliklendirmesinin risk seviyelerine g\"{o}re yap\i{}lmas\i{} sa\u{g}lanm\i{}\c{s} olunur.},
note = {AAI29159899}
}

@article{10.1016/j.jss.2019.110402,
author = {Xu, Zhou and Li, Shuai and Xu, Jun and Liu, Jin and Luo, Xiapu and Zhang, Yifeng and Zhang, Tao and Keung, Jacky and Tang, Yutian},
title = {LDFR: Learning deep feature representation for software defect prediction},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {158},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110402},
doi = {10.1016/j.jss.2019.110402},
journal = {J. Syst. Softw.},
month = dec,
numpages = {20},
keywords = {99-00, 00-01, Deep neural network, Weighted cross-entropy loss, Triplet loss, Deep feature representation, Software defect prediction}
}

@inproceedings{10.1109/CIS.2013.61,
author = {Shuai, Bo and Li, Haifeng and Li, Mengjun and Zhang, Quan and Tang, Chaojing},
title = {Software Defect Prediction Using Dynamic Support Vector Machine},
year = {2013},
isbn = {9781479925490},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CIS.2013.61},
doi = {10.1109/CIS.2013.61},
abstract = {In order to solve the problems of traditional SVM classifier for software defect prediction, this paper proposes a novel dynamic SVM method based on improved cost-sensitive SVM (CSSVM) which is optimized by the Genetic Algorithm (GA). Through selecting the geometric classification accuracy as the fitness function, the GA method could improve the performance of CSSVM by enhancing the accuracy of defective modules and reducing the total cost in the whole decision. Experimental results show that the GA-CSSVM method could achieve higher AUC value which denotes better prediction accuracy both for minority and majority samples in the imbalanced software defect data set.},
booktitle = {Proceedings of the 2013 Ninth International Conference on Computational Intelligence and Security},
pages = {260–263},
numpages = {4},
keywords = {software defect, GA, CSSVM, AUC},
series = {CIS '13}
}

@article{10.1016/j.infsof.2011.09.007,
author = {Ma, Ying and Luo, Guangchun and Zeng, Xue and Chen, Aiguo},
title = {Transfer learning for cross-company software defect prediction},
year = {2012},
issue_date = {March, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2011.09.007},
doi = {10.1016/j.infsof.2011.09.007},
abstract = {Context: Software defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction? Objective: In this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model. Method: Unlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built. Results: This article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods. Conclusion: It is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {248–256},
numpages = {9},
keywords = {Transfer learning, Software defect prediction, Naive Bayes, Machine learning, Different distribution}
}

@article{10.1504/IJWMC.2016.076145,
author = {Li, Feixiang and Rong, Xiaotao and Cui, Zhihua},
title = {A hybrid CRBA-SVM model for software defect prediction},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {10},
number = {2},
issn = {1741-1084},
url = {https://doi.org/10.1504/IJWMC.2016.076145},
doi = {10.1504/IJWMC.2016.076145},
abstract = {Support vector machine SVM model is becoming an increasingly popular method in software defects prediction. This model has strong non-linear classifying ability. However, SVM model lacks effective method to determine the best parameters. In this paper, a modified bat algorithm, named changing range bat algorithm, is employed to optimise the parameters of SVM model. To test the performance of this new model, several public datasets of software defect prediction are employed and then the results are compared with other five approaches. Experimental results show that the classification ability of hybrid CRBA-SVM model surpasses all other approaches.},
journal = {Int. J. Wire. Mob. Comput.},
month = apr,
pages = {191–196},
numpages = {6}
}

@phdthesis{10.5555/AAI28414631,
author = {Gatling, Teia C. and Blackburn, Timothy},
advisor = {Oluwatomi, Adetunji, and Amirhossein, Etemadi,},
title = {Applying Documentation Metrics in Cross Version Defect Prediction Modeling},
year = {2021},
isbn = {9798708754837},
publisher = {The George Washington University},
abstract = {Software documentation such as documented Application Programming Interface (API) and comments embedded with the software code aid in faster debugging of software defects. The existence of this documentation is used as a measurement of software quality. Over the last 40 years, a series of object-oriented metrics-based defect prediction models have been successfully developed. However, documentation metrics in combination with object-oriented metrics in software defect prediction modeling has not been explored in predicting defects. By leveraging a publicly available GitHub dataset that contains both documentation and object-oriented metrics and applying the cross version defect prediction approach, this research determined documentation metrics impact on defects across a project and developed a predictive model using these metric in combination with baseline metrics to improve model performance. As a result, Boosting ensemble method returned improved model performance when combining the documentation metrics with commonly used object-oriented code metrics. Likewise, the Random Forest returned an improved model when using a feature subset. Random Forest using a subset of metrics provided the most promising results with F-Measure performance improvement of 8.9 percent. The results of this research highlight quantitatively the impact documentation metrics have on software defect prediction and that model performance can improve when identifying a subset of metrics. The results also demonstrate the use of data from three previous versions versus solely using the latest version, the models perform within an average of five percentage points of each other. This knowledge can be leveraged by managers to enhance the application of documentation throughout the lifecycle of software.},
note = {AAI28414631}
}

@inproceedings{10.1145/2875913.2875944,
author = {Qing, He and Biwen, Li and Beijun, Shen and Xia, Yong},
title = {Cross-Project Software Defect Prediction Using Feature-Based Transfer Learning},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875944},
doi = {10.1145/2875913.2875944},
abstract = {Cross-project defect prediction is taken as an effective means of predicting software defects when the data shortage exists in the early phase of software development. Unfortunately, the precision of cross-project defect prediction is usually poor, largely because of the differences between the reference and the target projects. Having realized the project differences, this paper proposes CPDP, a feature-based transfer learning approach to cross-project defect prediction. The core insight of CPDP is to (1) filter and transfer highly-correlated data based on data samples in the target projects, and (2) evaluate and choose learning schemas for transferring data sets. Models are then built for predicting defects in the target projects. We have also conducted an evaluation of the proposed approach on PROMISE datasets. The evaluation results show that, the proposed approach adapts to cross-project defect prediction in that f-measure of 81.8% of projects can get improved, and AUC of 54.5% projects improved. It also achieves similar f-measure and AUC as some inner-project defect prediction approaches.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {74–82},
numpages = {9},
keywords = {transfer learning, feature-based transfer, cross-project defect prediction},
location = {Wuhan, China},
series = {Internetware '15}
}

@inproceedings{10.1109/ISISE.2012.114,
author = {Wang, Pei and Jin, Cong and Jin, Shu-Wei},
title = {Software Defect Prediction Scheme Based on Feature Selection},
year = {2012},
isbn = {9780769549514},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISISE.2012.114},
doi = {10.1109/ISISE.2012.114},
abstract = {Predicting defect-prone software modules accurately and effectively are important ways to control the quality of a software system during software development. Feature selection can highly improve the accuracy and efficiency of the software defect prediction model. The main purpose of this paper is to discuss the best size of feature subset for building a prediction model and prove that feature selection method is useful for establishing software defect prediction model. Mutual information is an outstanding indicator of relevance between variables, and it has been used as a measurement in our feature selection algorithm. We also introduce a nonlinear factor to our evaluation function for feature selection to improve its performance. The results of our feature selection algorithm are validated by different machine learning methods. The experiment results show that all the classifiers achieve higher accuracy by using the feature subset provided by our algorithm.},
booktitle = {Proceedings of the 2012 Fourth International Symposium on Information Science and Engineering},
pages = {477–480},
numpages = {4},
keywords = {software defect prediction, mutual information, feature selection},
series = {ISISE '12}
}

@inproceedings{10.1145/2961111.2962620,
author = {Shippey, Thomas and Hall, Tracy and Counsell, Steve and Bowes, David},
title = {So You Need More Method Level Datasets for Your Software Defect Prediction? Voil\`{a}!},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962620},
doi = {10.1145/2961111.2962620},
abstract = {Context: Defect prediction research is based on a small number of defect datasets and most are at class not method level. Consequently our knowledge of defects is limited. Identifying defect datasets for prediction is not easy and extracting quality data from identified datasets is even more difficult. Goal: Identify open source Java systems suitable for defect prediction and extract high quality fault data from these datasets. Method: We used the Boa to identify candidate open source systems. We reduce 50,000 potential candidates down to 23 suitable for defect prediction using a selection criteria based on the system's software repository and its defect tracking system. We use an enhanced SZZ algorithm to extract fault information and calculate metrics using JHawk. Result: We have produced 138 fault and metrics datasets for the 23 identified systems. We make these datasets (the ELFF datasets) and our data extraction tools freely available to future researchers. Conclusions: The data we provide enables future studies to proceed with minimal effort. Our datasets significantly increase the pool of systems currently being used in defect analysis studies.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {12},
numpages = {6},
keywords = {Defects, Defect linking, Defect Prediction, Data Mining, Boa},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@article{10.1145/3467895,
author = {Falessi, Davide and Ahluwalia, Aalok and Penta, Massimiliano DI},
title = {The Impact of Dormant Defects on Defect Prediction: A Study of 19 Apache Projects},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3467895},
doi = {10.1145/3467895},
abstract = {Defect prediction models can be beneficial to prioritize testing, analysis, or code review activities, and has been the subject of a substantial effort in academia, and some applications in industrial contexts. A necessary precondition when creating a defect prediction model is the availability of defect data from the history of projects. If this data is noisy, the resulting defect prediction model could result to be unreliable. One of the causes of noise for defect datasets is the presence of “dormant defects,” i.e., of defects discovered several releases after their introduction. This can cause a class to be labeled as defect-free while it is not, and is, therefore “snoring.” In this article, we investigate the impact of snoring on classifiers' accuracy and the effectiveness of a possible countermeasure, i.e., dropping too recent data from a training set. We analyze the accuracy of 15 machine learning defect prediction classifiers, on data from more than 4,000 defects and 600 releases of 19 open source projects from the Apache ecosystem. Our results show that on average across projects (i) the presence of dormant defects decreases the recall of defect prediction classifiers, and (ii) removing from the training set the classes that in the last release are labeled as not defective significantly improves the accuracy of the classifiers. In summary, this article provides insights on how to create defects datasets by mitigating the negative effect of dormant defects on defect prediction.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {4},
numpages = {26},
keywords = {dataset bias, fix-inducing changes, Defect prediction}
}

@article{10.1016/j.eswa.2019.113156,
author = {Majd, Amirabbas and Vahidi-Asl, Mojtaba and Khalilian, Alireza and Poorsarvi-Tehrani, Pooria and Haghighi, Hassan},
title = {SLDeep: Statement-level software defect prediction using deep-learning model on static code features},
year = {2020},
issue_date = {Jun 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {147},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113156},
doi = {10.1016/j.eswa.2019.113156},
journal = {Expert Syst. Appl.},
month = jun,
numpages = {14},
keywords = {Software metric, Fault prediction model, Machine learning, Software fault proneness, Defect}
}

@article{10.1016/j.compind.2021.103505,
author = {Gashi, Milot and Ofner, Patrick and Ennsbrunner, Helmut and Thalmann, Stefan},
title = {Dealing with missing usage data in defect prediction: A case study of a welding supplier},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2021.103505},
doi = {10.1016/j.compind.2021.103505},
journal = {Comput. Ind.},
month = nov,
numpages = {10},
keywords = {Multi-component systems, Predictive maintenance, Welding industry, End-of-line testing, Defect prediction}
}

@article{10.1016/j.compeleceng.2021.107370,
author = {Zheng, Shang and Gai, Jinjing and Yu, Hualong and Zou, Haitao and Gao, Shang},
title = {Training data selection for imbalanced cross-project defect prediction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {94},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107370},
doi = {10.1016/j.compeleceng.2021.107370},
journal = {Comput. Electr. Eng.},
month = sep,
numpages = {11},
keywords = {Relative density, Jensen-Shannon divergence, Data selection, Cross-project software prediction}
}

@inproceedings{10.1109/COMPSAC.2014.65,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {A Semi-supervised Approach to Software Defect Prediction},
year = {2014},
isbn = {9781479935758},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2014.65},
doi = {10.1109/COMPSAC.2014.65},
abstract = {Accurate detection of software components that need to be exposed to additional verification and validation offers the path to high quality products while minimizing non essential software assurance expenditures. In this type of quality modeling we assume that software modules with known fault content developed in similar environment are available. Supervised learning algorithms are the traditional methods of choice for training on existing modules. The models are then used to predict fault content for newly developed software components prior to product release. However, one needs to realize that establishing whether a module contains a fault or not, only to be used for model training, can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available, thus reducing the overall cost of quality assurance. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics used for prediction. Our results show that the dimension-reduction with semi-supervised learning algorithm preforms significantly better than one of the best performing supervised learning algorithm - random forest - in situations when few modules with known fault content are available. We compare our results with the published benchmarks and clearly demonstrate performance benefits.},
booktitle = {Proceedings of the 2014 IEEE 38th Annual Computer Software and Applications Conference},
pages = {416–425},
numpages = {10},
keywords = {software fault prediction, semi-supervised learning, dimension reduction, software metrics},
series = {COMPSAC '14}
}

@inproceedings{10.1145/3379247.3379278,
author = {Ahmed, Md. Razu and Ali, Md. Asraf and Ahmed, Nasim and Zamal, Md. Fahad Bin and Shamrat, F.M. Javed Mehedi},
title = {The Impact of Software Fault Prediction in Real-World Application: An Automated Approach for Software Engineering},
year = {2020},
isbn = {9781450376730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379247.3379278},
doi = {10.1145/3379247.3379278},
abstract = {Software fault prediction and proneness has long been considered as a critical issue for the tech industry and software professionals. In the traditional techniques, it requires previous experience of faults or a faulty module while detecting the software faults inside an application. An automated software fault recovery models enable the software to significantly predict and recover software faults using machine learning techniques. Such ability of the feature makes the software to run more effectively and reduce the faults, time and cost. In this paper, we proposed a software defect predictive development models using machine learning techniques that can enable the software to continue its projected task. Moreover, we used different prominent evaluation benchmark to evaluate the model's performance such as ten-fold cross-validation techniques, precision, recall, specificity, f 1 measure, and accuracy. This study reports a significant classification performance of 98-100% using SVM on three defect datasets in terms of f1 measure. However, software practitioners and researchers can attain independent understanding from this study while selecting automated task for their intended application.},
booktitle = {Proceedings of 2020 6th International Conference on Computing and Data Engineering},
pages = {247–251},
numpages = {5},
keywords = {Software fault, Software engineering, Machine learning, Defect prediction},
location = {Sanya, China},
series = {ICCDE '20}
}

@inproceedings{10.1145/2491411.2494581,
author = {Zhang, Hongyu and Cheung, S. C.},
title = {A cost-effectiveness criterion for applying software defect prediction models},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2494581},
doi = {10.1145/2491411.2494581},
abstract = {Ideally, software defect prediction models should help organize software quality assurance (SQA) resources and reduce cost of finding defects by allowing the modules most likely to contain defects to be inspected first. In this paper, we study the cost-effectiveness of applying defect prediction models in SQA and propose a basic cost-effectiveness criterion. The criterion implies that defect prediction models should be applied with caution. We also propose a new metric FN/(FN+TN) to measure the cost-effectiveness of a defect prediction model.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {643–646},
numpages = {4},
keywords = {evaluation metrics, cost effectiveness, Defect prediction},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@article{10.1109/TSE.2017.2731766,
author = {Bennin, Kwabena Ebo and Keung, Jacky and Phannachitta, Passakorn and Monden, Akito and Mensah, Solomon},
title = {MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction},
year = {2018},
issue_date = {June 2018},
publisher = {IEEE Press},
volume = {44},
number = {6},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2017.2731766},
doi = {10.1109/TSE.2017.2731766},
abstract = {Highly imbalanced data typically make accurate predictions difficult. Unfortunately, software defect datasets tend to have fewer defective modules than non-defective modules. Synthetic oversampling approaches address this concern by creating new minority defective modules to balance the class distribution before a model is trained. Notwithstanding the successes achieved by these approaches, they mostly result in over-generalization (high rates of false alarms) and generate near-duplicated data instances (less diverse data). In this study, we introduce MAHAKIL, a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with SMOTE, Borderline-SMOTE, ADASYN, Random Oversampling and the No sampling approach using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant &lt;italic&gt;pf&lt;/italic&gt; values than the other oversampling approaches, based on Brunner's statistical significance test and Cliff's effect sizes. Therefore, MAHAKIL is strongly recommended as an efficient alternative for defect prediction models built on highly imbalanced datasets.},
journal = {IEEE Trans. Softw. Eng.},
month = jun,
pages = {534–550},
numpages = {17}
}

@inproceedings{10.1109/ICSE-C.2017.72,
author = {Wu, Fei and Jing, Xiao-Yuan and Dong, Xiwei and Cao, Jicheng and Xu, Mingwei and Zhang, Hongyu and Ying, Shi and Xu, Baowen},
title = {Cross-project and within-project semi-supervised software defect prediction problems study using a unified solution},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.72},
doi = {10.1109/ICSE-C.2017.72},
abstract = {When there exists not enough historical defect data for building accurate prediction model, semi-supervised defect prediction (SSDP) and cross-project defect prediction (CPDP) are two feasible solutions. Existing CPDP methods assume that the available source data is well labeled. However, due to expensive human efforts for labeling a large amount of defect data, usually, we can only make use of the suitable unlabeled source data to help build the prediction model. We call CPDP in this scenario as cross-project semi-supervised defect prediction (CSDP). As to within-project semi-supervised defect prediction (WSDP), although some WSDP methods have been developed in recent years, there still exists much room for improvement. In this paper, we aim to provide an effective solution for both CSDP and WSDP problems. We introduce the semi-supervised dictionary learning technique, an effective machine learning technique, into defect prediction and propose a semi-supervised structured dictionary learning (SSDL) approach for CSDP and WSDP. SSDL can make full use of the useful information in limited labeled defect data and a large amount of unlabeled data. Experiments on two public datasets indicate that SSDL can obtain better prediction performance than related SSDP methods in the CSDP scenario.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {195–197},
numpages = {3},
keywords = {within-project semi-supervised defect prediction, semi-supervised structured dictionary learning, cross-project semi-supervised defect prediction},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@book{10.5555/3175829,
author = {Rashid, Ekbal and Rashid, Ekbal},
title = {Enhancing Software Fault Prediction With Machine Learning: Emerging Research and Opportunities},
year = {2017},
isbn = {1522531858},
publisher = {IGI Global},
address = {USA},
edition = {1st},
abstract = {Software development and design is an intricate and complex process that requires a multitude of steps to ultimately create a quality product. One crucial aspect of this process is minimizing potential errors through software fault prediction. Enhancing Software Fault Prediction With Machine Learning: Emerging Research and Opportunities is an innovative source of material on the latest advances and strategies for software quality prediction. Including a range of pivotal topics such as case-based reasoning, rate of improvement, and expert systems, this book is an ideal reference source for engineers, researchers, academics, students, professionals, and practitioners interested in novel developments in software design and analysis.}
}

@inproceedings{10.1145/3273934.3273938,
author = {Amasaki, Sousuke},
title = {Cross-Version Defect Prediction using Cross-Project Defect Prediction Approaches: Does it work?},
year = {2018},
isbn = {9781450365932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3273934.3273938},
doi = {10.1145/3273934.3273938},
abstract = {Background: Specifying and removing defects before release deserve extra cost for the success of software projects. Long-running projects experience multiple releases, and it is a natural choice to adopt cross-version defect prediction (CVDP) that uses information from older versions. A past study shows that feeding multi older versions data may have a positive influence on the performance. The study also suggests that cross-project defect prediction (CPDP) may fit the situation but one CPDP approach was only examined.Aims: To investigate whether feeding multiple older versions data is effective for CVDP using CPDP approaches. The investigation also involves performance comparisons of the CPDP approaches under CVDP situation. Method: We chose a style of replication of the comparative study on CPDP approaches by Herbold et al. under CVDP situation. Results: Feeding multiple older versions had a positive effect for more than a half CPDP approaches. However, almost all of the CPDP approaches did not perform significantly better than a simple rule-based prediction. Although the best CPDP approach could work better than it and with-in project defect prediction, we found no effect of feeding multiple older versions for it. Conclusions: Feeding multiple older versions could improve CPDP approaches under CVDP situation. However, it did not work for the best CPDP approach in the study.},
booktitle = {Proceedings of the 14th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {32–41},
numpages = {10},
keywords = {Comparative Study, Cross-Project Defect Prediction, Cross-Version Defect Prediction},
location = {Oulu, Finland},
series = {PROMISE'18}
}

@article{10.4018/IJOSSP.2017010102,
author = {Alsukhni, Emad and Saifan, Ahmad A. and Alawneh, Hanadi},
title = {A New Data Mining-Based Framework to Test Case Prioritization Using Software Defect Prediction},
year = {2017},
issue_date = {January 2017},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {1},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2017010102},
doi = {10.4018/IJOSSP.2017010102},
abstract = {Test cases do not have the same importance when used to detect faults in software; therefore, it is more efficient to test the system with the test cases that have the ability to detect the faults. This research proposes a new framework that combines data mining techniques to prioritize the test cases. It enhances fault prediction and detection using two different techniques: 1 the data mining regression classifier that depends on software metrics to predict defective modules, and 2 the k-means clustering technique that is used to select and prioritize test cases to identify the fault early. Our approach of test case prioritization yields good results in comparison with other studies. The authors used the Average Percentage of Faults Detection APFD metric to evaluate the proposed framework, which results in 19.9% for all system modules and 25.7% for defective ones. Our results give us an indication that it is effective to start the testing process with the most defective modules instead of testing all modules arbitrary arbitrarily.},
journal = {Int. J. Open Source Softw. Process.},
month = jan,
pages = {21–41},
numpages = {21},
keywords = {Test Case Prioritization, Software Testing, Software Defect Prediction, Data Mining}
}

@inproceedings{10.1007/978-3-030-27878-6_8,
author = {LaCasse, Phillip M. and Otieno, Wilkistar and Maturana, Francisco P.},
title = {Operationalization of a Machine Learning and Fuzzy Inference-Based Defect Prediction Case Study in a Holonic Manufacturing System},
year = {2019},
isbn = {978-3-030-27877-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27878-6_8},
doi = {10.1007/978-3-030-27878-6_8},
abstract = {Industry 4.0 capabilities have enabled manufacturers to collect and analyze smart manufacturing data across a broad array of diverse domains including but not limited to scheduling, production, maintenance, process, and quality. This development necessarily proceeds in a logical sequence by which first the organization develops the capability to capture and store this data and, at best concurrently but frequently lagging, develops and refines the competencies to analyze and effectively utilize it. This research presents an applied case study in surface mount technology (SMT) manufacture of printed circuit board (PCB) assemblies. Parametric data captured at the solder paste inspection (SPI) station is analyzed with machine learning models to identify patterns and relationships that can be harnessed to preempt electrical defects at downline inspection stations. This project is enabled by the recent conclusion of an Industrial Internet of Things (IIoT) capability enhancement at the manufacturing facility from which the data is drawn and is the logical next step in achieving value from the newly-available smart manufacturing data. The operationalization of this analysis is contextualized within the product-resource-order-staff architecture (PROSA) of a Holonic Manufacturing Systems (HMS). A Trigger Holon is nested between the Resource Holarchy and Product Holarchy that, at scheduling, distributes implementation instructions for the defect-prediction model. The Defect Prediction Holon is containerized within the Product Holarchy and provides instructions for corrective action when the model flags a record as exhibiting increased probability of a downline electrical defect.},
booktitle = {Industrial Applications of Holonic and Multi-Agent Systems: 9th International Conference, HoloMAS 2019, Linz, Austria, August 26–29, 2019, Proceedings},
pages = {96–104},
numpages = {9},
keywords = {Holonic manufacturing system, Machine learning, Defect prediction, Printed circuit board, Surface mount technology, Solder paste inspection, Ball grid array},
location = {Linz, Austria}
}

@inproceedings{10.1007/978-3-030-78612-0_5,
author = {Xu, Haitao and Duan, Ruifeng and Yang, Shengsong and Guo, Lei},
title = {An Empirical Study on Data Sampling for Just-in-Time Defect Prediction},
year = {2021},
isbn = {978-3-030-78611-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78612-0_5},
doi = {10.1007/978-3-030-78612-0_5},
abstract = {In this paper, the impact of Data Sampling on Just-in-Time defect prediction is explored. We find that there is a significant negative relationship between the class imbalance ratio of the dataset and the performance of the instant software defect prediction model. Secondly although most software defect data are not as unbalanced as expected, a moderate degree of imbalance is sufficient to affect the performance of traditional learning. This means that if the training data for immediate software defects show moderate or more severe imbalances, one need not expect good defect prediction performance and the data sampling approach to balancing the training data can improve the performance of the model. Finally, the empirical approach shows that although the under-sampling method slightly improves model performance, the different sampling methods do not have a substantial impact on the evaluation of immediate software defect prediction models.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part II},
pages = {54–69},
numpages = {16},
keywords = {Empirical study, Just-in-time defect, Data sampling},
location = {Dublin, Ireland}
}

@inproceedings{10.1145/3475716.3475791,
author = {Gesi, Jiri and Li, Jiawei and Ahmed, Iftekhar},
title = {An Empirical Examination of the Impact of Bias on Just-in-time Defect Prediction},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475791},
doi = {10.1145/3475716.3475791},
abstract = {Background: Just-In-Time (JIT) defect prediction models predict if a commit will introduce defects in the future. DeepJIT and CC2Vec are two state-of-the-art JIT Deep Learning (DL) techniques. Usually, defect prediction techniques are evaluated, treating all training data equally. However, data is usually imbalanced not only in terms of the overall class label (e.g., defect and non-defect) but also in terms of characteristics such as File Count, Edit Count, Multiline Comments, Inward Dependency Sum etc. Prior research has investigated the impact of class imbalance on prediction technique's performance but not the impact of imbalance of other characteristics. Aims: We aim to explore the impact of different commit related characteristic's imbalance on DL defect prediction. Method: We investigated different characteristic's impact on the overall performance of DeepJIT and CC2Vec. We also propose a Siamese network based few-shot learning framework for JIT defect prediction (SifterJIT) combining Siamese network and DeepJIT. Results: Our results show that DeepJIT and CC2Vec lose out on the performance by around 20% when trained and tested on imbalanced data. However, SifterJIT can outperform state-of-the-art DL techniques with an average of 8.65% AUC score, 11% precision, and 6% F1-score improvement. Conclusions: Our results highlight that dataset imbalanced in terms of commit characteristics can significantly impact prediction performance, and few-shot learning based techniques can help alleviate the situation.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {7},
numpages = {12},
keywords = {software engineering, few-shot learning, defect prediction, Deep learning},
location = {Bari, Italy},
series = {ESEM '21}
}

@article{10.1504/IJBIC.2018.092808,
title = {An improved twin support vector machine based on multi-objective cuckoo search for software defect prediction},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {11},
number = {4},
issn = {1758-0366},
url = {https://doi.org/10.1504/IJBIC.2018.092808},
doi = {10.1504/IJBIC.2018.092808},
abstract = {Recently, software defect prediction SDP has drawn much attention as software size becomes larger and consumers hold higher reliability expectations. The premise of SDP is to guide the detection of software bugs and to conserve computational resources. However, in prior research, data imbalances among software defect modules were largely ignored to focus instead on how to improve defect prediction accuracy. In this paper, a novel SDP model based on twin support vector machines TSVM and a multi-objective cuckoo search MOCS is proposed, called MOCSTSVM. We set the probability of detection and the probability of false alarm as the SDP objectives. We use TSVM to predict defected modules and employ MOCS to optimise TSVM for this dual-objective optimisation problem. To test our approach, we conduct a series of experiments on a public dataset from the PROMISE repository. The experimental results demonstrate that our approach achieves good performance compared with other SDP models.},
journal = {Int. J. Bio-Inspired Comput.},
month = jan,
pages = {282–291},
numpages = {10}
}

@article{10.1007/s11277-017-5069-3,
author = {Dong, Feng and Wang, Junfeng and Li, Qi and Xu, Guoai and Zhang, Shaodong},
title = {Defect Prediction in Android Binary Executables Using Deep Neural Network},
year = {2018},
issue_date = {October   2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {3},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-5069-3},
doi = {10.1007/s11277-017-5069-3},
abstract = {Software defect prediction locates defective code to help developers improve the security of software. However, existing studies on software defect prediction are mostly limited to the source code. Defect prediction for Android binary executables (called apks) has never been explored in previous studies. In this paper, we propose an explorative study of defect prediction in Android apks. We first propose smali2vec, a new approach to generate features that capture the characteristics of smali (decompiled files of apks) files in apks. Smali2vec extracts both token and semantic features of the defective files in apks and such comprehensive features are needed for building accurate prediction models. Then we leverage deep neural network (DNN), which is one of the most common architecture of deep learning networks, to train and build the defect prediction model in order to achieve accuracy. We apply our defect prediction model to more than 90,000 smali files from 50 Android apks and the results show that our model could achieve an AUC (the area under the receiver operating characteristic curve) of 85.98% and it is capable of predicting defects in apks. Furthermore, the DNN is proved to have a better performance than the traditional shallow machine learning algorithms (e.g., support vector machine and naive bayes) used in previous studies. The model has been used in our practical work and helped locate many defective files in apks.},
journal = {Wirel. Pers. Commun.},
month = oct,
pages = {2261–2285},
numpages = {25},
keywords = {Software defect prediction, Mobile security, Machine learning, Deep neural network, Android binary executables}
}

@article{10.1016/j.asoc.2020.106686,
author = {Haouari, Ahmed Taha and Souici-Meslati, Labiba and Atil, Fadila and Meslati, Djamel},
title = {Empirical comparison and evaluation of Artificial Immune Systems in inter-release software fault prediction},
year = {2020},
issue_date = {Nov 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {96},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.106686},
doi = {10.1016/j.asoc.2020.106686},
journal = {Appl. Soft Comput.},
month = nov,
numpages = {18},
keywords = {Neural Network, Artificial Immune Recognition System, Inter-projects fault prediction, Software defect prediction, Artificial Immune Systems}
}

@article{10.1016/j.asoc.2016.04.032,
author = {Malhotra, Ruchika},
title = {An empirical framework for defect prediction using machine learning techniques with Android software},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.04.032},
doi = {10.1016/j.asoc.2016.04.032},
abstract = {Display Omitted Use of appropriate and large number data sets for comparing 18 ML techniques for defect prediction using object-oriented metrics.Effective performance of the predicted models assessed using appropriate performance measures.Reliability of the results evaluated using statistical test and post-hoc analysis.Validating the predicted models using inter-release validation on various releases of seven application packages of Android software. ContextSoftware defect prediction is important for identification of defect-prone parts of a software. Defect prediction models can be developed using software metrics in combination with defect data for predicting defective classes. Various studies have been conducted to find the relationship between software metrics and defect proneness, but there are few studies that statistically determine the effectiveness of the results. ObjectiveThe main objectives of the study are (i) comparison of the machine-learning techniques using data sets obtained from popular open source software (ii) use of appropriate performance measures for measuring the performance of defect prediction models (iii) use of statistical tests for effective comparison of machine-learning techniques and (iv) validation of models over different releases of data sets. MethodIn this study we use object-oriented metrics for predicting defective classes using 18 machine-learning techniques. The proposed framework has been applied to seven application packages of well known, widely used Android operating system viz. Contact, MMS, Bluetooth, Email, Calendar, Gallery2 and Telephony. The results are validated using 10-fold and inter-release validation methods. The reliability and significance of the results are evaluated using statistical test and post-hoc analysis. ResultsThe results show that the area under the curve measure for Nave Bayes, LogitBoost and Multilayer Perceptron is above 0.7 in most of the cases. The results also depict that the difference between the ML techniques is statistically significant. However, it is also proved that the Support Vector Machines based techniques such as Support Vector Machines and voted perceptron do not possess the predictive capability for predicting defects. ConclusionThe results confirm the predictive capability of various ML techniques for developing defect prediction models. The results also confirm the superiority of one ML technique over the other ML techniques. Thus, the software engineers can use the results obtained from this study in the early phases of the software development for identifying defect-prone classes of given software.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1034–1050},
numpages = {17},
keywords = {Statistical tests, Software defect proneness, Object-oriented metrics, Machine-learning, Inter-release validation}
}

@article{10.1155/2021/5558561,
author = {Shao, Yanli and Zhao, Jingru and Wang, Xingqi and Wu, Weiwei and Fang, Jinglong and Gao, Honghao},
title = {Research on Cross-Company Defect Prediction Method to Improve Software Security},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/5558561},
doi = {10.1155/2021/5558561},
abstract = {As the scale and complexity of software increase, software security issues have become the focus of society. Software defect prediction (SDP) is an important means to assist developers in discovering and repairing potential defects that may endanger software security in advance and improving software security and reliability. Currently, cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) are widely studied to improve the defect prediction performance, but there are still problems such as inconsistent metrics and large differences in data distribution between source and target projects. Therefore, a new CCDP method based on metric matching and sample weight setting is proposed in this study. First, a clustering-based metric matching method is proposed. The multigranularity metric feature vector is extracted to unify the metric dimension while maximally retaining the information contained in the metrics. Then use metric clustering to eliminate metric redundancy and extract representative metrics through principal component analysis (PCA) to support one-to-one metric matching. This strategy not only solves the metric inconsistent and redundancy problem but also transforms the cross-company heterogeneous defect prediction problem into a homogeneous problem. Second, a sample weight setting method is proposed to transform the source data distribution. Wherein the statistical source sample frequency information is set as an impact factor to increase the weight of source samples that are more similar to the target samples, which improves the data distribution similarity between the source and target projects, thereby building a more accurate prediction model. Finally, after the above two-step processing, some classical machine learning methods are applied to build the prediction model, and 12 project datasets in NASA and PROMISE are used for performance comparison. Experimental results prove that the proposed method has superior prediction performance over other mainstream CCDP methods.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {19}
}

@article{10.1016/j.engappai.2021.104504,
author = {Vaish, Rachna and Dwivedi, U.D. and Tewari, Saurabh and Tripathi, S.M.},
title = {Machine learning applications in power system fault diagnosis: Research advancements and perspectives},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {106},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2021.104504},
doi = {10.1016/j.engappai.2021.104504},
journal = {Eng. Appl. Artif. Intell.},
month = nov,
numpages = {33},
keywords = {Unsupervised learning, Transfer learning, Supervised learning, Reinforcement learning, Machine learning (ML)}
}

@inproceedings{10.1007/978-3-030-30952-7_16,
author = {Liu, Xinyue and Li, Yanhui},
title = {Is Bigger Data Better for Defect Prediction: Examining the Impact of Data Size on Supervised and Unsupervised Defect Prediction},
year = {2019},
isbn = {978-3-030-30951-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30952-7_16},
doi = {10.1007/978-3-030-30952-7_16},
abstract = {Defect prediction could help software practitioners to predict the future occurrence of bugs in the software code regions. In order to improve the accuracy of defect prediction, dozens of supervised and unsupervised methods have been put forward and achieved good results in this field. One limiting factor of defect prediction is that the data size of defect data is not big, which restricts the scope of application with defect prediction models. In this study, we try to construct bigger defect datasets by merging available datasets with the same measurement dimension and check whether bigger data will bring better defect prediction performance with supervised and unsupervised models or not. The results of our experiment reveal that larger-scale dataset doesn’t bring improvements of both supervised and unsupervised classifiers.},
booktitle = {Web Information Systems and Applications: 16th International Conference, WISA 2019, Qingdao, China, September 20-22, 2019, Proceedings},
pages = {138–150},
numpages = {13},
keywords = {Defect prediction, Supervised, Classifier, Data size},
location = {Qingdao, China}
}

@inproceedings{10.1109/QSIC.2012.19,
author = {Wang, Jun and Shen, Beijun and Chen, Yuting},
title = {Compressed C4.5 Models for Software Defect Prediction},
year = {2012},
isbn = {9780769548333},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QSIC.2012.19},
doi = {10.1109/QSIC.2012.19},
abstract = {Defects in every software must be handled properly, and the number of defects directly reflects the quality of a software. In recent years, researchers have applied data mining and machine learning methods to predicting software defects. However, in their studies, the method in which the machine learning models are directly adopted may not be precise enough. Optimizing the machine learning models used in defects prediction will improve the prediction accuracy. In this paper, aiming at the characteristics of the metrics mined from the open source software, we proposed three new defect prediction models based on C4.5 model. The new models introduce the Spearman's rank correlation coefficient to the basis of choosing root node of the decision tree which makes the models better on defects prediction. In order to verify the effectiveness of the improved models, an experimental scheme is designed. In the experiment, we compared the prediction accuracies of the existing models and the improved models and the result showed that the improved models reduced the size of the decision tree by 49.91% on average and increased the prediction accuracy by 4.58% and 4.87% on two modules used in the experiment.},
booktitle = {Proceedings of the 2012 12th International Conference on Quality Software},
pages = {13–16},
numpages = {4},
keywords = {Software Repository, Defect Prediction, Decision Tree Learner, Data Mining},
series = {QSIC '12}
}

@article{10.1007/s00521-021-05811-3,
author = {Mehta, Sweta and Patnaik, K. Sridhar},
title = {Improved prediction of software defects using ensemble machine learning techniques},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05811-3},
doi = {10.1007/s00521-021-05811-3},
abstract = {Software testing process is a crucial part in software development. Generally the errors made by developers get fixed at a later stage of the software development process. This increases the impact of the defect. To prevent this, defects need to be predicted during the initial days of the software development, which in turn helps in efficient utilization of the testing resources. Defect prediction process involves classification of software modules into defect prone and non-defect prone. This paper aims to reduce the impact of two major issues faced during defect prediction, i.e., data imbalance and high dimensionality of the defect datasets. In this research work, various software metrics are evaluated using feature selection techniques such as Recursive Feature Elimination (RFE), Correlation-based feature selection, Lasso, Ridge, ElasticNet and Boruta. Logistic Regression, Decision Trees, K-nearest neighbor, Support Vector Machines and Ensemble Learning are some of the algorithms in machine learning that have been used in combination with the feature extraction and feature selection techniques for classifying the modules in software as defect prone and non-defect prone. The proposed model uses combination of Partial Least Square (PLS) Regression and RFE for dimension reduction which is further combined with Synthetic Minority Oversampling Technique due to the imbalanced nature of the used datasets. It has been observed that XGBoost and Stacking Ensemble technique gave best results for all the datasets with defect prediction accuracy more than 0.9 as compared to algorithms used in the research work.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {10551–10562},
numpages = {12},
keywords = {Stacking ensemble classifier, XGBoost, Machine learning algorithms, Data imbalance, Dimension reduction, Defect prediction}
}

@article{10.1007/s10664-020-09878-9,
author = {Bangash, Abdul Ali and Sahar, Hareem and Hindle, Abram and Ali, Karim},
title = {On the time-based conclusion stability of cross-project defect prediction models},
year = {2020},
issue_date = {Nov 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09878-9},
doi = {10.1007/s10664-020-09878-9},
abstract = {Researchers in empirical software engineering often make claims based on observable data such as defect reports. Unfortunately, in many cases, these claims are generalized beyond the data sets that have been evaluated. Will the researcher’s conclusions hold a year from now for the same software projects? Perhaps not. Recent studies show that in the area of Software Analytics, conclusions over different data sets are usually inconsistent. In this article, we empirically investigate whether conclusions in the area of cross-project defect prediction truly exhibit stability throughout time or not. Our investigation applies a time-aware evaluation approach where models are trained only on the past, and evaluations are executed only on the future. Through this time-aware evaluation, we show that depending on which time period we evaluate defect predictors, their performance, in terms of F-Score, the area under the curve (AUC), and Mathews Correlation Coefficient (MCC), varies and their results are not consistent. The next release of a product, which is significantly different from its prior release, may drastically change defect prediction performance. Therefore, without knowing about the conclusion stability, empirical software engineering researchers should limit their claims of performance within the contexts of evaluation, because broad claims about defect prediction performance might be contradicted by the next upcoming release of a product under analysis.},
journal = {Empirical Softw. Engg.},
month = nov,
pages = {5047–5083},
numpages = {37},
keywords = {Time-aware evaluation, Defect prediction, Conclusion stability}
}

@inproceedings{10.1145/3183440.3183449,
author = {Eken, Beyza},
title = {Assessing personalized software defect predictors},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183449},
doi = {10.1145/3183440.3183449},
abstract = {Software defect prediction models guide developers and testers to identify defect prone software modules in fewer time and effort, compared to manual inspections of the source code. The state-of-the-art predictors on publicly available software engineering data could catch around 70% of the defects. While early studies mostly utilize static code properties of the software, recent studies incorporate the people factor into the prediction models, such as the number of developers that touched a code unit, the experience of the developer, and interaction and cognitive behaviors of developers. Those information could give a stronger clue about the defect-prone parts because they could explain defect injection patterns in software development. Personalization has been emerging in many other systems such as social platforms, web search engines such that people get customized recommendations based on their actions, profiles and interest. Following this point of view, customization in defect prediction with respect to each developer would increase predictions' accuracy and usefulness than traditional, general models. In this thesis, we focus on building a personalized defect prediction framework that gives instant feedback to the developer at change level, based on historical defect and change data. Our preliminary analysis of the personalized prediction models of 121 developers in six open source projects indicate that, a personalized approach is not always the best model when compared to general models built for six projects. Other factors such as project characteristics, developer's historical data, the context and frequency of contributions, and/or development methodologies might affect which model to consider in practice. Eventually, this topic is open to improvement with further empirical studies on each of these factors.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {488–491},
numpages = {4},
keywords = {bug prediction, customization, personalized defect prediction},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1002/smr.2172,
author = {Gong, Lina and Jiang, Shujuan and Jiang, Li},
title = {An improved transfer adaptive boosting approach for mixed‐project defect prediction},
year = {2019},
issue_date = {October 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {10},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2172},
doi = {10.1002/smr.2172},
abstract = {Software defect prediction (SDP) has been a very important research topic in software engineering, since it can provide high‐quality results when given sufficient historical data of the project. Unfortunately, there are not abundant data to bulid the defect prediction model at the beginning of a project. For this scenario, one possible solution is to use data from other projects in the same company. However, using these data practically would get poor performance because of different distributional characteristics among projects. Also, software has more non‐defective instances than defective instances that may cause a significant bias towards defective instances. Considering these two problems, we propose an improved transfer adaptive boosting (ITrAdaBoost) approach for being given a small number of labeled data in the testing project. In our approach, ITrAdaBoost can not only employ the Matthews correlation coefficient (MCC) as the measure instead of accuracy rate but also use the asymmetric misclassification costs for non‐defective and defective instances. Extensive experiments on 18 public projects from four datasets indicate that: (a) our approach significantly outperforms state‐of‐the‐art cross‐project defect prediction (CPDP) approaches, and (b) our approach can obtain comparable prediction performances in contrast with within project prediction results. Consequently, the proposed approach can build an effective prediction model with a small number of labeled instances for mixed‐project defect prediction (MPDP).For mixed‐project defect prediction, improved transfer adaptive boosting approach (ITrAdaBoost) can not only employ the Matthews correlation coefficient (MCC) as the measure instead of accuracy rate, but also use the asymmetric misclassification costs for nondefective and defective instances. Extensive experiments on 18 public projects from four datasets indicate that (a) our approach significantly outperforms state‐of‐the‐art cross‐project defect prediction (CPDP) approaches, and (b) our approach can obtain comparable prediction performances in contrast with within project prediction results.


image
image},
journal = {J. Softw. Evol. Process},
month = oct,
numpages = {23},
keywords = {transfer learning, software defect prediction, mixed‐project, cross‐project, class imbalance}
}

@article{10.1016/j.procs.2018.05.115,
author = {Singh, Ajmer and Bhatia, Rajesh and Singhrova, Anita},
title = {Taxonomy of machine learning algorithms in software fault prediction using object oriented metrics},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.115},
doi = {10.1016/j.procs.2018.05.115},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {993–1001},
numpages = {9},
keywords = {Software fault prediction, Object Oriented Testing, Object Oriented Coupling, software faults prediction, machine learning}
}

@article{10.1016/j.is.2015.02.006,
author = {Siers, Michael J. and Islam, Md Zahidul},
title = {Software defect prediction using a cost sensitive decision forest and voting, and a potential solution to the class imbalance problem},
year = {2015},
issue_date = {July 2015},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {51},
number = {C},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2015.02.006},
doi = {10.1016/j.is.2015.02.006},
abstract = {Software development projects inevitably accumulate defects throughout the development process. Due to the high cost that defects can incur, careful consideration is crucial when predicting which sections of code are likely to contain defects. Classification algorithms used in machine learning can be used to create classifiers which can be used to predict defects. While traditional classification algorithms optimize for accuracy, cost-sensitive classification methods attempt to make predictions which incur the lowest classification cost. In this paper we propose a cost-sensitive classification technique called CSForest which is an ensemble of decision trees. We also propose a cost-sensitive voting technique called CSVoting in order to take advantage of the set of decision trees in minimizing the classification cost. We then investigate a potential solution to class imbalance within our decision forest algorithm. We empirically evaluate the proposed techniques comparing them with six (6) classifier algorithms on six (6) publicly available clean datasets that are commonly used in the research on software defect prediction. Our initial experimental results indicate a clear superiority of the proposed techniques over the existing ones. Author-HighlightsSDP is short for Software Defect Prediction.We show that there is not a clear winner in the studied existing methods for SDP*.A cost-sensitive decision forest and voting technique are proposed.The superiority of the proposed techniques is shown.A proposed framework for the forest algorithm for handling class imbalance.},
journal = {Inf. Syst.},
month = jul,
pages = {62–71},
numpages = {10},
keywords = {Software defect prediction, Forest voting, Decision forest, Cost-sensitive, Class imbalance}
}

@inproceedings{10.1109/RAISE.2019.00016,
author = {Humphreys, Jack and Dam, Hoa Khanh},
title = {An explainable deep model for defect prediction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/RAISE.2019.00016},
doi = {10.1109/RAISE.2019.00016},
abstract = {Self attention transformer encoders represent an effective method for sequence to class prediction tasks as they can disentangle long distance dependencies and have many regularising effects. We achieve results substantially better than state of the art in one such task, namely, defect prediction and with many added benefits. Existing techniques do not normalise for correlations that are inversely proportional to the usefulness of the prediction but do, in fact, go further, specifically exploiting these features which is tantamount to data leakage. Our model is end-to-end trainable and has the potential capability to explain its prediction. This explainability provides insights and potential causes of a model's decisions, the absence of which has stopped defect prediction from gaining any traction in industry.},
booktitle = {Proceedings of the 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
pages = {49–55},
numpages = {7},
keywords = {defect prediction, deep learning},
location = {Montreal, Quebec, Canada},
series = {RAISE '19}
}

@article{10.1007/s11219-021-09553-2,
author = {Wu, Jie and Wu , Yingbo and Niu, Nan and Zhou, Min},
title = {MHCPDP: multi-source heterogeneous cross-project defect prediction via multi-source transfer learning and autoencoder},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-021-09553-2},
doi = {10.1007/s11219-021-09553-2},
abstract = {Heterogeneous cross-project defect prediction (HCPDP) is aimed at building a defect prediction model for the target project by reusing datasets from source projects, where the source project datasets and target project dataset have different features. Most existing HCPDP methods only remove redundant or unrelated features without exploring the underlying features of cross-project datasets. Additionally, when the&nbsp;transfer learning method is used in HCPDP, these methods ignore the negative effect of transfer learning. In this paper, we propose a novel HCPDP method called multi-source heterogeneous cross-project defect prediction (MHCPDP). To reduce the gap between the target datasets and the source datasets, MHCPDP uses the autoencoder to extract the intermediate features from the original datasets instead of simply removing redundant and unrelated features and adopts a modified autoencoder algorithm to make instance selection for eliminating irrelevant instances from the source domain datasets. Furthermore, by incorporating multiple source projects to increase the number of source datasets, MHCPDP develops a multi-source transfer learning algorithm to reduce the impact of negative transfers and upgrade the performance of the classifier. We comprehensively evaluate MHCPDP on five open source datasets; our experimental results show that MHCPDP not only has significant improvement in two performance metrics but also overcomes the shortcomings of the conventional HCPDP methods.},
journal = {Software Quality Journal},
month = jun,
pages = {405–430},
numpages = {26},
keywords = {Modified autoencoder, Multi-source transfer learning, Heterogeneous cross-project defect prediction, Autoencoder}
}

@article{10.1016/j.eswa.2009.12.056,
author = {Zheng, Jun},
title = {Cost-sensitive boosting neural networks for software defect prediction},
year = {2010},
issue_date = {June, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {6},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2009.12.056},
doi = {10.1016/j.eswa.2009.12.056},
abstract = {Software defect predictors which classify the software modules into defect-prone and not-defect-prone classes are effective tools to maintain the high quality of software products. The early prediction of defect-proneness of the modules can allow software developers to allocate the limited resources on those defect-prone modules such that high quality software can be produced on time and within budget. In the process of software defect prediction, the misclassification of defect-prone modules generally incurs much higher cost than the misclassification of not-defect-prone ones. Most of the previously developed predication models do not consider this cost issue. In this paper, three cost-sensitive boosting algorithms are studied to boost neural networks for software defect prediction. The first algorithm based on threshold-moving tries to move the classification threshold towards the not-fault-prone modules such that more fault-prone modules can be classified correctly. The other two weight-updating based algorithms incorporate the misclassification costs into the weight-update rule of boosting procedure such that the algorithms boost more weights on the samples associated with misclassified defect-prone modules. The performances of the three algorithms are evaluated by using four datasets from NASA projects in terms of a singular measure, the Normalized Expected Cost of Misclassification (NECM). The experimental results suggest that threshold-moving is the best choice to build cost-sensitive software defect prediction models with boosted neural networks among the three algorithms studied, especially for the datasets from projects developed by object-oriented language.},
journal = {Expert Syst. Appl.},
month = jun,
pages = {4537–4543},
numpages = {7},
keywords = {Software defect, Neural networks, Cost-sensitive, Adaboost}
}

@article{10.1007/s00521-019-04651-6,
author = {Dib, M. A. and Oliveira, N. J. and Marques, A. E. and Oliveira, M. C. and Fernandes, J. V. and Ribeiro, B. M. and Prates, P. A.},
title = {Single and ensemble classifiers for defect prediction in sheet metal forming under variability},
year = {2020},
issue_date = {Aug 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-019-04651-6},
doi = {10.1007/s00521-019-04651-6},
abstract = {This paper presents an approach, based on machine learning techniques, to predict the occurrence of defects in sheet metal forming processes, exposed to sources of scatter in the material properties and process parameters. An empirical analysis of performance of ML techniques is presented, considering both single learning and ensemble models. These are trained using data sets populated with numerical simulation results of two sheet metal forming processes: U-Channel and Square Cup. Data sets were built for three distinct steel sheets. A total of eleven input features, related to the mechanical properties, sheet thickness and process parameters, were considered; also, two types of defects (outputs) were analysed for each process. The sampling data were generated, assuming that the variability of each input feature is described by a normal distribution. For a given type of defect, most single classifiers show similar performances, regardless of the material. When comparing single learning and ensemble models, the latter can provide an efficient alternative. The fact that ensemble predictive models present relatively high performances, combined with the possibility of reconciling model bias and variance, offer a promising direction for its application in industrial environment.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {12335–12349},
numpages = {15},
keywords = {Sheet metal forming, Defect prediction, Ensemble learning, Machine learning}
}

@inproceedings{10.1145/3412841.3442019,
author = {Zhao, Kunsong and Xu, Zhou and Yan, Meng and Tang, Yutian and Fan, Ming and Catolino, Gemma},
title = {Just-in-time defect prediction for Android apps via imbalanced deep learning model},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442019},
doi = {10.1145/3412841.3442019},
abstract = {Android mobile apps have played important roles in our daily life and work. To meet new requirements from users, the mobile apps encounter frequent updates, which involves in a large quantity of code commits. Previous studies proposed to apply Just-in-Time (JIT) defect prediction for mobile apps to timely identify whether new code commits can introduce defects into apps, aiming to assure the quality of mobile apps. In general, the number of defective commit instances is much fewer than that of clean ones, in other words, the defect data is class imbalanced. In this work, we propose a novel Imbalanced Deep Learning model, called IDL, to conduct JIT defect prediction task for Android mobile apps. More specifically, we introduce a state-of-the-art cost-sensitive cross-entropy loss function into the deep neural network to learn the high-level feature representation, in which the loss function alleviates the class imbalance issue by taking the prior probability of the two types of classes into account. We conduct experiments on a benchmark defect data consisting of 12 Android mobile apps. The results of rigorous experiments show that our proposed IDL model performs significantly better than 23 comparative imbalanced learning methods in terms of Matthews correlation coefficient performance indicator.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1447–1454},
numpages = {8},
keywords = {JIT defect prediction, imbalanced learning, mobile apps},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@article{10.1504/IJISTA.2016.076102,
author = {Rong, Xiaotao and Li, Feixiang and Cui, Zhihua},
title = {A model for software defect prediction using support vector machine based on CBA},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {15},
number = {1},
issn = {1740-8865},
url = {https://doi.org/10.1504/IJISTA.2016.076102},
doi = {10.1504/IJISTA.2016.076102},
abstract = {Software defection prediction is not only crucial for improving software quality, but also helpful for software test effort estimation. As is well-known, 80% of the fault happens in 20% of the modules. Therefore, we need to find out the most error prone modules accurately and correct them in time to save time, money, and energy. Support vector machine SVM is an advanced classification method that fits the defection classification. However, studies show that, the value of parameters of SVM model has a remarkable influence on its classification accuracy and the selection process lacks theory guidance that makes the SVM model uncertainty and low efficiency. In this paper, a CBA-SVM software defect prediction model is proposed, which take advantage of the non-linear computing ability of SVM model and optimisation capacity of bat algorithm with centroid strategy CBA. Through the experimental comparison with other models, CBA-SVM is proved to have a higher accuracy.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = apr,
pages = {19–34},
numpages = {16}
}

@article{10.1049/sfw2.12053,
author = {Huang, Qingan and Ma, Le and Jiang, Siyu and Wu, Guobin and Song, Hengjie and Jiang, Libiao and Zheng, Chunyun},
title = {A cross‐project defect prediction method based on multi‐adaptation and nuclear norm},
year = {2021},
issue_date = {April 2022},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {16},
number = {2},
url = {https://doi.org/10.1049/sfw2.12053},
doi = {10.1049/sfw2.12053},
abstract = {Cross‐project defect prediction (CPDP) is an important research direction in software defect prediction. Traditional CPDP methods based on hand‐crafted features ignore the semantic information in the source code. Existing CPDP methods based on the&nbsp;deep learning model may not fully consider the differences among projects. Additionally, these methods may not accurately classify the samples near the classification boundary. To solve these problems, the authors propose a model based on multi‐adaptation and nuclear norm (MANN) to deal with samples in projects. The feature of samples were embedded into the multi‐core Hilbert space for distribution and the multi‐kernel maximum mean discrepancy method was utilised to reduce differences among projects. More importantly, the nuclear norm module was constructed, which improved the discriminability and diversity of the target sample by calculating and maximizing the nuclear norm of the target sample in the process of domain adaptation, thus improving the performance of MANN. Finally, extensive experiments were conducted on 11 sizeable open‐source projects. The results indicate&nbsp;that the proposed method exceeds the state of the art under the widely used metrics.},
journal = {IET Software},
month = dec,
pages = {200–213},
numpages = {14},
keywords = {unsupervised learning, software reliability, software quality, neural nets}
}

@inproceedings{10.1145/2601248.2601294,
author = {Rodriguez, Daniel and Herraiz, Israel and Harrison, Rachel and Dolado, Javier and Riquelme, Jos\'{e} C.},
title = {Preliminary comparison of techniques for dealing with imbalance in software defect prediction},
year = {2014},
isbn = {9781450324762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2601248.2601294},
doi = {10.1145/2601248.2601294},
abstract = {Imbalanced data is a common problem in data mining when dealing with classification problems, where samples of a class vastly outnumber other classes. In this situation, many data mining algorithms generate poor models as they try to optimize the overall accuracy and perform badly in classes with very few samples. Software Engineering data in general and defect prediction datasets are not an exception and in this paper, we compare different approaches, namely sampling, cost-sensitive, ensemble and hybrid approaches to the problem of defect prediction with different datasets preprocessed differently. We have used the well-known NASA datasets curated by Shepperd et al. There are differences in the results depending on the characteristics of the dataset and the evaluation metrics, especially if duplicates and inconsistencies are removed as a preprocessing step.Further Results and replication package: http://www.cc.uah.es/drg/ease14},
booktitle = {Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {43},
numpages = {10},
keywords = {imbalanced data, defect prediction, data quality},
location = {London, England, United Kingdom},
series = {EASE '14}
}

@article{10.3233/JIFS-179459,
author = {Bashir, Kamal and Li, Tianrui and Yohannese, Chubato Wondaferaw and Yahaya, Mahama and Kahraman, Cengiz},
title = {SMOTEFRIS-INFFC: Handling the challenge of borderline and noisy examples in imbalanced learning for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {38},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-179459},
doi = {10.3233/JIFS-179459},
abstract = {The object of Software Defect Prediction (SDP) is to identify modules that are prone to defect. This is achieved by training prediction models with datasets obtained by mining software historical depositories. When one acquires data through this approach, it often includes class imbalance which has an unequal class representation among their example. We hypothesize that the imbalance learning is not a problem in itself and decrease in performance is also influenced by other factors related to class distribution in the data. One of these is the existence of noisy and borderline examples. Thus, the objective of our research is to propose a novel preprocessing method using Synthetic Minority Over-Sampling Technique (SMOTE), Fuzzy-rough Instance Selection type II (FRIS-II) and Iterative Noise Filter based on the Fusion of Classifiers (INFFC) which can overcome these problems. The experimental results show that the new proposal significantly outperformed all the methods compared in this study.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {917–933},
numpages = {17},
keywords = {noise filtering, fuzzy rough set, data sampling, Software defect prediction}
}

@article{10.1007/s11704-017-6015-y,
author = {Zhang, Yun and Lo, David and Xia, Xin and Sun, Jianling},
title = {Combined classifier for cross-project defect prediction: an extended empirical study},
year = {2018},
issue_date = {April     2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {12},
number = {2},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-017-6015-y},
doi = {10.1007/s11704-017-6015-y},
abstract = {To facilitate developers in effective allocation of their testing and debugging efforts, many software defect prediction techniques have been proposed in the literature. These techniques can be used to predict classes that are more likely to be buggy based on the past history of classes, methods, or certain other code elements. These techniques are effective provided that a sufficient amount of data is available to train a prediction model. However, sufficient training data are rarely available for new software projects. To resolve this problem, cross-project defect prediction, which transfers a prediction model trained using data from one project to another, was proposed and is regarded as a new challenge in the area of defect prediction. Thus far, only a few cross-project defect prediction techniques have been proposed. To advance the state of the art, in this study, we investigated seven composite algorithms that integrate multiple machine learning classifiers to improve cross-project defect prediction. To evaluate the performance of the composite algorithms, we performed experiments on 10 open-source software systems from the PROMISE repository, which contain a total of 5,305 instances labeled as defective or clean. We compared the composite algorithms with the combined defect predictor where logistic regression is used as the meta classification algorithm (CODEPLogistic), which is the most recent cross-project defect prediction algorithm in terms of two standard evaluation metrics: cost effectiveness and F-measure. Our experimental results show that several algorithms outperform CODEPLogistic: Maximum voting shows the best performance in terms of F-measure and its average F-measure is superior to that of CODEPLogistic by 36.88%. Bootstrap aggregation (BaggingJ48) shows the best performance in terms of cost effectiveness and its average cost effectiveness is superior to that of CODEPLogistic by 15.34%.},
journal = {Front. Comput. Sci.},
month = apr,
pages = {280–296},
numpages = {17},
keywords = {defect prediction, cross-project, classifier combination}
}

@inproceedings{10.1007/978-3-030-87007-2_28,
author = {Kumar, Lov and Dastidar, Triyasha Ghosh and Murthy Neti, Lalitha Bhanu and Satapathy, Shashank Mouli and Misra, Sanjay and Kocher, Vipul and Padmanabhuni, Srinivas},
title = {Deep-Learning Approach with DeepXplore for Software Defect Severity Level Prediction},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_28},
doi = {10.1007/978-3-030-87007-2_28},
abstract = {Fixing the defects of earlier releases and working on fast and efficient fixing of those software defects is detrimental for the release of further versions. Bug tracking systems like Bugzilla get thousands of software defect reports every day. Manually handling those report to assign severity to the defects is not feasible. Earlier traditional Machine Learning methods have been used to predict the severity level from the defect description. This paper presents different deep learning models to predict defect severity level. Furthermore, the deep neural network was tested using a framework developed similar to that DeepXplore. Different word-embedding techniques, feature-selection techniques, sampling techniques and deep learning models are analyzed and compared for this study. In this paper, we have considered Descriptive statistics, Box-plot, and Significant tests to compare the developed models for defect severity level prediction. The three performance metrics used for testing the models are AUC, Accuracy and Neuron Coverage. This is a preliminary study on DNN testing on this dataset. Thus, the paper focuses on DeepXplore DNN testing technique. However further studies would be undertaken on comparative analysis of different DNN testing techniques on this dataset.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {398–410},
numpages = {13},
keywords = {Word embedding, Deep learning, Feature selection, Imbalance handling, Severity prediction},
location = {Cagliari, Italy}
}

@article{10.1007/s10796-013-9430-0,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan and Napolitano, Amri and Wald, Randall},
title = {A comparative study of iterative and non-iterative feature selection techniques for software defect prediction},
year = {2014},
issue_date = {November  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {5},
issn = {1387-3326},
url = {https://doi.org/10.1007/s10796-013-9430-0},
doi = {10.1007/s10796-013-9430-0},
abstract = {Two important problems which can affect the performance of classification models are high-dimensionality (an overabundance of independent features in the dataset) and imbalanced data (a skewed class distribution which creates at least one class with many fewer instances than other classes). To resolve these problems concurrently, we propose an iterative feature selection approach, which repeated applies data sampling (in order to address class imbalance) followed by feature selection (in order to address high-dimensionality), and finally we perform an aggregation step which combines the ranked feature lists from the separate iterations of sampling. This approach is designed to find a ranked feature list which is particularly effective on the more balanced dataset resulting from sampling while minimizing the risk of losing data through the sampling step and missing important features. To demonstrate this technique, we employ 18 different feature selection algorithms and Random Undersampling with two post-sampling class distributions. We also investigate the use of sampling and feature selection without the iterative step (e.g., using the ranked list from a single iteration, rather than combining the lists from multiple iterations), and compare these results from the version which uses iteration. Our study is carried out using three groups of datasets with different levels of class balance, all of which were collected from a real-world software system. All of our experiments use four different learners and one feature subset size. We find that our proposed iterative feature selection approach outperforms the non-iterative approach.},
journal = {Information Systems Frontiers},
month = nov,
pages = {801–822},
numpages = {22},
keywords = {Software defect prediction, Iterative feature selection, High dimensionality, Date sampling, Class imbalance}
}

@inproceedings{10.1145/3449365.3449384,
author = {Malhotra, Ruchika and Budhiraja, Anmol and Kumar Singh, Abhinav and Ghoshal, Ishani},
title = {A Novel Feature Selection Approach based on Binary Particle Swarm Optimization and Ensemble Learning for Heterogeneous Defect Prediction},
year = {2021},
isbn = {9781450388108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449365.3449384},
doi = {10.1145/3449365.3449384},
abstract = {Software defect prediction is an integral part of the software development process. Defect prediction helps focus on the grey areas beforehand, thus saving the considerable amount of money that is otherwise wasted in finding and fixing the faults once the software is already in production. One of the popular areas of defect prediction in recent years is Heterogeneous Defect Prediction, which predicts defects in a target project using a source project with different metrics. Through our paper, we provide a novel feature selection based approach, En-BPSO, based on binary particle swarm optimization, coupled with majority voting ensemble classifier based fitness function for heterogeneous defect prediction. The datasets we are using are MORPH and SOFTLAB. The results show that the En-BPSO method provides the highest Friedman mean rank amongst all the feature selection methods used for comparison. En-BPSO technique also helps us dynamically determine the optimal number of features to build an accurate heterogeneous defect prediction model.},
booktitle = {Proceedings of the 2021 3rd Asia Pacific Information Technology Conference},
pages = {115–121},
numpages = {7},
keywords = {Heterogeneous Metrics, Feature Selection, Ensemble Learning, Defect Prediction, Binary Particle Swarm Optimization},
location = {Bangkok, Thailand},
series = {APIT '21}
}

@inproceedings{10.1109/MSR.2017.46,
author = {Madeyski, Lech and Kawalerowicz, Marcin},
title = {Continuous defect prediction: the idea and a related dataset},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.46},
doi = {10.1109/MSR.2017.46},
abstract = {We would like to present the idea of our Continuous Defect Prediction (CDP) research and a related dataset that we created and share. Our dataset is currently a set of more than 11 million data rows, representing files involved in Continuous Integration (CI) builds, that synthesize the results of CI builds with data we mine from software repositories. Our dataset embraces 1265 software projects, 30,022 distinct commit authors and several software process metrics that in earlier research appeared to be useful in software defect prediction. In this particular dataset we use TravisTorrent as the source of CI data. TravisTorrent synthesizes commit level information from the Travis CI server and GitHub open-source projects repositories. We extend this data to a file change level and calculate the software process metrics that may be used, for example, as features to predict risky software changes that could break the build if committed to a repository with CI enabled.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {515–518},
numpages = {4},
keywords = {software repository, open science, mining software repositories, defect prediction, continuous defect prediction},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1007/978-3-030-31726-3_42,
author = {Li, Juanjuan and Jing, Xiao-Yuan and Wu, Fei and Sun, Ying and Yang, Yongguang},
title = {A Cost-Sensitive Shared Hidden Layer Autoencoder for Cross-Project Defect Prediction},
year = {2019},
isbn = {978-3-030-31725-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31726-3_42},
doi = {10.1007/978-3-030-31726-3_42},
abstract = {Cross-project defect prediction means training a classifier model using the historical data of the other source project, and then testing whether the target project instance is defective or not. Since source and target projects have different data distributions, and data distribution difference will degrade the performance of classifier. Furthermore, the class imbalance of datasets increases the difficulty of classification. Therefore, a cost-sensitive shared hidden layer autoencoder (CSSHLA) method is proposed. CSSHLA learns a common feature representation between source and target projects by shared hidden layer autoencoder, and makes the different data distributions more similar. To solve the class imbalance problem, CSSHLA introduces a cost-sensitive factor to assign different importance weights to different instances. Experiments on 10 projects of PROMISE dataset show that CSSHLA improves the performance of cross-project defect prediction compared with baselines.},
booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part III},
pages = {491–502},
numpages = {12},
keywords = {Cross-project software defect prediction, Cost-sensitive learning, Shared hidden layer autoencoder},
location = {Xi'an, China}
}

@inproceedings{10.1109/ICMLA.2012.145,
author = {Gao, Kehan and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {A Hybrid Approach to Coping with High Dimensionality and Class Imbalance for Software Defect Prediction},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.145},
doi = {10.1109/ICMLA.2012.145},
abstract = {High dimensionality and class imbalance are the two main problems affecting many software defect prediction. In this paper, we propose a new technique, named SelectRUSBoost, which is a form of ensemble learning that in-corporates data sampling to alleviate class imbalance and feature selection to resolve high dimensionality. To evaluate the effectiveness of the new technique, we apply it to a group of datasets in the context of software defect prediction. We employ two classification learners and six feature selection techniques. We compare the technique to the approach where feature selection and data sampling are used together, as well as the case where feature selection is used alone (no sampling used at all). The experimental results demonstrate that the SelectRUSBoost technique is more effective in improving classification performance compared to the other approaches.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 02},
pages = {281–288},
numpages = {8},
keywords = {software defect prediction, high dimensionality, class imbalance},
series = {ICMLA '12}
}

@inproceedings{10.1109/ESEM.2017.48,
author = {Yan, Meng and Fang, Yicheng and Lo, David and Xia, Xin and Zhang, Xiaohong},
title = {File-level defect prediction: unsupervised vs. supervised models},
year = {2017},
isbn = {9781509040391},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ESEM.2017.48},
doi = {10.1109/ESEM.2017.48},
abstract = {Background: Software defect models can help software quality assurance teams to allocate testing or code review resources. A variety of techniques have been used to build defect prediction models, including supervised and unsupervised methods. Recently, Yang et al. [1] surprisingly find that unsupervised models can perform statistically significantly better than supervised models in effort-aware change-level defect prediction. However, little is known about relative performance of unsupervised and supervised models for effort-aware file-level defect prediction. Goal: Inspired by their work, we aim to investigate whether a similar finding holds in effort-aware file-level defect prediction. Method: We replicate Yang et al.'s study on PROMISE dataset with totally ten projects. We compare the effectiveness of unsupervised and supervised prediction models for effort-aware file-level defect prediction. Results: We find that the conclusion of Yang et al. [1] does not hold under within-project but holds under cross-project setting for file-level defect prediction. In addition, following the recommendations given by the best unsupervised model, developers needs to inspect statistically significantly more files than that of supervised models considering the same inspection effort (i.e., LOC). Conclusions: (a) Unsupervised models do not perform statistically significantly better than state-of-art supervised model under within-project setting, (b) Unsupervised models can perform statistically significantly better than state-of-art supervised model under cross-project setting, (c) We suggest that not only LOC but also number of files needed to be inspected should be considered when evaluating effort-aware file-level defect prediction models.},
booktitle = {Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {344–353},
numpages = {10},
keywords = {replication study, inspection effort, effort-aware defect prediction},
location = {Markham, Ontario, Canada},
series = {ESEM '17}
}

@article{10.1007/s10664-018-9679-5,
author = {Kondo, Masanari and Bezemer, Cor-Paul and Kamei, Yasutaka and Hassan, Ahmed E. and Mizuno, Osamu},
title = {The impact of feature reduction techniques on defect prediction models},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9679-5},
doi = {10.1007/s10664-018-9679-5},
abstract = {Defect prediction is an important task for preserving software quality. Most prior work on defect prediction uses software features, such as the number of lines of code, to predict whether a file or commit will be defective in the future. There are several reasons to keep the number of features that are used in a defect prediction model small. For example, using a small number of features avoids the problem of multicollinearity and the so-called `curse of dimensionality'. Feature selection and reduction techniques can help to reduce the number of features in a model. Feature selection techniques reduce the number of features in a model by selecting the most important ones, while feature reduction techniques reduce the number of features by creating new, combined features from the original features. Several recent studies have investigated the impact of feature selection techniques on defect prediction. However, there do not exist large-scale studies in which the impact of multiple feature reduction techniques on defect prediction is investigated. In this paper, we study the impact of eight feature reduction techniques on the performance and the variance in performance of five supervised learning and five unsupervised defect prediction models. In addition, we compare the impact of the studied feature reduction techniques with the impact of the two best-performing feature selection techniques (according to prior work). The following findings are the highlights of our study: (1) The studied correlation and consistency-based feature selection techniques result in the best-performing supervised defect prediction models, while feature reduction techniques using neural network-based techniques (restricted Boltzmann machine and autoencoder) result in the best-performing unsupervised defect prediction models. In both cases, the defect prediction models that use the selected/generated features perform better than those that use the original features (in terms of AUC and performance variance). (2) Neural network-based feature reduction techniques generate features that have a small variance across both supervised and unsupervised defect prediction models. Hence, we recommend that practitioners who do not wish to choose a best-performing defect prediction model for their data use a neural network-based feature reduction technique.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1925–1963},
numpages = {39},
keywords = {Restricted Boltzmann machine, Neural network, Feature selection, Feature reduction, Defect prediction}
}

@inproceedings{10.1145/3345629.3351449,
author = {Jahanshahi, Hadi and Jothimani, Dhanya and Ba\c{s}ar, Ay\c{s}e and Cevik, Mucahit},
title = {Does chronology matter in JIT defect prediction? A Partial Replication Study},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3351449},
doi = {10.1145/3345629.3351449},
abstract = {BACKGROUND: Just-In-Time (JIT) models, unlike the traditional defect prediction models, detect the fix-inducing changes (or defect inducing changes). These models are designed based on the assumption that past code change properties are similar to future ones. However, as the system evolves, the expertise of developers and/or the complexity of the system also change.AIM: In this work, we aim to investigate the effect of code change properties on JIT models over time. We also study the impact of using recent data as well as all available data on the performance of JIT models. Further, we analyze the effect of weighted sampling on the performance of fix-inducing properties of JIT models. For this purpose, we used datasets from four open-source projects, namely Eclipse JDT, Mozilla, Eclipse Platform, and PostgreSQL.METHOD: We used five families of change code properties such as size, diffusion, history, experience, and purpose. We used Random Forest to train and test the JIT model and Brier Score (BS) and Area Under Curve (AUC) for performance measurement. We applied the Wilcoxon Signed Rank Test on the output to statistically validate whether the performance of JIT models improves using all the available data or the recent data.RESULTS: Our paper suggest that the predictive power of JIT models does not change by time. Furthermore, we observed that the chronology of data in JIT defect prediction models can be discarded by considering all the available data. On the other hand, the importance score of families of code change properties is found to oscillate over time.CONCLUSION: To mitigate the impact of the evolution of code change properties, it is recommended to use weighted sampling approach in which more emphasis is placed upon the changes occurring closer to the current time. Moreover, since properties such as "Expertise of the Developer" and "Size" evolve with the time, the models obtained from old data may exhibit different characteristics compared to those employing the newer dataset. Hence, practitioners should constantly retrain JIT models to include fresh data.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {90–99},
numpages = {10},
keywords = {Just-In-Time prediction, defect prediction, quality assurance, software engineering},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1145/2786805.2786814,
author = {Nam, Jaechang and Kim, Sunghun},
title = {Heterogeneous defect prediction},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786814},
doi = {10.1145/2786805.2786814},
abstract = {Software defect prediction is one of the most active research areas in software engineering. We can build a prediction model with defect data collected from a software project and predict defects in the same project, i.e. within-project defect prediction (WPDP). Researchers also proposed cross-project defect prediction (CPDP) to predict defects for new projects lacking in defect data by using prediction models built by other projects. In recent studies, CPDP is proved to be feasible. However, CPDP requires projects that have the same metric set, meaning the metric sets should be identical between projects. As a result, current techniques for CPDP are difficult to apply across projects with heterogeneous metric sets. To address the limitation, we propose heterogeneous defect prediction (HDP) to predict defects across projects with heterogeneous metric sets. Our HDP approach conducts metric selection and metric matching to build a prediction model between projects with heterogeneous metric sets. Our empirical study on 28 subjects shows that about 68% of predictions using our approach outperform or are comparable to WPDP with statistical significance.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {508–519},
numpages = {12},
keywords = {quality assurance, heterogeneous metrics, Defect prediction},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@article{10.1016/j.asoc.2016.05.038,
author = {Serdar Bier, M. and Diri, Banu},
title = {Defect prediction for Cascading Style Sheets},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.05.038},
doi = {10.1016/j.asoc.2016.05.038},
abstract = {Graphical abstractDisplay Omitted Testing is a crucial activity in software development. However exhaustive testing of a given software is impossible in practice because projects have serious time and budget limitations. Therefore, software testing teams need guidance about which modules they should focus on. Defect prediction techniques are useful for this situation because they let testers to identify and focus on defect prone parts of software. These techniques are essential for software teams, because they help teams to efficiently allocate their precious resources in testing phase. Software defect prediction has been an active research area in recent years. Researchers in this field have been using different types of metrics in their prediction models. However, value of extracting static code metrics for style sheet languages has been ignored until now. User experience is a very important part of web applications and its mostly provided using Cascading Style Sheets (CSS). In this research, our aim is to improve defect prediction performance for web applications by utilizing metrics generated from CSS code. We generated datasets from four open source web applications to conduct our experiments. Defect prediction is then performed using three different well-known machine learning algorithms. The results revealed that static code metrics based defect prediction techniques can be performed effectively to improve quality of CSS code in web applications. Therefore we recommend utilizing domain-specific characteristics of applications in defect prediction as they result in significantly high prediction performance with low costs.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1078–1084},
numpages = {7},
keywords = {Web sites, Software quality, Software Metrics, Defect prediction}
}

@inproceedings{10.1145/3377811.3380360,
author = {Li, Ke and Xiang, Zilin and Chen, Tao and Wang, Shuo and Tan, Kay Chen},
title = {Understanding the automated parameter optimization on transfer learning for cross-project defect prediction: an empirical study},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380360},
doi = {10.1145/3377811.3380360},
abstract = {Data-driven defect prediction has become increasingly important in software engineering process. Since it is not uncommon that data from a software project is insufficient for training a reliable defect prediction model, transfer learning that borrows data/konwledge from other projects to facilitate the model building at the current project, namely cross-project defect prediction (CPDP), is naturally plausible. Most CPDP techniques involve two major steps, i.e., transfer learning and classification, each of which has at least one parameter to be tuned to achieve their optimal performance. This practice fits well with the purpose of automated parameter optimization. However, there is a lack of thorough understanding about what are the impacts of automated parameter optimization on various CPDP techniques. In this paper, we present the first empirical study that looks into such impacts on 62 CPDP techniques, 13 of which are chosen from the existing CPDP literature while the other 49 ones have not been explored before. We build defect prediction models over 20 real-world software projects that are of different scales and characteristics. Our findings demonstrate that: (1) Automated parameter optimization substantially improves the defect prediction performance of 77% CPDP techniques with a manageable computational cost. Thus more efforts on this aspect are required in future CPDP studies. (2) Transfer learning is of ultimate importance in CPDP. Given a tight computational budget, it is more cost-effective to focus on optimizing the parameter configuration of transfer learning algorithms (3) The research on CPDP is far from mature where it is 'not difficult' to find a better alternative by making a combination of existing transfer learning and classification techniques. This finding provides important insights about the future design of CPDP techniques.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {566–577},
numpages = {12},
keywords = {automated parameter optimization, classification techniques, cross-project defect prediction, transfer learning},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.4018/ijssci.2014040101,
author = {Mishra, Bharavi and Shukla, K.K.},
title = {Software Defect Prediction Based on GUHA Data Mining Procedure and Multi-Objective Pareto Efficient Rule Selection},
year = {2014},
issue_date = {April 2014},
publisher = {IGI Global},
address = {USA},
volume = {6},
number = {2},
issn = {1942-9045},
url = {https://doi.org/10.4018/ijssci.2014040101},
doi = {10.4018/ijssci.2014040101},
abstract = {Software defect prediction, if is effective, enables the developers to distribute their testing efforts efficiently and let them focus on defect prone modules. It would be very resource consuming to test all the modules while the defect lies in fraction of modules. Information about fault-proneness of classes and methods can be used to develop new strategies which can help mitigate the overall development cost and increase the customer satisfaction. Several machine learning strategies have been used in recent past to identify defective modules. These models are built using publicly available historical software defect data sets. Most of the proposed techniques are not able to deal with the class imbalance problem efficiently. Therefore, it is necessary to develop a prediction model which consists of small simple and comprehensible rules. Considering these facts, in this paper, the authors propose a novel defect prediction approach named GUHA based Classification Association Rule Mining algorithm G-CARM where "GUHA" stands for General Unary Hypothesis Automaton. G-CARM approach is primarily based on Classification Association Rule Mining, and deploys a two stage process involving attribute discretization, and rule generation using GUHA. GUHA is oldest yet very powerful method of pattern mining. The basic idea of GUHA procedure is to mine the interesting attribute patterns that indicate defect proneness. The new method has been compared against five other models reported in recent literature viz. Naive Bayes, Support Vector Machine, RIPPER, J48 and Nearest Neighbour classifier by using several measures, including AUC and probability of detection. The experimental results indicate that the prediction performance of G-CARM approach is better than other prediction approaches. The authors' approach achieved 76% mean recall and 83% mean precision for defective modules and 93% mean recall and 83% mean precision for non-defective modules on CM1, KC1, KC2 and Eclipse data sets. Further defect rule generation process often generates a large number of rules which require considerable efforts while using these rules as a defect predictor, hence, a rule sub-set selection process is also proposed to select best set of rules according to the requirements. Evolution criteria for defect prediction like sensitivity, specificity, precision often compete against each other. It is therefore, important to use multi-objective optimization algorithms for selecting prediction rules. In this paper the authors report prediction rules that are Pareto efficient in the sense that no further improvements in the rule set is possible without sacrificing some performance criteria. Non-Dominated Sorting Genetic Algorithm has been used to find Pareto front and defect prediction rules.},
journal = {Int. J. Softw. Sci. Comput. Intell.},
month = apr,
pages = {1–29},
numpages = {29},
keywords = {Pareto Optimality, General Unary Hypothesis Automaton GUHA, Fault Prediction, Defect Patterns, Data Mining}
}

@article{10.1007/s10664-016-9468-y,
author = {Herbold, Steffen and Trautsch, Alexander and Grabowski, Jens},
title = {Global vs. local models for cross-project defect prediction},
year = {2017},
issue_date = {August    2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-016-9468-y},
doi = {10.1007/s10664-016-9468-y},
abstract = {Although researchers invested significant effort, the performance of defect prediction in a cross-project setting, i.e., with data that does not come from the same project, is still unsatisfactory. A recent proposal for the improvement of defect prediction is using local models. With local models, the available data is first clustered into homogeneous regions and afterwards separate classifiers are trained for each homogeneous region. Since the main problem of cross-project defect prediction is data heterogeneity, the idea of local models is promising. Therefore, we perform a conceptual replication of the previous studies on local models with a focus on cross-project defect prediction. In a large case study, we evaluate the performance of local models and investigate their advantages and drawbacks for cross-project predictions. To this aim, we also compare the performance with a global model and a transfer learning technique designed for cross-project defect predictions. Our findings show that local models make only a minor difference in comparison to global models and transfer learning for cross-project defect prediction. While these results are negative, they provide valuable knowledge about the limitations of local models and increase the validity of previously gained research results.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1866–1902},
numpages = {37},
keywords = {Local models, Defect prediction, Cross-project}
}

@article{10.1007/s11219-015-9287-1,
author = {Ryu, Duksan and Jang, Jong-In and Baik, Jongmoon},
title = {A transfer cost-sensitive boosting approach for cross-project defect prediction},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-015-9287-1},
doi = {10.1007/s11219-015-9287-1},
abstract = {Software defect prediction has been regarded as one of the crucial tasks to improve software quality by effectively allocating valuable resources to fault-prone modules. It is necessary to have a sufficient set of historical data for building a predictor. Without a set of sufficient historical data within a company, cross-project defect prediction (CPDP) can be employed where data from other companies are used to build predictors. In such cases, a transfer learning technique, which extracts common knowledge from source projects and transfers it to a target project, can be used to enhance the prediction performance. There exists the class imbalance problem, which causes difficulties for the learner to predict defects. The main impacts of imbalanced data under cross-project settings have not been investigated in depth. We propose a transfer cost-sensitive boosting method that considers both knowledge transfer and class imbalance for CPDP when given a small amount of labeled target data. The proposed approach performs boosting that assigns weights to the training instances with consideration of both distributional characteristics and the class imbalance. Through comparative experiments with the transfer learning and the class imbalance learning techniques, we show that the proposed model provides significantly higher defect detection accuracy while retaining better overall performance. As a result, a combination of transfer learning and class imbalance learning is highly effective for improving the prediction performance under cross-project settings. The proposed approach will help to design an effective prediction model for CPDP. The improved defect prediction performance could help to direct software quality assurance activities and reduce costs. Consequently, the quality of software can be managed effectively.},
journal = {Software Quality Journal},
month = mar,
pages = {235–272},
numpages = {38},
keywords = {Transfer learning, Software defect prediction, Cross-project defect prediction, Cost-sensitive learning, Class imbalance, Boosting}
}

@article{10.1016/j.jss.2016.02.015,
author = {Rana, Rakesh and Staron, Miroslaw and Berger, Christian and Hansson, J\"{o}rgen and Nilsson, Martin and Meding, Wilhelm},
title = {Analyzing defect inflow distribution and applying Bayesian inference method for software defect prediction in large software projects},
year = {2016},
issue_date = {July 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {117},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.02.015},
doi = {10.1016/j.jss.2016.02.015},
abstract = {Defect inflow distribution of 14 large projects from industry &amp; OSS is analyzed.6 standard distributions are evaluated for their ability to fit the defect inflow.12 out of 14 projects defect inflow data was described best by beta distribution.Historical projects information is useful for early defect prediction using Bayesian inference method. Tracking and predicting quality and reliability is a major challenge in large and distributed software development projects. A number of standard distributions have been successfully used in reliability engineering theory and practice, common among these for modeling software defect inflow being exponential, Weibull, beta and Non-Homogeneous Poisson Process (NHPP). Although standard distribution models have been recognized in reliability engineering practice, their ability to fit defect data from proprietary and OSS software projects is not well understood. Lack of knowledge about underlying defect inflow distribution also leads to difficulty in applying Bayesian based inference methods for software defect prediction. In this paper we explore the defect inflow distribution of total of fourteen large software projects/release from two industrial domain and open source community. We evaluate six standard distributions for their ability to fit the defect inflow data and also assess which information criterion is practical for selecting the distribution with best fit. Our results show that beta distribution provides the best fit to the defect inflow data for all industrial projects as well as majority of OSS projects studied. In the paper we also evaluate how information about defect inflow distribution from historical projects is applied for modeling the prior beliefs/experience in Bayesian analysis which is useful for making software defect predictions early during the software project lifecycle.},
journal = {J. Syst. Softw.},
month = jul,
pages = {229–244},
numpages = {16},
keywords = {Software, SRGM, Defect Inflow}
}

@article{10.1007/s10462-017-9563-5,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {A study on software fault prediction techniques},
year = {2019},
issue_date = {February  2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {2},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-017-9563-5},
doi = {10.1007/s10462-017-9563-5},
abstract = {Software fault prediction aims to identify fault-prone software modules by using some underlying properties of the software project before the actual testing process begins. It helps in obtaining desired software quality with optimized cost and effort. Initially, this paper provides an overview of the software fault prediction process. Next, different dimensions of software fault prediction process are explored and discussed. This review aims to help with the understanding of various elements associated with fault prediction process and to explore various issues involved in the software fault prediction. We search through various digital libraries and identify all the relevant papers published since 1993. The review of these papers are grouped into three classes: software metrics, fault prediction techniques, and data quality issues. For each of the class, taxonomical classification of different techniques and our observations have also been presented. The review and summarization in the tabular form are also given. At the end of the paper, the statistical analysis, observations, challenges, and future directions of software fault prediction have been discussed.},
journal = {Artif. Intell. Rev.},
month = feb,
pages = {255–327},
numpages = {73},
keywords = {Taxonomic classification, Software metrics, Software fault prediction, Software fault datasets, Fault prediction techniques}
}

@inproceedings{10.1145/3412841.3442020,
author = {Hosseini, Seyedrebvar and Turhan, Burak},
title = {A comparison of similarity based instance selection methods for cross project defect prediction},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442020},
doi = {10.1145/3412841.3442020},
abstract = {Context: Previous studies have shown that training data instance selection based on nearest neighborhood (NN) information can lead to better performance in cross project defect prediction (CPDP) by reducing heterogeneity in training datasets. However, neighborhood calculation is computationally expensive and approximate methods such as Locality Sensitive Hashing (LSH) can be as effective as exact methods. Aim: We aim at comparing instance selection methods for CPDP, namely LSH, NN-filter, and Genetic Instance Selection (GIS). Method: We conduct experiments with five base learners, optimizing their hyper parameters, on 13 datasets from PROMISE repository in order to compare the performance of LSH with benchmark instance selection methods NN-Filter and GIS. Results: The statistical tests show six distinct groups for F-measure performance. The top two group contains only LSH and GIS benchmarks whereas the bottom two groups contain only NN-Filter variants. LSH and GIS favor recall more than precision. In fact, for precision performance only three significantly distinct groups are detected by the tests where the top group is comprised of NN-Filter variants only. Recall wise, 16 different groups are identified where the top three groups contain only LSH methods, four of the next six are GIS only and the bottom five contain only NN-Filter. Finally, NN-Filter benchmarks never outperform the LSH counterparts with the same base learner, tuned or non-tuned. Further, they never even belong to the same rank group, meaning that LSH is always significantly better than NN-Filter with the same learner and settings. Conclusions: The increase in performance and the decrease in computational overhead and runtime make LSH a promising approach. However, the performance of LSH is based on high recall and in environments where precision is considered more important NN-Filter should be considered.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1455–1464},
numpages = {10},
keywords = {approximate near neighbour, cross project defect prediction, instance selection, locality sensitive hashing, search based optimisation},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@article{10.1007/s10664-019-09736-3,
author = {Kondo, Masanari and German, Daniel M. and Mizuno, Osamu and Choi, Eun-Hye},
title = {The impact of context metrics on just-in-time defect prediction},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09736-3},
doi = {10.1007/s10664-019-09736-3},
abstract = {Traditional just-in-time defect prediction approaches have been using changed lines of software to predict defective-changes in software development. However, they disregard information around the changed lines. Our main hypothesis is that such information has an impact on the likelihood that the change is defective. To take advantage of this information in defect prediction, we consider n-lines (n = 1,2,…) that precede and follow the changed lines (which we call context lines), and propose metrics that measure them, which we call “Context Metrics.” Specifically, these context metrics are defined as the number of words/keywords in the context lines. In a large-scale empirical study using six open source software projects, we compare the performance of using our context metrics, traditional code churn metrics (e.g., the number of modified subsystems), our extended context metrics which measure not only context lines but also changed lines, and combination metrics that use two extended context metrics at a prediction model for defect prediction. The results show that context metrics that consider the context lines of added-lines achieve the best median value in all cases in terms of a statistical test. Moreover, using few number of context lines is suitable for context metric that considers words, and using more number of context lines is suitable for context metric that considers keywords. Finally, the combination metrics of two extended context metrics significantly outperform all studied metrics in all studied projects w. r. t. the area under the receiver operation characteristic curve (AUC) and Matthews correlation coefficient (MCC).},
journal = {Empirical Softw. Engg.},
month = jan,
pages = {890–939},
numpages = {50},
keywords = {Code churn metrics, Indentation metrics, Changed lines, Context lines, Source code changes, Defect prediction, Just-in-time defect prediction}
}

@article{10.5555/3197793.3197817,
author = {Shukla, Swapnil and Radhakrishnan, T. and Muthukumaran, K. and Neti, Lalita Bhanu},
title = {Multi-objective cross-version defect prediction},
year = {2018},
issue_date = {March     2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {6},
issn = {1432-7643},
abstract = {Defect prediction models help software project teams to spot defect-prone source files of software systems. Software project teams can prioritize and put up rigorous quality assurance (QA) activities on these predicted defect-prone files to minimize post-release defects so that quality software can be delivered. Cross-version defect prediction is building a prediction model from the previous version of a software project to predict defects in the current version. This is more practical than the other two ways of building models, i.e., cross-project prediction model and cross- validation prediction models, as previous version of same software project will have similar parameter distribution among files. In this paper, we formulate cross-version defect prediction problem as a multi-objective optimization problem with two objective functions: (a) maximizing recall by minimizing misclassification cost and (b) maximizing recall by minimizing cost of QA activities on defect prone files. The two multi-objective defect prediction models are compared with four traditional machine learning algorithms, namely logistic regression, na\"{\i}ve Bayes, decision tree and random forest. We have used 11 projects from the PROMISE repository consisting of a total of 41 different versions of these projects. Our findings show that multi-objective logistic regression is more cost-effective than single-objective algorithms.},
journal = {Soft Comput.},
month = mar,
pages = {1959–1980},
numpages = {22},
keywords = {Search-based software engineering, Multi-objective optimization, Misclassification cost, Cross-version defect prediction, Cost-effectiveness}
}

@inproceedings{10.5555/1332044.1332090,
author = {Catal, Cagatay and Diri, Banu},
title = {Software defect prediction using artificial immune recognition system},
year = {2007},
publisher = {ACTA Press},
address = {USA},
abstract = {Predicting fault-prone modules for software development projects enables companies to reach high reliable systems and minimizes necessary budget, personnel and resource to be allocated to achieve this goal. Researchers have investigated various statistical techniques and machine learning algorithms until now but most of them applied their models to the different datasets which are not public or used different criteria to decide the best predictor model. Artificial Immune Recognition System is a supervised learning algorithm which has been proposed in 2001 for the classification problems and its performance for UCI datasets (University of California machine learning repository) is remarkable.In this paper, we propose a novel software defect prediction model by applying Artificial Immune Recognition System (AIRS) along with the Correlation-Based Feature Selection (CFS) technique. In order to evaluate the performance of the proposed model, we apply it to the five NASA public defect datasets and compute G-mean 1, G-mean 2 and F-measure values to discuss the effectiveness of the model. Experimental results show that AIRS has a great potential for software defect prediction and AIRS along with CFS technique provides relatively better prediction for large scale projects which consist of many modules.},
booktitle = {Proceedings of the 25th Conference on IASTED International Multi-Conference: Software Engineering},
pages = {285–290},
numpages = {6},
keywords = {artificial immune recognition system (AIRS) and correlation-based feature selection, immune systems, quality prediction, software defect prediction},
location = {Innsbruck, Austria},
series = {SE'07}
}

@inproceedings{10.1007/978-3-030-16142-2_17,
author = {Li, Heng-Yi and Li, Ming and Zhou, Zhi-Hua},
title = {Towards One Reusable Model for Various Software Defect Mining Tasks},
year = {2019},
isbn = {978-3-030-16141-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-16142-2_17},
doi = {10.1007/978-3-030-16142-2_17},
abstract = {Software defect mining is playing an important role in software quality assurance. Many deep neural network based models have been proposed for software defect mining tasks, and have pushed forward the state-of-the-art mining performance. These deep models usually require a huge amount of task-specific source code for training to capture the code functionality to mine the defects. But such requirement is often hard to be satisfied in practice. On the other hand, lots of free source code and corresponding textual explanations are publicly available in the open source software repositories, which is potentially useful in modeling code functionality. However, no previous studies ever leverage these resources to help defect mining tasks. In this paper, we propose a novel framework to learn one reusable deep model for code functional representation using the huge amount of publicly available task-free source code as well as their textual explanations. And then reuse it for various software defect mining tasks. Experimental results on three major defect mining tasks with real world datasets indicate that by reusing this model in specific tasks, the mining performance outperforms its counterpart that learns deep models from scratch, especially when the training data is insufficient.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 23rd Pacific-Asia Conference, PAKDD 2019, Macau, China, April 14-17, 2019, Proceedings, Part III},
pages = {212–224},
numpages = {13},
keywords = {Software defect mining, Machine learning, Model reuse},
location = {Macau, China}
}

@inproceedings{10.1145/3183440.3194992,
author = {Guo, Yuchen and Shepperd, Martin and Li, Ning},
title = {Bridging effort-aware prediction and strong classification: a just-in-time software defect prediction study},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3194992},
doi = {10.1145/3183440.3194992},
abstract = {Context: Most research into software defect prediction ignores the differing amount of effort entailed in searching for defects between software components. The result is sub-optimal solutions in terms of allocating testing resources. Recently effort-aware (EA) defect prediction has sought to redress this deficiency. However, there is a gap between previous classification research and EA prediction.Objective: We seek to transfer strong defect classification capability to efficient effort-aware software defect prediction.Method: We study the relationship between classification performance and the cost-effectiveness curve experimentally (using six open-source software data sets).Results: We observe extremely skewed distributions of change size which contributes to the lack of relationship between classification performance and the ability to find efficient test orderings for defect detection. Trimming allows all effort-aware approaches bridging high classification capability to efficient effort-aware performance.Conclusion: Effort distributions dominate effort-aware models. Trimming is a practical method to handle this problem.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {325–326},
numpages = {2},
keywords = {defect prediction, effort-aware, just-in-time, software},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1007/s11390-019-1959-z,
author = {Xu, Zhou and Pang, Shuai and Zhang, Tao and Luo, Xia-Pu and Liu, Jin and Tang, Yu-Tian and Yu, Xiao and Xue, Lei},
title = {Cross Project Defect Prediction via Balanced Distribution Adaptation Based Transfer Learning},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {5},
issn = {1000-9000},
url = {https://doi.org/10.1007/s11390-019-1959-z},
doi = {10.1007/s11390-019-1959-z},
abstract = {Defect prediction assists the rational allocation of testing resources by detecting the potentially defective software modules before releasing products. When a project has no historical labeled defect data, cross project defect prediction (CPDP) is an alternative technique for this scenario. CPDP utilizes labeled defect data of an external project to construct a classification model to predict the module labels of the current project. Transfer learning based CPDP methods are the current mainstream. In general, such methods aim to minimize the distribution differences between the data of the two projects. However, previous methods mainly focus on the marginal distribution difference but ignore the conditional distribution difference, which will lead to unsatisfactory performance. In this work, we use a novel balanced distribution adaptation (BDA) based transfer learning method to narrow this gap. BDA simultaneously considers the two kinds of distribution differences and adaptively assigns different weights to them. To evaluate the effectiveness of BDA for CPDP performance, we conduct experiments on 18 projects from four datasets using six indicators (i.e., F-measure, g-means, Balance, AUC, EARecall, and EAF-measure). Compared with 12 baseline methods, BDA achieves average improvements of 23.8%, 12.5%, 11.5%, 4.7%, 34.2%, and 33.7% in terms of the six indicators respectively over four datasets.},
journal = {J. Comput. Sci. Technol.},
month = sep,
pages = {1039–1062},
numpages = {24},
keywords = {effort-aware indicator, balancing distribution, transfer learning, cross-project defect prediction}
}

@article{10.1007/s10515-019-00259-1,
author = {Li, Zhiqiang and Jing, Xiao-Yuan and Zhu, Xiaoke and Zhang, Hongyu and Xu, Baowen and Ying, Shi},
title = {Heterogeneous defect prediction with two-stage ensemble learning},
year = {2019},
issue_date = {Sep 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {3},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-019-00259-1},
doi = {10.1007/s10515-019-00259-1},
abstract = {Heterogeneous defect prediction (HDP) refers to predicting defect-prone software modules in one project (target) using heterogeneous data collected from other projects (source). Recently, several HDP methods have been proposed. However, these methods do not sufficiently incorporate the two characteristics of the defect data: (1) data could be linear inseparable, and (2) data could be highly imbalanced. These two data characteristics make it challenging to build an effective HDP model. In this paper, we propose a novel Two-Stage Ensemble Learning (TSEL) approach to HDP, which contains two stages: ensemble multi-kernel domain adaptation (EMDA) stage and ensemble data sampling (EDS) stage. In the EMDA stage, we develop an Ensemble Multiple Kernel Correlation Alignment (EMKCA) predictor, which combines the advantage of multiple kernel learning and domain adaptation techniques. In the EDS stage, we employ RESample with replacement (RES) technique to learn multiple different EMKCA predictors and use average ensemble to combine them together. These two stages create an ensemble of defect predictors. Extensive experiments on 30 public projects show that the proposed TSEL approach outperforms a range of competing methods. The improvement is 20.14–33.92% in AUC, 36.05–54.78% in f-measure, and 5.48–19.93% in balance, respectively.},
journal = {Automated Software Engg.},
month = sep,
pages = {599–651},
numpages = {53},
keywords = {Domain adaptation, Data sampling, Class imbalance, Multiple kernel learning, Linear inseparability, Two-stage ensemble learning, Heterogeneous defect prediction}
}

@article{10.3233/JIFS-18473,
author = {Malhotra, Ruchika and Sharma, Anjali},
title = {Empirical assessment of feature selection techniques in defect prediction models using web applications},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {36},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-18473},
doi = {10.3233/JIFS-18473},
abstract = {&nbsp;In order to minimize the over-fitting and related factors that are caused by the high dimensionality of the input data in software defect prediction, the attributes are often optimized using various feature selection techniques. However, the comparative performance of these selection techniques in combination with machine learning algorithms remains largely unexplored using web applications. In this work, we investigate the best possible combination of feature selection technique with machine learning algorithms, with the sample space chosen from open source Apache Click and Rave data sets. Our results are based on 945 defect prediction models derived from parametric, non-parametric and ensemble-based machine learning algorithms, for which the metrics are derived from the various filter and threshold-based ranking techniques. Friedman and Nemenyi post-hoc statistical tests are adopted to identify the performance difference of these models. We find that filter-based feature selection in combination with ensemble-based machine learning algorithms not only poise as the best strategy but also yields a maximum feature set redundancy by 94%, with little or no comprise on the performance index.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6567–6578},
numpages = {12},
keywords = {web application quality, machine learning, feature ranking, Feature selection}
}

@article{10.1007/s10489-020-01935-6,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {An empirical study of ensemble techniques for software fault prediction},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {6},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-01935-6},
doi = {10.1007/s10489-020-01935-6},
abstract = {Previously, many researchers have performed analysis of various techniques for the software fault prediction (SFP). Oddly, the majority of such studies have shown the limited prediction capability and their performance for given software fault datasets was not persistent. In contrast to this, recently, ensemble techniques based SFP models have shown promising and improved results across different software fault datasets. However, many new as well as improved ensemble techniques have been introduced, which are not explored for SFP. Motivated by this, the paper performs an investigation on ensemble techniques for SFP. We empirically assess the performance of seven ensemble techniques namely, Dagging, Decorate, Grading, MultiBoostAB, RealAdaBoost, Rotation Forest, and Ensemble Selection. We believe that most of these ensemble techniques are not used before for SFP. We conduct a series of experiments on the benchmark fault datasets and use three distinct classification algorithms, namely, naive Bayes, logistic regression, and J48 (decision tree) as base learners to the ensemble techniques. Experimental analysis revealed that rotation forest with J48 as the base learner achieved the highest precision, recall, and G-mean 1 values of 0.995, 0.994, and 0.994, respectively and Decorate achieved the highest AUC value of 0.986. Further, results of statistical tests showed used ensemble techniques demonstrated a statistically significant difference in their performance among the used ones for SFP. Additionally, the cost-benefit analysis showed that SFP models based on used ensemble techniques might be helpful in saving software testing cost and effort for twenty out of twenty-eight used fault datasets.},
journal = {Applied Intelligence},
month = jun,
pages = {3615–3644},
numpages = {30},
keywords = {Empirical analysis, PROMISE data repository, Ensemble techniques, Software fault prediction}
}

@article{10.1016/j.asoc.2014.11.023,
author = {Malhotra, Ruchika},
title = {A systematic review of machine learning techniques for software fault prediction},
year = {2015},
issue_date = {February 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {27},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2014.11.023},
doi = {10.1016/j.asoc.2014.11.023},
abstract = {Reviews studies from 1991-2013 to assess application of ML techniques for SFP.Identifies seven categories of the ML techniques.Identifies 64 studies to answer the established research questions.Selects primary studies according to the quality assessment of the studies.Systematic literature review performs the following:Summarize ML techniques for SFP models.Assess performance accuracy and capability of ML techniques for constructing SFP models.Provide comparison between the ML and statistical techniques.Provide comparison of performance accuracy of different ML techniques.Summarize the strength and weakness of the ML techniques.Provides future guidelines to software practitioners and researchers. BackgroundSoftware fault prediction is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. There are various machine learning techniques used in the past for predicting faults. MethodIn this study we perform a systematic review of studies from January 1991 to October 2013 in the literature that use the machine learning techniques for software fault prediction. We assess the performance capability of the machine learning techniques in existing research for software fault prediction. We also compare the performance of the machine learning techniques with the statistical techniques and other machine learning techniques. Further the strengths and weaknesses of machine learning techniques are summarized. ResultsIn this paper we have identified 64 primary studies and seven categories of the machine learning techniques. The results prove the prediction capability of the machine learning techniques for classifying module/class as fault prone or not fault prone. The models using the machine learning techniques for estimating software fault proneness outperform the traditional statistical models. ConclusionBased on the results obtained from the systematic review, we conclude that the machine learning techniques have the ability for predicting software fault proneness and can be used by software practitioners and researchers. However, the application of the machine learning techniques in software fault prediction is still limited and more number of studies should be carried out in order to obtain well formed and generalizable results. We provide future guidelines to practitioners and researchers based on the results obtained in this work.},
journal = {Appl. Soft Comput.},
month = feb,
pages = {504–518},
numpages = {15},
keywords = {Systematic literature review, Software fault proneness, Machine learning}
}

@inproceedings{10.1007/978-3-030-16145-3_23,
author = {Zhang, Wenzhou and Li, Weiwei and Jia, Xiuyi},
title = {Effort-Aware Tri-Training for Semi-supervised Just-in-Time Defect Prediction},
year = {2019},
isbn = {978-3-030-16144-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-16145-3_23},
doi = {10.1007/978-3-030-16145-3_23},
abstract = {In recent years, just-in-time (JIT) defect prediction has gained considerable interest as it enables developers to identify risky changes at check-in time. Previous studies tried to conduct research from both supervised and unsupervised perspectives. Since the label of change is hard to acquire, it would be more desirable for applications if a prediction model doesn’t highly rely on the label information. However, the performance of the unsupervised models proposed by previous work isn’t good in terms of precision and F1 due to the lack of supervised information. To overcome this weakness, we try to study the JIT defect prediction from the semi-supervised perspective, which only requires a few labeled data for training. In this paper, we propose an Effort-Aware Tri-Training (EATT) semi-supervised model for JIT defect prediction based on sample selection. We compare EATT with the state-of-the-art supervised and unsupervised models with respect to different labeled rates. The experimental results on six open-source projects demonstrate that EATT performs better than existing supervised and unsupervised models for effort-aware JIT defect prediction.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 23rd Pacific-Asia Conference, PAKDD 2019, Macau, China, April 14-17, 2019, Proceedings, Part II},
pages = {293–304},
numpages = {12},
keywords = {Defect prediction, Just-in-time, Tri-training, Effort-aware},
location = {Macau, China}
}

@article{10.1016/j.jss.2017.06.070,
author = {Yu, Qiao and Jiang, Shujuan and Zhang, Yanmei},
title = {A feature matching and transfer approach for cross-company defect prediction},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {132},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.06.070},
doi = {10.1016/j.jss.2017.06.070},
abstract = {A feature matching algorithm is designed to address the heterogeneous features.A feature matching and transfer (FMT) approach for cross-company defect prediction.An empirical study is conducted on 16 datasets from NASA and PROMISE.The results show that FMT is effective for cross-company defect prediction. Software defect prediction has drawn much attention of researchers in software engineering. Traditional defect prediction methods aim to build the prediction model based on historical data. For a new project or a project with limited historical data, we cannot build a good prediction model. Therefore, researchers have proposed the cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) methods to share the historical data among different projects. However, the features of cross-company datasets are often heterogeneous, which may affect the feasibility of CCDP. To address the heterogeneous features of CCDP, this paper presents a feature matching and transfer (FMT) approach. First, we conduct feature selection for the source project and get the distribution curves of selected features. Similarly, we also get the distribution curves of all features in the target project. Second, according to the distance of different distribution curves, we design a feature matching algorithm to convert the heterogeneous features into the matched features. Finally, we can achieve feature transfer from the source project to the target project. All experiments are conducted on 16 datasets from NASA and PROMISE, and the results show that FMT is effective for CCDP.},
journal = {J. Syst. Softw.},
month = oct,
pages = {366–378},
numpages = {13},
keywords = {Software defect prediction, Heterogeneous features, Feature transfer, Feature matching}
}

@inproceedings{10.1007/978-3-030-38961-1_8,
author = {Sun, Yuanyuan and Xu, Lele and Guo, Lili and Li, Ye and Wang, Yongming},
title = {A Comparison Study of VAE and GAN for Software Fault Prediction},
year = {2019},
isbn = {978-3-030-38960-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38961-1_8},
doi = {10.1007/978-3-030-38961-1_8},
abstract = {Software fault is an unavoidable problem in software project. How to predict software fault to enhance safety and reliability of system is worth studying. In recent years, deep learning has been widely used in the fields of image, text and voice. However it is seldom applied in the field of software fault prediction. Considering the ability of deep learning, we select the deep learning techniques of VAE and GAN for software fault prediction and compare the performance of them. There is one salient feature of software fault data. The proportion of non-fault data is well above the proportion of fault data. Because of the imbalanced data, it is difficult to get high accuracy to predict software fault. As we known, VAE and GAN are able to generate synthetic samples that obey the distribution of real data. We try to take advantage of their power to generate new fault samples in order to improve the accuracy of software fault prediction. The architectures of VAE and GAN are designed to fit for the high dimensional software fault data. New software fault samples are generated to balance the software fault datasets in order to get better performance for software fault prediction. The models of VAE and GAN are trained on GPU TITAN X. SMOTE is also adopted in order to compare the performance with VAE and GAN. The results in the experiment show that VAE and GAN are useful techniques for software fault prediction and VAE has better performance than GAN on this issue.},
booktitle = {Algorithms and Architectures for Parallel Processing: 19th International Conference, ICA3PP 2019, Melbourne, VIC, Australia, December 9–11, 2019, Proceedings, Part II},
pages = {82–96},
numpages = {15},
keywords = {Software fault prediction, GAN, VAE, Deep learning},
location = {Melbourne, VIC, Australia}
}

@article{10.1504/ijcsm.2021.117600,
author = {Hammad, Mustafa},
title = {Classifying defective software projects based on machine learning and complexity metrics},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {4},
issn = {1752-5055},
url = {https://doi.org/10.1504/ijcsm.2021.117600},
doi = {10.1504/ijcsm.2021.117600},
abstract = {Software defects can lead to software failures or errors at any time. Therefore, software developers and engineers spend a lot of time and effort in order to find possible defects. This paper proposes an automatic approach to predict software defects based on machine learning algorithms. A set of complexity measures values are used to train the classifier. Three public datasets were used to evaluate the ability of mining complexity measures for different software projects to predict possible defects. Experimental results showed that it is possible to min software complexity to build a defect prediction model with a high accuracy rate.},
journal = {Int. J. Comput. Sci. Math.},
month = jan,
pages = {401–412},
numpages = {11},
keywords = {support vector machine, SVM, decision trees, na\"{\i}ve Bayes, neural networks, complexity, machine learning, software metrics, defect prediction, software defects}
}

@inproceedings{10.1109/ICMLA.2009.18,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan},
title = {Feature Selection with Imbalanced Data for Software Defect Prediction},
year = {2009},
isbn = {9780769539263},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2009.18},
doi = {10.1109/ICMLA.2009.18},
abstract = {In this paper, we study the learning impact of data sampling followed by attribute selection on the classification models built with binary class imbalanced data within the scenario of software quality engineering. We use a wrapper-based attribute ranking technique to select a subset of attributes, and the random undersampling technique (RUS) on the majority class to alleviate the negative effects of imbalanced data on the prediction models. The datasets used in the empirical study were collected from numerous software projects. Five data preprocessing scenarios were explored in these experiments, including: (1) training on the original, unaltered fit dataset, (2) training on a sampled version of the fit dataset, (3) training on an unsampled version of the fit dataset using only the attributes chosen by feature selection based on the unsampled fit dataset, (4) training on an unsampled version of the fit dataset using only the attributes chosen by feature selection based on a sampled version of the fit dataset, and (5) training on a sampled version of the fit dataset using only the attributes chosen by feature selection based on the sampled version of the fit dataset. We compared the performances of the classification models constructed over these five different scenarios. The results demonstrate that the classification models constructed on the sampled fit data with or without feature selection (case 2 and case 5) significantly outperformed the classification models built with the other cases (unsampled fit data). Moreover, the two scenarios using sampled data (case 2 and case 5) showed very similar performances, but the subset of attributes (case 5) is only around 15% or 30% of the complete set of attributes (case 2).},
booktitle = {Proceedings of the 2009 International Conference on Machine Learning and Applications},
pages = {235–240},
numpages = {6},
keywords = {wrapper-based attribute ranking, software defect prediction, imbalanced data, feature selection},
series = {ICMLA '09}
}

@inproceedings{10.1007/978-3-030-62822-2_12,
author = {Zhou, Yangxi and Zhu, Yan and Chen, Liangyu},
title = {Software Defect-Proneness Prediction with Package Cohesion and Coupling Metrics Based on Complex Network Theory},
year = {2020},
isbn = {978-3-030-62821-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62822-2_12},
doi = {10.1007/978-3-030-62822-2_12},
abstract = {Driven by functionality requirements, software codes are increasingly inflated, and invocations between codes are frequent and random. This makes it difficult for programmers to be thoughtful when modifying code, increasing the risk of defects. In an object-oriented software system, packages take the role of a middle tier that aggregates classes and limits class access. However, as the software system evolves, the logic and correctness of packages are weakened. In this paper, we explore the relation between package metrics and object-oriented software defect-proneness. We use two metrics of package cohesion and coupling based on complex network theory to verify the impact of code structure on software quality. On six Java software systems, the experimental result shows that the cohesion and coupling metrics play a positive role in software defect prediction, and they can correctly and effectively evaluate package organization structure. Meanwhile, our study confirms that compliance with the design principle of high cohesion and low coupling can reduce the risk of software defect-proneness and improve software quality.},
booktitle = {Dependable Software Engineering. Theories, Tools, and Applications: 6th International Symposium, SETTA 2020, Guangzhou, China, November 24–27, 2020, Proceedings},
pages = {186–201},
numpages = {16},
keywords = {Cohesion and coupling metrics, Defect proneness, Software package},
location = {Guangzhou, China}
}

@article{10.1049/iet-sen.2019.0278,
author = {Zhu, Kun and Zhang, Nana and Ying, Shi and Zhu, Dandan},
title = {Within‐project and cross‐project just‐in‐time defect prediction based on denoising autoencoder and convolutional neural network},
year = {2020},
issue_date = {June 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2019.0278},
doi = {10.1049/iet-sen.2019.0278},
abstract = {Just‐in‐time defect prediction is an important and useful branch in software defect prediction. At present, deep learning is a research hotspot in the field of artificial intelligence, which can combine basic defect features into deep semantic features and make up for the shortcomings of machine learning algorithms. However, the mainstream deep learning techniques have not been applied yet in just‐in‐time defect prediction. Therefore, the authors propose a novel just‐in‐time defect prediction model named DAECNN‐JDP based on denoising autoencoder and convolutional neural network in this study, which has three main advantages: (i) Different weights for the position vector of each dimension feature are set, which can be automatically trained by adaptive trainable vector. (ii) Through the training of denoising autoencoder, the input features that are not contaminated by noise can be obtained, thus learning more robust feature representation. (iii) The authors leverage a powerful representation‐learning technique, convolution neural network, to construct the basic change features into the abstract deep semantic features. To evaluate the performance of the DAECNN‐JDP model, they conduct extensive within‐project and cross‐project defect prediction experiments on six large open source projects. The experimental results demonstrate that the superiority of DAECNN‐JDP on five evaluation metrics.},
journal = {IET Software},
month = jun,
pages = {185–195},
numpages = {18},
keywords = {cross-project defect prediction experiments, convolution neural network, autoencoder convolutional neural network, just-in-time defect prediction model, mainstream deep learning techniques, basic defect features, software defect prediction, denoising autoencoder, learning (artificial intelligence), neural nets}
}

@inproceedings{10.1145/3345629.3345638,
author = {Amasaki, Sousuke and Yokogawa, Tomoyuki and Aman, Hirohisa},
title = {Applying Cross Project Defect Prediction Approaches to Cross-Company Effort Estimation},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345638},
doi = {10.1145/3345629.3345638},
abstract = {BACKGROUND: Prediction systems in software engineering often suffer from the shortage of suitable data within a project. A promising solution is transfer learning that utilizes data from outside the project. Many transfer learning approaches have been proposed for defect prediction known as cross-project defect prediction (CPDP). In contrast, a few approaches have been proposed for software effort estimation known as cross-company software effort estimation (CCSEE). Both CCSEE and CPDP are engaged in a similar problem, and a few CPDP approaches are applicable as CCSEE in actual. It is thus beneficial for improving CCSEE performance to examine how well CPDP approaches can perform as CCSEE approaches. AIMS: To explore how well CPDP approaches work as CCSEE approaches. METHOD: An empirical experiment was conducted for evaluating the performance of CPDP approaches in CCSEE. We examined 7 CPDP approaches which were selected due to the easiness of application. Those approaches were applied to 8 data sets, each of which consists of a few subsets from different domains. The estimation results were evaluated with a common performance measure called SA. RESULTS: there were several CPDP approaches which could improve the estimation accuracy though the degree of improvement was not large. CONCLUSIONS: A straight forward application of selected CPDP approaches did not bring a clear effect. CCSEE may need specific transfer learning approaches for more improvement.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {76–79},
numpages = {4},
keywords = {cross-company effort estimation, cross-project defect prediction, transfer learning},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1145/3412841.3442027,
author = {Tsimpourlas, Foivos and Rajan, Ajitha and Allamanis, Miltiadis},
title = {Supervised learning over test executions as a test oracle},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442027},
doi = {10.1145/3412841.3442027},
abstract = {The challenge of automatically determining the correctness of test executions is referred to as the test oracle problem and is a key remaining issue for automated testing. The paper aims at solving the test oracle problem in a scalable and accurate way. To achieve this, we use supervised learning over test execution traces. We label a small fraction of the execution traces with their verdict of pass or fail. We use the labelled traces to train a neural network (NN) model to learn to distinguish runtime patterns for passing versus failing executions for a given program.We evaluate our approach using case studies from different application domains - 1. Module from Ethereum Blockchain, 2. Module from PyTorch deep learning framework, 3. Microsoft SEAL encryption library components and 4. Sed stream editor. We found the classification models for all subject programs resulted in high precision, recall and specificity, averaging to 89%, 88% and 92% respectively, while only training with an average 15% of the total traces. Our experiments show that the proposed NN model is promising as a test oracle and is able to learn runtime patterns to distinguish test executions for systems and tests from different application domains.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1521–1531},
numpages = {11},
keywords = {execution trace, neural networks, software testing, test oracle},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@inproceedings{10.1109/WORDS.2005.32,
author = {Challagulla, Venkata U. B. and Bastani, Farokh B. and Yen, I-Ling and Paul, Raymond A.},
title = {Empirical Assessment of Machine Learning based Software Defect Prediction Techniques},
year = {2005},
isbn = {0769523471},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WORDS.2005.32},
doi = {10.1109/WORDS.2005.32},
abstract = {The wide-variety of real-time software systems, including telecontrol/telepresence systems, robotic systems, and mission planning systems, can entail dynamic code synthesis based on runtime mission-specific requirements and operating conditions. This necessitates the need for dynamic dependability assessment to ensure that these systems will perform as specified and will not fail in catastrophic ways. One approach in achieving this is to dynamically assess the modules in the synthesized code using software defect prediction techniques. Statistical models, such as Stepwise Multi-linear Regression models and multivariate models, and machine learning approaches, such as Artificial Neural Networks, Instance-based Reasoning, Bayesian-Belief Networks, Decision Trees, and Rule Inductions, have been investigated for predicting software quality. However, there is still no consensus about the best predictor model for software defects. In this paper, we evaluate different predictor models on four different real-time software defect data sets. The results show that a combination of 1R and Instance-based Learning along with the Consistencybased Subset Evaluation technique provides relatively better consistency in accuracy prediction compared to other models. The results also show that "size" and "complexity" metrics are not sufficient for accurately predicting real-time software defects.},
booktitle = {Proceedings of the 10th IEEE International Workshop on Object-Oriented Real-Time Dependable Systems},
pages = {263–270},
numpages = {8},
series = {WORDS '05}
}

@article{10.1007/s10489-021-02346-x,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {Software fault prediction based on the dynamic selection of learning technique: findings from the eclipse project study},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {12},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-021-02346-x},
doi = {10.1007/s10489-021-02346-x},
abstract = {An effective software fault prediction (SFP) model could help developers in the quick and prompt detection of faults and thus help enhance the overall reliability and quality of the software project. Variations in the prediction performance of learning techniques for different software systems make it difficult to select a suitable learning technique for fault prediction modeling. The evaluation of previously presented SFP approaches has shown that single machine learning-based models failed to provide the best accuracy in any context, highlighting the need to use multiple techniques to build the SFP model. To solve this problem, we present and discuss a software fault prediction approach based on selecting the most appropriate learning techniques from a set of competitive and accurate learning techniques for building a fault prediction model. In work, we apply the discussed SFP approach for the five Eclipse project datasets and nine Object-oriented (OO) project datasets and report the findings of the experimental study. We have used different performance measures, i.e., AUC, accuracy, sensitivity, and specificity, to assess the discussed approach’s performance. Further, we have performed a cost-benefit analysis to evaluate the economic viability of the approach. Results showed that the presented approach predicted the software’s faults effectively for the used accuracy, AUC, sensitivity, and specificity measures with the highest achieved values of 0.816, 0.835, 0.98, and 0.903 for AUC, accuracy, sensitivity, and specificity, respectively. The cost-benefit analysis of the approach showed that it could help reduce the overall software testing cost.},
journal = {Applied Intelligence},
month = dec,
pages = {8945–8960},
numpages = {16},
keywords = {Machine learning techniques, Cost-benefit analysis, Dynamic selection, Eclipse project, Software fault prediction}
}

@inproceedings{10.5555/1881763.1881787,
author = {Liu, Guang-Jie and Wang, Wen-Yong},
title = {Research an educational software defect prediction model based on SVM},
year = {2010},
isbn = {3642145329},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We must pay attention and find defects, defects through the prediction to quantify the quality management and quality in order to achieve this goal, requires an estimate of the various defect detection process. Software defects are the departure of software are products' anticipative function. This paper collecting the data of the software defects, then, using the SVM model the predictive values are gained analyzing the predictive results, software are organizations can improve software control measure software process and allocate testing resources effectively.},
booktitle = {Proceedings of the Entertainment for Education, and 5th International Conference on E-Learning and Games},
pages = {215–222},
numpages = {8},
keywords = {software lifecycle, software defect, educational software, SVM},
location = {Changchun, China},
series = {Edutainment'10}
}

@inproceedings{10.1109/MSR.2017.20,
author = {Patil, Sangameshwar},
title = {Concept-based classification of software defect reports},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.20},
doi = {10.1109/MSR.2017.20},
abstract = {Automatic identification of the defect type from the textual description of a software defect can significantly speedup as well as improve the software defect management life-cycle. This has been recognized in the research community and multiple solutions based on supervised learning approach have been proposed in the recent literature. However, these approaches need significant amount of labeled training data for use in real-life projects.In this paper, we propose to use Explicit Semantic Analysis (ESA) to carry out concept-based classification of software defect reports. We compute the "semantic similarity" between the defect type labels and the defect report in a concept space spanned by Wikipedia articles and then, assign the defect type which has the highest similarity with the defect report. This approach helps us to circumvent the problem of dependence on labeled training data. Experimental results show that using concept-based classification is a promising approach for software defect classification to avoid the expensive process of creating labeled training data and yet get accuracy comparable to the traditional supervised learning approaches. To the best of our knowledge, this is the first use of Wikipedia and ESA for software defect classification problem.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {182–186},
numpages = {5},
keywords = {text data mining, software defect classification, mining software respositories, explicit semantic analysis},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@article{10.1007/s10664-018-9661-2,
author = {Huang, Qiao and Xia, Xin and Lo, David},
title = {Revisiting supervised and unsupervised models for effort-aware just-in-time defect prediction},
year = {2019},
issue_date = {Oct 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9661-2},
doi = {10.1007/s10664-018-9661-2},
abstract = {Effort-aware just-in-time (JIT) defect prediction aims at finding more defective software changes with limited code inspection cost. Traditionally, supervised models have been used; however, they require sufficient labelled training data, which is difficult to obtain, especially for new projects. Recently, Yang et al. proposed an unsupervised model (i.e., LT) and applied it to projects with rich historical bug data. Interestingly, they reported that, under the same inspection cost (i.e., 20 percent of the total lines of code modified by all changes), it could find about 12% - 27% more defective changes than a state-of-the-art supervised model (i.e., EALR) when using different evaluation settings. This is surprising as supervised models that benefit from historical data are expected to perform better than unsupervised ones. Their finding suggests that previous studies on defect prediction had made a simple problem too complex. Considering the potential high impact of Yang et al.’s work, in this paper, we perform a replication study and present the following new findings: (1) Under the same inspection budget, LT requires developers to inspect a large number of changes necessitating many more context switches. (2) Although LT finds more defective changes, many highly ranked changes are false alarms. These initial false alarms may negatively impact practitioners’ patience and confidence. (3) LT does not outperform EALR when the harmonic mean of Recall and Precision (i.e., F1-score) is considered. Aside from highlighting the above findings, we propose a simple but improved supervised model called CBS+, which leverages the idea of both EALR and LT. We investigate the performance of CBS+ using three different evaluation settings, including time-wise cross-validation, 10-times 10-fold cross-validation and cross-project validation. When compared with EALR, CBS+ detects about 15% - 26% more defective changes, while keeping the number of context switches and initial false alarms close to those of EALR. When compared with LT, the number of defective changes detected by CBS+ is comparable to LT’s result, while CBS+ significantly reduces context switches and initial false alarms before first success. Finally, we discuss how to balance the tradeoff between the number of inspected defects and context switches, and present the implications of our findings for practitioners and researchers.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {2823–2862},
numpages = {40},
keywords = {Research bias, Evaluation metrics, Defect prediction}
}

@inproceedings{10.1145/3196321.3196331,
author = {Xu, Zhou and Li, Shuai and Tang, Yutian and Luo, Xiapu and Zhang, Tao and Liu, Jin and Xu, Jun},
title = {Cross version defect prediction with representative data via sparse subset selection},
year = {2018},
isbn = {9781450357142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196321.3196331},
doi = {10.1145/3196321.3196331},
abstract = {Software defect prediction aims at detecting the defect-prone software modules by mining historical development data from software repositories. If such modules are identified at the early stage of the development, it can save large amounts of resources. Cross Version Defect Prediction (CVDP) is a practical scenario by training the classification model on the historical data of the prior version and then predicting the defect labels of modules of the current version. However, software development is a constantly-evolving process which leads to the data distribution differences across versions within the same project. The distribution differences will degrade the performance of the classification model. In this paper, we approach this issue by leveraging a state-of-the-art Dissimilarity-based Sparse Subset Selection (DS3) method. This method selects a representative module subset from the prior version based on the pairwise dissimilarities between the modules of two versions and assigns each module of the current version to one of the representative modules. These selected modules can well represent the modules of the current version, thus mitigating the distribution differences. We evaluate the effectiveness of DS3 for CVDP performance on total 40 cross-version pairs from 56 versions of 15 projects with three traditional and two effort-aware indicators. The extensive experiments show that DS3 outperforms three baseline methods, especially in terms of two effort-aware indicators.},
booktitle = {Proceedings of the 26th Conference on Program Comprehension},
pages = {132–143},
numpages = {12},
keywords = {cross version defect prediction, pairwise dissimilarities, representative data, sparse subset selection},
location = {Gothenburg, Sweden},
series = {ICPC '18}
}

@inproceedings{10.1109/ICMLA.2010.27,
author = {Wang, Huanjing and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {A Comparative Study of Ensemble Feature Selection Techniques for Software Defect Prediction},
year = {2010},
isbn = {9780769543000},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2010.27},
doi = {10.1109/ICMLA.2010.27},
abstract = {Feature selection has become the essential step in many data mining applications. Using a single feature subset selection method may generate local optima. Ensembles of feature selection methods attempt to combine multiple feature selection methods instead of using a single one. We present a comprehensive empirical study examining 17 different ensembles of feature ranking techniques (rankers) including six commonly-used feature ranking techniques, the signal-to-noise filter technique, and 11 threshold-based feature ranking techniques. This study utilized 16 real-world software measurement data sets of different sizes and built 13,600 classification models. Experimental results indicate that ensembles of very few rankers are very effective and even better than ensembles of many or all rankers.},
booktitle = {Proceedings of the 2010 Ninth International Conference on Machine Learning and Applications},
pages = {135–140},
numpages = {6},
keywords = {feature ranking, ensembles, defect prediction},
series = {ICMLA '10}
}

@inproceedings{10.1145/2896839.2896843,
author = {Koroglu, Yavuz and Sen, Alper and Kutluay, Doruk and Bayraktar, Akin and Tosun, Yalcin and Cinar, Murat and Kaya, Hasan},
title = {Defect prediction on a legacy industrial software: a case study on software with few defects},
year = {2016},
isbn = {9781450341547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896839.2896843},
doi = {10.1145/2896839.2896843},
abstract = {Context: Building defect prediction models for software projects is helpful for reducing the effort in locating defects. In this paper, we share our experiences in building a defect prediction model for a large industrial software project. We extract product and process metrics to build models and show that we can build an accurate defect prediction model even when 4% of the software is defective.Objective: Our goal in this project is to integrate a defect predictor into the continuous integration (CI) cycle of a large software project and decrease the effort in testing.Method: We present our approach in the form of an experience report. Specifically, we collected data from seven older versions of the software project and used additional features to predict defects of current versions. We compared several classification techniques including Naive Bayes, Decision Trees, and Random Forest and resampled our training data to present the company with the most accurate defect predictor.Results: Our results indicate that we can focus testing efforts by guiding the test team to only 8% of the software where 53% of actual defects can be found. Our model has 90% accuracy.Conclusion: We produce a defect prediction model with high accuracy for a software with defect rate of 4%. Our model uses Random Forest, that which we show has more predictive power than Naive Bayes, Logistic Regression and Decision Trees in our case.},
booktitle = {Proceedings of the 4th International Workshop on Conducting Empirical Studies in Industry},
pages = {14–20},
numpages = {7},
keywords = {random forest, process metrics, feature selection, experience report, defect prediction},
location = {Austin, Texas},
series = {CESI '16}
}

@inproceedings{10.1109/ASE.2013.6693087,
author = {Jiang, Tian and Tan, Lin and Kim, Sunghun},
title = {Personalized defect prediction},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693087},
doi = {10.1109/ASE.2013.6693087},
abstract = {Many defect prediction techniques have been proposed. While they often take the author of the code into consideration, none of these techniques build a separate prediction model for each developer. Different developers have different coding styles, commit frequencies, and experience levels, causing different defect patterns. When the defects of different developers are combined, such differences are obscured, hurting prediction performance.This paper proposes personalized defect prediction--building a separate prediction model for each developer to predict software defects. As a proof of concept, we apply our personalized defect prediction to classify defects at the file change level. We evaluate our personalized change classification technique on six large software projects written in C and Java--the Linux kernel, PostgreSQL, Xorg, Eclipse, Lucene and Jackrabbit. Our personalized approach can discover up to 155 more bugs than the traditional change classification (210 versus 55) if developers inspect the top 20% lines of code that are predicted buggy. In addition, our approach improves the F1-score by 0.01-0.06 compared to the traditional change classification.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {279–289},
numpages = {11},
keywords = {software reliability, personalized defect prediction, machine learning, change classification},
location = {Silicon Valley, CA, USA},
series = {ASE '13}
}

@article{10.1155/2020/8858010,
author = {Shen, Zhidong and Chen, Si and Coppolino, Luigi},
title = {A Survey of Automatic Software Vulnerability Detection, Program Repair, and Defect Prediction Techniques},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1939-0114},
url = {https://doi.org/10.1155/2020/8858010},
doi = {10.1155/2020/8858010},
abstract = {Open source software has been widely used in various industries due to its openness and flexibility, but it also brings potential software security problems. Together with the large-scale increase in the number of software and the increase in complexity, the traditional manual methods to deal with these security issues are inefficient and cannot meet the current cyberspace security requirements. Therefore, it is an important research topic for researchers in the field of software security to develop more intelligent technologies to apply to potential security issues in software. The development of deep learning technology has brought new opportunities for the study of potential security issues in software, and researchers have successively proposed many automation methods. In this paper, these automation technologies are evaluated and analysed in detail from three aspects: software vulnerability detection, software program repair, and software defect prediction. At the same time, we point out some problems of these research methods, give corresponding solutions, and finally look forward to the application prospect of deep learning technology in automated software vulnerability detection, automated program repair, and automated defect prediction.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {16}
}

@article{10.1007/s10586-021-03282-8,
author = {Mustaqeem, Mohd. and Saqib, Mohd.},
title = {Principal component based support vector machine (PC-SVM): a hybrid technique for software defect detection},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-021-03282-8},
doi = {10.1007/s10586-021-03282-8},
abstract = {Defects are the major problems in the current situation and predicting them is also a difficult task. Researchers and scientists have developed many software defects prediction techniques to overcome this very helpful issue. But to some extend there is a need for an algorithm/method to predict defects with more accuracy, reduce time and space complexities. All the previous research conducted on the data without feature reduction lead to the curse of dimensionality. We brought up a machine learning hybrid approach by combining Principal component Analysis (PCA) and Support vector machines (SVM) to overcome the ongoing problem. We have employed PROMISE (CM1: 344 observations, KC1: 2109 observations) data from the directory of NASA to conduct our research. We split the dataset into training (CM1: 240 observations, KC1: 1476 observations) dataset and testing (CM1: 104 observations, KC1: 633 observations) datasets. Using PCA, we find the principal components for feature optimization which reduce the time complexity. Then, we applied SVM for classification due to very native qualities over traditional and conventional methods. We also employed the GridSearchCV method for hyperparameter tuning. In the proposed hybrid model we have found better accuracy (CM1: 95.2%, KC1: 86.6%) than other methods. The proposed model also presents higher evaluation in the terms of other criteria. As a limitation, the only problem with SVM is there is no probabilistic explanation for classification which may very rigid towards classifications. In the future, some other method may also introduce which can overcome this limitation and keep a soft probabilistic based margin for classification on the optimal hyperplane.},
journal = {Cluster Computing},
month = sep,
pages = {2581–2595},
numpages = {15},
keywords = {Software defects detection, PCA, SVM, Feature optimization, Classification, PROMISE dataset}
}

@inproceedings{10.1145/3439961.3439979,
author = {Santos, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
title = {Predicting Software Defects with Explainable Machine Learning},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439979},
doi = {10.1145/3439961.3439979},
abstract = {Most software systems must evolve to cope with stakeholders’ requirements and fix existing defects. Hence, software defect prediction represents an area of interest in both academia and the software industry. As a result, predicting software defects can help the development team to maintain substantial levels of software quality. For this reason, machine learning models have increased in popularity for software defect prediction and have demonstrated effectiveness in many scenarios. In this paper, we evaluate a machine learning approach for selecting features to predict software module defects. We use a tree boosting algorithm that receives as input a training set comprising records of software features encoding characteristics of each module and outputs whether the corresponding module is defective prone. For nine projects within the widely known NASA data program, we build prediction models from a set of easy-to-compute module features. We then sample this sizable model space by randomly selecting software features to compose each model. This significant number of models allows us to structure our work along model understandability and predictive accuracy. We argue that explaining model predictions is meaningful to provide information to developers on features related to each module defective-prone. We show that (i) features that contribute most to finding the best models may vary depending on the project, and (ii) effective models are highly understandable based on a survey with 40 developers.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {18},
numpages = {10},
keywords = {software defects, explainable models, SHAP values, NASA datasets},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@article{10.1016/j.compeleceng.2018.02.043,
author = {Choudhary, Garvit Rajesh and Kumar, Sandeep and Kumar, Kuldeep and Mishra, Alok and Catal, Cagatay},
title = {Empirical analysis of change metrics for software fault prediction},
year = {2018},
issue_date = {Apr 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {67},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2018.02.043},
doi = {10.1016/j.compeleceng.2018.02.043},
journal = {Comput. Electr. Eng.},
month = apr,
pages = {15–24},
numpages = {10},
keywords = {Defect prediction, Software quality, Metrics, Change log, Eclipse, Software fault prediction}
}

@article{10.1016/j.infsof.2008.04.008,
author = {Chang, Ching-Pao and Chu, Chih-Ping and Yeh, Yu-Fang},
title = {Integrating in-process software defect prediction with association mining to discover defect pattern},
year = {2009},
issue_date = {February, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {51},
number = {2},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2008.04.008},
doi = {10.1016/j.infsof.2008.04.008},
abstract = {Rather than detecting defects at an early stage to reduce their impact, defect prevention means that defects are prevented from occurring in advance. Causal analysis is a common approach to discover the causes of defects and take corrective actions. However, selecting defects to analyze among large amounts of reported defects is time consuming, and requires significant effort. To address this problem, this study proposes a defect prediction approach where the reported defects and performed actions are utilized to discover the patterns of actions which are likely to cause defects. The approach proposed in this study is adapted from the Action-Based Defect Prediction (ABDP), an approach uses the classification with decision tree technique to build a prediction model, and performs association rule mining on the records of actions and defects. An action is defined as a basic operation used to perform a software project, while a defect is defined as software flaws and can arise at any stage of the software process. The association rule mining finds the maximum rule set with specific minimum support and confidence and thus the discovered knowledge can be utilized to interpret the prediction models and software process behaviors. The discovered patterns then can be applied to predict the defects generated by the subsequent actions and take necessary corrective actions to avoid defects. The proposed defect prediction approach applies association rule mining to discover defect patterns, and multi-interval discretization to handle the continuous attributes of actions. The proposed approach is applied to a business project, giving excellent prediction results and revealing the efficiency of the proposed approach. The main benefit of using this approach is that the discovered defect patterns can be used to evaluate subsequent actions for in-process projects, and reduce variance of the reported data resulting from different projects. Additionally, the discovered patterns can be used in causal analysis to identify the causes of defects for software process improvement.},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {375–384},
numpages = {10},
keywords = {Software defect prediction, Multi-interval discretization, Association rule}
}

@article{10.1016/j.engappai.2009.10.001,
author = {Pendharkar, Parag C.},
title = {Exhaustive and heuristic search approaches for learning a software defect prediction model},
year = {2010},
issue_date = {February, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {23},
number = {1},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2009.10.001},
doi = {10.1016/j.engappai.2009.10.001},
abstract = {In this paper, we propose a software defect prediction model learning problem (SDPMLP) where a classification model selects appropriate relevant inputs, from a set of all available inputs, and learns the classification function. We show that the SDPMLP is a combinatorial optimization problem with factorial complexity, and propose two hybrid exhaustive search and probabilistic neural network (PNN), and simulated annealing (SA) and PNN procedures to solve it. For small size SDPMLP, exhaustive search PNN works well and provides an (all) optimal solution(s). However, for large size SDPMLP, the use of exhaustive search PNN approach is not pragmatic and only the SA-PNN allows us to solve the SDPMLP in a practical time limit. We compare the performance of our hybrid approaches with traditional classification algorithms and find that our hybrid approaches perform better than traditional classification algorithms.},
journal = {Eng. Appl. Artif. Intell.},
month = feb,
pages = {34–40},
numpages = {7},
keywords = {Software engineering, Simulated annealing, Probabilistic neural networks, Heuristics, Exhaustive search}
}

@inproceedings{10.1145/2884781.2884804,
author = {Wang, Song and Liu, Taiyue and Tan, Lin},
title = {Automatically learning semantic features for defect prediction},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884804},
doi = {10.1145/2884781.2884804},
abstract = {Software defect prediction, which predicts defective code regions, can help developers find bugs and prioritize their testing efforts. To build accurate prediction models, previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs, and such a capability is needed for building accurate prediction models.To bridge the gap between programs' semantics and defect prediction features, this paper proposes to leverage a powerful representation-learning algorithm, deep learning, to learn semantic representation of programs automatically from source code. Specifically, we leverage Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs).Our evaluation on ten open source projects shows that our automatically learned semantic features significantly improve both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) compared to traditional features. Our semantic features improve WPDP on average by 14.7% in precision, 11.5% in recall, and 14.2% in F1. For CPDP, our semantic features based approach outperforms the state-of-the-art technique TCA+ with traditional features by 8.9% in F1.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {297–308},
numpages = {12},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/2884781.2884857,
author = {Tantithamthavorn, Chakkrit and McIntosh, Shane and Hassan, Ahmed E. and Matsumoto, Kenichi},
title = {Automated parameter optimization of classification techniques for defect prediction models},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884857},
doi = {10.1145/2884781.2884857},
abstract = {Defect prediction models are classifiers that are trained to identify defect-prone software modules. Such classifiers have configurable parameters that control their characteristics (e.g., the number of trees in a random forest classifier). Recent studies show that these classifiers may underperform due to the use of suboptimal default parameter settings. However, it is impractical to assess all of the possible settings in the parameter spaces. In this paper, we investigate the performance of defect prediction models where Caret --- an automated parameter optimization technique --- has been applied. Through a case study of 18 datasets from systems that span both proprietary and open source domains, we find that (1) Caret improves the AUC performance of defect prediction models by as much as 40 percentage points; (2) Caret-optimized classifiers are at least as stable as (with 35% of them being more stable than) classifiers that are trained using the default settings; and (3) Caret increases the likelihood of producing a top-performing classifier by as much as 83%. Hence, we conclude that parameter settings can indeed have a large impact on the performance of defect prediction models, suggesting that researchers should experiment with the parameters of the classification techniques. Since automated parameter optimization techniques like Caret yield substantially benefits in terms of performance improvement and stability, while incurring a manageable additional computational cost, they should be included in future defect prediction studies.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {321–332},
numpages = {12},
keywords = {software defect prediction, parameter optimization, experimental design, classification techniques},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3416508.3417118,
author = {Amasaki, Sousuke and Aman, Hirohisa and Yokogawa, Tomoyuki},
title = {An exploratory study on applicability of cross project defect prediction approaches to cross-company effort estimation},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417118},
doi = {10.1145/3416508.3417118},
abstract = {BACKGROUND: Research on software effort estimation has been active for decades, especially in developing effort estimation models. Effort estimation models need a dataset collected from completed projects similar to a project to be estimated. The similarity suffers from dataset shift, and cross-company software effort estimation (CCSEE) gets an attractive research topic. A recent study on the dataset shift problem examined the applicability and the effectiveness of cross-project defect prediction (CPDP) approaches. It was insufficient to bring a conclusion due to a limited number of examined approaches. AIMS: To investigate the characteristics of CPDP approaches that are applicable and effective for dataset shift problem in effort estimation. METHOD: We first reviewed the characteristics of 24 CPDP approaches to find applicable approaches. Next, we investigated their effectiveness in effort estimation performance with ten dataset configurations. RESULTS: 16 out of 24 CPDP approaches implemented in CrossPare framework were found to be applicable to CCSEE. However, only one approach could improve the effort estimation performance. Most of the others degraded it and were harmful. CONCLUSIONS: Most of the CPDP approaches we examined were helpless for CCSEE.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {71–80},
numpages = {10},
keywords = {cross-company effort estimation, cross-project defect prediction, empirical evaluation},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@article{10.4018/IJITSA.2021010104,
author = {Shatnawi, Raed and Mishra, Alok},
title = {An Empirical Study on Software Fault Prediction Using Product and Process Metrics},
year = {2021},
issue_date = {Jan 2021},
publisher = {IGI Global},
address = {USA},
volume = {14},
number = {1},
issn = {1935-570X},
url = {https://doi.org/10.4018/IJITSA.2021010104},
doi = {10.4018/IJITSA.2021010104},
abstract = {Product and process metrics are measured from the development and evolution of software. Metrics are indicators of software fault-proneness and advanced models using machine learning can be provided to the development team to select modules for further inspection. Most fault-proneness classifiers were built from product metrics. However, the inclusion of process metrics adds evolution as a factor to software quality. In this work, the authors propose a process metric measured from the evolution of software to predict fault-proneness in software models. The process metrics measures change-proneness of modules (classes and interfaces). Classifiers are trained and tested for five large open-source systems. Classifiers were built using product metrics alone and using a combination of product and the proposed process metric. The classifiers evaluation shows improvements whenever the process metrics were used. Evolution metrics are correlated with quality of software and helps in improving software quality prediction for future releases.},
journal = {Int. J. Inf. Technol. Syst. Appoach},
month = jan,
pages = {62–78},
numpages = {17},
keywords = {Software Fault, Product Metrics, Process Metrics, CK Metrics}
}

@inproceedings{10.1145/3324884.3415286,
author = {Perera, Anjana},
title = {Using defect prediction to improve the bug detection capability of search-based software testing},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3415286},
doi = {10.1145/3324884.3415286},
abstract = {Automated test generators, such as search based software testing (SBST) techniques, replace the tedious and expensive task of manually writing test cases. SBST techniques are effective at generating tests with high code coverage. However, is high code coverage sufficient to maximise the number of bugs found? We argue that SBST needs to be focused to search for test cases in defective areas rather in non-defective areas of the code in order to maximise the likelihood of discovering the bugs. Defect prediction algorithms give useful information about the bug-prone areas in software. Therefore, we formulate the objective of this thesis: Improve the bug detection capability of SBST by incorporating defect prediction information. To achieve this, we devise two research objectives, i.e., 1) Develop a novel approach (SBSTCL) that allocates time budget to classes based on the likelihood of classes being defective, and 2) Develop a novel strategy (SBSTML) to guide the underlying search algorithm (i.e., genetic algorithm) towards the defective areas in a class. Through empirical evaluation on 434 real reported bugs in the Defects4J dataset, we demonstrate that our novel approach, SBSTCL, is significantly more efficient than the state of the art SBST when they are given a tight time budget in a resource constrained environment.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1170–1174},
numpages = {5},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@article{10.1007/s10515-017-0220-7,
author = {Li, Zhiqiang and Jing, Xiao-Yuan and Wu, Fei and Zhu, Xiaoke and Xu, Baowen and Ying, Shi},
title = {Cost-sensitive transfer kernel canonical correlation analysis for heterogeneous defect prediction},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-017-0220-7},
doi = {10.1007/s10515-017-0220-7},
abstract = {Cross-project defect prediction (CPDP) refers to predicting defects in a target project using prediction models trained from historical data of other source projects. And CPDP in the scenario where source and target projects have different metric sets is called heterogeneous defect prediction (HDP). Recently, HDP has received much research interest. Existing HDP methods only consider the linear correlation relationship among the features (metrics) of the source and target projects, and such models are insufficient to evaluate nonlinear correlation relationship among the features. So these methods may suffer from the linearly inseparable problem in the linear feature space. Furthermore, existing HDP methods do not take the class imbalance problem into consideration. Unfortunately, the imbalanced nature of software defect datasets increases the learning difficulty for the predictors. In this paper, we propose a new cost-sensitive transfer kernel canonical correlation analysis (CTKCCA) approach for HDP. CTKCCA can not only make the data distributions of source and target projects much more similar in the nonlinear feature space, where the learned features have favorable separability, but also utilize the different misclassification costs for defective and defect-free classes to alleviate the class imbalance problem. We perform the Friedman test with Nemenyi's post-hoc statistical test and the Cliff's delta effect size test for the evaluation. Extensive experiments on 28 public projects from five data sources indicate that: (1) CTKCCA significantly performs better than the related CPDP methods; (2) CTKCCA performs better than the related state-of-the-art HDP methods.},
journal = {Automated Software Engg.},
month = jun,
pages = {201–245},
numpages = {45},
keywords = {Transfer learning, Kernel canonical correlation analysis, Heterogeneous defect prediction, Cost-sensitive learning, Class imbalance}
}

@inproceedings{10.1145/3127005.3127015,
author = {Amasaki, Sousuke},
title = {On Applicability of Cross-project Defect Prediction Method for Multi-Versions Projects},
year = {2017},
isbn = {9781450353052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127005.3127015},
doi = {10.1145/3127005.3127015},
abstract = {Context: Cross-project defect prediction (CPDP) research has been popular, and many CPDP methods have been proposed so far. As the straightforward use of Cross-project (CP) data was useless, those methods filter, weigh, and adapt CP data for a target project data. This idea would also be useful for a project having past defect data. Objective: To evaluate the applicability of CPDP methods for multi-versions projects. The evaluation focused on the relationship between the performance change and the proximity of older release data to a target project. Method: We conducted experiments that compared the predictive performance between using older version data with and without Nearest Neighbor (NN) filter, a classic CPDP method. Results: NN-filter could not make clear differences in predictive performance. Conclusions: NN-filter was not helpful for improving predictive performance with older release data.},
booktitle = {Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {93–96},
numpages = {4},
keywords = {Cross-Project, Defect Prediction, Experiment},
location = {Toronto, Canada},
series = {PROMISE}
}

@article{10.1016/j.eswa.2015.03.013,
author = {\"{O}zt\"{u}rk, Muhammed Maruf and Cavusoglu, Unal and Zengin, Ahmet},
title = {A novel defect prediction method for web pages using k-means++},
year = {2015},
issue_date = {November 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {19},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.03.013},
doi = {10.1016/j.eswa.2015.03.013},
abstract = {Presents a novel defect clustering method.Shed new light to defect prediction methods.Depicts the prominence of k-means++ for software testing.Unveils the density of error rates of web elements. With the increase of the web software complexity, defect detection and prevention have become crucial processes in the software industry. Over the past decades, defect prediction research has reported encouraging results for reducing software product costs. Despite promising results, these researches have hardly been applied to web based systems using clustering algorithms. An appropriate implementation of the clustering in defect prediction may facilitate to estimate defects in a web page source code. One of the widely used clustering algorithms is k-means whose derived versions such as k-means++ show good performance on large-data sets. Here, we present a new defect clustering method using k-means++ for web page source codes. According to the experimental results, almost half of the defects are detected in the middle of web pages. k-means++ is significantly better than the other four clustering algorithms in three criteria on four data set. We also tested our method on four classifiers and the results have shown that after the clustering, Linear Discriminant Analysis is, in general, better than the other three classifiers.},
journal = {Expert Syst. Appl.},
month = nov,
pages = {6496–6506},
numpages = {11},
keywords = {k-means++, Software testing, Fault clustering, Defect prediction}
}

@inproceedings{10.1145/2695664.2695959,
author = {Xuan, Xiao and Lo, David and Xia, Xin and Tian, Yuan},
title = {Evaluating defect prediction approaches using a massive set of metrics: an empirical study},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695959},
doi = {10.1145/2695664.2695959},
abstract = {To evaluate the performance of a within-project defect prediction approach, people normally use precision, recall, and F-measure scores. However, in machine learning literature, there are a large number of evaluation metrics to evaluate the performance of an algorithm, (e.g., Matthews Correlation Coefficient, G-means, etc.), and these metrics evaluate an approach from different aspects. In this paper, we investigate the performance of within-project defect prediction approaches on a large number of evaluation metrics. We choose 6 state-of-the-art approaches including naive Bayes, decision tree, logistic regression, kNN, random forest and Bayesian network which are widely used in defect prediction literature. And we evaluate these 6 approaches on 14 evaluation metrics (e.g., G-mean, F-measure, balance, MCC, J-coefficient, and AUC). Our goal is to explore a practical and sophisticated way for evaluating the prediction approaches comprehensively. We evaluate the performance of defect prediction approaches on 10 defect datasets from PROMISE repository. The results show that Bayesian network achieves a noteworthy performance. It achieves the best recall, FN-R, G-mean1 and balance on 9 out of the 10 datasets, and F-measure and J-coefficient on 7 out of the 10 datasets.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {1644–1647},
numpages = {4},
keywords = {machine learning, evaluation metric, defect prediction},
location = {Salamanca, Spain},
series = {SAC '15}
}

@article{10.3233/KES-200029,
author = {Singh, Pradeep and Verma, Shrish},
title = {ACO based comprehensive model for software fault prediction},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {24},
number = {1},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-200029},
doi = {10.3233/KES-200029},
abstract = {The comprehensive models can be used for software quality modelling which involves prediction of low-quality modules using interpretable rules. Such comprehensive model can guide the design and testing team to focus on the poor quality modules, thereby, limited resources allocated for software quality inspection can be targeted only towards modules that are likely to be defective. Ant Colony Optimization (ACO) based learner is one potential way to obtain rules that can classify the software modules faulty and not faulty. This paper investigates ACO based mining approach with ROC based rule quality updation to constructs a rule-based software fault prediction model with useful metrics. We have also investigated the effect of feature selection on ACO based and other benchmark algorithms. We tested the proposed method on several publicly available software fault data sets. We compared the performance of ACO based learning with the results of three benchmark classifiers on the basis of area under the receiver operating characteristic curve. The evaluation of performance measure proves that the ACO based learner outperforms other benchmark techniques.},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {63–71},
numpages = {9},
keywords = {ACO, fault prediction, Software metric}
}

@inproceedings{10.1145/3383219.3383281,
author = {Khan, Bilal and Iqbal, Danish and Badshah, Sher},
title = {Cross-Project Software Fault Prediction Using Data Leveraging Technique to Improve Software Quality},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383281},
doi = {10.1145/3383219.3383281},
abstract = {Software fault prediction is a process to detect bugs in software projects. Fault prediction in software engineering has attracted much attention from the last decade. The early prognostication of faults in software minimize the cost and effort of errors that come at later stages. Different machine learning techniques have been utilized for fault prediction, that is proven to be utilizable. Despite, the significance of fault prediction most of the companies do not consider fault prediction in practice and do not build useful models due to lack of data or lack of enough data to strengthen the power of fault predictors. However, models trained and tested on less amount of data are difficult to generalize, because they do not consider project size, project differences, and features selection. To overcome these issues, we proposed an instance-based transfer learning through data leveraging using logistic linear regression as a base proposed statistical methodology. In our study, we considered three software projects within the same domain. Finally, we performed a comparative analysis of three different experiments for building models (targeted project). The experimental results of the proposed approach show promising improvements in (SFP).},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {434–438},
numpages = {5},
keywords = {data leveraging, Software fault prediction, Software Quality, Machine learning, Instance-based learning, Cross-project},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1145/2915970.2916007,
author = {Petri\'{c}, Jean and Bowes, David and Hall, Tracy and Christianson, Bruce and Baddoo, Nathan},
title = {The jinx on the NASA software defect data sets},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2916007},
doi = {10.1145/2915970.2916007},
abstract = {Background: The NASA datasets have previously been used extensively in studies of software defects. In 2013 Shepperd et al. presented an essential set of rules for removing erroneous data from the NASA datasets making this data more reliable to use.Objective: We have now found additional rules necessary for removing problematic data which were not identified by Shepperd et al.Results: In this paper, we demonstrate the level of erroneous data still present even after cleaning using Shepperd et al.'s rules and apply our new rules to remove this erroneous data.Conclusion: Even after systematic data cleaning of the NASA MDP datasets, we found new erroneous data. Data quality should always be explicitly considered by researchers before use.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {13},
numpages = {5},
keywords = {software defect prediction, machine learning, data quality},
location = {Limerick, Ireland},
series = {EASE '16}
}

@article{10.1007/s10619-021-07331-4,
author = {Srinivasan, R. and Subalalitha, C. N.},
title = {Sentimental analysis from imbalanced code-mixed data using machine learning approaches},
year = {2021},
issue_date = {Jun 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {41},
number = {1},
issn = {0926-8782},
url = {https://doi.org/10.1007/s10619-021-07331-4},
doi = {10.1007/s10619-021-07331-4},
abstract = {Knowledge discovery from various perspectives has become a crucial asset in almost all fields. Sentimental analysis is a classification task used to classify the sentence based on the meaning of their context. This paper addresses class imbalance problem which is one of the important issues in sentimental analysis. Not much works focused on sentimental analysis with imbalanced class label distribution. The paper also focusses on another aspect of the problem which involves a concept called “Code Mixing”. Code mixed data consists of text alternating between two or more languages. Class imbalance distribution is a commonly noted phenomenon in a code-mixed data. The existing works have focused more on analyzing the sentiments in a monolingual data but not in a code-mixed data. This paper addresses all these issues and comes up with a solution to analyze sentiments for a class imbalanced code-mixed data using sampling technique combined with levenshtein distance metrics. Furthermore, this paper compares the performances of various machine learning approaches namely, Random Forest Classifier, Logistic Regression, XGBoost classifier, Support Vector Machine and Na\"{\i}ve Bayes Classifier using F1- Score.},
journal = {Distrib. Parallel Databases},
month = mar,
pages = {37–52},
numpages = {16},
keywords = {Code-mixed data, Sentimental analysis, Imbalanced data, Machine learning, Sampling}
}

@article{10.1007/s11219-019-09468-z,
author = {Eni\c{s}er, Hasan Ferit and Sen, Alper},
title = {Virtualization of stateful services via machine learning},
year = {2020},
issue_date = {Mar 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-019-09468-z},
doi = {10.1007/s11219-019-09468-z},
abstract = {Today’s enterprise software systems are much more complicated than the past. Increasing numbers of dependent applications, heterogeneous technologies, and wide usage of Service-Oriented Architectures (SOA), where numerous services communicate with each other, makes testing of such systems challenging. For testing these software systems, the concept of service virtualization is gaining popularity. Service virtualization is an automated technique to mimic the behavior of a given real service. Services can be classified as stateless or stateful services. Many services are stateful in nature, yet virtualization of stateful services is harder than virtualization of stateless services. In this work, we introduce two novel stateful service virtualization approaches. We employ classification-based and sequence-to-sequence-based machine learning algorithms in developing our solutions. Classification is a supervised learning method where the task is assigning given inputs to corresponding classes. A sequence-to-sequence model is a deep neural network architecture where the input and the output are sequences. We demonstrate the validity of our approaches on three datasets. Our evaluation shows that we obtain 75 % to 81 % accuracy on subject datasets with classification based method. Our deep neural network-based solution achieves even better accuracy results ranging from 89 to 97 % on subject datasets. Our evaluation on training times of the mentioned techniques show that classification based technique significantly outperforms other methods.},
journal = {Software Quality Journal},
month = mar,
pages = {283–306},
numpages = {24},
keywords = {Machine learning, Service virtualization, Software testing}
}

@inproceedings{10.1145/3383219.3383243,
author = {Pham, Van and Lokan, Chris and Kasmarik, Kathryn},
title = {A Better Set of Object-Oriented Design Metrics for Within-Project Defect Prediction},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383243},
doi = {10.1145/3383219.3383243},
abstract = {Background: Using design metrics to predict fault-prone elements of a software design can help to focus attention on classes that need redesign and more extensive testing. However, some design metrics have been pointed out to be theoretically invalid, and the usefulness of some metrics is questioned.Aim: To identify a set of object-oriented metrics that are theoretically valid, and useful for identifying fault-prone classes in a design.Method: Drawing on four well-known sets of design metrics (CK, LK, MOOD and QMOOD), we propose a consolidated set of metrics that covers many aspects of object-oriented software design. We conduct two experiments, first using a single large system and then considering successive releases of that system, to compare the usefulness of the consolidated set with the other four sets for within-project prediction of fault-prone classes.Results: Both experiments suggest the consolidated set is effective at identifying fault-prone classes, outperforming the other metric sets (though at a cost of more false alarms).Conclusion: This paper adds to knowledge about the usefulness of existing sets of design metrics for within-project defect prediction, and identifies a consolidated set of metrics that is more effective than the existing sets at identifying fault-prone classes.},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {230–239},
numpages = {10},
keywords = {fault-proneness prediction, design metrics, Object-oriented software design},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1145/2499393.2499395,
author = {Herbold, Steffen},
title = {Training data selection for cross-project defect prediction},
year = {2013},
isbn = {9781450320160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499393.2499395},
doi = {10.1145/2499393.2499395},
abstract = {Software defect prediction has been a popular research topic in recent years and is considered as a means for the optimization of quality assurance activities. Defect prediction can be done in a within-project or a cross-project scenario. The within-project scenario produces results with a very high quality, but requires historic data of the project, which is often not available. For the cross-project prediction, the data availability is not an issue as data from other projects is readily available, e.g., in repositories like PROMISE. However, the quality of the defect prediction results is too low for practical use. Recent research showed that the selection of appropriate training data can improve the quality of cross-project defect predictions. In this paper, we propose distance-based strategies for the selection of training data based on distributional characteristics of the available data. We evaluate the proposed strategies in a large case study with 44 data sets obtained from 14 open source projects. Our results show that our training data selection strategy improves the achieved success rate of cross-project defect predictions significantly. However, the quality of the results still cannot compete with within-project defect prediction.},
booktitle = {Proceedings of the 9th International Conference on Predictive Models in Software Engineering},
articleno = {6},
numpages = {10},
keywords = {cross-project prediction, defect-prediction, machine learning},
location = {Baltimore, Maryland, USA},
series = {PROMISE '13}
}

@inproceedings{10.1007/978-3-030-79379-1_1,
author = {Meinke, Karl and Khosrowjerdi, Hojat},
title = {Use Case Testing: A Constrained Active Machine Learning Approach},
year = {2021},
isbn = {978-3-030-79378-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79379-1_1},
doi = {10.1007/978-3-030-79379-1_1},
abstract = {As a methodology for system design and testing, use cases are well-known and widely used. While current active machine learning (ML) algorithms can effectively automate unit testing, they do not scale up&nbsp;to use case testing of complex systems in an efficient way.We present a new parallel distributed processing (PDP) architecture for a constrained active machine learning (CAML) approach to use case testing. To exploit CAML we introduce a use case modeling language with: (i) compile-time constraints on query generation, and (ii) run-time constraints using dynamic constraint checking. We evaluate this approach by applying a prototype implementation of CAML to use case testing of simulated multi-vehicle autonomous driving scenarios.},
booktitle = {Tests and Proofs: 15th International Conference, TAP 2021, Held as Part of STAF 2021, Virtual Event, June 21–22, 2021, Proceedings},
pages = {3–21},
numpages = {19},
keywords = {Use case testing, Requirements testing, Model checking, Machine learning, Learning-based testing, Constraint solving, Autonomous driving}
}

@inproceedings{10.1109/COMPSAC.2014.66,
author = {Liu, Shulong and Chen, Xiang and Liu, Wangshu and Chen, Jiaqiang and Gu, Qing and Chen, Daoxu},
title = {FECAR: A Feature Selection Framework for Software Defect Prediction},
year = {2014},
isbn = {9781479935758},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2014.66},
doi = {10.1109/COMPSAC.2014.66},
abstract = {Software defect prediction can classify new software entities into either buggy or clean. However the effectiveness of existing methods is influenced by irrelevant and redundant features. In this paper, we propose a new feature selection framework FECAR using Feature Clustering And feature Ranking. This framework firstly partitions original features into k clusters based on FF-Correlation measure. Then it selects relevant features from each cluster based on FC-Relevance measure. In empirical study, we choose Symmetric Uncertainty as FF-Correlation measure, and choose Information Gain, Chi-Square, and Relief as three different FC-Relevance measures. Based on some real projects Eclipse and NASA, we implemented our framework and performed empirical studies to investigate the redundancy rate and the performance of the trained defect predictors. Final results verify the effectiveness of our proposed framework and further provide a guideline for achieving cost-effective feature selection when using our framework.},
booktitle = {Proceedings of the 2014 IEEE 38th Annual Computer Software and Applications Conference},
pages = {426–435},
numpages = {10},
keywords = {Software Defect Prediction, Feature Selection, Feature Clustering, Feature Ranking},
series = {COMPSAC '14}
}

@inproceedings{10.1007/978-3-030-64881-7_16,
author = {Sharma, Arnab and Wehrheim, Heike},
title = {Automatic Fairness Testing of Machine Learning Models},
year = {2020},
isbn = {978-3-030-64880-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64881-7_16},
doi = {10.1007/978-3-030-64881-7_16},
abstract = {In recent years, there has been an increased application of machine learning (ML) to decision making systems. This has prompted an urgent need for validating requirements on ML models. Fairness is one such requirement to be ensured in numerous application domains. It specifies a software as “learned” by an ML algorithm to not be biased in the sense of discriminating against some attributes (like gender or age), giving different decisions upon flipping the values of these attributes.In this work, we apply verification-based testing (VBT) to the fairness checking of ML models. Verification-based testing employs verification technology to generate test cases potentially violating the property under interest. For fairness testing, we additionally provide a specification language for the formalization of different fairness requirements. From the ML model under test and fairness specification VBT automatically generates test inputs specific to the specified fairness requirement. The empirical evaluation on several benchmark ML models shows verification-based testing to perform better than existing fairness testing techniques with respect to effectiveness.},
booktitle = {Testing Software and Systems: 32nd IFIP WG 6.1 International Conference, ICTSS 2020, Naples, Italy, December 9–11, 2020, Proceedings},
pages = {255–271},
numpages = {17},
keywords = {SMT solving, Machine learning testing, Fairness},
location = {Naples, Italy}
}

@inproceedings{10.1145/2875913.2875922,
author = {Tang, Hao and Lan, Tian and Hao, Dan and Zhang, Lu},
title = {Enhancing Defect Prediction with Static Defect Analysis},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875922},
doi = {10.1145/2875913.2875922},
abstract = {In the software development process, how to develop better software at lower cost has been a major issue of concern. One way that helps is to find more defects as early as possible, on which defect prediction can provide effective guidance. The most popular defect prediction technique is to build defect prediction models based on machine learning. To improve the performance of defect prediction model, selecting appropriate features is critical. On the other hand, static analysis is usually used in defect detection. As static defect analyzers detects defects by matching some well-defined "defect patterns", its result is useful for locating defects. However, defect prediction and static defect analysis are supposed to be two parallel areas due to the differences in research motivation, solution and granularity.In this paper, we present a possible approach to improve the performance of defect prediction with the help of static analysis techniques. Specifically, we present to extract features based on defect patterns from static defect analyzers to improve the performance of defect prediction models. Based on this approach, we implemented a defect prediction tool and set up experiments to measure the effect of the features.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {43–51},
numpages = {9},
keywords = {static defect analyzer, predictive model, machine learning, defect pattern, code feature, Defect},
location = {Wuhan, China},
series = {Internetware '15}
}

@inproceedings{10.1145/3193977.3193985,
author = {Hardin, Bonnie and Kanewala, Upulee},
title = {Using semi-supervised learning for predicting metamorphic relations},
year = {2018},
isbn = {9781450357296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3193977.3193985},
doi = {10.1145/3193977.3193985},
abstract = {Software testing is difficult to automate, especially in programs which have no oracle, or method of determining which output is correct. Metamorphic testing is a solution this problem. Metamorphic testing uses metamorphic relations to define test cases and expected outputs. A large amount of time is needed for a domain expert to determine which metamorphic relations can be used to test a given program. Metamorphic relation prediction removes this need for such an expert. We propose a method using semi-supervised machine learning to detect which metamorphic relations are applicable to a given code base. We compare this semi-supervised model with a supervised model, and show that the addition of unlabeled data improves the classification accuracy of the MR prediction model.},
booktitle = {Proceedings of the 3rd International Workshop on Metamorphic Testing},
pages = {14–17},
numpages = {4},
keywords = {semi-supervised learning, metamorphic testing, metamorphic relations, machine learning},
location = {Gothenburg, Sweden},
series = {MET '18}
}

@article{10.1007/s10664-014-9346-4,
author = {Ryu, Duksan and Choi, Okjoo and Baik, Jongmoon},
title = {Value-cognitive boosting with a support vector machine for cross-project defect prediction},
year = {2016},
issue_date = {February  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9346-4},
doi = {10.1007/s10664-014-9346-4},
abstract = {It is well-known that software defect prediction is one of the most important tasks for software quality improvement. The use of defect predictors allows test engineers to focus on defective modules. Thereby testing resources can be allocated effectively and the quality assurance costs can be reduced. For within-project defect prediction (WPDP), there should be sufficient data within a company to train any prediction model. Without such local data, cross-project defect prediction (CPDP) is feasible since it uses data collected from similar projects in other companies. Software defect datasets have the class imbalance problem increasing the difficulty for the learner to predict defects. In addition, the impact of imbalanced data on the real performance of models can be hidden by the performance measures chosen. We investigate if the class imbalance learning can be beneficial for CPDP. In our approach, the asymmetric misclassification cost and the similarity weights obtained from distributional characteristics are closely associated to guide the appropriate resampling mechanism. We performed the effect size A-statistics test to evaluate the magnitude of the improvement. For the statistical significant test, we used Wilcoxon rank-sum test. The experimental results show that our approach can provide higher prediction performance than both the existing CPDP technique and the existing class imbalance technique.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {43–71},
numpages = {29},
keywords = {Transfer learning, Cross-project defect prediction, Class imbalance, Boosting}
}

@inproceedings{10.1145/3468264.3468614,
author = {Cito, J\"{u}rgen and Dillig, Isil and Kim, Seohyun and Murali, Vijayaraghavan and Chandra, Satish},
title = {Explaining mispredictions of machine learning models using rule induction},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468614},
doi = {10.1145/3468264.3468614},
abstract = {While machine learning (ML) models play an increasingly prevalent role in many software engineering tasks, their prediction accuracy is often problematic. When these models do mispredict, it can be very difficult to isolate the cause. In this paper, we propose a technique that aims to facilitate the debugging process of trained statistical models. Given an ML model and a labeled data set, our method produces an interpretable characterization of the data on which the model performs particularly poorly. The output of our technique can be useful for understanding limitations of the training data or the model itself; it can also be useful for ensembling if there are multiple models with different strengths. We evaluate our approach through case studies and illustrate how it can be used to improve the accuracy of predictive models used for software engineering tasks within Facebook.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {716–727},
numpages = {12},
keywords = {rule induction, machine learning, explainability},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/3338906.3341462,
author = {Caulo, Maria},
title = {A taxonomy of metrics for software fault prediction},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3341462},
doi = {10.1145/3338906.3341462},
abstract = {In the field of Software Fault Prediction (SFP), researchers exploit software metrics to build predictive models using machine learning and/or statistical techniques. SFP has existed for several decades and the number of metrics used has increased dramatically. Thus, the need for a taxonomy of metrics for SFP arises firstly to standardize the lexicon used in this field so that the communication among researchers is simplified and then to organize and systematically classify the used metrics. In this doctoral symposium paper, I present my ongoing work which aims not only to build such a taxonomy as comprehensive as possible, but also to provide a global understanding of the metrics for SFP in terms of detailed information: acronym(s), extended name, univocal description, granularity of the fault prediction (e.g., method and class), category, and research papers in which they were used.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1144–1147},
numpages = {4},
keywords = {taxonomy, software metrics, software fault prediction},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.5555/1671248.1671311,
author = {Tosun, Ayse and Bener, Ayse},
title = {Reducing false alarms in software defect prediction by decision threshold optimization},
year = {2009},
isbn = {9781424448425},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Software defect data has an imbalanced and highly skewed class distribution. The misclassification costs of two classes are not equal nor are known. It is critical to find the optimum bound, i.e. threshold, which would best separate defective and defect-free classes in software data. We have applied decision threshold optimization on Na\"{\i}ve Bayes classifier in order to find the optimum threshold for software defect data. ROC analyses show that decision threshold optimization significantly decreases false alarms (on the average by 11%) without changing probability of detection rates.},
booktitle = {Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
pages = {477–480},
numpages = {4},
series = {ESEM '09}
}

@inproceedings{10.1145/3194104.3194110,
author = {Young, Steven and Abdou, Tamer and Bener, Ayse},
title = {A replication study: just-in-time defect prediction with ensemble learning},
year = {2018},
isbn = {9781450357234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194104.3194110},
doi = {10.1145/3194104.3194110},
abstract = {Just-in-time defect prediction, which is also known as change-level defect prediction, can be used to efficiently allocate resources and manage project schedules in the software testing and debugging process. Just-in-time defect prediction can reduce the amount of code to review and simplify the assignment of developers to bug fixes. This paper reports a replicated experiment and an extension comparing the prediction of defect-prone changes using traditional machine learning techniques and ensemble learning. Using datasets from six open source projects, namely Bugzilla, Columba, JDT, Platform, Mozilla, and PostgreSQL we replicate the original approach to verify the results of the original experiment and use them as a basis for comparison for alternatives in the approach. Our results from the replicated experiment are consistent with the original. The original approach uses a combination of data preprocessing and a two-layer ensemble of decision trees. The first layer uses bagging to form multiple random forests. The second layer stacks the forests together with equal weights. Generalizing the approach to allow the use of any arbitrary set of classifiers in the ensemble, optimizing the weights of the classifiers, and allowing additional layers, we apply a new deep ensemble approach, called deep super learner, to test the depth of the original study. The deep super learner achieves statistically significantly better results than the original approach on five of the six projects in predicting defects as measured by F1 score.},
booktitle = {Proceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
pages = {42–47},
numpages = {6},
keywords = {defect prediction, deep learning},
location = {Gothenburg, Sweden},
series = {RAISE '18}
}

@article{10.1016/j.infsof.2013.05.002,
author = {Rodriguez, Daniel and Ruiz, Roberto and Riquelme, Jose C. and Harrison, Rachel},
title = {A study of subgroup discovery approaches for defect prediction},
year = {2013},
issue_date = {October, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {10},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.05.002},
doi = {10.1016/j.infsof.2013.05.002},
abstract = {Context: Although many papers have been published on software defect prediction techniques, machine learning approaches have yet to be fully explored. Objective: In this paper we suggest using a descriptive approach for defect prediction rather than the precise classification techniques that are usually adopted. This allows us to characterise defective modules with simple rules that can easily be applied by practitioners and deliver a practical (or engineering) approach rather than a highly accurate result. Method: We describe two well-known subgroup discovery algorithms, the SD algorithm and the CN2-SD algorithm to obtain rules that identify defect prone modules. The empirical work is performed with publicly available datasets from the Promise repository and object-oriented metrics from an Eclipse repository related to defect prediction. Subgroup discovery algorithms mitigate against characteristics of datasets that hinder the applicability of classification algorithms and so remove the need for preprocessing techniques. Results: The results show that the generated rules can be used to guide testing effort in order to improve the quality of software development projects. Such rules can indicate metrics, their threshold values and relationships between metrics of defective modules. Conclusions: The induced rules are simple to use and easy to understand as they provide a description rather than a complete classification of the whole dataset. Thus this paper represents an engineering approach to defect prediction, i.e., an approach which is useful in practice, easily understandable and can be applied by practitioners.},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {1810–1822},
numpages = {13},
keywords = {Subgroup discovery, Rules, Imbalanced datasets, Defect prediction}
}

@inproceedings{10.1007/978-3-030-33709-4_5,
author = {Tasnim Cynthia, Shamse and Rasul, Md. Golam and Ripon, Shamim},
title = {Effect of Feature Selection in Software Fault Detection},
year = {2019},
isbn = {978-3-030-33708-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33709-4_5},
doi = {10.1007/978-3-030-33709-4_5},
abstract = {The quality of software is enormously affected by the faults associated with it. Detection of faults at a proper stage in software development is a challenging task and plays a vital role in the quality of the software. Machine learning is, now a days, a commonly used technique for fault detection and prediction. However, the effectiveness of the fault detection mechanism is impacted by the number of attributes in the publicly available datasets. Feature selection is the process of selecting a subset of all the features that are most influential to the classification and it is a challenging task. This paper thoroughly investigates the effect of various feature selection techniques on software fault classification by using NASA’s some benchmark publicly available datasets. Various metrics are used to analyze the performance of the feature selection techniques. The experiment discovers that the most important and relevant features can be selected by the adopted feature selection techniques without sacrificing the performance of fault detection.},
booktitle = {Multi-Disciplinary Trends in Artificial Intelligence: 13th International Conference, MIWAI 2019, Kuala Lumpur, Malaysia, November 17–19, 2019, Proceedings},
pages = {52–63},
numpages = {12},
keywords = {Fault detection, Feature selection, Feature classification},
location = {Kuala Lumpur, Malaysia}
}

@article{10.1016/j.jss.2021.111031,
author = {Giray, G\"{o}rkem},
title = {A software engineering perspective on engineering machine learning systems: State of the art and challenges},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111031},
doi = {10.1016/j.jss.2021.111031},
journal = {J. Syst. Softw.},
month = oct,
numpages = {35},
keywords = {Systematic literature review, Deep learning, Machine learning, Software process, Software development, Software engineering}
}

@article{10.1145/3442181,
author = {Sabir, Bushra and Ullah, Faheem and Babar, M. Ali and Gaire, Raj},
title = {Machine Learning for Detecting Data Exfiltration: A Review},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442181},
doi = {10.1145/3442181},
abstract = {Context: Research at the intersection of cybersecurity, Machine Learning (ML), and Software Engineering (SE) has recently taken significant steps in proposing countermeasures for detecting sophisticated data exfiltration attacks. It is important to systematically review and synthesize the ML-based data exfiltration countermeasures for building a body of knowledge on this important topic. Objective: This article aims at systematically reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches, feature engineering techniques, evaluation datasets, and performance metrics used for these countermeasures. This review also aims at identifying gaps in research on ML-based data exfiltration countermeasures. Method: We used Systematic Literature Review (SLR) method to select and review 92 papers. Results: The review has enabled us to: (a) classify the ML approaches used in the countermeasures into data-driven, and behavior-driven approaches; (b) categorize features into six types: behavioral, content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance measures used by these studies. Conclusion: We conclude that: (i) The integration of data-driven and behavior-driven approaches should be explored; (ii) There is a need of developing high quality and large size evaluation datasets; (iii) Incremental ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial learning should be considered and explored during the development of countermeasures to avoid poisoning attacks; and (v) The use of automated feature engineering should be encouraged for efficiently detecting data exfiltration attacks.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {50},
numpages = {47},
keywords = {machine learning, data leakage, data breach, advanced persistent threat, Data exfiltration}
}

@inproceedings{10.1145/3377816.3381734,
author = {Byun, Taejoon and Rayadurgam, Sanjai},
title = {Manifold for machine learning assurance},
year = {2020},
isbn = {9781450371261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377816.3381734},
doi = {10.1145/3377816.3381734},
abstract = {The increasing use of machine-learning (ML) enabled systems in critical tasks fuels the quest for novel verification and validation techniques yet grounded in accepted system assurance principles. In traditional system development, model-based techniques have been widely adopted, where the central premise is that abstract models of the required system provide a sound basis for judging its implementation. We posit an analogous approach for ML systems using an ML technique that extracts from the high-dimensional training data implicitly describing the required system, a low-dimensional underlying structure---a manifold. It is then harnessed for a range of quality assurance tasks such as test adequacy measurement, test input generation, and runtime monitoring of the target ML system. The approach is built on variational autoencoder, an unsupervised method for learning a pair of mutually near-inverse functions between a given high-dimensional dataset and a low-dimensional representation. Preliminary experiments establish that the proposed manifold-based approach, for test adequacy drives diversity in test data, for test generation yields fault-revealing yet realistic test cases, and for run-time monitoring provides an independent means to assess trustability of the target system's output.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {97–100},
numpages = {4},
keywords = {variational autoencoder, neural networks, machine learning testing},
location = {Seoul, South Korea},
series = {ICSE-NIER '20}
}

@article{10.1016/j.cose.2021.102459,
author = {Zhao, Jinxiong and Guo, Sensen and Mu, Dejun},
title = {DouBiGRU-A: Software defect detection algorithm based on attention mechanism and double BiGRU},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {111},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2021.102459},
doi = {10.1016/j.cose.2021.102459},
journal = {Comput. Secur.},
month = dec,
numpages = {10},
keywords = {Flawfinder, RATS, Vulnerability identification, Software defect detection, DouBiGRU-A}
}

@inproceedings{10.1145/3368089.3417043,
author = {Ahmed, Md Sohel and Ishikawa, Fuyuki and Sugiyama, Mahito},
title = {Testing machine learning code using polyhedral region},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3417043},
doi = {10.1145/3368089.3417043},
abstract = {To date, although machine learning has been successful in various practical applications, generic methods of testing machine learning code have not been established yet. Here we present a new approach to test machine learning code using the possible input region obtained as a polyhedron. If an ML system generates different output for multiple input in the polyhedron, it is ensured that there exists a bug in the code. This property is known as one of theoretical fundamentals in statistical inference, for example, sparse regression models such as the lasso, and a wide range of machine learning algorithms satisfy this polyhedral condition, to which our testing procedure can be applied. We empirically show that the existence of bugs in lasso code can be effectively detected by our method in the mutation testing framework.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1533–1536},
numpages = {4},
keywords = {Testing, Polyhedral region, Mutation Analysis, Machine learning code, Lasso},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/1868328.1868350,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
title = {On the value of learning from defect dense components for software defect prediction},
year = {2010},
isbn = {9781450304047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868328.1868350},
doi = {10.1145/1868328.1868350},
abstract = {BACKGROUND: Defect predictors learned from static code measures can isolate code modules with a higher than usual probability of defects.AIMS: To improve those learners by focusing on the defect-rich portions of the training sets.METHOD: Defect data CM1, KC1, MC1, PC1, PC3 was separated into components. A subset of the projects (selected at random) were set aside for testing. Training sets were generated for a NaiveBayes classifier in two ways. In sample the dense treatment, the components with higher than the median number of defective modules were used for training. In the standard treatment, modules from any component were used for training. Both samples were run against the test set and evaluated using recall, probability of false alarm, and precision. In addition, under sampling and over sampling was performed on the defect data. Each method was repeated in a 10-by-10 cross-validation experiment.RESULTS: Prediction models learned from defect dense components out-performed standard method, under sampling, as well as over sampling. In statistical rankings based on recall, probability of false alarm, and precision, models learned from dense components won 4--5 times more often than any other method, and also lost the least amount of times.CONCLUSIONS: Given training data where most of the defects exist in small numbers of components, better defect predictors can be trained from the defect dense components.},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
articleno = {14},
numpages = {9},
keywords = {ceiling effect, defect dense components, defect prediction, sampling},
location = {Timi\c{s}oara, Romania},
series = {PROMISE '10}
}

@inproceedings{10.1007/978-3-030-63799-6_20,
author = {Johnson, Colin G.},
title = {Software Fault Localisation via Probabilistic Modelling},
year = {2020},
isbn = {978-3-030-63798-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63799-6_20},
doi = {10.1007/978-3-030-63799-6_20},
abstract = {Software development is a complex activity requiring intelligent action. This paper explores the use of an AI technique for one step in software development, viz. detecting the location of a fault in a program. A measure of program progress is proposed, which uses a Na\"{\i}ve Bayes model to measure how useful the information that has been produced by the program to the task that the program is tackling. Then, deviations in that measure are used to find the location of faults in the code. Experiments are carried out to test the effectiveness of this measure.},
booktitle = {Artificial Intelligence XXXVII: 40th SGAI International Conference on Artificial Intelligence, AI 2020, Cambridge, UK, December 15–17, 2020, Proceedings},
pages = {259–272},
numpages = {14},
keywords = {Na\"{\i}ve Bayes, Bug finding, Software development},
location = {Cambridge, United Kingdom}
}

@inproceedings{10.1109/CEC.2017.7969629,
author = {Ibarguren, Igor and P\'{e}rez, Jes\'{u}s M. and Mugerza, Javier and Rodriguez, Daniel and Harrison, Rachel},
title = {The Consolidated Tree Construction algorithm in imbalanced defect prediction datasets},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC.2017.7969629},
doi = {10.1109/CEC.2017.7969629},
abstract = {In this short paper, we compare well-known rule/tree classifiers in software defect prediction with the CTC decision tree classifier designed to deal with class imbalanced. It is well-known that most software defect prediction datasets are highly imbalance (non-defective instances outnumber defective ones). In this work, we focused only on tree/rule classifiers as these are capable of explaining the decision, i.e., describing the metrics and thresholds that make a module error prone. Furthermore, rules/decision trees provide the advantage that they are easily understood and applied by project managers and quality assurance personnel. The CTC algorithm was designed to cope with class imbalance and noisy datasets instead of using preprocessing techniques (oversampling or undersampling), ensembles or cost weights of misclassification. The experimental work was carried out using the NASA datasets and results showed that induced CTC decision trees performed better or similar to the rest of the rule/tree classifiers.},
booktitle = {2017 IEEE Congress on Evolutionary Computation (CEC)},
pages = {2656–2660},
numpages = {5},
location = {Donostia, San Sebasti\'{a}n, Spain}
}

@inproceedings{10.1109/ICMLA.2012.226,
author = {Hall, Tracy and Bowes, David},
title = {The State of Machine Learning Methodology in Software Fault Prediction},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.226},
doi = {10.1109/ICMLA.2012.226},
abstract = {The aim of this paper is to investigate the quality of methodology in software fault prediction studies using machine learning. Over two hundred studies of fault prediction have been published in the last 10 years. There is evidence to suggest that the quality of methodology used in some of these studies does not allow us to have confidence in the predictions reported by them. We evaluate the machine learning methodology used in 21 fault prediction studies. All of these studies use NASA data sets. We score each study from 1 to 10 in terms of the quality of their machine learning methodology (e.g. whether or not studies report randomising their cross validation folds). Only 10 out of the 21 studies scored 5 or more out of 10. Furthermore 1 study scored only 1 out of 10. When we plot these scores over time there is no evidence that the quality of machine learning methodology is better in recent studies. Our results suggest that there remains much to be done by both researchers and reviewers to improve the quality of machine learning methodology used in software fault prediction. We conclude that the results reported in some studies need to be treated with caution.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 02},
pages = {308–313},
numpages = {6},
keywords = {software engineering, methodology, machine learning, fault prediction, experimental techniques},
series = {ICMLA '12}
}

@article{10.1016/j.future.2019.09.009,
author = {Lopes, F\'{a}bio and Agnelo, Jo\~{a}o and Teixeira, C\'{e}sar A. and Laranjeiro, Nuno and Bernardino, Jorge},
title = {Automating orthogonal defect classification using machine learning algorithms},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {102},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.09.009},
doi = {10.1016/j.future.2019.09.009},
journal = {Future Gener. Comput. Syst.},
month = jan,
pages = {932–947},
numpages = {16},
keywords = {Text classification, Machine learning, Orthogonal defect classification, Bug reports, Software defects}
}

@phdthesis{10.5555/AAI28773561,
author = {Pan, Renjian and Krishnendu, Chakrabarty, and Yiran, Chen, and Hai, Li, and Qiang, Qiu,},
advisor = {Xin, Li,},
title = {Applying Machine Learning to Testing and Diagnosis of Integrated Systems},
year = {2021},
isbn = {9798780614135},
publisher = {Duke University},
address = {USA},
abstract = {The growing complexity of integrated boards and systems makes manufacturing test and diagnosis increasingly expensive. There is a pressing need to reduce test cost and to pinpoint the root causes of integrated systems in a more effective way. In light of machine learning, a number of intelligent test-cost reduction and root-cause analysis methods have been proposed. However, it remains extremely challenging to (i) reduce test cost for black-box testing for integrated systems, and (ii) pinpoint the root causes for integrated systems with little need on labeled test data from repair history. To tackle these challenges, we propose multiple machine-learning-based solutions for black-box test-cost reduction and unsupervised/semi-supervised root-cause analysis in this dissertation.For black-box test-cost reduction, we propose a novel test selection method based on a Bayesian network model. First, it is formulated as a constrained optimization problem. Next, a score-based algorithm is implemented to construct the Bayesian network for black-box tests. Finally, we propose a Bayesian index with the property of Markov blankets, and then an iterative test selection method is developed based on our proposed Bayesian index.For root-cause analysis, we first propose an unsupervised root-cause analysis method in which no repair history is needed. In the first stage, a decision-tree model is trained with system test information to cluster the data in a coarse-grained manner. In the second stage, frequent-pattern mining is applied to extract frequent patterns in each decision-tree node to precisely cluster the data so that each cluster represents only a small number of root causes. The proposed method can accommodate both numerical and categorical test items. A combination of the L-method, cross validation and Silhouette score enables us to automatically determine all hyper-parameters. Two industry case studies with system test data demonstrate that the proposed approach significantly outperforms the state-of-the-art unsupervised root-cause-analysis method.Utilizing transfer learning, we further improve the performance of unsupervised root-cause-analysis. A two-stage clustering method is first developed by exploiting model selection based on the concept of Silhouette score. Next, a data-selection method based on ensemble learning is proposed to transfer valuable information from a source product to improve the diagnosis accuracy on the target product with insufficient data. Two case studies based on industry designs demonstrate that the proposed approach significantly outperforms other state-of-the-art unsupervised root-cause-analysis methods.In addition, we propose a semi-supervised root-cause-analysis method with co-training, where only a small set of labeled data is required. Using random forest as the learning kernel, a co-training technique is proposed to leverage the unlabeled data by automatically pre-labeling a subset of them and retraining each decision tree. In addition, several novel techniques have been proposed to avoid over-fitting and determine hyper-parameters. Two case studies based on industrial designs demonstrate that the proposed approach significantly outperforms the state-of-the-art methods.In summary, this dissertation addresses the most difficult problems in testing and diagnosis of integrated systems with machine learning. A test selection method based on Bayesian networks reduces the test cost for black-box testing. With unsupervised learning, semi-supervised learning and transfer learning, we analysis root causes for integrated systems without much need on historical diagnosis information. The proposed approaches are expected to contribute to the semiconductor industry by effectively reducing the black-box test cost and efficiently diagnosing the integrated systems.},
note = {AAI28773561}
}

@article{10.1155/2020/6688075,
author = {Naseem, Rashid and Khan, Bilal and Ahmad, Arshad and Almogren, Ahmad and Jabeen, Saima and Hayat, Bashir and Shah, Muhammad Arif and Uddin, M. Irfan},
title = {Investigating Tree Family Machine Learning Techniques for a Predictive System to Unveil Software Defects},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1076-2787},
url = {https://doi.org/10.1155/2020/6688075},
doi = {10.1155/2020/6688075},
abstract = {Software defects prediction at the initial period of the software development life cycle remains a critical and important assignment. Defect prediction and correctness leads to the assurance of the quality of software systems and has remained integral to study in the previous years. The quick forecast of imperfect or defective modules in software development can serve the development squad to use the existing assets competently and effectively to provide remarkable software products in a given short timeline. Hitherto, several researchers have industrialized defect prediction models by utilizing statistical and machine learning techniques that are operative and effective approaches to pinpoint the defective modules. Tree family machine learning techniques are well-thought-out to be one of the finest and ordinarily used supervised learning methods. In this study, different tree family machine learning techniques are employed for software defect prediction using ten benchmark datasets. These techniques include Credal Decision Tree (CDT), Cost-Sensitive Decision Forest (CS-Forest), Decision Stump (DS), Forest by Penalizing Attributes (Forest-PA), Hoeffding Tree (HT), Decision Tree (J48), Logistic Model Tree (LMT), Random Forest (RF), Random Tree (RT), and REP-Tree (REP-T). Performance of each technique is evaluated using different measures, i.e., mean absolute error (MAE), relative absolute error (RAE), root mean squared error (RMSE), root relative squared error (RRSE), specificity, precision, recall, F-measure (FM), G-measure (GM), Matthew’s correlation coefficient (MCC), and accuracy. The overall outcomes of this paper suggested RF technique by producing best results in terms of reducing error rates as well as increasing accuracy on five datasets, i.e., AR3, PC1, PC2, PC3, and PC4. The average accuracy achieved by RF is 90.2238%. The comprehensive outcomes of this study can be used as a reference point for other researchers. Any assertion concerning the enhancement in prediction through any new model, technique, or framework can be benchmarked and verified.},
journal = {Complex.},
month = jan,
numpages = {21}
}

@article{10.1016/j.asoc.2016.04.009,
author = {Ryu, Duksan and Baik, Jongmoon},
title = {Effective multi-objective nave Bayes learning for cross-project defect prediction},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.04.009},
doi = {10.1016/j.asoc.2016.04.009},
abstract = {Display Omitted We propose novel multi-objective learning techniques considering the class imbalance context for cross-project defect prediction.The proposed approaches (i.e., MONB and MONBNN) show the better diversity compared to existing multi-objective prediction models.The proposed approaches show the similar prediction performance compared to within-project defect prediction models. Software defect prediction predicts fault-prone modules which will be tested thoroughly. Thereby, limited quality control resources can be allocated effectively on them. Without sufficient local data, defects can be predicted via cross-project defect prediction (CPDP) utilizing data from other projects to build a classifier. Software defect datasets have the class imbalance problem, indicating the defect class has much fewer instances than the non-defect class does. Unless defect instances are predicted correctly, software quality could be degraded. In this context, a classifier requires to provide high accuracy of the defect class without severely worsening the accuracy of the non-defect class. This class imbalance principle seamlessly connects to the purpose of the multi-objective (MO) optimization in that MO predictive models aim at balancing many of the competing objectives. In this paper, we target to identify effective multi-objective learning techniques under cross-project (CP) environments. Three objectives are devised considering the class imbalance context. The first objective is to maximize the probability of detection (PD). The second objective is to minimize the probability of false alarm (PF). The third objective is to maximize the overall performance (e.g., Balance). We propose novel MO naive Bayes learning techniques modeled by a Harmony Search meta-heuristic algorithm. Our approaches are compared with single-objective models, other existing MO models and within-project defect prediction models. The experimental results show that the proposed approaches are promising. As a result, they can be effectively applied to satisfy various prediction needs under CP settings.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1062–1077},
numpages = {16},
keywords = {Search-based software engineering, Multi-objective optimization, Harmony Search, Cross-project defect prediction, Class imbalance}
}

@article{10.1145/3183339,
author = {Zhou, Yuming and Yang, Yibiao and Lu, Hongmin and Chen, Lin and Li, Yanhui and Zhao, Yangyang and Qian, Junyan and Xu, Baowen},
title = {How Far We Have Progressed in the Journey? An Examination of Cross-Project Defect Prediction},
year = {2018},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3183339},
doi = {10.1145/3183339},
abstract = {Background. Recent years have seen an increasing interest in cross-project defect prediction (CPDP), which aims to apply defect prediction models built on source projects to a target project. Currently, a variety of (complex) CPDP models have been proposed with a promising prediction performance.Problem. Most, if not all, of the existing CPDP models are not compared against those simple module size models that are easy to implement and have shown a good performance in defect prediction in the literature.Objective. We aim to investigate how far we have really progressed in the journey by comparing the performance in defect prediction between the existing CPDP models and simple module size models.Method. We first use module size in the target project to build two simple defect prediction models, ManualDown and ManualUp, which do not require any training data from source projects. ManualDown considers a larger module as more defect-prone, while ManualUp considers a smaller module as more defect-prone. Then, we take the following measures to ensure a fair comparison on the performance in defect prediction between the existing CPDP models and the simple module size models: using the same publicly available data sets, using the same performance indicators, and using the prediction performance reported in the original cross-project defect prediction studies.Result. The simple module size models have a prediction performance comparable or even superior to most of the existing CPDP models in the literature, including many newly proposed models.Conclusion. The results caution us that, if the prediction performance is the goal, the real progress in CPDP is not being achieved as it might have been envisaged. We hence recommend that future studies should include ManualDown/ManualUp as the baseline models for comparison when developing new CPDP models to predict defects in a complete target project.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {1},
numpages = {51},
keywords = {unsupervised, supervised, model, cross-project, Defect prediction}
}

@article{10.1002/stvr.1570,
author = {Canfora, Gerardo and Lucia, Andrea De and Penta, Massimiliano Di and Oliveto, Rocco and Panichella, Annibale and Panichella, Sebastiano},
title = {Defect prediction as a multiobjective optimization problem},
year = {2015},
issue_date = {June 2015},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {25},
number = {4},
issn = {0960-0833},
url = {https://doi.org/10.1002/stvr.1570},
doi = {10.1002/stvr.1570},
abstract = {In this paper, we formalize the defect-prediction problem as a multiobjective optimization problem. Specifically, we propose an approach, coined as multiobjective defect predictor MODEP, based on multiobjective forms of machine learning techniques-logistic regression and decision trees specifically-trained using a genetic algorithm. The multiobjective approach allows software engineers to choose predictors achieving a specific compromise between the number of likely defect-prone classes or the number of defects that the analysis would likely discover effectiveness, and lines of code to be analysed/tested which can be considered as a proxy of the cost of code inspection. Results of an empirical evaluation on 10 datasets from the PROMISE repository indicate the quantitative superiority of MODEP with respect to single-objective predictors, and with respect to trivial baseline ranking classes by size in ascending or descending order. Also, MODEP outperforms an alternative approach for cross-project prediction, based on local prediction upon clusters of similar classes. Copyright © 2015John Wiley &amp; Sons, Ltd.},
journal = {Softw. Test. Verif. Reliab.},
month = jun,
pages = {426–459},
numpages = {34},
keywords = {multiobjective optimization, defect prediction, cross-project defect prediction, cost-effectiveness}
}

@inproceedings{10.5555/3507788.3507798,
author = {Khan, Md Asif and Azim, Akramul and Liscano, Ramiro and Smith, Kevin and Chang, Yee-Kang and Garcon, Sylvain and Tauseef, Qasim},
title = {Failure prediction using machine learning in IBM WebSphere liberty continuous integration environment},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {The growing complexity and dependencies of software have increased the importance of testing to ensure that frequent changes do not adversely affect existing functionality. Moreover, continuous integration comes with unique challenges associated with maintaining a stable build environment. Several studies have shown that the testing environment becomes more efficient with proper test case prioritization techniques. However, an application's dynamic behavior makes it challenging to derive test case prioritization techniques for achieving optimal results. With the advance of machine learning, the context of an application execution can be analyzed to select and prioritize test suites more efficiently.Test suite prioritization techniques aim to reorder test suites' execution to deliver high quality, maintainable software at lower costs to meet specific objectives such as revealing failures earlier. The state-of-the-art techniques on test prioritization in a continuous integration environment focus on relatively small, single-language, unit-tested projects. This paper compares and analyzes Machine learning-based test suite prioritization technique on two large-scale dataset collected from a continuous integration environment Google and IBM respectively. We optimize hyperparameters and report on experiments' findings by using different machine learning algorithms for test suite prioritization. Our optimized algorithms prioritize test suites with 93% accuracy on average and require 20% fewer test suites to detect 80% of the failures than the test suites prioritized randomly.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {63–72},
numpages = {10},
keywords = {test prioritization, machine learning, continuous integration, CI},
location = {Toronto, Canada},
series = {CASCON '21}
}

@inproceedings{10.1145/3368089.3418538,
author = {\v{C}egi\v{n}, J\'{a}n},
title = {Machine learning based test data generation for safety-critical software},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3418538},
doi = {10.1145/3368089.3418538},
abstract = {Unit testing focused on Modified Condition/Decision Coverage (MC/DC) criterion is essential in development safety-critical systems. However, design of test data that meets the MC/DC criterion currently needs detailed manual analysis of branching conditions in units under test by test engineers. Multiple state-of-art approaches exist with proven usage even in industrial projects. However, these approaches have multiple shortcomings, one of them being the Path explosion problem which has not been fully solved yet. Machine learning methods as meta-heuristic approximations can model behaviour of programs that are hard to test using traditional approaches, where the Path explosion problem does occur and thus could solve the limitations of the current state-of-art approaches. I believe, motivated by an ongoing collaboration with an industrial partner, that the machine learning methods could be combined with existing approaches to produce an approach suitable for testing of safety-critical projects.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1678–1681},
numpages = {4},
keywords = {unit testing, test data generation, machine learning, MC/DC criterion},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/3358331.3358376,
author = {Easttom, Chuck},
title = {A Methodological Approach to Weaponizing Machine Learning},
year = {2019},
isbn = {9781450372022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358331.3358376},
doi = {10.1145/3358331.3358376},
abstract = {The current literature is replete with studies involving the use of machine learning algorithms for defensive security implementations. For example, machine learning has been utilized to enhance antivirus software and intrusion detection systems. The use of machine learning in defensive cybersecurity operations is well documented. However, there is a substantial gap in the literature on the offensive use of machine learning. Particularly, use of machine learning algorithms to enhance cyber warfare operations. Cyber components to modern conflicts, whether those conflicts are cyber or kinetic warfare, are a fact of the modern international political landscape. It is a natural progression to explore applications of machine learning to cyber warfare, particularly weaponized malware.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Advanced Manufacturing},
articleno = {45},
numpages = {5},
keywords = {weaponized malware, machine learning, cyber warfare, Weaponized malware},
location = {Dublin, Ireland},
series = {AIAM 2019}
}

@article{10.1002/smr.2238,
author = {Naeem, Muhammad Rashid and Lin, Tao and Naeem, Hamad and Liu, Hailu},
title = {A machine learning approach for classification of equivalent mutants},
year = {2020},
issue_date = {May 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {32},
number = {5},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2238},
doi = {10.1002/smr.2238},
abstract = {Mutation testing is a fault‐based technique to test the quality of test suites by inducing artificial syntactic faults or mutants in a source program. However, some mutants have the same semantics as original program and cannot be detected by any test suite input known as equivalent mutants. Equivalent mutant problem (EMP) is undecidable as it requires manual human effort to identify a mutant as equivalent or killable. The constraint‐based testing (CBT) theory suggests the use of mathematical constraints which can help reveal some equivalent mutants using mutant features. In this paper, we consider three metrics of CBT theory, ie, reachability, necessity, and sufficiency to extract feature constraints from mutant programs. Constraints are extracted using program dependency graphs. Other features such as degree of significance, semantic distance, and information entropy of mutants are also extracted to build a binary classification model. Machine learning algorithms such as Random Forest, GBT, and SVM are applied under two application scenarios (split‐project and cross‐project) on ten Java programs to predict equivalent mutants. The analysis of the study demonstrates that that the proposed techniques not only improves the efficiency of the equivalent mutant detection but also reduces the effort required to perform it with small accuracy loss.},
journal = {J. Softw. Evol. Process},
month = apr,
numpages = {32},
keywords = {static analysis, program semantics, mutation testing, machine learning, equivalent mutants}
}

@article{10.1007/s10766-021-00707-0,
author = {\"{O}z, I\c{s}\i{}l and Arslan, Sanem},
title = {Predicting the Soft Error Vulnerability of Parallel Applications Using Machine Learning},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {3},
issn = {0885-7458},
url = {https://doi.org/10.1007/s10766-021-00707-0},
doi = {10.1007/s10766-021-00707-0},
abstract = {With the widespread use of the multicore systems having smaller transistor sizes, soft errors become an important issue for parallel program execution. Fault injection is a prevalent method to quantify the soft error rates of the applications. However, it is very time consuming to perform detailed fault injection experiments. Therefore, prediction-based techniques have been proposed to evaluate the soft error vulnerability in a faster way. In this work, we present a soft error vulnerability prediction approach for parallel applications using machine learning algorithms. We define a set of features including thread communication, data sharing, parallel programming, and performance characteristics; and train our models based on three ML algorithms. This study uses the parallel programming features, as well as the combination of all features for the first time in vulnerability prediction of parallel programs. We propose two models for the soft error vulnerability prediction: (1) A regression model with rigorous feature selection analysis that estimates correct execution rates, (2) A novel classification model that predicts the vulnerability level of the target programs. We get maximum prediction accuracy rate of 73.2% for the regression-based model, and achieve 89% F-score for our classification model.},
journal = {Int. J. Parallel Program.},
month = jun,
pages = {410–439},
numpages = {30},
keywords = {Machine Learning, Parallel programming, Fault injection, Soft error analysis}
}

@phdthesis{10.5555/AAI28772454,
author = {Stewart, Michael Allen and J., Laszlo, Michael and Sumitra, Mukherjee,},
advisor = {J, Mitropoulos, Francisco},
title = {Increasing Software Reliability Using Mutation Testing and Machine Learning},
year = {2021},
isbn = {9798492722906},
publisher = {Nova Southeastern University},
abstract = {Mutation testing is a type of software testing proposed in the 1970s where program statements are deliberately changed to introduce simple errors so that test cases can be validated to determine if they can detect the errors. The goal of mutation testing was to reduce complex program errors by preventing the related simple errors. Test cases are executed against the mutant code to determine if one fails, detects the error and ensures the program is correct. One major issue with this type of testing was it became intensive computationally to generate and test all possible mutations for complex programs.This dissertation used machine learning for the selection of mutation operators that reduced the computational cost of testing and improved test suite effectiveness. The goals were to produce mutations that were more resistant to test cases, improve test case evaluation, validate then improve the test suite's effectiveness, realize cost reductions by generating fewer mutations for testing and improving software reliability by detecting more errors. To accomplish these goals, experiments were conducted using sample programs to determine how well the reinforcement learning based algorithm performed with one live mutation, multiple live mutations and no live mutations. The experiments, measured by mutation score, were used to update the algorithm and improved accuracy for predictions. The performance was then evaluated on multiple processor computers.One key result from this research was the development of a reinforcement algorithm to identify mutation operator combinations that resulted in live mutants. During experimentation, the reinforcement learning algorithm identified the optimal mutation operator selections for various programs and test suite scenarios, as well as determined that by using parallel processing and multiple cores the reinforcement learning process for mutation operator selection was practical. With reinforcement learning the mutation operators utilized were reduced by 50–100%. In conclusion, these improvements created a 'live' mutation testing process that evaluated various mutation operators and generated mutants to perform real-time mutation testing while dynamically prioritizing mutation operator recommendations. This has enhanced the software developer's ability to improve testing processes. The contributions of this paper's research supported the shift-left testing approach, where testing is performed earlier in the software development cycle when error resolution is less costly.},
note = {AAI28772454}
}

@inproceedings{10.1145/3460319.3464844,
author = {Dutta, Saikat and Selvam, Jeeva and Jain, Aryaman and Misailovic, Sasa},
title = {TERA: optimizing stochastic regression tests in machine learning projects},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464844},
doi = {10.1145/3460319.3464844},
abstract = {The stochastic nature of many Machine Learning (ML) algorithms makes testing of ML tools and libraries challenging. ML algorithms allow a developer to control their accuracy and run-time through a set of hyper-parameters, which are typically manually selected in tests. This choice is often too conservative and leads to slow test executions, thereby increasing the cost of regression testing.  We propose TERA, the first automated technique for reducing the cost of regression testing in Machine Learning tools and libraries(jointly referred to as projects) without making the tests more flaky. TERA solves the problem of exploring the trade-off space between execution time of the test and its flakiness as an instance of Stochastic Optimization over the space of algorithm hyper-parameters. TERA presents how to leverage statistical convergence-testing techniques to estimate the level of flakiness of the test for a specific choice of hyper-parameters during optimization.  We evaluate TERA on a corpus of 160 tests selected from 15 popular machine learning projects. Overall, TERA obtains a geo-mean speedup of 2.23x over the original tests, for the minimum passing probability threshold of 99%. We also show that the new tests did not reduce fault detection ability through a mutation study and a study on a set of 12 historical build failures in studied projects.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {413–426},
numpages = {14},
keywords = {Test Optimization, Software Testing, Machine Learning, Bayesian Optimization},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1145/2908812.2908938,
author = {Panichella, Annibale and Alexandru, Carol V. and Panichella, Sebastiano and Bacchelli, Alberto and Gall, Harald C.},
title = {A Search-based Training Algorithm for Cost-aware Defect Prediction},
year = {2016},
isbn = {9781450342063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2908812.2908938},
doi = {10.1145/2908812.2908938},
abstract = {Research has yielded approaches to predict future defects in software artifacts based on historical information, thus assisting companies in effectively allocating limited development resources and developers in reviewing each others' code changes. Developers are unlikely to devote the same effort to inspect each software artifact predicted to contain defects, since the effort varies with the artifacts' size (cost) and the number of defects it exhibits (effectiveness). We propose to use Genetic Algorithms (GAs) for training prediction models to maximize their cost-effectiveness. We evaluate the approach on two well-known models, Regression Tree and Generalized Linear Model, and predict defects between multiple releases of six open source projects. Our results show that regression models trained by GAs significantly outperform their traditional counterparts, improving the cost-effectiveness by up to 240%. Often the top 10% of predicted lines of code contain up to twice as many defects.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference 2016},
pages = {1077–1084},
numpages = {8},
keywords = {machine learning, genetic algorithm, defect prediction},
location = {Denver, Colorado, USA},
series = {GECCO '16}
}

@inproceedings{10.1007/978-3-030-33607-3_12,
author = {Shepperd, Martin and Guo, Yuchen and Li, Ning and Arzoky, Mahir and Capiluppi, Andrea and Counsell, Steve and Destefanis, Giuseppe and Swift, Stephen and Tucker, Allan and Yousefi, Leila},
title = {The Prevalence of Errors in Machine Learning Experiments},
year = {2019},
isbn = {978-3-030-33606-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33607-3_12},
doi = {10.1007/978-3-030-33607-3_12},
abstract = {Context: Conducting experiments is central to research machine learning research to benchmark, evaluate and compare learning algorithms. Consequently it is important we conduct reliable, trustworthy experiments.Objective: We investigate the incidence of errors in a sample of machine learning experiments in the domain of software defect prediction. Our focus is simple arithmetical and statistical errors.Method: We analyse 49 papers describing 2456 individual experimental results from a previously undertaken systematic review comparing supervised and unsupervised defect prediction classifiers. We extract the confusion matrices and test for relevant constraints, e.g., the marginal probabilities must sum to one. We also check for multiple statistical significance testing errors.Results: We find that a total of 22 out of 49 papers contain demonstrable errors. Of these 7 were statistical and 16 related to confusion matrix inconsistency (one paper contained both classes of error).Conclusions: Whilst some errors may be of a relatively trivial nature, e.g., transcription errors their presence does not engender confidence. We strongly urge researchers to follow open science principles so errors can be more easily be detected and corrected, thus as a community reduce this worryingly high error rate with our computational experiments.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2019: 20th International Conference, Manchester, UK, November 14–16, 2019, Proceedings, Part I},
pages = {102–109},
numpages = {8},
keywords = {Classifier, Computational experiment, Reliability, Error},
location = {Manchester, United Kingdom}
}

@inproceedings{10.1109/ICSE43902.2021.00138,
author = {Wang, Song and Shrestha, Nishtha and Subburaman, Abarna Kucheri and Wang, Junjie and Wei, Moshi and Nagappan, Nachiappan},
title = {Automatic Unit Test Generation for Machine Learning Libraries: How Far Are We?},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00138},
doi = {10.1109/ICSE43902.2021.00138},
abstract = {Automatic unit test generation that explores the input space and produces effective test cases for given programs have been studied for decades. Many unit test generation tools that can help generate unit test cases with high structural coverage over a program have been examined. However, the fact that existing test generation tools are mainly evaluated on general software programs calls into question about its practical effectiveness and usefulness for machine learning libraries, which are statistically-orientated and have fundamentally different nature and construction from general software projects.In this paper, we set out to investigate the effectiveness of existing unit test generation techniques on machine learning libraries. To investigate this issue, we conducted an empirical study on five widely-used machine learning libraries with two popular unit test case generation tools, i.e., EVOSUITE and Randoop. We find that (1) most of the machine learning libraries do not maintain a high-quality unit test suite regarding commonly applied quality metrics such as code coverage (on average is 34.1%) and mutation score (on average is 21.3%), (2) unit test case generation tools, i.e., EVOSUITE and Randoop, lead to clear improvements in code coverage and mutation score, however, the improvement is limited, and (3) there exist common patterns in the uncovered code across the five machine learning libraries that can be used to improve unit test case generation tasks.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1548–1560},
numpages = {13},
keywords = {testing machine learning libraries, test case generation, Empirical software engineering},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1007/s11219-014-9241-7,
author = {Madeyski, Lech and Jureczko, Marian},
title = {Which process metrics can significantly improve defect prediction models? An empirical study},
year = {2015},
issue_date = {September 2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-014-9241-7},
doi = {10.1007/s11219-014-9241-7},
abstract = {The knowledge about the software metrics which serve as defect indicators is vital for the efficient allocation of resources for quality assurance. It is the process metrics, although sometimes difficult to collect, which have recently become popular with regard to defect prediction. However, in order to identify rightly the process metrics which are actually worth collecting, we need the evidence validating their ability to improve the product metric-based defect prediction models. This paper presents an empirical evaluation in which several process metrics were investigated in order to identify the ones which significantly improve the defect prediction models based on product metrics. Data from a wide range of software projects (both, industrial and open source) were collected. The predictions of the models that use only product metrics (simple models) were compared with the predictions of the models which used product metrics, as well as one of the process metrics under scrutiny (advanced models). To decide whether the improvements were significant or not, statistical tests were performed and effect sizes were calculated. The advanced defect prediction models trained on a data set containing product metrics and additionally Number of Distinct Committers (NDC) were significantly better than the simple models without NDC, while the effect size was medium and the probability of superiority (PS) of the advanced models over simple ones was high (  $$p=.016$$ p = . 016 ,  $$r=-.29$$ r = - . 29 ,  $$hbox {PS}=.76$$ PS = . 76 ), which is a substantial finding useful in defect prediction. A similar result with slightly smaller PS was achieved by the advanced models trained on a data set containing product metrics and additionally all of the investigated process metrics (  $$p=.038$$ p = . 038 ,  $$r=-.29$$ r = - . 29 ,  $$hbox {PS}=.68$$ PS = . 68 ). The advanced models trained on a data set containing product metrics and additionally Number of Modified Lines (NML) were significantly better than the simple models without NML, but the effect size was small (  $$p=.038$$ p = . 038 ,  $$r=.06$$ r = . 06 ). Hence, it is reasonable to recommend the NDC process metric in building the defect prediction models.},
journal = {Software Quality Journal},
month = sep,
pages = {393–422},
numpages = {30},
keywords = {Software metrics, Software defect prediction, Product metrics, Process metrics, Defect prediction models}
}

@inproceedings{10.5555/3432601.3432605,
author = {Krishnakumar, Sanjena and Abdou, Tamer},
title = {Towards interpretable and maintainable supervised learning using shapley values in arrhythmia},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {This paper investigates the application of a model-agnostic interpretability technique, Shapley Additive Explanations (SHAP), to understand and hence, enhance machine learning classification models using Shapley values in the prediction of arrhythmias1. Using the Arrhythmia dataset2, three different feature selection techniques, Information Gain (IG), Recursive Feature Elimination-Random Forest (RFE-RF), and AutoSpearman, were used to select features for machine learning models to predict the arrhythmia class. Four multi-class classification models, Na\"{\i}ve Bayes (NB), k-Nearest Neighbours (kNN), Random Forest (RF), and stacking heterogeneous ensemble (Ensemble) were built, evaluated, and compared. SHAP interpretation method was applied to find reliable explanations for the predictions of the classification models. Additionally, SHAP values were used to find `bellwether' instances to enhance the training of our models in order to improve their performances in the prediction of arrhythmia. The most stable and top-performing classification model was RF, followed by Ensemble in comparison to NB and kNN. SHAP provided robust and reliable explanations for the classification models. Furthermore, improving the training of our models with `bellwether' instances, found using SHAP values, enhanced the overall model performances in terms of accuracy, AUC, and F1 score. In conclusion, we recommend using SHAP value explanations as a robust and reliable method for local model-agnostic interpretability and to enhance machine learning models for arrhythmia prediction.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {23–32},
numpages = {10},
keywords = {shapley value, multi-class classification, machine learning, local model-agnostic interpretation, healthcare, bellwether, arrhythmia, SHAP, LIME},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@article{10.1007/s10664-020-09881-0,
author = {Riccio, Vincenzo and Jahangirova, Gunel and Stocco, Andrea and Humbatova, Nargiz and Weiss, Michael and Tonella, Paolo},
title = {Testing machine learning based systems: a systematic mapping},
year = {2020},
issue_date = {Nov 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09881-0},
doi = {10.1007/s10664-020-09881-0},
journal = {Empirical Softw. Engg.},
month = nov,
pages = {5193–5254},
numpages = {62},
keywords = {Machine learning, Software testing, Systematic review, Systematic mapping}
}

@article{10.1007/s10515-011-0091-2,
author = {Liparas, Dimitris and Angelis, Lefteris and Feldt, Robert},
title = {Applying the Mahalanobis-Taguchi strategy for software defect diagnosis},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0091-2},
doi = {10.1007/s10515-011-0091-2},
abstract = {The Mahalanobis-Taguchi (MT) strategy combines mathematical and statistical concepts like Mahalanobis distance, Gram-Schmidt orthogonalization and experimental designs to support diagnosis and decision-making based on multivariate data. The primary purpose is to develop a scale to measure the degree of abnormality of cases, compared to "normal" or "healthy" cases, i.e. a continuous scale from a set of binary classified cases. An optimal subset of variables for measuring abnormality is then selected and rules for future diagnosis are defined based on them and the measurement scale. This maps well to problems in software defect prediction based on a multivariate set of software metrics and attributes. In this paper, the MT strategy combined with a cluster analysis technique for determining the most appropriate training set, is described and applied to well-known datasets in order to evaluate the fault-proneness of software modules. The measurement scale resulting from the MT strategy is evaluated using ROC curves and shows that it is a promising technique for software defect diagnosis. It compares favorably to previously evaluated methods on a number of publically available data sets. The special characteristic of the MT strategy that it quantifies the level of abnormality can also stimulate and inform discussions with engineers and managers in different defect prediction situations.},
journal = {Automated Software Engg.},
month = jun,
pages = {141–165},
numpages = {25},
keywords = {Software testing, Software defect prediction, Mahalanobis-Taguchi strategy, Fault-proneness}
}

@article{10.1016/j.compeleceng.2021.107362,
author = {P, Gouthaman and Sankaranarayanan, Suresh},
title = {Prediction of Risk Percentage in Software Projects by Training Machine Learning Classifiers},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {94},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107362},
doi = {10.1016/j.compeleceng.2021.107362},
journal = {Comput. Electr. Eng.},
month = sep,
numpages = {9},
keywords = {Risk prediction, Machine learning, Incremental, Evolutionary, Waterfall, Agile, Software model}
}

@inproceedings{10.1109/RAMS.2019.8768923,
author = {Cui, Can and Liu, Bin and Li, Guoqi},
title = {A Novel Feature Selection Method for Software Fault Prediction Model},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/RAMS.2019.8768923},
doi = {10.1109/RAMS.2019.8768923},
abstract = {Software fault prediction (SFP) is an active issue in software engineering (SE). At present, machine learning (ML) has been successfully applied to SFP classification problems. However, one of the challenges for building software fault prediction models (SFPM) is processing high dimensional datasets, which include many irrelevant and redundant features. To address this issue, feature selection techniques, mainly contain wrapper methods and filter methods, are used. In the paper, we report an empirical study aimed at providing a novel approach to select feature for SFP.},
booktitle = {2019 Annual Reliability and Maintainability Symposium (RAMS)},
pages = {1–6},
numpages = {6},
location = {Orlando, FL, USA}
}

@article{10.1007/s11227-018-2326-5,
author = {Kalsoom, Anum and Maqsood, Muazzam and Ghazanfar, Mustansar Ali and Aadil, Farhan and Rho, Seungmin},
title = {A dimensionality reduction-based efficient software fault prediction using Fisher linear discriminant analysis (FLDA)},
year = {2018},
issue_date = {Sep 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {74},
number = {9},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-018-2326-5},
doi = {10.1007/s11227-018-2326-5},
abstract = {Software quality is an important factor in the success of software companies. Traditional software quality assurance techniques face some serious limitations especially in terms of time and budget. This leads to increase in the use of machine learning classification techniques to predict software faults. Software fault prediction can help developers to uncover software problems in early stages of software life cycle. The extent to which these techniques can be generalized to different sizes of software, class imbalance problem, and identification of discriminative software metrics are the most critical challenges. In this paper, we have analyzed the performance of nine widely used machine learning classifiers--Bayes Net, NB, artificial neural network, support vector machines, K nearest neighbors, AdaBoost, Bagging, Zero R, and Random Forest for software fault prediction. Two standard sampling techniques--SMOTE and Resample with substitution are used to handle the class imbalance problem. We further used FLDA-based feature selection approach in combination with SMOTE and Resample to select most discriminative metrics. Then the top four classifiers based on performance are used for software fault prediction. The experimentation is carried out over 15 publically available datasets (small, medium and large) which are collected from PROMISE repository. The proposed Resample-FLDA method gives better performance as compared to existing methods in terms of precision, recall, f-measure and area under the curve.},
journal = {J. Supercomput.},
month = sep,
pages = {4568–4602},
numpages = {35},
keywords = {Software fault prediction, Robustness, Reliability, Fisher linear discriminant, Fault-tolerance}
}

@inproceedings{10.1145/2979779.2979783,
author = {Maheshwari, Suchi and Agarwal, Sonali},
title = {Three-way decision based Defect Prediction for Object Oriented Software},
year = {2016},
isbn = {9781450342131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2979779.2979783},
doi = {10.1145/2979779.2979783},
abstract = {Early prediction of defective software module plays critical role in the software project development to reduce the overall development time, budgets and increases the customer satisfaction. The bug prediction based on two-way classification method classifies the software module as defective or non-defective. This method provides good accuracy measure but this metric is not sufficient in case if misclassification cost is concerned. Classifying the defective module as non-defective will lead to higher cost of entire software project at the end. In this study, three-way decision based classification method and Random Forest ensemble are used to predict the defect in Object Oriented Software to reduce the misclassification cost which will lead to avoid the cost overrun. The eclipse bug prediction dataset is used and experimental results show that the decision cost is reduced and accuracy is increased using our proposed method.},
booktitle = {Proceedings of the International Conference on Advances in Information Communication Technology &amp; Computing},
articleno = {4},
numpages = {6},
keywords = {Three-way decision, Software defect prediction, Random Forest, Na\"{\i}ve Bayes, Eclipse Bug Prediction dataset},
location = {Bikaner, India},
series = {AICTC '16}
}

@inproceedings{10.1145/2786805.2804429,
author = {Kim, Mijung and Nam, Jaechang and Yeon, Jaehyuk and Choi, Soonhwang and Kim, Sunghun},
title = {REMI: defect prediction for efficient API testing},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2804429},
doi = {10.1145/2786805.2804429},
abstract = {Quality assurance for common APIs is important since the the reliability of APIs affects the quality of other systems using the APIs. Testing is a common practice to ensure the quality of APIs, but it is a challenging and laborious task especially for industrial projects. Due to a large number of APIs with tight time constraints and limited resources, it is hard to write enough test cases for all APIs. To address these challenges, we present a novel technique, REMI that predicts high risk APIs in terms of producing potential bugs. REMI allows developers to write more test cases for the high risk APIs. We evaluate REMI on a real-world industrial project, Tizen-wearable, and apply REMI to the API development process at Samsung Electronics. Our evaluation results show that REMI predicts the bug-prone APIs with reasonable accuracy (0.681 f-measure on average). The results also show that applying REMI to the Tizen-wearable development process increases the number of bugs detected, and reduces the resources required for executing test cases.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {990–993},
numpages = {4},
keywords = {Quality Assurance, Defect Prediction, API Testing},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.5555/2819009.2819026,
author = {Tan, Ming and Tan, Lin and Dara, Sashank and Mayeux, Caleb},
title = {Online defect prediction for imbalanced data},
year = {2015},
publisher = {IEEE Press},
abstract = {Many defect prediction techniques are proposed to improve software reliability. Change classification predicts defects at the change level, where a change is the modifications to one file in a commit. In this paper, we conduct the first study of applying change classification in practice.We identify two issues in the prediction process, both of which contribute to the low prediction performance. First, the data are imbalanced---there are much fewer buggy changes than clean changes. Second, the commonly used cross-validation approach is inappropriate for evaluating the performance of change classification. To address these challenges, we apply and adapt online change classification, resampling, and updatable classification techniques to improve the classification performance.We perform the improved change classification techniques on one proprietary and six open source projects. Our results show that these techniques improve the precision of change classification by 12.2-89.5% or 6.4--34.8 percentage points (pp.) on the seven projects. In addition, we integrate change classification in the development process of the proprietary project. We have learned the following lessons: 1) new solutions are needed to convince developers to use and believe prediction results, and prediction results need to be actionable, 2) new and improved classification algorithms are needed to explain the prediction results, and insensible and unactionable explanations need to be filtered or refined, and 3) new techniques are needed to improve the relatively low precision.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {99–108},
numpages = {10},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3341105.3374008,
author = {Zakurdaeva, Alla and Weiss, Michael and Muegge, Steven},
title = {Detecting architectural integrity violation patterns using machine learning},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3374008},
doi = {10.1145/3341105.3374008},
abstract = {Recent1 years have seen a surge of research into new ways of analyzing software quality. Specifically, a set of studies has been devoted to the impact the architectural relations among files have on system maintainability and file bug-proneness. The literature has proposed a set of rules for determining recurring architectural design flaws that occur in most complex systems, are associated with bugs, and thus incur high maintenance costs. In the present paper we advocate for using machine learning as the means of refining the approach and revealing new patterns of architectural integrity violations. Having trained a machine learning model on the combination of structural and historical information acquired from the Tiki open source project, we have been able to replicate three of the six known types of architectural violations and discover one new type, the Reverse Unstable Interface pattern. The implication of our study is that machine learning can provide valuable insights into the problem and discover novel patterns which would help software analysts to pinpoint specific architectural problems that may be the root causes of elevated bug- and change-proneness.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {1480–1487},
numpages = {8},
keywords = {software architecture, machine learning, hotspot patterns, bug-proneness, architectural flaws},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@article{10.1504/IJDATS.2017.10003991,
title = {Software fault proneness prediction: a comparative study between bagging, boosting, and stacking ensemble and base learner methods},
year = {2017},
issue_date = {January 2017},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {1},
issn = {1755-8050},
url = {https://doi.org/10.1504/IJDATS.2017.10003991},
doi = {10.1504/IJDATS.2017.10003991},
abstract = {Modules with defects might be the prime reason for decreasing the software quality and increasing the cost of maintenance. Therefore, the prediction of faulty modules of systems under test at early stages contributes to the overall quality of software products. In this research three symmetric ensemble methods: bagging, boosting and stacking are used to predict faulty modules based on evaluating the performance of 11 base learners. The results reveal that the defect prediction performance of the base learner classifier and ensemble learner classifiers is the same for na\"{\i}ve Bayes, Bayes net, PART, random forest, IB1, VFI, decision table, and NB tree base learners, the case was different for boosted SMO, bagged J48 and boosted and bagged random tree. In addition the results showed that the random forest classifier is one of the most significant classifiers that should be stacked with other classifiers to gain the better fault prediction.},
journal = {Int. J. Data Anal. Tech. Strateg.},
month = jan,
pages = {1–16},
numpages = {16}
}

@inproceedings{10.1145/1370750.1370759,
author = {Ratzinger, Jacek and Sigmund, Thomas and Gall, Harald C.},
title = {On the relation of refactorings and software defect prediction},
year = {2008},
isbn = {9781605580241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370750.1370759},
doi = {10.1145/1370750.1370759},
abstract = {This paper analyzes the influence of evolution activities such as refactoring on software defects. In a case study of five open source projects we used attributes of software evolution to predict defects in time periods of six months. We use versioning and issue tracking systems to extract 110 data mining features, which are separated into refactoring and non-refactoring related features. These features are used as input into classification algorithms that create prediction models for software defects. We found out that refactoring related features as well as non-refactoring related features lead to high quality prediction models. Additionally, we discovered that refactorings and defects have an inverse correlation: The number of software defects decreases, if the number of refactorings increased in the preceding time period. As a result, refactoring should be a significant part of both bug fixes and other evolutionary changes to reduce software defects.},
booktitle = {Proceedings of the 2008 International Working Conference on Mining Software Repositories},
pages = {35–38},
numpages = {4},
keywords = {software evolution, software analysis, mining},
location = {Leipzig, Germany},
series = {MSR '08}
}

@inproceedings{10.1109/ICCAD51958.2021.9643459,
author = {Tseng, Hsiao-Yin and Chiu, I-Wei and Wu, Mu-Ting and Li, James Chien-Mo},
title = {Machine Learning-Based Test Pattern Generation for Neuromorphic Chips},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICCAD51958.2021.9643459},
doi = {10.1109/ICCAD51958.2021.9643459},
abstract = {The demand for neuromorphic chips has skyrocketed in recent years. Thus, efficient manufacturing testing becomes an issue. Conventional testing cannot be applied because some neuromorphic chips do not have scan chains. However, traditional functional testing for neuromorphic chips suffers from long test length and low fault coverage. In this work, we propose a machine learning-based test pattern generation technique with behavior fault models. We use the concept of adversarial attack to generate test patterns to improve the fault coverage of existing functional test patterns. The effectiveness of the proposed technique is demonstrated on two Spiking Neural Network models trained on MNIST. Compared to traditional functional testing, our proposed technique reduces test length by 566x to 8,824x and improves fault coverage by 8.1% to 86.3% on five fault models. Finally, we propose a methodology to solve the scalability issue for the synapse fault models, resulting in 25.7x run time reduction on test pattern generation for synapse faults.},
booktitle = {2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)},
pages = {1–7},
numpages = {7},
location = {Munich, Germany}
}

@phdthesis{10.5555/AAI28256855,
author = {Wu, Baijun and Arun, Lakhotia, and Anthony, Maida, and Miao, Jin,},
advisor = {Sheng, Chen,},
title = {Using Machine Learning to Improve Programming Error Reporting},
year = {2020},
isbn = {9798519181839},
publisher = {University of Louisiana at Lafayette},
abstract = {The main purpose of this research is to explore applying machine learning to improve programming error reporting. In the first part of this dissertation, I present the empirical study about how type error were fixed and what students did. The investigation results demonstrate that current error debugging support is far from sufficient in practice, where the located error causes for more than 50% of type errors are incorrect and the corresponding change suggestions are ineffective. I provide a fundamental understanding of why existing error debuggers do not work well for nonstructural type errors. To address this issue, a machine learning-base type error debugger, Learnskell, is developed. The evaluations results show that Learnskell could locate the error causes for nonstructural type errors several times more accurate than the state-of-the-art tools. In the second part, I study how to precisely infer error specifications in C. Error specifications, which specify the value range that each function returns to indicate failures, are widely used to check and propagate errors for the sake of reliability and security. I propose a general method, MLPEx, that can automatically generate error specifications by analyzing only the source code. MLPEx utilizes the idea of transfer learning, and therefore requires zero manual efforts to label data during the learning process. Error specifications are useful to detect bugs. As one example, I present how the results of MLPEx can be used to find new error handling bugs in real-world projects.},
note = {AAI28256855}
}

@inproceedings{10.1145/2597073.2597078,
author = {Zhang, Feng and Mockus, Audris and Keivanloo, Iman and Zou, Ying},
title = {Towards building a universal defect prediction model},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597078},
doi = {10.1145/2597073.2597078},
abstract = {To predict files with defects, a suitable prediction model must be built for a software project from either itself (within-project) or other projects (cross-project). A universal defect prediction model that is built from the entire set of diverse projects would relieve the need for building models for an individual project. A universal model could also be interpreted as a basic relationship between software metrics and defects. However, the variations in the distribution of predictors pose a formidable obstacle to build a universal model. Such variations exist among projects with different context factors (e.g., size and programming language). To overcome this challenge, we propose context-aware rank transformations for predictors. We cluster projects based on the similarity of the distribution of 26 predictors, and derive the rank transformations using quantiles of predictors for a cluster. We then fit the universal model on the transformed data of 1,398 open source projects hosted on SourceForge and GoogleCode. Adding context factors to the universal model improves the predictive power. The universal model obtains prediction performance comparable to the within-project models and yields similar results when applied on five external projects (one Apache and four Eclipse projects). These results suggest that a universal defect prediction model may be an achievable goal.},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {182–191},
numpages = {10},
keywords = {rank transformation, quality, large scale, defect prediction, defect, context factors, bug, Universal defect prediction model},
location = {Hyderabad, India},
series = {MSR 2014}
}

@article{10.1016/j.scico.2021.102713,
author = {Jain, Shivani and Saha, Anju},
title = {Improving performance with hybrid feature selection and ensemble machine learning techniques for code smell detection},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {212},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2021.102713},
doi = {10.1016/j.scico.2021.102713},
journal = {Sci. Comput. Program.},
month = dec,
numpages = {34},
keywords = {Stacking, Hybrid feature selection, Ensemble machine learning, Machine learning, Code smell}
}

@inproceedings{10.1145/2889160.2889256,
author = {Tantithamthavorn, Chakkrit},
title = {Towards a better understanding of the impact of experimental components on defect prediction modelling},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889256},
doi = {10.1145/2889160.2889256},
abstract = {Defect prediction models are used to pinpoint risky software modules and understand past pitfalls that lead to defective modules. The predictions and insights that are derived from defect prediction models may not be accurate and reliable if researchers do not consider the impact of experimental components (e.g., datasets, metrics, and classifiers) of defect prediction modelling. Therefore, a lack of awareness and practical guidelines from previous research can lead to invalid predictions and unreliable insights. In this thesis, we investigate the impact that experimental components have on the predictions and insights of defect prediction models. Through case studies of systems that span both proprietary and open-source domains, we find that (1) noise in defect datasets; (2) parameter settings of classification techniques; and (3) model validation techniques have a large impact on the predictions and insights of defect prediction models, suggesting that researchers should carefully select experimental components in order to produce more accurate and reliable defect prediction models.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {867–870},
numpages = {4},
keywords = {experimental components, defect prediction modelling},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3195546.3206423,
author = {Hamou-Lhadj, Wahab and Nayrolles, Mathieu},
title = {A project on software defect prevention at commit-time: a success story of university-industry research collaboration},
year = {2018},
isbn = {9781450357449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195546.3206423},
doi = {10.1145/3195546.3206423},
abstract = {In this talk, we describe a research collaboration project between Concordia University and Ubisoft. The project consists of investigating techniques for defect prevention at commit-time for increased software quality. The outcome of this project is a tool called CLEVER (Combining Levels of Bug Prevention and Resolution techniques) that uses machine learning to automatically detect coding defects as programmers write code. The main novelty of CLEVER is that it relies on code matching techniques to detect coding mistakes based on a database of historical code defects found in multiple related projects. The tool also proposes fixes based on known patterns.},
booktitle = {Proceedings of the 5th International Workshop on Software Engineering Research and Industrial Practice},
pages = {24–25},
numpages = {2},
keywords = {university-industry research project, software maintenance and evolution, machine learning, bug prevention at commit-time},
location = {Gothenburg, Sweden},
series = {SER&amp;IP '18}
}

@article{10.1007/s10664-015-9396-2,
author = {Zhang, Feng and Mockus, Audris and Keivanloo, Iman and Zou, Ying},
title = {Towards building a universal defect prediction model with rank transformed predictors},
year = {2016},
issue_date = {October   2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9396-2},
doi = {10.1007/s10664-015-9396-2},
abstract = {Software defects can lead to undesired results. Correcting defects costs 50 % to 75 % of the total software development budgets. To predict defective files, a prediction model must be built with predictors (e.g., software metrics) obtained from either a project itself (within-project) or from other projects (cross-project). A universal defect prediction model that is built from a large set of diverse projects would relieve the need to build and tailor prediction models for an individual project. A formidable obstacle to build a universal model is the variations in the distribution of predictors among projects of diverse contexts (e.g., size and programming language). Hence, we propose to cluster projects based on the similarity of the distribution of predictors, and derive the rank transformations using quantiles of predictors for a cluster. We fit the universal model on the transformed data of 1,385 open source projects hosted on SourceForge and GoogleCode. The universal model obtains prediction performance comparable to the within-project models, yields similar results when applied on five external projects (one Apache and four Eclipse projects), and performs similarly among projects with different context factors. At last, we investigate what predictors should be included in the universal model. We expect that this work could form a basis for future work on building a universal model and would lead to software support tools that incorporate it into a regular development workflow.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {2107–2145},
numpages = {39},
keywords = {Universal defect prediction model, Software quality, Rank transformation, Large-scale, Defect prediction, Context factors}
}

@article{10.1007/s11704-020-9441-1,
author = {Sun, Xiaobing and Zhou, Tianchi and Wang, Rongcun and Duan, Yucong and Bo, Lili and Chang, Jianming},
title = {Experience report: investigating bug fixes in machine learning frameworks/libraries},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {6},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-020-9441-1},
doi = {10.1007/s11704-020-9441-1},
abstract = {Machine learning (ML) techniques and algorithms have been successfully and widely used in various areas including software engineering tasks. Like other software projects, bugs are also common in ML projects and libraries. In order to more deeply understand the features related to bug fixing in ML projects, we conduct an empirical study with 939 bugs from five ML projects by manually examining the bug categories, fixing patterns, fixing scale, fixing duration, and types of maintenance. The results show that (1) there are commonly seven types of bugs in ML programs; (2) twelve fixing patterns are typically used to fix the bugs in ML programs; (3) 68.80% of the patches belong to micro-scale-fix and small-scale-fix; (4) 66.77% of the bugs in ML programs can be fixed within one month; (5) 45.90% of the bug fixes belong to corrective activity from the perspective of software maintenance. Moreover, we perform a questionnaire survey and send them to developers or users of ML projects to validate the results in our empirical study. The results of our empirical study are basically consistent with the feedback from developers. The findings from the empirical study provide useful guidance and insights for developers and users to effectively detect and fix bugs in ML projects.},
journal = {Front. Comput. Sci.},
month = dec,
numpages = {16},
keywords = {questionnaire survey, empirical study, machine learning project, bug fixing}
}

@inproceedings{10.1145/2972958.2972964,
author = {Hosseini, Seyedrebvar and Turhan, Burak and M\"{a}ntyl\"{a}, Mika},
title = {Search Based Training Data Selection For Cross Project Defect Prediction},
year = {2016},
isbn = {9781450347723},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2972958.2972964},
doi = {10.1145/2972958.2972964},
abstract = {Context: Previous studies have shown that steered training data or dataset selection can lead to better performance for cross project defect prediction (CPDP). On the other hand, data quality is an issue to consider in CPDP.Aim: We aim at utilising the Nearest Neighbor (NN)-Filter, embedded in a genetic algorithm, for generating evolving training datasets to tackle CPDP, while accounting for potential noise in defect labels.Method: We propose a new search based training data (i.e., instance) selection approach for CPDP called GIS (Genetic Instance Selection) that looks for solutions to optimize a combined measure of F-Measure and GMean, on a validation set generated by (NN)-filter. The genetic operations consider the similarities in features and address possible noise in assigned defect labels. We use 13 datasets from PROMISE repository in order to compare the performance of GIS with benchmark CPDP methods, namely (NN)-filter and naive CPDP, as well as with within project defect prediction (WPDP).Results: Our results show that GIS is significantly better than (NN)-Filter in terms of F-Measure (p -- value ≪ 0.001, Cohen's d = 0.697) and GMean (p -- value ≪ 0.001, Cohen's d = 0.946). It also outperforms the naive CPDP approach in terms of F-Measure (p -- value ≪ 0.001, Cohen's d = 0.753) and GMean (p -- value ≪ 0.001, Cohen's d = 0.994). In addition, the performance of our approach is better than that of WPDP, again considering F-Measure (p -- value ≪ 0.001, Cohen's d = 0.227) and GMean (p -- value ≪ 0.001, Cohen's d = 0.595) values.Conclusions: We conclude that search based instance selection is a promising way to tackle CPDP. Especially, the performance comparison with the within project scenario encourages further investigation of our approach. However, the performance of GIS is based on high recall in the expense of low precision. Using different optimization goals, e.g. targeting high precision, would be a future direction to investigate.},
booktitle = {Proceedings of the The 12th International Conference on Predictive Models and Data Analytics in Software Engineering},
articleno = {3},
numpages = {10},
keywords = {Cross Project Defect Prediction, Genetic Algorithms, Instance Selection, Search Based Optimization, Training Data Selection},
location = {Ciudad Real, Spain},
series = {PROMISE 2016}
}

@article{10.1016/j.asoc.2019.02.008,
author = {Juneja, Kapil},
title = {A fuzzy-filtered neuro-fuzzy framework for software fault prediction for inter-version and inter-project evaluation},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {77},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2019.02.008},
doi = {10.1016/j.asoc.2019.02.008},
journal = {Appl. Soft Comput.},
month = apr,
pages = {696–713},
numpages = {18},
keywords = {Fuzzy, Classification, Intra project, Inter project, Defect Prediction}
}

@inproceedings{10.1145/3379597.3387461,
author = {Chen, Yang and Santosa, Andrew E. and Yi, Ang Ming and Sharma, Abhishek and Sharma, Asankhaya and Lo, David},
title = {A Machine Learning Approach for Vulnerability Curation},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387461},
doi = {10.1145/3379597.3387461},
abstract = {Software composition analysis depends on database of open-source library vulerabilities, curated by security researchers using various sources, such as bug tracking systems, commits, and mailing lists. We report the design and implementation of a machine learning system to help the curation by by automatically predicting the vulnerability-relatedness of each data item. It supports a complete pipeline from data collection, model training and prediction, to the validation of new models before deployment. It is executed iteratively to generate better models as new input data become available. We use self-training to significantly and automatically increase the size of the training dataset, opportunistically maximizing the improvement in the models' quality at each iteration. We devised new deployment stability metric to evaluate the quality of the new models before deployment into production, which helped to discover an error. We experimentally evaluate the improvement in the performance of the models in one iteration, with 27.59% maximum PR AUC improvements. Ours is the first of such study across a variety of data sources. We discover that the addition of the features of the corresponding commits to the features of issues/pull requests improve the precision for the recall values that matter. We demonstrate the effectiveness of self-training alone, with 10.50% PR AUC improvement, and we discover that there is no uniform ordering of word2vec parameters sensitivity across data sources.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {32–42},
numpages = {11},
keywords = {self-training, open-source software, machine learning, classifiers ensemble, application security},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@article{10.1016/j.jss.2016.05.015,
author = {Chen, Tse-Hsun and Shang, Weiyi and Nagappan, Meiyappan and Hassan, Ahmed E. and Thomas, Stephen W.},
title = {Topic-based software defect explanation},
year = {2017},
issue_date = {July 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {129},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.05.015},
doi = {10.1016/j.jss.2016.05.015},
abstract = {Some topics are more defect-prone than others.Defect-prone topics are likely to remain so over time.Our topic-based metrics provide additional defect explanatory to baseline metrics.Our metrics outperform state-of-the-art topic-based cohesion and coupling metrics. Researchers continue to propose metrics using measurable aspects of software systems to understand software quality. However, these metrics largely ignore the functionality, i.e., the conceptual concerns, of software systems. Such concerns are the technical concepts that reflect the systems business logic. For instance, while lines of code may be a good general measure for defects, a large file responsible for simple I/O tasks is likely to have fewer defects than a small file responsible for complicated compiler implementation details. In this paper, we study the effect of concerns on software quality. We use a statistical topic modeling approach to approximate software concerns as topics (related words in source code). We propose various metrics using these topics to help explain the file defect-proneness. Case studies on multiple versions of Firefox, Eclipse, Mylyn, and NetBeans show that (i) some topics are more defect-prone than others; (ii) defect-prone topics tend to remain so over time; (iii) our topic-based metrics provide additional explanatory power for software quality over existing structural and historical metrics; and (iv) our topic-based cohesion metric outperforms state-of-the-art topic-based cohesion and coupling metrics in terms of defect explanatory power, while being simpler to implement and more intuitive to interpret.},
journal = {J. Syst. Softw.},
month = jul,
pages = {79–106},
numpages = {28},
keywords = {Topic modeling, Metrics, LDA, Coupling, Cohesion, Code quality}
}

@mastersthesis{10.5555/AAI27837415,
author = {Kumar, Abhishek and Song, Myoungkyu and Hale, Matthew},
advisor = {Harvey, Siy,},
title = {Validating Machine Learning Applications with Metamorphic Testing},
year = {2020},
isbn = {9798662408258},
publisher = {University of Nebraska at Omaha},
abstract = {As machine learning applications have gone into mainstream use, it is increasingly important to find ways of assessing the reliability of their outputs. Unlike conventional software applications, there is no known approach for systematically testing machine learning applications. It is because of a lack of useful oracles due to the large input space for such applications. One of the most common uses of machine learning is image recognition. Robust image recognition needs to accurately identify images, even in the face of slight distortions to the image. Metamorphic testing is a promising approach for testing such applications. It makes use of successful test cases to generate additional test inputs. The main idea is that a small change in the input from a known test case should lead to a similarly small change (or no change) in the output. The changes to the test cases are constrained by metamorphic relations, which are defined as "expected relation among input and output of multiple executions of a program."In this study, we developed a metamorphic testing framework for testing the robustness of machine learning algorithms. We use a simple metamorphic relation: small changes in the input image should not lead to a different classification by the machine. We implemented five machine learning algorithms and trained them on the same dataset. We then apply a set of affine transformations to the test data to generate follow-up test data. We feed the follow-up test data to the algorithms and compare the output to the original outputs. We progressively increase the transformations to identify the ``breaking point" of the algorithms. Our results on three image databases indicate that machine learning algorithms are more sensitive to image shifting than other transformations such as rotation and shearing. Based on the results of the study, we provide recommendations to use our metamorphic properties to generate follow-up test cases for machine learning algorithms. Finally, we generated a new test dataset with these recommendations to assess the robustness of the algorithms. Within these recommended ranges, we find that deep learning algorithms like convolutional neural networks can outperform other algorithms.},
note = {AAI27837415}
}

@inproceedings{10.1109/QRS.2015.14,
author = {Yang, Xinli and Lo, David and Xia, Xin and Zhang, Yun and Sun, Jianling},
title = {Deep Learning for Just-in-Time Defect Prediction},
year = {2015},
isbn = {9781467379892},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QRS.2015.14},
doi = {10.1109/QRS.2015.14},
abstract = {Defect prediction is a very meaningful topic, particularly at change-level. Change-level defect prediction, which is also referred as just-in-time defect prediction, could not only ensure software quality in the development process, but also make the developers check and fix the defects in time. Nowadays, deep learning is a hot topic in the machine learning literature. Whether deep learning can be used to improve the performance of just-in-time defect prediction is still uninvestigated. In this paper, to bridge this research gap, we propose an approach Deeper which leverages deep learning techniques to predict defect-prone changes. We first build a set of expressive features from a set of initial change features by leveraging a deep belief network algorithm. Next, a machine learning classifier is built on the selected features. To evaluate the performance of our approach, we use datasets from six large open source projects, i.e., Bugzilla, Columba, JDT, Platform, Mozilla, and PostgreSQL, containing a total of 137,417 changes. We compare our approach with the approach proposed by Kamei et al. The experimental results show that on average across the 6 projects, Deeper could discover 32.22% more bugs than Kamei et al's approach (51.04% versus 18.82% on average). In addition, Deeper can achieve F1-scores of 0.22-0.63, which are statistically significantly higher than those of Kamei et al.'s approach on 4 out of the 6 projects.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Software Quality, Reliability and Security},
pages = {17–26},
numpages = {10},
keywords = {Just-In-Time Defect Prediction, Deep Learning, Deep Belief Network, Cost Effectiveness},
series = {QRS '15}
}

@article{10.1504/ijiids.2020.109457,
author = {Anwar, Khalid and Siddiqui, Jamshed and Sohail, Shahab Saquib},
title = {Machine learning-based book recommender system: a survey and new perspectives},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {2–4},
issn = {1751-5858},
url = {https://doi.org/10.1504/ijiids.2020.109457},
doi = {10.1504/ijiids.2020.109457},
abstract = {The exponential growth of recommender systems research has drawn the attention of the scientific community recently. These systems are very useful in reducing information overload and providing users with the items of their need. The major areas where recommender systems have contributed significantly include e-commerce, online auction, and books and conference recommendation for academia and industrialists. Book recommender systems suggest books of interest to users according to their preferences and requirements. In this article, we have surveyed machine learning techniques which have been used in book recommender systems. Moreover, evaluation metrics applied to evaluate recommendation techniques is also studied. Six categories for book recommendation techniques have been identified and discussed which would enable the scientific community to lay a foundation of research in the concerned field. We have also proposed future perspectives to improve recommender system. We hope that researchers exploring recommendation technology in general and book recommendation in particular will be finding this work highly beneficial.},
journal = {Int. J. Intell. Inf. Database Syst.},
month = jan,
pages = {231–248},
numpages = {17},
keywords = {evaluation metrics, association rule mining, classification, machine learning, BRS, book recommender system}
}

@inproceedings{10.1109/ISSRE.2014.35,
author = {Lu, Huihua and Kocaguneli, Ekrem and Cukic, Bojan},
title = {Defect Prediction between Software Versions with Active Learning and Dimensionality Reduction},
year = {2014},
isbn = {9781479960330},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2014.35},
doi = {10.1109/ISSRE.2014.35},
abstract = {Accurate detection of defects prior to product release helps software engineers focus verification activities on defect prone modules, thus improving the effectiveness of software development. A common scenario is to use the defects from prior releases to build the prediction model for the upcoming release, typically through a supervised learning method. As software development is a dynamic process, fault characteristics in subsequent releases may vary. Therefore, supplementing the defect information from prior releases with limited information about the defects from the current release detected early seems to offer intuitive and practical benefits. We propose active learning as a way to automate the development of models which improve the performance of defect prediction between successive releases. Our results show that the integration of active learning with uncertainty sampling consistently outperforms the corresponding supervised learning approach. We further improve the prediction performance with feature compression techniques, where feature selection or dimensionality reduction is applied to defect data prior to active learning. We observe that dimensionality reduction techniques, particularly multidimensional scaling with random forest similarity, work better than feature selection due to their ability to identify and combine essential information in data set features. We present the improvements offered by this methodology through the prediction of defective modules in the three successive versions of Eclipse.},
booktitle = {Proceedings of the 2014 IEEE 25th International Symposium on Software Reliability Engineering},
pages = {312–322},
numpages = {11},
keywords = {Software defect prediction, Machine learning, Dimensionality reduction, Complexity measures, Active learning},
series = {ISSRE '14}
}

@inproceedings{10.1109/ICSE-NIER52604.2021.00022,
author = {Panichella, Annibale and Liem, Cynthia C. S.},
title = {What are we really testing in mutation testing for machine learning? a critical reflection},
year = {2021},
isbn = {9780738133249},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER52604.2021.00022},
doi = {10.1109/ICSE-NIER52604.2021.00022},
abstract = {Mutation testing is a well-established technique for assessing a test suite's quality by injecting artificial faults into production code. In recent years, mutation testing has been extended to machine learning (ML) systems, and deep learning (DL) in particular; researchers have proposed approaches, tools, and statistically sound heuristics to determine whether mutants in DL systems are killed or not. However, as we will argue in this work, questions can be raised to what extent currently used mutation testing techniques in DL are actually in line with the classical interpretation of mutation testing. We observe that ML model development resembles a test-driven development (TDD) process, in which a training algorithm ('programmer') generates a model (program) that fits the data points (test data) to labels (implicit assertions), up to a certain threshold. However, considering proposed mutation testing techniques for ML systems under this TDD metaphor, in current approaches, the distinction between production and test code is blurry, and the realism of mutation operators can be challenged. We also consider the fundamental hypotheses underlying classical mutation testing: the competent programmer hypothesis and coupling effect hypothesis. As we will illustrate, these hypotheses do not trivially translate to ML system development, and more conscious and explicit scoping and concept mapping will be needed to truly draw parallels. Based on our observations, we propose several action points for better alignment of mutation testing techniques for ML with paradigms and vocabularies of classical mutation testing.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {66–70},
numpages = {5},
keywords = {software testing, mutation testing, mutation operators, machine learning},
location = {Virtual Event, Spain},
series = {ICSE-NIER '21}
}

@inproceedings{10.1145/3318299.3318345,
author = {Li, ZhanJun and Shao, Yan},
title = {A Survey of Feature Selection for Vulnerability Prediction Using Feature-based Machine Learning},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318345},
doi = {10.1145/3318299.3318345},
abstract = {This paper summarized the basic process of software vulnerability prediction using feature-based machine learning for the first time. In addition to sorting out the related types and basis of vulnerability features definition, the advantages and disadvantages of different methods are compared. Finally, this paper analyzed the difficulties and challenges in this research field, and put forward some suggestions for future work.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {36–42},
numpages = {7},
keywords = {machine learning, feature, Software vulnerability prediction},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@inproceedings{10.1109/ISCID.2013.199,
author = {Xia, Ye and Yan, Guoying and Si, Qianran},
title = {A Study on the Significance of Software Metrics in Defect Prediction},
year = {2013},
isbn = {9780769550794},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISCID.2013.199},
doi = {10.1109/ISCID.2013.199},
abstract = {In the case of metrics-based software defect prediction, an intelligent selection of metrics plays an important role in improving the model performance. In this paper, we use different ways for feature selection and dimensionality reduction to determine the most important software metrics. Three different classifiers are utilized, namely Na\"{\i}ve Bayes, support vector machine and decision tree. On the publicly NASA data, a comparative experiment results show that instead of 22 or more metrics, less than 10 metrics can get better performance.},
booktitle = {Proceedings of the 2013 Sixth International Symposium on Computational Intelligence and Design - Volume 02},
pages = {343–346},
numpages = {4},
keywords = {software metric, feature selection, defect prediction, classifier},
series = {ISCID '13}
}

@inproceedings{10.1109/COMPSAC.2015.58,
author = {Zhang, Yun and Lo, David and Xia, Xin and Sun, Jianling},
title = {An Empirical Study of Classifier Combination for Cross-Project Defect Prediction},
year = {2015},
isbn = {9781467365642},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2015.58},
doi = {10.1109/COMPSAC.2015.58},
abstract = {To help developers better allocate testing and debugging efforts, many software defect prediction techniques have been proposed in the literature. These techniques can be used to predict classes that are more likely to be buggy based on past history of buggy classes. These techniques work well as long as a sufficient amount of data is available to train a prediction model. However, there is rarely enough training data for new software projects. To deal with this problem, cross-project defect prediction, which transfers a prediction model trained using data from one project to another, has been proposed and is regarded as a new challenge for defect prediction. So far, only a few cross-project defect prediction techniques have been proposed. To advance the state-of-the-art, in this work, we investigate 7 composite algorithms, which integrate multiple machine learning classifiers, to improve cross-project defect prediction. To evaluate the performance of the composite algorithms, we perform experiments on 10 open source software systems from the PROMISE repository which contain a total of 5,305 instances labeled as defective or clean. We compare the composite algorithms with CODEP Logistic, which is the latest cross-project defect prediction algorithm proposed by Panichella et al., in terms of two standard evaluation metrics: cost effectiveness and F-measure. Our experiment results show that several algorithms outperform CODEP Logistic: Max performs the best in terms of F-measure and its average F-measure outperforms that of CODEP Logistic by 36.88%. Bagging J48 performs the best in terms of cost effectiveness and its average cost effectiveness outperforms that of CODEP Logistic by 15.34%.},
booktitle = {Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 02},
pages = {264–269},
numpages = {6},
keywords = {Defect Prediction, Cross-Project, Classifier Combination},
series = {COMPSAC '15}
}

@inproceedings{10.1007/978-3-030-41418-4_3,
author = {Nakajima, Shin},
title = {Distortion and Faults in Machine Learning Software},
year = {2019},
isbn = {978-3-030-41417-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-41418-4_3},
doi = {10.1007/978-3-030-41418-4_3},
abstract = {Machine learning software, deep neural networks (DNN) software in particular, discerns valuable information from a large dataset, a set of data, so as to synthesize approximate input-output relations. The outcomes of such DNN programs are dependent on the quality of both learning programs and datasets. However, the quality assurance of DNN software is difficult. The trained machine learning models, defining the functional behavior of the approximate relations, are unknown prior to its development, and the validation is conducted indirectly in terms of the prediction performance. This paper introduces a hypothesis that faults in DNN programs manifest themselves as distortions in trained machine learning models. Relative distortion degrees measured with appropriate observer functions may indicate that the programs have some hidden faults. The proposal is demonstrated with the cases of the MNIST dataset.},
booktitle = {Structured Object-Oriented Formal Language and Method: 9th International Workshop, SOFL+MSVL 2019, Shenzhen, China, November 5, 2019, Revised Selected Papers},
pages = {29–41},
numpages = {13},
location = {Shenzhen, China}
}

@article{10.5555/3271870.3271878,
title = {Software fault prediction using firefly algorithm},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {6},
number = {3–4},
issn = {1758-8715},
abstract = {The software fault prediction SFP literature has shown an immense growth of the research studies involving the artificial neural network ANN based fault prediction models. However, the default gradient descent back propagation neural networks BPNNs have a high risk of getting stuck in the local minima of the search space. A class of nature inspired computing methods overcomes this disadvantage of BPNNs and has helped ANNs to evolve into a class of adaptive ANN. In this work, we propose a hybrid SFP model built using firefly algorithm FA and artificial neural network ANN, along with an empirical comparison with GA and PSO based evolutionary methods in optimising the connection weights of ANN. Seven different datasets were involved and MSE and the confusion matrix parameters were used for performance evaluation. The results have shown that FA-ANN model has performed better than the genetic and particle swarm optimised ANN fault prediction models.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {356–377},
numpages = {22}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00049,
author = {Zhu, Junjie and Long, Teng and Memon, Atif},
title = {Automatically authoring regression tests for machine-learning based systems},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00049},
doi = {10.1109/ICSE-SEIP52600.2021.00049},
abstract = {Two key design characteristics of machine learning (ML) systems---their ever-improving nature, and learning-based emergent functional behavior---create a moving target, posing new challenges for authoring/maintaining functional regression tests. We identify four specific challenges and address them by developing a new general methodology to automatically author and maintain tests. In particular, we use the volume of production data to periodically refresh our large corpus of test inputs and expected outputs; we use perturbation of the data to obtain coverage-adequate tests; and we use clustering to help identify patterns of failures that are indicative of software bugs. We demonstrate our methodology on an ML-based context-aware Speller. Our coverage-adequate, approx. 1 million regression test cases, automatically authored and maintained for Speller (1) are virtually maintenance free, (2) detect a higher number of Speller failures than previous manually-curated tests, (3) have better coverage of previously unknown functional boundaries of the ML component, and (4) lend themselves to automatic failure triaging by clustering and prioritizing subcategories of tests with over-represented failures. We identify several systematic failure patterns which were due to previously undetected bugs in the Speller, e.g., (1) when the user misses the first letter in a short word, and (2) when the user mistakenly inserts a character in the last token of an address; these have since been fixed.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {374–383},
numpages = {10},
keywords = {spelling correction, ML-based testing, ML testing},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@proceedings{10.1145/3472674,
title = {MaLTESQuE 2021: Proceedings of the 5th International Workshop on Machine Learning Techniques for Software Quality Evolution},
year = {2021},
isbn = {9781450386258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the fifth edition of the workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE 2021) to be held virtually on August 23, 2021, co-located with the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2021).},
location = {Athens, Greece}
}

@article{10.5555/1991856.1991869,
author = {Jiang, Yuan and Li, Ming and Zhou, Zhi-Hua},
title = {Software defect detection with rocus},
year = {2011},
issue_date = {March 2011},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {2},
issn = {1000-9000},
abstract = {Software defect detection aims to automatically identify defective software modules for efficient software test in order to improve the quality of a software system. Although many machine learning methods have been successfully applied to the task, most of them fail to consider two practical yet important issues in software defect detection. First, it is rather difficult to collect a large amount of labeled training data for learning a well-performing model; second, in a software system there are usually much fewer defective modules than defect-free modules, so learning would have to be conducted over an imbalanced data set. In this paper, we address these two practical issues simultaneously by prcposing a novel semi-supervised learning approach named ROCUS. This method exploits the abundant unlabeled examples to improve the detection accuracy, as well as employs under-sampling to tackle the class-imbalance problem in the learning process. Experimental results of real-world software defect detection tasks show that ROCUS is effective for software defect cetection. Its performance is better than a semi-supervised learning method that ignores the class-imbalance nature of the task and a class-imbalance learning method that does not make effective use of unlabeled data.},
journal = {J. Comput. Sci. Technol.},
month = mar,
pages = {328–342},
numpages = {15},
keywords = {software defect detection, semi-supervised learning, machine learning, data mining, class-imbalance}
}

@inproceedings{10.1145/3425174.3425226,
author = {Santos, Sebasti\~{a}o H. N. and da Silveira, Beatriz Nogueira Carvalho and Andrade, Stev\~{a}o A. and Delamaro, M\'{a}rcio and Souza, Simone R. S.},
title = {An Experimental Study on Applying Metamorphic Testing in Machine Learning Applications},
year = {2020},
isbn = {9781450387552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425174.3425226},
doi = {10.1145/3425174.3425226},
abstract = {Machine learning techniques have been successfully employed in various areas and, in particular, for the development of healthcare applications, aiming to support in more effective and faster diagnostics (such as cancer diagnosis). However, machine learning models may present uncertainties and errors. Errors in the training process, classification, and evaluation can generate incorrect results and, consequently, to wrong clinical decisions, reducing the professionals' confidence in the use of such techniques. Similar to other application domains, the quality should be guaranteed to produce more reliable models capable of assisting health professionals in their daily activities. Metamorphic testing can be an interesting option to validate machine learning applications. Using this testing approach is possible to define relationships that define changes to be made in the application's input data to identify faults. This paper presents an experimental study to evaluate the effectiveness of metamorphic testing to validate machine learning applications. A Machine learning application to verify breast cancer diagnostic was developed, using an available dataset composed of 569 samples whose data were taken from breast cancer images, and used as the software under test, in which the metamorphic testing was applied. The results indicate that metamorphic testing can be an alternative to support the validation of machine learning applications.},
booktitle = {Proceedings of the 5th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {98–106},
numpages = {9},
keywords = {Metamorphic Test, Machine Learning, Experimental Study},
location = {Natal, Brazil},
series = {SAST '20}
}

@inproceedings{10.1007/978-3-030-79463-7_36,
author = {Kawalerowicz, Marcin and Madeyski, Lech},
title = {Jaskier: A Supporting Software Tool for&nbsp;Continuous Build Outcome Prediction Practice},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_36},
doi = {10.1007/978-3-030-79463-7_36},
abstract = {Continuous Defect Prediction (CDP) is an assisting software development practice that combines Software Defect Prediction (SDP) with machine learning aided modelling and continuous developer feedback. Jaskier is a set of software tools developed under the supervision and with the participation of the authors of the article that implements a lightweight version of CDP called Continuous Build Outcome Prediction (CBOP). CBOP uses classification to label the possible build results based on historical data and metrics derived from the software repository. This paper contains a detailed description of the tool that was already started to be used in the production environment of a real software project where the CBOP practice is being evaluated.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {426–438},
numpages = {13},
keywords = {Continuous integration, Software defect prediction},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1145/3324884.3416617,
author = {Li, Ke and Xiang, Zilin and Chen, Tao and Tan, Kay Chen},
title = {BiLO-CPDP: bi-level programming for automated model discovery in cross-project defect prediction},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416617},
doi = {10.1145/3324884.3416617},
abstract = {Cross-Project Defect Prediction (CPDP), which borrows data from similar projects by combining a transfer learner with a classifier, have emerged as a promising way to predict software defects when the available data about the target project is insufficient. However, developing such a model is challenge because it is difficult to determine the right combination of transfer learner and classifier along with their optimal hyper-parameter settings. In this paper, we propose a tool, dubbed BiLO-CPDP, which is the first of its kind to formulate the automated CPDP model discovery from the perspective of bi-level programming. In particular, the bi-level programming proceeds the optimization with two nested levels in a hierarchical manner. Specifically, the upper-level optimization routine is designed to search for the right combination of transfer learner and classifier while the nested lower-level optimization routine aims to optimize the corresponding hyper-parameter settings. To evaluate BiLO-CPDP, we conduct experiments on 20 projects to compare it with a total of 21 existing CPDP techniques, along with its single-level optimization variant and Auto-Sklearn, a state-of-the-art automated machine learning tool. Empirical results show that BiLO-CPDP champions better prediction performance than all other 21 existing CPDP techniques on 70% of the projects, while being overwhelmingly superior to Auto-Sklearn and its single-level optimization variant on all cases. Furthermore, the unique bi-level formalization in BiLO-CPDP also permits to allocate more budget to the upper-level, which significantly boosts the performance.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {573–584},
numpages = {12},
keywords = {automated parameter optimization, classification techniques, configurable software and tool, cross-project defect prediction, transfer learning},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/3395363.3404364,
author = {Guo, Zichen and Liu, Jiawei and He, Tieke and Li, Zhuoyang and Zhangzhu, Peitian},
title = {TauJud: test augmentation of machine learning in judicial documents},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3404364},
doi = {10.1145/3395363.3404364},
abstract = {The booming of big data makes the adoption of machine learning ubiquitous in the legal field. As we all know, a large amount of test data can better reflect the performance of the model, so the test data must be naturally expanded. In order to solve the high cost problem of labeling data in natural language processing, people in the industry have improved the performance of text classification tasks through simple data amplification techniques. However, the data amplification requirements in the judgment documents are interpretable and logical, as observed from CAIL2018 test data with over 200,000 judicial documents. Therefore, we have designed a test augmentation tool called TauJud specifically for generating more effective test data with uniform distribution over time and location for model evaluation and save time in marking data. The demo can be found at https://github.com/governormars/TauJud.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {549–552},
numpages = {4},
keywords = {Test Augmentation, Machine Learning, Judicial Documents},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@inproceedings{10.1145/3468264.3468615,
author = {Dutta, Saikat and Shi, August and Misailovic, Sasa},
title = {FLEX: fixing flaky tests in machine learning projects by updating assertion bounds},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468615},
doi = {10.1145/3468264.3468615},
abstract = {Many machine learning (ML) algorithms are inherently random – multiple executions using the same inputs may produce slightly different results each time. Randomness impacts how developers write tests that check for end-to-end quality of their implementations of these ML algorithms. In particular, selecting the proper thresholds for comparing obtained quality metrics with the reference results is a non-intuitive task, which may lead to flaky test executions.  We present FLEX, the first tool for automatically fixing flaky tests due to algorithmic randomness in ML algorithms. FLEX fixes tests that use approximate assertions to compare actual and expected values that represent the quality of the outputs of ML algorithms. We present a technique for systematically identifying the acceptable bound between the actual and expected output quality that also minimizes flakiness. Our technique is based on the Peak Over Threshold method from statistical Extreme Value Theory, which estimates the tail distribution of the output values observed from several runs. Based on the tail distribution, FLEX updates the bound used in the test, or selects the number of test re-runs, based on a desired confidence level.  We evaluate FLEX on a corpus of 35 tests collected from the latest versions of 21 ML projects. Overall, FLEX identifies and proposes a fix for 28 tests. We sent 19 pull requests, each fixing one test, to the developers. So far, 9 have been accepted by the developers.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {603–614},
numpages = {12},
keywords = {Machine Learning, Flaky tests, Extreme Value Theory},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1109/ICSE43902.2021.00100,
author = {Velez, Miguel and Jamshidi, Pooyan and Siegmund, Norbert and Apel, Sven and K\"{a}stner, Christian},
title = {White-Box Analysis over Machine Learning: Modeling Performance of Configurable Systems},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00100},
doi = {10.1109/ICSE43902.2021.00100},
abstract = {Performance-influence models can help stakeholders understand how and where configuration options and their interactions influence the performance of a system. With this understanding, stakeholders can debug performance behavior and make deliberate configuration decisions. Current black-box techniques to build such models combine various sampling and learning strategies, resulting in tradeoffs between measurement effort, accuracy, and interpretability. We present Comprex, a white-box approach to build performance-influence models for configurable systems, combining insights of local measurements, dynamic taint analysis to track options in the implementation, compositionality, and compression of the configuration space, without relying on machine learning to extrapolate incomplete samples. Our evaluation on 4 widely-used, open-source projects demonstrates that Comprex builds similarly accurate performance-influence models to the most accurate and expensive black-box approach, but at a reduced cost and with additional benefits from interpretable and local models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1072–1084},
numpages = {13},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1016/j.jss.2014.10.032,
author = {Moeyersoms, Julie and Junqu\'{e} de Fortuny, Enric and Dejaeger, Karel and Baesens, Bart and Martens, David},
title = {Comprehensible software fault and effort prediction},
year = {2015},
issue_date = {February 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {100},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.10.032},
doi = {10.1016/j.jss.2014.10.032},
abstract = {HighlightsWe argue that comprehensibility is crucial in software effort and fault prediction.We extracted new datasets based on the Android repository.ALPA extracts a tree that mimics the performance of the complex model.The extracted trees are not only comprehensible but also more accurate. Software fault and effort prediction are important tasks to minimize costs of a software project. In software effort prediction the aim is to forecast the effort needed to complete a software project, whereas software fault prediction tries to identify fault-prone modules. In this research both tasks are considered, thereby using different data mining techniques. The predictive models not only need to be accurate but also comprehensible, demanding that the user can understand the motivation behind the model's prediction. Unfortunately, to obtain predictive performance, comprehensibility is often sacrificed and vice versa. To overcome this problem, we extract trees from well performing Random Forests (RFs) and Support Vector Machines for regression (SVRs) making use of a rule extraction algorithm ALPA. This method builds trees (using C4.5 and REPTree) that mimic the black-box model (RF, SVR) as closely as possible. The proposed methodology is applied to publicly available datasets, complemented with new datasets that we have put together based on the Android repository. Surprisingly, the trees extracted from the black-box models by ALPA are not only comprehensible and explain how the black-box model makes (most of) its predictions, but are also more accurate than the trees obtained by working directly on the data.},
journal = {J. Syst. Softw.},
month = feb,
pages = {80–90},
numpages = {11},
keywords = {Software fault and effort prediction, Rule extraction, Comprehensibility}
}

@article{10.1016/j.eswa.2018.12.033,
author = {Turabieh, Hamza and Mafarja, Majdi and Li, Xiaodong},
title = {Iterated feature selection algorithms with layered recurrent neural network for software fault prediction},
year = {2019},
issue_date = {May 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2018.12.033},
doi = {10.1016/j.eswa.2018.12.033},
journal = {Expert Syst. Appl.},
month = may,
pages = {27–42},
numpages = {16},
keywords = {Layered recurrent neural network, Feature selection, Software fault prediction}
}

@inproceedings{10.1145/2851613.2851788,
author = {das D\^{o}res, Silvia N. and Alves, Luciano and Ruiz, Duncan D. and Barros, Rodrigo C.},
title = {A meta-learning framework for algorithm recommendation in software fault prediction},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851788},
doi = {10.1145/2851613.2851788},
abstract = {Software fault prediction is a significant part of software quality assurance and it is commonly used to detect faulty software modules based on software measurement data. Several machine learning based approaches have been proposed for generating predictive models from collected data, although none has become standard given the specificities of each software project. Hence, we believe that recommending the best algorithm for each project is much more important and useful than developing a single algorithm for being used in any project. For achieving that goal, we propose in this paper a novel framework for recommending machine learning algorithms that is capable of automatically identifying the most suitable algorithm according to the software project that is being considered. Our solution, namely SFP-MLF, makes use of the meta-learning paradigm in order to learn the best learner for a particular project. Results show that the SFP-MLF framework provides both the best single algorithm recommendation and also the best ranking recommendation for the software fault prediction problem.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1486–1491},
numpages = {6},
keywords = {algorithm recommendation, machine learning, meta-learning, software fault prediction, software quality},
location = {Pisa, Italy},
series = {SAC '16}
}

@article{10.2478/acss-2020-0017,
author = {Abramov, Kirill and Grundspenkis, Janis},
title = {Suitability Determination of Machine Learning Techniques for the Operational Quality Assessment of Geophysical Survey Results},
year = {2020},
issue_date = {Dec 2020},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {25},
number = {2},
issn = {2255-8691},
url = {https://doi.org/10.2478/acss-2020-0017},
doi = {10.2478/acss-2020-0017},
abstract = {Well logging, also known as a geophysical survey, is one of the main components of a nuclear fuel cycle. This survey follows directly after the drilling process, and the operational quality assessment of its results is a very serious problem. Any mistake in this survey can lead to the culling of the whole well. This paper examines the feasibility of applying machine learning techniques to quickly assess the well logging quality results. The studies were carried out by a reference well modelling for the selected uranium deposit of the Republic of Kazakhstan and further comparing it with the results of geophysical surveys recorded earlier. The parameters of the geophysical methods and the comparison rules for them were formulated after the reference well modelling process. The classification trees and the artificial neural networks were used during the research process and the results obtained for both methods were compared with each other. The results of this paper may be useful to the enterprises engaged in the geophysical well surveys and data processing obtained during the logging process.},
journal = {Appl. Comput. Syst.},
month = dec,
pages = {153–162},
numpages = {10},
keywords = {well logging, neural networks, machine learning, Classification trees}
}

@inproceedings{10.1109/ACIT-CSI.2015.104,
author = {Kawata, Kazuya and Amasaki, Sousuke and Yokogawa, Tomoyuki},
title = {Improving Relevancy Filter Methods for Cross-Project Defect Prediction},
year = {2015},
isbn = {9781467396424},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ACIT-CSI.2015.104},
doi = {10.1109/ACIT-CSI.2015.104},
abstract = {Context: Cross-project defect prediction (CPDP)research has been popular. One of the techniques for CPDP isa relevancy filter which utilizes clustering algorithms to selecta useful subset of the cross-project data. Their performanceheavily relies on the quality of clustering, and using an advancedclustering algorithm instead of simple ones used in the past studiescan contribute to the performance improvement. Objective:To propose and examine a new relevancy filter method usingan advanced clustering method DBSCAN (Density-Based SpatialClustering). Method: We conducted an experiment that examinedthe predictive performance of the proposed method. Theexperiments compared three relevancy filter methods, namely,Burak-filter, Peters-filter, and the proposed method with 56project data and four prediction models. Results: The predictiveperformance measures supported the proposed method. It wasbetter than Burak-filter and Peters-filter in terms of AUC andg-measure. Conclusion: The proposed method achieved betterprediction than the conventional methods. The results suggestedthat exploring advanced clustering algorithms could contributeto cross-project defect prediction.},
booktitle = {Proceedings of the 2015 3rd International Conference on Applied Computing and Information Technology/2nd International Conference on Computational Science and Intelligence},
pages = {2–7},
numpages = {6},
series = {ACIT-CSI '15}
}

@article{10.1109/TSE.2010.90,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
title = {A General Software Defect-Proneness Prediction Framework},
year = {2011},
issue_date = {May 2011},
publisher = {IEEE Press},
volume = {37},
number = {3},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2010.90},
doi = {10.1109/TSE.2010.90},
abstract = {BACKGROUND—Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE—We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD—The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS—The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS—Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.},
journal = {IEEE Trans. Softw. Eng.},
month = may,
pages = {356–370},
numpages = {15},
keywords = {software defect-proneness prediction, scheme evaluation., machine learning, Software defect prediction}
}

@inproceedings{10.5555/3049877.3049895,
author = {Mezouar, Mariam El and Zhang, Feng and Zou, Ying},
title = {Local versus global models for effort-aware defect prediction},
year = {2016},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software entities (e.g., files or classes) do not have the same density of defects and therefore do not require the same amount of effort for inspection. With limited resources, it is critical to reveal as many defects as possible. To satisfy such need, effort-aware defect prediction models have been proposed. However, the performance of prediction models is commonly affected by a large amount of possible variability in the training data. Prior studies have inspected whether using a subset of the original training data (i.e., local models) could improve the performance of prediction models in the context of defect prediction and effort estimation in comparison with global models (i.e., trained on the whole dataset). However, no consensus has been reached and the comparison has not been performed in the context of effort-aware defect prediction.In this study, we compare local and global effort-aware defect prediction models using 15 projects from the widely used AEEEM and PROMISE datasets. We observe that although there is at least one local model that can outperform the global model, there always exists another local model that performs very poorly in all the projects. We further find that the poor performing local model is built on the subset of the training set with a low ratio of defective entities. By excluding such subset of the training set and building a local effort-aware model with the remaining training set, the local model usually underperforms the global model in 11 out of the 15 studied projects. A close inspection on the failure of local effort-aware models reveals that the major challenge comes from defective entities with small size (i.e., few lines of code), as such entities tend to be correctly predicted by the global model but missed by the local model. Further work should pay special attention to the small but defective entities.},
booktitle = {Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering},
pages = {178–187},
numpages = {10},
location = {Toronto, Ontario, Canada},
series = {CASCON '16}
}

@inproceedings{10.1145/1985793.1985859,
author = {Kim, Sunghun and Zhang, Hongyu and Wu, Rongxin and Gong, Liang},
title = {Dealing with noise in defect prediction},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985859},
doi = {10.1145/1985793.1985859},
abstract = {Many software defect prediction models have been built using historical defect data obtained by mining software repositories (MSR). Recent studies have discovered that data so collected contain noises because current defect collection practices are based on optional bug fix keywords or bug report links in change logs. Automatically collected defect data based on the change logs could include noises.This paper proposes approaches to deal with the noise in defect data. First, we measure the impact of noise on defect prediction models and provide guidelines for acceptable noise level. We measure noise resistant ability of two well-known defect prediction algorithms and find that in general, for large defect datasets, adding FP (false positive) or FN (false negative) noises alone does not lead to substantial performance differences. However, the prediction performance decreases significantly when the dataset contains 20%-35% of both FP and FN noises. Second, we propose a noise detection and elimination algorithm to address this problem. Our empirical study shows that our algorithm can identify noisy instances with reasonable accuracy. In addition, after eliminating the noises using our algorithm, defect prediction accuracy is improved.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {481–490},
numpages = {10},
keywords = {noise resistance, defect prediction, data quality, buggy files, buggy changes},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@article{10.1007/s10664-015-9376-6,
author = {Herzig, Kim and Just, Sascha and Zeller, Andreas},
title = {The impact of tangled code changes on defect prediction models},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9376-6},
doi = {10.1007/s10664-015-9376-6},
abstract = {When interacting with source control management system, developers often commit unrelated or loosely related code changes in a single transaction. When analyzing version histories, such tangled changes will make all changes to all modules appear related, possibly compromising the resulting analyses through noise and bias. In an investigation of five open-source Java projects, we found between 7 % and 20 % of all bug fixes to consist of multiple tangled changes. Using a multi-predictor approach to untangle changes, we show that on average at least 16.6 % of all source files are incorrectly associated with bug reports. These incorrect bug file associations seem to not significantly impact models classifying source files to have at least one bug or no bugs. But our experiments show that untangling tangled code changes can result in more accurate regression bug prediction models when compared to models trained and tested on tangled bug datasets--in our experiments, the statistically significant accuracy improvements lies between 5 % and 200 %. We recommend better change organization to limit the impact of tangled changes.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {303–336},
numpages = {34},
keywords = {Untangling, Defect prediction, Data noise}
}

@article{10.5555/3057337.3057441,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {A decision tree logic based recommendation system to select software fault prediction techniques},
year = {2017},
issue_date = {March     2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {99},
number = {3},
issn = {0010-485X},
abstract = {Identifying a reliable fault prediction technique is the key requirement for building effective fault prediction model. It has been found that the performance of fault prediction techniques is highly dependent on the characteristics of the fault dataset. To mitigate this issue, researchers have evaluated and compared a plethora of fault prediction techniques by varying the context in terms of domain information, characteristics of input data, complexity, etc. However, the lack of an accepted benchmark makes it difficult to select fault prediction technique for a particular context of prediction. In this paper, we present a recommendation system that facilitates the selection of appropriate technique(s) to build fault prediction model. First, we have reviewed the literature to elicit the various characteristics of the fault dataset and the appropriateness of the machine learning and statistical techniques for the identified characteristics. Subsequently, we have formalized our findings and built a recommendation system that helps in the selection of fault prediction techniques. We performed an initial appraisal of our presented system and found that proposed recommendation system provides useful hints in the selection of the fault prediction techniques.},
journal = {Computing},
month = mar,
pages = {255–285},
numpages = {31},
keywords = {verification, requirements, metrics, etc.), Software fault prediction techniques, Software fault prediction, Recommendation system, Decision tree, 68N30 Mathematical aspects of software engineering (specification}
}

@article{10.1007/s10664-011-9173-9,
author = {D'Ambros, Marco and Lanza, Michele and Robbes, Romain},
title = {Evaluating defect prediction approaches: a benchmark and an extensive comparison},
year = {2012},
issue_date = {August    2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4–5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-011-9173-9},
doi = {10.1007/s10664-011-9173-9},
abstract = {Reliably predicting software defects is one of the holy grails of software engineering. Researchers have devised and implemented a plethora of defect/bug prediction approaches varying in terms of accuracy, complexity and the input data they require. However, the absence of an established benchmark makes it hard, if not impossible, to compare approaches. We present a benchmark for defect prediction, in the form of a publicly available dataset consisting of several software systems, and provide an extensive comparison of well-known bug prediction approaches, together with novel approaches we devised. We evaluate the performance of the approaches using different performance indicators: classification of entities as defect-prone or not, ranking of the entities, with and without taking into account the effort to review an entity. We performed three sets of experiments aimed at (1) comparing the approaches across different systems, (2) testing whether the differences in performance are statistically significant, and (3) investigating the stability of approaches across different learners. Our results indicate that, while some approaches perform better than others in a statistically significant manner, external validity in defect prediction is still an open problem, as generalizing results to different contexts/learners proved to be a partially unsuccessful endeavor.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {531–577},
numpages = {47},
keywords = {Source code metrics, Defect prediction, Change metrics}
}

@inproceedings{10.1109/ICTAI.2010.27,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan and Seliya, Naeem},
title = {Attribute Selection and Imbalanced Data: Problems in Software Defect Prediction},
year = {2010},
isbn = {9780769542638},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICTAI.2010.27},
doi = {10.1109/ICTAI.2010.27},
abstract = {The data mining and machine learning community is often faced with two key problems: working with imbalanced data and selecting the best features for machine learning. This paper presents a process involving a feature selection technique for selecting the important attributes and a data sampling technique for addressing class imbalance. The application domain of this study is software engineering, more specifically, software quality prediction using classification models. When using feature selection and data sampling together, different scenarios should be considered. The four possible scenarios are: (1) feature selection based on original data, and modeling (defect prediction) based on original data; (2) feature selection based on original data, and modeling based on sampled data; (3) feature selection based on sampled data, and modeling based on original data; and (4) feature selection based on sampled data, and modeling based on sampled data. The research objective is to compare the software defect prediction performances of models based on the four scenarios. The case study consists of nine software measurement data sets obtained from the PROMISE software project repository. Empirical results suggest that feature selection based on sampled data performs significantly better than feature selection based on original data, and that defect prediction models perform similarly regardless of whether the training data was formed using sampled or original data.},
booktitle = {Proceedings of the 2010 22nd IEEE International Conference on Tools with Artificial Intelligence - Volume 01},
pages = {137–144},
numpages = {8},
keywords = {software measurements, feature selection, defect prediction, data sampling},
series = {ICTAI '10}
}

@inproceedings{10.1145/1985793.1985950,
author = {Nguyen, Tung Thanh and Nguyen, Tien N. and Phuong, Tu Minh},
title = {Topic-based defect prediction (NIER track)},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985950},
doi = {10.1145/1985793.1985950},
abstract = {Defects are unavoidable in software development and fixing them is costly and resource-intensive. To build defect prediction models, researchers have investigated a number of factors related to the defect-proneness of source code, such as code complexity, change complexity, or socio-technical factors. In this paper, we propose a new approach that emphasizes on technical concerns/functionality of a system. In our approach, a software system is viewed as a collection of software artifacts that describe different technical concerns/-aspects. Those concerns are assumed to have different levels of defect-proneness, thus, cause different levels of defectproneness to the relevant software artifacts. We use topic modeling to measure the concerns in source code, and use them as the input for machine learning-based defect prediction models. Preliminary result on Eclipse JDT shows that the topic-based metrics have high correlation to the number of bugs (defect-proneness), and our topic-based defect prediction has better predictive performance than existing state-of-the-art approaches.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {932–935},
numpages = {4},
keywords = {topic modeling, defect prediction},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.1145/2025113.2025156,
author = {Lee, Taek and Nam, Jaechang and Han, DongGyun and Kim, Sunghun and In, Hoh Peter},
title = {Micro interaction metrics for defect prediction},
year = {2011},
isbn = {9781450304436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2025113.2025156},
doi = {10.1145/2025113.2025156},
abstract = {There is a common belief that developers' behavioral interaction patterns may affect software quality. However, widely used defect prediction metrics such as source code metrics, change churns, and the number of previous defects do not capture developers' direct interactions. We propose 56 novel micro interaction metrics (MIMs) that leverage developers' interaction information stored in the Mylyn data. Mylyn is an Eclipse plug-in, which captures developers' interactions such as file editing and selection events with time spent. To evaluate the performance of MIMs in defect prediction, we build defect prediction (classification and regression) models using MIMs, traditional metrics, and their combinations. Our experimental results show that MIMs significantly improve defect classification and regression accuracy.},
booktitle = {Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering},
pages = {311–321},
numpages = {11},
keywords = {mylyn, micro interaction metrics, defect prediction},
location = {Szeged, Hungary},
series = {ESEC/FSE '11}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00034,
author = {Lwakatare, Lucy Ellen and R\r{a}nge, Ellinor and Crnkovic, Ivica and Bosch, Jan},
title = {On the experiences of adopting automated data validation in an industrial machine learning project},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00034},
doi = {10.1109/ICSE-SEIP52600.2021.00034},
abstract = {Background: Data errors are a common challenge in machine learning (ML) projects and generally cause significant performance degradation in ML-enabled software systems. To ensure early detection of erroneous data and avoid training ML models using bad data, research and industrial practice suggest incorporating a data validation process and tool in ML system development process.Aim: The study investigates the adoption of a data validation process and tool in industrial ML projects. The data validation process demands significant engineering resources for tool development and maintenance. Thus, it is important to identify the best practices for their adoption especially by development teams that are in the early phases of deploying ML-enabled software systems.Method: Action research was conducted at a large-software intensive organization in telecommunications, specifically within the analytics R&amp;D organization for an ML use case of classifying faults from returned hardware telecommunication devices.Results: Based on the evaluation results and learning from our action research, we identified three best practices, three benefits, and two barriers to adopting the data validation process and tool in ML projects. We also propose a data validation framework (DVF) for systematizing the adoption of a data validation process.Conclusions: The results show that adopting a data validation process and tool in ML projects is an effective approach of testing ML-enabled software systems. It requires having an overview of the level of data (feature, dataset, cross-dataset, data stream) at which certain data quality tests can be applied.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {248–257},
numpages = {10},
keywords = {software engineering, machine learning, data validation, data quality, data errors},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@inproceedings{10.5555/2820690.2820697,
author = {Cavezza, Davide G. and Pietrantuono, Roberto and Russo, Stefano},
title = {Performance of defect prediction in rapidly evolving software},
year = {2015},
publisher = {IEEE Press},
abstract = {Defect prediction techniques allow spotting modules (or commits) likely to contain (introduce) a defect by training models with product or process metrics -- thus supporting testing, code integration, and release decisions. When applied to processes where software changes rapidly, conventional techniques might fail, as trained models are not thought to evolve along with the software.In this study, we analyze the performance of defect prediction in rapidly evolving software. Framed in a high commit frequency context, we set up an approach to continuously refine prediction models by using new commit data, and predict whether or not an attempted commit is going to introduce a bug. An experiment is set up on the Eclipse JDT software to assess the prediction ability trend. Results enable to leverage defect prediction potentials in modern development paradigms with short release cycle and high code variability.},
booktitle = {Proceedings of the Third International Workshop on Release Engineering},
pages = {8–11},
numpages = {4},
location = {Florence, Italy},
series = {RELENG '15}
}

@inproceedings{10.1145/3395363.3397366,
author = {Dutta, Saikat and Shi, August and Choudhary, Rutvik and Zhang, Zhekun and Jain, Aryaman and Misailovic, Sasa},
title = {Detecting flaky tests in probabilistic and machine learning applications},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3397366},
doi = {10.1145/3395363.3397366},
abstract = {Probabilistic programming systems and machine learning frameworks like Pyro, PyMC3, TensorFlow, and PyTorch provide scalable and efficient primitives for inference and training. However, such operations are non-deterministic. Hence, it is challenging for developers to write tests for applications that depend on such frameworks, often resulting in flaky tests – tests which fail non-deterministically when run on the same version of code.  In this paper, we conduct the first extensive study of flaky tests in this domain. In particular, we study the projects that depend on four frameworks: Pyro, PyMC3, TensorFlow-Probability, and PyTorch. We identify 75 bug reports/commits that deal with flaky tests, and we categorize the common causes and fixes for them. This study provides developers with useful insights on dealing with flaky tests in this domain.  Motivated by our study, we develop a technique, FLASH, to systematically detect flaky tests due to assertions passing and failing in different runs on the same code. These assertions fail due to differences in the sequence of random numbers in different runs of the same test. FLASH exposes such failures, and our evaluation on 20 projects results in 11 previously-unknown flaky tests that we reported to developers.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {211–224},
numpages = {14},
keywords = {Randomness, Probabilistic Programming, Non-Determinism, Machine Learning, Flaky tests},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@article{10.1145/2841425,
author = {Natella, Roberto and Cotroneo, Domenico and Madeira, Henrique S.},
title = {Assessing Dependability with Software Fault Injection: A Survey},
year = {2016},
issue_date = {February 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/2841425},
doi = {10.1145/2841425},
abstract = {With the rise of software complexity, software-related accidents represent a significant threat for computer-based systems. Software Fault Injection is a method to anticipate worst-case scenarios caused by faulty software through the deliberate injection of software faults. This survey provides a comprehensive overview of the state of the art on Software Fault Injection to support researchers and practitioners in the selection of the approach that best fits their dependability assessment goals, and it discusses how these approaches have evolved to achieve fault representativeness, efficiency, and usability. The survey includes a description of relevant applications of Software Fault Injection in the context of fault-tolerant systems.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {44},
numpages = {55},
keywords = {software fault tolerance, dependability assessment, Software faults}
}

@inproceedings{10.1007/978-3-319-47955-2_19,
author = {Murillo-Morera, Juan and Castro-Herrera, Carlos and Arroyo, Javier and Fuentes-Fern\'{a}ndez, Rub\'{e}n},
title = {An Empirical Validation of Learning Schemes Using an Automated Genetic Defect Prediction Framework},
year = {2016},
isbn = {978-3-319-47954-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-47955-2_19},
doi = {10.1007/978-3-319-47955-2_19},
abstract = {Today, it is common for software projects to collect measurement data through development processes. With these data, defect prediction software can try to estimate the defect proneness of a software module, with the objective of assisting and guiding software practitioners. With timely and accurate defect predictions, practitioners can focus their limited testing resources on higher risk areas. This paper reports a benchmarking study that uses a genetic algorithm that automatically generates and compares different learning schemes (preprocessing + attribute selection + learning algorithms). Performance of the software development defect prediction models (using AUC, Area Under the Curve) was validated using NASA-MDP and PROMISE data sets. Twelve data sets from NASA-MDP (8) and PROMISE (4) projects were analyzed running a -fold cross-validation. We used a genetic algorithm to select the components of the learning schemes automatically, and to evaluate and report those with the best performance. In all, 864 learning schemes were studied. The most common learning schemes were: data preprocessors: Log and CoxBox + attribute selectors: Backward Elimination, BestFirst and LinearForwardSelection + learning algorithms: NaiveBayes, NaiveBayesSimple, SimpleLogistic, MultilayerPerceptron, Logistic, LogitBoost, BayesNet, and OneR. The genetic algorithm reported steady performance and runtime among data sets, according to statistical analysis.},
booktitle = {Advances in Artificial Intelligence - IBERAMIA 2016: 15th Ibero-American Conference on AI, San Jos\'{e}, Costa Rica, November 23-25, 2016, Proceedings},
pages = {222–234},
numpages = {13},
keywords = {Software quality, Fault prediction models, Genetic algorithms, Learning schemes, Learning algorithms, Machine learning},
location = {San Jos\'{e}, Costa Rica}
}

@article{10.1007/s42979-021-00872-6,
author = {Sakhrawi, Zaineb and Sellami, Asma and Bouassida, Nadia},
title = {Software Enhancement Effort Prediction Using Machine-Learning Techniques: A Systematic Mapping Study},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {6},
url = {https://doi.org/10.1007/s42979-021-00872-6},
doi = {10.1007/s42979-021-00872-6},
abstract = {Accurate prediction of software enhancement effort is a key success in software project management. To increase the accuracy of estimates, several proposals used machine-learning (ML) techniques for predicting the software project effort. However, there is no clear evidence for determining which techniques to select for predicting more accurate effort within the context of enhancement projects. This paper aims to present a systematic mapping study (SMS) related to the use of ML techniques for predicting software enhancement effort (SEME). A SMS was performed by reviewing relevant papers from 1995 through 2020. We followed well-known guidelines. We selected 30 relevant studies; 19 from journals and 11 conferences proceedings through 4 search engines. Some of the key findings indicate that (1) there is relatively little activity in the area of SEME, (2) most of the successful studies cited focused on regression problems for enhancement maintenance effort prediction, (3) SEME is the dependent variable the most commonly used in software enhancement project planning, and the enhancement size (or the functional change size) is the most used independent variables, (4) several private datasets were used in the selected studies, and there is a growing demand for the use of commonly published datasets, and (5) only single models were employed for SEME prediction. Results indicate that much more work is needed to develop repositories in all prediction models. Based on the findings obtained in this SMS, estimators should be aware that SEME using ML techniques as part of non-algorithmic models demonstrated increased accuracy prediction over the algorithmic models. The use of ML techniques generally provides a reasonable accuracy when using the enhancement functional size as independent variables.},
journal = {SN Comput. Sci.},
month = sep,
numpages = {15},
keywords = {Machine learning (ML), Software enhancement effort (SEME) prediction, Functional change (FC), Systematic mapping study (SMS)}
}

@article{10.1007/s10009-020-00577-w,
author = {Usman, Muhammad and Wang, Wenxi and Wang, Kaiyuan and Yelen, Cagdas and Dini, Nima and Khurshid, Sarfraz},
title = {A study of learning likely data structure properties using machine learning models},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-020-00577-w},
doi = {10.1007/s10009-020-00577-w},
abstract = {Data structure properties are important for many testing and analysis tasks. For example, model checkers use these properties to find program faults. These properties are often written manually which can be error prone and lead to false alarms. This paper presents the results of controlled experiments performed using existing machine learning (ML) models on various data structures. These data structures are dynamic and reside on the program heap. We use ten data structure subjects and ten ML models to evaluate the learnability of data structure properties. The study reveals five key findings. One, most of the ML models perform well in learning data structure properties, but some of the ML models such as quadratic discriminant analysis and Gaussian naive Bayes are not suitable for learning data structure properties. Two, most of the ML models have high performance even when trained on just 1% of data samples. Three, certain data structure properties such as binary heap and red black tree are more learnable than others. Four, there are no significant differences between the learnability of varied-size (i.e., up to a certain size) and fixed-size data structures. Five, there can be significant differences in performance based on the encoding used. These findings show that using machine learning models to learn data structure properties is very promising. We believe that these properties, once learned, can be used to provide a run-time check to see whether a program state at a particular point satisfies the learned property. Learned properties can also be employed in the future to automate static and dynamic analysis, which would enhance software testing and verification techniques.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {601–615},
numpages = {15},
keywords = {Learnability, Korat, Machine learning, Data structure invariants}
}

@inproceedings{10.1145/2491411.2491418,
author = {Rahman, Foyzur and Posnett, Daryl and Herraiz, Israel and Devanbu, Premkumar},
title = {Sample size vs. bias in defect prediction},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2491418},
doi = {10.1145/2491411.2491418},
abstract = {Most empirical disciplines promote the reuse and sharing of datasets, as it leads to greater possibility of replication. While this is increasingly the case in Empirical Software Engineering, some of the most popular bug-fix datasets are now known to be biased. This raises two significant concerns: first, that sample bias may lead to underperforming prediction models, and second, that the external validity of the studies based on biased datasets may be suspect. This issue has raised considerable consternation in the ESE literature in recent years. However, there is a confounding factor of these datasets that has not been examined carefully: size. Biased datasets are sampling only some of the data that could be sampled, and doing so in a biased fashion; but biased samples could be smaller, or larger. Smaller data sets in general provide less reliable bases for estimating models, and thus could lead to inferior model performance. In this setting, we ask the question, what affects performance more, bias, or size? We conduct a detailed, large-scale meta-analysis, using simulated datasets sampled with bias from a high-quality dataset which is relatively free of bias. Our results suggest that size always matters just as much bias direction, and in fact much more than bias direction when considering information-retrieval measures such as AUCROC and F-score. This indicates that at least for prediction models, even when dealing with sampling bias, simply finding larger samples can sometimes be sufficient. Our analysis also exposes the complexity of the bias issue, and raises further issues to be explored in the future.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {147–157},
numpages = {11},
keywords = {size, defect prediction, bias},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@inproceedings{10.1145/3452383.3452400,
author = {Misra, Janardan and Podder, Sanjay},
title = {Association of Defect Log Suitability for Machine Learning with Performance: An Experience Report},
year = {2021},
isbn = {9781450390460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452383.3452400},
doi = {10.1145/3452383.3452400},
abstract = {Machine learning (ML) based solutions utilizing textual details in defect logs have been shown to enable automation of defect management process and make it cost effective. In this work, we assess effectiveness of apriori manual analysis of the suitability of applying ML to problems encountered during defect management process. We consider problems of mapping defects to service engineers and business processes for designing experiments. Experimental analysis on these problems using multiple defect logs from practice reveals that a systematic analysis of the defect log data by project experts can provide approximate indication of the eventual performance of the ML model even before they are actually built. We discuss practical significance of the conclusions for designing ML based solutions in-practice.},
booktitle = {Proceedings of the 14th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {17},
numpages = {5},
keywords = {Assignee Recommendation, Business Process Mapping, Defect Management Life-Cycle, Machine Learning Suitability, Mining Defect Repositories, Text Analysis},
location = {Bhubaneswar, Odisha, India},
series = {ISEC '21}
}

@inproceedings{10.5555/2818754.2818850,
author = {Ghotra, Baljinder and McIntosh, Shane and Hassan, Ahmed E.},
title = {Revisiting the impact of classification techniques on the performance of defect prediction models},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Defect prediction models help software quality assurance teams to effectively allocate their limited resources to the most defect-prone software modules. A variety of classification techniques have been used to build defect prediction models ranging from simple (e.g., logistic regression) to advanced techniques (e.g., Multivariate Adaptive Regression Splines (MARS)). Surprisingly, recent research on the NASA dataset suggests that the performance of a defect prediction model is not significantly impacted by the classification technique that is used to train it. However, the dataset that is used in the prior study is both: (a) noisy, i.e., contains erroneous entries and (b) biased, i.e., only contains software developed in one setting. Hence, we set out to replicate this prior study in two experimental settings. First, we apply the replicated procedure to the same (known-to-be noisy) NASA dataset, where we derive similar results to the prior study, i.e., the impact that classification techniques have appear to be minimal. Next, we apply the replicated procedure to two new datasets: (a) the cleaned version of the NASA dataset and (b) the PROMISE dataset, which contains open source software developed in a variety of settings (e.g., Apache, GNU). The results in these new datasets show a clear, statistically distinct separation of groups of techniques, i.e., the choice of classification technique has an impact on the performance of defect prediction models. Indeed, contrary to earlier research, our results suggest that some classification techniques tend to produce defect prediction models that outperform others.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {789–800},
numpages = {12},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3338906.3342484,
author = {Moghadam, Mahshid Helali},
title = {Machine learning-assisted performance testing},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3342484},
doi = {10.1145/3338906.3342484},
abstract = {Automated testing activities like automated test case generation imply a reduction in human effort and cost, with the potential to impact the test coverage positively. If the optimal policy, i.e., the course of actions adopted, for performing the intended test activity could be learnt by the testing system, i.e., a smart tester agent, then the learnt policy could be reused in analogous situations which leads to even more efficiency in terms of required efforts. Performance testing under stress execution conditions, i.e., stress testing, which involves providing extreme test conditions to find the performance breaking points, remains a challenge, particularly for complex software systems. Some common approaches for generating stress test conditions are based on source code or system model analysis, or use-case based design approaches. However, source code or precise system models might not be easily available for testing. Moreover, drawing a precise performance model is often difficult, particularly for complex systems. In this research, I have used model-free reinforcement learning to build a self-adaptive autonomous stress testing framework which is able to learn the optimal policy for stress test case generation without having a model of the system under test. The conducted experimental analysis shows that the proposed smart framework is able to generate the stress test conditions for different software systems efficiently and adaptively without access to performance models.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1187–1189},
numpages = {3},
keywords = {Test case generation, Stress testing, Reinforcement learning, Performance testing, Autonomous testing},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1016/j.jss.2017.07.027,
author = {Zhang, Xiao-Yi and Zheng, Zheng and Cai, Kai-Yuan},
title = {Exploring the usefulness of unlabelled test cases in software fault localization},
year = {2018},
issue_date = {February 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {136},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.07.027},
doi = {10.1016/j.jss.2017.07.027},
abstract = {The usefulness of unlabelled test cases in fault localization is explored.An approach using test classification is proposed to utilize unlabelled test cases.A classifier utilizing the domain knowledge of fault localization is designed.Experiments are conducted to demonstrate the usefulness of our approach. In automatic software fault localization techniques, both the coverage and the testing outcomes of the provided test suite are considered to be essential information. The problem occurs when test oracles do not exist. Specifically, the test suite will contain a large number of unlabelled test cases, i.e., test cases whose output is not identified as being either correct (passing) or incorrect (failing). Such unlabelled test cases cannot be directly used, thereby leading to a degradation of localization effectiveness. In this paper, we propose an approach based on test classification to enable the use of unlabelled test cases in localizing faults. In our approach, unlabelled test cases are classified based on their execution information and are then assigned corresponding estimated labels to allow them to be utilized in fault localization. Experimental results show that with the utilization of these newly labelled test cases, the effectiveness of fault localization can indeed be improved.},
journal = {J. Syst. Softw.},
month = feb,
pages = {278–290},
numpages = {13},
keywords = {Unlabelled test cases, Test classification, Software testing, Software fault localization, Oracle problem}
}

@inproceedings{10.1145/3266003.3266004,
author = {de Santiago, Valdivino Alexandre and da Silva, Leoni Augusto Romain and de Andrade Neto, Pedro Ribeiro},
title = {Testing Environmental Models supported by Machine Learning},
year = {2018},
isbn = {9781450365550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3266003.3266004},
doi = {10.1145/3266003.3266004},
abstract = {In this paper we present a new methodology, DaOBML, to test environmental models whose outputs are complex artifacts such as images (maps) or plots. Our approach suggests several test data generation techniques (Combinatorial Interaction Testing, Model-Based Testing, Random Testing) and digital image processing methods to drive the creation of Knowledge Bases (KBs). Considering such KBs and Machine Learning (ML) algorithms, a test oracle assigns the verdicts of new test data. Our methodology is supported by a tool and we applied it to models developed via the TerraME product. A controlled experiment was carried out and we conclude that Random Testing is the most feasible test data generation approach for developing the KBs, Artificial Neural Networks present the best performance out of six ML algorithms, and the larger the KB, in terms of size, the better.},
booktitle = {Proceedings of the III Brazilian Symposium on Systematic and Automated Software Testing},
pages = {3–12},
numpages = {10},
keywords = {Random Testing, Model-Based Testing, Machine Learning, Environmental Modeling, Empirical Software Engineering, Digital Image Processing, Combinatorial Interaction Testing},
location = {SAO CARLOS, Brazil},
series = {SAST '18}
}

@article{10.1016/j.jss.2007.05.035,
author = {Gondra, Iker},
title = {Applying machine learning to software fault-proneness prediction},
year = {2008},
issue_date = {February, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {2},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.05.035},
doi = {10.1016/j.jss.2007.05.035},
abstract = {The importance of software testing to quality assurance cannot be overemphasized. The estimation of a module's fault-proneness is important for minimizing cost and improving the effectiveness of the software testing process. Unfortunately, no general technique for estimating software fault-proneness is available. The observed correlation between some software metrics and fault-proneness has resulted in a variety of predictive models based on multiple metrics. Much work has concentrated on how to select the software metrics that are most likely to indicate fault-proneness. In this paper, we propose the use of machine learning for this purpose. Specifically, given historical data on software metric values and number of reported errors, an Artificial Neural Network (ANN) is trained. Then, in order to determine the importance of each software metric in predicting fault-proneness, a sensitivity analysis is performed on the trained ANN. The software metrics that are deemed to be the most critical are then used as the basis of an ANN-based predictive model of a continuous measure of fault-proneness. We also view fault-proneness prediction as a binary classification task (i.e., a module can either contain errors or be error-free) and use Support Vector Machines (SVM) as a state-of-the-art classification method. We perform a comparative experimental study of the effectiveness of ANNs and SVMs on a data set obtained from NASA's Metrics Data Program data repository.},
journal = {J. Syst. Softw.},
month = feb,
pages = {186–195},
numpages = {10},
keywords = {Support vector machine, Software testing, Software metrics, Sensitivity analysis, Neural network, Machine learning, Fault-proneness}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00066,
author = {Wan, Chengcheng and Liu, Shicheng and Hoffmann, Henry and Maire, Michael and Lu, Shan},
title = {A replication of are machine learning cloud APIs used correctly},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00066},
doi = {10.1109/ICSE-Companion52605.2021.00066},
abstract = {This artifact aims to provide benchmark suite, data, and script used in our study "Are Machine Learning Cloud APIs Used Correctly?". We collected a suite of 360 non-trivial applications that use ML cloud APIs for manual study. We also developed checkers and tool to detect and fix API mis-uses. We hope this artifact can motivate and help future research to further tackle ML API mis-uses. All related data are available online.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {158–159},
numpages = {2},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@inproceedings{10.5555/3291291.3291297,
author = {Nascimento, Nathalia and Alencar, Paulo and Lucena, Carlos and Cowan, Donald},
title = {A context-aware machine learning-based approach},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {It is known that training a general and versatile Machine Learning (ML)-based model is more cost-effective than training several specialized ML-models for different operating contexts. However, as the volume of training information grows, the higher the probability of producing biased results. Learning bias is a critical problem for many applications, such as those related to healthcare scenarios, environmental monitoring and air traffic control. In this paper, we compare the use of a general model that was trained using all contexts against a system that is composed of a set of specialized models that was trained for each particular operating context. For this purpose, we propose a local learning approach based on context-awareness, which involves: (i) anticipating, analyzing and representing context changes; (ii) training and finding machine learning models to maximize a given scoring function for each operating context; (iii) storing trained ML-based models and associating them with corresponding operating contexts; and (iv) deploying a system that is able to select the best-fit ML-based model at runtime based on the context. To illustrate our proposed approach, we reproduce two experiments: one that uses a neural network regression-based model to perform predictions and another one that uses an evolutionary neural network-based approach to make decisions. For each application, we compare the results of the general model, which was trained based on all contexts, against the results of our proposed approach. We show that our context-aware approach can improve results by alleviating bias with different ML tasks.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {40–47},
numpages = {8},
keywords = {neural network, machine learning, learning bias, contextual modeling, context-awareness},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@inproceedings{10.1109/EUROMICRO.2006.56,
author = {Ceylan, Evren and Kutlubay, F. Onur and Bener, Ayse B.},
title = {Software Defect Identification Using Machine Learning Techniques},
year = {2006},
isbn = {0769525946},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/EUROMICRO.2006.56},
doi = {10.1109/EUROMICRO.2006.56},
abstract = {Software engineering is a tedious job that includes people, tight deadlines and limited budgets. Delivering what customer wants involves minimizing the defects in the programs. Hence, it is important to establish quality measures early on in the project life cycle. The main objective of this research is to analyze problems in software code and propose a model that will help catching those problems earlier in the project life cycle. Our proposed model uses machine learning methods. Principal Component Analysis is used for dimensionality reduction, and Decision Tree, Multi Layer Perceptron and Radial Basis Functions are used for defect prediction. The experiments in this research are carried out with different software metric datasets that are obtained from real-life projects of three big software companies in Turkey. We can say that, the improved method that we proposed brings out satisfactory results in terms of defect prediction.},
booktitle = {Proceedings of the 32nd EUROMICRO Conference on Software Engineering and Advanced Applications},
pages = {240–247},
numpages = {8},
series = {EUROMICRO '06}
}

@article{10.1007/s10586-018-1923-7,
author = {Viji, C. and Rajkumar, N. and Duraisamy, S.},
title = {Prediction of software fault-prone classes using an unsupervised hybrid SOM algorithm},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-018-1923-7},
doi = {10.1007/s10586-018-1923-7},
abstract = {In software engineering fault proneness prediction is one of the important fields for quality measurement using multiple code metrics. The metrics thresholds are very practical in measuring the code quality for fault proneness prediction. It helps to improvise the software quality in short time with very low cost. Many researchers are in the race to develop a measuring attribute for the software quality using various methodologies. Currently so many fault proneness prediction models are available. Among that most of the methods are used to identify the faults either by data history or by special supervising algorithms. In most of the real time cases the fault data bases may not be available so that the process becomes tedious. This article proposes a hybrid model for identifying the faults in the software models and also we proposed coupling model along with the algorithm so that the metrics are used to identify the faults and the coupling model couples the metrics and the faults for the developed system software.},
journal = {Cluster Computing},
month = jan,
pages = {133–143},
numpages = {11},
keywords = {ANN, Fault proneness, Coupling, Fault prediction, Software metrics}
}

@inproceedings{10.1145/3409501.3409543,
author = {Yan, Ziyue and Zong, Lu},
title = {Spatial Prediction of Housing Prices in Beijing Using Machine Learning Algorithms},
year = {2020},
isbn = {9781450375603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3409501.3409543},
doi = {10.1145/3409501.3409543},
abstract = {The real estate industry places key influence on almost every aspect of social economy given its great financing capacity and prolonged upstream and downstream industry chain. Therefore, predicting housing prices is regarded as an emerging topic in the recent decades. Hedonic Regression and Machine Learning Algorithms are two main methods in this field. This study aims to explore the important explanatory features and determine an accurate mechanism to implement spatial prediction of housing prices in Beijing by incorporating a list of machine learning techniques, including XGBoost, linear regression, Random Forest Regression, Ridge and Lasso Model, bagging and boosting, based on the housing price and features data in Beijing, China. Our result shows that compared to traditional hedonic method, machine learning methods demonstrate significant improvements on the accuracy of estimation despite that they are more time-costly. Moreover, it is found that XGBoost is the most accurate model in explaining and prediciting the spatial dynamics of housing prices in Beijing.},
booktitle = {Proceedings of the 2020 4th High Performance Computing and Cluster Technologies Conference &amp; 2020 3rd International Conference on Big Data and Artificial Intelligence},
pages = {64–71},
numpages = {8},
keywords = {Spatial Modeling, Prediction, Machine Learning Algorithms, Housing Price},
location = {Qingdao, China},
series = {HPCCT &amp; BDAI '20}
}

@article{10.1007/s10515-011-0090-3,
author = {He, Zhimin and Shu, Fengdi and Yang, Ye and Li, Mingshu and Wang, Qing},
title = {An investigation on the feasibility of cross-project defect prediction},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0090-3},
doi = {10.1007/s10515-011-0090-3},
abstract = {Software defect prediction helps to optimize testing resources allocation by identifying defect-prone modules prior to testing. Most existing models build their prediction capability based on a set of historical data, presumably from the same or similar project settings as those under prediction. However, such historical data is not always available in practice. One potential way of predicting defects in projects without historical data is to learn predictors from data of other projects. This paper investigates defect predictions in the cross-project context focusing on the selection of training data. We conduct three large-scale experiments on 34 data sets obtained from 10 open source projects. Major conclusions from our experiments include: (1) in the best cases, training data from other projects can provide better prediction results than training data from the same project; (2) the prediction results obtained using training data from other projects meet our criteria for acceptance on the average level, defects in 18 out of 34 cases were predicted at a Recall greater than 70% and a Precision greater than 50%; (3) results of cross-project defect predictions are related with the distributional characteristics of data sets which are valuable for training data selection. We further propose an approach to automatically select suitable training data for projects without historical data. Prediction results provided by the training data selected by using our approach are comparable with those provided by training data from the same project.},
journal = {Automated Software Engg.},
month = jun,
pages = {167–199},
numpages = {33},
keywords = {Training data, Machine learning, Defect prediction, Data characteristics, Cross-project}
}

@article{10.1016/j.asoc.2016.08.025,
author = {Erturk, Ezgi and Akcapinar Sezer, Ebru},
title = {Iterative software fault prediction with a hybrid approach},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.08.025},
doi = {10.1016/j.asoc.2016.08.025},
abstract = {Display Omitted To make software fault prediction (SFP) more beneficial, it should be into service at the beginning of the project.A novel prediction methodology based on existing methods (i.e. FIS, ANN) are proposed here.Version based development of software projects are considered to design an iterative prediction approach.Proposed methodology is developed as Eclipse plugin.Experiments show that proposed methodology gives promising results to use SFP in daily routine of software development phases. In this study, we consider a software fault prediction task that can assist a developer during the lifetime of a project. We aim to improve the performance of software fault prediction task while keeping it as applicable. Initial predictions are constructed by Fuzzy Inference Systems (FISs), whereas subsequent predictions are performed by data-driven methods. In this paper, an Artificial Neural Network and Adaptive Neuro Fuzzy Inference System are employed. We propose an iterative prediction model that begins with a FIS when no data are available for the software project and continues with a data-driven method when adequate data become available. To prove the usability of this iterative prediction approach, software fault prediction experiments are performed using expert knowledge for the initial version and information about previous versions for subsequent versions. The datasets employed in this paper comprise different versions of Ant, jEdit, Camel, Xalan, Log4j and Lucene projects from the PROMISE repository. The metrics of the models are common object-oriented metrics, such as coupling between objects, weighted methods per class and response for a class. The results of the models are evaluated according to the receiver operating characteristics with the area under the curve approach. The results indicate that the iterative software fault prediction is successful and can be transformed into a tool that can automatically locate fault-prone modules due to its well-organized information flow. We also implement the proposed methodology as a plugin for the Eclipse environment.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1020–1033},
numpages = {14},
keywords = {Software fault prediction, Iterative prediction, Fuzzy inference systems, Artificial neural network, Adaptive neuro fuzzy inference system}
}

@inproceedings{10.1145/3482909.3482911,
author = {Santos, Sebasti\~{a}o and Silveira, Beatriz and Durelli, Vinicius and Durelli, Rafael and Souza, Simone and Delamaro, Marcio},
title = {On Using Decision Tree Coverage Criteria forTesting Machine Learning Models},
year = {2021},
isbn = {9781450385039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3482909.3482911},
doi = {10.1145/3482909.3482911},
abstract = {Over the past decade, there has been a growing interest in applying machine learning (ML) to address a myriad of tasks. Owing to this interest, the adoption of ML-based systems has gone mainstream. However, this widespread adoption of ML-based systems poses new challenges for software testers that must improve the quality and reliability of these ML-based solutions. To cope with the challenges of testing ML-based systems, we propose novel test adequacy criteria based on decision tree models. Differently from the traditional approach to testing ML models, which relies on manual collection and labelling of data, our criteria leverage the internal structure of decision tree models to guide the selection of test inputs. Thus, we introduce decision tree coverage (DTC) and boundary value analysis (BVA) as approaches to systematically guide the creation of effective test data that exercises key structural elements of a given decision tree model. To evaluate these criteria, we carried out an experiment using 12 datasets. We measured the effectiveness of test inputs in terms of the difference in model’s behavior between the test input and the training data. The experiment results indicate that our testing criteria can be used to guide the generation of effective test data.},
booktitle = {Proceedings of the 6th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {1–9},
numpages = {9},
keywords = {Testing Criterion, Software Testing, Decision Tree},
location = {Joinville, Brazil},
series = {SAST '21}
}

@article{10.1016/j.infsof.2019.106214,
author = {Alsolai, Hadeel and Roper, Marc},
title = {A systematic literature review of machine learning techniques for software maintainability prediction},
year = {2020},
issue_date = {Mar 2020},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {119},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.106214},
doi = {10.1016/j.infsof.2019.106214},
journal = {Inf. Softw. Technol.},
month = mar,
numpages = {25},
keywords = {Dataset, Metric, Machine learning, Software maintainability prediction, Systematic literature review}
}

@inproceedings{10.5555/3507788.3507810,
author = {Korlepara, Piyush and Grigoriou, Marios and Kontogiannis, Kostas and Brealey, Chris and Giammaria, Alberto},
title = {Combining domain expert knowledge and machine learning for the identification of error prone files},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {Identifying as early as possible fault prone modules in order to facilitate continuous delivery in large software systems, has been an area where significant attention has been paid over the past few years. Recent efforts consider source code metrics and process metrics for training machine learning models to predict whether a software source code file is fault prone or not. In such prediction frameworks the accuracy of the trained model relies heavily on the features selected and the profiles of the metrics used for training the model which are unique to each system. Furthermore, these models act as black-boxes, where the end-user does not know how a specific prediction was reached. In this paper, we propose an approach which allows for domain expert knowledge to be combined with machine learning in order to yield fault-proneness prediction models that both exhibit high levels of recall and at the same time are able to provide explanations to the developers as to how and why these predictions were reached. For this paper we apply two rule-based inferencing techniques namely, Fuzzy reasoning, and Markov Logic Networks. The main contribution of this work is that it allows for expert developers to identify in the form of if-then rules domain logic that pertains to the fault-proneness of a source code file in the specific system being analysed. Results obtained from 19 open source systens indicate that MLNs perform better than Fuzzy Logic models and that project-customized rules achieve better results than generic rules. Furthermore, results indicate that its possible to compile a common set of rules that yields consistently acceptable results across different projects.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {153–162},
numpages = {10},
keywords = {software repositories, process metrics, fault-proneness prediction, continuous software engineering},
location = {Toronto, Canada},
series = {CASCON '21}
}

@article{10.1007/s10586-019-02917-1,
author = {Mohammed, Bashir and Awan, Irfan and Ugail, Hassan and Younas, Muhammad},
title = {Failure prediction using machine learning in a virtualised HPC system and application},
year = {2019},
issue_date = {Mar 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-019-02917-1},
doi = {10.1007/s10586-019-02917-1},
abstract = {Failure is an increasingly important issue in high performance computing and cloud systems. As large-scale systems continue to grow in scale and complexity, mitigating the impact of failure and providing accurate predictions with sufficient lead time remains a challenging research problem. Traditional existing fault-tolerance strategies such as regular check-pointing and replication are not adequate because of the emerging complexities of high performance computing systems. This necessitates the importance of having an effective as well as proactive failure management approach in place aimed at minimizing the effect of failure within the system. With the advent of machine learning techniques, the ability to learn from past information to predict future pattern of behaviours makes it possible to predict potential system failure more accurately. Thus, in this paper, we explore the predictive abilities of machine learning by applying a number of algorithms to improve the accuracy of failure prediction. We have developed a failure prediction model using time series and machine learning, and performed comparison based tests on the prediction accuracy. The primary algorithms we considered are the support vector machine (SVM), random forest (RF), k-nearest neighbors (KNN), classification and regression trees (CART) and linear discriminant analysis (LDA). Experimental results indicates that the average prediction accuracy of our model using SVM when predicting failure is 90% accurate and effective compared to other algorithms. This finding implies that our method can effectively predict all possible future system and application failures within the system.},
journal = {Cluster Computing},
month = jun,
pages = {471–485},
numpages = {15},
keywords = {Machine learning, High performance computing, Failure, Cloud computing}
}

@article{10.1007/s11219-020-09511-4,
author = {Moreno, Valent\'{\i}n and G\'{e}nova, Gonzalo and Parra, Eugenio and Fraga, Anabel},
title = {Application of machine learning techniques to the flexible assessment and improvement of requirements quality},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09511-4},
doi = {10.1007/s11219-020-09511-4},
abstract = {It is already common to compute quantitative metrics of requirements to assess their quality. However, the risk is to build assessment methods and tools that are both arbitrary and rigid in the parameterization and combination of metrics. Specifically, we show that a linear combination of metrics is insufficient to adequately compute a global measure of quality. In this work, we propose to develop a flexible method to assess and improve the quality of requirements that can be adapted to different contexts, projects, organizations, and quality standards, with a high degree of automation. The domain experts contribute with an initial set of requirements that they have classified according to their quality, and we extract their quality metrics. We then use machine learning techniques to emulate the implicit expert’s quality function. We provide also a procedure to suggest improvements in bad requirements. We compare the obtained rule-based classifiers with different machine learning algorithms, obtaining measurements of effectiveness around 85%. We show as well the appearance of the generated rules and how to interpret them. The method is tailorable to different contexts, different styles to write requirements, and different demands in quality. The whole process of inferring and applying the quality rules adapted to each organization is highly automated.},
journal = {Software Quality Journal},
month = dec,
pages = {1645–1674},
numpages = {30},
keywords = {Flexible assessment, Experts’ judgment, Automatic improvement, Automatic classification, Machine learning, Requirements quality}
}

@inproceedings{10.5555/2487085.2487161,
author = {Peters, Fayola and Menzies, Tim and Marcus, Andrian},
title = {Better cross company defect prediction},
year = {2013},
isbn = {9781467329361},
publisher = {IEEE Press},
abstract = {How can we find data for quality prediction? Early in the life cycle, projects may lack the data needed to build such predictors. Prior work assumed that relevant training data was found nearest to the local project. But is this the best approach?  This paper introduces the Peters filter which is based on the following conjecture: When local data is scarce, more information exists in other projects. Accordingly, this filter selects training data via the structure of other projects.  To assess the performance of the Peters filter, we compare it with two other approaches for quality prediction. Within- company learning and cross-company learning with the Burak filter (the state-of-the-art relevancy filter). This paper finds that: 1) within-company predictors are weak for small data-sets; 2) the Peters filter+cross-company builds better predictors than both within-company and the Burak filter+cross-company; and 3) the Peters filter builds 64% more useful predictors than both within- company and the Burak filter+cross-company approaches. Hence, we recommend the Peters filter for cross-company learning.},
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
pages = {409–418},
numpages = {10},
location = {San Francisco, CA, USA},
series = {MSR '13}
}

@inproceedings{10.1145/3387940.3391490,
author = {Liem, Cynthia C. S. and Panichella, Annibale},
title = {Oracle Issues in Machine Learning and Where to Find Them},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391490},
doi = {10.1145/3387940.3391490},
abstract = {The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed. For supervised ML applications, oracle information is indeed available in the form of dataset 'ground truth', that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system's integrity. While syntactic issues may automatically be verified and corrected, the higher-level issues traditionally need human judgment and manual analysis. In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for software engineering strategies that especially target and assess the oracle.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {483–488},
numpages = {6},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@article{10.1016/j.ins.2010.04.019,
author = {Peng, Yi and Wang, Guoxun and Wang, Honggang},
title = {User preferences based software defect detection algorithms selection using MCDM},
year = {2012},
issue_date = {May, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {191},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2010.04.019},
doi = {10.1016/j.ins.2010.04.019},
abstract = {A variety of classification algorithms for software defect detection have been developed over the years. How to select an appropriate classifier for a given task is an important issue in Data mining and knowledge discovery (DMKD). Many studies have compared different types of classification algorithms and the performances of these algorithms may vary using different performance measures and under different circumstances. Since the algorithm selection task needs to examine several criteria, such as accuracy, computational time, and misclassification rate, it can be modeled as a multiple criteria decision making (MCDM) problem. The goal of this paper is to use a set of MCDM methods to rank classification algorithms, with empirical results based on the software defect detection datasets. Since the preferences of the decision maker (DM) play an important role in algorithm evaluation and selection, this paper involved the DM during the ranking procedure by assigning user weights to the performance measures. Four MCDM methods are examined using 38 classification algorithms and 13 evaluation criteria over 10 public-domain software defect datasets. The results indicate that the boosting of CART and the boosting of C4.5 decision tree are ranked as the most appropriate algorithms for software defect datasets. Though the MCDM methods provide some conflicting results for the selected software defect datasets, they agree on most top-ranked classification algorithms.},
journal = {Inf. Sci.},
month = may,
pages = {3–13},
numpages = {11},
keywords = {Software defect detection, Multi-criteria decision making (MCDM), Knowledge-driven data mining, Classification algorithm, Algorithm selection}
}

@inproceedings{10.1145/3266237.3266273,
author = {Braga, Rony\'{e}rison and Neto, Pedro Santos and Rab\^{e}lo, Ricardo and Santiago, Jos\'{e} and Souza, Matheus},
title = {A machine learning approach to generate test oracles},
year = {2018},
isbn = {9781450365031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3266237.3266273},
doi = {10.1145/3266237.3266273},
abstract = {One of the essential activities for quality assurance in software development is the software testing. Studies report that Software Testing is one of the most costly activities in the development process, can reach up to 50 percent of its total cost. One of the great challenges of conducting software testing is related to the automation of a mechanism known as "test oracle". This work presents an approach based on machine learning (ML) for automation of the test oracle mechanism in software. The approach uses historical usage data from an application captured by inserting a capture component into the application under test. These data go through a Knowledge Discovery in Database step and are then used for training to generate an oracle suitable for the application under test. Four experiments were executed with web applications to evaluate the proposed approach. The first and second experiments were performed with a fictitious application, with faults inserted randomly in the first experiment, inserted by a developer in the second one and inserted by mutation tests in third one. The fourth experiment was carried out with a large real application in order to assure the results of the preliminary experiments. The experiments presented indications of the suitability of the approach to the solution of the problem.},
booktitle = {Proceedings of the XXXII Brazilian Symposium on Software Engineering},
pages = {142–151},
numpages = {10},
keywords = {testing automation, test oracle, machine learning},
location = {Sao Carlos, Brazil},
series = {SBES '18}
}

@article{10.1016/j.eswa.2014.10.025,
author = {Erturk, Ezgi and Sezer, Ebru Akcapinar},
title = {A comparison of some soft computing methods for software fault prediction},
year = {2015},
issue_date = {March 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2014.10.025},
doi = {10.1016/j.eswa.2014.10.025},
abstract = {Software fault prediction is implemented with ANN, SVM and ANFIS.First ANFIS implementation is applied to solve fault prediction problem.Parameters are discussed in neuro fuzzy approach.Experiments show that the application of ANFIS to the software fault prediction problem is highly reasonable. The main expectation from reliable software is the minimization of the number of failures that occur when the program runs. Determining whether software modules are prone to fault is important because doing so assists in identifying modules that require refactoring or detailed testing. Software fault prediction is a discipline that predicts the fault proneness of future modules by using essential prediction metrics and historical fault data. This study presents the first application of the Adaptive Neuro Fuzzy Inference System (ANFIS) for the software fault prediction problem. Moreover, Artificial Neural Network (ANN) and Support Vector Machine (SVM) methods, which were experienced previously, are built to discuss the performance of ANFIS. Data used in this study are collected from the PROMISE Software Engineering Repository, and McCabe metrics are selected because they comprehensively address the programming effort. ROC-AUC is used as a performance measure. The results achieved were 0.7795, 0.8685, and 0.8573 for the SVM, ANN and ANFIS methods, respectively.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {1872–1879},
numpages = {8},
keywords = {Support Vector Machines, Software fault prediction, McCabe metrics, Artificial Neural Networks, Adaptive neuro fuzzy systems}
}

@article{10.1007/s11334-017-0294-1,
author = {Pandey, Nitish and Sanyal, Debarshi Kumar and Hudait, Abir and Sen, Amitava},
title = {Automated classification of software issue reports using machine learning techniques: an empirical study},
year = {2017},
issue_date = {December  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-017-0294-1},
doi = {10.1007/s11334-017-0294-1},
abstract = {Software developers, testers and customers routinely submit issue reports to software issue trackers to record the problems they face in using a software. The issues are then directed to appropriate experts for analysis and fixing. However, submitters often misclassify an improvement request as a bug and vice versa. This costs valuable developer time. Hence automated classification of the submitted reports would be of great practical utility. In this paper, we analyze how machine learning techniques may be used to perform this task. We apply different classification algorithms, namely naive Bayes, linear discriminant analysis, k-nearest neighbors, support vector machine (SVM) with various kernels, decision tree and random forest separately to classify the reports from three open-source projects. We evaluate their performance in terms of F-measure, average accuracy and weighted average F-measure. Our experiments show that random forests perform best, while SVM with certain kernels also achieve high performance.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {279–297},
numpages = {19},
keywords = {Random forest, Machine learning, F-measure, Bug classification, Accuracy}
}

@article{10.1007/s10515-010-0069-5,
author = {Menzies, Tim and Milton, Zach and Turhan, Burak and Cukic, Bojan and Jiang, Yue and Bener, Ay\c{s}e},
title = {Defect prediction from static code features: current results, limitations, new approaches},
year = {2010},
issue_date = {December  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-010-0069-5},
doi = {10.1007/s10515-010-0069-5},
abstract = {Building quality software is expensive and software quality assurance (QA) budgets are limited. Data miners can learn defect predictors from static code features which can be used to control QA resources; e.g. to focus on the parts of the code predicted to be more defective.Recent results show that better data mining technology is not leading to better defect predictors. We hypothesize that we have reached the limits of the standard learning goal of maximizing area under the curve (AUC) of the probability of false alarms and probability of detection "AUC(pd, pf)"; i.e. the area under the curve of a probability of false alarm versus probability of detection.Accordingly, we explore changing the standard goal. Learners that maximize "AUC(effort, pd)" find the smallest set of modules that contain the most errors. WHICH is a meta-learner framework that can be quickly customized to different goals. When customized to AUC(effort, pd), WHICH out-performs all the data mining methods studied here. More importantly, measured in terms of this new goal, certain widely used learners perform much worse than simple manual methods.Hence, we advise against the indiscriminate use of learners. Learners must be chosen and customized to the goal at hand. With the right architecture (e.g. WHICH), tuning a learner to specific local business goals can be a simple task.},
journal = {Automated Software Engg.},
month = dec,
pages = {375–407},
numpages = {33},
keywords = {WHICH, Static code features, Defect prediction}
}

@inproceedings{10.1145/2811411.2811544,
author = {Siebra, Clauirton A. and Mello, Michael A. B.},
title = {The importance of replications in software engineering: a case study in defect prediction},
year = {2015},
isbn = {9781450337380},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811411.2811544},
doi = {10.1145/2811411.2811544},
abstract = {Prediction of defects in software is an important investigation area in software engineering, since such technique is able to return indications of parts of the code that are prone to contain problems. Thus, test teams can optimize the allocation of their resources by directing them to modules that are more defect-prone. The use of supervised learning is one of the approaches to support the design of prediction models. However, the erroneous use of training datasets can lead to poor models and, consequently, false results regarding accuracy. This work replicates important experiments of the area and shows how they could provide reliable results via the use of simple techniques of pre-processing. Based on the results, we discuss the importance of replications as method to find problems in current results and how this method is being motivated inside the software engineering area.},
booktitle = {Proceedings of the 2015 Conference on Research in Adaptive and Convergent Systems},
pages = {376–381},
numpages = {6},
keywords = {supervised learning, replication, defect prediction},
location = {Prague, Czech Republic},
series = {RACS '15}
}

@inproceedings{10.1109/ASE.2015.56,
author = {Nam, Jaechang and Kim, Sunghun},
title = {CLAMI: defect prediction on unlabeled datasets},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.56},
doi = {10.1109/ASE.2015.56},
abstract = {Defect prediction on new projects or projects with limited historical data is an interesting problem in software engineering. This is largely because it is difficult to collect defect information to label a dataset for training a prediction model. Cross-project defect prediction (CPDP) has tried to address this problem by reusing prediction models built by other projects that have enough historical data. However, CPDP does not always build a strong prediction model because of the different distributions among datasets. Approaches for defect prediction on unlabeled datasets have also tried to address the problem by adopting unsupervised learning but it has one major limitation, the necessity for manual effort.In this study, we propose novel approaches, CLA and CLAMI, that show the potential for defect prediction on unlabeled datasets in an automated manner without need for manual effort. The key idea of the CLA and CLAMI approaches is to label an unlabeled dataset by using the magnitude of metric values. In our empirical study on seven open-source projects, the CLAMI approach led to the promising prediction performances, 0.636 and 0.723 in average f-measure and AUC, that are comparable to those of defect prediction based on supervised learning.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {452–463},
numpages = {12},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@proceedings{10.1145/3416505,
title = {MaLTeSQuE 2020: Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the fourth edition of the workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE 2020) to be held virtually on November 16, 2020, co-located with the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2020).},
location = {Virtual, USA}
}

@inproceedings{10.5555/2040660.2040688,
author = {Wahyudin, Dindin and Ramler, Rudolf and Biffl, Stefan},
title = {A framework for defect prediction in specific software project contexts},
year = {2008},
isbn = {9783642223853},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software defect prediction has drawn the attention of many researchers in empirical software engineering and software maintenance due to its importance in providing quality estimates and to identify the needs for improvement from project management perspective. However, most defect prediction studies seem valid primarily in a particular context and little concern is given on how to find out which prediction model is well suited for a given project context. In this paper we present a framework for conducting software defect prediction as aid for the project manager in the context of a particular project or organization. The framework has been aligned with practitioners' requirements and is supported by our findings from a systematical literature review on software defect prediction. We provide a guide to the body of existing studies on defect prediction by mapping the results of the systematic literature review to the framework.},
booktitle = {Proceedings of the Third IFIP TC 2 Central and East European Conference on Software Engineering Techniques},
pages = {261–274},
numpages = {14},
keywords = {systematical literature review, software defect prediction, metric-based defect prediction},
location = {Brno, Czech Republic},
series = {CEE-SET'08}
}

@article{10.1145/3407183,
author = {Jagtap, Pushpak and Abdi, Fardin and Rungger, Matthias and Zamani, Majid and Caccamo, Marco},
title = {Software Fault Tolerance for Cyber-Physical Systems via Full System Restart},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
issn = {2378-962X},
url = {https://doi.org/10.1145/3407183},
doi = {10.1145/3407183},
abstract = {The article addresses the issue of reliability of complex embedded control systems in the safety-critical environment. In this article, we propose a novel approach to design controller that (i) guarantees the safety of nonlinear physical systems, (ii) enables safe system restart during runtime, and (iii) allows the use of complex, unverified controllers (e.g., neural networks) that drive the physical systems toward complex specifications. We use abstraction-based controller synthesis approach to design a formally verified controller that provides application and system-level fault tolerance along with safety guarantee. Moreover, our approach is implementable using a commercial-off-the-shelf (COTS) processing unit. To demonstrate the efficacy of our solution and to verify the safety of the system under various types of faults injected in applications and in the underlying real-time operating system (RTOS), we implemented the proposed controller for the inverted pendulum and three degrees-of-freedom (3-DOF) helicopter.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = aug,
articleno = {47},
numpages = {20},
keywords = {nonlinear systems, full system restart, fault-tolerance, abstraction-based control, Cyber-physical systems}
}

@article{10.1049/iet-sen.2014.0067,
author = {Fagundes, Roberta A.A. and Souza, Renata M.C.R. and Cysneiros, Francisco J.A.},
title = {Zero‐inflated prediction model in software‐fault data},
year = {2016},
issue_date = {February 2016},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {10},
number = {1},
url = {https://doi.org/10.1049/iet-sen.2014.0067},
doi = {10.1049/iet-sen.2014.0067},
abstract = {Software fault data with many zeroes in addition to large non‐zero values are common in the software estimation area. A two‐component prediction approach that provides a robust way to predict this type of data is introduced in this study. This approach allows to combine parametric and non‐parametric models to improve the prediction accuracy. This way provides a more flexible structure to understand data. To show the usefulness of the proposed approach, experiments using eight projects from the NASA repository are considered. In addition, this method is compared with methods from the machine learning and statistical literature. The performance of the methods is measured by the prediction accuracy that is assessed based on the mean magnitude of relative errors.},
journal = {IET Software},
month = feb,
pages = {1–9},
numpages = {9},
keywords = {statistical literature, machine learning, NASA repository, flexible structure, two-component prediction approach, software estimation area, software-fault data, zero-inflated prediction model, statistical analysis, learning (artificial intelligence), software fault tolerance}
}

@inproceedings{10.1145/2786805.2786813,
author = {Jing, Xiaoyuan and Wu, Fei and Dong, Xiwei and Qi, Fumin and Xu, Baowen},
title = {Heterogeneous cross-company defect prediction by unified metric representation and CCA-based transfer learning},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786813},
doi = {10.1145/2786805.2786813},
abstract = {Cross-company defect prediction (CCDP) learns a prediction model by using training data from one or multiple projects of a source company and then applies the model to the target company data. Existing CCDP methods are based on the assumption that the data of source and target companies should have the same software metrics. However, for CCDP, the source and target company data is usually heterogeneous, namely the metrics used and the size of metric set are different in the data of two companies. We call CCDP in this scenario as heterogeneous CCDP (HCCDP) task. In this paper, we aim to provide an effective solution for HCCDP. We propose a unified metric representation (UMR) for the data of source and target companies. The UMR consists of three types of metrics, i.e., the common metrics of the source and target companies, source-company specific metrics and target-company specific metrics. To construct UMR for source company data, the target-company specific metrics are set as zeros, while for UMR of the target company data, the source-company specific metrics are set as zeros. Based on the unified metric representation, we for the first time introduce canonical correlation analysis (CCA), an effective transfer learning method, into CCDP to make the data distributions of source and target companies similar. Experiments on 14 public heterogeneous datasets from four companies indicate that: 1) for HCCDP with partially different metrics, our approach significantly outperforms state-of-the-art CCDP methods; 2) for HCCDP with totally different metrics, our approach obtains comparable prediction performances in contrast with within-project prediction results. The proposed approach is effective for HCCDP.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {496–507},
numpages = {12},
keywords = {unified metric representation, company-specific metrics, common metrics, canonical correlation analysis (CCA), Heterogeneous cross-company defect prediction (HCCDP)},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1145/2020390.2020406,
author = {Paikari, Elham and Sun, Bo and Ruhe, Guenther and Livani, Emadoddin},
title = {Customization support for CBR-based defect prediction},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020406},
doi = {10.1145/2020390.2020406},
abstract = {Background: The prediction performance of a case-based reasoning (CBR) model is influenced by the combination of the following parameters: (i) similarity function, (ii) number of nearest neighbor cases, (iii) weighting technique used for attributes, and (iv) solution algorithm. Each combination of the above parameters is considered as an instantiation of the general CBR-based prediction method. The selection of an instantiation for a new data set with specific characteristics (such as size, defect density and language) is called customization of the general CBR method.Aims: For the purpose of defect prediction, we approach the question which combinations of parameters works best at which situation. Three more specific questions were studied:(RQ1) Does one size fit all? Is one instantiation always the best?(RQ2) If not, which individual and combined parameter settings occur most frequently in generating the best prediction results?(RQ3) Are there context-specific rules to support the customization?Method: In total, 120 different CBR instantiations were created and applied to 11 data sets from the PROMISE repository. Predictions were evaluated in terms of their mean magnitude of relative error (MMRE) and percentage Pred(α) of objects fulfilling a prediction quality level α. For the third research question, dependency network analysis was performed.Results: Most frequent parameter options for CBR instantiations were neural network based sensitivity analysis (as the weighting technique), un-weighted average (as the solution algorithm), and maximum number of nearest neighbors (as the number of nearest neighbors). Using dependency network analysis, a set of recommendations for customization was provided.Conclusion: An approach to support customization is provided. It was confirmed that application of context-specific rules across groups of similar data sets is risky and produces poor results.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {16},
numpages = {10},
keywords = {case-based reasoning, customization, defect prediction, dependency network analysis, instantiation},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@article{10.1016/j.infsof.2019.01.008,
author = {Meqdadi, Omar and Alhindawi, Nouh and Alsakran, Jamal and Saifan, Ahmad and Migdadi, Hatim},
title = {Mining software repositories for adaptive change commits using machine learning techniques},
year = {2019},
issue_date = {May 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {109},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.01.008},
doi = {10.1016/j.infsof.2019.01.008},
journal = {Inf. Softw. Technol.},
month = may,
pages = {80–91},
numpages = {12},
keywords = {Machine learning, Maintenance classification, Commit types, Adaptive maintenance, Code change metrics}
}

@article{10.1007/s10664-011-9180-x,
author = {Ekanayake, Jayalath and Tappolet, Jonas and Gall, Harald C. and Bernstein, Abraham},
title = {Time variance and defect prediction in software projects},
year = {2012},
issue_date = {August    2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4–5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-011-9180-x},
doi = {10.1007/s10664-011-9180-x},
abstract = {It is crucial for a software manager to know whether or not one can rely on a bug prediction model. A wrong prediction of the number or the location of future bugs can lead to problems in the achievement of a project's goals. In this paper we first verify the existence of variability in a bug prediction model's accuracy over time both visually and statistically. Furthermore, we explore the reasons for such a high variability over time, which includes periods of stability and variability of prediction quality, and formulate a decision procedure for evaluating prediction models before applying them. To exemplify our findings we use data from four open source projects and empirically identify various project features that influence the defect prediction quality. Specifically, we observed that a change in the number of authors editing a file and the number of defects fixed by them influence the prediction quality. Finally, we introduce an approach to estimate the accuracy of prediction models that helps a project manager decide when to rely on a prediction model. Our findings suggest that one should be aware of the periods of stability and variability of prediction quality and should use approaches such as ours to assess their models' accuracy in advance.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {348–389},
numpages = {42},
keywords = {Time variance, Mining software repository, Defect prediction, Decision tree learner, Concept drift}
}

@article{10.1145/3343440,
author = {Kaur, Harsurinder and Pannu, Husanbir Singh and Malhi, Avleen Kaur},
title = {A Systematic Review on Imbalanced Data Challenges in Machine Learning: Applications and Solutions},
year = {2019},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3343440},
doi = {10.1145/3343440},
abstract = {In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {79},
numpages = {36},
keywords = {sampling, machine learning, data analysis, Data imbalance}
}

@article{10.1016/j.jss.2019.03.027,
author = {Xu, Zhou and Li, Shuai and Luo, Xiapu and Liu, Jin and Zhang, Tao and Tang, Yutian and Xu, Jun and Yuan, Peipei and Keung, Jacky},
title = {TSTSS: A two-stage training subset selection framework for cross version defect prediction},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {154},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.03.027},
doi = {10.1016/j.jss.2019.03.027},
journal = {J. Syst. Softw.},
month = aug,
pages = {59–78},
numpages = {20},
keywords = {99-00, 00–01, Weighted extreme learning machine, Training subset selection, Spare modeling, Cross version defect prediction}
}

@inproceedings{10.1109/ACT.2009.212,
author = {Singh, Pradeep and Verma, Shirish},
title = {An Investigation of the Effect of Discretization on Defect Prediction Using Static Measures},
year = {2010},
isbn = {9780769539157},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ACT.2009.212},
doi = {10.1109/ACT.2009.212},
abstract = {Software repositories with defect logs are main resource for defect prediction. In recent years, researchers have used the vast amount of data that is contained by software repositories to predict the location of defect in the code that caused problems. In this paper we evaluate the effectiveness of software fault prediction with Naive-Bayes classifiers and J48 classifier by integrating with supervised discretization algorithm developed by Fayyad and Irani. Public datasets from the promise repository have been explored for this purpose. The repository contains software metric data and error data at the function/method level. Our experiment shows that integration of discretization method improves the software fault prediction accuracy when integrated with Naive-Bayes and J48 classifiers},
booktitle = {Proceedings of the 2009 International Conference on Advances in Computing, Control, and Telecommunication Technologies},
pages = {837–839},
numpages = {3},
keywords = {Software metrics, Machine learning, Defect prediction},
series = {ACT '09}
}

@article{10.1007/s11219-008-9053-8,
author = {Kastro, Yomi and Bener, Ay\c{s}e Basar},
title = {A defect prediction method for software versioning},
year = {2008},
issue_date = {December  2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-008-9053-8},
doi = {10.1007/s11219-008-9053-8},
abstract = {New methodologies and tools have gradually made the life cycle for software development more human-independent. Much of the research in this field focuses on defect reduction, defect identification and defect prediction. Defect prediction is a relatively new research area that involves using various methods from artificial intelligence to data mining. Identifying and locating defects in software projects is a difficult task. Measuring software in a continuous and disciplined manner provides many advantages such as the accurate estimation of project costs and schedules as well as improving product and process qualities. This study aims to propose a model to predict the number of defects in the new version of a software product with respect to the previous stable version. The new version may contain changes related to a new feature or a modification in the algorithm or bug fixes. Our proposed model aims to predict the new defects introduced into the new version by analyzing the types of changes in an objective and formal manner as well as considering the lines of code (LOC) change. Defect predictors are helpful tools for both project managers and developers. Accurate predictors may help reducing test times and guide developers towards implementing higher quality codes. Our proposed model can aid software engineers in determining the stability of software before it goes on production. Furthermore, such a model may provide useful insight for understanding the effects of a feature, bug fix or change in the process of defect detection.},
journal = {Software Quality Journal},
month = dec,
pages = {543–562},
numpages = {20},
keywords = {Software defects, Neural networks, Defect prediction}
}

@phdthesis{10.5555/AAI28022522,
author = {Islam, Md Johirul and Ciardo, Gianfranco and Prabhu, Gurpur and Tian, Jin and Sharma, Anuj},
advisor = {Hridesh, Rajan,},
title = {Towards Understanding the Challenges Faced by Machine Learning Software Developers and Enabling Automated Solutions},
year = {2020},
isbn = {9798672106496},
publisher = {Iowa State University},
address = {USA},
abstract = {Modern software systems are increasingly including machine learning (ML) as an integral component. However, we do not yet understand the difficulties faced by software developers when learning about ML libraries and using them within their systems. To fill that gap this thesis reports on a detailed (manual) examination of 3,243 highly-rated Q&amp;A posts related to ten ML libraries, namely Tensorflow, Keras, scikitlearn, Weka, Caffe, Theano, MLlib, Torch, Mahout, and H2O, on Stack Overflow, a popular online technical Q&amp;A forum. Our findings reveal the urgent need for software engineering (SE) research in this area.The second part of the thesis particularly focuses on understanding the Deep Neural Network (DNN) bug characteristics. We study 2,716 high-quality posts from Stack Overflow and 500 bug fix commits from Github about five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand the types of bugs, their root causes and impacts, bug-prone stage of deep learning pipeline as well as whether there are some common antipatterns found in this buggy software.While exploring the bug characteristics, our findings imply that repairing software that uses DNNs is one such unmistakable SE need where automated tools could be beneficial; however, we do not fully understand challenges to repairing and patterns that are utilized when manually repairing DNNs. So, the third part of this thesis presents a comprehensive study of bug fix patterns to address these questions. We have studied 415 repairs from Stack Overflow and 555 repairs from Github for five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand challenges in repairs and bug repair patterns. Our key findings reveal that DNN bug fix patterns are distinctive compared to traditional bug fix patterns and the most common bug fix patterns are fixing data dimension and neural network connectivity.Finally, we propose an automatic technique to detect ML Application Programming Interface (API) misuses. We started with an empirical study to understand ML API misuses. Our study shows that ML API misuse is prevalent and distinct compared to non-ML API misuses. Inspired by these findings, we contributed Amimla (Api Misuse In Machine Learning Apis) an approach and a tool for ML API misuse detection. Amimla relies on several technical innovations. First, we proposed an abstract representation of ML pipelines to use in misuse detection. Second, we proposed an abstract representation of neural networks for deep learning related APIs. Third, we have developed a representation strategy for constraints on ML APIs. Finally, we have developed a misuse detection strategy for both single and multi-APIs. Our experimental evaluation shows that Amimla achieves a high average accuracy of ∼80% on two benchmarks of misuses from Stack Overflow and Github.},
note = {AAI28022522}
}

@inproceedings{10.1145/3338906.3338937,
author = {Aggarwal, Aniya and Lohia, Pranay and Nagar, Seema and Dey, Kuntal and Saha, Diptikalyan},
title = {Black box fairness testing of machine learning models},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338937},
doi = {10.1145/3338906.3338937},
abstract = {Any given AI system cannot be accepted unless its trustworthiness is proven. An important characteristic of a trustworthy AI system is the absence of algorithmic bias. 'Individual discrimination' exists when a given individual different from another only in 'protected attributes' (e.g., age, gender, race, etc.) receives a different decision outcome from a given machine learning (ML) model as compared to the other individual. The current work addresses the problem of detecting the presence of individual discrimination in given ML models. Detection of individual discrimination is test-intensive in a black-box setting, which is not feasible for non-trivial systems. We propose a methodology for auto-generation of test inputs, for the task of detecting individual discrimination. Our approach combines two well-established techniques - symbolic execution and local explainability for effective test case generation. We empirically show that our approach to generate test cases is very effective as compared to the best-known benchmark systems that we examine.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {625–635},
numpages = {11},
keywords = {Symbolic Execution, Local Explainability, Individual Discrimination, Fairness Testing},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1016/j.infsof.2013.02.009,
author = {Radjenovi\'{c}, Danijel and Heri\v{c}ko, Marjan and Torkar, Richard and \v{Z}ivkovi\v{c}, Ale\v{s}},
title = {Software fault prediction metrics},
year = {2013},
issue_date = {August 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.02.009},
doi = {10.1016/j.infsof.2013.02.009},
abstract = {ContextSoftware metrics may be used in fault prediction models to improve software quality by predicting fault location. ObjectiveThis paper aims to identify software metrics and to assess their applicability in software fault prediction. We investigated the influence of context on metrics' selection and performance. MethodThis systematic literature review includes 106 papers published between 1991 and 2011. The selected papers are classified according to metrics and context properties. ResultsObject-oriented metrics (49%) were used nearly twice as often compared to traditional source code metrics (27%) or process metrics (24%). Chidamber and Kemerer's (CK) object-oriented metrics were most frequently used. According to the selected studies there are significant differences between the metrics used in fault prediction performance. Object-oriented and process metrics have been reported to be more successful in finding faults compared to traditional size and complexity metrics. Process metrics seem to be better at predicting post-release faults compared to any static code metrics. ConclusionMore studies should be performed on large industrial software systems to find metrics more relevant for the industry and to answer the question as to which metrics should be used in a given context.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {1397–1418},
numpages = {22},
keywords = {Systematic literature review, Software metric, Software fault prediction}
}

@article{10.4018/IJSSCI.2016070102,
author = {Rashid, Ekbal},
title = {R4 Model for Case-Based Reasoning and Its Application for Software Fault Prediction},
year = {2016},
issue_date = {July 2016},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {3},
issn = {1942-9045},
url = {https://doi.org/10.4018/IJSSCI.2016070102},
doi = {10.4018/IJSSCI.2016070102},
abstract = {Making R4 model effective and efficient I have introduced some new features, i.e., renovation of knowledgebase KBS and reducing the maintenance cost by removing the duplicate record from the KBS. Renovation of knowledgebase is the process of removing duplicate record stored in knowledgebase and adding world new problems along with world new solutions. This paper explores case-based reasoning and its applications for software quality improvement through early prediction of error patterns. It summarizes a variety of techniques for software quality prediction in the domain of software engineering. The system predicts the error level with respect to LOC and with respect to development time, and both affects the quality level. This paper also reviews four existing models of case-based reasoning CBR. The paper presents a work in which I have expanded our previous work Rashid et al., 2012. I have used different similarity measures to find the best method that increases reliability. The present work is also credited through introduction of some new terms like coefficient of efficiency, i.e., developer's ability.},
journal = {Int. J. Softw. Sci. Comput. Intell.},
month = jul,
pages = {19–38},
numpages = {20},
keywords = {Software Fault Prediction, Similarity Function, Reliability, Machine Learning, LOC, Development Time}
}

@article{10.1007/s40595-013-0008-z,
author = {Abaei, Golnoush and Selamat, Ali},
title = {A survey on software fault detection based on different prediction approaches},
year = {2014},
issue_date = {May       2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {2},
issn = {2196-8888},
url = {https://doi.org/10.1007/s40595-013-0008-z},
doi = {10.1007/s40595-013-0008-z},
abstract = {One of the software engineering interests is quality assurance activities such as testing, verification and validation, fault tolerance and fault prediction. When any company does not have sufficient budget and time for testing the entire application, a project manager can use some fault prediction algorithms to identify the parts of the system that are more defect prone. There are so many prediction approaches in the field of software engineering such as test effort, security and cost prediction. Since most of them do not have a stable model, software fault prediction has been studied in this paper based on different machine learning techniques such as decision trees, decision tables, random forest, neural network, Na\"{\i}ve Bayes and distinctive classifiers of artificial immune systems (AISs) such as artificial immune recognition system, CLONALG and Immunos. We use four public NASA datasets to perform our experiment. These datasets are different in size and number of defective data. Distinct parameters such as method-level metrics and two feature selection approaches which are principal component analysis and correlation based feature selection are used to evaluate the finest performance among the others. According to this study, random forest provides the best prediction performance for large data sets and Na\"{\i}ve Bayes is a trustable algorithm for small data sets even when one of the feature selection techniques is applied. Immunos99 performs well among AIS classifiers when feature selection technique is applied, and AIRSParallel performs better without any feature selection techniques. The performance evaluation has been done based on three different metrics such as area under receiver operating characteristic curve, probability of detection and probability of false alarm. These three evaluation metrics could give the reliable prediction criteria together.},
journal = {Vietnam J. of Computer Science},
month = may,
pages = {79–95},
numpages = {17},
keywords = {Software fault prediction, Random forest, Machine learning, CSCA, Artificial immune system, AISParallel}
}

@phdthesis{10.5555/AAI28216179,
author = {Li, Xia},
advisor = {Lingming, Zhang,},
title = {An Integrated Approach for Automated Software Debugging via Machine Learning and Big Code Mining},
year = {2020},
isbn = {9798678186591},
publisher = {The University of Texas at Dallas},
abstract = {Over the past decades, software systems have been widely adopted in almost all aspects of human lives, and are making our lives more and more convenient. However, software systems also inevitably suffer from different faults (a.k.a., bugs), which can incur great loss of properties and even lives. Due to the huge code volume, manual debugging can be always time-consuming and error-prone. This thesis is a novel integrated approach for automated debugging that can help localize and detect different software faults. Specifically, fault localization (FL) can help localize the potential faulty location(s) if some test cases fail in a program while API-misuse detection can help detect API related bugs due to API misuses without the execution of test cases. We seek to improve the effectiveness of fault localization and API misuses detection by applying knowledge from various fields such as static and dynamic program analysis, machine learning/deep learning techniques, as well as mining big code repositories. In this dissertation, we propose two fault localization techniques and one API-misuse detection technique. The first fault localization technique is called TraPT, which is a learning-to-rank-based technique to combine transformed impact information extracted from mutation-based fault localization (MBFL) and coverage information extracted from spectrum-based fault localization (SBFL). The second fault localization technique is called DeepFL which is the first deep-learning-based fault localization technique integrating various dynamic and static program features. The two fault localization techniques rely on high-quality test cases to capture necessary program features but not all software systems can provide such tests, making fault localization techniques not always available. To solve more comprehensive debugging problems, we also propose an API-misuse detection technique called BiD3 based on the analysis of a large-scale of bug-fixing commits (958,368 commits in total) in history, which doesn't require the execution of test cases. Various experiments on the three techniques show the promising effectiveness. For example, DeepFL can localize 213 faults within Top-1 out of 395 real faults, 53 more faults than state-of-the-art technique (33.1% improvement). BiD3 can detect 360 real misuses in the latest Apache projects and 57 misuses have been confirmed and fixed by developers.},
note = {AAI28216179}
}

@inproceedings{10.1109/ICSE.2019.00029,
author = {He, Zhijian and Chen, Yao and Huang, Enyan and Wang, Qixin and Pei, Yu and Yuan, Haidong},
title = {A system identification based Oracle for control-CPS software fault localization},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00029},
doi = {10.1109/ICSE.2019.00029},
abstract = {Control-CPS software fault localization (SFL, aka bug localization) is of critical importance as bugs may cause major failures, even injuries/deaths. To locate the bugs in control-CPSs, SFL tools often demand many labeled ("correct"/"incorrect") source code execution traces as inputs. To label the correctness of these traces, we must judge the corresponding control-CPS physical trajectories' correctness. However, unlike discrete outputs, the boundaries between correct and incorrect physical trajectories are often vague. The mechanism (aka oracle) to judge the physical trajectories' correctness thus becomes a major challenge. So far, the ad hoc practice of "human oracles" is still widely used, whose qualities heavily depend on the human experts' expertise and availability. This paper proposes an oracle based on the well adopted autoregressive system identification (AR-SI). With proven success for controlling black-box physical systems, AR-SI is adapted by us to identify the buggy control-CPS as a black-box. We use this identification result as an oracle to judge the control-CPS's behaviors, and propose a methodology to prepare traces for control-CPS debugging. Comprehensive evaluations on classic control-CPSs with injected real-life and artificial bugs show that our proposed approach significantly outperforms the human oracle approach in SFL accuracy (recall) and latency, and in oracle false positive/negative rates. Our approach also helps discover a new real-life bug in a consumer-grade control-CPS.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {116–127},
numpages = {12},
keywords = {testing, oracle, debug, cyber-physical system},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/2499393.2499397,
author = {Tass\'{e}, Jos\'{e}e},
title = {Using code change types in an analogy-based classifier for short-term defect prediction},
year = {2013},
isbn = {9781450320160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499393.2499397},
doi = {10.1145/2499393.2499397},
abstract = {Current approaches for defect prediction usually analyze files (or modules) and their development as work is done on a given release, to predict post-release defects. What is missing is an approach for predicting bugs to be detected in a more short-term interval, even within the development of a particular version. In this paper, we propose a defect predictor that looks into change bursts in a given file, analyzing the number of changes and their types, and then predict whether the file is likely to have a bug found within the next 3 months after that change burst. An analogy-based classifier is used for this task: the prediction is made based on comparisons with similar change bursts that occurred in other files. New metrics are described to capture the change type of a file (e.g., small local change, massive change all in one place, multiple changes scattered throughout the file).},
booktitle = {Proceedings of the 9th International Conference on Predictive Models in Software Engineering},
articleno = {5},
numpages = {4},
keywords = {analogy-based classifier, change burst, change type metrics, defect prediction, short-term prediction},
location = {Baltimore, Maryland, USA},
series = {PROMISE '13}
}

@article{10.1016/j.ins.2019.03.045,
author = {Li, Jin and Palmieri, Francesco and Xiang, Yang},
title = {Special Issue on Security and Privacy in Machine Learning},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {487},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.03.045},
doi = {10.1016/j.ins.2019.03.045},
journal = {Inf. Sci.},
month = jun,
pages = {208–209},
numpages = {2}
}

@article{10.1504/IJDATS.2016.075971,
author = {Erturk, Ezgi and Sezer, Ebru Akcapinar},
title = {Software fault prediction using Mamdani type fuzzy inference system},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {8},
number = {1},
issn = {1755-8050},
url = {https://doi.org/10.1504/IJDATS.2016.075971},
doi = {10.1504/IJDATS.2016.075971},
abstract = {High quality software requires the occurrence of minimum number of failures while software runs. Software fault prediction is the determining whether software modules are prone to fault or not. Identification of the modules or code segments which need detailed testing, editing or, reorganising can be possible with the help of software fault prediction systems. In literature, many studies present models for software fault prediction using some soft computing methods which use training/testing phases. As a result, they require historical data to build models. In this study, to eliminate this drawback, Mamdani type fuzzy inference system FIS is applied for the software fault prediction problem. Several FIS models are produced and assessed with ROC-AUC as performance measure. The results achieved are ranging between 0.7138 and 0.7304; they are encouraging us to try FIS with the different software metrics and data to demonstrate general FIS performance on this problem.},
journal = {Int. J. Data Anal. Tech. Strateg.},
month = apr,
pages = {14–28},
numpages = {15}
}

@article{10.1145/3212695,
author = {Allamanis, Miltiadis and Barr, Earl T. and Devanbu, Premkumar and Sutton, Charles},
title = {A Survey of Machine Learning for Big Code and Naturalness},
year = {2018},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3212695},
doi = {10.1145/3212695},
abstract = {Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {81},
numpages = {37},
keywords = {software engineering tools, machine learning, code naturalness, Big code}
}

@inproceedings{10.1145/2393596.2393669,
author = {Rahman, Foyzur and Posnett, Daryl and Devanbu, Premkumar},
title = {Recalling the "imprecision" of cross-project defect prediction},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393596.2393669},
doi = {10.1145/2393596.2393669},
abstract = {There has been a great deal of interest in defect prediction: using prediction models trained on historical data to help focus quality-control resources in ongoing development. Since most new projects don't have historical data, there is interest in cross-project prediction: using data from one project to predict defects in another. Sadly, results in this area have largely been disheartening. Most experiments in cross-project defect prediction report poor performance, using the standard measures of precision, recall and F-score. We argue that these IR-based measures, while broadly applicable, are not as well suited for the quality-control settings in which defect prediction models are used. Specifically, these measures are taken at specific threshold settings (typically thresholds of the predicted probability of defectiveness returned by a logistic regression model). However, in practice, software quality control processes choose from a range of time-and-cost vs quality tradeoffs: how many files shall we test? how many shall we inspect? Thus, we argue that measures based on a variety of tradeoffs, viz., 5%, 10% or 20% of files tested/inspected would be more suitable. We study cross-project defect prediction from this perspective. We find that cross-project prediction performance is no worse than within-project performance, and substantially better than random prediction!},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {61},
numpages = {11},
keywords = {inspection, fault prediction, empirical software engineering},
location = {Cary, North Carolina},
series = {FSE '12}
}

@inproceedings{10.5555/2042243.2042277,
author = {Rodr\'{\i}guez, Daniel and Ruiz, R. and Riquelme, J. C. and Harrison, Rachel},
title = {Subgroup discovery for defect prediction},
year = {2011},
isbn = {9783642237157},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Proceedings of the Third International Conference on Search Based Software Engineering},
pages = {269–270},
numpages = {2},
location = {Szeged, Hungary},
series = {SSBSE'11}
}

@inproceedings{10.1145/3395363.3404540,
author = {Tizpaz-Niari, Saeid and \v{C}ern\'{y}, Pavol and Trivedi, Ashutosh},
title = {Detecting and understanding real-world differential performance bugs in machine learning libraries},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3404540},
doi = {10.1145/3395363.3404540},
abstract = {Programming errors that degrade the performance of systems are widespread, yet there is very little tool support for finding and diagnosing these bugs. We present a method and a tool based on differential performance analysis---we find inputs for which the performance varies widely, despite having the same size. To ensure that the differences in the performance are robust (i.e. hold also for large inputs), we compare the performance of not only single inputs, but of classes of inputs, where each class has similar inputs parameterized by their size. Thus, each class is represented by a performance function from the input size to performance. Importantly, we also provide an explanation for why the performance differs in a form that can be readily used to fix a performance bug. The two main phases in our method are discovery with fuzzing and explanation with decision tree classifiers, each of which is supported by clustering. First, we propose an evolutionary fuzzing algorithm to generate inputs that characterize different performance functions. For this fuzzing task, the unique challenge is that we not only need the input class with the worst performance, but rather a set of classes exhibiting differential performance. We use clustering to merge similar input classes which significantly improves the efficiency of our fuzzer. Second, we explain the differential performance in terms of program inputs and internals (e.g., methods and conditions). We adapt discriminant learning approaches with clustering and decision trees to localize suspicious code regions. We applied our techniques on a set of micro-benchmarks and real-world machine learning libraries. On a set of micro-benchmarks, we show that our approach outperforms state-of-the-art fuzzers in finding inputs to characterize differential performance. On a set of case-studies, we discover and explain multiple performance bugs in popular machine learning frameworks, for instance in implementations of logistic regression in scikit-learn. Four of these bugs, reported first in this paper, have since been fixed by the developers.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {189–199},
numpages = {11},
keywords = {Testing, ML Libraries, Differential Performance Bugs, Debugging},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@article{10.1145/3092566,
author = {Ghaffarian, Seyed Mohammad and Shahriari, Hamid Reza},
title = {Software Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey},
year = {2017},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092566},
doi = {10.1145/3092566},
abstract = {Software security vulnerabilities are one of the critical issues in the realm of computer security. Due to their potential high severity impacts, many different approaches have been proposed in the past decades to mitigate the damages of software vulnerabilities. Machine-learning and data-mining techniques are also among the many approaches to address this issue. In this article, we provide an extensive review of the many different works in the field of software vulnerability analysis and discovery that utilize machine-learning and data-mining techniques. We review different categories of works in this domain, discuss both advantages and shortcomings, and point out challenges and some uncharted territories in the field.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {56},
numpages = {36},
keywords = {survey, software vulnerability discovery, software security, review, machine-learning, data-mining, Software vulnerability analysis}
}

@inproceedings{10.1007/978-3-030-58817-5_66,
author = {Kumari, Madhu and Singh, Ujjawal Kumar and Sharma, Meera},
title = {Entropy Based Machine Learning Models for Software Bug Severity Assessment in Cross Project Context},
year = {2020},
isbn = {978-3-030-58816-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58817-5_66},
doi = {10.1007/978-3-030-58817-5_66},
abstract = {There can be noise and uncertainty in the bug reports data as the bugs are reported by a heterogeneous group of users working across different countries. Bug description is an essential attribute that helps to predict other bug attributes, such as severity, priority, and time fixes. We need to consider the noise and confusion present in the text of the bug report, as it can impact the output of different machine learning techniques. Shannon entropy has been used in this paper to calculate summary uncertainty about the bug. Bug severity attribute tells about the type of impact the bug has on the functionality of the software. Correct bug severity estimation allows scheduling and repair bugs and hence help in resource and effort utilization. To predict the severity of the bug we need software project historical data to train the classifier. These training data are not always available in particular for new software projects. The solution which is called cross project prediction is to use the training data from other projects. Using bug priority, summary weight and summary entropy, we have proposed cross project bug severity assessment models. Results for proposed summary entropy based approach for bug severity prediction in cross project context show improved performance of the Accuracy and F-measure up to 70.23% and 93.72% respectively across all the machine learning techniques over existing work.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part VI},
pages = {939–953},
numpages = {15},
location = {Cagliari, Italy}
}

@inproceedings{10.1145/3180155.3180197,
author = {Agrawal, Amritanshu and Menzies, Tim},
title = {Is "better data" better than "better data miners"? on the benefits of tuning SMOTE for defect prediction},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180197},
doi = {10.1145/3180155.3180197},
abstract = {We report and fix an important systematic error in prior studies that ranked classifiers for software analytics. Those studies did not (a) assess classifiers on multiple criteria and they did not (b) study how variations in the data affect the results. Hence, this paper applies (a) multi-performance criteria while (b) fixing the weaker regions of the training data (using SMOTUNED, which is an auto-tuning version of SMOTE). This approach leads to dramatically large increases in software defect predictions when applied in a 5*5 cross-validation study for 3,681 JAVA classes (containing over a million lines of code) from open source systems, SMOTUNED increased AUC and recall by 60% and 20% respectively. These improvements are independent of the classifier used to predict for defects. Same kind of pattern (improvement) was observed when a comparative analysis of SMOTE and SMOTUNED was done against the most recent class imbalance technique.In conclusion, for software analytic tasks like defect prediction, (1) data pre-processing can be more important than classifier choice, (2) ranking studies are incomplete without such pre-processing, and (3) SMOTUNED is a promising candidate for pre-processing.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {1050–1061},
numpages = {12},
keywords = {SMOTE, classification, data analytics for software engineering, defect prediction, preprocessing, search based SE, unbalanced data},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1016/j.infsof.2021.106653,
author = {Xiao, Xi and Pan, Yuqing and Zhang, Bin and Hu, Guangwu and Li, Qing and Lu, Runiu},
title = {ALBFL: A novel neural ranking model for software fault localization via combining static and dynamic features},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106653},
doi = {10.1016/j.infsof.2021.106653},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {11},
keywords = {Software quality, Learning to rank, Fault localization, Attention mechanism}
}

@inproceedings{10.1109/ICPC.2019.00023,
author = {Pecorelli, Fabiano and Palomba, Fabio and Di Nucci, Dario and De Lucia, Andrea},
title = {Comparing heuristic and machine learning approaches for metric-based code smell detection},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICPC.2019.00023},
doi = {10.1109/ICPC.2019.00023},
abstract = {Code smells represent poor implementation choices performed by developers when enhancing source code. Their negative impact on source code maintainability and comprehensibility has been widely shown in the past and several techniques to automatically detect them have been devised. Most of these techniques are based on heuristics, namely they compute a set of code metrics and combine them by creating detection rules; while they have a reasonable accuracy, a recent trend is represented by the use of machine learning where code metrics are used as predictors of the smelliness of code artefacts. Despite the recent advances in the field, there is still a noticeable lack of knowledge of whether machine learning can actually be more accurate than traditional heuristic-based approaches. To fill this gap, in this paper we propose a large-scale study to empirically compare the performance of heuristic-based and machine-learning-based techniques for metric-based code smell detection. We consider five code smell types and compare machine learning models with Decor, a state-of-the-art heuristic-based approach. Key findings emphasize the need of further research aimed at improving the effectiveness of both machine learning and heuristic approaches for code smell detection: while Decor generally achieves better performance than a machine learning baseline, its precision is still too low to make it usable in practice.},
booktitle = {Proceedings of the 27th International Conference on Program Comprehension},
pages = {93–104},
numpages = {12},
keywords = {machine learning, heuristics, empirical study, code smells detection},
location = {Montreal, Quebec, Canada},
series = {ICPC '19}
}

@article{10.1016/j.infsof.2010.06.006,
author = {Tosun, Ay\c{s}e and Bener, Ay\c{s}e and Turhan, Burak and Menzies, Tim},
title = {Practical considerations in deploying statistical methods for defect prediction: A case study within the Turkish telecommunications industry},
year = {2010},
issue_date = {November, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {11},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2010.06.006},
doi = {10.1016/j.infsof.2010.06.006},
abstract = {Context: Building defect prediction models in large organizations has many challenges due to limited resources and tight schedules in the software development lifecycle. It is not easy to collect data, utilize any type of algorithm and build a permanent model at once. We have conducted a study in a large telecommunications company in Turkey to employ a software measurement program and to predict pre-release defects. Based on our prior publication, we have shared our experience in terms of the project steps (i.e. challenges and opportunities). We have further introduced new techniques that improve our earlier results. Objective: In our previous work, we have built similar predictors using data representative for US software development. Our task here was to check if those predictors were specific solely to US organizations or to a broader class of software. Method: We have presented our approach and results in the form of an experience report. Specifically, we have made use of different techniques for improving the information content of the software data and the performance of a Naive Bayes classifier in the prediction model that is locally tuned for the company. We have increased the information content of the software data by using module dependency data and improved the performance by adjusting the hyper-parameter (decision threshold) of the Naive Bayes classifier. We have reported and discussed our results in terms of defect detection rates and false alarms. We also carried out a cost-benefit analysis to show that our approach can be efficiently put into practice. Results: Our general result is that general defect predictors, which exist across a wide range of software (in both US and Turkish organizations), are present. Our specific results indicate that concerning the organization subject to this study, the use of version history information along with code metrics decreased false alarms by 22%, the use of dependencies between modules further reduced false alarms by 8%, and the decision threshold optimization for the Naive Bayes classifier using code metrics and version history information further improved false alarms by 30% in comparison to a prediction using only code metrics and a default decision threshold. Conclusion: Implementing statistical techniques and machine learning on a real life scenario is a difficult yet possible task. Using simple statistical and algorithmic techniques produces an average detection rate of 88%. Although using dependency data improves our results, it is difficult to collect and analyze such data in general. Therefore, we would recommend optimizing the hyper-parameter of the proposed technique, Naive Bayes, to calibrate the defect prediction model rather than employing more complex classifiers. We also recommend that researchers who explore statistical and algorithmic methods for defect prediction should spend less time on their algorithms and more time on studying the pragmatic considerations of large organizations.},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {1242–1257},
numpages = {16},
keywords = {Static code attributes, Software defect prediction, Na\"{\i}ve Bayes, Experience report}
}

@article{10.5555/3292849.3292858,
title = {A hybrid approach to improve the quality of software fault prediction using Na\"{\i}ve Bayes and k-NN classification algorithm with ensemble method},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {17},
number = {4},
issn = {1740-8865},
abstract = {This paper considers an improvisation in software fault prediction research area using supervised classification algorithms and it mainly focuses to increase the performance of fault prediction. In this paper, we propose a hybrid prediction model using Na\"{\i}ve Bayes and k-nearest neighbour classification algorithm with vote ensemble method; in short it called as hNK. The goal of this model is to predict the best classification algorithm for software fault prediction based on the metrics and attributes of datasets. In the work, we have applied training sets and testing sets in hNK model with ensemble vote and we proposed the model to identify a suitable classification algorithm for fault prediction based on the accuracy and precision. We have achieved better results using hNK model for classifying supervised algorithms with different dataset.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {483–496},
numpages = {14}
}

@article{10.1007/s10664-008-9064-x,
author = {Hewett, Rattikorn and Kijsanayothin, Phongphun},
title = {On modeling software defect repair time},
year = {2009},
issue_date = {April     2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-008-9064-x},
doi = {10.1007/s10664-008-9064-x},
abstract = {The ability to predict the time required to repair software defects is important for both software quality management and maintenance. Estimated repair times can be used to improve the reliability and time-to-market of software under development. This paper presents an empirical approach to predicting defect repair times by constructing models that use well-established machine learning algorithms and defect data from past software defect reports. We describe, as a case study, the analysis of defect reports collected during the development of a large medical software system. Our predictive models give accuracies as high as 93.44%, despite the limitations of the available data. We present the proposed methodology along with detailed experimental results, which include comparisons with other analytical modeling approaches.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {165–186},
numpages = {22},
keywords = {Testing management, Software testing, Quality assurance, Defect report analysis, Data mining}
}

@article{10.1016/j.procs.2015.02.154,
author = {Mahajan, Rohit and Gupta, Sunil Kumar and Bedi, Rajeev Kumar},
title = {Design of Software Fault Prediction Model Using BR Technique},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.154},
doi = {10.1016/j.procs.2015.02.154},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {849–858},
numpages = {10},
keywords = {public dataset ;, Neural network, Levenberg-Marquardt (LM)algorithm, Back Propagation (BPA) algorithm ;Bayesian Regularization(BR)algorithml}
}

@inproceedings{10.1145/1540438.1540448,
author = {Mende, Thilo and Koschke, Rainer},
title = {Revisiting the evaluation of defect prediction models},
year = {2009},
isbn = {9781605586342},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1540438.1540448},
doi = {10.1145/1540438.1540448},
abstract = {Defect Prediction Models aim at identifying error-prone parts of a software system as early as possible. Many such models have been proposed, their evaluation, however, is still an open question, as recent publications show.An important aspect often ignored during evaluation is the effort reduction gained by using such models. Models are usually evaluated per module by performance measures used in information retrieval, such as recall, precision, or the area under the ROC curve (AUC). These measures assume that the costs associated with additional quality assurance activities are the same for each module, which is not reasonable in practice. For example, costs for unit testing and code reviews are roughly proportional to the size of a module.In this paper, we investigate this discrepancy using optimal and trivial models. We describe a trivial model that takes only the module size measured in lines of code into account, and compare it to five classification methods. The trivial model performs surprisingly well when evaluated using AUC. However, when an effort-sensitive performance measure is used, it becomes apparent that the trivial model is in fact the worst.},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
articleno = {7},
numpages = {10},
keywords = {cost-sensitive performance measures, defect prediction},
location = {Vancouver, British Columbia, Canada},
series = {PROMISE '09}
}

@inproceedings{10.1145/3106237.3106291,
author = {Ma, Shiqing and Aafer, Yousra and Xu, Zhaogui and Lee, Wen-Chuan and Zhai, Juan and Liu, Yingqi and Zhang, Xiangyu},
title = {LAMP: data provenance for graph based machine learning algorithms through derivative computation},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106291},
doi = {10.1145/3106237.3106291},
abstract = {Data provenance tracking determines the set of inputs related to a given output. It enables quality control and problem diagnosis in data engineering. Most existing techniques work by tracking program dependencies. They cannot quantitatively assess the importance of related inputs, which is critical to machine learning algorithms, in which an output tends to depend on a huge set of inputs while only some of them are of importance. In this paper, we propose LAMP, a provenance computation system for machine learning algorithms. Inspired by automatic differentiation (AD), LAMP quantifies the importance of an input for an output by computing the partial derivative. LAMP separates the original data processing and the more expensive derivative computation to different processes to achieve cost-effectiveness. In addition, it allows quantifying importance for inputs related to discrete behavior, such as control flow selection. The evaluation on a set of real world programs and data sets illustrates that LAMP produces more precise and succinct provenance than program dependence based techniques, with much less overhead. Our case studies demonstrate the potential of LAMP in problem diagnosis in data engineering.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {786–797},
numpages = {12},
keywords = {Machine Learning, Debugging, Data Provenance},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1145/1414004.1414066,
author = {Tosun, Ayse and Turhan, Burak and Bener, Ayse},
title = {Ensemble of software defect predictors: a case study},
year = {2008},
isbn = {9781595939715},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1414004.1414066},
doi = {10.1145/1414004.1414066},
abstract = {In this paper, we present a defect prediction model based on ensemble of classifiers, which has not been fully explored so far in this type of research. We have conducted several experiments on public datasets. Our results reveal that ensemble of classifiers considerably improve the defect detection capability compared to Naive Bayes algorithm. We also conduct a cost-benefit analysis for our ensemble, where it turns out that it is enough to inspect 32% of the code on the average, for detecting 76% of the defects.},
booktitle = {Proceedings of the Second ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {318–320},
numpages = {3},
keywords = {static code attributes, ensemble of classifiers, defect prediction},
location = {Kaiserslautern, Germany},
series = {ESEM '08}
}

@article{10.5555/2938006.2938019,
author = {Arcelli Fontana, Francesca and M\"{a}ntyl\"{a}, Mika V. and Zanoni, Marco and Marino, Alessandro},
title = {Comparing and experimenting machine learning techniques for code smell detection},
year = {2016},
issue_date = {June      2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {3},
issn = {1382-3256},
abstract = {Several code smell detection tools have been developed providing different results, because smells can be subjectively interpreted, and hence detected, in different ways. In this paper, we perform the largest experiment of applying machine learning algorithms to code smells to the best of our knowledge. We experiment 16 different machine-learning algorithms on four code smells (Data Class, Large Class, Feature Envy, Long Method) and 74 software systems, with 1986 manually validated code smell samples. We found that all algorithms achieved high performances in the cross-validation data set, yet the highest performances were obtained by J48 and Random Forest, while the worst performance were achieved by support vector machines. However, the lower prevalence of code smells, i.e., imbalanced data, in the entire data set caused varying performances that need to be addressed in the future studies. We conclude that the application of machine learning to the detection of these code smells can provide high accuracy (&gt;96 %), and only a hundred training examples are needed to reach at least 95 % accuracy.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {1143–1191},
numpages = {49},
keywords = {Machine learning techniques, Code smells detection, Benchmark for code smell detection}
}

@inproceedings{10.1007/978-3-030-26250-1_33,
author = {Matsuno, Yutaka and Ishikawa, Fuyuki and Tokumoto, Susumu},
title = {Tackling Uncertainty in Safety Assurance for Machine Learning: Continuous Argument Engineering with Attributed Tests},
year = {2019},
isbn = {978-3-030-26249-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-26250-1_33},
doi = {10.1007/978-3-030-26250-1_33},
abstract = {There are unique kinds of uncertainty in implementations constructed by machine learning from training data. This uncertainty affects the strategy and activities for safety assurance. In this paper, we investigate this point in terms of continuous argument engineering with a granular performance evaluation over the expected operational domain. We employ an attribute testing method for evaluating an implemented model in terms of explicit (partial) specification. We then show experimental results that demonstrate how safety arguments are affected by the uncertainty of machine learning. As an example, we show the weakness of a model, which cannot be predicted beforehand. We show our tool for continuous argument engineering to track the latest state of assurance.},
booktitle = {Computer Safety, Reliability, and Security: SAFECOMP 2019 Workshops, ASSURE, DECSoS, SASSUR, STRIVE, and WAISE, Turku, Finland, September 10, 2019, Proceedings},
pages = {398–404},
numpages = {7},
location = {Turku, Finland}
}

@article{10.1007/s00500-016-2284-x,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {An empirical study of some software fault prediction techniques for the number of faults prediction},
year = {2017},
issue_date = {December  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {24},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-016-2284-x},
doi = {10.1007/s00500-016-2284-x},
abstract = {During the software development process, prediction of the number of faults in software modules can be more helpful instead of predicting the modules being faulty or non-faulty. Such an approach may help in more focused software testing process and may enhance the reliability of the software system. Most of the earlier works on software fault prediction have used classification techniques for classifying software modules into faulty or non-faulty categories. The techniques such as Poisson regression, negative binomial regression, genetic programming, decision tree regression, and multilayer perceptron can be used for the prediction of the number of faults. In this paper, we present an experimental study to evaluate and compare the capability of six fault prediction techniques such as genetic programming, multilayer perceptron, linear regression, decision tree regression, zero-inflated Poisson regression, and negative binomial regression for the prediction of number of faults. The experimental investigation is carried out for eighteen software project datasets collected from the PROMISE data repository. The results of the investigation are evaluated using average absolute error, average relative error, measure of completeness, and prediction at level l measures. We also perform Kruskal---Wallis test and Dunn's multiple comparison test to compare the relative performance of the considered fault prediction techniques.},
journal = {Soft Comput.},
month = dec,
pages = {7417–7434},
numpages = {18},
keywords = {Zero-inflated Poisson regression, Software fault prediction, Multilayer perceptron, Kruskal---Wallis test, Genetic programming, Dunn's multiple comparison test}
}

@inproceedings{10.1145/3371158.3371233,
author = {Mannarswamy, Sandya and Roy, Shourya and Chidambaram, Saravanan},
title = {Tutorial on Software Testing &amp; Quality Assurance for Machine Learning Applications from research bench to real world},
year = {2020},
isbn = {9781450377386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3371158.3371233},
doi = {10.1145/3371158.3371233},
abstract = {Rapid progress in Machine Learning (ML) has seen a swift translation to real world commercial deployment. While research and development of ML applications have progressed at an exponential pace, the required software engineering process for ML applications and the corresponding eco-system of testing and quality assurance tools which enable software reliable, trustworthy and safe and easy to deploy, have sadly lagged behind. Specifically, the challenges and gaps in quality assurance (QA) and testing of AI applications have largely remained unaddressed contributing to a poor translation rate of ML applications from research to real world. Unlike traditional software, which has a well-defined software testing methodology, ML applications have largely taken an ad-hoc approach to testing. ML researchers and practitioners either fall back to traditional software testing approaches, which are inadequate for this domain, due to its inherent probabilistic and data dependent nature, or rely largely on non-rigorous self-defined QA methodologies. These issues have driven the ML and Software Engineering research communities to develop of newer tools and techniques designed specifically for ML. These research advances need to be publicized and practiced in real world in ML development and deployment for enabling successful translation of ML from research prototypes to real world. This tutorial intends to address this need.This tutorial aims to:[1] Provide a comprehensive overview of testing of ML applications[2] Provide practical insights and share community best practices for testing ML softwareBesides scientific literature, we derive our insights from our conversations with industry experts in ML.},
booktitle = {Proceedings of the 7th ACM IKDD CoDS and 25th COMAD},
pages = {373–374},
numpages = {2},
keywords = {Software Testing, Quality Assurance, Machine Learning},
location = {Hyderabad, India},
series = {CoDS COMAD 2020}
}

@article{10.1016/j.datak.2008.10.005,
author = {Turhan, Burak and Bener, Ayse},
title = {Analysis of Naive Bayes' assumptions on software fault data: An empirical study},
year = {2009},
issue_date = {February, 2009},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {68},
number = {2},
issn = {0169-023X},
url = {https://doi.org/10.1016/j.datak.2008.10.005},
doi = {10.1016/j.datak.2008.10.005},
abstract = {Software defect prediction is important for reducing test times by allocating testing resources effectively. In terms of predicting the defects in software, Naive Bayes outperforms a wide range of other methods. However, Naive Bayes assumes the 'independence' and 'equal importance' of attributes. In this work, we analyze these assumptions of Naive Bayes using public software defect data from NASA. Our analysis shows that independence assumption is not harmful for software defect data with PCA pre-processing. Our results also indicate that assigning weights to static code attributes may increase the prediction performance significantly, while removing the need for feature subset selection.},
journal = {Data Knowl. Eng.},
month = feb,
pages = {278–290},
numpages = {13},
keywords = {Software defect prediction, Naive Bayes, Empirical study}
}

@inproceedings{10.1145/2070821.2070823,
author = {Roychowdhury, Shounak and Khurshid, Sarfraz},
title = {Software fault localization using feature selection},
year = {2011},
isbn = {9781450310222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2070821.2070823},
doi = {10.1145/2070821.2070823},
abstract = {Manually locating and fixing faults can be tedious and hard. Recent years have seen much progress in automated techniques for fault localization. A particularly promising approach is to analyze passing and failing runs to compute how likely each statement is to be faulty. Techniques based on this approach have so far largely focused on either using statistical analysis or similarity based algorithms, which have a natural application in evaluating such runs. We present a novel approach to fault localization using feature selection techniques from machine learning. Our insight is that each additional failing or passing run can provide significantly diverse amount of information, which can help localize faults in code -- the statements with maximum feature diversity information can point to most suspicious lines of code. Experimental results show that our approach outperforms state-of-the-art approaches for localizing faults in most subject programs of the Siemens suite, which have previously been used to evaluate several fault localization techniques.},
booktitle = {Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering},
pages = {11–18},
numpages = {8},
keywords = {statistical debugging, machine learning, feature selection, fault localization, automated debugging, RELIEF},
location = {Lawrence, Kansas, USA},
series = {MALETS '11}
}

@article{10.1007/s11334-015-0258-2,
author = {Abdi, Yousef and Parsa, Saeed and Seyfari, Yousef},
title = {A hybrid one-class rule learning approach based on swarm intelligence for software fault prediction},
year = {2015},
issue_date = {December  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {11},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-015-0258-2},
doi = {10.1007/s11334-015-0258-2},
abstract = {Software testing is a fundamental activity in the software development process aimed to determine the quality of software. To reduce the effort and cost of this process, defect prediction methods can be used to determine fault-prone software modules through software metrics to focus testing activities on them. Because of model interpretation and easily used by programmers and testers some recent studies presented classification rules to make prediction models. This study presents a rule-based prediction approach based on kernel k-means clustering algorithm and Distance based Multi-objective Particle Swarm Optimization (DSMOPSO). Because of discrete search space, we modified this algorithm and named it DSMOPSO-D. We prevent best global rules to dominate local rules by dividing the search space with kernel k-means algorithm and by taking different approaches for imbalanced and balanced clusters, we solved imbalanced data set problem. The presented model performance was evaluated by four publicly available data sets from the PROMISE repository and compared with other machine learning and rule learning algorithms. The obtained results demonstrate that our model presents very good performance, especially in large data sets.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {289–301},
numpages = {13},
keywords = {Multi-objective particle swarm optimization, Kernel k-means, Imbalanced data sets, Fault prediction, DSMOPSO-D, Classification rules}
}

@inproceedings{10.1109/QSIC.2010.40,
author = {He, Zhimin and Shu, Fengdi and Yang, Ye and Zhang, Wen and Wang, Qing},
title = {Data Unpredictability in Software Defect-Fixing Effort Prediction},
year = {2010},
isbn = {9780769541310},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QSIC.2010.40},
doi = {10.1109/QSIC.2010.40},
abstract = {The prediction of software defect-fixing effort is important for strategic resource allocation and software quality management. Machine learning techniques have become very popular in addressing this problem and many related prediction models have been proposed. However, almost every model today faces a challenging issue of demonstrating satisfactory prediction accuracy and meaningful prediction results. In this paper, we investigate what makes high-precision prediction of defect-fixing effort so hard from the perspective of the characteristics of defect dataset. We develop a method using a metric to quantitatively analyze the unpredictability of a defect dataset and carry out case studies on two defect datasets. The results show that data unpredictability is a key factor for unsatisfactory prediction accuracy and our approach can explain why high-precision prediction for some defect datasets is hard to achieve inherently. We also provide some suggestions on how to collect highly predictable defect data.},
booktitle = {Proceedings of the 2010 10th International Conference on Quality Software},
pages = {220–226},
numpages = {7},
keywords = {software defect-fixing effort prediction, machine learning, data unpredictability, MAE},
series = {QSIC '10}
}

@article{10.1016/j.procs.2015.02.041,
author = {Dhanalaxmi, B. and Naidu, G. Apparao and Anuradha, K.},
title = {Adaptive PSO Based Association Rule Mining Technique for Software Defect Classification Using ANN},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.041},
doi = {10.1016/j.procs.2015.02.041},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {432–442},
numpages = {11},
keywords = {Defect prevention., Software testing, Artificial neural network, Adaptive particle swarm optimization algorithm, Association rule mining}
}

@article{10.1016/j.knosys.2021.107541,
author = {Pandey, Sushant Kumar and Tripathi, Anil Kumar},
title = {DNNAttention: A deep neural network and attention based architecture for cross project defect number prediction},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {233},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107541},
doi = {10.1016/j.knosys.2021.107541},
journal = {Know.-Based Syst.},
month = dec,
numpages = {30},
keywords = {Software defect number prediction, Long short term memory (LSTM), Attention layer, Deep neural network, Cross project defect prediction}
}

@article{10.1007/s11241-019-09339-7,
author = {Bhat, Anand and Samii, Soheil and Rajkumar, Ragunathan},
title = {Practical task allocation for software fault-tolerance and its implementation in embedded automotive systems},
year = {2019},
issue_date = {Oct 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {55},
number = {4},
issn = {0922-6443},
url = {https://doi.org/10.1007/s11241-019-09339-7},
doi = {10.1007/s11241-019-09339-7},
abstract = {Due to the advent of active safety features and automated driving capabilities, the complexity of embedded computing systems within automobiles continues to increase. Such advanced driver assistance systems (ADAS) are inherently safety-critical and must tolerate failures in any subsystem. However, fault-tolerance in safety-critical systems has been traditionally supported by hardware replication, which is prohibitively expensive in terms of cost, weight, and size for the automotive market. Recent work has studied the use of software-based fault-tolerance techniques that utilize task-level hot and cold standbys to tolerate fail-stop processor and task failures. The benefit of using standbys is maximal when a task and any of its standbys obey the placement constraint of not being co-located on the same processor. We propose a new heuristic based on a “tiered” placement constraint, and show that our heuristic produces a better task assignment that saves at least one processor up to 40% of the time relative to the best known heuristic to date. We then introduce a task allocation algorithm that, for the first time to our knowledge, leverages the run-time attributes of cold standbys. Our empirical study finds that our heuristic uses no more than one additional processor in most cases relative to an optimal allocation that we construct for evaluation purposes using a creative technique. We also extend our heuristic to support mixed-criticality systems which allow for overload operation. We have designed and implemented our software fault-tolerance framework in AUTOSAR, an automotive industry standard. We use this implementation to provide an experimental evaluation of our task-level fault-tolerance features. Finally, we present an analysis of the worst-case behavior of our task recovery features.},
journal = {Real-Time Syst.},
month = oct,
pages = {889–924},
numpages = {36},
keywords = {Task allocation, Fault tolerance, Automotive systems, Real-time systems}
}

@article{10.1007/s00521-016-2437-y,
author = {Chatterjee, S. and Nigam, S. and Roy, A.},
title = {Software fault prediction using neuro-fuzzy network and evolutionary learning approach},
year = {2017},
issue_date = {January   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {28},
number = {1},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-016-2437-y},
doi = {10.1007/s00521-016-2437-y},
abstract = {In the real world, a great deal of information is provided by human experts that normally do not conform to the rules of physics, but describe the complicated systems by a set of incomplete or vague statements. The need of conducting uncertainty analysis in software reliability for the large and complex system is demanding. For large complex systems made up of many components, the uncertainty of each individual parameter amplifies the uncertainty of the total system reliability. In this paper, to overcome with the problem of uncertainty in software development process and environment, a neuro-fuzzy modeling has been proposed for software fault prediction. The training of the proposed neuro-fuzzy model has been done with genetic algorithm and back-propagation learning algorithm. The proposed model has been validated using some real software failure data. The efficiency of the two learning algorithms has been compared with various fuzzy and statistical time series-based forecasting algorithms on the basis of their prediction ability.},
journal = {Neural Comput. Appl.},
month = jan,
pages = {1221–1231},
numpages = {11},
keywords = {Software reliability, Genetic algorithm, Fuzzy neural network, Faults}
}

@inproceedings{10.1145/3236024.3236055,
author = {Hu, Gang and Zhu, Linjie and Yang, Junfeng},
title = {AppFlow: using machine learning to synthesize robust, reusable UI tests},
year = {2018},
isbn = {9781450355735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236024.3236055},
doi = {10.1145/3236024.3236055},
abstract = {UI testing is known to be difficult, especially as today’s development cycles become faster. Manual UI testing is tedious, costly and error- prone. Automated UI tests are costly to write and maintain. This paper presents AppFlow, a system for synthesizing highly robust, highly reusable UI tests. It leverages machine learning to automatically recognize common screens and widgets, relieving developers from writing ad hoc, fragile logic to use them in tests. It enables developers to write a library of modular tests for the main functionality of an app category (e.g., an “add to cart” test for shopping apps). It can then quickly test a new app in the same category by synthesizing full tests from the modular ones in the library. By focusing on the main functionality, AppFlow provides “smoke testing” requiring little manual work. Optionally, developers can customize AppFlow by adding app-specific tests for completeness. We evaluated AppFlow on 60 popular apps in the shopping and the news category, two case studies on the BBC news app and the JackThreads shopping app, and a user-study of 15 subjects on the Wish shopping app. Results show that AppFlow accurately recognizes screens and widgets, synthesizes highly robust and reusable tests, covers 46.6% of all automatable tests for Jackthreads with the tests it synthesizes, and reduces the effort to test a new app by up to 90%. Interestingly, it found eight bugs in the evaluated apps, including seven functionality bugs, despite that they were publicly released and supposedly went through thorough testing.},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {269–282},
numpages = {14},
keywords = {test synthesis, test reuse, mobile testing, machine learning, UI testing, UI recognition},
location = {Lake Buena Vista, FL, USA},
series = {ESEC/FSE 2018}
}

@article{10.1109/TSE.2012.20,
author = {Dejaeger, Karel and Verbraken, Thomas and Baesens, Bart},
title = {Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers},
year = {2013},
issue_date = {February 2013},
publisher = {IEEE Press},
volume = {39},
number = {2},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2012.20},
doi = {10.1109/TSE.2012.20},
abstract = {Software testing is a crucial activity during software development and fault prediction models assist practitioners herein by providing an upfront identification of faulty software code by drawing upon the machine learning literature. While especially the Naive Bayes classifier is often applied in this regard, citing predictive performance and comprehensibility as its major strengths, a number of alternative Bayesian algorithms that boost the possibility of constructing simpler networks with fewer nodes and arcs remain unexplored. This study contributes to the literature by considering 15 different Bayesian Network (BN) classifiers and comparing them to other popular machine learning techniques. Furthermore, the applicability of the Markov blanket principle for feature selection, which is a natural extension to BN theory, is investigated. The results, both in terms of the AUC and the recently introduced H-measure, are rigorously tested using the statistical framework of Dem\v{s}ar. It is concluded that simple and comprehensible networks with less nodes can be constructed using BN classifiers other than the Naive Bayes classifier. Furthermore, it is found that the aspects of comprehensibility and predictive performance need to be balanced out, and also the development context is an item which should be taken into account during model selection.},
journal = {IEEE Trans. Softw. Eng.},
month = feb,
pages = {237–257},
numpages = {21},
keywords = {comprehensibility, classification, Software fault prediction, Software, Probability distribution, Predictive models, Measurement, Machine learning, Capability maturity model, Bayesian networks, Bayesian methods}
}

@article{10.1007/s10836-018-5716-y,
author = {Mandouh, Eman and Wassal, Amr G.},
title = {Application of Machine Learning Techniques in Post-Silicon Debugging and Bug Localization},
year = {2018},
issue_date = {April     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {34},
number = {2},
issn = {0923-8174},
url = {https://doi.org/10.1007/s10836-018-5716-y},
doi = {10.1007/s10836-018-5716-y},
abstract = {As the size of hardware (HW) design increases significantly, a huge amount of data is generated during the design simulation, emulation or prototyping. Debugging large HW designs becomes a tedious, time consuming and a bottleneck task within the function verification activities. This paper proposes the utilization of machine learning techniques to automate the diagnosis of design trace dump as well as helping in bug localization during post-silicon validation. Our framework starts by signal selection algorithm that identifies which signals to monitor during design execution. Signal selection depends on signal types as well as their connectivity network. The design is then executed and the trace dump is saved for offline analysis. Big-Data processing technique, namely, Map-Reduce is used to overcome the challenge of processing huge trace dump resulted from design running on FPGA prototype. K-means Clustering method is applied to group trace segments that are very similar and to identify the ones with a rare occurrence during the design execution. Additionally, we propose a bug localization framework in which X-means clustering is used to group the passing regression tests in clusters such that buggy tests can be detected when they fail to be assigned to any of the trained clusters. Our experimental results demonstrate the feasibility of the proposed approach in guiding the debugging effort using a group of industrial HW designs and its ability to detect multiple design injected defects using mutation-based-testing method.},
journal = {J. Electron. Test.},
month = apr,
pages = {163–181},
numpages = {19},
keywords = {Post-silicon validation, HW debugging and machine learning, Big-data}
}

@inproceedings{10.1145/3213846.3213858,
author = {Dwarakanath, Anurag and Ahuja, Manish and Sikand, Samarth and Rao, Raghotham M. and Bose, R. P. Jagadeesh Chandra and Dubash, Neville and Podder, Sanjay},
title = {Identifying implementation bugs in machine learning based image classifiers using metamorphic testing},
year = {2018},
isbn = {9781450356992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213846.3213858},
doi = {10.1145/3213846.3213858},
abstract = {We have recently witnessed tremendous success of Machine Learning (ML) in practical applications. Computer vision, speech recognition and language translation have all seen a near human level performance. We expect, in the near future, most business applications will have some form of ML. However, testing such applications is extremely challenging and would be very expensive if we follow today's methodologies. In this work, we present an articulation of the challenges in testing ML based applications. We then present our solution approach, based on the concept of Metamorphic Testing, which aims to identify implementation bugs in ML based image classifiers. We have developed metamorphic relations for an application based on Support Vector Machine and a Deep Learning based application. Empirical validation showed that our approach was able to catch 71% of the implementation bugs in the ML applications.},
booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {118–128},
numpages = {11},
keywords = {Testing Machine Learning based applications, Metamorphic Testing},
location = {Amsterdam, Netherlands},
series = {ISSTA 2018}
}

@article{10.1109/TSE.2016.2553030,
author = {Tantithamthavorn, Chakkrit and McIntosh, Shane and Hassan, Ahmed E. and Matsumoto, Kenichi},
title = {Comments on \'{z}Researcher Bias: The Use of Machine Learning in Software Defect Prediction\'{z}},
year = {2016},
issue_date = {November 2016},
publisher = {IEEE Press},
volume = {42},
number = {11},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2016.2553030},
doi = {10.1109/TSE.2016.2553030},
abstract = {Shepperd&nbsp;et&nbsp;al.&nbsp;find that the reported performance of a defect prediction model shares a strong relationship with the group of researchers who construct the models. In this paper, we perform an alternative investigation of Shepperd&nbsp;et&nbsp;al.'s data. We observe that (a) research group shares a strong association with other explanatory variables (i.e., the dataset and metric families that are used to build a model); (b) the strong association among these explanatory variables makes it difficult to discern the impact of the research group on model performance; and (c) after mitigating the impact of this strong association, we find that the research group has a smaller impact than the metric family. These observations lead us to conclude that the relationship between the research group and the performance of a defect prediction model are more likely due to the tendency of researchers to reuse experimental components (e.g., datasets and metrics). We recommend that researchers experiment with a broader selection of datasets and metrics to combat any potential bias in their results.},
journal = {IEEE Trans. Softw. Eng.},
month = nov,
pages = {1092–1094},
numpages = {3}
}

@inproceedings{10.1145/1987875.1987888,
author = {Bi\c{c}er, Serdar and Bener, Ay\c{s}e Ba\c{s}ar and \c{C}a\u{g}layan, Bora},
title = {Defect prediction using social network analysis on issue repositories},
year = {2011},
isbn = {9781450307307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1987875.1987888},
doi = {10.1145/1987875.1987888},
abstract = {People are the most important pillar of software development process. It is critical to understand how they interact with each other and how these interactions affect the quality of the end product in terms of defects. In this research we propose to include a new set of metrics, a.k.a. social network metrics on issue repositories in predicting defects. Social network metrics on issue repositories has not been used before to predict defect proneness of a software product. To validate our hypotheses we used two datasets, development data of IBM1 Rational ® Team Concert™ (RTC) and Drupal, to conduct our experiments. The results of the experiments revealed that compared to other set of metrics such as churn metrics using social network metrics on issue repositories either considerably decreases high false alarm rates without compromising the detection rates or considerably increases low prediction rates without compromising low false alarm rates. Therefore we recommend practitioners to collect social network metrics on issue repositories since people related information is a strong indicator of past patterns in a given team.},
booktitle = {Proceedings of the 2011 International Conference on Software and Systems Process},
pages = {63–71},
numpages = {9},
keywords = {social networks, network metrics, developer communication, defect prediction},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSSP '11}
}

@article{10.1007/s10664-009-9115-y,
author = {Gokhale, Swapna S. and Mullen, Robert E.},
title = {A multiplicative model of software defect repair times},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-009-9115-y},
doi = {10.1007/s10664-009-9115-y},
abstract = {We hypothesize that software defect repair times can be characterized by the Laplace Transform of the Lognormal (LTLN) distribution. This hypothesis is rooted in the observation that software defect repair times are influenced by the multiplicative interplay of several factors, and the lognormal distribution is a natural choice to model rates of occurrence of such phenomenon. Conversion of the lognormal rate distribution to an occurrence time distribution yields the LTLN. We analyzed a total of more than 10,000 software defect repair times collected over nine products at Cisco Systems to confirm our LTLN hypothesis. Our results also demonstrate that the LTLN distribution provides a statistically better fit to the observed repair times than either of the two most widely used repair time distributions, namely, the lognormal and the exponential. Moreover, we show that the repair times of subsets of defects, partitioned according to the Orthogonal Defect Classification (ODC) scheme also follow the LTLN distribution. Finally, we describe how the insights that lead to the LTLN repair time model allow us to consider and evaluate alternative process improvement strategies.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {296–319},
numpages = {24},
keywords = {Software defect repair, Multiplicative effect, Lognormal}
}

@article{10.1007/s10664-008-9103-7,
author = {Turhan, Burak and Menzies, Tim and Bener, Ay\c{s}e B. and Di Stefano, Justin},
title = {On the relative value of cross-company and within-company data for defect prediction},
year = {2009},
issue_date = {October   2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {14},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-008-9103-7},
doi = {10.1007/s10664-008-9103-7},
abstract = {We propose a practical defect prediction approach for companies that do not track defect related data. Specifically, we investigate the applicability of cross-company (CC) data for building localized defect predictors using static code features. Firstly, we analyze the conditions, where CC data can be used as is. These conditions turn out to be quite few. Then we apply principles of analogy-based learning (i.e. nearest neighbor (NN) filtering) to CC data, in order to fine tune these models for localization. We compare the performance of these models with that of defect predictors learned from within-company (WC) data. As expected, we observe that defect predictors learned from WC data outperform the ones learned from CC data. However, our analyses also yield defect predictors learned from NN-filtered CC data, with performance close to, but still not better than, WC data. Therefore, we perform a final analysis for determining the minimum number of local defect reports in order to learn WC defect predictors. We demonstrate in this paper that the minimum number of data samples required to build effective defect predictors can be quite small and can be collected quickly within a few months. Hence, for companies with no local defect data, we recommend a two-phase approach that allows them to employ the defect prediction process instantaneously. In phase one, companies should use NN-filtered CC data to initiate the defect prediction process and simultaneously start collecting WC (local) data. Once enough WC data is collected (i.e. after a few months), organizations should switch to phase two and use predictors learned from WC data.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {540–578},
numpages = {39},
keywords = {Within-company, Nearest-neighbor filtering, Metrics (product metrics), Learning, Defect prediction, Cross-company}
}

@inproceedings{10.1145/2938503.2938553,
author = {Soltanifar, Behjat and Akbarinasaji, Shirin and Caglayan, Bora and Bener, Ayse Basar and Filiz, Asli and Kramer, Bryan M.},
title = {Software Analytics in Practice: A Defect Prediction Model Using Code Smells},
year = {2016},
isbn = {9781450341189},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2938503.2938553},
doi = {10.1145/2938503.2938553},
abstract = {In software engineering, maintainability is related to investigating the defects and their causes, correcting the defects and modifying the system to meet customer requirements. Maintenance is a time consuming activity within the software life cycle. Therefore, there is a need for efficiently organizing the software resources in terms of time, cost and personnel for maintenance activity. One way of efficiently managing maintenance resources is to predict defects that may occur after the deployment. Many researchers so far have built defect prediction models using different sets of metrics such as churn and static code metrics. However, hidden causes of defects such as code smells have not been investigated thoroughly. In this study we propose using data science and analytics techniques on software data to build defect prediction models. In order to build the prediction model we used code smells metrics, churn metrics and combination of churn and code smells metrics. The results of our experiments on two different software companies show that code smells is a good indicator of defect proneness of the software product. Therefore, we recommend that code smells metrics should be used to train a defect prediction model to guide the software maintenance team.},
booktitle = {Proceedings of the 20th International Database Engineering &amp; Applications Symposium},
pages = {148–155},
numpages = {8},
keywords = {Mining software repositories, Defect Prediction Model, Code Smells},
location = {Montreal, QC, Canada},
series = {IDEAS '16}
}

@inproceedings{10.1145/2393596.2393619,
author = {Caglayan, Bora and Misirli, Ayse Tosun and Calikli, Gul and Bener, Ayse and Aytac, Turgay and Turhan, Burak},
title = {Dione: an integrated measurement and defect prediction solution},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393596.2393619},
doi = {10.1145/2393596.2393619},
abstract = {We present an integrated measurement and defect prediction tool: Dione. Our tool enables organizations to measure, monitor, and control product quality through learning based defect prediction. Similar existing tools either provide data collection and analytics, or work just as a prediction engine. Therefore, companies need to deal with multiple tools with incompatible interfaces in order to deploy a complete measurement and prediction solution. Dione provides a fully integrated solution where data extraction, defect prediction and reporting steps fit seamlessly. In this paper, we present the major functionality and architectural elements of Dione followed by an overview of our demonstration.},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {20},
numpages = {2},
keywords = {software tool, software defect prediction, measurement},
location = {Cary, North Carolina},
series = {FSE '12}
}

@inproceedings{10.1145/3330204.3330275,
author = {Luiz, Frederico Caram and de Oliveira Rodrigues, Bruno Rafael and Parreiras, Fernando Silva},
title = {Machine learning techniques for code smells detection: an empirical experiment on a highly imbalanced setup},
year = {2019},
isbn = {9781450372374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3330204.3330275},
doi = {10.1145/3330204.3330275},
booktitle = {Proceedings of the XV Brazilian Symposium on Information Systems},
articleno = {65},
numpages = {8},
location = {Aracaju, Brazil},
series = {SBSI '19}
}

@inproceedings{10.1145/1540438.1540453,
author = {Tosun, Ay\c{s}e and Turhan, Burak and Bener, Ay\c{s}e},
title = {Practical considerations in deploying AI for defect prediction: a case study within the Turkish telecommunication industry},
year = {2009},
isbn = {9781605586342},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1540438.1540453},
doi = {10.1145/1540438.1540453},
abstract = {We have conducted a study in a large telecommunication company in Turkey to employ a software measurement program and to predict pre-release defects. We have previously built such predictors using AI techniques. This project is a transfer of our research experience into a real life setting to solve a specific problem for the company: to improve code quality by predicting pre-release defects and efficiently allocating testing resources. Our results in this project have many practical implications that managers have started benefiting: code analysis, bug tracking, effective use of version management system and defect prediction. Using version history information, developers can find around 88% of the defects with 28% false alarms, compared to same detection rate with 50% false alarms without using historical data. In this paper we also shared in detail our experience in terms of the project steps (i.e. challenges and opportunities).},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
articleno = {11},
numpages = {9},
keywords = {AI methods, experience report, prediction, software defect prediction, static code attributes},
location = {Vancouver, British Columbia, Canada},
series = {PROMISE '09}
}

@article{10.5555/2596370.2596386,
author = {Jin, Cong and Jin, Shu-Wei},
title = {Applications of fuzzy integrals for predicting software fault-prone},
year = {2014},
issue_date = {March 2014},
publisher = {IOS Press},
address = {NLD},
volume = {26},
number = {2},
issn = {1064-1246},
abstract = {Software fault-prone prediction is one of the active areas of software engineering. It plays a very important role in the analysis of software quality and balance of software cost. Practically, the identification of a module's fault-prone is very important for minimizing cost and improving the effectiveness of the software development process. Software fault-prone prediction helps us to develop dependable software. How to obtain the correlation between software metrics and module's fault-prone, hiding in the observed metrics data, has been focused by many researches. In this paper, we propose the use of a fuzzy integral FI for this purpose. FI offers significant advantages over other approaches due to its ability to naturally represent qualitative characteristic of software fault-prone. Proposed approach was applied on Chidamber-Kemerer CK metrics and two datasets of NASA Metrics Data Program from PROMISE repository. Experiments results confirm that proposed approach is very effective for establishing relationship between software metrics and fault-prone. Its implementation doesn't require expert's knowledge. Proposed approach can give useful results for software project managers.},
journal = {J. Intell. Fuzzy Syst.},
month = mar,
pages = {721–729},
numpages = {9},
keywords = {Software Metrics, Software Fault-Prone, Prediction, Fuzzy Integral}
}

@article{10.3233/JIFS-169703,
author = {Vig, Vidhi and Kaur, Arvinder and Tiwari, Shailesh and Trivedi, Munesh and Kohle, Mohan L.},
title = {Test effort estimation and prediction of traditional and rapid release models using machine learning algorithms},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {35},
number = {2},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-169703},
doi = {10.3233/JIFS-169703},
abstract = {Recently, many software companies have shifted to shorter release cycles from the traditional multi-month release cycle. Evolution and transition of release cycles may affect the test effort in the system. This paper analyses 25 traditional releases containing 1210 classes and 69 rapid releases containing 2616 classes of four Open Source Java systems. Correlations between 48 Object Oriented metrics and 2 test metrics were evaluated to identify the best indicators of test effort. The results show that (i) correlation between OO and test metrics remain irrespective of release models, (ii) test effort required in Rapid Release (RR) models (shorter release cycles) is slightly more as compared to Traditional Release (TR) models, (iii) Out of 18 machine learning algorithms instance based machine learning algorithms IBK and K star followed by Multi-Layer Perceptron (MLP) and additive regression are able to predict the test effort accurately in classes.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {1657–1669},
numpages = {13},
keywords = {test effort, software metrics, prediction, machine learning, Release cycles}
}

@inproceedings{10.1145/3134600.3134620,
author = {Yan, Hua and Sui, Yulei and Chen, Shiping and Xue, Jingling},
title = {Machine-Learning-Guided Typestate Analysis for Static Use-After-Free Detection},
year = {2017},
isbn = {9781450353458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3134600.3134620},
doi = {10.1145/3134600.3134620},
abstract = {Typestate analysis relies on pointer analysis for detecting temporal memory safety errors, such as use-after-free (UAF). For large programs, scalable pointer analysis is usually imprecise in analyzing their hard "corner cases", such as infeasible paths, recursion cycles, loops, arrays, and linked lists. Due to a sound over-approximation of the points-to information, a large number of spurious aliases will be reported conservatively, causing the corresponding typestate analysis to report a large number of false alarms. Thus, the usefulness of typestate analysis for heap-intensive clients, like UAF detection, becomes rather limited, in practice.We introduce Tac, a static UAF detector that bridges the gap between typestate and pointer analyses by machine learning. Tac learns the correlations between program features and UAF-related aliases by using a Support Vector Machine (SVM) and applies this knowledge to further disambiguate the UAF-related aliases reported imprecisely by the pointer analysis so that only the ones validated by its SVM classifier are further investigated by the typestate analysis. Despite its unsoundness, Tac represents a practical typestate analysis approach for UAF detection. We have implemented Tac in LLVM-3.8.0 and evaluated it using a set of eight open-source C/C++ programs. The results show that Tac is effective (in terms of finding 5 known CVE vulnerabilities, 1 known bug, and 8 new bugs with a low false alarm rate) and scalable (in terms of analyzing a large codebase with 2,098 KLOC in just over 4 hours).},
booktitle = {Proceedings of the 33rd Annual Computer Security Applications Conference},
pages = {42–54},
numpages = {13},
keywords = {vulnerability detection, use-after-free, static analysis, machine learning},
location = {Orlando, FL, USA},
series = {ACSAC '17}
}

@inproceedings{10.1145/2832987.2833042,
author = {RadhaKrishna, Vangipuram},
title = {Design and Analysis of Novel Kernel Measure for Software Fault Localization},
year = {2015},
isbn = {9781450334181},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2832987.2833042},
doi = {10.1145/2832987.2833042},
abstract = {The problem of software fault localization may be viewed as an approach for finding hidden faults or bugs in the existing program codes which are syntactically correct and give fault free output for some input instances but fail for all other input instances. Some of the reasons include logical errors, wrong interpretation of specification, coding errors. Finding such faults is not possible sometimes with the help of compilers. This is where the necessity and significance of software fault localization stems out. The main contribution for this work is to first introduce the block hit-miss function which relates block vectors of execution sequences of software code over sample runs performed and the decision vector which denotes fault or error free output. The similarity measure is applied to the block vector and decision vectors as input and the pair with maximum similarity is considered as faulty block.},
booktitle = {Proceedings of the The International Conference on Engineering &amp; MIS 2015},
articleno = {34},
numpages = {5},
keywords = {Testing, Kernel measure, Fault Vector, Fault},
location = {Istanbul, Turkey},
series = {ICEMIS '15}
}

@article{10.1504/IJIIDS.2015.070825,
author = {Abaei, Golnoush and Mashinchi, M. Reza and Selamat, Ali},
title = {Software fault prediction using BP-based crisp artificial neural networks},
year = {2015},
issue_date = {July 2015},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {1},
issn = {1751-5858},
url = {https://doi.org/10.1504/IJIIDS.2015.070825},
doi = {10.1504/IJIIDS.2015.070825},
abstract = {Early fault detection for software reduces the cost of developments. Fault level can be predicted through learning mechanisms. Conventionally, precise metrics measure the fault level and crisp artificial neural networks CANNs perform the learning. However, the performance of CANNs depends on complexities of data and learning algorithm. This paper considers these two complexities to predict the fault level of software. We apply the principle component analysis PCA to reduce the dimensionality of data, and employ the correlation-based feature selection CFS to select the best features. CANNs, then, predict the fault level of software using back propagation BP algorithm as a learning mechanism. To investigate the performance of BP-based CANNs, we analyse varieties of dimensionality reduction. The results reveal the superiority of PCA to CFS in terms of accuracy.},
journal = {Int. J. Intell. Inf. Database Syst.},
month = jul,
pages = {15–31},
numpages = {17}
}

@inproceedings{10.1109/MSR.2019.00016,
author = {Hoang, Thong and Dam, Hoa Khanh and Kamei, Yasutaka and Lo, David and Ubayashi, Naoyasu},
title = {DeepJIT: an end-to-end deep learning framework for just-in-time defect prediction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00016},
doi = {10.1109/MSR.2019.00016},
abstract = {Software quality assurance efforts often focus on identifying defective code. To find likely defective code early, change-level defect prediction - aka. Just-In-Time (JIT) defect prediction - has been proposed. JIT defect prediction models identify likely defective changes and they are trained using machine learning techniques with the assumption that historical changes are similar to future ones. Most existing JIT defect prediction approaches make use of manually engineered features. Unlike those approaches, in this paper, we propose an end-to-end deep learning framework, named DeepJIT, that automatically extracts features from commit messages and code changes and use them to identify defects. Experiments on two popular software projects (i.e., QT and OPENSTACK) on three evaluation settings (i.e., cross-validation, short-period, and long-period) show that the best variant of DeepJIT (DeepJIT-Combined), compared with the best performing state-of-the-art approach, achieves improvements of 10.36--11.02% for the project QT and 9.51--13.69% for the project OPENSTACK in terms of the Area Under the Curve (AUC).},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {34–45},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/2020390.2020405,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {An iterative semi-supervised approach to software fault prediction},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020405},
doi = {10.1145/2020390.2020405},
abstract = {Background: Many statistical and machine learning techniques have been implemented to build predictive fault models. Traditional methods are based on supervised learning. Software metrics for a module and corresponding fault information, available from previous projects, are used to train a fault prediction model. This approach calls for a large size of training data set and enables the development of effective fault prediction models. In practice, data collection costs, the lack of data from earlier projects or product versions may make large fault prediction training data set unattainable. Small size of the training set that may be available from the current project is known to deteriorate the performance of the fault predictive model. In semi-supervised learning approaches, software modules with known or unknown fault content can be used for training.Aims: To implement and evaluate a semi-supervised learning approach in software fault prediction.Methods: We investigate an iterative semi-supervised approach to software quality prediction in which a base supervised learner is used within a semi-supervised application.Results: We varied the size of labeled software modules from 2% to 50% of all the modules in the project. After tracking the performance of each iteration in the semi-supervised algorithm, we observe that semi-supervised learning improves fault prediction if the number of initially labeled software modules exceeds 5%.Conclusion: The semi-supervised approach outperforms the corresponding supervised learning approach when both use random forest as base classification algorithm.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {15},
numpages = {10},
keywords = {fault prediction, semi-supervised learning},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@article{10.1002/spe.1043,
author = {Gao, Kehan and Khoshgoftaar, Taghi M. and Wang, Huanjing and Seliya, Naeem},
title = {Choosing software metrics for defect prediction: an investigation on feature selection techniques},
year = {2011},
issue_date = {April 2011},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {41},
number = {5},
issn = {0038-0644},
url = {https://doi.org/10.1002/spe.1043},
doi = {10.1002/spe.1043},
abstract = {The selection of software metrics for building software quality prediction models is a search-based software engineering problem. An exhaustive search for such metrics is usually not feasible due to limited project resources, especially if the number of available metrics is large. Defect prediction models are necessary in aiding project managers for better utilizing valuable project resources for software quality improvement. The efficacy and usefulness of a fault-proneness prediction model is only as good as the quality of the software measurement data. This study focuses on the problem of attribute selection in the context of software quality estimation. A comparative investigation is presented for evaluating our proposed hybrid attribute selection approach, in which feature ranking is first used to reduce the search space, followed by a feature subset selection. A total of seven different feature ranking techniques are evaluated, while four different feature subset selection approaches are considered. The models are trained using five commonly used classification algorithms. The case study is based on software metrics and defect data collected from multiple releases of a large real-world software system. The results demonstrate that while some feature ranking techniques performed similarly, the automatic hybrid search algorithm performed the best among the feature subset selection methods. Moreover, performances of the defect prediction models either improved or remained unchanged when over 85were eliminated. Copyright © 2011 John Wiley &amp; Sons, Ltd.},
journal = {Softw. Pract. Exper.},
month = apr,
pages = {579–606},
numpages = {28},
keywords = {software quality, software metric, search-based software engineering, feature subset selection, feature ranking, defect prediction, attribute selection}
}

@article{10.4018/ijsi.2014100105,
author = {Abaei, Golnoush and Selamat, Ali},
title = {Increasing the Accuracy of Software Fault Prediction using Majority Ranking Fuzzy Clustering},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {2},
number = {4},
issn = {2166-7160},
url = {https://doi.org/10.4018/ijsi.2014100105},
doi = {10.4018/ijsi.2014100105},
abstract = {Despite proposing many software fault prediction models, this area has yet to be explored as still there is a room for stable and consistent model with better performance. In this paper, a new method is proposed to increase the accuracy of fault prediction based on the notion of fuzzy clustering and majority ranking. The authors investigated the effect of irrelevant and inconsistent modules on software fault prediction and tried to decrease it by designing a new framework, in which the entire project modules are clustered. The obtained results showed that fuzzy clustering could decrease the negative effect of irrelevant modules on prediction performance. Eight data sets from NASA and Turkish white-goods software is employed to evaluate our model. Performance evaluation in terms of false positive rate, false negative rate, and overall error showed the superiority of our model compared to other predicting models. The authors proposed majority ranking fuzzy clustering approach showed between 3% to 18% and 1% to 4% improvement in false negative rate and overall error, respectively, compared with other available proposed models (ACF and ACN) in more than half of the testing cases. According to the results, our systems can be used to guide testing effort by identifying fault prone modules to improve the quality of software development and software testing in a limited time and budget.},
journal = {Int. J. Softw. Innov.},
month = oct,
pages = {60–71},
numpages = {12},
keywords = {Software Fault Prediction, NASA, Majority Ranking, Fuzzy Clustering, Available Proposed Models}
}

@proceedings{10.1145/3340482,
title = {MaLTeSQuE 2019: Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@article{10.1016/j.eswa.2007.02.012,
author = {Bibi, S. and Tsoumakas, G. and Stamelos, I. and Vlahavas, I.},
title = {Regression via Classification applied on software defect estimation},
year = {2008},
issue_date = {April, 2008},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {34},
number = {3},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2007.02.012},
doi = {10.1016/j.eswa.2007.02.012},
abstract = {In this paper we apply Regression via Classification (RvC) to the problem of estimating the number of software defects. This approach apart from a certain number of faults, it also outputs an associated interval of values, within which this estimate lies with a certain confidence. RvC also allows the production of comprehensible models of software defects exploiting symbolic learning algorithms. To evaluate this approach we perform an extensive comparative experimental study of the effectiveness of several machine learning algorithms in two software data sets. RvC manages to get better regression error than the standard regression approaches on both datasets.},
journal = {Expert Syst. Appl.},
month = apr,
pages = {2091–2101},
numpages = {11},
keywords = {Software quality, Software metrics, Software fault estimation, Regression via Classification, Machine learning, ISBSG data set}
}

@article{10.1007/s10515-021-00285-y,
author = {Goyal, Somya},
title = {Predicting the Defects using Stacked Ensemble Learner with Filtered Dataset},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-021-00285-y},
doi = {10.1007/s10515-021-00285-y},
abstract = {Software defect prediction is a crucial software project management activity to enhance the software quality. It aids the development team to forecast about which modules need extra attention for testing; which part of software is more prone to errors and faults; before the commencement of testing phase. It helps to reduce the testing cost and hence the overall development cost of the software. Though, it ensures in-time delivery of good quality end-product, but there is one major hinderance in making this prediction. This is the class imbalance issue in the training data. Data imbalance in class distribution adversely affects the performance of classifiers. This paper proposes a K-nearest neighbour (KNN) filtering-based data pre-processing technique for stacked ensemble classifier to handle class imbalance issue. First, nearest neighbour-based filtering is applied to filter out the overlapped data-points to reduce Imbalanced Ratio, then, the processed data with static code metrics is supplied to stacked ensemble for prediction. The stacking is achieved with five base classifiers namely Artificial Neural Network, Decision Tree, Na\"{\i}ve Bayes, K-nearest neighbour (KNN) and Support Vector Machine. A comparative analysis among 30 classifiers (5 data pre-processing techniques * 6 prediction techniques) is made. In the experiments, five public datasets from NASA repository namely CM1, JM1, KC1, KC2 and PC1 are used. In total 150 prediction models (5 data pre-processing techniques * 6 classification techniques * 5 datasets) are proposed and their performances are assessed in terms of measures namely Receiver Operator Curve, Area under the Curve and accuracy. The statistical analysis shows that proposed stacked ensemble classifier with KNN filtering performs best among all the predictors independent of datasets.},
journal = {Automated Software Engg.},
month = nov,
numpages = {81},
keywords = {ROC and AUC, Support vector machine, Nearest neighbour, Decision trees, Stacked ensembles, Artificial neural networks (ANN), Class imbalance, Data pre-processing, Defect prediction, Software quality}
}

@inproceedings{10.1007/978-3-540-73451-2_66,
author = {Ramanna, Sheela and Bhatt, Rajen and Biernot, Piotr},
title = {Software Defect Classification: A Comparative Study with Rough Hybrid Approaches},
year = {2007},
isbn = {9783540734505},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-73451-2_66},
doi = {10.1007/978-3-540-73451-2_66},
abstract = {This paper is an extension of our earlier work in combining strengths of rough set theory and neuro-fuzzy decision trees in classifying software defect data. The extension includes the application of a rough-fuzzy classification trees to classifying defects. We compare classification results for five methods: rough sets, neuro-fuzzy decision trees, partial decision trees, rough-neuro-fuzzy decision trees and rough-fuzzy classification trees. The analysis of the results include a paired t-test for accuracy and number of rules. The results demonstrate that there is improvement in classification accuracy with the rough fuzzy classification trees with a minimal set of rules. The contribution of this paper is a comparative study of several hybrid approaches in classifying software defect data.},
booktitle = {Proceedings of the International Conference on Rough Sets and Intelligent Systems Paradigms},
pages = {630–638},
numpages = {9},
keywords = {software defects, rough-fuzzy classification trees, rough sets, neuro-fuzzy decision trees, Classification},
location = {Warsaw, Poland},
series = {RSEISP '07}
}

@inproceedings{10.1145/2811681.2811699,
author = {Hussain, Shahid and Keung, Jacky and Khan, Arif Ali and Bennin, Kwabena Ebo},
title = {Performance Evaluation of Ensemble Methods For Software Fault Prediction: An Experiment},
year = {2015},
isbn = {9781450337960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811681.2811699},
doi = {10.1145/2811681.2811699},
abstract = {In object-oriented software development, a plethora of studies have been carried out to present the application of machine learning algorithms for fault prediction. Furthermore, it has been empirically validated that an ensemble method can improve classification performance as compared to a single classifier. But, due to the inherent differences among machine learning and data mining approaches, the classification performance of ensemble methods will be varied. In this study, we investigated and evaluated the performance of different ensemble methods with itself and base-level classifiers, in predicting the faults proneness classes. Subsequently, we used three ensemble methods AdaboostM1, Vote and StackingC with five base-level classifiers namely Naivebayes, Logistic, J48, VotedPerceptron and SMO in Weka tool. In order to evaluate the performance of ensemble methods, we retrieved twelve datasets of open source projects from PROMISE repository. In this experiment, we used k-fold (k=10) cross-validation and ROC analysis for validation. Besides, we used recall, precision, accuracy, F-value measures to evaluate the performance of ensemble methods and base-level Classifiers. Finally, we observed significant performance improvement of applying ensemble methods as compared to its base-level classifier, and among ensemble methods we observed StackingC outperformed other selected ensemble methods for software fault prediction.},
booktitle = {Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference},
pages = {91–95},
numpages = {5},
keywords = {Weka, Performance, Measures, Ensemble Methods, Classifiers, Chidamber and Kemerer (CK) Metrics},
location = {Adelaide, SA, Australia},
series = {ASWEC ' 15 Vol. II}
}

@inproceedings{10.1109/ICSE43902.2021.00109,
author = {Bui, Nghi D. Q. and Yu, Yijun and Jiang, Lingxiao},
title = {InferCode: Self-Supervised Learning of Code Representations by Predicting Subtrees},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00109},
doi = {10.1109/ICSE43902.2021.00109},
abstract = {Learning code representations has found many uses in software engineering, such as code classification, code search, comment generation, and bug prediction, etc. Although representations of code in tokens, syntax trees, dependency graphs, paths in trees, or the combinations of their variants have been proposed, existing learning techniques have a major limitation that these models are often trained on datasets labeled for specific downstream tasks, and as such the code representations may not be suitable for other tasks. Even though some techniques generate representations from unlabeled code, they are far from being satisfactory when applied to the downstream tasks. To overcome the limitation, this paper proposes InferCode, which adapts the self-supervised learning idea from natural language processing to the abstract syntax trees (ASTs) of code. The novelty lies in the training of code representations by predicting subtrees automatically identified from the contexts of ASTs. With InferCode, subtrees in ASTs are treated as the labels for training the code representations without any human labelling effort or the overhead of expensive graph construction, and the trained representations are no longer tied to any specific downstream tasks or code units.We have trained an instance of InferCode model using Tree-Based Convolutional Neural Network (TBCNN) as the encoder of a large set of Java code. This pre-trained model can then be applied to downstream unsupervised tasks such as code clustering, code clone detection, cross-language code search, or be reused under a transfer learning scheme to continue training the model weights for supervised tasks such as code classification and method name prediction. Compared to prior techniques applied to the same downstream tasks, such as code2vec, code2seq, ASTNN, using our pre-trained InferCode model higher performance is achieved with a significant margin for most of the tasks, including those involving different programming languages. The implementation of InferCode and the trained embeddings are available at the link: https://github.com/bdqnghi/infercode.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1186–1197},
numpages = {12},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3302333.3302338,
author = {Amand, Benoit and Cordy, Maxime and Heymans, Patrick and Acher, Mathieu and Temple, Paul and J\'{e}z\'{e}quel, Jean-Marc},
title = {Towards Learning-Aided Configuration in 3D Printing: Feasibility Study and Application to Defect Prediction},
year = {2019},
isbn = {9781450366489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302333.3302338},
doi = {10.1145/3302333.3302338},
abstract = {Configurators rely on logical constraints over parameters to aid users and determine the validity of a configuration. However, for some domains, capturing such configuration knowledge is hard, if not infeasible. This is the case in the 3D printing industry, where parametric 3D object models contain the list of parameters and their value domains, but no explicit constraints. This calls for a complementary approach that learns what configurations are valid based on previous experiences. In this paper, we report on preliminary experiments showing the capability of state-of-the-art classification algorithms to assist the configuration process. While machine learning holds its promises when it comes to evaluation scores, an in-depth analysis reveals the opportunity to combine the classifiers with constraint solvers.},
booktitle = {Proceedings of the 13th International Workshop on Variability Modelling of Software-Intensive Systems},
articleno = {7},
numpages = {9},
keywords = {Sampling, Machine Learning, Configuration, 3D printing},
location = {Leuven, Belgium},
series = {VaMoS '19}
}

@inproceedings{10.1145/3293882.3330580,
author = {Cordy, Maxime and Muller, Steve and Papadakis, Mike and Le Traon, Yves},
title = {Search-based test and improvement of machine-learning-based anomaly detection systems},
year = {2019},
isbn = {9781450362245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293882.3330580},
doi = {10.1145/3293882.3330580},
abstract = {Machine-learning-based anomaly detection systems can be vulnerable to new kinds of deceptions, known as training attacks, which exploit the live learning mechanism of these systems by progressively injecting small portions of abnormal data. The injected data seamlessly swift the learned states to a point where harmful data can pass unnoticed. We focus on the systematic testing of these attacks in the context of intrusion detection systems (IDS). We propose a search-based approach to test IDS by making training attacks. Going a step further, we also propose searching for countermeasures, learning from the successful attacks and thereby increasing the resilience of the tested IDS. We evaluate our approach on a denial-of-service attack detection scenario and a dataset recording the network traffic of a real-world system. Our experiments show that our search-based attack scheme generates successful attacks bypassing the current state-of-the-art defences. We also show that our approach is capable of generating attack patterns for all configuration states of the studied IDS and that it is capable of providing appropriate countermeasures. By co-evolving our attack and defence mechanisms we succeeded at improving the defence of the IDS under test by making it resilient to 49 out of 50 independently generated attacks.},
booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {158–168},
numpages = {11},
keywords = {software testing, intrusion detection systems, clustering},
location = {Beijing, China},
series = {ISSTA 2019}
}

@article{10.1007/s10664-010-9151-7,
author = {Kpodjedo, Segla and Ricca, Filippo and Galinier, Philippe and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l and Antoniol, Giuliano},
title = {Design evolution metrics for defect prediction in object oriented systems},
year = {2011},
issue_date = {February  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-010-9151-7},
doi = {10.1007/s10664-010-9151-7},
abstract = {Testing is the most widely adopted practice to ensure software quality. However, this activity is often a compromise between the available resources and software quality. In object-oriented development, testing effort should be focused on defective classes. Unfortunately, identifying those classes is a challenging and difficult activity on which many metrics, techniques, and models have been tried. In this paper, we investigate the usefulness of elementary design evolution metrics to identify defective classes. The metrics include the numbers of added, deleted, and modified attributes, methods, and relations. The metrics are used to recommend a ranked list of classes likely to contain defects for a system. They are compared to Chidamber and Kemerer's metrics on several versions of Rhino and of ArgoUML. Further comparison is conducted with the complexity metrics computed by Zimmermann et al. on several releases of Eclipse. The comparisons are made according to three criteria: presence of defects, number of defects, and defect density in the top-ranked classes. They show that the design evolution metrics, when used in conjunction with known metrics, improve the identification of defective classes. In addition, they show that the design evolution metrics make significantly better predictions of defect density than other metrics and, thus, can help in reducing the testing effort by focusing test activity on a reduced volume of code.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {141–175},
numpages = {35},
keywords = {Error tolerant graph matching, Design evolution metrics, Defect prediction}
}

@article{10.1016/j.infsof.2009.10.003,
author = {Hassouna, Alaa and Tahvildari, Ladan},
title = {An effort prediction framework for software defect correction},
year = {2010},
issue_date = {February, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {2},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2009.10.003},
doi = {10.1016/j.infsof.2009.10.003},
abstract = {This article tackles the problem of predicting effort (in person-hours) required to fix a software defect posted on an Issue Tracking System. The proposed method is inspired by the Nearest Neighbour Approach presented by the pioneering work of Weiss et al. (2007) [1]. We propose four enhancements to Weiss et al. (2007) [1]: Data Enrichment, Majority Voting, Adaptive Threshold and Binary Clustering. Data Enrichment infuses additional issue information into the similarity-scoring procedure, aiming to increase the accuracy of similarity scores. Majority Voting exploits the fact that many of the similar historical issues have repeating effort values, which are close to the actual. Adaptive Threshold automatically adjusts the similarity threshold to ensure that we obtain only the most similar matches. We use Binary Clustering if the similarity scores are very low, which might result in misleading predictions. This uses common properties of issues to form clusters (independent of the similarity scores) which are then used to produce the predictions. Numerical results are presented showing a noticeable improvement over the method proposed in Weiss et al. (2007) [1].},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {197–209},
numpages = {13},
keywords = {Software effort prediction, Software defect correction, Issue tracking system, Clustering, Case-based reasoning}
}

@inproceedings{10.1007/978-3-540-72530-5_9,
author = {Ramanna, Sheela and Bhatt, Rajen and Biernot, Piotr},
title = {A Rough-Hybrid Approach to Software Defect Classification},
year = {2009},
isbn = {9783540725299},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-72530-5_9},
doi = {10.1007/978-3-540-72530-5_9},
abstract = {Knowledge discovery methods used to find relationships among software engineering data and the extraction of rules have gained increasing importance in recent years. These methods have become necessary for improvements in the quality of the software product and the process. The focus of this paper is a first attempt towards combining strengths of rough set theory and neuro-fuzzy decision trees in classifying software defect data. We compare classification results for four methods: rough sets, neuro-fuzzy decision trees, partial decision trees, rough-neuro-fuzzy decision trees. The analysis of the results include a family-wise 10 fold paired t-test for accuracy and number of rules. The contribution of this paper is the application of a hybrid rough-neuro-fuzzy decision tree method in classifying software defect data.},
booktitle = {Proceedings of the 11th International Conference on Rough Sets, Fuzzy Sets, Data Mining and Granular Computing},
pages = {79–86},
numpages = {8},
keywords = {Software Defects, Rough Sets, Neuro-Fuzzy-Decision Trees, Classification},
location = {Toronto, Ontario, Canada},
series = {RSFDGrC '07}
}

@inproceedings{10.5555/1888258.1888293,
author = {Eichinger, Frank and Krogmann, Klaus and Klug, Roland and B\"{o}hm, Klemens},
title = {Software-defect localisation by mining dataflow-enabled call graphs},
year = {2010},
isbn = {364215879X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Defect localisation is essential in software engineering and is an important task in domain-specific data mining. Existing techniques building on call-graph mining can localise different kinds of defects. However, these techniques focus on defects that affect the controlflow and are agnostic regarding the dataflow. In this paper, we introduce dataflowenabled call graphs that incorporate abstractions of the dataflow. Building on these graphs, we present an approach for defect localisation. The creation of the graphs and the defect localisation are essentially data mining problems, making use of discretisation, frequent subgraph mining and feature selection. We demonstrate the defect-localisation qualities of our approach with a study on defects introduced into Weka. As a result, defect localisation now works much better, and a developer has to investigate on average only 1.5 out of 30 methods to fix a defect.},
booktitle = {Proceedings of the 2010 European Conference on Machine Learning and Knowledge Discovery in Databases: Part I},
pages = {425–441},
numpages = {17},
location = {Barcelona, Spain},
series = {ECML PKDD'10}
}

@inproceedings{10.1145/2532443.2532461,
author = {Chen, Jiaqiang and Liu, Shulong and Chen, Xiang and Gu, Qing and Chen, Daoxu},
title = {Empirical studies on feature selection for software fault prediction},
year = {2013},
isbn = {9781450323697},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2532443.2532461},
doi = {10.1145/2532443.2532461},
abstract = {Classification based software fault prediction methods aim to classify the modules into either fault-prone or non-fault-prone. Feature selection is a preprocess step used to improve the data quality. However most of previous research mainly focus on feature relevance analysis, there is little work focusing on feature redundancy analysis. Therefore we propose a two-stage framework for feature selection to solve this issue. In particular, during the feature relevance phase, we adopt three different relevance measures to obtain the relevant feature subset. Then during the feature redundancy analysis phase, we use a cluster-based method to eliminate redundant features. To verify the effectiveness of our proposed framework, we choose typical real-world software projects, including Eclipse projects and NASA software project KC1. Final empirical result shows the effectiveness of our proposed framework.},
booktitle = {Proceedings of the 5th Asia-Pacific Symposium on Internetware},
articleno = {26},
numpages = {4},
keywords = {software fault prediction, relevance analysis, redundancy analysis, feature selection},
location = {Changsha, China},
series = {Internetware '13}
}

@article{10.1007/s00500-016-2316-6,
author = {Chinna Gounder Dhanajayan, Rajaganapathy and Appavu Pillai, Subramani},
title = {SLMBC: spiral life cycle model-based Bayesian classification technique for efficient software fault prediction and classification},
year = {2017},
issue_date = {January   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {2},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-016-2316-6},
doi = {10.1007/s00500-016-2316-6},
abstract = {Software fault prediction and classification plays a vital role in the software development process for assuring high quality and reliability of the software product. Earlier prediction of the fault-prone software modules enables timely correction of the faults and delivery of reliable product. Generally, the fuzzy logic, decision tree and neural networks are deployed for fault prediction. But these techniques suffer due to low accuracy and inconsistency. To overcome these issues, this paper proposes a spiral life cycle model-based Bayesian classification technique for efficient software fault prediction and classification. In this process, initially the dependent and independent software modules are identified. The spiral life cycle model is used for testing the software modules in each life cycle of the software development process. Bayesian classification is applied to classify the software modules as faulty module and non-faulty module, by using the probability distribution models. Robust similarity-aware clustering algorithm performs clustering of the faulty and non-faulty software modules based on the similarity measure of the features in the dataset. From the experimental results, it is observed that the proposed method enables accurate prediction and classification of the faulty modules. The proposed technique achieves higher accuracy, precision, recall, probability of detection, F-measure and lower error rate than the existing techniques. The misclassification rate of the proposed technique is found to be lower than the existing techniques. Hence, the reliability of the software development process can be improved.},
journal = {Soft Comput.},
month = jan,
pages = {403–415},
numpages = {13},
keywords = {Spiral life cycle model-based Bayesian classification technique (SLMBC), Spiral life cycle model, Software development, Segregate fault prediction algorithm, Robust similarity-aware clustering (RSC) algorithm, Bayesian classification}
}

@inproceedings{10.1145/2701126.2701207,
author = {Kim, Jeongho and Park, Jonghee and Lee, Eunseok},
title = {A new hybrid algorithm for software fault localization},
year = {2015},
isbn = {9781450333771},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2701126.2701207},
doi = {10.1145/2701126.2701207},
abstract = {We previously presented a spectrum-based fault localization (SFL) technique, which we named Hybrid, that localizes a bug by using the program hit spectra and test results. We also proposed a distinct mechanism for test data that enables the SFL algorithms to localize fault in a more precise manner than what would be possible with the original test data. However, there was a limitation of the Hybrid algorithm. In that the technique only showed better performance when using distinct test data. Therefore, in the current work, we improve over Hybrid by analyzing more than 30 types of existing algorithms. After choosing the appropriate algorithms, we adopted their specific strengths through experimentation. Finally, we developed the novel Combination Algorithms (CAL). In our experimental study, we used the Siemens test program to confirm that our technique was more precise than the state-of-the-art SFL algorithm D Star and Heuristic III for both original and distinct test data. In particular, our technique localizes a fault under 2 percent on average as well as decreases the coverage of the reading code by a third of the source code.},
booktitle = {Proceedings of the 9th International Conference on Ubiquitous Information Management and Communication},
articleno = {50},
numpages = {8},
keywords = {suspicious code, spectrum based fault localization, program debugging, fault localization, execution trace},
location = {Bali, Indonesia},
series = {IMCOM '15}
}

@inproceedings{10.1145/2365324.2365335,
author = {Lu, Huihua and Cukic, Bojan},
title = {An adaptive approach with active learning in software fault prediction},
year = {2012},
isbn = {9781450312417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2365324.2365335},
doi = {10.1145/2365324.2365335},
abstract = {Background: Software quality prediction plays an important role in improving the quality of software systems. By mining software metrics, predictive models can be induced that provide software managers with insights into quality problems they need to tackle as effectively as possible.Objective: Traditional, supervised learning approaches dominate software quality prediction. Resulting models tend to be project specific. On the other hand, in situations where there are no previous releases, supervised learning approaches are not very useful because large training data sets are needed to develop accurate predictive models.Method: This paper eases the limitations of supervised learning approaches and offers good prediction performance. We propose an adaptive approach in which supervised learning and active learning are coupled together. NaiveBayes classifier is used as the base learner.Results: We track the performance at each iteration of the adaptive learning algorithm and compare it with the performance of supervised learning. Our results show that proposed scheme provides good fault prediction performance over time, i.e., it eventually outperforms the corresponding supervised learning approach. On the other hand, adaptive learning classification approach reduces the variance in prediction performance in comparison with the corresponding supervised learning algorithm.Conclusion: The adaptive approach outperforms the corresponding supervised learning approach when both use Naive-Bayes as base learner. Additional research is needed to investigate whether this observation remains valid with other base classifiers.},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering},
pages = {79–88},
numpages = {10},
keywords = {active learning, adaptive learning, software fault prediction},
location = {Lund, Sweden},
series = {PROMISE '12}
}

@article{10.1007/s11219-019-09472-3,
author = {Li, J . Jenny and Ulrich, Andreas and Bai, Xiaoying and Bertolino, Antonia},
title = {Advances in test automation for software with special focus on artificial intelligence and machine learning},
year = {2020},
issue_date = {Mar 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-019-09472-3},
doi = {10.1007/s11219-019-09472-3},
journal = {Software Quality Journal},
month = mar,
pages = {245–248},
numpages = {4}
}

@inproceedings{10.5555/2337223.2337246,
author = {Peters, Fayola and Menzies, Tim},
title = {Privacy and utility for defect prediction: experiments with MORPH},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {Ideally, we can learn lessons from software projects across multiple organizations. However, a major impediment to such knowledge sharing are the privacy concerns of software development organizations. This paper aims to provide defect data-set owners with an effective means of privatizing their data prior to release. We explore MORPH which understands how to maintain class boundaries in a data-set. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. The value of training on this MORPHed data is tested via a 10-way within learning study and a cross learning study using Random Forests, Naive Bayes, and Logistic Regression for ten object-oriented defect data-sets from the PROMISE data repository. Measured in terms of exposure of sensitive attributes, the MORPHed data was four times more private than the unMORPHed data. Also, in terms of the f-measures, there was little difference between the MORPHed and unMORPHed data (original data and data privatized by data-swapping) for both the cross and within study. We conclude that at least for the kinds of OO defect data studied in this project, data can be privatized without concerns for inference efficacy.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {189–199},
numpages = {11},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@inproceedings{10.1007/978-3-642-05250-7_46,
author = {Ren, Jiadong and Hu, Changzhen and Wang, Kunsheng and Zhang, Dongmei},
title = {Software Fault Feature Clustering Algorithm Based on Sequence Pattern},
year = {2009},
isbn = {9783642052491},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-05250-7_46},
doi = {10.1007/978-3-642-05250-7_46},
abstract = {Software fault feature analysis has been the important part of software security property analysis and modeling. In this paper, a software fault feature clustering algorithm based on sequence pattern (SFFCSP) is proposed. In SFFCSP, Fault feature matrix is defined to store the relation between the fault feature and the existing sequence pattern. The optimal number of clusters is determined through computing the improved silhouette of fault feature matrix row vector, which corresponds to the software fault feature. In the agglomerative hierarchical clustering phase, entropy is considered as the similarity metric. In order to improve the time complexity of the software fault feature analysis, the fault features of the software to be analyzed are matched to each centroid of clustering results. Experimental results show that SFFCSP has better clustering accuracy and lower time complexity compared with the SEQOPTICS.},
booktitle = {Proceedings of the International Conference on Web Information Systems and Mining},
pages = {439–447},
numpages = {9},
keywords = {software fault feature clustering, sequence pattern, improved silhouette, entropy},
location = {Shanghai, China},
series = {WISM '09}
}

@article{10.1016/j.ins.2019.08.077,
author = {Peng, Zhendong and Xiao, Xi and Hu, Guangwu and Kumar Sangaiah, Arun and Atiquzzaman, Mohammed and Xia, Shutao},
title = {ABFL: An autoencoder based practical approach for software fault localization},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {510},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.08.077},
doi = {10.1016/j.ins.2019.08.077},
journal = {Inf. Sci.},
month = feb,
pages = {108–121},
numpages = {14},
keywords = {Autoencoder, SBFL, Debugging, Fault localization}
}

@inproceedings{10.1007/11497455_10,
author = {Leszak, Marek},
title = {Software defect analysis of a multi-release telecommunications system},
year = {2005},
isbn = {3540262008},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11497455_10},
doi = {10.1007/11497455_10},
abstract = {This paper provides a study of several process metrics of an industrial large-scale embedded software system, the Lucent product Lambda-UniteTM MSS. This product is an evolutionary hardware/software system for the metropolitan and wide-area transmission and switching market. An analysis of defect data is performed, including and comparing all major (i.e. feature) releases till end of 2004. Several defect metrics on file-level are defined and analyzed, as basis for a defect prediction model. Main analysis results include the following. Faults and code size per file show only a weak correlation. Portion of faulty files per release tend to decrease across releases. Size and error-proneness in previous release alone is not a good predictor of a file's faults per release. Customer-found defects are strongly correlated with pre-delivery defects found per subsystem. These results are being compared to a recent similar study of fault distributions; the differences are significant.},
booktitle = {Proceedings of the 6th International Conference on Product Focused Software Process Improvement},
pages = {98–114},
numpages = {17},
keywords = {software process metrics, errorproneness, defect prediction, defect density, case study},
location = {Oulu, Finland},
series = {PROFES'05}
}

@article{10.1007/s00500-019-04047-7,
author = {Sudharson, D. and Prabha, D.},
title = {RETRACTED ARTICLE: A novel machine learning
approach for software reliability growth modelling with pareto distribution
function},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {18},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-019-04047-7},
doi = {10.1007/s00500-019-04047-7},
abstract = {Software reliability is the important quantifiable attribute in gaining
reliability by assessing faults at the time of testing in the software products.
Time-based software reliability models used to identify the defects in the product,
and it is not suitable for dynamic situations. Instead of time, test effect is used
in few explorations through effort function and it is not realistic for infinite
testing time. Identifying number of defects is essential in software reliability
models, and this research work presents a Pareto distribution (PD) to predict the
fault distribution of software under homogenous and nonhomogeneous conditions along
with artificial neural network (ANN). This methodology enables the parallel
evolution of a product through NN models which exhibit estimated Pareto optimality
with respect to multiple error measures. The proposed PD-ANN-based SRGM describes
types of failure data and also improves the accuracy of parameter estimation more
than existing growth models such as homogeneous poison process and two fuzzy time
series-based software reliability models. Experimental evidence is presented for
general application and the proposed framework by generating solutions for different
product and developer indexes.},
journal = {Soft Comput.},
month = sep,
pages = {8379–8387},
numpages = {9},
keywords = {Software reliability, Artificial neural networks, Pareto distribution, Distribution parameter estimation}
}

@inproceedings{10.1145/1083165.1083173,
author = {Boetticher, Gary D.},
title = {Nearest neighbor sampling for better defect prediction},
year = {2005},
isbn = {1595931252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083165.1083173},
doi = {10.1145/1083165.1083173},
abstract = {An important step in building effective predictive models applies one or more sampling techniques. Traditional sampling techniques include random, stratified, systemic, and clustered. The problem with these techniques is that they focus on the class attribute, rather than the non-class attributes. For example, if a test instance's nearest neighbor is from the opposite class of the training set, then it seems doomed to misclassification. To illustrate this problem, this paper conducts 20 experiments on five different NASA defect datasets (CM1, JM1, KC1, KC2, PC1) using two different learners (J48 and Na\"{\i}ve Bayes). Each data set is divided into 3 groups, a training set, and "nice/nasty" neighbor test sets. Using a nearest neighbor approach, "Nice neighbors" consist of those test instances closest to class training instances. "Nasty neighbors" are closest to opposite class training instances. The "Nice" experiments average 94 percent accuracy and the "Nasty" experiments average 20 percent accuracy. Based on these results a new nearest neighbor sampling technique is proposed.},
booktitle = {Proceedings of the 2005 Workshop on Predictor Models in Software Engineering},
pages = {1–6},
numpages = {6},
keywords = {NASA data repository, decision trees, defect prediction, empirical software engineering, nearest neighbor analysis},
location = {St. Louis, Missouri},
series = {PROMISE '05}
}

@article{10.1016/j.eswa.2008.10.027,
author = {Catal, Cagatay and Diri, Banu},
title = {A systematic review of software fault prediction studies},
year = {2009},
issue_date = {May, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2008.10.027},
doi = {10.1016/j.eswa.2008.10.027},
abstract = {This paper provides a systematic review of previous software fault prediction studies with a specific focus on metrics, methods, and datasets. The review uses 74 software fault prediction papers in 11 journals and several conference proceedings. According to the review results, the usage percentage of public datasets increased significantly and the usage percentage of machine learning algorithms increased slightly since 2005. In addition, method-level metrics are still the most dominant metrics in fault prediction research area and machine learning algorithms are still the most popular methods for fault prediction. Researchers working on software fault prediction area should continue to use public datasets and machine learning algorithms to build better fault predictors. The usage percentage of class-level is beyond acceptable levels and they should be used much more than they are now in order to predict the faults earlier in design phase of software life cycle.},
journal = {Expert Syst. Appl.},
month = may,
pages = {7346–7354},
numpages = {9},
keywords = {Public datasets, Method-level metrics, Machine learning, Expert systems, Automated fault prediction models}
}

@inproceedings{10.1145/3416505.3423563,
author = {Palma, Stefano Dalla and Mohammadi, Majid and Di Nucci, Dario and Tamburri, Damian A.},
title = {Singling the odd ones out: a novelty detection approach to find defects in infrastructure-as-code},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423563},
doi = {10.1145/3416505.3423563},
abstract = {Infrastructure-as-Code (IaC) is increasingly adopted. However, little is known about how to best maintain and evolve it. Previous studies focused on defining Machine-Learning models to predict defect-prone blueprints using supervised binary classification. This class of techniques uses both defective and non-defective instances in the training phase. Furthermore, the high imbalance between defective and non-defective samples makes the training more difficult and leads to unreliable classifiers. In this work, we tackle the defect-prediction problem from a different perspective using novelty detection and evaluate the performance of three techniques, namely OneClassSVM, LocalOutlierFactor, and IsolationForest, and compare their performance with a baseline RandomForest binary classifier. Such models are trained using only non-defective samples: defective data points are treated as novelty because the number of defective samples is too little compared to defective ones. We conduct an empirical study on an extremely-imbalanced dataset consisting of 85 real-world Ansible projects containing only small amounts of defective instances. We found that novelty detection techniques can recognize defects with a high level of precision and recall, an AUC-PR up to 0.86, and an MCC up to 0.31. We deem our results can influence the current trends in defect detection and put forward a new research path toward dealing with this problem.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {31–36},
numpages = {6},
keywords = {Novelty Detection, Infrastructure-as-Code, Defect Prediction},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@inproceedings{10.1145/2593833.2593842,
author = {Malhotra, Ruchika},
title = {Search based techniques for software fault prediction: current trends and future directions},
year = {2014},
isbn = {9781450328524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593833.2593842},
doi = {10.1145/2593833.2593842},
abstract = {The effective allocation of the resources is crucial and essential in the testing phase of the software development life cycle so that the weak areas in the software can be verified and validated efficiently. The prediction of fault prone classes in the early phases of software development can help software developers to focus the limited available resources on those portions of software, which are more prone to fault. Recently, the search based techniques have been successfully applied in the software engineering domain. In this study, we analyze the position of search based techniques for use in software fault prediction by collecting relevant studies from the literature which were conducted during the period January 1991 to October 2013. We further summarize current trends by assessing the performance capability of the search based techniques in the existing research and suggest future directions.},
booktitle = {Proceedings of the 7th International Workshop on Search-Based Software Testing},
pages = {35–36},
numpages = {2},
keywords = {Software Quality, Software Fault proneness, Search Based Techniques},
location = {Hyderabad, India},
series = {SBST 2014}
}

@article{10.1145/1317471.1317478,
author = {Ploski, Jan and Rohr, Matthias and Schwenkenberg, Peter and Hasselbring, Wilhelm},
title = {Research issues in software fault categorization},
year = {2007},
issue_date = {November 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {6},
issn = {0163-5948},
url = {https://doi.org/10.1145/1317471.1317478},
doi = {10.1145/1317471.1317478},
abstract = {Software faults are a major threat for the dependability of software systems. When we intend to study the impact of software faults on software behavior, examine the quality of fault tolerance mechanisms, or evaluate diagnostic techniques, the issue of distinguishing fault categories and their frequency distribution arises immediately. This article surveys the literature that provides quantitative data on categories of software faults and discusses the applicability of these software fault category distributions to fault injection case studies.},
journal = {SIGSOFT Softw. Eng. Notes},
month = nov,
pages = {6–es},
numpages = {8},
keywords = {software reliability, software faults, software fault categorization, injection of software faults, bugs}
}

@inproceedings{10.1145/2970276.2970364,
author = {Li, Xin and Liang, Yongjuan and Qian, Hong and Hu, Yi-Qi and Bu, Lei and Yu, Yang and Chen, Xin and Li, Xuandong},
title = {Symbolic execution of complex program driven by machine learning based constraint solving},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970364},
doi = {10.1145/2970276.2970364},
abstract = {Symbolic execution is a widely-used program analysis technique. It collects and solves path conditions to guide the program traversing. However, due to the limitation of the current constraint solvers, it is difficult to apply symbolic execution on programs with complex path conditions, like nonlinear constraints and function calls. In this paper, we propose a new symbolic execution tool MLB to handle such problem. Instead of relying on the classical constraint solving, in MLB, the feasibility problems of the path conditions are transformed into optimization problems, by minimizing some dissatisfaction degree. The optimization problems are then handled by the underlying optimization solver through machine learning guided sampling and validation. MLB is implemented on the basis of Symbolic PathFinder and encodes not only the simple linear path conditions, but also nonlinear arithmetic operations, and even black-box function calls of library methods, into symbolic path conditions. Experiment results show that MLB can achieve much better coverage on complex real-world programs.},
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {554–559},
numpages = {6},
keywords = {Symbolic Execution, Machine Learning, Constraint Solving, Complicated Path Condition},
location = {Singapore, Singapore},
series = {ASE '16}
}

@inproceedings{10.1109/IVS.2018.8500421,
author = {Tuncali, Cumhur Erkan and Fainekos, Georgios and Ito, Hisahiro and Kapinski, James},
title = {Simulation-based Adversarial Test Generation for Autonomous Vehicles with Machine Learning Components},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IVS.2018.8500421},
doi = {10.1109/IVS.2018.8500421},
abstract = {Many organizations are developing autonomous driving systems, which are expected to be deployed at a large scale in the near future. Despite this, there is a lack of agreement on appropriate methods to test, debug, and certify the performance of these systems. One of the main challenges is that many autonomous driving systems have machine learning (ML) components, such as deep neural networks, for which formal properties are difficult to characterize. We present a testing framework that is compatible with test case generation and automatic falsification methods, which are used to evaluate cyber-physical systems. We demonstrate how the framework can be used to evaluate closed-loop properties of an autonomous driving system model that includes the ML components, all within a virtual environment. We demonstrate how to use test case generation methods, such as covering arrays, as well as requirement falsification methods to automatically identify problematic test scenarios. The resulting framework can be used to increase the reliability of autonomous driving systems.},
booktitle = {2018 IEEE Intelligent Vehicles Symposium (IV)},
pages = {1555–1562},
numpages = {8},
location = {Changshu, Suzhou, China}
}

@inproceedings{10.5555/1802408.1802423,
author = {Jiang, Yue and Lin, Jie and Cukic, Bojan and Menzies, Tim},
title = {Variance analysis in software fault prediction models},
year = {2009},
isbn = {9781424453757},
publisher = {IEEE Press},
abstract = {Software fault prediction models play an important role in software quality assurance. They identify software subsystems (modules, components, classes, or files) which are likely to contain faults. These subsystems, in turn, receive additional resources for verification and validation activities. Fault prediction models are binary classifiers typically developed using one of the supervised learning techniques from either a subset of the fault data from the current project or from a similar past project. In practice, it is critical that such models provide a reliable prediction performance on the data not used in training. Variance is an important reliability indicator of software fault prediction models. However, variance is often ignored or barely mentioned in many published studies. In this paper, through the analysis of twelve data sets from a public software engineering repository from the perspective of variance, we explore the following five questions regarding fault prediction models: (1) Do different types of classification performance measures exhibit different variance? (2) Does the size of the data set imply a more (or less) accurate prediction performance? (3) Does the size of training subset impact model's stability? (4) Do different classifiers consistently exhibit different performance in terms of model's variance? (5) Are there differences between variance from 1000 runs and 10 runs of 10-fold cross validation experiments? Our results indicate that variance is a very important factor in understanding fault prediction models and we recommend the best practice for reporting variance in empirical software engineering studies.},
booktitle = {Proceedings of the 20th IEEE International Conference on Software Reliability Engineering},
pages = {99–108},
numpages = {10},
location = {Bengaluru-Mysuru, India},
series = {ISSRE'09}
}

@article{10.1109/TKDE.2011.163,
author = {Bishnu, Partha S. and Bhattacherjee, Vandana},
title = {Software Fault Prediction Using Quad Tree-Based K-Means Clustering Algorithm},
year = {2012},
issue_date = {June 2012},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {24},
number = {6},
issn = {1041-4347},
url = {https://doi.org/10.1109/TKDE.2011.163},
doi = {10.1109/TKDE.2011.163},
abstract = {Unsupervised techniques like clustering may be used for fault prediction in software modules, more so in those cases where fault labels are not available. In this paper a Quad Tree-based K-Means algorithm has been applied for predicting faults in program modules. The aims of this paper are twofold. First, Quad Trees are applied for finding the initial cluster centers to be input to the K-Means Algorithm. An input threshold parameter delta governs the number of initial cluster centers and by varying delta the user can generate desired initial cluster centers. The concept of clustering gain has been used to determine the quality of clusters for evaluation of the Quad Tree-based initialization algorithm as compared to other initialization techniques. The clusters obtained by Quad Tree-based algorithm were found to have maximum gain values. Second, the Quad Tree-based algorithm is applied for predicting faults in program modules. The overall error rates of this prediction approach are compared to other existing algorithms and are found to be better in most of the cases.},
journal = {IEEE Trans. on Knowl. and Data Eng.},
month = jun,
pages = {1146–1150},
numpages = {5},
keywords = {software fault prediction., Quad Tree, K-Means clustering}
}

@inproceedings{10.1145/3373477.3373486,
author = {Aggarwal, Simran},
title = {Software code analysis using ensemble learning techniques},
year = {2020},
isbn = {9781450372916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373477.3373486},
doi = {10.1145/3373477.3373486},
abstract = {Ensuing the advent of advancements in software systems, the probability of them containing high severity defects is exponentially on the rise. With each technological addition, the complexity of software is increasing. Reproduction and rectification of a defect requires time and effort. Current state of the art analysis tools cater to the investigation of static aspects of a production level code. However, it is imperative to assess the dynamic development process of a system so as to be able to timely detect erroneous components early on in the development life cycle of a software. A novel automated defect prediction feature enhancement is proposed that analyses the static structure of the current code and state of the software in past releases to extract relevant static and dynamic feature sets. Data generated is modelled for defect trends in the future release of the software by four ensemble classifiers. Results demonstrate the superiority of Voting algorithm for the problem of defect prediction.},
booktitle = {Proceedings of the 1st International Conference on Advanced Information Science and System},
articleno = {9},
numpages = {7},
keywords = {software quality, object-oriented metrics, machine learning, ensemble learning, empirical validation, defect prediction},
location = {Singapore, Singapore},
series = {AISS '19}
}

@article{10.1016/j.jss.2010.11.920,
author = {Xie, Xiaoyuan and Ho, Joshua W. K. and Murphy, Christian and Kaiser, Gail and Xu, Baowen and Chen, Tsong Yueh},
title = {Testing and validating machine learning classifiers by metamorphic testing},
year = {2011},
issue_date = {April, 2011},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {84},
number = {4},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2010.11.920},
doi = {10.1016/j.jss.2010.11.920},
abstract = {Abstract: Machine learning algorithms have provided core functionality to many application domains - such as bioinformatics, computational linguistics, etc. However, it is difficult to detect faults in such applications because often there is no ''test oracle'' to verify the correctness of the computed outputs. To help address the software quality, in this paper we present a technique for testing the implementations of machine learning classification algorithms which support such applications. Our approach is based on the technique ''metamorphic testing'', which has been shown to be effective to alleviate the oracle problem. Also presented include a case study on a real-world machine learning application framework, and a discussion of how programmers implementing machine learning algorithms can avoid the common pitfalls discovered in our study. We also conduct mutation analysis and cross-validation, which reveal that our method has high effectiveness in killing mutants, and that observing expected cross-validation result alone is not sufficiently effective to detect faults in a supervised classification program. The effectiveness of metamorphic testing is further confirmed by the detection of real faults in a popular open-source classification program.},
journal = {J. Syst. Softw.},
month = apr,
pages = {544–558},
numpages = {15},
keywords = {Verification, Validation, Test oracle, Oracle problem, Metamorphic testing, Machine learning}
}

@phdthesis{10.5555/2519129,
author = {Xu, Jie},
title = {Empirical analysis of the procedure for deriving software defect estimation models},
year = {2011},
isbn = {9780494895252},
publisher = {University of Western Ontario},
address = {CAN},
abstract = {Software has become ubiquitous in our daily lives, and software with trusted quality has been critical in many domains. As a result, software quality assurance has been a heated topic for several decades. More precise quality management can be accomplished if we can allocate resources based on accurate quality estimation in the early stages of a project. Many software metrics and software quality estimation models have been proposed to enhance software quality and they have shown promise, but their usefulness was controversial and none of them was widely accepted. Moreover, there is no practical guideline for building software quality estimation models. In this dissertation, a general procedure is proposed to derive software defect estimation models and various techniques are presented to accomplish the tasks in individual steps. The description of the six-step procedure is clearly stated and thorough. The first step is to review the literature review in order to identify the estimation target and related problems. Next, data preparation is done to collect suitable data for the modeling. Then statistical techniques together with machine learning methods are used to validate the effectiveness of software metrics. After that, statistical modeling can be performed to obtain the regression formula. Moreover, a neuro-fuzzy recalibration approach is adopted to improve the accuracy of the statistical model. Lastly, the evaluation of the derived model can be made. This six-step procedure is carried out based on data from both the ISBSG repository and OSS projects to present its practical value. The results demonstrate the significance of the procedure in building software quality estimation models. The proposed procedure is applicable to build defect estimation models from scratch or improve performance of current algorithmic estimation models. Moreover, it can be used in other areas of software estimation such as software cost estimation.   Keywords:  software quality, quality estimation, statistical techniques, soft computing, neuro-fuzzy approach},
note = {AAINR89525}
}

@article{10.1007/s11334-017-0295-0,
author = {Shatnawi, Raed},
title = {The application of ROC analysis in threshold identification, data imbalance and metrics selection for software fault prediction},
year = {2017},
issue_date = {September 2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {2–3},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-017-0295-0},
doi = {10.1007/s11334-017-0295-0},
abstract = {Software engineers have limited resources and need metrics analysis tools to investigate software quality such as fault-proneness of modules. There are a large number of software metrics available to investigate quality. However, not all metrics are strongly correlated with faults. In addition, software fault data are imbalanced and affect quality assessment tools such as fault prediction or threshold values that are used to identify risky modules. Software quality is investigated for three purposes. First, the receiver operating characteristics (ROC) analysis is used to identify threshold values to identify risky modules. Second, the ROC analysis is investigated for imbalanced data. Third, the ROC analysis is considered for feature selection. This work validated the use of ROC to identify thresholds for four metrics (WMC, CBO, RFC and LCOM). The ROC results after sampling the data are not significantly different from before sampling. The ROC analysis selects the same metrics (WMC, CBO and RFC) in most datasets, while other techniques have a large variation in selecting metrics.},
journal = {Innov. Syst. Softw. Eng.},
month = sep,
pages = {201–217},
numpages = {17},
keywords = {Software metrics, ROC analysis, Imbalanced data, Feature selection, Fault-proneness models}
}

@article{10.1016/j.ins.2018.05.035,
author = {Siers, Michael J. and Islam, Md Zahidul},
title = {Novel algorithms for cost-sensitive classification and knowledge discovery in class imbalanced datasets with an application to NASA software defects},
year = {2018},
issue_date = {Aug 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {459},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2018.05.035},
doi = {10.1016/j.ins.2018.05.035},
journal = {Inf. Sci.},
month = aug,
pages = {53–70},
numpages = {18},
keywords = {Knowledge discovery, Decision forest, Cost-sensitive, Class imbalance, Software defect prediction}
}

@article{10.1016/j.eswa.2010.08.022,
author = {Catal, Cagatay and Sevim, Ugur and Diri, Banu},
title = {Practical development of an Eclipse-based software fault prediction tool using Naive Bayes algorithm},
year = {2011},
issue_date = {March, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {3},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.08.022},
doi = {10.1016/j.eswa.2010.08.022},
abstract = {Despite the amount of effort software engineers have been putting into developing fault prediction models, software fault prediction still poses great challenges. This research using machine learning and statistical techniques has been ongoing for 15years, and yet we still have not had a breakthrough. Unfortunately, none of these prediction models have achieved widespread applicability in the software industry due to a lack of software tools to automate this prediction process. Historical project data, including software faults and a robust software fault prediction tool, can enable quality managers to focus on fault-prone modules. Thus, they can improve the testing process. We developed an Eclipse-based software fault prediction tool for Java programs to simplify the fault prediction process. We also integrated a machine learning algorithm called Naive Bayes into the plug-in because of its proven high-performance for this problem. This article presents a practical view to software fault prediction problem, and it shows how we managed to combine software metrics with software fault data to apply Naive Bayes technique inside an open source platform.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {2347–2353},
numpages = {7},
keywords = {Software fault prediction, Naive Bayes, Machine learning, Eclipse technology}
}

@article{10.1016/j.engappai.2013.01.008,
author = {Rafael Lenz, Alexandre and Pozo, Aurora and Regina Vergilio, Silvia},
title = {Linking software testing results with a machine learning approach},
year = {2013},
issue_date = {May, 2013},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {26},
number = {5–6},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2013.01.008},
doi = {10.1016/j.engappai.2013.01.008},
abstract = {Software testing techniques and criteria are considered complementary since they can reveal different kinds of faults and test distinct aspects of the program. The functional criteria, such as Category Partition, are difficult to be automated and are usually manually applied. Structural and fault-based criteria generally provide measures to evaluate test sets. The existing supporting tools produce a lot of information including: input and produced output, structural coverage, mutation score, faults revealed, etc. However, such information is not linked to functional aspects of the software. In this work, we present an approach based on machine learning techniques to link test results from the application of different testing techniques. The approach groups test data into similar functional clusters. After this, according to the tester's goals, it generates classifiers (rules) that have different uses, including selection and prioritization of test cases. The paper also presents results from experimental evaluations and illustrates such uses.},
journal = {Eng. Appl. Artif. Intell.},
month = may,
pages = {1631–1640},
numpages = {10},
keywords = {Test coverage criteria, Software testing, Machine learning}
}

@inproceedings{10.1145/3178212.3178221,
author = {Rizwan, Syed and Tiantian, Wang and Xiaohong, Su and Salahuddin},
title = {Empirical Study on Software Bug Prediction},
year = {2017},
isbn = {9781450354882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3178212.3178221},
doi = {10.1145/3178212.3178221},
abstract = {Software defect prediction is a vital research direction in software engineering field. Software defect prediction predicts whether software errors are present in the software by using machine learning analysis on software metrics. It can help software developers to improve the quality of the software. Software defect prediction is usually a binary classification problem, which relies on software metrics and the use of classifiers. There have been many research efforts to improve accuracy in software defect prediction using a variety of classifiers and data preprocessing techniques. However, the "classic classifier validity" and "data preprocessing techniques can enhance the functionality of software defect prediction" has not yet been answered explicitly. Therefore, it is necessary to conduct an empirical analysis to compare these studies. In software defect prediction, the category of interest is a defective module, and the number of defective modules is much less than that of a non-defective module in data. This leads to a category of imbalance problem that reduces the accuracy of the prediction. Therefore, the problem of imbalance is a key problem that needs to be solved in software defect prediction. In this paper, we proposed an experimental model and used the NASA MDP data set to analyze the software defect prediction. Five research questions were defined and analyzed experimentally. In addition to experimental analysis, this paper focuses on the improvement of SMOTE. SMOTE ASMO algorithm has been proposed to overcome the shortcomings of SMOTE.},
booktitle = {Proceedings of the 2017 International Conference on Software and E-Business},
pages = {55–59},
numpages = {5},
keywords = {SMOTE, Defect prediction, Data preprocessing, Classification},
location = {Hong Kong, Hong Kong},
series = {ICSEB '17}
}

@article{10.1145/1943371.1943381,
author = {Bishnu, P. S. and Bhattacherjee, V.},
title = {Application of K-Medoids with Kd-Tree for Software Fault Prediction},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/1943371.1943381},
doi = {10.1145/1943371.1943381},
abstract = {Software fault prediction area is subject to problems like non availability of fault data which makes the application of supervised techniques difficult. In such cases unsupervised approaches like clustering are helpful. In this paper, K-Medoids clustering approach has been applied for software fault prediction. To overcome the inherent computational complexity of KMedoids algorithm a data structure called Kd-Tree has been used to identify data agents in the datasets. Partitioning Around Medoids is applied on these data agents and this results in a set of medoids. All the remaining data points are assigned to the nearest medoids thus obtained to get the final clusters. Software fault prediction error analysis results show that our approach outperforms all unsupervised approaches in the case of one given real dataset and gives best values for the evaluation parameters. For other real datasets, our results are comparable to other techniques. Performance evaluation of our technique with other techniques has been done. Results show that our technique reduces the total number of distance calculations drastically since the number of data agents is much less than the number of data points.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–6},
numpages = {6},
keywords = {Software fault prediction, Kd-Tree, K-Medoids}
}

@article{10.1007/s10489-009-0193-8,
author = {Hewett, Rattikorn},
title = {Mining software defect data to support software testing management},
year = {2011},
issue_date = {April     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {34},
number = {2},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-009-0193-8},
doi = {10.1007/s10489-009-0193-8},
abstract = {Achieving high quality software would be easier if effective software development practices were known and deployed in appropriate contexts. Because our theoretical knowledge of the underlying principles of software development is far from complete, empirical analysis of past experience in software projects is essential for acquiring useful software practices. As advances in software technology continue to facilitate automated tracking and data collection, more software data become available. Our research aims to develop methods to exploit such data for improving software development practices.This paper proposes an empirical approach, based on the analysis of defect data, that provides support for software testing management in two ways: (1) construction of a predictive model for defect repair times, and (2) a method for assessing testing quality across multiple releases. The approach employs data mining techniques including statistical methods and machine learning. To illustrate the proposed approach, we present a case study using the defect reports created during the development of three releases of a large medical software system, produced by a large well-established software company. We validate our proposed testing quality assessment using a statistical test at a significance level of 0.1. Despite the limitations of the available data, our predictive models give accuracies as high as 93%.},
journal = {Applied Intelligence},
month = apr,
pages = {245–257},
numpages = {13},
keywords = {Software testing management, Quality assurance, Defect report, Data mining}
}

@inproceedings{10.1145/3172871.3172880,
author = {Singh, Maninder and Anu, Vaibhav and Walia, Gursimran S. and Goswami, Anurag},
title = {Validating Requirements Reviews by Introducing Fault-Type Level Granularity: A Machine Learning Approach},
year = {2018},
isbn = {9781450363983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3172871.3172880},
doi = {10.1145/3172871.3172880},
abstract = {Inspections are a proven approach for improving software requirements quality. Owing to the fact that inspectors report both faults and non-faults (i.e., false-positives) in their inspection reports, a major chunk of work falls on the person who is responsible for consolidating the reports received from multiple inspectors. We aim at automation of fault-consolidation step by using supervised machine learning algorithms that can effectively isolate faults from non-faults. Three different inspection studies were conducted in controlled environments to obtain real inspection data from inspectors belonging to both industry and from academic backgrounds. Next, we devised a methodology to separate faults from non-faults by first using ten individual classifiers from five different classification families to categorize different fault-types (e.g., omission, incorrectness, and inconsistencies). Based on the individual performance of classifiers for each fault-type, we created targeted ensembles that are suitable for identification of each fault-type. Our analysis showed that our selected ensemble classifiers were able to separate faults from non-faults with very high accuracy (as high as 85-89% for some fault-types), with a notable result being that in some cases, individual classifiers performed better than ensembles. In general, our approach can significantly reduce effort required to isolate faults from false-positives during the fault consolidation step of requirements inspections. Our approach also discusses the percentage possibility of correctly classifying each fault-type.},
booktitle = {Proceedings of the 11th Innovations in Software Engineering Conference},
articleno = {10},
numpages = {11},
keywords = {Supervised learning, Machine learning, Inspection reviews, Fault types, Ensemble},
location = {Hyderabad, India},
series = {ISEC '18}
}

@phdthesis{10.5555/AAI29173689,
author = {\"{O}zt\"{u}rk, Muhammed Maruf and Tuncay, Yi̇\u{g}i̇t, and brahim, \c{C}undefinedl, and Ahmet, \"{O}zmen, and Arif, Koyun,},
advisor = {Ahmet, Zengin,},
title = {Tekrar Eden Veri Analizini Kullanarak yaz\i{}l\i{}m geli\c{s}tirme i\c{c}in iyile\c{s}tirilmi\c{s} Hata Tahmini / A New Improved Defect Prediction Framework for Software Development Using Repeated Data Analysis},
year = {2016},
isbn = {9798837582400},
publisher = {Sakarya Universitesi (Turkey)},
abstract = {Yaz\i{}l\i{}m hata tahmini, yo\u{g}un \c{c}aba gerektiren ve yaz\i{}l\i{}m geli\c{s}tirme maliyetlerini azaltmaya odaklanm\i{}\c{s} metotlar\i{}n geli\c{s}tirildi\u{g}i i\c{s}lemleri i\c{c}erir. Veri analizleri i\c{c}in istatistiksel ve makine \"{o}\u{g}renmesi metotlar\i{}n\i{}n s\i{}kl\i{}kla kullan\i{}ld\i{}\u{g}\i{} bu i\c{s}lemler hata veri setlerindeki bozukluk veya eksikliklerden kaynaklanan yanl\i{}\c{s} sonu\c{c}lar\i{} \"{u}retebilmektedir. Bunlara ek olarak s\i{}n\i{}f dengesizli\u{g}i (class imbalance) olarak adland\i{}r\i{}lan hatal\i{} verilerin sistemin belirli b\"{o}lgelerinde yo\u{g}unla\c{s}mas\i{}ndan kaynaklanan sorunlar da ortaya \c{c}\i{}kmaktad\i{}r. Tahmin edici modellerin do\u{g}ruluklar\i{}n\i{} artt\i{}rabilmek i\c{c}in hata veri setlerinin bir \"{o}n i\c{s}lemeden ge\c{c}mesi gereklidir. Ancak bu \c{s}ekilde g\"{u}venilir veriler \"{u}zerinde \c{c}al\i{}\c{s}\i{}labilir. SMOTE, rastgele \"{o}rnekleme gibi y\"{o}ntemlerle hata veri setleri \"{u}zerinde i\c{s}lem yap\i{}lmaktad\i{}r. Bununla beraber hata veri setlerine y\"{o}nelik \"{o}zel bir \"{o}rnekleme tekni\u{g}i bulunmamaktad\i{}r.Tezin amac\i{} b\"{u}y\"{u}k veri setlerinde h\i{}zl\i{} \c{c}al\i{}\c{s}abilen ve tekrar eden verileri y\"{u}ksek do\u{g}rulukla tespit edebilen bir \"{o}n-i\c{s}leme algoritmas\i{} geli\c{s}tirmektir. Algoritma, metrik t\"{u}retimi ile ilgili i\c{s}lemleri kapsar. Bir di\u{g}er ama\c{c} ise algoritman\i{}n makine \"{o}\u{g}renmesi alan\i{}nda kullan\i{}labilecek hata veri setlerine y\"{o}nelik \"{o}zel bir y\"{o}ntem geli\c{s}tirmektir. Deney sonu\c{c}lar\i{}nda g\"{o}zlenen kesinlik de\u{g}erleri literart\"{u}deki di\u{g}er \"{o}n-i\c{s}leme y\"{o}ntemlerinden \"{u}st\"{u}n oldu\u{g}u takdirde makine \"{o}\u{g}renmesi ikili s\i{}n\i{}fland\i{}rma veri setlerinde de kullan\i{}labilir. Hata kesinli\u{g}i y\"{o}ntemle birlikte artt\i{}\u{g}\i{} i\c{c}in yaz\i{}l\i{}m geli\c{s}tirme maliyetlerinin azalt\i{}lmas\i{}na katk\i{} sa\u{g}lamaktad\i{}r. Veri madencili\u{g}i verilerinin temizlenmesi i\c{c}in geli\c{s}tirilecek y\"{o}ntemlere algoritman\i{}n y\"{o}n vermesi beklenmektedir. Y\"{o}ntem, ANOVA, t-test, ki-kare gibi istatistik tabanl\i{} metotlar kullanarak ikili s\i{}n\i{}fland\i{}rma verilerinde tekrar eden verilerin ortadan kald\i{}r\i{}lmas\i{}n\i{} sa\u{g}layan bir veri temizleme algoritmas\i{}n\i{} kapsar. Buna ek olarak d\"{u}\c{s}\"{u}k seviyeli metrik t\"{u}retiminin \"{o}\u{g}renme algoritmalar\i{}n\i{}n ba\c{s}ar\i{}s\i{}na etkisi g\"{o}zlemlenmi\c{s}tir.Kullan\i{}lan makine \"{o}\u{g}renmesi y\"{o}ntemleri ve istatistiksel i\c{s}lemler ile \"{o}nerilen \"{o}n-i\c{s}leme algoritmas\i{}n\i{} da i\c{c}eren bir yaz\i{}l\i{}m \c{c}er\c{c}evesi C# programlama dili kullan\i{}larak geli\c{s}tirilmi\c{s}tir. Bu \c{c}er\c{c}eve \c{c}e\c{s}itli formattaki hata veri setleri \"{u}zerinde ikili s\i{}n\i{}fland\i{}rma performans analizlerini ve temel istatistiksel i\c{s}lemleri de yapabilmektedir. \"{O}nerilen y\"{o}ntem 15 end\"{u}striyel ve 5 a\c{c}\i{}k kaynak olmak \"{u}zere toplamda 20 adet yaz\i{}l\i{}m proje veri seti \"{u}zerinde denenmi\c{s} e\u{g}rinin alt\i{}nda kalan alan (auc) ve kesinlik (precision) performans parametrelerinde algoritman\i{}n etkisi d\"{o}rt farkl\i{} s\i{}n\i{}land\i{}r\i{}c\i{} kullan\i{}larak \"{o}l\c{c}\"{u}lm\"{u}\c{s}t\"{u}r. Geli\c{s}tirilen algoritma hata veri setlerinde tekrar eden veri setlerinin elenmesine y\"{o}nelik geli\c{s}tirilen ilk algoritmad\i{}r. Anahtar kelimeler: Hata tahmini, yaz\i{}l\i{}m metrikleri, yaz\i{}l\i{}m kalitesi, makine \"{o}\u{g}renmesi.},
note = {AAI29173689}
}

@article{10.1016/j.asoc.2015.07.006,
author = {Jin, Cong and Jin, Shu-Wei},
title = {Prediction approach of software fault-proneness based on hybrid artificial neural network and quantum particle swarm optimization},
year = {2015},
issue_date = {October 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {35},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.07.006},
doi = {10.1016/j.asoc.2015.07.006},
abstract = {We present a hybrid method using ANN and QPSO for software fault-prone prediction.ANN is used for the classification of software modules.QPSO is controlled more easily than PSO. The identification of a module's fault-proneness is very important for minimizing cost and improving the effectiveness of the software development process. How to obtain the correlation between software metrics and module's fault-proneness has been the focus of much research. This paper presents the application of hybrid artificial neural network (ANN) and Quantum Particle Swarm Optimization (QPSO) in software fault-proneness prediction. ANN is used for classifying software modules into fault-proneness or non fault-proneness categories, and QPSO is applied for reducing dimensionality. The experiment results show that the proposed prediction approach can establish the correlation between software metrics and modules' fault-proneness, and is very simple because its implementation requires neither extra cost nor expert's knowledge. Proposed prediction approach can provide the potential software modules with fault-proneness to software developers, so developers only need to focus on these software modules, which may minimize effort and cost of software maintenance.},
journal = {Appl. Soft Comput.},
month = oct,
pages = {717–725},
numpages = {9},
keywords = {Software metrics, QPSO, Fault-prone prediction, ANN}
}

@inproceedings{10.5555/1566864.1566872,
author = {Hietaniemi, Manu and Elsil\"{a}, Ulla and Laurinen, Perttu and R\"{o}ning, Juha},
title = {Defect Prediction in Hot Strip Rolling Using ANN and SVM},
year = {2008},
isbn = {9781586038670},
publisher = {IOS Press},
address = {NLD},
abstract = {One of the largest factors affecting the loss for steel manufacturing are defects in the steel strips produced. Therefore the prediction of these defects forehand would be very important. In this study we used classifiers --feedforward neural networks and a support vector machine --to solve this problem. We also used different kinds of feature selection methods such as a preprocessing step for the classifiers. As a result, these two classifiers confirmed the same grade of classification error in this study.},
booktitle = {Proceedings of the 2008 Conference on Tenth Scandinavian Conference on Artificial Intelligence: SCAI 2008},
pages = {44–51},
numpages = {8},
keywords = {Support Vector Machine, Neural Networks, Hot Steel Rolling, Feature Selection, Classification}
}

@inproceedings{10.1109/APSEC.2012.14,
author = {Zhou, Hongbo and Jin, Dahai and Gong, Yunzhan},
title = {An Interval-Based Model for Detecting Software Defect Using Alias Analysis},
year = {2012},
isbn = {9780769549224},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2012.14},
doi = {10.1109/APSEC.2012.14},
abstract = {Alias analysis is a branch of static program analysis aiming at computing variables which are alias of each other. It is a basis research for many analyses and optimizations in software engineering and compiler construction. Precise modeling of alias analysis is fundamental for software analysis. This paper presents two practical approximation models for representing and computing alias: memory-sensitive model (MSM) and value-sensitive model (VSM). Based on defect-oriented detecting, we present a method to detect software defect using VSM and MSM, which realizes inter-procedure detecting by procedure summary. According to whether type of analysis object coming from defect is value-sensitive or memory-sensitive, we propose two detecting algorithms based on two alias models respectively. One is for memory leak (ML) based on MSM, and the other is for invalid arithmetic operation (IAO) based on VSM. We apply a defect testing system (DTS) to detect six C++ open source projects for proving our models effectiveness. Experimental results show that applying our technique to detect IAO and ML defect can improve detecting efficiency, at the same time reduce potential false positives and false negatives.},
booktitle = {Proceedings of the 2012 19th Asia-Pacific Software Engineering Conference - Volume 02},
pages = {136–144},
numpages = {9},
keywords = {static analysis, procedure summary, interval computation, defect detection, alias analysis},
series = {APSEC '12}
}

@article{10.1016/j.infsof.2013.07.004,
author = {Yu, Zhongxing and Bai, Chenggang and Cai, Kai-Yuan},
title = {Mutation-oriented test data augmentation for GUI software fault localization},
year = {2013},
issue_date = {December, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {12},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.07.004},
doi = {10.1016/j.infsof.2013.07.004},
abstract = {Context: Fault localization lies at the heart of program debugging and often proceeds by contrasting the statistics of program constructs executed by passing and failing test cases. A vital issue here is how to obtain these ''suitable'' test cases. Techniques presented in the literature mostly assume the existence of a large test suite a priori. However, developers often encounter situations where a failure occurs, but where no or no appropriate test suite is available for use to localize the fault. Objective: This paper aims to alleviate this key limitation of traditional fault localization techniques for GUI software particularly, namely, it aims at enabling cost-effective fault localization process for GUI software in the described scenario. Method: To address this scenario, we propose a mutation-oriented test data augmentation technique, which actually is directed by the ''similarity'' criterion in GUI software's test case context towards the generation of test suite with excellent fault localization capabilities. More specifically, the technique mainly uses four proposed novel mutation operators to iteratively mutate some failing GUI test cases' event sequences to derive new test cases potentially useful to localize the specific encountered fault. We then compare the fault localization performance of the test suite generated using this technique with that of an original provided large event-pair adequate test suite on some GUI applications. Results: The results indicate that the proposed technique is capable of generating a test suite that has comparable, if not better, fault localization effectiveness to the event-pair adequate test suite, but it is much smaller and it is generated immediately once a failure is encountered by developers. Conclusion: It is concluded that the proposed technique can truly enable quick-start cost-effective fault localization process under the investigated all-too-common scenario, greatly alleviating one key limitation of traditional fault localization techniques and prompting the test-diagnose-repair cycle.},
journal = {Inf. Softw. Technol.},
month = dec,
pages = {2076–2098},
numpages = {23},
keywords = {Test data augmentation, Mutation operator, GUI software, Fault localization}
}

@article{10.1109/MS.2005.149,
author = {Koru, A. Gunes and Liu, Hongfang},
title = {Building Defect Prediction Models in Practice},
year = {2005},
issue_date = {November 2005},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {22},
number = {6},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2005.149},
doi = {10.1109/MS.2005.149},
abstract = {Predicting defect-prone modules successfully can help software developers improve product quality by focusing quality assurance activities on those modules. We built several machine-learning models to predict the defective modules in five software products developed by NASA, named, CM1, JM1, KC1, KC2, and PC1. Using a set of static measures as predictor variables, the models failed to predict performance satisfactorily on the products' original data sets. However, these data sets used the smallest unit of functionality--that is, a function or method as a module. This meant the defect prediction was performed at a fine granularity level. Stratifying the original data sets according to module size showed the prediction performance to be better in subsets that included larger modules. Aggregating the method-level KC1 data to class level improved prediction performance for the top defect classes. Guidelines based on these results help software developers build effective defect-prediction models for focused quality assurance activities.This article is part of a special issue on predictor modeling.},
journal = {IEEE Softw.},
month = nov,
pages = {23–29},
numpages = {7},
keywords = {software quality, software metrics}
}

@inproceedings{10.1145/1294948.1294953,
author = {Bernstein, Abraham and Ekanayake, Jayalath and Pinzger, Martin},
title = {Improving defect prediction using temporal features and non linear models},
year = {2007},
isbn = {9781595937223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1294948.1294953},
doi = {10.1145/1294948.1294953},
abstract = {Predicting the defects in the next release of a large software system is a very valuable asset for the project manger to plan her resources. In this paper we argue that temporal features (or aspects) of the data are central to prediction performance. We also argue that the use of non-linear models, as opposed to traditional regression, is necessary to uncover some of the hidden interrelationships between the features and the defects and maintain the accuracy of the prediction in some cases.Using data obtained from the CVS and Bugzilla repositories of the Eclipse project, we extract a number of temporal features, such as the number of revisions and number of reported issues within the last three months. We then use these data to predict both the location of defects (i.e., the classes in which defects will occur) as well as the number of reported bugs in the next month of the project. To that end we use standard tree-based induction algorithms in comparison with the traditional regression.Our non-linear models uncover the hidden relationships between features and defects, and present them in easy to understand form. Results also show that using the temporal features our prediction model can predict whether a source file will have a defect with an accuracy of 99% (area under ROC curve 0.9251) and the number of defects with a mean absolute error of 0.019 (Spearman's correlation of 0.96).},
booktitle = {Ninth International Workshop on Principles of Software Evolution: In Conjunction with the 6th ESEC/FSE Joint Meeting},
pages = {11–18},
numpages = {8},
keywords = {mining software repository, defect prediction, decision tree learner},
location = {Dubrovnik, Croatia},
series = {IWPSE '07}
}

@article{10.5555/1481923.1481924,
author = {Shatnawi, Omar and Kapur, P. K.},
title = {A generalized software fault classification model},
year = {2008},
issue_date = {September 2008},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
volume = {7},
number = {9},
issn = {1109-2750},
abstract = {Most non-homogenous Poisson process (NHPP) based software reliability growth models (SRGMs) presented in the literature assume that the faults in the software are of the same type. However, this assumption is not truly representative of reality. It has been observed that the software contains different types of faults and each fault requires different strategies and different amount of testing-effort to remove it. If this assumption is not taken into account, the SRGM may give misleading results. This paper proposes a generalized model based on classification the faults in the software system according to their removal complexity. The removal complexity is proportional to the amount of testing-effort required to remove the fault. The testing-effort expenditures are represented by the number of stages required to remove the fault after the failure observation / fault isolation (with time delay between the stages). Therefore, it explicitly takes into account the faults of different severity and can capture variability in the growth curves depending on the environment it is being used and at the same time it has the capability to reduce either to exponential or S-shaped growth curves. Such modelling approach is very much suited for object-oriented programming and distributed development environments. Actual software reliability data have been used to demonstrate the proposed generalized model.},
journal = {W. Trans. on Comp.},
month = sep,
pages = {1375–1384},
numpages = {10},
keywords = {software testing, software reliability, software engineering, fault severity, SRGM, NHPP}
}

@article{10.1016/j.cie.2021.107580,
author = {Ma, Qiuping and Li, Hongyan and Thorstenson, Anders},
title = {A big data-driven root cause analysis system: Application of Machine Learning in quality problem solving},
year = {2021},
issue_date = {Oct 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {160},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2021.107580},
doi = {10.1016/j.cie.2021.107580},
journal = {Comput. Ind. Eng.},
month = oct,
numpages = {16},
keywords = {Neural Network, Multi-class classification, Machine Learning, Data mining, Quality management}
}

@inproceedings{10.1007/978-3-642-15880-3_33,
author = {Eichinger, Frank and Krogmann, Klaus and Klug, Roland and B\"{o}hm, Klemens},
title = {Software-defect localisation by mining dataflow-enabled call graphs},
year = {2010},
isbn = {364215879X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-15880-3_33},
doi = {10.1007/978-3-642-15880-3_33},
abstract = {Defect localisation is essential in software engineering and is an important task in domain-specific data mining. Existing techniques building on call-graph mining can localise different kinds of defects. However, these techniques focus on defects that affect the controlflow and are agnostic regarding the dataflow. In this paper, we introduce dataflow-enabled call graphs that incorporate abstractions of the dataflow. Building on these graphs, we present an approach for defect localisation. The creation of the graphs and the defect localisation are essentially data mining problems, making use of discretisation, frequent subgraph mining and feature selection. We demonstrate the defect-localisation qualities of our approach with a study on defects introduced into Weka. As a result, defect localisation now works much better, and a developer has to investigate on average only 1.5 out of 30 methods to fix a defect.},
booktitle = {Proceedings of the 2010th European Conference on Machine Learning and Knowledge Discovery in Databases - Volume Part I},
pages = {425–441},
numpages = {17},
location = {Barcelona, Spain},
series = {ECMLPKDD'10}
}

@inproceedings{10.1145/3368089.3417062,
author = {Suh, Alexander},
title = {Adapting bug prediction models to predict reverted commits at Wayfair},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3417062},
doi = {10.1145/3368089.3417062},
abstract = {Researchers have proposed many algorithms to predict software bugs. Given a software entity (e.g., a file or method), these algorithms predict whether the entity is bug-prone. However, since these algorithms cannot identify specific bugs, this does not tend to be particularly useful in practice. In this work, we adapt this prior work to the related problem of predicting whether a commit is likely to be reverted. Given the batch nature of continuous integration deployment at scale, this allows developers to find time-sensitive bugs in production more quickly. The models in this paper are based on features extracted from the revision history of a codebase that are typically used in bug prediction. Our experiments, performed on the three main repositories for the Wayfair website, show that our models can rank reverted commits above 80% of non-reverted commits on average. Moreover, when given to Wayfair developers, our models reduce the amount of time needed to find certain kinds of bugs by 55%. Wayfair continues to use our findings and models today to help find bugs during software deployments.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1251–1262},
numpages = {12},
keywords = {software deployment, software defect prediction, reverted commits},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1007/s00521-021-06158-5,
author = {Nevendra, Meetesh and Singh, Pradeep},
title = {Defect count prediction via metric-based convolutional neural network},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {22},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-06158-5},
doi = {10.1007/s00521-021-06158-5},
abstract = {With the increasing complexity and volume of the software, the number of defects in software modules is also increasing consistently, which affects the quality and delivery of software in time and budget. To improve the software quality and timely allocation of resources, defects should be detected at the initial phases of the software development life cycle. However, the existing defect prediction methodology based on high-dimensional and limited data only focuses on predicting defective modules. In contrast, the number of defects present in the software module has not been explored so far, especially using deep neural network. Also, whether deep learning could enhance the performance of defect count prediction is still uninvestigated. To fill this gap, we proposed an improved Convolutional Neural Network model, called metrics-based convolutional neural network (MB-CNN), which combines the advantages of appropriate metrics and an improved CNN method by introducing dropout for regularization between convolutions and dense layer. The proposed method predicts the presented defect count in the software module for homogeneous scenarios as within-version and cross-version. The experimental results show that, on average, across the fourteen real-world defect datasets, the proposed approach improves Li’s CNN architecture by 31% in within-version prediction and 28% in cross-version prediction. Moreover, the Friedman ranking test and Wilcoxon nonparametric test reveal the usefulness of our proposed approach over ten benchmark learning algorithms to predict defect count.},
journal = {Neural Comput. Appl.},
month = nov,
pages = {15319–15344},
numpages = {26},
keywords = {Cross-project, CNN, Deep learning, Software defect count prediction}
}

@inproceedings{10.1145/2568225.2568307,
author = {Lee, Sangho and Jung, Changhee and Pande, Santosh},
title = {Detecting memory leaks through introspective dynamic behavior modelling using machine learning},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568307},
doi = {10.1145/2568225.2568307},
abstract = {This paper expands staleness-based memory leak detection by presenting a machine learning-based framework. The proposed framework is based on an idea that object staleness can be better leveraged in regard to similarity of objects; i.e., an object is more likely to have leaked if it shows significantly high staleness not observed from other similar objects with the same allocation context.  A central part of the proposed framework is the modeling of heap objects. To this end, the framework observes the staleness of objects during a representative run of an application. From the observed data, the framework generates training examples, which also contain instances of hypothetical leaks. Via machine learning, the proposed framework replaces the error-prone user-definable staleness predicates used in previous research with a model-based prediction.  The framework was tested using both synthetic and real-world examples. Evaluation with synthetic leakage workloads of SPEC2006 benchmarks shows that the proposed method achieves the optimal accuracy permitted by staleness-based leak detection. Moreover, by incorporating allocation context into the model, the proposed method achieves higher accuracy than is possible with object staleness alone. Evaluation with real-world memory leaks demonstrates that the proposed method is effective for detecting previously reported bugs with high accuracy.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {814–824},
numpages = {11},
keywords = {Runtime analysis, Memory leak detection, Machine learning},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{10.1145/3387904.3389295,
author = {Lenarduzzi, Valentina and Palomba, Fabio and Taibi, Davide and Tamburri, Damian Andrew},
title = {OpenSZZ: A Free, Open-Source, Web-Accessible Implementation of the SZZ Algorithm},
year = {2020},
isbn = {9781450379588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387904.3389295},
doi = {10.1145/3387904.3389295},
abstract = {The accurate identification of defect-inducing commits represents a key problem for researchers interested in studying the naturalness of defects and defining defect prediction models. To tackle this problem, software engineering researchers have relied on and proposed several implementations of the well-known Sliwerski-Zimmermann-Zeller (SZZ) algorithm. Despite its popularity and wide usage, no open-source, publicly available, and web-accessible implementation of the algorithm has been proposed so far. In this paper, we prototype and make available one such implementation for further use by practitioners and researchers alike. The evaluation of the proposed prototype showed competitive results and lays the foundation for future work. This paper outlines our prototype, illustrating its usage and reporting on its evaluation in action.},
booktitle = {Proceedings of the 28th International Conference on Program Comprehension},
pages = {446–450},
numpages = {5},
keywords = {Web APIs, Software Defect Proneness, Software Defect Prediction, Open-Source Tools},
location = {Seoul, Republic of Korea},
series = {ICPC '20}
}

@inproceedings{10.1109/ISSRE.2009.13,
author = {Jiang, Yue and Lin, Jie and Cukic, Bojan and Menzies, Tim},
title = {Variance Analysis in Software Fault Prediction Models},
year = {2009},
isbn = {9780769538785},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2009.13},
doi = {10.1109/ISSRE.2009.13},
abstract = {Software fault prediction models play an important role in softwarequality assurance. They identify software subsystems (modules,components, classes, or files) which are likely to contain faults.These subsystems, in turn, receive additional resources forverification and validation activities.Fault prediction models arebinary classifiers typically developed using one of the supervisedlearning techniques from either a subset of the fault data from thecurrent project or from a similar past project.In practice, itis critical that such models provide a reliable predictionperformance on the data not used in training.Variance is animportant reliability indicator of software fault prediction models.However, variance is often ignored or barely mentioned in manypublished studies. In this paper, through the analysis of twelvedata sets from a public software engineering repository from theperspective of variance, we explore the following five questionsregarding fault prediction models:(1) Do different types ofclassification performance measures exhibit different variance? (2)Does the size of the data set imply a more (or less) accurateprediction performance? (3) Does the size of training subset impactmodel's stability? (4) Do different classifiers consistently exhibitdifferent performance in terms of model's variance? (5) Are theredifferences between variance from 1000 runs and 10 runs of 10-fold crossvalidation experiments?Our results indicate that variance is avery important factor in understanding fault prediction models andwe recommend the best practice for reporting variance in empiricalsoftware engineering studies.},
booktitle = {Proceedings of the 2009 20th International Symposium on Software Reliability Engineering},
pages = {99–108},
numpages = {10},
keywords = {variance, machine learning, fault prediction models},
series = {ISSRE '09}
}

@inproceedings{10.5555/1513605.1513774,
author = {Shatnawi, Omar},
title = {A generalized software fault classification model},
year = {2008},
isbn = {9789606766855},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {Most non-homogenous Poisson process (NHPP) based software reliability growth models (SRGMs) presented in the literature assume that the faults in the software are of the same type. This assumption implies that the fault removal rate per remaining faults is independent of the testing time. However, this assumption is not truly representative of reality. It has been observed that the software contains different types of faults and each fault requires different strategies and different amount of testing-effort to remove it. This paper proposes a generalized model based on classification the faults in the software system according to their removal complexity. The removal complexity is proportional to the amount of testing-effort required to remove the fault. The testing-effort expenditures are represented by the number of stages required to remove the fault after the failure observation / fault isolation (with time delay between the stages). Therefore, it explicitly takes into account the faults of different severity and can capture variability in the growth curves depending on the environment it is being used and at the same time it has the capability to reduce either to exponential or S-shaped growth curves. Such modelling approach is very much suited for object-oriented programming and distributed development environments. Actual software reliability data have been used to demonstrate the proposed generalized model.},
booktitle = {Proceedings of the 12th WSEAS International Conference on Computers},
pages = {993–998},
numpages = {6},
keywords = {software testing, software engineering, fault severity, SRGM, NHPP},
location = {Heraklion, Greece},
series = {ICCOMP'08}
}

@inproceedings{10.1145/1368088.1368114,
author = {Moser, Raimund and Pedrycz, Witold and Succi, Giancarlo},
title = {A comparative analysis of the efficiency of change metrics and static code attributes for defect prediction},
year = {2008},
isbn = {9781605580791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1368088.1368114},
doi = {10.1145/1368088.1368114},
abstract = {In this paper we present a comparative analysis of the predictive power of two different sets of metrics for defect prediction. We choose one set of product related and one set of process related software metrics and use them for classifying Java files of the Eclipse project as defective respective defect-free. Classification models are built using three common machine learners: logistic regression, Na\"{\i}ve Bayes, and decision trees. To allow different costs for prediction errors we perform cost-sensitive classification, which proves to be very successful: &gt;75% percentage of correctly classified files, a recall of &gt;80%, and a false positive rate &lt;30%. Results indicate that for the Eclipse data, process metrics are more efficient defect predictors than code metrics.},
booktitle = {Proceedings of the 30th International Conference on Software Engineering},
pages = {181–190},
numpages = {10},
keywords = {software metrics, defect prediction, cost-sensitive classification},
location = {Leipzig, Germany},
series = {ICSE '08}
}

@inproceedings{10.1007/978-3-030-79463-7_35,
author = {Kawalerowicz, Marcin and Madeyski, Lech},
title = {Continuous Build Outcome Prediction: A Small-N Experiment in Settings of a Real Software Project},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_35},
doi = {10.1007/978-3-030-79463-7_35},
abstract = {We explain the idea of Continuous Build Outcome Prediction (CBOP) practice that uses classification to label the possible build results (success or failure) based on historical data and metrics (features) derived from the software repository. Additionally, we present a preliminary empirical evaluation of CBOP in a real live software project. In a small-n repeated-measure with two conditions and replicates experiment, we study whether CBOP will reduce the Failed Build Ratio (FBR). Surprisingly, the result of the study indicates a slight increase in FBR while using the CBOP, although the effect size is very small. A plausible explanation of the revealed phenomenon may come from the authority principle, which is rarely discussed in the software engineering context in general, and AI-supported software development practices in particular.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {412–425},
numpages = {14},
keywords = {Machine learning, Continuous integration, Agile experimentation, Software defect prediction},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.5555/2666527.2666533,
author = {Morgado, In\^{e}s Coimbra and Paiva, Ana C. R. and Faria, Jo\~{a}o Pascoal and Camacho, Rui},
title = {GUI reverse engineering with machine learning},
year = {2012},
isbn = {9781467317535},
publisher = {IEEE Press},
abstract = {This paper proposes a new approach to reduce the effort of building formal models representative of the structure and behaviour of Graphical User Interfaces (GUI). The main goal is to automatically extract the GUI model with a dynamic reverse engineering process, consisting in an exploration phase, that extracts information by interacting with the GUI, and in a model generation phase that, making use of machine learning techniques, uses the extracted information of the first step to generate a state-machine model of the GUI, including guard conditions to remove ambiguity in transitions.},
booktitle = {Proceedings of the First International Workshop on Realizing AI Synergies in Software Engineering},
pages = {27–31},
numpages = {5},
keywords = {reverse engineering, model-based testing, machine learning, inductive logic programming},
location = {Zurich, Switzerland},
series = {RAISE '12}
}

@article{10.1504/ijaip.2019.101983,
author = {Kumar, Reddi Kiran and Rao, S.V. Achuta},
title = {Severity of defect: an optimised prediction},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {3–4},
issn = {1755-0386},
url = {https://doi.org/10.1504/ijaip.2019.101983},
doi = {10.1504/ijaip.2019.101983},
abstract = {To assure the quality of software an important activity is performed namely software defect prediction (SDP). Historical databases are used to detect software defects using different machine learning techniques. Conversely, there are disadvantages like testing becomes expensive, poor quality and so the product is unreliable for use. This paper classifies the severity of defects by using a method based on optimised neural network (NN). In full search space, a solution is found by many meta-heuristic optimisations and global search ability has been used. Hence, high-quality solutions are finding within a reasonable period of time. SDP performance is improved by the combination of meta-heuristic optimisation methods. For class imbalance problem, meta-heuristic optimisation methods such as genetic algorithm (GA) and shuffled frog leaping algorithm (SFLA) are applied. The above method is based on SFLA and the experimental outputs show that it can do better than Leven berg Marquardt based NN system (LM-NN).},
journal = {Int. J. Adv. Intell. Paradigms},
month = jan,
pages = {334–345},
numpages = {11},
keywords = {shuffled frog and fuzzy classifier, LM, Levenberg Marquardt, neural network, severity, SDP, software defect prediction}
}

@inproceedings{10.1109/ITNG.2009.12,
author = {Catal, Cagatay and Sevim, Ugur and Diri, Banu},
title = {Clustering and Metrics Thresholds Based Software Fault Prediction of Unlabeled Program Modules},
year = {2009},
isbn = {9780769535968},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ITNG.2009.12},
doi = {10.1109/ITNG.2009.12},
abstract = {Predicting the fault-proneness of program modules when the fault labels for modules are unavailable is a practical problem frequently encountered in the software industry. Because fault data belonging to previous software version is not available, supervised learning approaches can not be applied, leading to the need for new methods, tools, or techniques. In this study, we propose a clustering and metrics thresholds based software fault prediction approach for this challenging problem and explore it on three datasets, collected from a Turkish white-goods manufacturer developing embedded controller software. Experiments reveal that unsupervised software fault prediction can be automated and reasonable results can be produced with techniques based on metrics thresholds and clustering. The results of this study demonstrate the effectiveness of metrics thresholds and show that the standalone application of metrics thresholds (one-stage) is currently easier than the clustering and metrics thresholds based (two-stage) approach because the selection of cluster number is performed heuristically in this clustering based method.},
booktitle = {Proceedings of the 2009 Sixth International Conference on Information Technology: New Generations},
pages = {199–204},
numpages = {6},
keywords = {unsupervised learning, unlabeled program modules, software fault prediction, metrics thresholds, clustering},
series = {ITNG '09}
}

@inproceedings{10.1145/2915970.2915979,
author = {Petri\'{c}, Jean},
title = {Using different characteristics of machine learners to identify different defect families},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2915979},
doi = {10.1145/2915970.2915979},
abstract = {Background: Software defect prediction has been an active area of research for the last few decades. Many models have been developed with aim to find locations in code likely to contain defects. As of yet, these prediction models are of limited use and rarely used in the software industry.Problem: Current modelling techniques are too coarse grained and fail in finding some defects. Most of the prediction models do not look for targeted defect characteristics, but rather treat them as a black box and homogeneous. No study has investigated in greater detail how well certain defect characteristics work with different prediction modelling techniques.Methodology: This PhD will address three major tasks. First, the relation among software defects, prediction models and static code metrics will be analysed. Second, the possibility of a mapping function between prediction models and defect characteristics shall be investigated. Third, an optimised ensemble model that searches for targeted defects will be developed.Contribution: A few contributions will yield from this work. Characteristics of defects will be identified, allowing other researchers to build on this work to produce more efficient prediction models in future. New modelling techniques that better suit state-of-the-art knowledge in defect prediction shall be designed. Such prediction models should be transformed in a tool that can be used by our industrial collaborator in the real industry environment.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {5},
numpages = {4},
keywords = {software defect prediction, prediction modeling, machine learning},
location = {Limerick, Ireland},
series = {EASE '16}
}

@article{10.3233/JIFS-169571,
author = {Kostopoulos, G. and Livieris, I.E. and Kotsiantis, S. and Tampakas, V. and Patnaik, Srikanta},
title = {CST-Voting: A semi-supervised ensemble method for classification problems},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {35},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-169571},
doi = {10.3233/JIFS-169571},
abstract = {Semi-supervised learning is an emerging subfield of machine learning, with a view to building efficient classifiers exploiting a limited pool of labeled data together with a large pool of unlabeled ones. Most of the studies regarding semi-supervised learning deal with classification problems, whose goal is to learn a function that maps an unlabeled instance into a finite number of classes. In this paper, a new semi-supervised classification algorithm, which is based on a voting methodology, is proposed. The term attributed to this ensemble method is called CST-Voting. Ensemble methods have been effectively applied in various scientific fields and often perform better than the individual classifiers from which they are originated. The efficiency of the proposed algorithm is compared to three familiar semi-supervised learning methods on a plethora of benchmark datasets using three representative supervised classifiers as base learners. Experimental results demonstrate the predominance of the proposed method, outperforming classical semi-supervised classification algorithms as illustrated from the accuracy measurements and confirmed by the Friedman Aligned Ranks nonparametric test.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {99–109},
numpages = {11},
keywords = {accuracy, ensemble methods, voting, classification, Semi-supervised learning}
}

@article{10.1145/2020976.2020991,
author = {Malhotra, Ruchika and Jain, Ankita},
title = {Software fault prediction for object oriented systems: a literature review},
year = {2011},
issue_date = {September 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2020976.2020991},
doi = {10.1145/2020976.2020991},
abstract = {There always has been a demand to produce efficient and high quality software. There are various object oriented metrics that measure various properties of the software like coupling, cohesion, inheritance etc. which affect the software to a large extent. These metrics can be used in predicting important quality attributes such as fault proneness, maintainability, effort, productivity and reliability. Early prediction of fault proneness will help us to focus on testing resources and use them only on the classes which are predicted to be fault-prone. Thus, this will help in early phases of software development to give a measurement of quality assessment.This paper provides the review of the previous studies which are related to software metrics and the fault proneness. In other words, it reviews several journals and conference papers on software fault prediction. There is large number of software metrics proposed in the literature. Each study uses a different subset of these metrics and performs the analysis using different datasets. Also, the researchers have used different approaches such as Support vector machines, naive bayes network, random forest, artificial neural network, decision tree, logistic regression etc. Thus, this study focuses on the metrics used, dataset used and the evaluation or analysis method used by various authors. This review will be beneficial for the future studies as various researchers and practitioners can use it for comparative analysis.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–6},
numpages = {6},
keywords = {software quality, object oriented, metrics, fault proneness, empirical validation}
}

@inproceedings{10.5555/1627368.1627435,
author = {Podgorelec, Vili},
title = {On software fault prediction by mining software complexity data with dynamically filtered training sets},
year = {2009},
isbn = {9789604741137},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {Software fault prediction methods are very appropriate for improving the software reliability. With the creation of large empirical databases of software projects, as a result of stimulated research on estimation models, metrics and methods for measuring and improving processes and products, intelligent mining of these datasets can largely add to the improvement of software reliability. In the paper we present a study on using decision tree classifiers for predicting software faults. A new training set filtering method is presented that should improve the classification performance when mining the software complexity measures data. The classification improvement should be achieved by removing the identified outliers from a training set. We argue that a classifier trained by a filtered dataset captures a more general knowledge model and should therefore perform better also on unseen cases. The proposed method is applied on a real-world software reliability analysis dataset and the obtained results are discussed.},
booktitle = {Proceedings of the 9th WSEAS International Conference on Simulation, Modelling and Optimization},
pages = {332–337},
numpages = {6},
keywords = {software fault prediction, search-based software engineering, filtering training set, complexity metrics, classification},
location = {Budapest, Hungary},
series = {SMO'09}
}

@inproceedings{10.5555/2818754.2818851,
author = {Peters, Fayola and Menzies, Tim and Layman, Lucas},
title = {LACE2: better privacy-preserving data sharing for cross project defect prediction},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Before a community can learn general principles, it must share individual experiences. Data sharing is the fundamental step of cross project defect prediction, i.e. the process of using data from one project to predict for defects in another. Prior work on secure data sharing allowed data owners to share their data on a single-party basis for defect prediction via data minimization and obfuscation. However the studied method did not consider that bigger data required the data owner to share more of their data.In this paper, we extend previous work with LACE2 which reduces the amount of data shared by using multi-party data sharing. Here data owners incrementally add data to a cache passed among them and contribute "interesting" data that are not similar to the current content of the cache. Also, before data owner i passes the cache to data owner j, privacy is preserved by applying obfuscation algorithms to hide project details. The experiments of this paper show that (a) LACE2 is comparatively less expensive than the single-party approach and (b) the multi-party approach of LACE2 yields higher privacy than the prior approach without damaging predictive efficacy (indeed, in some cases, LACE2 leads to better defect predictors).},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {801–811},
numpages = {11},
location = {Florence, Italy},
series = {ICSE '15}
}

@article{10.1016/j.infsof.2020.106269,
author = {Mahdieh, Mostafa and Mirian-Hosseinabadi, Seyed-Hassan and Etemadi, Khashayar and Nosrati, Ali and Jalali, Sajad},
title = {Incorporating fault-proneness estimations into coverage-based test case prioritization methods},
year = {2020},
issue_date = {May 2020},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {121},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2020.106269},
doi = {10.1016/j.infsof.2020.106269},
journal = {Inf. Softw. Technol.},
month = may,
numpages = {12},
keywords = {Bug history, Machine learning, Defect prediction, Test case prioritization, Regression testing}
}

@inproceedings{10.1145/1083165.1083172,
author = {Koru, A. G\"{u}nes and Liu, Hongfang},
title = {An investigation of the effect of module size on defect prediction using static measures},
year = {2005},
isbn = {1595931252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1083165.1083172},
doi = {10.1145/1083165.1083172},
abstract = {We used several machine learning algorithms to predict the defective modules in five NASA products, namely, CM1, JM1, KC1, KC2, and PC1. A set of static measures were employed as predictor variables. While doing so, we observed that a large portion of the modules were small, as measured by lines of code (LOC). When we experimented on the data subsets created by partitioning according to module size, we obtained higher prediction performance for the subsets that include larger modules. We also performed defect prediction using class-level data for KC1 rather than the method-level data. In this case, the use of class-level data resulted in improved prediction performance compared to using method-level data. These findings suggest that quality assurance activities can be guided even better if defect prediction is performed by using data that belong to larger modules.},
booktitle = {Proceedings of the 2005 Workshop on Predictor Models in Software Engineering},
pages = {1–5},
numpages = {5},
keywords = {defect prediction, prediction models, software metrics, software quality management, static measures},
location = {St. Louis, Missouri},
series = {PROMISE '05}
}

@article{10.1016/j.advengsoft.2011.03.010,
author = {Alsmadi, Izzat and Najadat, Hassan},
title = {Evaluating the change of software fault behavior with dataset attributes based on categorical correlation},
year = {2011},
issue_date = {August, 2011},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {42},
number = {8},
issn = {0965-9978},
url = {https://doi.org/10.1016/j.advengsoft.2011.03.010},
doi = {10.1016/j.advengsoft.2011.03.010},
abstract = {Utilization of data mining in software engineering has been the subject of several research papers. Majority of subjects of those paper were in making use of historical data for decision making activities such as cost estimation and product or project attributes prediction and estimation. The ability to predict software fault modules and the ability to correlate relations between faulty modules and product attributes using statistics is the subject of this paper. Correlations and relations between the attributes and the categorical variable or the class are studied through generating a pool of records from each dataset and then select two samples every time from the dataset and compare them. The correlation between the two selected records is studied in terms of changing from faulty to non-faulty or the opposite for the module defect attribute and the value change between the two records in each evaluated attribute (e.g. equal, larger or smaller). The goal was to study if there are certain attributes that are consistently affecting changing the state of the module from faulty to none, or the opposite. Results indicated that such technique can be very useful in studying the correlations between each attribute and the defect status attribute. Another prediction algorithm is developed based on statistics of the module and the overall dataset. The algorithm gave each attribute true class and faulty class predictions. We found that dividing prediction capability for each attribute into those two (i.e. correct and faulty module prediction) facilitate understanding the impact of attribute values on the class and hence improve the overall prediction relative to previous studies and data mining algorithms. Results were evaluated and compared with other algorithms and previous studies. ROC metrics were used to evaluate the performance of the developed metrics. Results from those metrics showed that accuracy or prediction performance calculated traditionally using accurately predicted records divided by the total number of records in the dataset does not necessarily give the best indicator of a good metric or algorithm predictability. Those predictions may give wrong implication if other metrics are not considered with them. The ROC metrics were able to show some other important aspects of performance or accuracy.},
journal = {Adv. Eng. Softw.},
month = aug,
pages = {535–546},
numpages = {12},
keywords = {Software quality, Software mining, Prediction algorithms, Fault prone modules, Data mining, Correlation, Clustering}
}

@article{10.1016/j.ins.2008.12.001,
author = {Catal, Cagatay and Diri, Banu},
title = {Investigating the effect of dataset size, metrics sets, and feature selection techniques on software fault prediction problem},
year = {2009},
issue_date = {March, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {179},
number = {8},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2008.12.001},
doi = {10.1016/j.ins.2008.12.001},
abstract = {Software quality engineering comprises of several quality assurance activities such as testing, formal verification, inspection, fault tolerance, and software fault prediction. Until now, many researchers developed and validated several fault prediction models by using machine learning and statistical techniques. There have been used different kinds of software metrics and diverse feature reduction techniques in order to improve the models' performance. However, these studies did not investigate the effect of dataset size, metrics set, and feature selection techniques for software fault prediction. This study is focused on the high-performance fault predictors based on machine learning such as Random Forests and the algorithms based on a new computational intelligence approach called Artificial Immune Systems. We used public NASA datasets from the PROMISE repository to make our predictive models repeatable, refutable, and verifiable. The research questions were based on the effects of dataset size, metrics set, and feature selection techniques. In order to answer these questions, there were defined seven test groups. Additionally, nine classifiers were examined for each of the five public NASA datasets. According to this study, Random Forests provides the best prediction performance for large datasets and Naive Bayes is the best prediction algorithm for small datasets in terms of the Area Under Receiver Operating Characteristics Curve (AUC) evaluation parameter. The parallel implementation of Artificial Immune Recognition Systems (AIRS2Parallel) algorithm is the best Artificial Immune Systems paradigm-based algorithm when the method-level metrics are used.},
journal = {Inf. Sci.},
month = mar,
pages = {1040–1058},
numpages = {19},
keywords = {Software fault prediction, Random Forests, Naive Bayes, Machine learning, J48, Artificial Immune Systems}
}

@inproceedings{10.1109/ICMLA.2014.63,
author = {Coelho, Rodrigo A. and Guimar\~{a}es, Fabr\'{\i}cio dos R. N. and Esmin, Ahmed A. A.},
title = {Applying Swarm Ensemble Clustering Technique for Fault Prediction Using Software Metrics},
year = {2014},
isbn = {9781479974153},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2014.63},
doi = {10.1109/ICMLA.2014.63},
abstract = {Number of defects remaining in a system provides an insight into the quality of the system. Defect detection systems predict defects by using software metrics and data mining techniques. Clustering analysis is adopted to build the software defect prediction models. Cluster ensembles have emerged as a prominent method for improving robustness, stability and accuracy of clustering solutions. The clustering ensembles combine multiple partitions generated by different clustering algorithms into a single clustering solution. In this paper, the clustering ensemble using Particle Swarm Optimization algorithm (PSO) solution is proposed to improve the prediction quality. An empirical study shows that the PSO can be a good choice to build defect prediction software models.},
booktitle = {Proceedings of the 2014 13th International Conference on Machine Learning and Applications},
pages = {356–361},
numpages = {6},
keywords = {Software defect prediction, Particle swarm optimization, Ensemble clustering, Cluster data},
series = {ICMLA '14}
}

@article{10.1016/j.jss.2016.06.006,
author = {Okutan, Ahmet and Taner Yildiz, Olcay},
title = {A novel kernel to predict software defectiveness},
year = {2016},
issue_date = {September 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {119},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.06.006},
doi = {10.1016/j.jss.2016.06.006},
abstract = {We propose new kernels for defect prediction that are based on the source code similarity.We model the relationship between source code similarity and defectiveness.The precomputed kernels are used with SVM and KNN classifiers.The proposed technique performs better than the SVM with linear kernel.It also achieves comparable performance when compared to the KNN classifier. Although the software defect prediction problem has been researched for a long time, the results achieved are not so bright. In this paper, we propose to use novel kernels for defect prediction that are based on the plagiarized source code, software clones and textual similarity. We generate precomputed kernel matrices and compare their performance on different data sets to model the relationship between source code similarity and defectiveness. Each value in a kernel matrix shows how much parallelism exists between the corresponding files of a software system chosen. Our experiments on 10 real world datasets indicate that support vector machines (SVM) with a precomputed kernel matrix performs better than the SVM with the usual linear kernel in terms of F-measure. Similarly, when used with a precomputed kernel, the k-nearest neighbor classifier (KNN) achieves comparable performance with respect to KNN classifier. The results from this preliminary study indicate that source code similarity can be used to predict defect proneness.},
journal = {J. Syst. Softw.},
month = sep,
pages = {109–121},
numpages = {13},
keywords = {SVM, Kernel methods, Defect prediction}
}

@inproceedings{10.1109/ESEM.2011.29,
author = {Li, Lianfa and Leung, Hareton},
title = {Mining Static Code Metrics for a Robust Prediction of Software Defect-Proneness},
year = {2011},
isbn = {9780769546049},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ESEM.2011.29},
doi = {10.1109/ESEM.2011.29},
abstract = {Defect-proneness prediction is affected by multiple aspects including sampling bias, non-metric factors, uncertainty of models etc. These aspects often contribute to prediction uncertainty and result in variance of prediction. This paper proposes two methods of data mining static code metrics to enhance defect-proneness prediction. Given little non-metric or qualitative information extracted from software codes, we first suggest to use a robust unsupervised learning method, shared nearest neighbors (SNN) to extract the similarity patterns of the code metrics. These patterns indicate similar characteristics of the components of the same cluster that may result in introduction of similar defects. Using the similarity patterns with code metrics as predictors, defect-proneness prediction may be improved. The second method uses the Occam's windows and Bayesian model averaging to deal with model uncertainty: first, the datasets are used to train and cross-validate multiple learners and then highly qualified models are selected and integrated into a robust prediction. From a study based on 12 datasets from NASA, we conclude that our proposed solutions can contribute to a better defect-proneness prediction.},
booktitle = {Proceedings of the 2011 International Symposium on Empirical Software Engineering and Measurement},
pages = {207–214},
numpages = {8},
keywords = {uncertainty, software quality, robust prediction, defect-proneness, data mining},
series = {ESEM '11}
}

@inproceedings{10.1109/FLOSS.2009.5071357,
author = {Caglayan, Bora and Bener, Ayse and Koch, Stefan},
title = {Merits of using repository metrics in defect prediction for open source projects},
year = {2009},
isbn = {9781424437207},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/FLOSS.2009.5071357},
doi = {10.1109/FLOSS.2009.5071357},
abstract = {Many corporate code developers are the beta testers of open source software.They continue testing until they are sure that they have a stable version to build their code on. In this respect defect predictors play a critical role to identify defective parts of the software. Performance of a defect predictor is determined by correctly finding defective parts of the software without giving any false alarms. Having high false alarms means testers/ developers would inspect bug free code unnecessarily. Therefore in this research we focused on decreasing the false alarm rates by using repository metrics. We conducted experiments on the data sets of Eclipse project. Our results showed that repository metrics decreased the false alarm rates on the average to 23% from 32% corresponding up to 907 less files to inspect.},
booktitle = {Proceedings of the 2009 ICSE Workshop on Emerging Trends in Free/Libre/Open Source Software Research and Development},
pages = {31–36},
numpages = {6},
series = {FLOSS '09}
}

@article{10.1007/s10489-011-0316-x,
author = {Chatterjee, S. and Nigam, S. and Singh, J. B. and Upadhyaya, L. N.},
title = {Software fault prediction using Nonlinear Autoregressive with eXogenous Inputs (NARX) network},
year = {2012},
issue_date = {July      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {37},
number = {1},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-011-0316-x},
doi = {10.1007/s10489-011-0316-x},
abstract = {This paper explores a new approach for predicting software faults by means of NARX neural network. Also, a careful analysis has been carried out to determine the applicability of NARX network in software reliability. The validation of the proposed approach has been performed using two real software failure data sets. Comparison has been made with some existing parametric software reliability models as well as some neural network (Elman net and TDNN) based SRGM. The results computed shows that the proposed approach outperformed the other existing parametric and neural network based software reliability models with a reasonably good predictive accuracy.},
journal = {Applied Intelligence},
month = jul,
pages = {121–129},
numpages = {9},
keywords = {Time between failures, Software reliability, NARX neural network, Faults}
}

@article{10.1007/s00500-021-06048-x,
author = {Rathore, Santosh S.},
title = {An exploratory analysis of regression methods for predicting faults in software systems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {23},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06048-x},
doi = {10.1007/s00500-021-06048-x},
abstract = {The use of regression methods, for instance, linear regression, decision tree regression, etc., has been used earlier to build software fault prediction (SFP) models. However, these methods showed limited SFP performance with higher misclassification errors. In previous works, issues such as multicollinearity, feature scaling, and imbalance distribution of faulty and non-faulty modules in the dataset have not been considered reasonably, which might be a potential cause behind the poor prediction performance of these regression methods. Motivated from it, in this paper, we investigate the impact of 15 different regression methods for the faults count prediction in the software system and report their interpretation for fault models. We consider different fault data quality issues, and a comprehensive assessment of the regression methods is presented to handle these issues. We believe that many used regression methods have not been explored before for the SFP by considering different data quality issues. In the presented study, 44 fault datasets and their versions are used that are collected from the PROMISE software data repository are used to validate the performance of the regression methods, and absolute relative error (ARE), root mean square error (RSME), and fault-percentile-average (FPA) are used as the performance measures. For the model building, five different scenarios are considered, (1) original dataset without preprocessing; (2) standardized processed dataset; (3) balanced dataset; (4) non-multicollinearity processed dataset; (5) balanced+non-multicollinearity processed dataset. Experimental results showed that overall kernel-based regression methods, KernelRidge and SVR (Support vector regression, both linear and nonlinear kernels), yielded the best performance for predicting the fault counts compared to other methods. Other regression methods, in particular NNR (Nearest neighbor regression), RFR (Random forest regression), and GBR (Gradient boosting regression), are performed significantly accurately. Further, results showed that applying standardization and handling multicollinearity in the fault dataset helped improve regression methods’ performance. It is concluded that regression methods are promising for building software fault prediction models.},
journal = {Soft Comput.},
month = dec,
pages = {14841–14872},
numpages = {32},
keywords = {Empirical study, PROMISE data repository, Regression methods, Software fault prediction}
}

@inproceedings{10.1145/1810295.1810313,
author = {Kl\"{a}s, Michael and Elberzhager, Frank and M\"{u}nch, J\"{u}rgen and Hartjes, Klaus and von Graevemeyer, Olaf},
title = {Transparent combination of expert and measurement data for defect prediction: an industrial case study},
year = {2010},
isbn = {9781605587196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1810295.1810313},
doi = {10.1145/1810295.1810313},
abstract = {Defining strategies on how to perform quality assurance (QA) and how to control such activities is a challenging task for organizations developing or maintaining software and software-intensive systems. Planning and adjusting QA activities could benefit from accurate estimations of the expected defect content of relevant artifacts and the effectiveness of important quality assurance activities. Combining expert opinion with commonly available measurement data in a hybrid way promises to overcome the weaknesses of purely data-driven or purely expert-based estimation methods. This article presents a case study of the hybrid estimation method HyDEEP for estimating defect content and QA effectiveness in the telecommunication domain. The specific focus of this case study is the use of the method for gaining quantitative predictions. This aspect has not been empirically analyzed in previous work. Among other things, the results show that for defect content estimation, the method performs significantly better statistically than purely data-based methods, with a relative error of 0.3 on average (MMRE).},
booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2},
pages = {119–128},
numpages = {10},
keywords = {hybrid estimation, effectiveness, defect content, HyDEEP},
location = {Cape Town, South Africa},
series = {ICSE '10}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00061,
author = {Liu, Changlin and Xiao, Xusheng},
title = {ProMal: precise window transition graphs for Android via synergy of program analysis and machine learning},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00061},
doi = {10.1109/ICSE-Companion52605.2021.00061},
abstract = {Mobile apps have been an integral part in our daily life. As these apps become more complex, it is critical to provide automated analysis techniques to ensure the correctness, security, and performance of these apps. A key component for these automated analysis techniques is to create a graphical user interface (GUI) model of an app, i.e., a window transition graph (WTG), that models windows and transitions among the windows. While existing work has provided both static and dynamic analysis to build the WTG for an app, the constructed WTG misses many transitions or contains many infeasible transitions due to the coverage issues of dynamic analysis and over-approximation of the static analysis. We propose ProMal, a "tribrid" analysis that synergistically combines static analysis, dynamic analysis, and machine learning to construct a precise WTG. Specifically, ProMal first applies static analysis to build a static WTG, and then applies dynamic analysis to verify the transitions in the static WTG. For the unverified transitions, ProMal further provides machine learning techniques that leverage runtime information (i.e., screenshots, UI layouts, and text information) to predict whether they are feasible transitions. Our evaluations on 40 real-world apps demonstrate the superiority of ProMal in building WTGs over static analysis, dynamic analysis, and machine learning techniques when they are applied separately.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {144–146},
numpages = {3},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@article{10.1145/2347696.2347709,
author = {Rashid, Ekbal and Patnayak, Srikanta and Bhattacherjee, Vandana},
title = {A survey in the area of machine learning and its application for software quality prediction},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2347696.2347709},
doi = {10.1145/2347696.2347709},
abstract = {This paper explores software quality improvement through early prediction of error patterns. It summarizes a variety of techniques for software quality prediction in the domain of software engineering. The objective of this research is to apply the various machine learning approaches, such as Case-Based Reasoning and Fuzzy logic, to predict software quality. The system predicts the error after accepting the values of certain parameters of the software. This paper advocates the use of case-based reasoning (i.e., CBR) to build a software quality prediction system with the help of human experts. The prediction is based on analogy. We have used different similarity measures to find the best method that increases reliability. This software is compiled using Turbo C++ 3.0 and hence it is very compact and standalone. It can be readily deployed on any configuration without affecting its performance.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–7},
numpages = {7},
keywords = {software quality, similarity, machine learning, function, erffort estimation, analogy, CBR}
}

@article{10.4018/jaras.2011010105,
author = {Carrozza, Gabriella and Natella, Roberto},
title = {A Recovery-Oriented Approach for Software Fault Diagnosis in Complex Critical Systems},
year = {2011},
issue_date = {January 2011},
publisher = {IGI Global},
address = {USA},
volume = {2},
number = {1},
issn = {1947-9220},
url = {https://doi.org/10.4018/jaras.2011010105},
doi = {10.4018/jaras.2011010105},
abstract = {This paper proposes an approach to software faults diagnosis in complex fault tolerant systems, encompassing the phases of error detection, fault location, and system recovery. Errors are detected in the first phase, exploiting the operating system support. Faults are identified during the location phase, through a machine learning based approach. Then, the best recovery action is triggered once the fault is located. Feedback actions are also used during the location phase to improve detection quality over time. A real world application from the Air Traffic Control field has been used as case study for evaluating the proposed approach. Experimental results, achieved by means of fault injection, show that the diagnosis engine is able to diagnose faults with high accuracy and at a low overhead.},
journal = {Int. J. Adapt. Resilient Auton. Syst.},
month = jan,
pages = {77–104},
numpages = {28},
keywords = {Software Dependability, Machine Learning, Fault Tolerance Systems, Fault Diagnosis, Errors}
}

@article{10.1016/j.jss.2019.110451,
author = {Agnelo, Jo\~{a}o and Laranjeiro, Nuno and Bernardino, Jorge},
title = {Using Orthogonal Defect Classification to characterize NoSQL database defects},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {159},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110451},
doi = {10.1016/j.jss.2019.110451},
journal = {J. Syst. Softw.},
month = jan,
numpages = {23},
keywords = {Software fault, Software defect, Orthogonal Defect Classification, NoSQL, Defect analysis}
}

@inproceedings{10.5555/2486788.2487006,
author = {Jonsson, Leif},
title = {Increasing anomaly handling efficiency in large organizations using applied machine learning},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {Maintenance costs can be substantial for large organizations (several hundreds of programmers) with very large and complex software systems. By large we mean lines of code in the range of hundreds of thousands or millions. Our research objective is to improve the process of handling anomaly reports for large organizations. Specifically, we are addressing the problem of the manual, laborious and time consuming process of assigning anomaly reports to the correct design teams and the related issue of localizing faults in the system architecture. In large organizations, with complex systems, this is particularly problematic because the receiver of an anomaly report may not have detailed knowledge of the whole system. As a consequence, anomaly reports may be assigned to the wrong team in the organization, causing delays and unnecessary work. We have so far developed two machine learning prototypes to validate our approach. The latest, a re-implementation and extension, of the first is being evaluated on four large systems at Ericsson AB. Our main goal is to investigate how large software development organizations can significantly improve development efficiency by replacing manual anomaly report assignment and fault localization with machine learning techniques. Our approach focuses on training machine learning systems on anomaly report databases; this is in contrast to many other approaches that are based on test case execution combined with program sampling and/or source code analysis.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {1361–1364},
numpages = {4},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@phdthesis{10.5555/2519464,
author = {Pelayo Ramirez, Lourdes},
advisor = {Dick, Scott},
title = {Developing and evaluating methods for mitigating sample selection bias in machine learning},
year = {2011},
isbn = {9780494892763},
publisher = {University of Alberta},
address = {CAN},
abstract = {The imbalanced learning problem occurs in a large number of economic and health domains of great importance; consequently, it has drawn a significant amount of interest from academia, industry, and government funding agencies. Several researchers have used stratification to alleviate this problem; however, it is not clear what stratification strategy is in general more effective: under-sampling, over-sampling or the combination of both. Our first topic evaluates the contribution of stratification strategies in the software defect prediction area. We study the statistical contribution of stratification in the new Mozilla dataset, a new large-scale software defect prediction dataset which includes both object-oriented metrics and a count of defects per module. Our second topic responds to the debate about the contribution of over-sampling, under-sampling and the combination of both with the employment of a full-factorial design experiment using the Analysis of Variance (ANOVA) over six software defect prediction datasets. We extend our research to develop a stratification method to mitigate sample selection bias in function approximation problems. The sample selection bias is present when the training and test instances are drawn from a different distribution, with the imbalance dataset problem considered a particular case of sample selection bias. We extend the well-known SMOTE over-sampling technique to continuous-valued response variables. Our new algorithm proves to be a valuable algorithm helping to increase the performance on function approximation problems and effectively reducing the impact of sample selection bias.},
note = {AAINR89276}
}

@article{10.1016/j.eswa.2010.10.024,
author = {Catal, Cagatay},
title = {Review: Software fault prediction: A literature review and current trends},
year = {2011},
issue_date = {April, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.10.024},
doi = {10.1016/j.eswa.2010.10.024},
abstract = {Software engineering discipline contains several prediction approaches such as test effort prediction, correction cost prediction, fault prediction, reusability prediction, security prediction, effort prediction, and quality prediction. However, most of these prediction approaches are still in preliminary phase and more research should be conducted to reach robust models. Software fault prediction is the most popular research area in these prediction approaches and recently several research centers started new projects on this area. In this study, we investigated 90 software fault prediction papers published between year 1990 and year 2009 and then we categorized these papers according to the publication year. This paper surveys the software engineering literature on software fault prediction and both machine learning based and statistical based approaches are included in this survey. Papers explained in this article reflect the outline of what was published so far, but naturally this is not a complete review of all the papers published so far. This paper will help researchers to investigate the previous studies from metrics, methods, datasets, performance evaluation metrics, and experimental results perspectives in an easy and effective manner. Furthermore, current trends are introduced and discussed.},
journal = {Expert Syst. Appl.},
month = apr,
pages = {4626–4636},
numpages = {11},
keywords = {Statistical methods, Software quality engineering, Software engineering, Machine learning, Expert systems, Automated fault prediction models}
}

@inproceedings{10.1109/QSIC.2008.29,
author = {Briand, Lionel C.},
title = {Novel Applications of Machine Learning in Software Testing},
year = {2008},
isbn = {9780769533124},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QSIC.2008.29},
doi = {10.1109/QSIC.2008.29},
abstract = {Machine learning techniques have long been used for various purposes in software engineering. This paper provides a brief overview of the state of the art and reports on a number of novel applications I was involved with in the area of software testing. Reflecting on this personal experience, I draw lessons learned and argue that more research should be performed in that direction as machine learning has the potential to significantly help in addressing some of the long-standing software testing problems.},
booktitle = {Proceedings of the 2008 The Eighth International Conference on Quality Software},
pages = {3–10},
numpages = {8},
keywords = {software testing, Machine learning},
series = {QSIC '08}
}

@article{10.1109/TSE.2013.11,
author = {Shepperd, Martin and Song, Qinbao and Sun, Zhongbin and Mair, Carolyn},
title = {Data Quality: Some Comments on the NASA Software Defect Datasets},
year = {2013},
issue_date = {September 2013},
publisher = {IEEE Press},
volume = {39},
number = {9},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2013.11},
doi = {10.1109/TSE.2013.11},
abstract = {Background--Self-evidently empirical analyses rely upon the quality of their data. Likewise, replications rely upon accurate reporting and using the same rather than similar versions of datasets. In recent years, there has been much interest in using machine learners to classify software modules into defect-prone and not defect-prone categories. The publicly available NASA datasets have been extensively used as part of this research. Objective--This short note investigates the extent to which published analyses based on the NASA defect datasets are meaningful and comparable. Method--We analyze the five studies published in the IEEE Transactions on Software Engineering since 2007 that have utilized these datasets and compare the two versions of the datasets currently in use. Results--We find important differences between the two versions of the datasets, implausible values in one dataset and generally insufficient detail documented on dataset preprocessing. Conclusions--It is recommended that researchers 1) indicate the provenance of the datasets they use, 2) report any preprocessing in sufficient detail to enable meaningful replication, and 3) invest effort in understanding the data prior to applying machine learners.},
journal = {IEEE Trans. Softw. Eng.},
month = sep,
pages = {1208–1215},
numpages = {8},
keywords = {machine learning, defect prediction, data quality, Sun, Software, PROM, NASA, Empirical software engineering, Educational institutions, Communities, Abstracts}
}

@inproceedings{10.1145/3416506.3423578,
author = {Fan, Ming and Jia, Ang and Liu, Jingwen and Liu, Ting and Chen, Wei},
title = {When representation learning meets software analysis},
year = {2020},
isbn = {9781450381253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416506.3423578},
doi = {10.1145/3416506.3423578},
abstract = {In recent years, deep learning is increasingly prevalent in the field of Software Engineering (SE). Especially, representation learning, which can learn vectors from the syntactic and semantics of the code, offers much convenience and promotion for the downstream tasks such as code search and vulnerability detection. In this work, we introduce our two applications of leveraging representation learning for software analysis, including defect prediction and vulnerability detection.},
booktitle = {Proceedings of the 1st ACM SIGSOFT International Workshop on Representation Learning for Software Engineering and Program Languages},
pages = {17–18},
numpages = {2},
keywords = {vulnerability detection, representation learning, defect prediction},
location = {Virtual, USA},
series = {RL+SE&amp;PL 2020}
}

@inproceedings{10.5555/1348359.1348448,
author = {Jirong, Sun and Zhishu, Li and Jiancheng, Ni and Feng, Yin},
title = {Priority strategy of software fault localization},
year = {2007},
isbn = {9789608457614},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {To a given test case, fault localization has to be proceeded when its output is wrong. A novel method is presented to localize a fault. Firstly, by analyzing the relation between testing requirement and test cases that satisfying it, some assistant test cases are selected out. Then, program sliceis introduced to reduce the searching domain based on priority, which has been evaluated according to the occurrences in the selected slices. Two procedures, refining and augmenting, are followed here to fault localization: in the refining phase, the most suspicious codes are checked step by step; in the augmenting phase, more codes will be gradually considered on the basis of direct data dependency. At last, experimental studies are performed to illustrate the effectiveness of the technique.},
booktitle = {Proceedings of the 6th Conference on WSEAS International Conference on Applied Computer Science - Volume 6},
pages = {499–505},
numpages = {7},
keywords = {test suite management, fault localization, execution slice, dynamic slice, direct data dependency, assistant slice},
location = {Hangzhou, China},
series = {ACOS'07}
}

@inproceedings{10.1145/3475716.3475790,
author = {Wang, Song and Wang, Junjie and Nam, Jaechang and Nagappan, Nachiappan},
title = {Continuous Software Bug Prediction},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475790},
doi = {10.1145/3475716.3475790},
abstract = {Background: Many software bug prediction models have been proposed and evaluated on a set of well-known benchmark datasets. We conducted pilot studies on the widely used benchmark datasets and observed common issues among them. Specifically, most of existing benchmark datasets consist of randomly selected historical versions of software projects, which poses non-trivial threats to the validity of existing bug prediction studies since the real-world software projects often evolve continuously. Yet how to conduct software bug prediction in the real-world continuous software development scenarios is not well studied.Aims: In this paper, to bridge the gap between current software bug prediction practice and real-world continuous software development, we propose new approaches to conduct bug prediction in real-world continuous software development regarding model building, updating, and evaluation.Method: For model building, we propose ConBuild, which leverages distributional characteristics of bug prediction data to guide the training version selection. For model updating, we propose ConUpdate, which leverages the evolution of distributional characteristics of bug prediction data between versions to guide the reuse or update of bug prediction models in continuous software development. For model evaluation, we propose ConEA, which leverages the evolution of buggy probability of files between versions to conduct effort-aware evaluation.Results: Experiments on 120 continuously release versions that span across six large-scale open-source software systems show the practical value of our approaches.Conclusions: This paper provides new insights and guidelines for conducting software bug prediction in the context of continuous software development.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {14},
numpages = {12},
keywords = {software quality, software defect prediction, continuous software development, Empirical software engineering},
location = {Bari, Italy},
series = {ESEM '21}
}

@article{10.4018/jaec.2010070104,
author = {Mohanty, Ramakanta and Ravi, V. and Patra, M. R.},
title = {Application of Machine Learning Techniques to Predict Software Reliability},
year = {2010},
issue_date = {July 2010},
publisher = {IGI Global},
address = {USA},
volume = {1},
number = {3},
issn = {1942-3594},
url = {https://doi.org/10.4018/jaec.2010070104},
doi = {10.4018/jaec.2010070104},
abstract = {In this paper, the authors employed machine learning techniques, specifically, Back propagation trained neural network (BPNN), Group method of data handling (GMDH), Counter propagation neural network (CPNN), Dynamic evolving neuro-fuzzy inference system (DENFIS), Genetic Programming (GP), TreeNet, statistical multiple linear regression (MLR), and multivariate adaptive regression splines (MARS), to accurately forecast software reliability. Their effectiveness is demonstrated on three datasets taken from literature, where performance is compared in terms of normalized root mean square error (NRMSE) obtained in the test set. From rigorous experiments conducted, it was observed that GP outperformed all techniques in all datasets, with GMDH coming a close second.},
journal = {Int. J. Appl. Evol. Comput.},
month = jul,
pages = {70–86},
numpages = {17},
keywords = {Software Reliability, Machine Learning Techniques, Group Method of Data Handling, Genetic Programming, Dynamic Evolving Neuro-Fuzzy Inference System, Counter Propagation Neural Network, Back Propagation Trained Neural Network}
}

@article{10.1016/j.infsof.2006.07.005,
author = {Kanmani, S. and Uthariaraj, V. Rhymend and Sankaranarayanan, V. and Thambidurai, P.},
title = {Object-oriented software fault prediction using neural networks},
year = {2007},
issue_date = {May, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {49},
number = {5},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2006.07.005},
doi = {10.1016/j.infsof.2006.07.005},
abstract = {This paper introduces two neural network based software fault prediction models using Object-Oriented metrics. They are empirically validated using a data set collected from the software modules developed by the graduate students of our academic institution. The results are compared with two statistical models using five quality attributes and found that neural networks do better. Among the two neural networks, Probabilistic Neural Networks outperform in predicting the fault proneness of the Object-Oriented modules developed.},
journal = {Inf. Softw. Technol.},
month = may,
pages = {483–492},
numpages = {10},
keywords = {Probabilistic neural network, Object-Oriented metrics, Logistic regression, Fault proneness, Discriminant analysis, Back propagation neural network}
}

@article{10.1016/j.asoc.2014.03.030,
author = {Chatterjee, Subhashish and Roy, Arunava},
title = {Web software fault prediction under fuzzy environment using MODULO-M multivariate overlapping fuzzy clustering algorithm and newly proposed revised prediction algorithm},
year = {2014},
issue_date = {September, 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {22},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2014.03.030},
doi = {10.1016/j.asoc.2014.03.030},
abstract = {In recent years some research works have been carried out on web software error analysis and reliability predictions. In all these works the web environment has been considered as crisp one, which is not a very realistic assumption. Moreover, web error forecasting remains unworthy for the researchers for quite a long time. Furthermore, among various well known forecasting techniques, fuzzy time series based methods are extensively used, though they are suffering from some serious drawbacks, viz., fixed sized intervals, using some fixed membership values (0, 0.5, and 1) and moreover, the defuzzification process only deals with the factor that is to be predicted. Prompted by these facts, the present authors have proposed a novel multivariate fuzzy forecasting algorithm that is able to remove all the aforementioned drawbacks as also can predict the future occurrences of different web failures (considering the web environment as fuzzy) with better predictive accuracy. Also, the complexity analysis of the proposed algorithm is done to unveil its better run time complexity. Moreover, the comparisons with the other existing frequently used forecasting algorithms were performed to demonstrate its better efficiency and predictive accuracy. Additionally, at the very end, the developed algorithm was applied on the real web failure data of http://www.ismdhanbad.ac.in/, the official website of ISM Dhanbad, India, collected from the corresponding HTTP log files.},
journal = {Appl. Soft Comput.},
month = sep,
pages = {372–396},
numpages = {25},
keywords = {Web software reliability, Web errors, Server logs, Fuzzy time series, Fuzzy clustering, Algorithm}
}

@article{10.1007/s00521-016-2327-3,
author = {Nassif, Ali Bou and Azzeh, Mohammad and Banitaan, Shadi and Neagu, Daniel},
title = {Guest editorial: special issue on predictive analytics using machine learning},
year = {2016},
issue_date = {November  2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {27},
number = {8},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-016-2327-3},
doi = {10.1007/s00521-016-2327-3},
journal = {Neural Comput. Appl.},
month = nov,
pages = {2153–2155},
numpages = {3}
}

@article{10.1016/j.jss.2007.07.034,
author = {Vandecruys, Olivier and Martens, David and Baesens, Bart and Mues, Christophe and De Backer, Manu and Haesen, Raf},
title = {Mining software repositories for comprehensible software fault prediction models},
year = {2008},
issue_date = {May, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {5},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.07.034},
doi = {10.1016/j.jss.2007.07.034},
abstract = {Software managers are routinely confronted with software projects that contain errors or inconsistencies and exceed budget and time limits. By mining software repositories with comprehensible data mining techniques, predictive models can be induced that offer software managers the insights they need to tackle these quality and budgeting problems in an efficient way. This paper deals with the role that the Ant Colony Optimization (ACO)-based classification technique AntMiner+ can play as a comprehensible data mining technique to predict erroneous software modules. In an empirical comparison on three real-world public datasets, the rule-based models produced by AntMiner+ are shown to achieve a predictive accuracy that is competitive to that of the models induced by several other included classification techniques, such as C4.5, logistic regression and support vector machines. In addition, we will argue that the intuitiveness and comprehensibility of the AntMiner+ models can be considered superior to the latter models.},
journal = {J. Syst. Softw.},
month = may,
pages = {823–839},
numpages = {17},
keywords = {Software mining, Fault prediction, Comprehensibility, Classification, Ant Colony Optimization}
}

@inproceedings{10.1007/978-3-540-69566-0_18,
author = {Singh, Yogesh and Kaur, Arvinder and Malhotra, Ruchika},
title = {Predicting Software Fault Proneness Model Using Neural Network},
year = {2008},
isbn = {9783540695646},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-69566-0_18},
doi = {10.1007/978-3-540-69566-0_18},
abstract = {Importance of construction of models for predicting software quality attributes is increasing leading to usage of artificial intelligence techniques such as Artificial Neural Network (ANN). The goal of this paper is to empirically compare traditional strategies such as Logistic Regression (LR) and ANN to assess software quality. The study used data collected from public domain NASA data set. We find the effect of software metrics on fault proneness. The fault proneness models were predicted using LR regression and ANN methods. The performance of the two methods was compared by Receiver Operating Characteristic (ROC) analysis. The areas under the ROC curves are 0.78 and 0.745 for the LR and ANN model, respectively. The predicted model shows that software metrics are related to fault proneness. The models predict faulty classes with more than 70 percent accuracy. The study showed that ANN method can also be used in constructing software quality models and more similar studies should further investigate the issue. Based on these results, it is reasonable to claim that such a model could help for planning and executing testing by focusing resources on fault-prone parts of the design and code.},
booktitle = {Proceedings of the 9th International Conference on Product-Focused Software Process Improvement},
pages = {204–214},
numpages = {11},
keywords = {software quality, metrics, empirical validation, artificial neural network},
location = {Monte Porzio Catone, Italy},
series = {PROFES '08}
}

@inproceedings{10.1109/COMPSAC.2015.66,
author = {Liu, Wangshu and Liu, Shulong and Gu, Qing and Chen, Xiang and Chen, Daoxu},
title = {FECS: A Cluster Based Feature Selection Method for Software Fault Prediction with Noises},
year = {2015},
isbn = {9781467365642},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2015.66},
doi = {10.1109/COMPSAC.2015.66},
abstract = {Noises are inevitable when mining software archives for software fault prediction. Although some researchers have investigated the noise tolerance of existing feature selection methods, few studies focus on proposing new feature selection methods with a certain noise tolerance. To solve this issue, we propose a novel method FECS (FEature Clustering with Selection strategies). This method includes two phases: a feature clustering phase and a feature selection phase with three different heuristic search strategies. During empirical studies, we choose real-world software projects, such as Eclipse and NASA and inject class level and feature level noises simultaneously to imitate noisy datasets. After using classical feature selection methods as the baseline, we confirm the effectiveness of FECS and provide a guideline of using FECS after analyzing the effects of varying either the percentage of selected features or the noise rate.},
booktitle = {Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 02},
pages = {276–281},
numpages = {6},
keywords = {Software Quality Assurance, Software Fault Prediction, Noise Tolerance, Feature Selection, Classification Model},
series = {COMPSAC '15}
}

@article{10.1007/s10664-021-09944-w,
author = {Riom, Timoth\'{e} and Sawadogo, Arthur and Allix, Kevin and Bissyand\'{e}, Tegawend\'{e} F. and Moha, Naouel and Klein, Jacques},
title = {Revisiting the VCCFinder approach for the identification of vulnerability-contributing commits},
year = {2021},
issue_date = {May 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09944-w},
doi = {10.1007/s10664-021-09944-w},
abstract = {Detecting vulnerabilities in software is a constant race between development teams and potential attackers. While many static and dynamic approaches have focused on regularly analyzing the software in its entirety, a recent research direction has focused on the analysis of changes that are applied to the code. VCCFinder is a seminal approach in the literature that builds on machine learning to automatically detect whether an incoming commit will introduce some vulnerabilities. Given the influence of VCCFinder in the literature, we undertake an investigation into its performance as a state-of-the-art system. To that end, we propose to attempt a replication study on the VCCFinder supervised learning approach. The insights of our failure to replicate the results reported in the original publication informed the design of a new approach to identify vulnerability-contributing commits based on a semi-supervised learning technique with an alternate feature set. We provide all artefacts and a clear description of this approach as a new reproducible baseline for advancing research on machine learning-based identification of vulnerability-introducing commits.},
journal = {Empirical Softw. Engg.},
month = may,
numpages = {30},
keywords = {Software engineering, Replication, Machine learning, Vulnerability detection}
}

@article{10.1016/j.jss.2021.111060,
author = {Xu, Liming and Towey, Dave and French, Andrew P. and Benford, Steve and Zhou, Zhi Quan and Chen, Tsong Yueh},
title = {Using metamorphic relations to verify and enhance Artcode classification},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111060},
doi = {10.1016/j.jss.2021.111060},
journal = {J. Syst. Softw.},
month = dec,
numpages = {14},
keywords = {Artcode, Machine learning, Software verification, Classification, Metamorphic relation, Metamorphic testing}
}

@article{10.1016/j.neucom.2015.10.137,
author = {Shafiabady, Niusha and Lee, L.H. and Rajkumar, R. and Kallimani, V.P. and Akram, Nik Ahmad and Isa, Dino},
title = {Using unsupervised clustering approach to train the Support Vector Machine for text classification},
year = {2016},
issue_date = {October 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {211},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2015.10.137},
doi = {10.1016/j.neucom.2015.10.137},
abstract = {The use of learning algorithms for text classification assumes the availability of a large amount of documents which have been organized and labeled correctly by human experts for use in the training phase. Unless the text documents in question have been in existence for some time, using an expert system is inevitable because manual organizing and labeling of thousands of groups of text documents can be a very labor intensive and intellectually challenging activity. Also, in some new domains, the knowledge to organize and label different classes might not be unavailable. Therefore unsupervised learning schemes for automatically clustering data in the training phase are needed. Furthermore, even when knowledge exists, variation is high when the subject under classification depends on personal opinions and is open to different interpretations. This paper describes a methodology which uses Self Organizing Maps (SOM) and alternatively does the automatic clustering by using the Correlation Coefficient (CorrCoef). Consequently the clusters are used as the labels to train the Support Vector Machine (SVM). Experiments and results are presented based on applying the methodology to some standard text datasets in order to verify the accuracy of the proposed scheme. We will also present results which are used to evaluate the effect that dimensionality reduction and changes in the clustering schemes have on the accuracy of the SVM. Results show that the proposed combination has better accuracy compared to training the learning machine using the expert knowledge.},
journal = {Neurocomput.},
month = oct,
pages = {4–10},
numpages = {7},
keywords = {Unsupervised learning, Support Vector Machines, Classification}
}

@inproceedings{10.1109/ICMLA.2006.5,
author = {Hulse, Jason Van and Khoshgoftaar, Taghi M. and Seiffert, Chris},
title = {A Comparison of Software Fault Imputation Procedures},
year = {2006},
isbn = {0769527353},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2006.5},
doi = {10.1109/ICMLA.2006.5},
abstract = {This work presents a detailed comparison of three imputation techniques, Bayesian multiple imputation, regression imputation and k nearest neighbor imputation, at various missingness levels. Starting with a complete real-world software measurement dataset called CCCS, missing values were injected into the dependent variable at four levels according to three different missingness mechanisms. The three imputation techniques are evaluated by comparing the imputed and actual values. Our analysis includes a three-way analysis of variance (ANOVA) model, which demonstrates that Bayesian multiple imputation obtains the best performance, followed closely by regression.},
booktitle = {Proceedings of the 5th International Conference on Machine Learning and Applications},
pages = {135–142},
numpages = {8},
series = {ICMLA '06}
}

@inproceedings{10.1007/978-3-540-72590-9_145,
author = {Liu, Dong and Xing, Weiyan and Li, Rui and Zhang, Chunyuan and Li, Haiyan},
title = {A Fault-Tolerant Real-Time Scheduling Algorithm in Software Fault-Tolerant Module},
year = {2007},
isbn = {9783540725893},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-72590-9_145},
doi = {10.1007/978-3-540-72590-9_145},
abstract = {In software fault-tolerant module, the key issue that affects the performance of fault-tolerant scheduling algorithm is how to predict precisely whether a primary is executable. In order to improve the prediction precision, a new algorithm named DPA, Deep-Prediction based Algorithm, is put forward. DPA uses prediction-table to predict whether a primary can be completed before it is scheduled. Simulation results show that DPA provides more execution time for primaries and wastes less processor time than the well-known similar algorithms.},
booktitle = {Proceedings of the 7th International Conference on Computational Science, Part IV: ICCS 2007},
pages = {961–964},
numpages = {4},
keywords = {software fault-tolerance, scheduling algorithm, real-time system},
location = {Beijing, China},
series = {ICCS '07}
}

@inproceedings{10.1109/RIDE.2005.9,
author = {Jagadeesh Chandra Bose, R. P. and Srinivasan, S. H.},
title = {Data Mining Approaches to Software Fault Diagnosis},
year = {2005},
isbn = {0769523900},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/RIDE.2005.9},
doi = {10.1109/RIDE.2005.9},
abstract = {Automatic identification of software faults has enormous practical significance. This requires characterizing program execution behavior and the use of appropriate data mining techniques on the chosen representation. In this paper, we use the sequence of system calls to characterize program execution. The data mining tasks addressed are learning to map system call streams to fault labels and automatic identification of fault causes. Spectrum kernels and SVM are used for the former while latent semantic analysis is used for the latter. The techniques are demonstrated for the intrusion dataset containing system call traces. The results show that kernel techniques are as accurate as the best available results but are faster by orders of magnitude. We also show that latent semantic indexing is capable of revealing fault-specific features.},
booktitle = {Proceedings of the 15th International Workshop on Research Issues in Data Engineering: Stream Data Mining and Applications},
pages = {45–52},
numpages = {8},
series = {RIDE '05}
}

@inproceedings{10.1109/ICMV.2009.54,
author = {Kaur, Arashdeep and Sandhu, Parvinder S. and Bra, Amanpreet Singh},
title = {Early Software Fault Prediction Using Real Time Defect Data},
year = {2010},
isbn = {9780769539447},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMV.2009.54},
doi = {10.1109/ICMV.2009.54},
abstract = {Quality of a software component can be measured in terms of fault proneness of data. Quality estimations are made using fault proneness data available from previously developed similar type of projects and the training data consisting of software measurements. To predict faulty modules in software data different techniques have been proposed which includes statistical method, machine learning methods, neural network techniques and clustering techniques. The aim of proposed approach is to investigate that whether metrics available in the early lifecycle (i.e. requirement metrics), metrics available in the late lifecycle (i.e. code metrics) and metrics available in the early lifecycle (i.e. requirement metrics) combined with metrics available in the late lifecycle (i.e. code metrics) can be used to identify fault prone modules by using clustering techniques. This approach has been tested with three real time defect datasets of NASA software projects, JM1, PC1 and CM1. Predicting faults early in the software life cycle can be used to improve software process control and achieve high software reliability. The results show that when all the prediction techniques are evaluated, the best prediction model is found to be the fusion of requirement and code metric model.},
booktitle = {Proceedings of the 2009 Second International Conference on Machine Vision},
pages = {242–245},
numpages = {4},
series = {ICMV '09}
}

@article{10.1016/j.infsof.2009.06.006,
author = {Briand, Lionel C. and Labiche, Yvan and Bawar, Zaheer and Spido, Nadia Traldi},
title = {Using machine learning to refine Category-Partition test specifications and test suites},
year = {2009},
issue_date = {November, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {51},
number = {11},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2009.06.006},
doi = {10.1016/j.infsof.2009.06.006},
abstract = {In the context of open source development or software evolution, developers often face test suites which have been developed with no apparent rationale and which may need to be augmented or refined to ensure sufficient dependability, or even reduced to meet tight deadlines. We refer to this process as the re-engineering of test suites. It is important to provide both methodological and tool support to help people understand the limitations of test suites and their possible redundancies, so as to be able to refine them in a cost effective manner. To address this problem in the case of black-box, Category-Partition testing, we propose a methodology and a tool based on machine learning that has shown promising results on a case study involving students as testers.},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {1551–1564},
numpages = {14},
keywords = {Test improvement, Machine learning, Category-Partition, Black box testing}
}

@inproceedings{10.1007/978-3-030-27455-9_1,
author = {Sarro, Federica},
title = {Search-Based Predictive Modelling for Software Engineering: How Far Have We Gone?},
year = {2019},
isbn = {978-3-030-27454-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27455-9_1},
doi = {10.1007/978-3-030-27455-9_1},
abstract = {In this keynote I introduce the use of Predictive Analytics for Software Engineering (SE) and then focus on the use of search-based heuristics to tackle long-standing SE prediction problems including (but not limited to) software development effort estimation and software defect prediction. I review recent research in Search-Based Predictive Modelling for SE in order to assess the maturity of the field and point out promising research directions. I conclude my keynote by discussing best practices for a rigorous and realistic empirical evaluation of search-based predictive models, a condicio sine qua non to facilitate the adoption of prediction models in software industry practices.},
booktitle = {Search-Based Software Engineering: 11th International Symposium, SSBSE 2019, Tallinn, Estonia, August 31 – September 1, 2019, Proceedings},
pages = {3–7},
numpages = {5},
keywords = {Software analytics, Machine learning, Search-based software engineering, Predictive modelling, Predictive analytics},
location = {Tallinn, Estonia}
}

@article{10.1504/ijiei.2021.120322,
author = {Lakra, Kirti and Chug, Anuradha},
title = {Application of metaheuristic techniques in software quality prediction: a systematic mapping study},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {4},
issn = {1758-8715},
url = {https://doi.org/10.1504/ijiei.2021.120322},
doi = {10.1504/ijiei.2021.120322},
abstract = {This paper focuses on the systematic review of various metaheuristic techniques employed for analysing different software quality aspects, including fault proneness, defect anticipation, change proneness, maintainability prediction, and software reliability prediction. It is observed that machine learning algorithms are still popular models, but metaheuristic algorithms are also gaining popularity in the field of software quality measurement. This is due to the fact that metaheuristic algorithms are more efficient in solving real-world, search-based, and optimisation problems. Initially, 90 papers were considered and analysed for conducting this study from 2010 to 2020, and 55 studies were shortlisted based on predesigned quality evaluation standards. Resultantly, particle swarm optimisation (PSO), and genetic algorithms came out as the most prominently used metaheuristic techniques for developing software quality models in 36.3% and 27.2% of the shortlisted studies, respectively. The current review will benefit other researchers by providing an insight into the current trends in software quality domain.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {355–399},
numpages = {44},
keywords = {software quality improvement, software maintainability prediction, software reliability prediction, software change prediction, software defect prediction, software fault proneness, software quality, object-oriented metrics, metaheuristic techniques}
}

@inproceedings{10.1145/3460945.3464954,
author = {Hasabnis, Niranjan and Gottschlich, Justin},
title = {ControlFlag: a self-supervised idiosyncratic pattern detection system for software control structures},
year = {2021},
isbn = {9781450384674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460945.3464954},
doi = {10.1145/3460945.3464954},
abstract = {Software debugging has been shown to utilize upwards of half of developers’ time. Yet, machine programming (MP), the field concerned with the automation of software (and hardware) development, has recently made strides in both research and production-quality automated debugging systems. In this paper we present ControlFlag, a self-supervised MP system that aims to improve debugging by attempting to detect idiosyncratic pattern violations in software control structures. ControlFlag also suggests possible corrections in the event an anomalous pattern is detected. We present ControlFlag’s design and provide an experimental evaluation and analysis of its efficacy in identifying potential programming errors in production-quality software. As a first concrete evidence towards improving software quality, ControlFlag has already found an anomaly in CURL that has been acknowledged and fixed by its developers. We also discuss future extensions of ControlFlag.},
booktitle = {Proceedings of the 5th ACM SIGPLAN International Symposium on Machine Programming},
pages = {32–42},
numpages = {11},
keywords = {self-supervised learning, Source-code mining},
location = {Virtual, Canada},
series = {MAPS 2021}
}

@article{10.4018/jossp.2012040103,
author = {Chaturvedi, K. K. and Singh, V.B.},
title = {An Empirical Comparison of Machine Learning Techniques in Predicting the Bug Severity of Open and Closed Source Projects},
year = {2012},
issue_date = {April 2012},
publisher = {IGI Global},
address = {USA},
volume = {4},
number = {2},
issn = {1942-3926},
url = {https://doi.org/10.4018/jossp.2012040103},
doi = {10.4018/jossp.2012040103},
abstract = {Bug severity is the degree of impact that a defect has on the development or operation of a component or system, and can be classified into different levels based on their impact on the system. Identification of severity level can be useful for bug triager in allocating the bug to the concerned bug fixer. Various researchers have attempted text mining techniques in predicting the severity of bugs, detection of duplicate bug reports and assignment of bugs to suitable fixer for its fix. In this paper, an attempt has been made to compare the performance of different machine learning techniques namely Support vector machine SVM, probability based Na\"{\i}ve Bayes NB, Decision Tree based J48 A Java implementation of C4.5, rule based Repeated Incremental Pruning to Produce Error Reduction RIPPER and Random Forests RF learners in predicting the severity level 1 to 5 of a reported bug by analyzing the summary or short description of the bug reports. The bug report data has been taken from NASA's PITS Projects and Issue Tracking System datasets as closed source and components of Eclipse, Mozilla &amp; GNOME datasets as open source projects. The analysis has been carried out in RapidMiner and STATISTICA data mining tools. The authors measured the performance of different machine learning techniques by considering i the value of accuracy and F-Measure for all severity level and ii number of best cases at different threshold level of accuracy and F-Measure.},
journal = {Int. J. Open Source Softw. Process.},
month = apr,
pages = {32–59},
numpages = {28},
keywords = {Text Mining, Supervised Classification, Multiclass Classification, Bug Severity, Bug Repositories, 10-fold Cross Validation}
}

@inproceedings{10.5555/2394450.2394484,
author = {Catal, Cagatay and Diri, Banu},
title = {Software fault prediction with object-oriented metrics based artificial immune recognition system},
year = {2007},
isbn = {3540734597},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software testing is a time-consuming and expensive process. Software fault prediction models are used to identify fault-prone classes automatically before system testing. These models can reduce the testing duration, project risks, resource and infrastructure costs. In this study, we propose a novel fault prediction model to improve the testing process. Chidamber-Kemerer Object-Oriented metrics and method-level metrics such as Halstead and McCabe are used as independent metrics in our Artificial Immune Recognition System based model. According to this study, class-level metrics based model which applies AIRS algorithm can be used successfully for fault prediction and its performance is higher than J48 based approach. A fault prediction tool which uses this model can be easily integrated into the testing process.},
booktitle = {Proceedings of the 8th International Conference on Product-Focused Software Process Improvement},
pages = {300–314},
numpages = {15},
location = {Riga, Latvia},
series = {PROFES'07}
}

@inproceedings{10.1007/978-3-030-57321-8_28,
author = {Saranti, Anna and Taraghi, Behnam and Ebner, Martin and Holzinger, Andreas},
title = {Property-Based Testing for Parameter Learning of Probabilistic Graphical Models},
year = {2020},
isbn = {978-3-030-57320-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-57321-8_28},
doi = {10.1007/978-3-030-57321-8_28},
abstract = {Code quality is a requirement for successful and sustainable software development. The emergence of Artificial Intelligence and data driven Machine Learning in current applications makes customized solutions for both data as well as code quality a requirement. The diversity and the stochastic nature of Machine Learning algorithms require different test methods, each of which is suitable for a particular method. Conventional unit tests in test-automation environments provide the common, well-studied approach to tackle code quality issues, but Machine Learning applications pose new challenges and have different requirements, mostly as far the numerical computations are concerned. In this research work, a concrete use of property-based testing for quality assurance in the parameter learning algorithm of a probabilistic graphical model is described. The necessity and effectiveness of this method in comparison to unit tests is analyzed with concrete code examples for enhanced retraceability and interpretability, thus highly relevant for what is called explainable AI.},
booktitle = {Machine Learning and Knowledge Extraction: 4th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9 International Cross-Domain Conference, CD-MAKE 2020, Dublin, Ireland, August 25–28, 2020, Proceedings},
pages = {499–515},
numpages = {17},
keywords = {Machine learning, Probabilistic graphical models, Property-based testing},
location = {Dublin, Ireland}
}

@article{10.1016/j.infsof.2017.03.007,
author = {Yang, Xinli and Lo, David and Xia, Xin and Sun, Jianling},
title = {TLEL},
year = {2017},
issue_date = {July 2017},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {87},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.03.007},
doi = {10.1016/j.infsof.2017.03.007},
abstract = {We propose a novel approach TLEL, which can be seen as a two-layer ensemble learning technique, to achieve a better performance for just-in-time defect prediction problem.We compare TLEL with three baselines, i.e., Deeper, DNC and MKEL, on six large software projects.The experiment results show that our approach can achieve a substantial improvement over all of them. Moreover, TLEL could discover over 70% reviewing only 20% of the lines of code. Display Omitted ContextDefect prediction is a very meaningful topic, particularly at change-level. Change-level defect prediction, which is also referred as just-in-time defect prediction, could not only ensure software quality in the development process, but also make the developers check and fix the defects in time [1]. ObjectiveEnsemble learning becomes a hot topic in recent years. There have been several studies about applying ensemble learning to defect prediction [25]. Traditional ensemble learning approaches only have one layer, i.e., they use ensemble learning once. There are few studies that leverages ensemble learning twice or more. To bridge this research gap, we try to hybridize various ensemble learning methods to see if it will improve the performance of just-in-time defect prediction. In particular, we focus on one way to do this by hybridizing bagging and stacking together and leave other possibly hybridization strategies for future work. MethodIn this paper, we propose a two-layer ensemble learning approach TLEL which leverages decision tree and ensemble learning to improve the performance of just-in-time defect prediction. In the inner layer, we combine decision tree and bagging to build a Random Forest model. In the outer layer, we use random under-sampling to train many different Random Forest models and use stacking to ensemble them once more. ResultsTo evaluate the performance of TLEL, we use two metrics, i.e., cost effectiveness and F1-score. We perform experiments on the datasets from six large open source projects, i.e., Bugzilla, Columba, JDT, Platform, Mozilla, and PostgreSQL, containing a total of 137,417 changes. Also, we compare our approach with three baselines, i.e., Deeper, the approach proposed by us [6], DNC, the approach proposed by Wang etal. [2], and MKEL, the approach proposed by Wang etal. [3]. The experimental results show that on average across the six datasets, TLEL could discover over 70% of the bugs by reviewing only 20% of the lines of code, as compared with about 50% for the baselines. In addition, the F1-scores TLEL can achieve are substantially and statistically significantly higher than those of three baselines across the six datasets. ConclusionTLEL can achieve a substantial and statistically significant improvement over the state-of-the-art methods, i.e., Deeper, DNC and MKEL. Moreover, TLEL could discover over 70% of the bugs by reviewing only 20% of the lines of code.},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {206–220},
numpages = {15},
keywords = {Just-in-time defect prediction, Ensemble learning, Cost effectiveness}
}

@article{10.1007/s11334-015-0256-4,
author = {Valles-Barajas, Fernando},
title = {A comparative analysis between two techniques for the prediction of software defects: fuzzy and statistical linear regression},
year = {2015},
issue_date = {December  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {11},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-015-0256-4},
doi = {10.1007/s11334-015-0256-4},
abstract = {Software engineers should estimate the necessary resources (time, people, software tools among others) to satisfy software project requirements; this activity is carried out in the planning phase. The estimated time for developing software projects is a necessary element to establish the cost of software projects and to assign human resources to every phase of software projects. Most companies fail to finish software projects on time because of a poor estimation technique or the lack of the same. The estimated time must consider the time spent eliminating software defects injected during each of the software phases. A comparative analysis between two techniques (fuzzy linear regression and statistical linear regression) to perform software defect estimation is presented. These two techniques model uncertainty in a different way; statistical linear regression models uncertainty as randomness, whereas fuzzy linear regression models uncertainty as fuzziness. The main objective of this paper was to establish the kind of uncertainty associated with software defect prediction and to contrast these two prediction techniques. The KC1 NASA data set was used to do this analysis. Only six of the metrics included in KC1 data set and lines of code metric were used in this comparative analysis. Descriptive statistics was first used to have an overview of the main characteristics of the data set used in this research. Linearity property between predictor variables and the variable of interest number of defects was checked using scatter plots and Pearson's correlation coefficient. Then the problem of multicollinearity was verified using inter-correlations among metrics and the variance inflation factor. Best subset regression was applied to detect the most influencing subset of predictor variables; this subset was later used to build fuzzy and statistical regression models. Linearity property between metrics and number of defects was confirmed. The problem of multicollinearity was not detected in the predictor variables. Best subset regression found that the subset composed of 5 variables was the most influencing subset. The analysis showed that the statistical regression model in general outperformed the fuzzy regression model. Techniques for making software defect prediction should be carefully employed in order to have quality plans. Software engineers should consider and understand a set of prediction techniques and know their weaknesses and strengths. At least, in the KC1 data set, the uncertainty in the software defect prediction model is due to randomness so it is reasonable to use statistical linear regression instead of fuzzy linear regression to build a prediction model.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {277–287},
numpages = {11},
keywords = {Statistical linear regression, Software defect prediction, Fuzzy linear regression}
}

@article{10.1007/s10664-008-9082-8,
author = {Weyuker, Elaine J. and Ostrand, Thomas J. and Bell, Robert M.},
title = {Do too many cooks spoil the broth? Using the number of developers to enhance defect prediction models},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-008-9082-8},
doi = {10.1007/s10664-008-9082-8},
abstract = {Fault prediction by negative binomial regression models is shown to be effective for four large production software systems from industry. A model developed originally with data from systems with regularly scheduled releases was successfully adapted to a system without releases to identify 20% of that system's files that contained 75% of the faults. A model with a pre-specified set of variables derived from earlier research was applied to three additional systems, and proved capable of identifying averages of 81, 94 and 76% of the faults in those systems. A primary focus of this paper is to investigate the impact on predictive accuracy of using data about the number of developers who access individual code units. For each system, including the cumulative number of developers who had previously modified a file yielded no more than a modest improvement in predictive accuracy. We conclude that while many factors can "spoil the broth" (lead to the release of software with too many defects), the number of developers is not a major influence.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {539–559},
numpages = {21},
keywords = {Software faults, Negative binomial model, Empirical study, Developer counts}
}

@article{10.1016/j.procs.2021.08.013,
author = {Tomescu, Vlad-Ioan and Czibula, Gabriela and Ni\c{t}ic\u{a}, \c{S}tefan},
title = {A study on using deep autoencoders for imbalanced binary classification},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {192},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.08.013},
doi = {10.1016/j.procs.2021.08.013},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {119–128},
numpages = {10},
keywords = {68T10, 2000 MSC: 68T07, Breast cancer detection, Autoencoders, Deep learning, Imbalanced classification}
}

@article{10.1016/j.ins.2021.05.041,
author = {Kluska, Jacek and Madera, Michal},
title = {Extremely simple classifier based on fuzzy logic and gene expression programming},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {571},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2021.05.041},
doi = {10.1016/j.ins.2021.05.041},
journal = {Inf. Sci.},
month = sep,
pages = {560–579},
numpages = {20},
keywords = {Interpretability, Gene expression programming, Fuzzy rule-based classifier, Data mining, Machine learning}
}

@inproceedings{10.1145/568760.568824,
author = {Denaro, Giovanni and Morasca, Sandro and Pezz\`{e}, Mauro},
title = {Deriving models of software fault-proneness},
year = {2002},
isbn = {1581135564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/568760.568824},
doi = {10.1145/568760.568824},
abstract = {The effectiveness of the software testing process is a key issue for meeting the increasing demand of quality without augmenting the overall costs of software development. The estimation of software fault-proneness is important for assessing costs and quality and thus better planning and tuning the testing process. Unfortunately, no general techniques are available for estimating software fault-proneness and the distribution of faults to identify the correct level of test for the required quality. Although software complexity and testing thoroughness are intuitively related to the costs of quality assurance and the quality of the final product, single software metrics and coverage criteria provide limited help in planning the testing process and assuring the required quality.By using logistic regression, this paper shows how models can be built that relate software measures and software fault-proneness for classes of homogeneous software products. It also proposes the use of cross-validation for selecting valid models even for small data sets.The early results show that it is possible to build statistical models based on historical data for estimating fault-proneness of software modules before testing, and thus better planning and monitoring the testing activities.},
booktitle = {Proceedings of the 14th International Conference on Software Engineering and Knowledge Engineering},
pages = {361–368},
numpages = {8},
keywords = {software testing process, software metrics, software faultiness, logistic regression, fault-proneness models, cross-validation},
location = {Ischia, Italy},
series = {SEKE '02}
}

@inproceedings{10.5555/1890580.1890595,
author = {Zhong, Shi and Khoshgoftaar, Taghi M. and Seliya, Naeem},
title = {Unsupervised learning for expert-based software quality estimation},
year = {2004},
isbn = {0769520944},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Current software quality estimation models often involve using supervised learning methods to train a software quality classifier or a software fault prediction model. In such models, the dependent variable is a software quality measurement indicating the quality of a software module by either a risk-based class membership (e.g., whether it is fault-prone or not fault-prone) or the number of faults. In reality, such a measurement may be inaccurate, or even unavailable. In such situations, this paper advocates the use of unsupervised learning (i.e., clustering) techniques to build a software quality estimation system, with the help of a software engineering human expert. The system first clusters hundreds of software modules into a small number of coherent groups and presents the representative of each group to a software quality expert, who labels each cluster as either fault-prone or not fault-prone based on his domain knowledge as well as some data statistics (without any knowledge of the dependent variable, i.e., the software quality measurement). Our preliminary empirical results show promising potentials of this methodology in both predicting software quality and detecting potential noise in a software measurement and quality dataset.},
booktitle = {Proceedings of the Eighth IEEE International Conference on High Assurance Systems Engineering},
pages = {149–155},
numpages = {7},
location = {Tampa, Florida},
series = {HASE'04}
}

@article{10.1145/3384517,
author = {Kapur, Ritu and Sodhi, Balwinder},
title = {A Defect Estimator for Source Code: Linking Defect Reports with Programming Constructs Usage Metrics},
year = {2020},
issue_date = {April 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3384517},
doi = {10.1145/3384517},
abstract = {An important issue faced during software development is to identify defects and the properties of those defects, if found, in a given source file. Determining defectiveness of source code assumes significance due to its implications on software development and maintenance cost.We present a novel system to estimate the presence of defects in source code and detect attributes of the possible defects, such as the severity of defects. The salient elements of our system are: (i) a dataset of newly introduced source code metrics, called PROgramming CONstruct (PROCON) metrics, and (ii) a novel Machine-Learning (ML)-based system, called Defect Estimator for Source Code (DESCo), that makes use of PROCON dataset for predicting defectiveness in a given scenario. The dataset was created by processing 30,400+ source files written in four popular programming languages, viz., C, C++, Java, and Python.The results of our experiments show that DESCo system outperforms one of the state-of-the-art methods with an improvement of 44.9%. To verify the correctness of our system, we compared the performance of 12 different ML algorithms with 50+ different combinations of their key parameters. Our system achieves the best results with SVM technique with a mean accuracy measure of 80.8%.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {12},
numpages = {35},
keywords = {source code mining, software metrics, software faults and failures, software defect prediction, automated software engineering, Maintaining software, AI in software engineering}
}

@phdthesis{10.5555/1369140,
author = {Challagulla, Venkata Udaya Bhaskar},
advisor = {Bastani, Farokh B.},
title = {A machine learning-based approach for dynamic reliability assessment of mission critical software systems},
year = {2007},
isbn = {9780549270720},
publisher = {University of Texas at Dallas},
address = {USA},
abstract = {Software continues to become more complex and difficult to certify to a high degree of confidence due to the increasing scope and sophistication of the requirements. Consequently, traditional development techniques face growing challenges in satisfying these requirements. Future distributed real-time systems, such as robotic swarm systems, telecontrol systems, and industrial automation systems, may need to dynamically adapt themselves based on the run-time mission-specific requirements and operating conditions. This further compounds the problems of developing highly dependable systems. This is also the case with emerging Service Oriented Architecture (SOA) based systems that perform dynamic discovery of services and reconfiguration and composition of services at run-time. These dynamic features combined with the abstractions provided by the services necessitate the need for high-confidence run-time software reliability assessment techniques. This Dissertation investigates machine learning-based software defect prediction techniques to monitor and assess the services in the synthesized code. Experimental assessment of various prediction algorithms using real-world data shows that memory-based reasoning (MBR) techniques perform relatively better than other methods. Based on these results, a framework is developed to automatically derive the optimal configuration of an MBR classifier for software defect data by logical variations of its configuration parameters. This adaptive MBR technique provides a flexible and effective environment for accurate prediction of mission-critical software defect data. In practice, since these systems are dynamically assembled from existing services, a dearth of sufficient sample data regarding the actual operational environment can reduce the level of confidence in the reliability estimate. The Dissertation investigates the combination of Bayesian Belief Network (BBN) and MBR methodologies to integrate multiple evidences from all the services to obtain high-confidence estimates in the reliability of dynamically assembled mission-critical SOA-based systems. Latent defects in more frequently executed domains affect the reliability of the component much more than the domains tested using random testing strategies. A dynamic monitoring and diagnosis framework is developed to accurately estimate the reliability of the system as it executes. The framework incorporates a Markov model to determine the service reliability from its component reliabilities. This systematic assessment method is evaluated using a simulated system and a real-world case study involving an Enterprise Content Management System. An Intelligent Software Defect Analysis Tool (ISDAT) that implements the above framework is developed, to realize the framework objectives of providing a unified framework for dynamically assessing the reliability of mission-critical SOA-based systems to a high-degree of confidence by using AI-based prediction analysis on the defect metrics data collected from real-time system monitoring.},
note = {AAI3285271}
}

@article{10.1007/s10115-021-01560-w,
author = {Brzezinski, Dariusz and Minku, Leandro L. and Pewinski, Tomasz and Stefanowski, Jerzy and Szumaczuk, Artur},
title = {The impact of data difficulty factors on classification of imbalanced and concept drifting data streams},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {63},
number = {6},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-021-01560-w},
doi = {10.1007/s10115-021-01560-w},
abstract = {Class imbalance introduces additional challenges when learning classifiers from concept drifting data streams. Most existing work focuses on designing new algorithms for dealing with the global imbalance ratio and does not consider other data complexities. Independent research on static imbalanced data has highlighted the influential role of local data difficulty factors such as minority class decomposition and presence of unsafe types of examples. Despite often being present in real-world data, the interactions between concept drifts and local data difficulty factors have not been investigated in concept drifting data streams yet. We thoroughly study the impact of such interactions on drifting imbalanced streams. For this purpose, we put forward a new categorization of concept drifts for class imbalanced problems. Through comprehensive experiments with synthetic and real data streams, we study the influence of concept drifts, global class imbalance, local data difficulty factors, and their combinations, on predictions of representative online classifiers. Experimental results reveal the high influence of new considered factors and their local drifts, as well as differences in existing classifiers’ reactions to such factors. Combinations of multiple factors are the most challenging for classifiers. Although existing classifiers are partially capable of coping with global class imbalance, new approaches are needed to address challenges posed by imbalanced data streams.},
journal = {Knowl. Inf. Syst.},
month = jun,
pages = {1429–1469},
numpages = {41},
keywords = {Stream classification, Drift categorization, Data difficulty factors, Concept drift, Class imbalance}
}

@inproceedings{10.1145/3340482.3342742,
author = {Borg, Markus and Svensson, Oscar and Berg, Kristian and Hansson, Daniel},
title = {SZZ unleashed: an open implementation of the SZZ algorithm - featuring example usage in a study of just-in-time bug prediction for the Jenkins project},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340482.3342742},
doi = {10.1145/3340482.3342742},
abstract = {Machine learning applications in software engineering often rely on detailed information about bugs. While issue trackers often contain information about when bugs were fixed, details about when they were introduced to the system are often absent. As a remedy, researchers often rely on the SZZ algorithm as a heuristic approach to identify bug-introducing software changes. Unfortunately, as reported in a recent systematic literature review, few researchers have made their SZZ implementations publicly available. Consequently, there is a risk that research effort is wasted as new projects based on SZZ output need to initially reimplement the approach. Furthermore, there is a risk that newly developed (closed source) SZZ implementations have not been properly tested, thus conducting research based on their output might introduce threats to validity. We present SZZ Unleashed, an open implementation of the SZZ algorithm for git repositories. This paper describes our implementation along with a usage example for the Jenkins project, and conclude with an illustrative study on just-in-time bug prediction. We hope to continue evolving SZZ Unleashed on GitHub, and warmly invite the community to contribute.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
pages = {7–12},
numpages = {6},
keywords = {mining software repositories, issue tracking, defect prediction, SZZ},
location = {Tallinn, Estonia},
series = {MaLTeSQuE 2019}
}

@article{10.1016/j.jss.2019.110493,
author = {Pascarella, Luca and Palomba, Fabio and Bacchelli, Alberto},
title = {On the performance of method-level bug prediction: A negative result},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {161},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110493},
doi = {10.1016/j.jss.2019.110493},
journal = {J. Syst. Softw.},
month = mar,
numpages = {15},
keywords = {Mining software repositories, Empirical software engineering, Defect prediction}
}

@inproceedings{10.1109/ICST.2010.46,
author = {Silva, Daniel G. e. and Jino, Mario and Abreu, Bruno T. de},
title = {Machine Learning Methods and Asymmetric Cost Function to Estimate Execution Effort of Software Testing},
year = {2010},
isbn = {9780769539904},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICST.2010.46},
doi = {10.1109/ICST.2010.46},
abstract = {Planning and scheduling of testing activities play an important role for any independent test team that performs tests for different software systems, developed by different development teams. This work studies the application of machine learning tools and variable selection tools to solve the problem of estimating the execution effort of functional tests. An analysis of the test execution process is developed and experiments are performed on two real databases. The main contributions of this paper are the approach of selecting the significant variables for database synthesis and the use of an artificial neural network trained with an asymmetric cost function.},
booktitle = {Proceedings of the 2010 Third International Conference on Software Testing, Verification and Validation},
pages = {275–284},
numpages = {10},
keywords = {software testing, prediction, neural networks, estimate, effort, asymmetric function},
series = {ICST '10}
}

@article{10.1016/j.procs.2019.09.156,
author = {Czibula, Gabriela and Mihai, Andrei and Crivei, Liana Maria},
title = {S PRAR: A novel relational association rule mining classification model applied for academic performance prediction},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {159},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.09.156},
doi = {10.1016/j.procs.2019.09.156},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {20–29},
numpages = {10},
keywords = {68P15, Relational association rules 2000 MSC: 68T05, Supervised learning, Students’ performance prediction, Educational data mining}
}

@article{10.1016/j.cogsys.2018.06.001,
author = {Geng, Wang},
title = {RETRACTED: Cognitive Deep Neural Networks prediction method for software fault tendency module based on Bound Particle Swarm Optimization},
year = {2018},
issue_date = {Dec 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {52},
number = {C},
issn = {1389-0417},
url = {https://doi.org/10.1016/j.cogsys.2018.06.001},
doi = {10.1016/j.cogsys.2018.06.001},
journal = {Cogn. Syst. Res.},
month = dec,
pages = {12–20},
numpages = {9}
}

@article{10.1007/s00521-020-05016-0,
author = {Naz, Samina and Majeed, Hammad and Khan, Farrukh Aslam},
title = {Memory augmented hyper-heuristic framework to solve multi-disciplinary problems inspired by cognitive problem solving skills},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {4},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05016-0},
doi = {10.1007/s00521-020-05016-0},
abstract = {This paper proposes a new framework, named Deja-Vu+, which is an extension of Deja Vu framework, a classic study on hyper-heuristic framework with 2R (Record and Recall) modules. Deja-Vu+ has the ability to handle two other domains, namely regression and unsupervised learning. The extension examines the strength of Deja-Vu+ for solving regression and unsupervised learning tasks. The regression problems are treated here as multiclass classification tasks, and unsupervised learning tasks are considered as clustering problems. The proposed framework is tested on a number of regression and unsupervised learning benchmark problems and has shown promising results to handle regression as classification. The framework attains an overall average accuracy of 70% for regression and clustering data sets. Deja-Vu+ is knowledge-rich hyper-heuristic framework, which is capable enough to transfer knowledge successfully. This knowledge transfer improves the performance of learning by avoiding the extensive heuristic search process. Our experimental results show that using previously attained knowledge to reduce the&nbsp;computational effort is beneficial in solving multi-disciplinary machine learning problems.},
journal = {Neural Comput. Appl.},
month = feb,
pages = {1367–1378},
numpages = {12},
keywords = {Deja Vu, Hyper-heuristic framework, K-means clustering, Discretization, Unsupervised learning, Regression, Transfer learning}
}

@inproceedings{10.1109/ICTAI.2006.77,
author = {Zhang, Du},
title = {Machine Learning in Value-Based Software Test Data Generation},
year = {2006},
isbn = {0769527280},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICTAI.2006.77},
doi = {10.1109/ICTAI.2006.77},
abstract = {Software engineering research and practice thus far are primarily conducted in a value-neutral setting where each artifact in software development such as requirement, use case, test case, and defect, is treated as equally important during a software system development process. There are a number of shortcomings of such value-neutral software engineering. Value-based software engineering is to integrate value considerations into the full range of existing and emerging software engineering principles and practices. Machine learning has been playing an increasingly important role in helping develop and maintain large and complex software systems. However, machine learning applications to software engineering have been largely confined to the value-neutral software engineering setting. In this paper, we advocate a shift to applying machine learning methods to value-based software engineering. We propose a framework for value-based software test data generation. The proposed framework incorporates some general principles in value-based software testing and can help improve return on investment.},
booktitle = {Proceedings of the 18th IEEE International Conference on Tools with Artificial Intelligence},
pages = {732–736},
numpages = {5},
keywords = {value-based software test data generation, value-based software engineering, genetic algorithms.},
series = {ICTAI '06}
}

@article{10.1155/2016/7658207,
author = {Tomar, Divya and Agarwal, Sonali},
title = {Prediction of defective software modules using class imbalance learning},
year = {2016},
issue_date = {January 2016},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2016},
issn = {1687-9724},
url = {https://doi.org/10.1155/2016/7658207},
doi = {10.1155/2016/7658207},
abstract = {Software defect predictors are useful to maintain the high quality of software products effectively. The early prediction of defective software modules can help the software developers to allocate the available resources to deliver high quality software products. The objective of software defect prediction system is to find as many defective software modules as possible without affecting the overall performance. The learning process of a software defect predictor is difficult due to the imbalanced distribution of software modules between defective and nondefective classes. Misclassification cost of defective software modules generally incurs much higher cost than the misclassification of nondefective one. Therefore, on considering the misclassification cost issue, we have developed a software defect prediction system using Weighted Least Squares Twin Support Vector Machine (WLSTSVM). This system assigns higher misclassification cost to the data samples of defective classes and lower cost to the data samples of nondefective classes. The experiments on eight software defect prediction datasets have proved the validity of the proposed defect prediction system. The significance of the results has been tested via statistical analysis performed by using nonparametric Wilcoxon signed rank test.},
journal = {Appl. Comp. Intell. Soft Comput.},
month = jan,
articleno = {6},
numpages = {1}
}

@article{10.1155/2019/5901087,
author = {Onan, Aytu\u{g} and Garc\'{\i}a-D\'{\i}az, Vicente},
title = {Consensus Clustering-Based Undersampling Approach to Imbalanced Learning},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1058-9244},
url = {https://doi.org/10.1155/2019/5901087},
doi = {10.1155/2019/5901087},
abstract = {Class imbalance is an important problem, encountered in machine learning applications, where one class (named as, the minority class) has extremely small number of instances and the other class (referred as, the majority class) has immense quantity of instances. Imbalanced datasets can be of great importance in several real-world applications, including medical diagnosis, malware detection, anomaly identification, bankruptcy prediction, and spam filtering. In this paper, we present a consensus clustering based-undersampling approach to imbalanced learning. In this scheme, the number of instances in the majority class was undersampled by utilizing a consensus clustering-based scheme. In the empirical analysis, 44 small-scale and 2 large-scale imbalanced classification benchmarks have been utilized. In the consensus clustering schemes, five clustering algorithms (namely, k-means, k-modes, k-means++, self-organizing maps, and DIANA algorithm) and their combinations were taken into consideration. In the classification phase, five supervised learning methods (namely, na\"{\i}ve Bayes, logistic regression, support vector machines, random forests, and k-nearest neighbor algorithm) and three ensemble learner methods (namely, AdaBoost, bagging, and random subspace algorithm) were utilized. The empirical results indicate that the proposed heterogeneous consensus clustering-based undersampling scheme yields better predictive performance.},
journal = {Sci. Program.},
month = jan,
numpages = {14}
}

@inproceedings{10.1145/2905055.2905123,
author = {Singh, Satwinder and Singla, Rozy},
title = {Comparative Performance of Fault-Prone Prediction Classes with K-means Clustering and MLP},
year = {2016},
isbn = {9781450339629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2905055.2905123},
doi = {10.1145/2905055.2905123},
abstract = {Software defect in today's era is most important in the field of software engineering. Most of the organizations used various techniques to predict defects in their products before they are delivered. Defect prediction techniques help the organizations to use their resources effectively which results in lower cost and time requirements. There are various techniques that are used for predicting defects in software before it has to be delivered. For example clustering, neural networks, support vector machine (SVM) etc. In this paper two defect prediction techniques: - K-means Clustering and Multilayer Perceptron model (MLP), are compared. Both the techniques are implemented on different platforms. K-means clustering is implemented using WEKA tool and MLP is implemented using SPSS. The results are compared to find which algorithm produces better results. In this paper Object-Oriented metrics are used for predicting defects in the software.},
booktitle = {Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies},
articleno = {65},
numpages = {7},
keywords = {Weka, Object-Oriented Metrics, Neural Network, K-means Clustering, Defect prediction},
location = {Udaipur, India},
series = {ICTCS '16}
}

@inproceedings{10.1145/3468264.3478690,
author = {Nagappan, Nachiappan},
title = {The 4ps: product, process, people, and productivity: a data-driven approach to improve software engineering (keynote)},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3478690},
doi = {10.1145/3468264.3478690},
abstract = {In this talk I will provide a broad overview on developer productivity and dive deep into specific analysis related to how product, process and the people impact productivity. I will use examples from industry on effort estimation and defect prediction in product, distributed development in process and the ramp up of new employees in the people category. The talk will also cover interventions via tools and process changes and their impact and discuss future challenges. This talk will be based on previously published work.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {3},
numpages = {1},
keywords = {Empirical Software Engineering, Effort Estimation, Distributed Development, Developer Productivity, Defect Prediction},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.5555/3524938.3525939,
author = {Yasunaga, Michihiro and Liang, Percy},
title = {Graph-based, self-supervised program repair from diagnostic feedback},
year = {2020},
publisher = {JMLR.org},
abstract = {We consider the problem of learning to repair programs from diagnostic feedback (e.g., compiler error messages). Program repair is challenging for two reasons: First, it requires reasoning and tracking symbols across source code and diagnostic feedback. Second, labeled datasets available for program repair are relatively small. In this work, we propose novel solutions to these two challenges. First, we introduce a program-feedback graph, which connects symbols relevant to program repair in source code and diagnostic feedback, and then apply a graph neural network on top to model the reasoning process. Second, we present a self-supervised learning paradigm for program repair that leverages unlabeled programs available online to create a large amount of extra program repair examples, which we use to pre-train our models. We evaluate our proposed approach on two applications: correcting introductory programming assignments (DeepFix dataset) and correcting the outputs of program synthesis (SPoC dataset). Our final system, DrRepair, significantly outperforms prior work, achieving 68.2% full repair rate on DeepFix (+22.9% over the prior best), and 48.4% synthesis success rate on SPoC (+3.7% over the prior best).},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {1001},
numpages = {10},
series = {ICML'20}
}

@article{10.1016/j.micpro.2020.103538,
author = {Li, Liya},
title = {RETRACTED: Software Reliability Growth Fault Correction Model Based on Machine Learning and Neural Network Algorithm},
year = {2021},
issue_date = {Feb 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {80},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2020.103538},
doi = {10.1016/j.micpro.2020.103538},
journal = {Microprocess. Microsyst.},
month = feb,
numpages = {5}
}

@inproceedings{10.1145/3318299.3318337,
author = {Zhang, Zongtang and Chen, Zhe and Dai, Weiguo and Cheng, Yusheng},
title = {An Over-sampling Method Based on Margin Theory},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318337},
doi = {10.1145/3318299.3318337},
abstract = {Imbalanced data widely exists in real life, while the traditional classification method usually takes accuracy as the classification criterion, which is not suitable for the classification of imbalanced data. Resampling is an important method to deal with imbalanced data classification. In this paper, a margin based random over-sampling (MRO) method is proposed, and then MROBoost algorithm is proposed by combining the AdaBoost algorithm. Experimental results on the UCI dataset show that the MROBoost algorithm is superior to AdaBoost for imbalanced data classification problem.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {506–510},
numpages = {5},
keywords = {over-sampling, imbalanced data, Machine learning, AdaBoost},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@inproceedings{10.1007/978-3-030-92708-0_22,
author = {Youssef, Ayman and Abdelrazek, Mohamed and Karmakar, Chandan and Baig, Zubair},
title = {Tracing Software Exploitation},
year = {2021},
isbn = {978-3-030-92707-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-92708-0_22},
doi = {10.1007/978-3-030-92708-0_22},
abstract = {Current exploit detection techniques are designed based on expert observations, manual analysis, and heuristic-like techniques. Because of the manual process for creating such defences, they are usually limited in the number of exploit techniques that can be detected. Machine Learning-based techniques offer greater promise to detect zero-day exploits. Current research in the use of machine learning for unknown attack detection is limited to intrusion detection and malware analysis, limited research is available for the detection of exploits targeting zero-day vulnerabilities using machine learning methods. These limitations stem from the lack of extensive datasets that are tailored for the problem of software exploitation. In this paper, we introduce a method and toolset for creating exploit traces datasets. Our approach allows capturing full traces of benign software under exploitation and recording of the vulnerable threads within an application, providing a comprehensive view of program execution. We evaluated our method and tools on 13 unique and distinct applications and recorded their traces while they were under attack. Our approach was able to successfully trace 53% of the applications and was able to detect the exploit payloads in 71% of the applications that were successfully traced.},
booktitle = {Network and System Security: 15th International Conference, NSS 2021, Tianjin, China, October 23, 2021, Proceedings},
pages = {340–352},
numpages = {13},
keywords = {Machine learning, Dataset, Zero-day, Trace collection, Exploit},
location = {Tianjin, China}
}

@inproceedings{10.1145/3460319.3464840,
author = {Pan, Cong and Pradel, Michael},
title = {Continuous test suite failure prediction},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464840},
doi = {10.1145/3460319.3464840},
abstract = {Continuous integration advocates to run the test suite of a project frequently, e.g., for every code change committed to a shared repository. This process imposes a high computational cost and sometimes also a high human cost, e.g., when developers must wait for the test suite to pass before a change appears in the main branch of the shared repository. However, only 4% of all test suite invocations turn a previously passing test suite into a failing test suite. The question arises whether running the test suite for each code change is really necessary. This paper presents continuous test suite failure prediction, which reduces the cost of continuous integration by predicting whether a particular code change should trigger the test suite at all. The core of the approach is a machine learning model based on features of the code change, the test suite, and the development history. We also present a theoretical cost model that describes when continuous test suite failure prediction is worthwhile. Evaluating the idea with 15k test suite runs from 242 open-source projects shows that the approach is effective at predicting whether running the test suite is likely to reveal a test failure. Moreover, we find that our approach improves the AUC over baselines that use features proposed for just-in-time defect prediction and test case failure prediction by 13.9% and 2.9%, respectively. Overall, continuous test suite failure prediction can significantly reduce the cost of continuous integration.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {553–565},
numpages = {13},
keywords = {machine learning, cost model, continuous test suite failure prediction, continuous integration},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.5555/1337691.1338380,
author = {Briand, Lionel C. and Labiche, Yvan and Liu, Xuetao},
title = {Using Machine Learning to Support Debugging with Tarantula},
year = {2007},
isbn = {0769530249},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Using a specific machine learning technique, this paper proposes a way to identify suspicious statements during debugging. The technique is based on principles similar to Tarantula but addresses its main flaw: its difficulty to deal with the presence of multiple faults as it assumes that failing test cases execute the same fault(s). The improvement we present in this paper results from the use of C4.5 decision trees to identify various failure conditions based on information regarding the test cases' inputs and outputs. Failing test cases executing under similar conditions are then assumed to fail due to the same fault(s). Statements are then considered suspicious if they are covered by a large proportion of failing test cases that execute under similar conditions. We report on a case study that demonstrates improvement over the original Tarantula technique in terms of statement ranking. Another contribution of this paper is to show that failure conditions as modeled by a C4.5 decision tree accurately predict failures and can therefore be used as well to help debugging.},
booktitle = {Proceedings of the The 18th IEEE International Symposium on Software Reliability},
pages = {137–146},
numpages = {10},
series = {ISSRE '07}
}

@article{10.1155/2021/6662932,
author = {Gupta, Mansi and Rajnish, Kumar and Bhattacharjee, Vandana and Gou, Jianping},
title = {Impact of Parameter Tuning for Optimizing Deep Neural Network Models for Predicting Software Faults},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/6662932},
doi = {10.1155/2021/6662932},
abstract = {Deep neural network models built by the appropriate design decisions are crucial to obtain the desired classifier performance. This is especially desired when predicting fault proneness of software modules. When correctly identified, this could help in reducing the testing cost by directing the efforts more towards the modules identified to be fault prone. To be able to build an efficient deep neural network model, it is important that the parameters such as number of hidden layers, number of nodes in each layer, and training details such as learning rate and regularization methods be investigated in detail. The objective of this paper is to show the importance of hyperparameter tuning in developing efficient deep neural network models for predicting fault proneness of software modules and to compare the results with other machine learning algorithms. It is shown that the proposed model outperforms the other algorithms in most cases.},
journal = {Sci. Program.},
month = jan,
numpages = {17}
}

@inproceedings{10.1145/3416505.3423564,
author = {Borovits, Nemania and Kumara, Indika and Krishnan, Parvathy and Palma, Stefano Dalla and Di Nucci, Dario and Palomba, Fabio and Tamburri, Damian A. and van den Heuvel, Willem-Jan},
title = {DeepIaC: deep learning-based linguistic anti-pattern detection in IaC},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423564},
doi = {10.1145/3416505.3423564},
abstract = {Linguistic anti-patterns are recurring poor practices concerning inconsistencies among the naming, documentation, and implementation of an entity. They impede readability, understandability, and maintainability of source code. This paper attempts to detect linguistic anti-patterns in infrastructure as code (IaC) scripts used to provision and manage computing environments. In particular, we consider inconsistencies between the logic/body of IaC code units and their names. To this end, we propose a novel automated approach that employs word embeddings and deep learning techniques. We build and use the abstract syntax tree of IaC code units to create their code embedments. Our experiments with a dataset systematically extracted from open source repositories show that our approach yields an accuracy between 0.785 and 0.915 in detecting inconsistencies.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {7–12},
numpages = {6},
keywords = {Word2Vec, Linguistic Anti-patterns, Infrastructure Code, IaC, Defects, Deep Learning, Code Embedding},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@article{10.1016/j.eswa.2017.04.014,
author = {Rathore, Santosh Singh and Kumar, Sandeep},
title = {Towards an ensemble based system for predicting the number of software faults},
year = {2017},
issue_date = {October 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {82},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2017.04.014},
doi = {10.1016/j.eswa.2017.04.014},
abstract = {Paper presents ensemble based system for the prediction of number of software faults.System is based on the heterogeneous ensemble method.System uses three fault prediction techniques as base learners for the ensemble.Results are verified on Eclipse datasets. Software fault prediction using different techniques has been done by various researchers previously. It is observed that the performance of these techniques varied from dataset to dataset, which make them inconsistent for fault prediction in the unknown software project. On the other hand, use of ensemble method for software fault prediction can be very effective, as it takes the advantage of different techniques for the given dataset to come up with better prediction results compared to individual technique. Many works are available on binary class software fault prediction (faulty or non-faulty prediction) using ensemble methods, but the use of ensemble methods for the prediction of number of faults has not been explored so far. The objective of this work is to present a system using the ensemble of various learning techniques for predicting the number of faults in given software modules. We present a heterogeneous ensemble method for the prediction of number of faults and use a linear combination rule and a non-linear combination rule based approaches for the ensemble. The study is designed and conducted for different software fault datasets accumulated from the publicly available data repositories. The results indicate that the presented system predicted number of faults with higher accuracy. The results are consistent across all the datasets. We also use prediction at level l (Pred(l)), and measure of completeness to evaluate the results. Pred(l) shows the number of modules in a dataset for which average relative error value is less than or equal to a threshold value l. The results of prediction at level l analysis and measure of completeness analysis have also confirmed the effectiveness of the presented system for the prediction of number of faults. Compared to the single fault prediction technique, ensemble methods produced improved performance for the prediction of number of software faults. Main impact of this work is to allow better utilization of testing resources helping in early and quick identification of most of the faults in the software system.},
journal = {Expert Syst. Appl.},
month = oct,
pages = {357–382},
numpages = {26},
keywords = {Software fault prediction techniques, Promise repository, Linear regression, Gradient boosting, Genetic programming, Empirical study}
}

@inproceedings{10.1007/978-3-642-27549-4_49,
author = {Ramler, Rudolf and Natschl\"{a}ger, Thomas},
title = {Applying heuristic approaches for predicting defect-prone software components},
year = {2011},
isbn = {9783642275487},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-27549-4_49},
doi = {10.1007/978-3-642-27549-4_49},
abstract = {Effective and efficient quality assurance has to focus on those parts of a software system that are most likely to fail. Defect prediction promises to indicate the defect-prone components of a software system. In this paper we investigate the viability of predicting defect-prone components in upcoming releases of a large industrial software system. Prediction models constructed with heuristic machine learning are used to classify the components of future versions of the software system as defective or defect-free. It could be shown that the accuracy of the predictions made for the next version is significantly higher (around 74%) than guessing even when taking only new or modified components into account. Furthermore, the results reveal that, depending on the specific prediction model, acceptable accuracy can be achieved for up to three versions in the future.},
booktitle = {Proceedings of the 13th International Conference on Computer Aided Systems Theory - Volume Part I},
pages = {384–391},
numpages = {8},
keywords = {software defect prediction, machine learning},
location = {Las Palmas de Gran Canaria, Spain},
series = {EUROCAST'11}
}

@article{10.1016/j.ins.2021.05.008,
author = {Zhang, Nana and Ying, Shi and Ding, Weiping and Zhu, Kun and Zhu, Dandan},
title = {WGNCS: A robust hybrid cross-version defect model via multi-objective optimization and deep enhanced feature representation},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {570},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2021.05.008},
doi = {10.1016/j.ins.2021.05.008},
journal = {Inf. Sci.},
month = sep,
pages = {545–576},
numpages = {32},
keywords = {Convolutional neural network, Wasserstein GAN with Gradient Penalty, Deep learning techniques, Multi-objective feature selection, Cross-version defect prediction}
}

@article{10.1016/j.eswa.2019.113085,
author = {Pandey, Sushant Kumar and Mishra, Ravi Bhushan and Tripathi, Anil Kumar},
title = {BPDET: An effective software bug prediction model using deep representation and ensemble learning techniques},
year = {2020},
issue_date = {Apr 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113085},
doi = {10.1016/j.eswa.2019.113085},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {22},
keywords = {Heterogeneous Ensemble learning technique, Staked denoising auto-encoder, Boosting, Deep representation, Software metrics, Classification technique, Software bug prediction}
}

@inproceedings{10.1007/978-3-030-41299-9_14,
author = {Ji, Xiaotong and Zheng, Yuchen and Suehiro, Daiki and Uchida, Seiichi},
title = {Optimal Rejection Function Meets Character Recognition Tasks},
year = {2019},
isbn = {978-3-030-41298-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-41299-9_14},
doi = {10.1007/978-3-030-41299-9_14},
abstract = {In this paper, we propose an optimal rejection method for rejecting ambiguous samples by a rejection function. This rejection function is trained together with a classification function under the framework of Learning-with-Rejection (LwR). The highlights of LwR are: (1) the rejection strategy is not heuristic but has a strong background from a machine learning theory, and (2) the rejection function can be trained on an arbitrary feature space which is different from the feature space for classification. The latter suggests we can choose a feature space which is more suitable for rejection. Although the past research on LwR focused only its theoretical aspect, we propose to utilize LwR for practical pattern classification tasks. Moreover, we propose to use features from different CNN layers for classification and rejection. Our extensive experiments of notMNIST classification and character/non-character classification demonstrate that the proposed method achieves better performance than traditional rejection strategies.},
booktitle = {Pattern Recognition: 5th Asian Conference, ACPR 2019, Auckland, New Zealand, November 26–29, 2019, Revised Selected Papers, Part II},
pages = {169–183},
numpages = {15},
keywords = {Theoretical machine learning, Optimal rejection function, Learning with Rejection},
location = {Auckland, New Zealand}
}

@article{10.1016/j.ins.2021.07.053,
author = {Zheng, Ming and Li, Tong and Zheng, Xiaoyao and Yu, Qingying and Chen, Chuanming and Zhou, Ding and Lv, Changlong and Yang, Weiyi},
title = {UFFDFR: Undersampling framework with denoising, fuzzy c-means clustering, and representative sample selection for imbalanced data classification},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {576},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2021.07.053},
doi = {10.1016/j.ins.2021.07.053},
journal = {Inf. Sci.},
month = oct,
pages = {658–680},
numpages = {23},
keywords = {Denoising, Clustering-based undersampling methods, Undersampling methods, Imbalanced data}
}

@inproceedings{10.1145/3177457.3191709,
author = {Ren, Yidan and Zhu, Zhengzhou and Chen, Xiangzhou and Ding, Huixia and Zhang, Geng},
title = {Research on Defect Detection Technology of Trusted Behavior Decision Tree Based on Intelligent Data Semantic Analysis of Massive Data},
year = {2018},
isbn = {9781450363396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3177457.3191709},
doi = {10.1145/3177457.3191709},
abstract = {With the rapid development of information technology, software systems' scales and complexity are showing a trend of expansion. The users' needs for the software security, software security reliability and software stability are growing increasingly. At present, the industry has applied machine learning methods to the fields of defect detection to repair and improve software defects through the massive data intelligent semantic analysis or code scanning. The model in machine learning is faced with big difficulty of model building, understanding, and the poor visualization in the field of traditional software defect detection. In view of the above problems, we present a point of view that intelligent semantic analysis technology based on massive data, and using the trusted behavior decision tree model to analyze the soft behavior by layered detection technology. At the same time, it is equipped related test environment to compare the tested software. The result shows that the defect detection technology based on intelligent semantic analysis of massive data is superior to other techniques at the cost of building time and error reported ratio.},
booktitle = {Proceedings of the 10th International Conference on Computer Modeling and Simulation},
pages = {168–175},
numpages = {8},
keywords = {software defect detection, intelligent semantic analysis, decision tree, Massive data},
location = {Sydney, Australia},
series = {ICCMS '18}
}

@inproceedings{10.1109/MILCOM47813.2019.9021013,
author = {Venkatesan, Sridhar and Newcomb, E. Allison and Hoffman, Blaine and Buchler, Norbou and Youzwak, Jason A. and Sugrim, Shridatt and Chiang, Cho-Yu J. and Poylisher, Alexander and Witkowski, Matthew and Walther, Gary and Wolberg, Michelle and Chadha, Ritu},
title = {VulnerVAN: A Vulnerable Network Generation Tool},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MILCOM47813.2019.9021013},
doi = {10.1109/MILCOM47813.2019.9021013},
abstract = {Cyber training, security testing, and research and development activities are vital to improve the security posture of a network. Currently, many institutions use cyber security testbeds to conduct these activities in an isolated virtual environment. One of the important requirements for such an environment is to provide organizers (or experimenters) with a library of vulnerable network scenarios and capabilities to mount attacks against them. However, the task of preparing a vulnerable network scenario in current testbed environments is costly in time and labor, requires significant support from the testbed staff. To this end, we present a toolset called VulnerVAN that creates a vulnerable network scenario to realize an attack sequence. In this paper, we discuss the design of VulnerVAn - our proof-of-concept implementation on CyberVAN - and present a new high-level attack specification language that enables users to chain attack steps into an attack sequence. For a given attack sequence and network scenario, VulnerVAN identifies all possible attack paths through the network that can realize the attack sequence, and provides instructions to configure machines on an attack path selected by the user. VulnerVAn also provides an attack blueprint that can guide a Red team or an automated attacker to execute the attack sequence. To demonstrate VulnerVAN's capability, we consider the use-case of a typical data exfiltration attack sequence conducted by APTs and study the performance of VulnerVAn in mapping the attack sequence to different networks.},
booktitle = {MILCOM 2019 - 2019 IEEE Military Communications Conference (MILCOM)},
pages = {1–6},
numpages = {6},
location = {Norfolk, VA, USA}
}

@inproceedings{10.1145/2931037.2931039,
author = {Bowes, David and Hall, Tracy and Harman, Mark and Jia, Yue and Sarro, Federica and Wu, Fan},
title = {Mutation-aware fault prediction},
year = {2016},
isbn = {9781450343909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2931037.2931039},
doi = {10.1145/2931037.2931039},
abstract = {We introduce mutation-aware fault prediction, which leverages additional guidance from metrics constructed in terms of mutants and the test cases that cover and detect them. We report the results of 12 sets of experiments, applying 4 different predictive modelling techniques to 3 large real-world systems (both open and closed source). The results show that our proposal can significantly (p ≤ 0.05) improve fault prediction performance. Moreover, mutation-based metrics lie in the top 5% most frequently relied upon fault predictors in 10 of the 12 sets of experiments, and provide the majority of the top ten fault predictors in 9 of the 12 sets of experiments.},
booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
pages = {330–341},
numpages = {12},
keywords = {Software Metrics, Software Fault Prediction, Software Defect Prediction, Mutation Testing, Empirical Study},
location = {Saarbr\"{u}cken, Germany},
series = {ISSTA 2016}
}

@article{10.1016/j.compeleceng.2019.04.011,
author = {G., Geetharamani and J., Arun Pandian},
title = {Identification of plant leaf diseases using a nine-layer deep convolutional neural network},
year = {2019},
issue_date = {Jun 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {76},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.04.011},
doi = {10.1016/j.compeleceng.2019.04.011},
journal = {Comput. Electr. Eng.},
month = jun,
pages = {323–338},
numpages = {16},
keywords = {Transfer learning, Training epoch, Mini batch, Machine learning, Leaf diseases identification, Image augmentation, Dropout, Deep learning, Deep convolutional neural networks, Artificial intelligence}
}

@inproceedings{10.5555/1625275.1625642,
author = {Baskiotis, Nicolas and Sebag, Mich\`{e}le and Gaudel, Marie-Claude and Gouraud, Sandrine},
title = {A machine learning approach for statistical software testing},
year = {2007},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {Some Statistical Software Testing approaches rely on sampling the feasible paths in the control flow graph of the program; the difficulty comes from the tiny ratio of feasible paths. This paper presents an adaptive sampling mechanismcalled EXIST for Exploration/ eXploitation Inference for Software Testing, able to retrieve distinct feasible paths with high probability. EXIST proceeds by alternatively exploiting and updating a distribution on the set of program paths. An original representation of paths, accommodating long-range dependencies and data sparsity and based on extended Parikh maps, is proposed. Experimental validation on real-world and artificial problems demonstrates dramatic improvements compared to the state of the art.},
booktitle = {Proceedings of the 20th International Joint Conference on Artifical Intelligence},
pages = {2274–2279},
numpages = {6},
location = {Hyderabad, India},
series = {IJCAI'07}
}

@inproceedings{10.1145/3474624.3477070,
author = {Martins, Luana and Bezerra, Carla and Costa, Heitor and Machado, Ivan},
title = {Smart prediction for refactorings in the software test code},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3477070},
doi = {10.1145/3474624.3477070},
abstract = {Test smells are bad practices to either design or implement a test code. Their presence may reduce the test code quality, harming the software testing activities, primarily from a maintenance perspective. Therefore, defining strategies and tools to handle test smells and improve the test code quality is necessary. State-of-the-art strategies encompass automated support mainly based on hard thresholds of rules, static and dynamic metrics to identify the test smells. Such thresholds are subjective to interpretation and may not consider the complexity of the software projects. Moreover, they are limited as they do not automate test refactoring but only count on developers’ expertise and intuition. In this context, a technique that uses historical implicit or tacit data to generate knowledge could assist the identification and refactoring of test smells. This study aims to establish a novel approach based on machine learning techniques to suggest developers refactoring strategies for test smells. As an expected result, we could understand the applicability of the machine learning techniques to handle test smells and a framework proposal that helps developers in decision-making regarding the refactoring of test smells.},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {115–120},
numpages = {6},
keywords = {Test Smells, Software Quality, Machine Learning},
location = {Joinville, Brazil},
series = {SBES '21}
}

@article{10.1002/stvr.1594,
author = {Kanewala, Upulee and Bieman, James M. and Ben-Hur, Asa},
title = {Predicting metamorphic relations for testing scientific software: a machine learning approach using graph kernels},
year = {2016},
issue_date = {May 2016},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {26},
number = {3},
issn = {0960-0833},
url = {https://doi.org/10.1002/stvr.1594},
doi = {10.1002/stvr.1594},
abstract = {Comprehensive, automated software testing requires an oracle to check whether the output produced by a test case matches the expected behaviour of the programme. But the challenges in creating suitable oracles limit the ability to perform automated testing in some programmes, and especially in scientific software. Metamorphic testing is a method for automating the testing process for programmes without test oracles. This technique operates by checking whether the programme behaves according to properties called metamorphic relations. A metamorphic relation describes the change in output when the input is changed in a prescribed way. Unfortunately, finding the metamorphic relations satisfied by a programme or function remains a labour-intensive task, which is generally performed by a domain expert or a programmer. In this work, we propose a machine learning approach for predicting metamorphic relations that uses a graph-based representation of a programme to represent control flow and data dependency information. In earlier work, we found that simple features derived from such graphs provide good performance. An analysis of the features used in this earlier work led us to explore the effectiveness of several representations of those graphs using the machine learning framework of graph kernels, which provide various ways of measuring similarity between graphs. Our results show that a graph kernel that evaluates the contribution of all paths in the graph has the best accuracy and that control flow information is more useful than data dependency information. The data used in this study are available for download at http://www.cs.colostate.edu/saxs/MRpred/functions.tar.gz to help researchers in further development of metamorphic relation prediction methods. Copyright © 2015 John Wiley &amp; Sons, Ltd.},
journal = {Softw. Test. Verif. Reliab.},
month = may,
pages = {245–269},
numpages = {25},
keywords = {support vector machines, metamorphic testing, metamorphic relations, graph kernels}
}

@article{10.1007/s00354-021-00124-4,
author = {Karadeniz, Talha and Tokdemir, G\"{u}l and Mara\c{s}, Hadi Hakan},
title = {Ensemble Methods for Heart Disease Prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Ohmsha},
address = {JPN},
volume = {39},
number = {3–4},
issn = {0288-3635},
url = {https://doi.org/10.1007/s00354-021-00124-4},
doi = {10.1007/s00354-021-00124-4},
abstract = {Heart disease prediction is a critical task regarding human health. It is based on deriving an Machine Learning model from medical parameters to predict risk levels. In this work, we propose and test novel ensemble methods for heart disease prediction. Randomness analysis of distance sequences is utilized to derive a classifier, which is served as a base estimator of a bagging scheme. Method is successfully tested on medical Spectf dataset. Additionally, a Graph Lasso and Ledoit–Wolf shrinkage-based classifier is developed for Statlog dataset which is a UCI data. These two algorithms yield comparatively good accuracy results: 88.7 and 88.8 for Spectf and Statlog, respectively. These proposed algorithms provide promising results and novel classification methods that can be utilized in various domains to improve performance of ensemble methods.},
journal = {New Gen. Comput.},
month = nov,
pages = {569–581},
numpages = {13},
keywords = {Weak classifier, Bagging classifier, Mahalanobis distance, Covariance estimator, Heart disease prediction, Ensemble methods, Randomness test}
}

@article{10.1007/s10489-014-0610-5,
author = {Zhang, Xueying and Song, Qinbao and Wang, Guangtao and Zhang, Kaiyuan and He, Liang and Jia, Xiaolin},
title = {A dissimilarity-based imbalance data classification algorithm},
year = {2015},
issue_date = {April     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {42},
number = {3},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-014-0610-5},
doi = {10.1007/s10489-014-0610-5},
abstract = {Class imbalances have been reported to compromise the performance of most standard classifiers, such as Naive Bayes, Decision Trees and Neural Networks. Aiming to solve this problem, various solutions have been explored mainly via balancing the skewed class distribution or improving the existing classification algorithms. However, these methods pay more attention on the imbalance distribution, ignoring the discriminative ability of features in the context of class imbalance data. In this perspective, a dissimilarity-based method is proposed to deal with the classification of imbalanced data. Our proposed method first removes the useless and redundant features by feature selection from the given data set; and then, extracts representative instances from the reduced data as prototypes; finally, projects the reduced data into a dissimilarity space by constructing new features, and builds the classification model with data in the dissimilarity space. Extensive experiments over 24 benchmark class imbalance data sets show that, compared with seven other imbalance data tackling solutions, our proposed method greatly improves the performance of imbalance learning, and outperforms the other solutions with all given classification algorithms.},
journal = {Applied Intelligence},
month = apr,
pages = {544–565},
numpages = {22},
keywords = {Software defect prediction, Prototype selection, Feature selection, Dissimilarity-based classification, Class imbalance}
}

@article{10.1504/IJCAT.2009.026595,
author = {Singh, Yogesh and Kaur, Arvinder and Malhotra, Ruchika},
title = {Comparative analysis of regression and machine learning methods for predicting fault proneness models},
year = {2009},
issue_date = {June 2009},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {35},
number = {2/3/4},
issn = {0952-8091},
url = {https://doi.org/10.1504/IJCAT.2009.026595},
doi = {10.1504/IJCAT.2009.026595},
abstract = {Demand for quality software has undergone rapid growth during the last few years. This is leading to increase in development of machine learning techniques for exploring datasets which can be used in constructing models for predicting quality attributes such as Decision Tree (DT), Support Vector Machine (SVM) and Artificial Neural Network (ANN). This paper examines and compares Logistic Regression (LR), ANN (model predicted in an analogous study using the same dataset), SVM and DT methods. These two methods are explored empirically to find the effect of object-oriented metrics given by Chidamber and Kemerer on the fault proneness of object-oriented system classes. Data collected from Java applications is used in the study. The performance of the methods was compared by Receiver Operating Characteristic (ROC) analysis. DT modelling showed 84.7% of correct classifications of faulty classes and is a better model than the model predicted using LR, SVM and ANN method. The area under the ROC curve of LR, ANN, SVM and DT model is 0.826, 0.85, 0.85 and 0.87, respectively. The paper shows that machine learning methods are useful in constructing software quality models.},
journal = {Int. J. Comput. Appl. Technol.},
month = jun,
pages = {183–193},
numpages = {11},
keywords = {support vector machine, software quality models, receiver operating characteristics curve, object-oriented systems, metrics, machine learning, logistic regression, fault-prone software, decision trees, artificial neural networks, SVM, ANNs}
}

@inproceedings{10.5555/3304889.3305050,
author = {Wang, Nan and Zhao, Xibin and Jiang, Yu and Gao, Yue},
title = {Iterative metric learning for imbalance data classification},
year = {2018},
isbn = {9780999241127},
publisher = {AAAI Press},
abstract = {In many classification applications, the amount of data from different categories usually vary significantly, such as software defect predication and medical diagnosis. Under such circumstances, it is essential to propose a proper method to solve the imbalance issue among the data. However, most of the existing methods mainly focus on improving the performance of classifiers rather than searching for an appropriate way to find an effective data space for classification. In this paper, we propose a method named Iterative Metric Learning (IML) to explore the correlations among the imbalance data and construct an effective data space for classification. Given the imbalance training data, it is important to select a subset of training samples for each testing data. Thus, we aim to find a more stable neighborhood for the testing data using the iterative metric learning strategy. To evaluate the effectiveness of the proposed method, we have conducted experiments on two groups of dataset, i.e., the NASA Metrics Data Program (NASA) dataset and UCI Machine Learning Repository (UCI) dataset. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.},
booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence},
pages = {2805–2811},
numpages = {7},
location = {Stockholm, Sweden},
series = {IJCAI'18}
}

@article{10.1016/j.knosys.2016.12.017,
author = {Rathore, Santosh Singh and Kumar, Sandeep},
title = {Linear and non-linear heterogeneous ensemble methods to predict the number of faults in software systems},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {119},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2016.12.017},
doi = {10.1016/j.knosys.2016.12.017},
abstract = {This paper expands the use of ensemble methods for the prediction of number of faults unlikely the earlier works on ensemble methods that focused on predicting software modules as faulty or non-faulty.This paper investigates the usage of both heterogeneous ensemble methods as well as homogeneous ensemble methods for the prediction of number of faults.We present two linear combination rules and two non-linear combination rules for combining the outputs of the base learners in the ensemble.In addition, we assess the performance of ensemble methods under two different scenarios, intra-release prediction and inter-releases prediction.The experiments are performed over five open-source software systems with their fifteen releases, collected from the PROMISE data repository. Several classification techniques have been investigated and evaluated earlier for the software fault prediction. These techniques have produced different prediction accuracy for the different software systems and none of the technique has always performed consistently better across different domains. On the other hand, software fault prediction using ensemble methods can be very effective, as they take the advantage of each participating technique for the given dataset and try to come up with better prediction results compared to the individual techniques. Many works are available for classifying software modules being faulty or non-faulty using the ensemble methods. These works are only specifying that whether a given software module is faulty or not, but number of faults in that module are not predicted by them. The use of ensemble methods for the prediction of number of faults has not been explored so far. To fulfill this gap, this paper presents ensemble methods for the prediction of number of faults in the given software modules. The experimental study is designed and conducted for five open-source software projects with their fifteen releases, collected from the PROMISE data repository. The results are evaluated under two different scenarios, intra-release prediction and inter-releases prediction. The prediction accuracy of ensemble methods is evaluated using absolute error, relative error, prediction at level l, and measure of completeness performance measures. Results show that the presented ensemble methods yield improved prediction accuracy over the individual fault prediction techniques under consideration. Further, the results are consistent for all the used datasets. The evidences obtained from the prediction at level l and measure of completeness analysis have also confirmed the effectiveness of the proposed ensemble methods for predicting the number of faults.},
journal = {Know.-Based Syst.},
month = mar,
pages = {232–256},
numpages = {25},
keywords = {Software fault prediction, Prediction of number of faults, Heterogeneous ensemble, Ensemble methods}
}

@article{10.1016/j.procs.2019.09.155,
author = {Miholca, Diana-Lucia and Czibula, Gabriela},
title = {DynGRAR: A dynamic approach to mining gradual relational association rules},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {159},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.09.155},
doi = {10.1016/j.procs.2019.09.155},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {10–19},
numpages = {10},
keywords = {68T35, 03B52, gradual relational association rule 2000 MSC: 68T05, data mining, Unuspervised learning}
}

@inproceedings{10.1109/SC.2014.65,
author = {Chen, Zhengzhang and Son, Seung Woo and Hendrix, William and Agrawal, Ankit and Liao, Wei-keng and Choudhary, Alok},
title = {NUMARCK: machine learning algorithm for resiliency and checkpointing},
year = {2014},
isbn = {9781479955008},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC.2014.65},
doi = {10.1109/SC.2014.65},
abstract = {Data checkpointing is an important fault tolerance technique in High Performance Computing (HPC) systems. As the HPC systems move towards exascale, the storage space and time costs of checkpointing threaten to overwhelm not only the simulation but also the post-simulation data analysis. One common practice to address this problem is to apply compression algorithms to reduce the data size. However, traditional lossless compression techniques that look for repeated patterns are ineffective for scientific data in which high-precision data is used and hence common patterns are rare to find. This paper exploits the fact that in many scientific applications, the relative changes in data values from one simulation iteration to the next are not very significantly different from each other. Thus, capturing the distribution of relative changes in data instead of storing the data itself allows us to incorporate the temporal dimension of the data and learn the evolving distribution of the changes. We show that an order of magnitude data reduction becomes achievable within guaranteed user-defined error bounds for each data point.We propose NUMARCK, Northwestern University Machine learning Algorithm for Resiliency and ChecKpointing, that makes use of the emerging distributions of data changes between consecutive simulation iterations and encodes them into an indexing space that can be concisely represented. We evaluate NUMARCK using two production scientific simulations, FLASH and CMIP5, and demonstrate a superior performance in terms of compression ratio and compression accuracy. More importantly, our algorithm allows users to specify the maximum tolerable error on a per point basis, while compressing the data by an order of magnitude.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
pages = {733–744},
numpages = {12},
location = {New Orleans, Louisana},
series = {SC '14}
}

@inproceedings{10.1109/TAIC-PART.2006.15,
author = {Li, Keqin and Groz, Roland and Shahbaz, Muzammil},
title = {Integration Testing of Components Guided by Incremental State Machine Learning},
year = {2006},
isbn = {0769526721},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/TAIC-PART.2006.15},
doi = {10.1109/TAIC-PART.2006.15},
abstract = {The design of complex systems, e.g., telecom services, is nowadays usually based on the integration of components (COTS), loosely coupled in distributed architectures. When components come from third party sources, their internal structure is usually unknown and the documentation is insufficient. Therefore, the system integrator faces the problem of providing a required system assembling COTS whose behaviour is barely specified and for which no model is usually available. In this paper, we address the problem of integration testing of COTS. It combines test generation techniques with machine learning algorithms. Statebased models of components are built from observed behaviours. The models are alternatively used to generate tests and extended to take into account observed behaviour. This process is iterated until a satisfactory level of confidence in testing is achieved.},
booktitle = {Proceedings of the Testing: Academic &amp; Industrial Conference on Practice And Research Techniques},
pages = {59–70},
numpages = {12},
series = {TAIC-PART '06}
}

@inproceedings{10.1145/3412841.3441894,
author = {Gartziandia, Aitor and Arrieta, Aitor and Agirre, Aitor and Sagardui, Goiuria and Arratibel, Maite},
title = {Using regression learners to predict performance problems on software updates: a case study on elevators dispatching algorithms},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3441894},
doi = {10.1145/3412841.3441894},
abstract = {Remote software deployment and updating has long been commonplace in many different fields, but now, the increasing expansion of IoT and CPSoS (Cyber-Physcal System of Systems) has highlighted the need for additional mechanisms in these systems, to ensure the correct behaviour of the deployed software version after deployment. In this sense, this paper investigates the use of Machine Learning algorithms to predict acceptable behaviour in system performance of a new software release. By monitoring the real performance, eventual unexpected problems can be identified. Based on previous knowledge and actual run-time information, the proposed approach predicts the response time that can be considered acceptable for the new software release, and this information is used to identify problematic releases. The mechanism has been applied to the post-deployment monitoring of traffic algorithms in elevator systems. To evaluate the approach, we have used performance mutation testing, obtaining good results. This paper makes two contributions. First, it proposes several regression learners that have been trained with different types of traffic profiles to efficiently predict response time of the traffic dispatching algorithm. This prediction is then compared with the actual response time of the new algorithm release, and provides a verdict about its performance. Secondly, a comparison of the different learners is performed.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {135–144},
numpages = {10},
keywords = {cyber-physical systems, machine learning, performance bugs},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@article{10.1016/j.eswa.2016.06.005,
title = {A multiobjective weighted voting ensemble classifier based on differential evolution algorithm for text sentiment classification},
year = {2016},
issue_date = {November 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {62},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.06.005},
doi = {10.1016/j.eswa.2016.06.005},
abstract = {A novel multi-objective differential evolution algorithm based classifier ensemble for text sentiment classification. An empirical comparison of weighted and unweighted voting schemes. Extensive empirical analysis on metaheuristic based voting schemes for sentiment analysis. High classification accuracies for text sentiment classification (98.86% for Laptop dataset). Typically performed by supervised machine learning algorithms, sentiment analysis is highly useful for extracting subjective information from text documents online. Most approaches that use ensemble learning paradigms toward sentiment analysis involve feature engineering in order to enhance the predictive performance. In response, we sought to develop a paradigm of a multiobjective, optimization-based weighted voting scheme to assign appropriate weight values to classifiers and each output class based on the predictive performance of classification algorithms, all to enhance the predictive performance of sentiment classification. The proposed ensemble method is based on static classifier selection involving majority voting error and forward search, as well as a multiobjective differential evolution algorithm. Based on the static classifier selection scheme, our proposed ensemble method incorporates Bayesian logistic regression, na\"{\i}ve Bayes, linear discriminant analysis, logistic regression, and support vector machines as base learners, whose performance in terms of precision and recall values determines weight adjustment. Our experimental analysis of classification tasks, including sentiment analysis, software defect prediction, credit risk modeling, spam filtering, and semantic mapping, suggests that the proposed classification scheme can predict better than conventional ensemble learning methods such as AdaBoost, bagging, random subspace, and majority voting. Of all datasets examined, the laptop dataset showed the best classification accuracy (98.86%).},
journal = {Expert Syst. Appl.},
month = nov,
pages = {1–16},
numpages = {16}
}

@article{10.1007/s11277-018-5916-x,
author = {Guo, Jun and Tan, Zheng-Hua and Cho, Sung Ho and Zhang, Guoqiang},
title = {Wireless Personal Communications: Machine Learning for Big Data Processing in Mobile Internet},
year = {2018},
issue_date = {October   2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {3},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-018-5916-x},
doi = {10.1007/s11277-018-5916-x},
journal = {Wirel. Pers. Commun.},
month = oct,
pages = {2093–2098},
numpages = {6}
}

@article{10.1016/j.future.2019.05.080,
author = {Zhao, Linchang and Shang, Zhaowei and Qin, Anyong and Zhang, Taiping and Zhao, Ling and Wei, Yu and Tang, Yuan Yan},
title = {A cost-sensitive meta-learning classifier: SPFCNN-Miner},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {100},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.05.080},
doi = {10.1016/j.future.2019.05.080},
journal = {Future Gener. Comput. Syst.},
month = nov,
pages = {1031–1043},
numpages = {13},
keywords = {Data mining, Siamese parallel fully-connected networks, Machine learning, Cost-sensitive learning, Few-shot learning, Meta learning}
}

@article{10.1145/3122787,
author = {Balkan, Ayca and Tabuada, Paulo and Deshmukh, Jyotirmoy V. and Jin, Xiaoqing and Kapinski, James},
title = {Underminer: A Framework for Automatically Identifying Nonconverging Behaviors in Black-Box System Models},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {1539-9087},
url = {https://doi.org/10.1145/3122787},
doi = {10.1145/3122787},
abstract = {Evaluation of industrial embedded control system designs is a time-consuming and imperfect process. While an ideal process would apply a formal verification technique such as model checking or theorem proving, these techniques do not scale to industrial design problems, and it is often difficult to use these techniques to verify performance aspects of control system designs, such as stability or convergence. For industrial designs, engineers rely on testing processes to identify critical or unexpected behaviors. We propose a novel framework called Underminer to improve the testing process; this is an automated technique to identify nonconverging behaviors in embedded control system designs. Underminer treats the system as a black box and lets the designer indicate the model parameters, inputs, and outputs that are of interest. It differentiates convergent from nonconvergent behaviors using Convergence Classifier Functions (CCFs).The tool can be applied in the context of testing models created late in the controller development stage, where it assumes that the given model displays mostly convergent behavior and learns a CCF in an unsupervised fashion from such convergent model behaviors. This CCF is then used to guide a thorough exploration of the model with the help of optimization-guided techniques or adaptive sampling techniques, with the goal of identifying rare nonconvergent model behaviors. Underminer can also be used early in the development stage, where models may have some significant nonconvergent behaviors. Here, the framework permits designers to indicate their mental model for convergence by labeling behaviors as convergent/nonconvergent and then constructs a CCF using a supervised learning technique. In this use case, the goal is to use the CCF to test an improved design for the model. Underminer supports a number of convergence-like notions, such as those based on Lyapunov analysis and temporal logic, and also CCFs learned directly from labeled output behaviors using machine-learning techniques such as support vector machines and neural networks. We demonstrate the efficacy of Underminer by evaluating its performance on several academic as well as industrial examples.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = dec,
articleno = {20},
numpages = {28},
keywords = {stability, machine learning, formal methods, Automatic testing}
}

@article{10.1016/j.neucom.2011.08.040,
author = {Wang, Huanjing and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {Software measurement data reduction using ensemble techniques},
year = {2012},
issue_date = {September, 2012},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {92},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2011.08.040},
doi = {10.1016/j.neucom.2011.08.040},
abstract = {Software defect prediction models are used to identify program modules that are high-risk, or likely to have a high number of faults. These models are built using software metrics which are collected during the software development process. Various techniques and approaches have been created for improving fault predictions. One of these is feature (metric) selection. Choosing the most important features is important to improve the effectiveness of defect predictors. However, using a single feature subset selection method may generate local optima. Ensembles of feature selection methods attempt to combine multiple feature selection methods instead of using a single one. In this paper, we present a comprehensive empirical study examining 17 different ensembles of feature ranking techniques (rankers) including six commonly used feature ranking techniques, the signal-to-noise filter technique, and 11 threshold-based feature ranking techniques. This study utilized 16 real-world software measurement data sets of different sizes and built 54,400 classification models using four well known classifiers. The main conclusion is that ensembles of very few rankers are very effective and even better than ensembles of many or all rankers.},
journal = {Neurocomput.},
month = sep,
pages = {124–132},
numpages = {9},
keywords = {Feature selection, Ensembles of feature ranking techniques, Defect prediction}
}

@article{10.1007/s10664-021-10004-6,
author = {Quach, Sophia and Lamothe, Maxime and Adams, Bram and Kamei, Yasutaka and Shang, Weiyi},
title = {Evaluating the impact of falsely detected performance bug-inducing changes in JIT models},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-10004-6},
doi = {10.1007/s10664-021-10004-6},
abstract = {Performance bugs bear a heavy cost on both software developers and end-users. Tools to reduce the occurrence, impact, and repair time of performance bugs, can therefore provide key assistance for software developers racing to fix these bugs. Classification models that focus on identifying defect-prone commits, referred to as Just-In-Time (JIT) Quality Assurance are known to be useful in allowing developers to review risky commits. These commits can be reviewed while they are still fresh in developers’ minds, reducing the costs of developing high-quality software. JIT models, however, leverage the SZZ approach to identify whether or not a change is bug-inducing. The fixes to performance bugs may be scattered across the source code, separated from their bug-inducing locations. The nature of performance bugs may make SZZ a sub-optimal approach for identifying their bug-inducing commits. Yet, prior studies that leverage or evaluate the SZZ approach do not distinguish performance bugs from other bugs, leading to potential bias in the results. In this paper, we conduct an empirical study on the JIT defect prediction for performance bugs. We concentrate on SZZ’s ability to identify the bug-inducing commits of performance bugs in two open-source projects, Cassandra, and Hadoop. We verify whether the bug-inducing commits found by SZZ are truly bug-inducing commits by manually examining these identified commits. Our manual examination includes cross referencing fix commits and JIRA bug reports. We evaluate model performance for JIT models by using them to identify bug-inducing code commits for performance related bugs. Our findings show that JIT defect prediction classifies non-performance bug-inducing commits better than performance bug-inducing commits, i.e., the SZZ approach does introduce errors when identifying bug-inducing commits. However, we find that manually correcting these errors in the training data only slightly improves the models. In the absence of a large number of correctly labelled performance bug-inducing commits, our findings show that combining all available training data (i.e., truly performance bug-inducing commits, non-performance bug-inducing commits, and non-bug-inducing commits) yields the best classification results.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {32},
keywords = {Performance, Just-in-time, Defect prediction bugs, Software engineering}
}

@inproceedings{10.1007/978-3-030-29551-6_57,
author = {Lahsoumi, Abir and Elouedi, Zied},
title = {Evidential Artificial Immune Recognition System},
year = {2019},
isbn = {978-3-030-29550-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-29551-6_57},
doi = {10.1007/978-3-030-29551-6_57},
abstract = {Uncertainty is one of the main classification issues that must be handled carefully and not rejected in order to make better decisions. Artificial immune recognition system (AIRS) is an immune-inspired supervised learning classifier that has shown good and competitive classification results. It works perfectly in a certain context, however it is quite the opposite in an environment pervaded with uncertainty. To overcome this limitation, we propose a new approach combining the AIRS and belief function theory one of the well-know theories managing uncertainty. Experimentations on real data sets from the U.C.I machine learning repository show good performances of the proposed approach.},
booktitle = {Knowledge Science, Engineering and Management: 12th International Conference, KSEM 2019, Athens, Greece, August 28–30, 2019, Proceedings, Part I},
pages = {643–654},
numpages = {12},
keywords = {Belief function theory, Uncertainty, Classification, Artificial immune recognition system (AIRS)},
location = {Athens, Greece}
}

@inproceedings{10.1145/3172871.3172872,
author = {Kumar, Lov and Sureka, Ashish},
title = {Feature Selection Techniques to Counter Class Imbalance Problem for Aging Related Bug Prediction: Aging Related Bug Prediction},
year = {2018},
isbn = {9781450363983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3172871.3172872},
doi = {10.1145/3172871.3172872},
abstract = {Aging-Related Bugs (ARBs) occur in long running systems due to error conditions caused because of accumulation of problems such as memory leakage or unreleased files and locks. Aging-Related Bugs are hard to discover during software testing and also challenging to replicate. Automatic identification and prediction of aging related fault-prone files and classes in an object oriented system can help the software quality assurance team to optimize their testing efforts. In this paper, we present a study on the application of static source code metrics and machine learning techniques to predict aging related bugs. We conduct a series of experiments on publicly available dataset from two large open-source software systems: Linux and MySQL. Class imbalance and high dimensionality are the two main technical challenges in building effective predictors for aging related bugs.We investigate the application of five different feature selection techniques (OneR, Information Gain, Gain Ratio, RELEIF and Symmetric Uncertainty) for dimensionality reduction and five different strategies (Random Under-sampling, Random Oversampling, SMOTE, SMOTEBoost and RUSBoost) to counter the effect of class imbalance in our proposed machine learning based solution approach. Experimental results reveal that the random under-sampling approach performs best followed by RUSBoost in-terms of the mean AUC metric. Statistical significance test demonstrates that there is a significant difference between the performance of the various feature selection techniques. Experimental results shows that Gain Ratio and RELEIF performs best in comparison to other strategies to address the class imbalance problem. We infer from the statistical significance test that there is no difference between the performances of the five different learning algorithms.},
booktitle = {Proceedings of the 11th Innovations in Software Engineering Conference},
articleno = {2},
numpages = {11},
keywords = {Source Code Metrics, Software Maintenance, Predictive Modeling, Machine Learning, Imbalance Learning, Feature Selection Techniques, Empirical Software Engineering, Aging Related Bugs},
location = {Hyderabad, India},
series = {ISEC '18}
}

@inproceedings{10.1145/3106237.3106258,
author = {Wang, Song and Nam, Jaechang and Tan, Lin},
title = {QTEP: quality-aware test case prioritization},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106258},
doi = {10.1145/3106237.3106258},
abstract = {Test case prioritization (TCP) is a practical activity in software testing for exposing faults earlier. Researchers have proposed many TCP techniques to reorder test cases. Among them, coverage-based TCPs have been widely investigated. Specifically, coverage-based TCP approaches leverage coverage information between source code and test cases, i.e., static code coverage and dynamic code coverage, to schedule test cases. Existing coverage-based TCP techniques mainly focus on maximizing coverage while often do not consider the likely distribution of faults in source code. However, software faults are not often equally distributed in source code, e.g., around 80% faults are located in about 20% source code. Intuitively, test cases that cover the faulty source code should have higher priorities, since they are more likely to find faults.  In this paper, we present a quality-aware test case prioritization technique, QTEP, to address the limitation of existing coverage-based TCP algorithms. In QTEP, we leverage code inspection techniques, i.e., a typical statistic defect prediction model and a typical static bug finder, to detect fault-prone source code and then adapt existing coverage-based TCP algorithms by considering the weighted source code in terms of fault-proneness. Our evaluation with 16 variant QTEP techniques on 33 different versions of 7 open source Java projects shows that QTEP could improve existing coverage-based TCP techniques for both regression and new test cases. Specifically, the improvement of the best variant of QTEP for regression test cases could be up to 15.0% and on average 7.6%, and for all test cases (both regression and new test cases), the improvement could be up to 10.0% and on average 5.0%.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {523–534},
numpages = {12},
keywords = {static bug finder, defect prediction, Test case prioritization},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@article{10.1504/IJICS.2007.012246,
author = {Helmer, Guy and Wong, Johnny and Slagell, Mark and Honavar, Vasant and Miller, Les and Wang, Yanxin and Wang, Xia and Stakhanova, Natalia},
title = {Software fault tree and coloured Petri net based specification, design and implementation of agent-based intrusion detection systems},
year = {2007},
issue_date = {January 2007},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {1},
number = {1/2},
issn = {1744-1765},
url = {https://doi.org/10.1504/IJICS.2007.012246},
doi = {10.1504/IJICS.2007.012246},
abstract = {The integration of Software Fault Tree (SFT), which describes intrusions and Coloured Petri Nets (CPNs) that specifies design, is examined for an Intrusion Detection System (IDS). The IDS under development is a collection of mobile agents that detect, classify, and correlate the system and network activities. SFTs, augmented with nodes that describe trust, temporal and contextual relationships, are used to describe intrusions. CPNs for intrusion detection are built using CPN templates created from the augmented SFTs. Hierarchical CPNs are created to detect critical stages of intrusions. The agentbased implementation of the IDS is then constructed from the CPNs. Examples of intrusions and descriptions of the prototype implementation are used to demonstrate how the CPN approach has been used in the development of the IDS. The main contribution of this paper is an approach to systematic specification, design and implementation of an IDS; Innovations include (1) using stages of intrusions to structure the specification and design of the IDS; (2) augmentation of SFT with trust, temporal and contextual nodes to model intrusions; (3) algorithmic construction of CPNs from augmented SFT; and (4) generation of mobile agents from CPNs.},
journal = {Int. J. Inf. Comput. Secur.},
month = jan,
pages = {109–142},
numpages = {34},
keywords = {software fault tree analysis, multi-agent systems, mobile agents, intrusion detection systems, information security, computer security, coloured Petri nets, agent-based systems}
}

@inproceedings{10.1145/3236024.3236050,
author = {Chen, Di and Fu, Wei and Krishna, Rahul and Menzies, Tim},
title = {Applications of psychological science for actionable analytics},
year = {2018},
isbn = {9781450355735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236024.3236050},
doi = {10.1145/3236024.3236050},
abstract = {According to psychological scientists, humans understand models that most match their own internal models, which they characterize as lists of "heuristic"s (i.e. lists of very succinct rules). One such heuristic rule generator is the Fast-and-Frugal Trees (FFT) preferred by psychological scientists. Despite their successful use in many applied domains, FFTs have not been applied in software analytics. Accordingly, this paper assesses FFTs for software analytics.  We find that FFTs are remarkably effective in that their models are very succinct (5 lines or less describing a binary decision tree) while also outperforming result from very recent, top-level, conference papers. Also, when we restrict training data to operational attributes (i.e., those attributes that are frequently changed by developers), the performance of FFTs are not effected (while the performance of other learners can vary wildly).  Our conclusions are two-fold. Firstly, there is much that software analytics community could learn from psychological science. Secondly, proponents of complex methods should always baseline those methods against simpler alternatives. For example, FFTs could be used as a standard baseline learner against which other software analytics tools are compared.},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {456–467},
numpages = {12},
keywords = {software analytics, psychological science, heuristics, empirical studies, defect prediction, Decision trees},
location = {Lake Buena Vista, FL, USA},
series = {ESEC/FSE 2018}
}

@inproceedings{10.1145/3348445.3348453,
author = {Cynthia, Shamse Tasnim and Ripon, Shamim H.},
title = {Predicting and Classifying Software Faults: A Data Mining Approach},
year = {2019},
isbn = {9781450371957},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3348445.3348453},
doi = {10.1145/3348445.3348453},
abstract = {In the field of software engineering, the detection of fault in the software has become a major topic to explore. With the help of data mining and machine learning approaches, this paper aims to denote whether a software is fault prone or not. In order to accomplish that this paper gives importance to compare between different machine learning approaches and by observing their performances we can conclude which models perform better to detect fault in the selected software modules. The dataset we have chosen to work on has imbalanced data. This paper research also worked with the imbalanced dataset and what results the imbalanced dataset gave when examined. The accuracy comparison, the performance of the different metrics can broadly help in software defect detection mechanism.},
booktitle = {Proceedings of the 7th International Conference on Computer and Communications Management},
pages = {143–147},
numpages = {5},
keywords = {prediction, data mining, association rules, Software faults, SVM, Adaboost},
location = {Bangkok, Thailand},
series = {ICCCM '19}
}

@article{10.1016/j.eswa.2021.114810,
author = {Demirci, Mustafa Yusuf and Be\c{s}li, Nurettin and G\"{u}m\"{u}\c{s}\c{c}\"{u}, Abd\"{u}lkadir},
title = {Efficient deep feature extraction and classification for identifying defective photovoltaic module cells in Electroluminescence images},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {175},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114810},
doi = {10.1016/j.eswa.2021.114810},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {15},
keywords = {Deep learning, Deep features, Feature selection, Feature extraction, Defect detection, Electroluminescence imaging}
}

@article{10.1016/j.compeleceng.2021.107433,
author = {Hirakawa, Rin and Uchida, Hironori and Nakano, Asato and Tominaga, Keitaro and Nakatoh, Yoshihisa},
title = {Anomaly detection on software log based on Temporal Memory},
year = {2021},
issue_date = {Oct 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {95},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107433},
doi = {10.1016/j.compeleceng.2021.107433},
journal = {Comput. Electr. Eng.},
month = oct,
numpages = {12},
keywords = {Defect analysis, Time series pattern, Unsupervised learning, Temporal memory, Software log, Anomaly detection}
}

@article{10.1007/s13748-021-00236-4,
author = {Raghuwanshi, Bhagat Singh and Shukla, Sanyam},
title = {Classifying multiclass imbalanced data using generalized class-specific extreme learning machine},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {10},
number = {3},
url = {https://doi.org/10.1007/s13748-021-00236-4},
doi = {10.1007/s13748-021-00236-4},
abstract = {Learning from the imbalanced problem is among the most attractive issues in the contemporary machine learning community. However, the extensive majority of attention in this domain is given to the two-class imbalanced problems, while their much more complex multiclass counterparts are comparatively unexplored. It has been shown (Huang et al. in IEEE Trans Syst Man Cybern B (Cybern) 42(2):513–529, 2012) that extreme learning machine (ELM) achieves much better generalization performance compared to support vector machine (SVM) and least-squares support vector machine (LS-SVM) for multiclass classification problems. On this account, this work proposes a novel generalized class-specific extreme learning machine (GCS-ELM), the extension of our recently proposed, class-specific extreme learning machine (CS-ELM) to address the multiclass imbalanced problems more effectively. The proposed GCS-ELM can be applied directly to the multiclass imbalance problems. The proposed method also has reduced computational cost compared to the weighted extreme learning machine (WELM) for multiclass imbalance problems. The proposed method uses class-specific regularization coefficients, which are computed by employing class distribution. The proposed method has lower computational overhead compared to the class-specific cost regulation extreme learning machine (CCR-ELM). The proposed work is assessed by using benchmark real-world imbalanced datasets downloaded from the well-known KEEL dataset repository and synthetic datasets. The experimental results, supported by the extensive statistical analysis, demonstrate that GCS-ELM is capable to improve the generalization performance for multiclass imbalanced classification problems.},
journal = {Prog. in Artif. Intell.},
month = sep,
pages = {259–281},
numpages = {23},
keywords = {Classification, Multiclass imbalance problem, Generalized class-specific extreme learning machine, Extreme learning machine}
}

@inproceedings{10.1145/3001867.3001874,
author = {Queiroz, Rodrigo and Berger, Thorsten and Czarnecki, Krzysztof},
title = {Towards predicting feature defects in software product lines},
year = {2016},
isbn = {9781450346474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3001867.3001874},
doi = {10.1145/3001867.3001874},
abstract = {Defect-prediction techniques can enhance the quality assurance activities for software systems. For instance, they can be used to predict bugs in source files or functions. In the context of a software product line, such techniques could ideally be used for predicting defects in features or combinations of features, which would allow developers to focus quality assurance on the error-prone ones. In this preliminary case study, we investigate how defect prediction models can be used to identify defective features using machine-learning techniques. We adapt process metrics and evaluate and compare three classifiers using an open-source product line. Our results show that the technique can be effective. Our best scenario achieves an accuracy of 73 % for accurately predicting features as defective or clean using a Naive Bayes classifier. Based on the results we discuss directions for future work.},
booktitle = {Proceedings of the 7th International Workshop on Feature-Oriented Software Development},
pages = {58–62},
numpages = {5},
keywords = {software product lines, features, defect prediction},
location = {Amsterdam, Netherlands},
series = {FOSD 2016}
}

@inproceedings{10.1145/3338906.3340442,
author = {Barash, Guy and Farchi, Eitan and Jayaraman, Ilan and Raz, Orna and Tzoref-Brill, Rachel and Zalmanovici, Marcel},
title = {Bridging the gap between ML solutions and their business requirements using feature interactions},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3340442},
doi = {10.1145/3338906.3340442},
abstract = {Machine Learning (ML) based solutions are becoming increasingly popular and pervasive. When testing such solutions, there is a tendency to focus on improving the ML metrics such as the F1-score and accuracy at the expense of ensuring business value and correctness by covering business requirements. In this work, we adapt test planning methods of classical software to ML solutions. We use combinatorial modeling methodology to define the space of business requirements and map it to the ML solution data, and use the notion of data slices to identify the weaker areas of the ML solution and strengthen them. We apply our approach to three real-world case studies and demonstrate its value.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1048–1058},
numpages = {11},
keywords = {Software Testing, Machine Learning, Combinatorial Modeling},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/3218603.3218624,
author = {Zhang, Sheng and Tang, Adrian and Jiang, Zhewei and Sethumadhavan, Simha and Seok, Mingoo},
title = {Blacklist Core: Machine-Learning Based Dynamic Operating-Performance-Point Blacklisting for Mitigating Power-Management Security Attacks},
year = {2018},
isbn = {9781450357043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3218603.3218624},
doi = {10.1145/3218603.3218624},
abstract = {Most modern computing devices make available fine-grained control of operating frequency and voltage for power management. These interfaces, as demonstrated by recent attacks, open up a new class of software fault injection attacks that compromise security on commodity devices. CLKSCREW, a recently-published attack that stretches the frequency of devices beyond their operational limits to induce faults, is one such attack. Statically and permanently limiting frequency and voltage modulation space, i.e., guard-banding, could mitigate such attacks but it incurs large performance degradation and long testing time. Instead, in this paper, we propose a run-time technique which dynamically blacklists unsafe operating performance points using a neural-net model. The model is first trained offline in the design time and then subsequently adjusted at run-time by inspecting a selected set of features such as power management control registers, timing-error signals, and core temperature. We designed the algorithm and hardware, titled a BlackList (BL) core, which is capable of detecting and mitigating such power management-based security attack at high accuracy. The BL core incurs a reasonably small amount of overhead in power, delay, and area.},
booktitle = {Proceedings of the International Symposium on Low Power Electronics and Design},
articleno = {5},
numpages = {6},
keywords = {power management, operating performance point, blacklist, Security},
location = {Seattle, WA, USA},
series = {ISLPED '18}
}

@article{10.1007/s11219-007-9013-8,
author = {Seliya, Naeem and Khoshgoftaar, Taghi M.},
title = {Software quality estimation with limited fault data: a semi-supervised learning perspective},
year = {2007},
issue_date = {September 2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-007-9013-8},
doi = {10.1007/s11219-007-9013-8},
abstract = {We addresses the important problem of software quality analysis when there is limited software fault or fault-proneness data. A software quality model is typically trained using software measurement and fault data obtained from a previous release or similar project. Such an approach assumes that fault data is available for all the training modules. Various issues in software development may limit the availability of fault-proneness data for all the training modules. Consequently, the available labeled training dataset is such that the trained software quality model may not provide predictions. More specifically, the small set of modules with known fault-proneness labels is not sufficient for capturing the software quality trends of the project. We investigate semi-supervised learning with the Expectation Maximization (EM) algorithm for software quality estimation with limited fault-proneness data. The hypothesis is that knowledge stored in software attributes of the unlabeled program modules will aid in improving software quality estimation. Software data collected from a large NASA software project is used during the semi-supervised learning process. The software quality model is evaluated with multiple test datasets collected from other NASA software projects. Compared to software quality models trained only with the available set of labeled program modules, the EM-based semi-supervised learning scheme improves generalization performance of the software quality models.},
journal = {Software Quality Journal},
month = sep,
pages = {327–344},
numpages = {18},
keywords = {Unlabeled data, Software quality estimation, Software metrics, Semi-supervised learning, Expectation maximization}
}

@inproceedings{10.1007/978-3-030-91265-9_11,
author = {Wei, Shaozhi and Mo, Ran and Xiong, Pu and Zhang, Siyuan and Zhao, Yang and Li, Zengyang},
title = {Predicting and Monitoring Bug-Proneness at the Feature Level},
year = {2021},
isbn = {978-3-030-91264-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91265-9_11},
doi = {10.1007/978-3-030-91265-9_11},
abstract = {Enabling quick feature modification and delivery is important for a project’s success. Obtaining early estimates of software features’ bug-proneness is helpful for effectively allocating resources to the bug-prone features requiring further fixes. Researchers have proposed various studies on bug prediction at different granularity levels, such as class level, package level, method level, etc. However, there exists little work building predictive models at the feature level. In this paper, we investigated how to predict bug-prone features and monitor their evolution. More specifically, we first identified a project’s features and their involved files. Next, we collected a suite of code metrics and selected a relevant set of metrics as attributes to be used for six machine learning algorithms to predict bug-prone features. Through our evaluation, we have presented that using the machine learning algorithms with an appropriate set of code metrics, we can build effective models of bug prediction at the feature level. Furthermore, we build regression models to monitor growth trends of bug-prone features, which shows how these features accumulate bug-proneness over time.},
booktitle = {Dependable Software Engineering. Theories, Tools, and Applications: 7th International Symposium, SETTA 2021, Beijing, China, November 25–27, 2021, Proceedings},
pages = {201–218},
numpages = {18},
keywords = {Feature bug prediction, Machine learning, Code metrics},
location = {Beijing, China}
}

@inproceedings{10.1145/3442167.3442177,
author = {Spring, Jonathan M. and Galyardt, April and Householder, Allen D. and VanHoudnos, Nathan},
title = {On managing vulnerabilities in AI/ML systems},
year = {2021},
isbn = {9781450389952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442167.3442177},
doi = {10.1145/3442167.3442177},
abstract = {This paper explores how the current paradigm of vulnerability management might adapt to include machine learning systems through a thought experiment: what if flaws in machine learning (ML) were assigned Common Vulnerabilities and Exposures (CVE) identifiers (CVE-IDs)? We consider both ML algorithms and model objects. The hypothetical scenario is structured around exploring the changes to the six areas of vulnerability management: discovery, report intake, analysis, coordination, disclosure, and response. While algorithm flaws are well-known in academic research community, there is no apparent clear line of communication between this research community and the operational communities that deploy and manage systems that use ML. The thought experiments identify some ways in which CVE-IDs may establish some useful lines of communication between these two communities. In particular, it would start to introduce the research community to operational security concepts, which appears to be a gap left by existing efforts.},
booktitle = {Proceedings of the New Security Paradigms Workshop 2020},
pages = {111–126},
numpages = {16},
keywords = {vulnerability management, prioritization, machine learning, CVE-ID},
location = {Online, USA},
series = {NSPW '20}
}

@article{10.1007/s10664-019-09778-7,
author = {Titcheu Chekam, Thierry and Papadakis, Mike and Bissyand\'{e}, Tegawend\'{e} F. and Le Traon, Yves and Sen, Koushik},
title = {Selecting fault revealing mutants},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09778-7},
doi = {10.1007/s10664-019-09778-7},
abstract = {Mutant selection refers to the problem of choosing, among a large number of mutants, the (few) ones that should be used by the testers. In view of this, we investigate the problem of selecting the fault revealing mutants, i.e., the mutants that are killable and lead to test cases that uncover unknown program faults. We formulate two variants of this problem: the fault revealing mutant selection and the fault revealing mutant prioritization. We argue and show that these problems can be tackled through a set of ‘static’ program features and propose a machine learning approach, named FaRM, that learns to select and rank killable and fault revealing mutants. Experimental results involving 1,692 real faults show the practical benefits of our approach in both examined problems. Our results show that FaRM achieves a good trade-off between application cost and effectiveness (measured in terms of faults revealed). We also show that FaRM outperforms all the existing mutant selection methods, i.e., the random mutant sampling, the selective mutation and defect prediction (mutating the code areas pointed by defect prediction). In particular, our results show that with respect to mutant selection, our approach reveals 23% to 34% more faults than any of the baseline methods, while, with respect to mutant prioritization, it achieves higher average percentage of revealed faults with a median difference between 4% and 9% (from the random mutant orderings).},
journal = {Empirical Softw. Engg.},
month = jan,
pages = {434–487},
numpages = {54},
keywords = {Mutant prioritization, Mutant selection, Machine learning, Mutation testing}
}

@inproceedings{10.1109/ESEM.2017.49,
author = {Bin, Yi and Zhou, Kai and Lu, Hongmin and Zhou, Yuming and Xu, Baowen},
title = {Training data selection for cross-project defection prediction: which approach is better?},
year = {2017},
isbn = {9781509040391},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ESEM.2017.49},
doi = {10.1109/ESEM.2017.49},
abstract = {Background: Many relevancy filters have been proposed to select training data for building cross-project defect prediction (CPDP) models. However, up to now, there is no consensus about which relevancy filter is better for CPDP. Goal: In this paper, we conduct a thorough experiment to compare nine relevancy filters proposed in the recent literature. Method: Based on 33 publicly available data sets, we compare not only the retaining ratio of the original training data and the overlapping degree among the retained data but also the prediction performance of the resulting CPDP models under the ranking and classification scenarios. Results: In terms of retaining ratio and overlapping degree, there are important differences among these filters. According to the defect prediction performance, global filter always stays in the first level. Conclusions: For practitioners, it appears that there is no need to filter source project data, as this may lead to better defect prediction results.},
booktitle = {Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {354–363},
numpages = {10},
keywords = {model, filter, defect prediction, cross-project},
location = {Markham, Ontario, Canada},
series = {ESEM '17}
}

@inproceedings{10.1145/3278142.3278145,
author = {Tu, Huy and Nair, Vivek},
title = {Is one hyperparameter optimizer enough?},
year = {2018},
isbn = {9781450360562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278142.3278145},
doi = {10.1145/3278142.3278145},
abstract = {Hyperparameter tuning is the black art of automatically finding a good combination of control parameters for a data miner. While widely applied in empirical Software Engineering, there has not been much discussion on which hyperparameter tuner is best for software analytics.To address this gap in the literature, this paper applied a range of hyperparameter optimizers (grid search, random search, differential evolution, and Bayesian optimization) to a defect prediction problem. Surprisingly, no hyperparameter optimizer was observed to be “best” and, for one of the two evaluation measures studied here (F-measure), hyperparameter optimization, in 50% of cases, was no better than using default configurations. We conclude that hyperparameter optimization is more nuanced than previously believed. While such optimization can certainly lead to large improvements in the performance of classifiers used in software analytics, it remains to be seen which specific optimizers should be applied to a new dataset.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Software Analytics},
pages = {19–25},
numpages = {7},
keywords = {SBSE, Hyperparameter Tuning, Defect Prediction},
location = {Lake Buena Vista, FL, USA},
series = {SWAN 2018}
}

@article{10.1145/3488280,
author = {Sowah, Robert A. and Kuditchar, Bernard and Mills, Godfrey A. and Acakpovi, Amevi and Twum, Raphael A. and Buah, Gifty and Agboyi, Robert},
title = {HCBST: An Efficient Hybrid Sampling Technique for Class Imbalance Problems},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {1556-4681},
url = {https://doi.org/10.1145/3488280},
doi = {10.1145/3488280},
abstract = {Class imbalance problem is prevalent in many real-world domains. It has become an active area of research. In binary classification problems, imbalance learning refers to learning from a dataset with a high degree of skewness to the negative class. This phenomenon causes classification algorithms to perform woefully when predicting positive classes with new examples. Data resampling, which involves manipulating the training data before applying standard classification techniques, is among the most commonly used techniques to deal with the class imbalance problem. This article presents a new hybrid sampling technique that improves the overall performance of classification algorithms for solving the class imbalance problem significantly. The proposed method called the Hybrid Cluster-Based Undersampling Technique (HCBST) uses a combination of the cluster undersampling technique to under-sample the majority instances and an oversampling technique derived from Sigma Nearest Oversampling based on Convex Combination, to oversample the minority instances to solve the class imbalance problem with a high degree of accuracy and reliability. The performance of the proposed algorithm was tested using 11 datasets from the National Aeronautics and Space Administration Metric Data Program data repository and University of California Irvine Machine Learning data repository with varying degrees of imbalance. Results were compared with classification algorithms such as the K-nearest neighbours, support vector machines, decision tree, random forest, neural network, AdaBoost, na\"{\i}ve Bayes, and quadratic discriminant analysis. Tests results revealed that for the same datasets, the HCBST performed better with average performances of 0.73, 0.67, and 0.35 in terms of performance measures of area under curve, geometric mean, and Matthews Correlation Coefficient, respectively, across all the classifiers used for this study. The HCBST has the potential of improving the performance of the class imbalance problem, which by extension, will improve on the various applications that rely on the concept for a solution.},
journal = {ACM Trans. Knowl. Discov. Data},
month = nov,
articleno = {57},
numpages = {37},
keywords = {classification, clustering, cluster undersampling technique, data sampling, Class imbalance}
}

@article{10.1016/j.eswa.2016.12.035,
author = {Haixiang, Guo and Yijing, Li and Shang, Jennifer and Mingyun, Gu and Yuanyue, Huang and Bing, Gong},
title = {Learning from class-imbalanced data},
year = {2017},
issue_date = {May 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {73},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.12.035},
doi = {10.1016/j.eswa.2016.12.035},
abstract = {527 articles related to imbalanced data and rare events are reviewed.Viewing reviewed papers from both technical and practical perspectives.Summarizing existing methods and corresponding statistics by a new taxonomy idea.Categorizing 162 application papers into 13 domains and giving introduction.Some opening questions are discussed at the end of this manuscript. Rare events, especially those that could potentially negatively impact society, often require humans decision-making responses. Detecting rare events can be viewed as a prediction task in data mining and machine learning communities. As these events are rarely observed in daily life, the prediction task suffers from a lack of balanced data. In this paper, we provide an in depth review of rare event detection from an imbalanced learning perspective. Five hundred and seventeen related papers that have been published in the past decade were collected for the study. The initial statistics suggested that rare events detection and imbalanced learning are concerned across a wide range of research areas from management science to engineering. We reviewed all collected papers from both a technical and a practical point of view. Modeling methods discussed include techniques such as data preprocessing, classification algorithms and model evaluation. For applications, we first provide a comprehensive taxonomy of the existing application domains of imbalanced learning, and then we detail the applications for each category. Finally, some suggestions from the reviewed papers are incorporated with our experiences and judgments to offer further research directions for the imbalanced learning and rare event detection fields.},
journal = {Expert Syst. Appl.},
month = may,
pages = {220–239},
numpages = {20},
keywords = {Rare events, Machine learning, Imbalanced data, Data mining}
}

@article{10.1504/IJISTA.2017.081311,
author = {Singh, Satwinder and Singla, Rozy},
title = {Classification of defective modules using object-oriented metrics},
year = {2017},
issue_date = {January 2017},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {16},
number = {1},
issn = {1740-8865},
url = {https://doi.org/10.1504/IJISTA.2017.081311},
doi = {10.1504/IJISTA.2017.081311},
abstract = {Software defect in today's era is crucial in the field of software engineering. Most of the organisations use various techniques to predict defects in their products before they are delivered. Defect prediction techniques help the organisations to use their resources effectively which results in lower cost and time requirements. There are various techniques that are used for predicting defects in software before it has to be delivered, e.g., clustering, neural networks, support vector machine SVM. In this paper two defect prediction techniques: K-means clustering and multi-layer perceptron model MLP are compared. Both the techniques are implemented on different platforms. K-means clustering is implemented using WEKA tool and MLP is implemented using SPSS. The results are compared to find which algorithm produces better results. In this paper object-oriented metrics are used for predicting defects in the software.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {1–13},
numpages = {13},
keywords = {software engineering, software development, software defects, object-oriented metrics, multi-layer perceptron, defective modules, defect prediction, classification, artificial neural networks, WEKA, SPSS, MLP, K-means clustering, ANNs}
}

@article{10.1007/s10515-017-0229-y,
author = {Nizamani, Zeeshan Ahmed and Liu, Hui and Chen, David Matthew and Niu, Zhendong},
title = {Automatic approval prediction for software enhancement requests},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-017-0229-y},
doi = {10.1007/s10515-017-0229-y},
abstract = {Software applications often receive a large number of enhancement requests that suggest developers to fulfill additional functions. Such requests are usually checked manually by the developers, which is time consuming and tedious. Consequently, an approach that can automatically predict whether a new enhancement report will be approved is beneficial for both the developers and enhancement suggesters. With the approach, according to their available time, the developers can rank the reports and thus limit the number of reports to evaluate from large collection of low quality enhancement requests that are unlikely to be approved. The approach can help developers respond to the useful requests more quickly. To this end, we propose a multinomial naive Bayes based approach to automatically predict whether a new enhancement report is likely to be approved or rejected. We acquire the enhancement reports of open-source software applications from Bugzilla for evaluation. Each report is preprocessed and modeled as a vector. Using these vectors with their corresponding approval status, we train a Bayes based classifier. The trained classifier predicts approval or rejection of the new enhancement reports. We apply different machine learning and neural network algorithms, and it turns out that the multinomial naive Bayes classifier yields the highest accuracy with the given dataset. The proposed approach is evaluated with 40,000 enhancement reports from 35 open source applications. The results of tenfold cross validation suggest that the average accuracy is up to 89.25%.},
journal = {Automated Software Engg.},
month = jun,
pages = {347–381},
numpages = {35},
keywords = {Software enhancements, Multinomial naive Bayes, Machine learning, Document classification}
}

@article{10.1016/j.patcog.2021.108069,
author = {Raghuwanshi, Bhagat Singh and Shukla, Sanyam},
title = {Minimum variance-embedded kernelized extension of extreme learning machine for imbalance learning},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {119},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2021.108069},
doi = {10.1016/j.patcog.2021.108069},
journal = {Pattern Recogn.},
month = nov,
numpages = {23},
keywords = {Classification, Class imbalance problem, Minimum variance-embedded class-specific kernelized extreme learning machine, Extreme learning machine}
}

@article{10.1002/smr.2178,
author = {Zakari, Abubakar and Lee, Sai Peck},
title = {Parallel debugging: An investigative study},
year = {2019},
issue_date = {November 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {11},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2178},
doi = {10.1002/smr.2178},
abstract = {In the simultaneous localization of multiple software faults, a parallel debugging approach has consistently been utilized. The effectiveness of a parallel debugging approach is critically determined by the type of clustering algorithm and the distance metric used. However, clustering algorithms that group failed tests based on their execution profile similarity with distance metrics such as Euclidean distance, Jaccard distance, and Hamming distance are considered to be problematic and not appropriate. In this paper, we conducted an investigative study on the usefulness of the problematic parallel debugging approach that makes use of k‐means clustering algorithm (that groups failed tests based on their execution profile similarity) with Euclidian distance metric on three similarity coefficient‐based fault localization techniques in terms of localization effectiveness. Secondly, we compare the effectiveness of the problematic parallel debugging approach with one‐bug‐at‐a‐time debugging approach (OBA) and a state‐of‐the‐art parallel debugging approach named MSeer. The empirical evaluation is conducted on 540 multiple‐fault versions of eight medium‐sized to large‐sized subject programs with two, three, four, and five faulty versions. Our results suggest that clustering failed tests based on their execution profile similarity and the utilization of distance metrics such as Euclidean distance is indeed problematic and contributes to the reduction of effectiveness in localizing multiple faults.Figure&nbsp;1 shows a program with test cases. The results of our controlled experiments showed that, even though the problematic parallel debugging approach is useful and better in comparison with the OBA debugging approach, yet, it is not as effective when compared with the existing state‐of‐the‐art parallel debugging approach.Therefore, the result affirms the previous studies claims that performing failed tests clustering based on their execution profile similarity, estimating the number of clusters based on the number of failed tests, and the utilization of metrics like Euclidian distance to measure the due‐to relationship between failed test cases are problematic and not appropriate which indeed reduces the effectiveness of a parallel debugging approach.


image
image},
journal = {J. Softw. Evol. Process},
month = nov,
numpages = {25},
keywords = {software fault localization, program spectra, program debugging, parallel debugging, multiple faults}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00026,
author = {Li, Paul Luo and Chai, Xiaoyu and Campbell, Frederick and Liao, Jilong and Abburu, Neeraja and Kang, Minsuk and Niculescu, Irina and Brake, Greg and Patil, Siddharth and Dooley, James and Paddock, Brandon},
title = {Evolving software to be ML-driven utilizing real-world A/B testing: experiences, insights, challenges},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00026},
doi = {10.1109/ICSE-SEIP52600.2021.00026},
abstract = {ML-driven software is heralded as the next major advancement in software engineering; existing software today can benefit from being evolved to be ML-driven. In this paper, we contribute practical knowledge about evolving software to be ML-driven, utilizing real-world A/B testing. We draw on experiences evolving two software features from the Windows operating system to be ML-driven, with more than ten realworld A/B tests on millions of PCs over more than two years. We discuss practical reasons for using A/B testing to engineer ML-driven software, insights for success, as well as on-going realworld challenges. This knowledge may help practitioners, as well as help direct future research and innovations.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {170–179},
numpages = {10},
keywords = {software quality, software engineering, software development management, predictive models, machine learning algorithms, machine learning, learning (artificial intelligence), data analysis, big data applications},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@article{10.5555/2639331.2639338,
author = {Frey, Lewis and Li, Cen and Talbert, Douglas and Fisher, Doug},
title = {A Review of the Fourteenth International Conference on Machine Learning},
year = {1998},
issue_date = {May 1998},
publisher = {IOS Press},
address = {NLD},
volume = {2},
number = {3},
issn = {1088-467X},
abstract = {We briefly review each paper of the Fourteenth International Conference on Machine Learning, along with some general observations on the conference as a whole. The major topics of papers include data reduction, feature selection, ensembles of classifiers, natural language learning, text categorization, inductive logic programming, stochastic models, and reinforcement learning.},
journal = {Intell. Data Anal.},
month = may,
pages = {245–255},
numpages = {11},
keywords = {Stochastic Models, Reinforcement Learning, Natural Language Learning, Inductive Logic Programming, Inductive Concept Learning, Ensembles}
}

@inproceedings{10.1145/3243127.3243129,
author = {Khosrowjerdi, Hojat and Meinke, Karl},
title = {Learning-based testing for autonomous systems using spatial and temporal requirements},
year = {2018},
isbn = {9781450359726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243127.3243129},
doi = {10.1145/3243127.3243129},
abstract = {Cooperating cyber-physical systems-of-systems (CO-CPS) such as vehicle platoons, robot teams or drone swarms usually have strict safety requirements on both spatial and temporal behavior. Learning-based testing is a combination of machine learning and model checking that has been successfully used for black-box requirements testing of cyber-physical systems-of-systems. We present an overview of research in progress to apply learning-based testing to evaluate spatio-temporal requirements on autonomous systems-of-systems through modeling and simulation.},
booktitle = {Proceedings of the 1st International Workshop on Machine Learning and Software Engineering in Symbiosis},
pages = {6–15},
numpages = {10},
keywords = {spatio-temporal logic, requirements testing, model-based testing, machine learning, learning-based testing, black-box testing, Automotive software},
location = {Montpellier, France},
series = {MASES 2018}
}

@inproceedings{10.1145/3453483.3454045,
author = {He, Jingxuan and Lee, Cheng-Chun and Raychev, Veselin and Vechev, Martin},
title = {Learning to find naming issues with big code and small supervision},
year = {2021},
isbn = {9781450383912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453483.3454045},
doi = {10.1145/3453483.3454045},
abstract = {We introduce a new approach for finding and fixing naming issues in source code. The method is based on a careful combination of unsupervised and supervised procedures: (i) unsupervised mining of patterns from Big Code that express common naming idioms. Program fragments violating such idioms indicates likely naming issues, and (ii) supervised learning of a classifier on a small labeled dataset which filters potential false positives from the violations.  We implemented our method in a system called Namer and evaluated it on a large number of Python and Java programs. We demonstrate that Namer is effective in finding naming mistakes in real world repositories with high precision (~70%). Perhaps surprisingly, we also show that existing deep learning methods are not practically effective and achieve low precision in finding naming issues (up to ~16%).},
booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {296–311},
numpages = {16},
keywords = {Static analysis, Name-based program analysis, Machine learning, Bug detection, Anomaly detection},
location = {Virtual, Canada},
series = {PLDI 2021}
}

@inproceedings{10.1145/3194718.3194730,
author = {Sarro, Federica},
title = {Predictive analytics for software testing: keynote paper},
year = {2018},
isbn = {9781450357418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194718.3194730},
doi = {10.1145/3194718.3194730},
abstract = {This keynote discusses the use of Predictive Analytics for Software Engineering, and in particular for Software Defect Prediction and Software Testing, by presenting the latest results achieved in these fields leveraging Artificial Intelligence, Search-based and Machine Learning methods, and by giving some directions for future work.},
booktitle = {Proceedings of the 11th International Workshop on Search-Based Software Testing},
pages = {1},
numpages = {1},
keywords = {search-based predictive modelling, predictive analytics},
location = {Gothenburg, Sweden},
series = {SBST '18}
}

@article{10.1016/j.ins.2011.01.039,
author = {Rodr\'{\i}guez, D. and Ruiz, R. and Riquelme, J. C. and Aguilar-Ruiz, J. S.},
title = {Searching for rules to detect defective modules: A subgroup discovery approach},
year = {2012},
issue_date = {May, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {191},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2011.01.039},
doi = {10.1016/j.ins.2011.01.039},
abstract = {Data mining methods in software engineering are becoming increasingly important as they can support several aspects of the software development life-cycle such as quality. In this work, we present a data mining approach to induce rules extracted from static software metrics characterising fault-prone modules. Due to the special characteristics of the defect prediction data (imbalanced, inconsistency, redundancy) not all classification algorithms are capable of dealing with this task conveniently. To deal with these problems, Subgroup Discovery (SD) algorithms can be used to find groups of statistically different data given a property of interest. We propose EDER-SD (Evolutionary Decision Rules for Subgroup Discovery), a SD algorithm based on evolutionary computation that induces rules describing only fault-prone modules. The rules are a well-known model representation that can be easily understood and applied by project managers and quality engineers. Thus, rules can help them to develop software systems that can be justifiably trusted. Contrary to other approaches in SD, our algorithm has the advantage of working with continuous variables as the conditions of the rules are defined using intervals. We describe the rules obtained by applying our algorithm to seven publicly available datasets from the PROMISE repository showing that they are capable of characterising subgroups of fault-prone modules. We also compare our results with three other well known SD algorithms and the EDER-SD algorithm performs well in most cases.},
journal = {Inf. Sci.},
month = may,
pages = {14–30},
numpages = {17},
keywords = {Subgroup discovery, Rules, Imbalanced datasets, Defect prediction}
}

@article{10.1016/j.asoc.2016.08.002,
author = {ztrk, Muhammed Maruf and Zengin, Ahmet},
title = {How repeated data points affect bug prediction performance},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.08.002},
doi = {10.1016/j.asoc.2016.08.002},
abstract = {Graphical abstractDisplay Omitted HighlightsPresents a novel pre-processing algorithm for defect data sets.Discusses the effects of the use of low level metrics in bug prediction.Compares repeated data points industrial versus open-source projects.Provides tips to obtain better bug prediction results. In defect prediction studies, open-source and real-world defect data sets are frequently used. The quality of these data sets is one of the main factors affecting the validity of defect prediction methods. One of the issues is repeated data points in defect prediction data sets. The main goal of the paper is to explore how low-level metrics are derived. This paper also presents a cleansing algorithm that removes repeated data points from defect data sets. The method was applied on 20 data sets, including five open source sets, and area under the curve (AUC) and precision performance parameters have been improved by 4.05% and 6.7%, respectively. In addition, this work discusses how static code metrics should be used in bug prediction. The study provides tips to obtain better defect prediction results.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1051–1061},
numpages = {11},
keywords = {Software metrics, Repeated data, Bug prediction}
}

@article{10.1007/s10515-014-0155-1,
author = {Huang, Liguo and Ng, Vincent and Persing, Isaac and Chen, Mingrui and Li, Zeheng and Geng, Ruili and Tian, Jeff},
title = {AutoODC: Automated generation of orthogonal defect classifications},
year = {2015},
issue_date = {March     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-014-0155-1},
doi = {10.1007/s10515-014-0155-1},
abstract = {Orthogonal defect classification (ODC), the most influential framework for software defect classification and analysis, provides valuable in-process feedback to system development and maintenance. Conducting ODC classification on existing organizational defect reports is human-intensive and requires experts' knowledge of both ODC and system domains. This paper presents AutoODC, an approach for automating ODC classification by casting it as a supervised text classification problem. Rather than merely applying the standard machine learning framework to this task, we seek to acquire a better ODC classification system by integrating experts' ODC experience and domain knowledge into the learning process via proposing a novel relevance annotation framework. We have trained AutoODC using two state-of-the-art machine learning algorithms for text classification, Naive Bayes (NB) and support vector machine (SVM), and evaluated it on both an industrial defect report from the social network domain and a larger defect list extracted from a publicly accessible defect tracker of the open source system FileZilla. AutoODC is a promising approach: not only does it leverage minimal human effort beyond the human annotations typically required by standard machine learning approaches, but it achieves overall accuracies of 82.9 % (NB) and 80.7 % (SVM) on the industrial defect report, and accuracies of 77.5 % (NB) and 75.2 % (SVM) on the larger, more diversified open source defect list.},
journal = {Automated Software Engg.},
month = mar,
pages = {3–46},
numpages = {44},
keywords = {Text classification, Orthogonal defect classification (ODC), Natural language processing, Machine learning}
}

@article{10.1007/s11219-020-09546-7,
author = {Oyetoyan, Tosin Daniel and Morrison, Patrick},
title = {An improved text classification modelling approach to identify security messages in heterogeneous projects},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09546-7},
doi = {10.1007/s11219-020-09546-7},
abstract = {Security remains under-addressed in many organisations, illustrated by the number of large-scale software security breaches. Preventing breaches can begin during software development if attention is paid to security during the software’s design and implementation. One approach to security assurance during software development is to examine communications between developers as a means of studying the security concerns of the project. Prior research has investigated models for classifying project communication messages (e.g., issues or commits) as security related or not. A known problem is that these models are project-specific, limiting their use by other projects or organisations. We investigate whether we can build a generic classification model that can generalise across projects. We define a set of security keywords by extracting them from relevant security sources, dividing them into four categories: asset, attack/threat, control/mitigation, and implicit. Using different combinations of these categories and including them in the training dataset, we built a classification model and evaluated it on industrial, open-source, and research-based datasets containing over 45 different products. Our model based on harvested security keywords as a feature set shows average recall from 55 to 86%, minimum recall from 43 to 71% and maximum recall from 60 to 100%. An average f-score between 3.4 and 88%, an average g-measure of at least 66% across all the dataset, and an average AUC of ROC from 69 to 89%. In addition, models that use externally sourced features outperformed models that use project-specific features on average by a margin of 26–44% in recall, 22–50% in g-measure, 0.4–28% in f-score, and 15–19% in AUC of ROC. Further, our results outperform a state-of-the-art prediction model for security bug reports in all cases. We find using sound statistical and effect size tests that (1) using harvested security keywords as features to train a text classification model improve classification models and generalise to other projects significantly. (2) Including features in the training dataset before model construction improve classification models significantly. (3) Different security categories represent predictors for different projects. Finally, we introduce new and promising approaches to construct models that can generalise across different independent projects.},
journal = {Software Quality Journal},
month = jun,
pages = {509–553},
numpages = {45},
keywords = {Machine learning, Software repository, Text classification, Classification model, Security}
}

@article{10.1145/3447876,
author = {Lyu, Yingzhe and Li, Heng and Sayagh, Mohammed and Jiang, Zhen Ming (Jack) and Hassan, Ahmed E.},
title = {An Empirical Study of the Impact of Data Splitting Decisions on the Performance of AIOps Solutions},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3447876},
doi = {10.1145/3447876},
abstract = {AIOps (Artificial Intelligence for IT Operations) leverages machine learning models to help practitioners handle the massive data produced during the operations of large-scale systems. However, due to the nature of the operation data, AIOps modeling faces several data splitting-related challenges, such as imbalanced data, data leakage, and concept drift. In this work, we study the data leakage and concept drift challenges in the context of AIOps and evaluate the impact of different modeling decisions on such challenges. Specifically, we perform a case study on two commonly studied AIOps applications: (1) predicting job failures based on trace data from a large-scale cluster environment and (2) predicting disk failures based on disk monitoring data from a large-scale cloud storage environment. First, we observe that the data leakage issue exists in AIOps solutions. Using a time-based splitting of training and validation datasets can significantly reduce such data leakage, making it more appropriate than using a random splitting in the AIOps context. Second, we show that AIOps solutions suffer from concept drift. Periodically updating AIOps models can help mitigate the impact of such concept drift, while the performance benefit and the modeling cost of increasing the update frequency depend largely on the application data and the used models. Our findings encourage future studies and practices on developing AIOps solutions to pay attention to their data-splitting decisions to handle the data leakage and concept drift challenges.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jul,
articleno = {54},
numpages = {38},
keywords = {model maintenance, machine learning engineering, failure prediction, data leakage, concept drift, AIOps}
}

@inproceedings{10.1145/3472674.3473981,
author = {Pontillo, Valeria and Palomba, Fabio and Ferrucci, Filomena},
title = {Toward static test flakiness prediction: a feasibility study},
year = {2021},
isbn = {9781450386258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472674.3473981},
doi = {10.1145/3472674.3473981},
abstract = {Flaky tests are tests that exhibit both a passing and failing behavior when run against the same code. While the research community has attempted to define automated approaches for detecting and addressing test flakiness, most of them suffer from scalability issues and uncertainty as they require test cases to be run multiple times. This limitation has been recently targeted by means of machine learning solutions that could predict the flakiness of tests using a set of both static and dynamic metrics that would avoid the re-execution of tests. Recognizing the effort spent so far, this paper poses the first steps toward an orthogonal view of the problem, namely the classification of flaky tests using only statically computable software metrics. We propose a feasibility study on 72 projects of the iDFlakies dataset, and investigate the differences between flaky and non-flaky tests in terms of 25 test and production code metrics and smells. First, we statistically assess those differences. Second, we build a logistic regression model to verify the extent to which the differences observed are still significant when the metrics are considered together. The results show a relation between test flakiness and a number of test and production code factors, indicating the possibility to build classification approaches that exploit those factors to predict test flakiness.},
booktitle = {Proceedings of the 5th International Workshop on Machine Learning Techniques for Software Quality Evolution},
pages = {19–24},
numpages = {6},
keywords = {Software Quality Evaluation, Flaky Tests, Empirical Studies},
location = {Athens, Greece},
series = {MaLTESQuE 2021}
}

@inproceedings{10.1007/978-3-030-85928-2_24,
author = {Chen, Rui and Luo, Lailong and Chen, Yingwen and Xia, Junxu and Guo, Deke},
title = {A Hybrid Framework for&nbsp;Class-Imbalanced Classification},
year = {2021},
isbn = {978-3-030-85927-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-85928-2_24},
doi = {10.1007/978-3-030-85928-2_24},
abstract = {Data classification is a commonly used data processing method in the fields of networks and distributed systems, and it has attracted extensive attention in recent years. Nevertheless, the existing classification algorithms are mainly aimed at relatively balanced datasets, while the data in reality often exhibits imbalanced characteristics. In this paper, we propose a novel Hybrid Resampling-based Ensemble (HRE) model, which aims to solve the classification problem of highly skewed data. The main idea of the HRE is to leverage the resampling approach for tackling class imbalance, and then twelve classifiers are further adopted to construct an ensemble model. Besides, a novel combination of under-sampling and over-sampling is elaborately proposed to balance the heterogeneity among different data categories. We decide the resampling rate in an empirical manner, which provides a practical guideline for the use of sampling methods. We compare the effect of different resampling methods based on the imbalanced network anomaly detection dataset, where few abnormal data need to be distinguished from a large number of common network traffics. The results of extensive experiments show that the HRE model achieves better accuracy performance than the methods without hybrid resampling.},
booktitle = {Wireless Algorithms, Systems, and Applications: 16th International Conference, WASA 2021, Nanjing, China, June 25–27, 2021, Proceedings, Part I},
pages = {301–313},
numpages = {13},
keywords = {Ensemble model, Resampling, Class-imbalanced learning},
location = {Nanjing, China}
}

@article{10.1016/j.jss.2021.111050,
author = {Myllyaho, Lalli and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi and Mikkonen, Tommi and Nurminen, Jukka K.},
title = {Systematic literature review of validation methods for AI systems},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {181},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111050},
doi = {10.1016/j.jss.2021.111050},
journal = {J. Syst. Softw.},
month = nov,
numpages = {22},
keywords = {Systematic literature review, V&amp;V, Testing, Validation, Machine learning, Artificial intelligence}
}

@inproceedings{10.1145/3400286.3418263,
author = {Das, Dipta and Schiewe, Micah and Brighton, Elizabeth and Fuller, Mark and Cerny, Tomas and Bures, Miroslav and Frajtak, Karel and Shin, Dongwan and Tisnovsky, Pavel},
title = {Failure Prediction by Utilizing Log Analysis: A Systematic Mapping Study},
year = {2020},
isbn = {9781450380256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3400286.3418263},
doi = {10.1145/3400286.3418263},
abstract = {In modern computing, log files provide a wealth of information regarding the past of a system, including the system failures and security breaches that cost companies and developers a fortune in both time and money. While this information can be used to attempt to recover from a problem, such an approach merely mitigates the damage that has already been done. Detecting problems, however, is not the only information that can be gathered from log files. It is common knowledge that segments of log files, if analyzed correctly, can yield a good idea of what the system is likely going to do next in real-time, allowing a system to take corrective action before any negative actions occur. In this paper, the authors put forth a systematic map of this field of log prediction, screening several hundred papers and finally narrowing down the field to approximately 30 relevant papers. These papers, when broken down, give a good idea of the state of the art, methodologies employed, and future challenges that still must be overcome. Findings and conclusions of this study can be applied to a variety of software systems and components, including classical software systems, as well as software parts of control, or the Internet of Things (IoT) systems.},
booktitle = {Proceedings of the International Conference on Research in Adaptive and Convergent Systems},
pages = {188–195},
numpages = {8},
keywords = {Mapping Study, Log Analysis, Failure Prediction, Error Logs, Defect Prediction},
location = {Gwangju, Republic of Korea},
series = {RACS '20}
}

@inproceedings{10.1109/ICSSP.2019.00011,
author = {Kapur, Ritu and Sodhi, Balwinder},
title = {Towards a knowledge warehouse and expert system for the automation of SDLC tasks},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSSP.2019.00011},
doi = {10.1109/ICSSP.2019.00011},
abstract = {Cost of a skilled and competent software developer is high, and it is desirable to minimize dependency on such costly human resources. One of the ways to minimize such costs is via automation of various software development tasks.Recent advances in Artificial Intelligence (AI) and the availability of a large volume of knowledge bearing data at various software development related venues present a ripe opportunity for building tools that can automate software development tasks. For instance, there is significant latent knowledge present in raw or unstructured data associated with items such as source files, code commit logs, defect reports, comments, and so on, available in the Open Source Software (OSS) repositories.We aim to leverage such knowledge-bearing data, the latest advances in AI and hardware to create knowledge warehouses and expert systems for the software development domain. Such tools can help in building applications for performing various software development tasks such as defect prediction, effort estimation, code review, etc.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {5–8},
numpages = {4},
keywords = {supervised learning, software maintenance, data mining, automated software engineering},
location = {Montreal, Quebec, Canada},
series = {ICSSP '19}
}

@article{10.1023/B:SQJO.0000034709.63615.8b,
author = {Gokhale, Swapna S. and Lyu, Michael R. and Trivedi, Kishor S.},
title = {Analysis of Software Fault Removal Policies Using a Non-Homogeneous Continuous Time Markov Chain},
year = {2004},
issue_date = {September 2004},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1023/B:SQJO.0000034709.63615.8b},
doi = {10.1023/B:SQJO.0000034709.63615.8b},
abstract = {Software reliability is an important metric that quantifies the quality of a software product and is inversely related to the residual number of faults in the system. Fault removal is a critical process in achieving desired level of quality before software deployment in the field. Conventional software reliability models assume that the time to remove a fault is negligible and that the fault removal process is perfect. In this paper we examine various kinds of fault removal policies, and analyze their effect on the residual number of faults at the end of the testing process, using a non-homogeneous continuous time Markov chain. The fault removal rate is initially assumed to be constant, and it is subsequently extended to cover time and state dependencies. We then extend the non-homogeneous continuous time Markov chain (NHCTMC) framework to include imperfections in the fault removal process. A method to compute the failure intensity of the software in the presence of explicit fault removal is also proposed. The fault removal scenarios can be easily incorporated using the state-space view of the non-homogeneous Poisson process.},
journal = {Software Quality Journal},
month = sep,
pages = {211–230},
numpages = {20},
keywords = {software reliability, non-homogeneous continuous time Markov chain, fault removal}
}

@article{10.1016/j.compag.2019.01.041,
author = {Kaya, Aydin and Keceli, Ali Seydi and Catal, Cagatay and Yalic, Hamdi Yalin and Temucin, Huseyin and Tekinerdogan, Bedir},
title = {Analysis of transfer learning for deep neural network based plant classification models},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {158},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2019.01.041},
doi = {10.1016/j.compag.2019.01.041},
journal = {Comput. Electron. Agric.},
month = mar,
pages = {20–29},
numpages = {10},
keywords = {Convolutional neural networks, Fine-tuning, Deep neural networks, Transfer learning, Plant classification}
}

@inproceedings{10.1109/ICSE43902.2021.00086,
author = {Ma, Wei and Chekam, Thierry Titcheu and Papadakis, Mike and Harman, Mark},
title = {MuDelta: Delta-Oriented Mutation Testing at Commit Time},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00086},
doi = {10.1109/ICSE43902.2021.00086},
abstract = {To effectively test program changes using mutation testing, one needs to use mutants that are relevant to the altered program behaviours. We introduce MuDelta, an approach that identifies commit-relevant mutants; mutants that affect and are affected by the changed program behaviours. Our approach uses machine learning applied on a combined scheme of graph and vector-based representations of static code features. Our results, from 50 commits in 21 Coreutils programs, demonstrate a strong prediction ability of our approach; yielding 0.80 (ROC) and 0.50 (PR-Curve) AUC values with 0.63 and 0.32 precision and recall values. These predictions are significantly higher than random guesses, 0.20 (PR-Curve) AUC, 0.21 and 0.21 precision and recall, and subsequently lead to strong relevant tests that kill 45% more relevant mutants than randomly sampled mutants (either sampled from those residing on the changed component(s) or from the changed lines). Our results also show that MuDelta selects mutants with 27% higher fault revealing ability in fault introducing commits. Taken together, our results corroborate the conclusion that commit-based mutation testing is suitable and promising for evolving software.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {897–909},
numpages = {13},
keywords = {regression testing, mutation testing, machine learning, continuous integration, commit-relevant mutants},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1007/978-3-030-61401-0_39,
author = {Kostrzewa, Daniel and Karczewski, Konrad and Brzeski, Robert},
title = {Optimization of the Values of Classifiers Parameters – Is it Still Worthwhile to Deal with it?},
year = {2020},
isbn = {978-3-030-61400-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-61401-0_39},
doi = {10.1007/978-3-030-61401-0_39},
abstract = {This paper presents a comparison of the use of several selected optimization algorithms. They were applied to determine the parameters of classifiers. The value of these parameters should have a significant impact on the quality of the classification, and their determination is not a trivial process. This article checks how selected optimization algorithms deal with the task of determining the values of classifier parameters. Four algorithms were selected: particle swarm optimization, simulated annealing, cuckoo optimization algorithm, and lion optimization algorithm. The process of parameter determination was carried out using the five selected classifiers on several selected sets of data.},
booktitle = {Artificial Intelligence and Soft Computing: 19th International Conference, ICAISC 2020, Zakopane, Poland, October 12-14, 2020, Proceedings, Part I},
pages = {417–428},
numpages = {12},
keywords = {UCI Machine Learning Repository, Weka, Accuracy, Data analysis, Classification, Lion optimization algorithm, Cuckoo optimization algorithm, Simulated annealing, Particle swarm optimization},
location = {Zakopane, Poland}
}

@article{10.1007/s10515-020-00270-x,
author = {Richter, Cedric and H\"{u}llermeier, Eyke and Jakobs, Marie-Christine and Wehrheim, Heike},
title = {Algorithm selection for software validation based on graph kernels},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1–2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-020-00270-x},
doi = {10.1007/s10515-020-00270-x},
abstract = {Algorithm selection is the task of choosing an algorithm from a given set of candidate algorithms when faced with a particular problem instance. Algorithm selection via machine learning (ML) has recently been successfully applied for various problem classes, including computationally hard problems such as SAT. In this paper, we study algorithm selection for software validation, i.e., the task of choosing a software validation tool for a given validation instance. A validation instance consists of a program plus properties to be checked on it. The application of machine learning techniques to this task first of all requires an appropriate representation of software. To this end,
we propose a dedicated kernel function, which compares two programs in terms of their similarity, thus making the algorithm selection task amenable to kernel-based machine learning methods. Our kernel operates on a graph representation of source code mixing elements of control-flow and program-dependence graphs with abstract syntax trees.
Thus, given two such representations as input, the kernel function yields a real-valued score that can be interpreted as a degree of similarity. We experimentally evaluate our kernel in two learning scenarios, namely a classification and a ranking problem: (1) selecting between a verification and a testing tool for bug finding (i.e., property violation), and (2) ranking several verification tools,
from presumably best to worst, for property proving. The evaluation, which is based on data sets from the annual software verification competition SV-COMP, demonstrates our kernel to generalize well and to achieve rather high prediction accuracy, both for the classification and the ranking task.},
journal = {Automated Software Engg.},
month = jun,
pages = {153–186},
numpages = {34},
keywords = {Testing, Verification, Graph kernels, Machine learning, Software validation, Algorithm selection}
}

@article{10.1155/2021/5549300,
author = {Museba, Tinofirei and Nelwamondo, Fulufhelo and Ouahada, Khmaies and Yi, Yugen},
title = {ADES: A New Ensemble Diversity-Based Approach for Handling Concept Drift},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/5549300},
doi = {10.1155/2021/5549300},
abstract = {Beyond applying machine learning predictive models to static tasks, a significant corpus of research exists that applies machine learning predictive models to streaming environments that incur concept drift. With the prevalence of streaming real-world applications that are associated with changes in the underlying data distribution, the need for applications that are capable of adapting to evolving and time-varying dynamic environments can be hardly overstated. Dynamic environments are nonstationary and change with time and the target variables to be predicted by the learning algorithm and often evolve with time, a phenomenon known as concept drift. Most work in handling concept drift focuses on updating the prediction model so that it can recover from concept drift while little effort has been dedicated to the formulation of a learning system that is capable of learning different types of drifting concepts at any time with minimum overheads. This work proposes a novel and evolving data stream classifier called Adaptive Diversified Ensemble Selection Classifier (ADES) that significantly optimizes adaptation to different types of concept drifts at any time and improves convergence to new concepts by exploiting different amounts of ensemble diversity. The ADES algorithm generates diverse base classifiers, thereby optimizing the margin distribution to exploit ensemble diversity to formulate an ensemble classifier that generalizes well to unseen instances and provides fast recovery from different types of concept drift. Empirical experiments conducted on both artificial and real-world data streams demonstrate that ADES can adapt to different types of drifts at any given time. The prediction performance of ADES is compared to three other ensemble classifiers designed to handle concept drift using both artificial and real-world data streams. The comparative evaluation performed demonstrated the ability of ADES to handle different types of concept drifts. The experimental results, including statistical test results, indicate comparable performances with other algorithms designed to handle concept drift and prove their significance and effectiveness.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {17}
}

@inproceedings{10.1109/ASE.2011.6100070,
author = {Chen, Ning and Hoi, Steven C. H. and Xiao, Xiaokui},
title = {Software process evaluation: A machine learning approach},
year = {2011},
isbn = {9781457716386},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2011.6100070},
doi = {10.1109/ASE.2011.6100070},
abstract = {Software process evaluation is essential to improve software development and the quality of software products in an organization. Conventional approaches based on manual qualitative evaluations (e.g., artifacts inspection) are deficient in the sense that (i) they are time-consuming, (ii) they suffer from the authority constraints, and (iii) they are often subjective. To overcome these limitations, this paper presents a novel semi-automated approach to software process evaluation using machine learning techniques. In particular, we formulate the problem as a sequence classification task, which is solved by applying machine learning algorithms. Based on the framework, we define a new quantitative indicator to objectively evaluate the quality and performance of a software process. To validate the efficacy of our approach, we apply it to evaluate the defect management process performed in four real industrial software projects. Our empirical results show that our approach is effective and promising in providing an objective and quantitative measurement for software process evaluation.},
booktitle = {Proceedings of the 26th IEEE/ACM International Conference on Automated Software Engineering},
pages = {333–342},
numpages = {10},
series = {ASE '11}
}

@inproceedings{10.1007/978-3-030-47426-3_61,
author = {Perera, Kushani and Chan, Jeffrey and Karunasekera, Shanika},
title = {A Framework for Feature Selection to Exploit Feature Group Structures},
year = {2020},
isbn = {978-3-030-47425-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-47426-3_61},
doi = {10.1007/978-3-030-47426-3_61},
abstract = {Filter feature selection methods play an important role in machine learning tasks when low computational costs, classifier independence or simplicity is important. Existing filter methods predominantly focus only on the input data and do not take advantage of the external sources of correlations within feature groups to improve the classification accuracy. We propose a framework which facilitates supervised filter feature selection methods to exploit feature group information from external sources of knowledge and use this framework to incorporate feature group information into minimum Redundancy Maximum Relevance (mRMR) algorithm, resulting in GroupMRMR algorithm. We show that GroupMRMR achieves high accuracy gains over mRMR (up&nbsp;to 35%) and other popular filter methods (up&nbsp;to 50%). GroupMRMR has same computational complexity as that of mRMR, therefore, does not incur additional computational costs. Proposed method has many real world applications, particularly the ones that use genomic, text and image data whose features demonstrate strong group structures.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 24th Pacific-Asia Conference, PAKDD 2020, Singapore, May 11–14, 2020, Proceedings, Part I},
pages = {792–804},
numpages = {13},
keywords = {Squared [inline-graphic not available: see fulltext] norm minimisation, Feature groups, Filter feature selection},
location = {Singapore, Singapore}
}

@inproceedings{10.1109/CASE49439.2021.9551659,
author = {Melakhsou, Abdallah Amine and Batton-Hubert, Mireille},
title = {On welding defect detection and causalities between welding signals},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CASE49439.2021.9551659},
doi = {10.1109/CASE49439.2021.9551659},
abstract = {In the manufacturing of hot water tanks, welding quality evaluation and fault detection is a critical operation that is still frequently conducted visually or with the help of none destructive tests, which can generate a high consumption of time and resources. To overcome this problem, many methods have been proposed for defect detection based on the classification of the welding signals. However, most of the proposed methods do not consider the problems of defect localization and the generalization from small sample size. Moreover, studies on the interactions between welding signals seem to be absent in the literature despite its importance in the formulation of the defect detection problem. In this paper, we aim to address these gaps by presenting a study on the causalities between welding signals in the circular welding of hot water tanks. Based on the findings from the causality study, we propose a method that detects and localize welding defect with high accuracy and handles the problem of small sample size. Furthermore, we present a study on the defects root cause and show the possibility of early defect prediction.},
booktitle = {2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)},
pages = {401–408},
numpages = {8},
location = {Lyon, France}
}

@inproceedings{10.1145/3416505.3423561,
author = {Vasiliev, Roman and Koznov, Dmitrij and Chernishev, George and Khvorov, Aleksandr and Luciv, Dmitry and Povarov, Nikita},
title = {TraceSim: a method for calculating stack trace similarity},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423561},
doi = {10.1145/3416505.3423561},
abstract = {Many contemporary software products have subsystems for automatic crash reporting. However, it is well-known that the same bug can produce slightly different reports. To manage this problem, reports are usually grouped, often manually by developers. Manual triaging, however, becomes infeasible for products that have large userbases, which is the reason for many different approaches to automating this task. Moreover, it is important to improve quality of triaging due to a large volume of reports that needs to be processed properly. Therefore, even a relatively small improvement could play a significant role in the overall accuracy of report bucketing. The majority of existing studies use some kind of a stack trace similarity metric, either based on information retrieval techniques or string matching methods. However, it should be stressed that the quality of triaging is still insufficient.  In this paper, we describe TraceSim — a novel approach to this problem which combines TF-IDF, Levenshtein distance, and machine learning to construct a similarity metric. Our metric has been implemented inside an industrial-grade report triaging system. The evaluation on a manually labeled dataset shows significantly better results compared to baseline approaches.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {25–30},
numpages = {6},
keywords = {Stack Trace, Software Repositories, Software Engineering, Information Retrieval, Duplicate Crash Report, Duplicate Bug Report, Deduplication, Crash Stack, Crash Reports, Crash Report Deduplication, Automatic Problem Reporting Tools, Automatic Crash Reporting},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@inproceedings{10.5555/3540261.3542176,
author = {Milbich, Timo and Roth, Karsten and Sinha, Samarth and Schmidt, Ludwig and Ghassemi, Marzyeh and Ommer, Bj\"{o}rn},
title = {Characterizing generalization under out-of-distribution shifts in deep metric learning},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep Metric Learning (DML) aims to find representations suitable for zero-shot transfer to a priori unknown test distributions. However, common evaluation protocols only test a single, fixed data split in which train and test classes are assigned randomly. More realistic evaluations should consider a broad spectrum of distribution shifts with potentially varying degree and difficulty. In this work, we systematically construct train-test splits of increasing difficulty and present the ooDML benchmark to characterize generalization under out-of-distribution shifts in DML. ooDML is designed to probe the generalization performance on much more challenging, diverse train-to-test distribution shifts. Based on our new benchmark, we conduct a thorough empirical analysis of state-of-the-art DML methods. We find that while generalization tends to consistently degrade with difficulty, some methods are better at retaining performance as the distribution shift increases. Finally, we propose few-shot DML as an efficient way to consistently improve generalization in response to unknown test shifts presented in ooDML.},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {1915},
numpages = {13},
series = {NIPS '21}
}

@inproceedings{10.5555/3104635.3104788,
author = {Shinohara, Yasushi},
title = {Software fault reduction methodology for reliable knowledge bases},
year = {1996},
isbn = {9056995243},
publisher = {Gordon and Breach Science Publishers, Inc.},
address = {USA},
booktitle = {Proceedings of the 9th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems},
pages = {788},
numpages = {1},
location = {Fukuoka, Japan},
series = {IEA/AIE'96}
}

@inproceedings{10.5555/645526.657125,
author = {Cohen, William W. and Devanbu, Premkumar T.},
title = {A Comparative Study of Inductive Logic Programming Methods for Software Fault Prediction},
year = {1997},
isbn = {1558604863},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Fourteenth International Conference on Machine Learning},
pages = {66–74},
numpages = {9},
series = {ICML '97}
}

@article{10.1007/s11219-020-09525-y,
author = {Malhotra, Ruchika and Lata, Kusum},
title = {An empirical study on predictability of software maintainability using imbalanced data},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09525-y},
doi = {10.1007/s11219-020-09525-y},
abstract = {In software engineering predictive modeling, early prediction of software modules or classes that possess high maintainability effort is a challenging task. Many prediction models are constructed to predict the maintainability of software classes or modules by applying various machine learning (ML) techniques. If the software modules or classes need&nbsp;high maintainability, effort would be reduced&nbsp;in a dataset, and&nbsp;there would be imbalanced data to train the model. The imbalanced datasets make&nbsp;ML techniques bias their predictions towards low maintainability effort or majority classes, and minority class instances get discarded as noise by the machine learning (ML) techniques. In this direction, this paper presents empirical work to improve the performance of software maintainability prediction (SMP) models developed with ML techniques using imbalanced data. For developing the models, the imbalanced data is pre-processed by applying data resampling methods. Fourteen data resampling methods, including oversampling, undersampling, and hybrid resampling, are used in the study. The study results recommend that the safe-level synthetic minority oversampling technique (Safe-Level-SMOTE) is a useful method to deal with the imbalanced datasets and to develop competent prediction models to forecast software maintainability.},
journal = {Software Quality Journal},
month = dec,
pages = {1581–1614},
numpages = {34},
keywords = {Imbalanced learning, Data resampling, Machine learning, Software maintainability prediction}
}

@inproceedings{10.1145/2499393.2499398,
author = {Calikli, Gul and Bener, Ayse},
title = {An algorithmic approach to missing data problem in modeling human aspects in software development},
year = {2013},
isbn = {9781450320160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499393.2499398},
doi = {10.1145/2499393.2499398},
abstract = {Background: In our previous research, we built defect prediction models by using confirmation bias metrics. Due to confirmation bias developers tend to perform unit tests to make their programs run rather than breaking their code. This, in turn, leads to an increase in defect density. The performance of prediction model that is built using confirmation bias was as good as the models that were built with static code or churn metrics.Aims: Collection of confirmation bias metrics may result in partially "missing data" due to developers' tight schedules, evaluation apprehension and lack of motivation as well as staff turnover. In this paper, we employ Expectation-Maximization (EM) algorithm to impute missing confirmation bias data.Method: We used four datasets from two large-scale companies. For each dataset, we generated all possible missing data configurations and then employed Roweis' EM algorithm to impute missing data. We built defect prediction models using the imputed data. We compared the performances of our proposed models with the ones that used complete data.Results: In all datasets, when missing data percentage is less than or equal to 50% on average, our proposed model that used imputed data yielded performance results that are comparable with the performance results of the models that used complete data.Conclusions: We may encounter the "missing data" problem in building defect prediction models. Our results in this study showed that instead of discarding missing or noisy data, in our case confirmation bias metrics, we can use effective techniques such as EM based imputation to overcome this problem.},
booktitle = {Proceedings of the 9th International Conference on Predictive Models in Software Engineering},
articleno = {10},
numpages = {10},
keywords = {confirmation bias, expectation maximisation (EM) algorithm, handling missing data, software defect prediction},
location = {Baltimore, Maryland, USA},
series = {PROMISE '13}
}

@article{10.1016/j.jss.2021.111012,
author = {Yang, Yingzhuo and Li, Zenan and Wang, Huiyan and Xu, Chang and Ma, Xiaoxing},
title = {Towards effective metamorphic testing by algorithm stability for linear classification programs},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111012},
doi = {10.1016/j.jss.2021.111012},
journal = {J. Syst. Softw.},
month = oct,
numpages = {15},
keywords = {Algorithm stability, Linear classifier, Machine learning program, Metamorphic relation, Metamorphic testing}
}

@inproceedings{10.1145/3302541.3313101,
author = {Sch\"{o}rgenhumer, Andreas and Kahlhofer, Mario and Gr\"{u}nbacher, Paul and M\"{o}ssenb\"{o}ck, Hanspeter},
title = {Can we Predict Performance Events with Time Series Data from Monitoring Multiple Systems?},
year = {2019},
isbn = {9781450362863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302541.3313101},
doi = {10.1145/3302541.3313101},
abstract = {Predicting performance-related events is an important part of proactive fault management. As a result, many approaches exist for the context of single systems. Surprisingly, despite its potential benefits, multi-system event prediction, i.e., using data from multiple, independent systems, has received less attention. We present ongoing work towards an approach for multi-system event prediction that works with limited data and can predict events for new systems. We present initial results showing the feasibility of our approach. Our preliminary evaluation is based on 20 days of continuous, preprocessed monitoring time series data of 90 independent systems. We created five multi-system machine learning models and compared them to the performance of single-system machine learning models. The results show promising prediction capabilities with accuracies and F1-scores over 90% and false-positive-rates below 10%.},
booktitle = {Companion of the 2019 ACM/SPEC International Conference on Performance Engineering},
pages = {9–12},
numpages = {4},
keywords = {supervised machine learning, multivariate timeseries, infrastructure monitoring data, event prediction},
location = {Mumbai, India},
series = {ICPE '19}
}

@inproceedings{10.1145/3278186.3278194,
author = {Santiago, Dionny and Clarke, Peter J. and Alt, Patrick and King, Tariq M.},
title = {Abstract flow learning for web application test generation},
year = {2018},
isbn = {9781450360531},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278186.3278194},
doi = {10.1145/3278186.3278194},
abstract = {Achieving high software quality today involves manual analysis, test planning, documentation of testing strategy and test cases, and the development of scripts to support automated regression testing. To keep pace with software evolution, test artifacts must also be frequently updated. Although test automation practices help mitigate the cost of regression testing, a large gap exists between the current paradigm and fully automated software testing. Researchers and practitioners are realizing the potential for artificial intelligence and machine learning (ML) to help bridge the gap between the testing capabilities of humans and those of machines. This paper presents an ML approach that combines a language specification that includes a grammar that can be used to describe test flows, and a trainable test flow generation model, in order to generate tests in a way that is trainable, reusable across different applications, and generalizable to new applications.},
booktitle = {Proceedings of the 9th ACM SIGSOFT International Workshop on Automating TEST Case Design, Selection, and Evaluation},
pages = {49–55},
numpages = {7},
keywords = {Testing, Test generation, Machine learning, Language, Automation},
location = {Lake Buena Vista, FL, USA},
series = {A-TEST 2018}
}

@article{10.1016/j.procs.2021.09.121,
author = {B\l{}aszczyk, Miko\l{}aj and Jundefineddrzejowicz, Joanna},
title = {Framework for imbalanced data classification},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {192},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.09.121},
doi = {10.1016/j.procs.2021.09.121},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {3477–3486},
numpages = {10},
keywords = {dynamic selection of classifiers, oversampling, imbalanced data}
}

@article{10.1007/s10664-020-09843-6,
author = {Krishna, Rahul and Menzies, Tim},
title = {Learning actionable analytics from multiple software projects},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09843-6},
doi = {10.1007/s10664-020-09843-6},
abstract = {The current generation of software analytics tools are mostly prediction algorithms (e.g. support vector machines, naive bayes, logistic regression, etc). While prediction is useful, after prediction comes planning about what actions to take in order to improve quality. This research seeks methods that generate demonstrably useful guidance on “what to do” within the context of a specific software project. Specifically, we propose XTREE (for within-project planning) and BELLTREE (for cross-project planning) to generating plans that can improve software quality. Each such plan has the property that, if followed, it reduces the expected number of future defect reports. To find this expected number, planning was first applied to data from release x. Next, we looked for change in release x + 1 that conformed to our plans. This procedure was applied using a range of planners from the literature, as well as XTREE. In 10 open-source JAVA systems, several hundreds of defects were reduced in sections of the code that conformed to XTREE’s plans. Further, when compared to other planners, XTREE’s plans were found to be easier to implement (since they were shorter) and more effective at reducing the expected number of defects.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3468–3500},
numpages = {33},
keywords = {Defect prediction, Bellwethers, Planning, Actionable analytics, Data mining}
}

@inproceedings{10.1145/3475716.3475781,
author = {Croft, Roland and Newlands, Dominic and Chen, Ziyu and Babar, M. Ali},
title = {An Empirical Study of Rule-Based and Learning-Based Approaches for Static Application Security Testing},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475781},
doi = {10.1145/3475716.3475781},
abstract = {Background: Static Application Security Testing (SAST) tools purport to assist developers in detecting security issues in source code. These tools typically use rule-based approaches to scan source code for security vulnerabilities. However, due to the significant shortcomings of these tools (i.e., high false positive rates), learning-based approaches for Software Vulnerability Prediction (SVP) are becoming a popular approach. Aims: Despite the similar objectives of these two approaches, their comparative value is unexplored. We provide an empirical analysis of SAST tools and SVP models, to identify their relative capabilities for source code security analysis. Method: We evaluate the detection and assessment performance of several common SAST tools and SVP models on a variety of vulnerability datasets. We further assess the viability and potential benefits of combining the two approaches. Results: SAST tools and SVP models provide similar detection capabilities, but SVP models exhibit better overall performance for both detection and assessment. Unification of the two approaches is difficult due to lacking synergies. Conclusions: Our study generates 12 main findings which provide insights into the capabilities and synergy of these two approaches. Through these observations we provide recommendations for use and improvement.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {8},
numpages = {12},
keywords = {Static Application Security Testing, Security, Machine Learning},
location = {Bari, Italy},
series = {ESEM '21}
}

@inproceedings{10.5555/1756748.1756834,
author = {Choi, Changyeol and Kim, Sungsoo},
title = {Self-configuring algorithm for software fault tolerance in (n,k)-way cluster systems},
year = {2003},
isbn = {3540401555},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Complex software-intensive applications can be built with commercially available systems for cluster systems. To improve availability of (n,k)-way cluster systems, we develop self-configuring algorithm that not only determines the number of primary and backup nodes for meeting the requirement of availability and waiting time deadline, but also uses software rejuvenation for dealing with dormant software faults. Availability modeling of (n,k)-way cluster systems with software rejuvenation has a view of fault tolerance and switchover states with a semi-Markov process. According to the operating parameters, steady-state probabilities and availability are calculated, which are used for self-configuring algorithm.},
booktitle = {Proceedings of the 2003 International Conference on Computational Science and Its Applications: PartI},
pages = {742–751},
numpages = {10},
location = {Montreal, Canada},
series = {ICCSA'03}
}

@inproceedings{10.5555/998675.999452,
author = {Brun, Yuriy and Ernst, Michael D.},
title = {Finding Latent Code Errors via Machine Learning over Program Executions},
year = {2004},
isbn = {0769521630},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper proposes a technique for identifying programproperties that indicate errors. The technique generates machinelearning models of program properties known to resultfrom errors, and applies these models to program propertiesof user-written code to classify and rank propertiesthat may lead the user to errors. Given a set of propertiesproduced by the program analysis, the technique selectssubset of properties that are most likely to reveal an error.An implementation, the Fault Invariant Classifier,demonstrates the efficacy of the technique. The implementationuses dynamic invariant detection to generate programproperties. It uses support vector machine and decision treelearning tools to classify those properties. In our experimentalevaluation, the technique increases the relevance(the concentration of fault-revealing properties) by a factorof 50 on average for the C programs, and 4.8 for the Javaprograms. Preliminary experience suggests that most of thefault-revealing properties do lead a programmer to an error.},
booktitle = {Proceedings of the 26th International Conference on Software Engineering},
pages = {480–490},
numpages = {11},
series = {ICSE '04}
}

@inproceedings{10.1109/ICTAI.2011.172,
author = {Gao, Kehan and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {Impact of Data Sampling on Stability of Feature Selection for Software Measurement Data},
year = {2011},
isbn = {9780769545967},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICTAI.2011.172},
doi = {10.1109/ICTAI.2011.172},
abstract = {Software defect prediction can be considered a binary classification problem. Generally, practitioners utilize historical software data, including metric and fault data collected during the software development process, to build a classification model and then employ this model to predict new program modules as either fault-prone (fp) or not-fault-prone (nfp). Limited project resources can then be allocated according to the prediction results by (for example) assigning more reviews and testing to the modules predicted to be potentially defective. Two challenges often come with the modeling process: (1) high-dimensionality of software measurement data and (2) skewed or imbalanced distributions between the two types of modules (fp and nfp) in those datasets. To overcome these problems, extensive studies have been dedicated towards improving the quality of training data. The commonly used techniques are feature selection and data sampling. Usually, researchers focus on evaluating classification performance after the training data is modified. The present study assesses a feature selection technique from a different perspective. We are more interested in studying the stability of a feature selection method, especially in understanding the impact of data sampling techniques on the stability of feature selection when using the sampled data. Some interesting findings are found based on two case studies performed on datasets from two real-world software projects.},
booktitle = {Proceedings of the 2011  IEEE 23rd International Conference on Tools with Artificial Intelligence},
pages = {1004–1011},
numpages = {8},
keywords = {stability, software metrics, feature selection, defect prediction, data sampling},
series = {ICTAI '11}
}

@article{10.1007/s11219-014-9230-x,
author = {Caglayan, Bora and Tosun Misirli, Ayse and Bener, Ayse Basar and Miranskyy, Andriy},
title = {Predicting defective modules in different test phases},
year = {2015},
issue_date = {June      2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-014-9230-x},
doi = {10.1007/s11219-014-9230-x},
abstract = {Defect prediction is a well-established research area in software engineering . Prediction models in the literature do not predict defect-prone modules in different test phases. We investigate the relationships between defects and test phases in order to build defect prediction models for different test phases. We mined the version history of a large-scale enterprise software product to extract churn and static code metrics. We used three testing phases that have been employed by our industry partner, namely function, system and field, to build a learning-based model for each testing phase. We examined the relation of different defect symptoms with the testing phases. We compared the performance of our proposed model with a benchmark model that has been constructed for the entire test phase (benchmark model). Our results show that building a model to predict defect-prone modules for each test phase significantly improves defect prediction performance and shortens defect detection time. The benefit analysis shows that using the proposed model, the defects are detected on the average 7 months earlier than the actual. The outcome of prediction models should lead to an action in a software development organization. Our proposed model gives a more granular outcome in terms of predicting defect-prone modules in each testing phase so that managers may better organize the testing teams and effort.},
journal = {Software Quality Journal},
month = jun,
pages = {205–227},
numpages = {23},
keywords = {Testing phase, Software testing, Defect prediction}
}

@article{10.1016/j.jss.2021.111044,
author = {Pereira, Juliana Alves and Acher, Mathieu and Martin, Hugo and J\'{e}z\'{e}quel, Jean-Marc and Botterweck, Goetz and Ventresque, Anthony},
title = {Learning software configuration spaces: A systematic literature review},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111044},
doi = {10.1016/j.jss.2021.111044},
journal = {J. Syst. Softw.},
month = dec,
numpages = {29},
keywords = {Configurable systems, Machine learning, Software product lines, Systematic literature review}
}

@article{10.1007/s10489-020-02026-2,
author = {Van Nguyen, Sinh and Tran, Ha Manh},
title = {An automated fault detection system for communication networks and distributed systems},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {8},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-02026-2},
doi = {10.1007/s10489-020-02026-2},
abstract = {Automating fault detection in communication networks and distributed systems is a challenging process that usually requires the involvement of supporting tools and the expertise of system operators. Automated event monitoring and correlating systems produce event data that is forwarded to system operators for analyzing error events and creating fault reports. Machine learning methods help not only analyzing event data more precisely but also forecasting possible error events by learning from existing faults. This study introduces an automated fault detection system that assists system operators in detecting and forecasting faults. This system is characterized by the capability of exploiting bug knowledge resources at various online repositories, log events and status parameters from the monitored system; and applying bug analysis and event filtering methods for evaluating events and forecasting faults. The system contains a fault data model to collect bug reports, a feature and semantic filtering method to correlate log events, and machine learning methods to evaluate the severity, priority and relation of log events and forecast the forthcoming critical faults of the monitored system. We have evaluated the prototyping implementation of the proposed system on a high performance computing cluster system and provided analysis with lessons learned.},
journal = {Applied Intelligence},
month = aug,
pages = {5405–5419},
numpages = {15},
keywords = {Bug tracking system, Random forest, Machine learning, Automation, Fault detection}
}

@inproceedings{10.1145/3377811.3380411,
author = {Zhao, Dehai and Xing, Zhenchang and Chen, Chunyang and Xu, Xiwei and Zhu, Liming and Li, Guoqiang and Wang, Jinshui},
title = {Seenomaly: vision-based linting of GUI animation effects against design-don't guidelines},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380411},
doi = {10.1145/3377811.3380411},
abstract = {GUI animations, such as card movement, menu slide in/out, snackbar display, provide appealing user experience and enhance the usability of mobile applications. These GUI animations should not violate the platform's UI design guidelines (referred to as design-don't guideline in this work) regarding component motion and interaction, content appearing and disappearing, and elevation and shadow changes. However, none of existing static code analysis, functional GUI testing and GUI image comparison techniques can "see" the GUI animations on the scree, and thus they cannot support the linting of GUI animations against design-don't guidelines. In this work, we formulate this GUI animation linting problem as a multi-class screencast classification task, but we do not have sufficient labeled GUI animations to train the classifier. Instead, we propose an unsupervised, computer-vision based adversarial autoencoder to solve this linting problem. Our autoencoder learns to group similar GUI animations by "seeing" lots of unlabeled real-application GUI animations and learning to generate them. As the first work of its kind, we build the datasets of synthetic and real-world GUI animations. Through experiments on these datasets, we systematically investigate the learning capability of our model and its effectiveness and practicality for linting GUI animations, and identify the challenges in this linting problem for future work.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1286–1297},
numpages = {12},
keywords = {GUI animation, design guidelines, lint, unsupervised learning},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3377811.3380369,
author = {Bertolino, Antonia and Guerriero, Antonio and Miranda, Breno and Pietrantuono, Roberto and Russo, Stefano},
title = {Learning-to-rank vs ranking-to-learn: strategies for regression testing in continuous integration},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380369},
doi = {10.1145/3377811.3380369},
abstract = {In Continuous Integration (CI), regression testing is constrained by the time between commits. This demands for careful selection and/or prioritization of test cases within test suites too large to be run entirely. To this aim, some Machine Learning (ML) techniques have been proposed, as an alternative to deterministic approaches. Two broad strategies for ML-based prioritization are learning-to-rank and what we call ranking-to-learn (i.e., reinforcement learning). Various ML algorithms can be applied in each strategy. In this paper we introduce ten of such algorithms for adoption in CI practices, and perform a comprehensive study comparing them against each other using subjects from the Apache Commons project. We analyze the influence of several features of the code under test and of the test process. The results allow to draw criteria to support testers in selecting and tuning the technique that best fits their context.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1–12},
numpages = {12},
keywords = {continuous integration, machine learning, regression testing, test prioritization, test selection},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1007/978-3-030-87007-2_27,
author = {Aladics, Tam\'{a}s and J\'{a}sz, Judit and Ferenc, Rudolf},
title = {Bug Prediction Using Source Code Embedding Based on Doc2Vec},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_27},
doi = {10.1007/978-3-030-87007-2_27},
abstract = {Bug prediction is a resource demanding task that is hard to automate using static source code analysis. In many fields of computer science, machine learning has proven to be extremely useful in tasks like this, however, for it to work we need a way to use source code as input. We propose a simple, but meaningful representation for source code based on its abstract syntax tree and the Doc2Vec embedding algorithm. This representation maps the source code to a fixed length vector which can be used for various upstream tasks – one of which is bug prediction. We measured this approach’s validity by itself and its effectiveness compared to bug prediction based solely on code metrics. We also experimented on numerous machine learning approaches to check the connection between different embedding parameters with different machine learning models. Our results show that this representation provides meaningful information as it improves the bug prediction accuracy in most cases, and is always at least as good as only using code metrics as features.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {382–397},
numpages = {16},
keywords = {Doc2Vec, Java, Bug prediction, Code metrics, Source code embedding},
location = {Cagliari, Italy}
}

@article{10.1109/TSE.2013.59,
author = {Groce, Alex and Kulesza, Todd and Zhang, Chaoqiang and Shamasunder, Shalini and Burnett, Margaret and Wong, Weng-Keen and Stumpf, Simone and Das, Shubhomoy and Shinsel, Amber and Bice, Forrest and McIntosh, Kevin},
title = {You Are the Only Possible Oracle: Effective Test Selection for End Users of Interactive Machine Learning Systems},
year = {2014},
issue_date = {March 2014},
publisher = {IEEE Press},
volume = {40},
number = {3},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2013.59},
doi = {10.1109/TSE.2013.59},
abstract = {How do you test a program when only a single user, with no expertise in software testing, is able to determine if the program is performing correctly? Such programs are common today in the form of machine-learned classifiers. We consider the problem of testing this common kind of machine-generated program when the only oracle is an end user: e.g., only you can determine if your email is properly filed. We present test selection methods that provide very good failure rates even for small test suites, and show that these methods work in both large-scale random experiments using a “gold standard” and in studies with real users. Our methods are inexpensive and largely algorithm-independent. Key to our methods is an exploitation of properties of classifiers that is not possible in traditional software testing. Our results suggest that it is plausible for time-pressured end users to interactively detect failures—even very hard-to-find failures—without wading through a large number of successful (and thus less useful) tests. We additionally show that some methods are able to find the arguably most difficult-to-detect faults of classifiers: cases where machine learning algorithms have high confidence in an incorrect result.},
journal = {IEEE Trans. Softw. Eng.},
month = mar,
pages = {307–323},
numpages = {17}
}

@article{10.1109/TCBB.2018.2822803,
author = {Sevakula, Rahul K. and Singh, Vikas and Verma, Nishchal K. and Kumar, Chandan and Cui, Yan},
title = {Transfer Learning for Molecular Cancer Classification Using Deep Neural Networks},
year = {2019},
issue_date = {Nov.-Dec. 2019},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {16},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2018.2822803},
doi = {10.1109/TCBB.2018.2822803},
abstract = {The emergence of deep learning has impacted numerous machine learning based applications and research. The reason for its success lies in two main advantages: 1) it provides the ability to learn very complex non-linear relationships between features and 2) it allows one to leverage information from unlabeled data that does not belong to the problem being handled. This paper presents a transfer learning procedure for cancer classification, which uses feature selection and normalization techniques in conjunction with s sparse auto-encoders on gene expression data. While classifying any two tumor types, data of other tumor types were used in unsupervised manner to improve the feature representation. The performance of our algorithm was tested on 36 two-class benchmark datasets from the GEMLeR repository. On performing statistical tests, it is clearly ascertained that our algorithm statistically outperforms several generally used cancer classification approaches. The deep learning based molecular disease classification can be used to guide decisions made on the diagnosis and treatment of diseases, and therefore may have important applications in precision medicine.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = dec,
pages = {2089–2100},
numpages = {12}
}

@article{10.1016/j.jksuci.2018.05.008,
author = {Bhatt, Arpita Jadhav and Gupta, Chetna and Mittal, Sangeeta},
title = {iABC-AL: Active learning-based privacy leaks threat detection for iOS applications},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {33},
number = {7},
issn = {1319-1578},
url = {https://doi.org/10.1016/j.jksuci.2018.05.008},
doi = {10.1016/j.jksuci.2018.05.008},
journal = {J. King Saud Univ. Comput. Inf. Sci.},
month = sep,
pages = {769–786},
numpages = {18},
keywords = {Active learning, Permission extraction, Static analysis, Information security, iOS applications}
}

@inproceedings{10.1145/3482909.3482916,
author = {Camara, Bruno and Silva, Marco and Endo, Andre and Vergilio, Silvia},
title = {On the use of test smells for prediction of flaky tests},
year = {2021},
isbn = {9781450385039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3482909.3482916},
doi = {10.1145/3482909.3482916},
abstract = {Regression testing is an important phase to deliver software with quality. However, flaky tests hamper the evaluation of test results and can increase costs. This is because a flaky test may pass or fail non-deterministically and to identify properly the flakiness of a test requires rerunning the test suite multiple times. To cope with this challenge, approaches have been proposed based on prediction models and machine learning. Existing approaches based on the use of the test case vocabulary may be context-sensitive and prone to overfitting, presenting low performance when executed in a cross-project scenario. To overcome these limitations, we investigate the use of test smells as predictors of flaky tests. We conducted an empirical study to understand if test smells have good performance as a classifier to predict the flakiness in the cross-project context, and analysed the information gain of each test smell. We also compared the test smell-based approach with the vocabulary-based one. As a result, we obtained a classifier that had a reasonable performance (Random Forest, 0.83%) to predict the flakiness in the testing phase. This classifier presented better performance than vocabulary-based model for cross-project prediction. The Assertion Roulette and Sleepy Test test smell types are the ones associated with the best information gain values.},
booktitle = {Proceedings of the 6th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {46–54},
numpages = {9},
keywords = {test smells, test flakiness, regression testing, machine learning},
location = {Joinville, Brazil},
series = {SAST '21}
}

@inproceedings{10.5555/3540261.3541858,
author = {Li, Yu and Li, Min and Lai, Qiuxia and Liu, Yannan and Xu, Qiang},
title = {TestRank: bringing order into unlabeled test instances for deep learning tasks},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep learning (DL) systems are notoriously difficult to test and debug due to the lack of correctness proof and the huge test input space to cover. Given the ubiquitous unlabeled test data and high labeling cost, in this paper, we propose a novel test input prioritization technique, namely TestRank, which aims at revealing more model failures with less labeling effort. TestRank brings order into the unlabeled test data according to their likelihood of being a failure, i.e., their failure-revealing capabilities. Different from existing solutions, TestRank leverages both intrinsic and contextual attributes of the unlabeled test data when prioritizing them. To be specific, we first build a similarity graph on both unlabeled test samples and labeled samples (e.g., training or previously labeled test samples). Then, we conduct graph-based semi-supervised learning to extract contextual features from the correctness of similar labeled samples. For a particular test instance, the contextual features extracted with the graph neural network and the intrinsic features obtained with the DL model itself are combined to predict its failure-revealing capability. Finally, TestRank prioritizes unlabeled test inputs in descending order of the above probability value. We evaluate TestRank on three popular image classification datasets, and results show that TestRank significantly outperforms existing test input prioritization techniques.},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {1597},
numpages = {13},
series = {NIPS '21}
}

@inproceedings{10.1145/3377816.3381738,
author = {Arokiam, Jude and Bradbury, Jeremy S.},
title = {Automatically predicting bug severity early in the development process},
year = {2020},
isbn = {9781450371261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377816.3381738},
doi = {10.1145/3377816.3381738},
abstract = {Bug severity is an important factor in prioritizing which bugs to fix first. The process of triaging bug reports and assigning a severity requires developer expertise and knowledge of the underlying software. Methods to automate the assignment of bug severity have been developed to reduce the developer cost, however, many of these methods require 70-90% of the project's bug reports as training data and delay their use until later in the development process. Not being able to automatically predict a bug report's severity early in a project can greatly reduce the benefits of automation. We have developed a new bug report severity prediction method that leverages how bug reports are written rather than what the bug reports contain. Our method allows for the prediction of bug severity at the beginning of the project by using an organization's historical data, in the form of bug reports from past projects, to train the prediction classifier. In validating our approach, we conducted over 1000 experiments on a dataset of five NASA robotic mission software projects. Our results demonstrate that our method was not only able to predict the severity of bugs earlier in development, but it was also able to outperform an existing keyword-based classifier for a majority of the NASA projects.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {17–20},
numpages = {4},
keywords = {natural language processing, machine learning, bug severity},
location = {Seoul, South Korea},
series = {ICSE-NIER '20}
}

@inproceedings{10.1145/3205651.3208262,
author = {Ebert, Samuel and Farhana, Effat and Heber, Steffen},
title = {A parallel island model for biogeography-based classification rule mining in julia},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3208262},
doi = {10.1145/3205651.3208262},
abstract = {In this paper, we present a distributed island model implementation of biogeography-based optimization for classification rule mining (island BBO-RM). Island BBO-RM is an evolutionary algorithm for rule mining that uses Pittsburgh style classification rule encoding, which represents an entire ruleset (classifier) as a single chromosome. Our algorithm relies on biogeography-based optimization (BBO), an optimization technique that is inspired by species migration pattern between habitats. Biogeography-based optimization has been reported to perform well in various applications ranging from function optimization to image classification. A major limitation of evolutionary rule mining algorithms is their high computational cost and running time. To address this challenge, we have applied a distributed island model to parallelize the rule extraction phase via BBO. We have explored several different migration topologies and data windowing techniques. Our algorithm is implemented in Julia, a dynamic programming language designed for high-performance and parallel computation. Our results show that our distributed implementation is able to achieve considerable speedups when compared to a serial implementation. Without data windowing, we obtain speedups up to a factor of nine without a loss of classification accuracy. With data windowing, we obtain speedups up to a factor of 30 with a small loss of accuracy in some cases.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1284–1291},
numpages = {8},
keywords = {island model, genetics-based machine learning, evolutionary algorithms, biogeography-based optimization},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@inproceedings{10.1007/978-3-030-91265-9_12,
author = {Yan, Yue and Jiang, Shujuan and Zhang, Shenggang and Huang, Ying},
title = {CSFL: Fault Localization on Real Software Bugs Based on the Combination of Context and Spectrum},
year = {2021},
isbn = {978-3-030-91264-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91265-9_12},
doi = {10.1007/978-3-030-91265-9_12},
abstract = {Spectrum-based fault localization has been intensively studied recently. Previous studies have shown that the traditional spectrum-based fault localization applies statistical analysis on the coverage information about failed or passed tests to calculate the suspiciousness of program elements by specific formula. However, the traditional spectrum-based fault localization does not consider the propagation of faults, it only counts whether a single program element is covered by failed or passed tests. In this work, we propose an approach of Context and Spectrum based Fault Localization (CSFL), which combines program context analysis with spectrum for fault localization. Program context can not only improve the effectiveness of fault localization, but also provides help for developers. CSFL has been studied on 414 real bugs from the widely used Defects4J benchmark. The experimental results show that CSFL outperforms the SBFL techniques (e.g., localizing 61 more faults within Top-1). Furthermore, we also investigate the time cost of CSFL.},
booktitle = {Dependable Software Engineering. Theories, Tools, and Applications: 7th International Symposium, SETTA 2021, Beijing, China, November 25–27, 2021, Proceedings},
pages = {219–238},
numpages = {20},
keywords = {Real software bugs, Context analysis, Spectrum-based, Software fault localization},
location = {Beijing, China}
}

@inproceedings{10.1145/3383219.3383268,
author = {Lenz, Luca and Felderer, Michael and Schwedes, Sascha and M\"{u}ller, Kai},
title = {Explainable Priority Assessment of Software-Defects using Categorical Features at SAP HANA},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383268},
doi = {10.1145/3383219.3383268},
abstract = {We want to automate priority assessment of software defects. To do so we provide a tool which uses an explainability-driven framework and classical machine learning algorithms to keep the decisions transparent. Differing from other approaches we only use objective and categorical fields from the bug tracking system as features. This makes our approach lightweight and extremely fast. We perform binary classification with priority labels corresponding to deadlines. Additionally, we evaluate the tool on real data to ensure good performance in the practical use case.},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {366–367},
numpages = {2},
keywords = {software quality, machine learning, defect assessment, bug priority},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1109/ICSE43902.2021.00067,
author = {Li, Yi and Wang, Shaohua and Nguyen, Tien N.},
title = {Fault Localization with Code Coverage Representation Learning},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00067},
doi = {10.1109/ICSE43902.2021.00067},
abstract = {In this paper, we propose DEEPRL4FL, a deep learning fault localization (FL) approach that locates the buggy code at the statement and method levels by treating FL as an image pattern recognition problem. DEEPRL4FL does so via novel code coverage representation learning (RL) and data dependencies RL for program statements. Those two types of RL on the dynamic information in a code coverage matrix are also combined with the code representation learning on the static information of the usual suspicious source code. This combination is inspired by crime scene investigation in which investigators analyze the crime scene (failed test cases and statements) and related persons (statements with dependencies), and at the same time, examine the usual suspects who have committed a similar crime in the past (similar buggy code in the training data).For the code coverage information, DEEPRL4FL first orders the test cases and marks error-exhibiting code statements, expecting that a model can recognize the patterns discriminating between faulty and non-faulty statements/methods. For dependencies among statements, the suspiciousness of a statement is seen taking into account the data dependencies to other statements in execution and data flows, in addition to the statement by itself. Finally, the vector representations for code coverage matrix, data dependencies among statements, and source code are combined and used as the input of a classifier built from a Convolution Neural Network to detect buggy statements/methods. Our empirical evaluation shows that DEEPRL4FL improves the top-1 results over the state-of-the-art statement-level FL baselines from 173.1% to 491.7%. It also improves the top-1 results over the existing method-level FL baselines from 15.0% to 206.3%.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {661–673},
numpages = {13},
keywords = {representation learning, machine learning, fault localization, deep learning, code coverage},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1016/j.neucom.2019.01.080,
author = {Wang, Shuo and Minku, Leandro L. and Chawla, Nitesh and Yao, Xin},
title = {Learning in the presence of class imbalance and concept drift},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {343},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.01.080},
doi = {10.1016/j.neucom.2019.01.080},
journal = {Neurocomput.},
month = may,
pages = {1–2},
numpages = {2}
}

@inproceedings{10.1145/3010079.3010086,
author = {Garcia, Washington and Benson, Theophilus},
title = {A First Look at Bugs in OpenStack},
year = {2016},
isbn = {9781450346733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3010079.3010086},
doi = {10.1145/3010079.3010086},
abstract = {An increasing amount of popular services are utilizing cloud infrastructure due to its convenience, low cost, and scalability. However, as more services turn to cloud as a means of storing and delivering data to consumers, the faults of cloud infrastructure become more apparent. When cloud infrastructure fails, the consequences are disastrous, with failures making national headlines. Popular services such as Amazon, Quora, Netflix, and many social media sites all rely on cloud computing at their core. Although new cloud infrastructures have sprouted in recent years, there is limited knowledge about what type of bugs they contain, and how these bugs affect quality of service of cloud components. We propose a system that can automatically classify bug tickets using the natural language descriptions provided by developers. We then utilize this system to classify a random sub-sample of 30k OpenStack bugs, and reveal trends related to OpenStack releases, priority assignments, and project characteristics. For example, we find that existing issues make up over 70% of bugs in OpenStack modules, with over half of these bugs corresponding to reliability.},
booktitle = {Proceedings of the 2016 ACM Workshop on Cloud-Assisted Networking},
pages = {67–72},
numpages = {6},
keywords = {software bugs, openstack, machine learning, cloud},
location = {Irvine, California, USA},
series = {CAN '16}
}

@inproceedings{10.1007/978-3-030-91452-3_19,
author = {J\"{o}ckel, Lisa and Bauer, Thomas and Kl\"{a}s, Michael and Hauer, Marc P. and Gro\ss{}, Janek},
title = {Towards a Common Testing Terminology for Software Engineering and Data Science Experts},
year = {2021},
isbn = {978-3-030-91451-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91452-3_19},
doi = {10.1007/978-3-030-91452-3_19},
abstract = {Analytical quality assurance, especially testing, is an integral part of software-intensive system development. With the increased usage of Artificial Intelligence (AI) and Machine Learning (ML) as part of such systems, this becomes more difficult as well-understood software testing approaches cannot be applied directly to the AI-enabled parts of the system. The required adaptation of classical testing approaches and the development of new concepts for AI would benefit from a deeper understanding and exchange between AI and software engineering experts. We see the different terminologies used in the two communities as a major obstacle on this way. As we consider a mutual understanding of the testing terminology a key, this paper contributes a mapping between the most important concepts from classical software testing and AI testing. In the mapping, we highlight differences in the relevance and naming of the mapped concepts.},
booktitle = {Product-Focused Software Process Improvement: 22nd International Conference, PROFES 2021, Turin, Italy, November 26, 2021, Proceedings},
pages = {281–289},
numpages = {9},
keywords = {Target application scope, Concept mapping, Definitions, Artificial intelligence testing, Quality characteristics, Data-driven model, Machine learning evaluation, Analytical quality assurance},
location = {Turin, Italy}
}

@article{10.1007/s10664-020-09848-1,
author = {Jiarpakdee, Jirayus and Tantithamthavorn, Chakkrit and Treude, Christoph},
title = {The impact of automated feature selection techniques on the interpretation of defect models},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09848-1},
doi = {10.1007/s10664-020-09848-1},
abstract = {The interpretation of defect models heavily relies on software metrics that are used to construct them. Prior work often uses feature selection techniques to remove metrics that are correlated and irrelevant in order to improve model performance. Yet, conclusions that are derived from defect models may be inconsistent if the selected metrics are inconsistent and correlated. In this paper, we systematically investigate 12 automated feature selection techniques with respect to the consistency, correlation, performance, computational cost, and the impact on the interpretation dimensions. Through an empirical investigation of 14 publicly-available defect datasets, we find that (1) 94–100% of the selected metrics are inconsistent among the studied techniques; (2) 37–90% of the selected metrics are inconsistent among training samples; (3) 0–68% of the selected metrics are inconsistent when the feature selection techniques are applied repeatedly; (4) 5–100% of the produced subsets of metrics contain highly correlated metrics; and (5) while the most important metrics are inconsistent among correlation threshold values, such inconsistent most important metrics are highly-correlated with the Spearman correlation of 0.85–1. Since we find that the subsets of metrics produced by the commonly-used feature selection techniques (except for AutoSpearman) are often inconsistent and correlated, these techniques should be avoided when interpreting defect models. In addition to introducing AutoSpearman which mitigates correlated metrics better than commonly-used feature selection techniques, this paper opens up new research avenues in the automated selection of features for defect models to optimise for interpretability as well as performance.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3590–3638},
numpages = {49},
keywords = {Feature selection, Model interpretation, Defect prediction, Software analytics}
}

@article{10.1007/s10664-020-09915-7,
author = {Temple, Paul and Perrouin, Gilles and Acher, Mathieu and Biggio, Battista and J\'{e}z\'{e}quel, Jean-Marc and Roli, Fabio},
title = {Empirical assessment of generating adversarial configurations for software product lines},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09915-7},
doi = {10.1007/s10664-020-09915-7},
abstract = {Software product line (SPL) engineering allows the derivation of products tailored to stakeholders’ needs through the setting of a large number of configuration options. Unfortunately, options and their interactions create a huge configuration space which is either intractable or too costly to explore exhaustively. Instead of covering all products, machine learning (ML) approximates the set of acceptable products (e.g., successful builds, passing tests) out of a training set (a sample of configurations). However, ML techniques can make prediction errors yielding non-acceptable products wasting time, energy and other resources. We apply adversarial machine learning techniques to the world of SPLs and craft new configurations faking to be acceptable configurations but that are not and vice-versa. It allows to diagnose prediction errors and take appropriate actions. We develop two adversarial configuration generators on top of state-of-the-art attack algorithms and capable of synthesizing configurations that are both adversarial and conform to logical constraints. We empirically assess our generators within two case studies: an industrial video synthesizer (MOTIV) and an industry-strength, open-source Web-app configurator (JHipster). For the two cases, our attacks yield (up to) a 100% misclassification rate without sacrificing the logical validity of adversarial configurations. This work lays the foundations of a quality assurance framework for ML-based SPLs.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {49},
keywords = {Quality assurance, Machine learning, Software testing, Software variability, Configurable system, Software product line}
}

@inproceedings{10.1145/3468264.3468545,
author = {Suneja, Sahil and Zheng, Yunhui and Zhuang, Yufan and Laredo, Jim A. and Morari, Alessandro},
title = {Probing model signal-awareness via prediction-preserving input minimization},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468545},
doi = {10.1145/3468264.3468545},
abstract = {This work explores the signal awareness of AI models for source code understanding. Using a software vulnerability detection use case, we evaluate the models' ability to capture the correct vulnerability signals to produce their predictions. Our prediction-preserving input minimization (P2IM) approach systematically reduces the original source code to a minimal snippet which a model needs to maintain its prediction. The model's reliance on incorrect signals is then uncovered when the vulnerability in the original code is missing in the minimal snippet, both of which the model however predicts as being vulnerable. We measure the signal awareness of models using a new metric we propose -- Signal-aware Recall (SAR). We apply P2IM on three different neural network architectures across multiple datasets. The results show a sharp drop in the model's Recall from the high 90s to sub-60s with the new metric, highlighting that the models are presumably picking up a lot of noise or dataset nuances while learning their vulnerability detection logic. Although the drop in model performance may be perceived as an adversarial attack, but this isn't P2IM's objective. The idea is rather to uncover the signal-awareness of a black-box model in a data-driven manner via controlled queries. SAR's purpose is to measure the impact of task-agnostic model training, and not to suggest a shortcoming in the Recall metric. The expectation, in fact, is for SAR to match Recall in the ideal scenario where the model truly captures task-specific signals.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {945–955},
numpages = {11},
keywords = {signal-aware recall, model signal-awareness, machine learning},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@article{10.1504/ijiei.2021.118275,
author = {Mittal, Shruti and Nagpal, Chander Kumar},
title = {Reinforcement learning based predictive analytics framework for survival in stock market},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {3},
issn = {1758-8715},
url = {https://doi.org/10.1504/ijiei.2021.118275},
doi = {10.1504/ijiei.2021.118275},
abstract = {Contemporary research in stock market domain is limited to forecasting of the stock price from one day to one week. Such small period predictions cannot be of much help for continuous gainful survival in the stock market. In fact, there has to be predictive analytics framework which analyses the current situation in the holistic manner and provides the appropriate advice for selling/buying/no action along with the quantity resulting in significant gain for the user/investor. The proposed framework generates various reinforcement signals by applying statistical and machine learning techniques on historical data and studies their impact on the stock prices by analysing future data. The outcome of the process has been used to generate rewards, through the use of fuzzy logic, for various actions in a given state of the environment. Fully automated implementation of the proposed framework can help both institutional and common investor in taking the rational decision.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {294–327},
numpages = {33},
keywords = {single value decomposition, stock technical analysis, stock fundamental, fuzzy rule base, finite state machine, fuzzy sets and logic, reinforcement learning, stock market predictions, machine learning, statistical learning, predictive analytics}
}

@article{10.1007/s10462-012-9360-0,
author = {Jenhani, Ilyes and Elouedi, Zied},
title = {Re-visiting the artificial immune recognition system: a survey and an improved version},
year = {2014},
issue_date = {December  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {42},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-012-9360-0},
doi = {10.1007/s10462-012-9360-0},
abstract = {This paper surveys the major works related to an artificial immune system based classifier that was proposed in the 2000s, namely, the artificial immune recognition system (AIRS) algorithm. This survey has revealed that most works on AIRS was dedicated to the application of the algorithm to real-world problems rather than to theoretical developments of the algorithm. Based on this finding, we propose an improved version of the AIRS algorithm which we dub AIRS3. AIRS3 takes into account an important parameter that was ignored by the original algorithm, namely, the number of training antigens represented by each memory cell at the end of learning (numRepAg). Experiments of the new AIRS3 algorithm on data sets taken from the UCI machine learning repository have shown that taking into account the numRepAg information enhances the classification accuracy of AIRS.},
journal = {Artif. Intell. Rev.},
month = dec,
pages = {821–833},
numpages = {13},
keywords = {Machine learning, Classification, Artificial immune systems, Artificial immune recognition systems (AIRS)}
}

@inproceedings{10.1145/3193977.3193978,
author = {Xu, Liming and Towey, Dave and French, Andrew P. and Benford, Steve and Zhou, Zhi Quan and Chen, Tsong Yueh},
title = {Enhancing supervised classifications with metamorphic relations},
year = {2018},
isbn = {9781450357296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3193977.3193978},
doi = {10.1145/3193977.3193978},
abstract = {We report on a novel use of metamorphic relations (MRs) in machine learning: instead of conducting metamorphic testing, we use MRs for the augmentation of the machine learning algorithms themselves. In particular, we report on how MRs can enable enhancements to an image classification problem of images containing hidden visual markers ("Artcodes").Working on an original classifier, and using the characteristics of two different categories of images, two MRs, based on separation and occlusion, were used to improve the performance of the classifier. Our experimental results show that the MR-augmented classifier achieves better performance than the original classifier, algorithms, and extending the use of MRs beyond the context of software testing.},
booktitle = {Proceedings of the 3rd International Workshop on Metamorphic Testing},
pages = {46–53},
numpages = {8},
keywords = {supervised classification, random forests, metamorphic testing, metamorphic relations, artcodes},
location = {Gothenburg, Sweden},
series = {MET '18}
}

@article{10.1016/j.ins.2011.01.026,
author = {Park, Byoung-Jun and Oh, Sung-Kwun and Pedrycz, Witold},
title = {The design of polynomial function-based neural network predictors for detection of software defects},
year = {2013},
issue_date = {April, 2013},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {229},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2011.01.026},
doi = {10.1016/j.ins.2011.01.026},
abstract = {In this study, we introduce a design methodology of polynomial function-based Neural Network (pf-NN) classifiers (predictors). The essential design components include Fuzzy C-Means (FCM) regarded as a generic clustering algorithm and polynomials providing all required nonlinear capabilities of the model. The learning method uses a weighted cost function (objective function) while to analyze the performance of the system we engage a standard receiver operating characteristics (ROC) analysis. The proposed networks are used to detect software defects. From the conceptual standpoint, the classifier of this form can be expressed as a collection of ''if-then'' rules. Fuzzy clustering (Fuzzy C-Means, FCM) is aimed at the development of premise layer of the rules while the corresponding consequences of the rules are formed by some local polynomials. A detailed learning algorithm for the pf-NNs is presented with particular provisions made for dealing with imbalanced classes encountered quite commonly in software quality problems. The use of simple measures such as accuracy of classification becomes questionable. In the assessment of quality of classifiers, we confine ourselves to the use of the area under curve (AUC) in the receiver operating characteristics (ROCs) analysis. AUC comes as a sound classifier metric capturing a tradeoff between the high true positive rate (TP) and the low false positive rate (FP). The performance of the proposed classifier is contrasted with the results produced by some ''standard'' Radial Basis Function (RBF) neural networks.},
journal = {Inf. Sci.},
month = apr,
pages = {40–57},
numpages = {18},
keywords = {Two-class discrimination, Software defect, Pattern classification, Neural networks, Imbalanced data, Fuzzy clustering}
}

@inproceedings{10.1145/3368089.3409723,
author = {She, Dongdong and Krishna, Rahul and Yan, Lu and Jana, Suman and Ray, Baishakhi},
title = {MTFuzz: fuzzing with a multi-task neural network},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409723},
doi = {10.1145/3368089.3409723},
abstract = {Fuzzing is a widely used technique for detecting software bugs and vulnerabilities. Most popular fuzzers generate new inputs using an evolutionary search to maximize code coverage. Essentially, these fuzzers start with a set of seed inputs, mutate them to generate new inputs, and identify the promising inputs using an evolutionary fitness function for further mutation.Despite their success, evolutionary fuzzers tend to get stuck in long sequences of unproductive mutations. In recent years, machine learning (ML) based mutation strategies have reported promising results. However, the existing ML-based fuzzers are limited by the lack of quality and diversity of the training data. As the input space of the target programs is high dimensional and sparse, it is prohibitively expensive to collect many diverse samples demonstrating successful and unsuccessful mutations to train the model.In this paper, we address these issues by using a Multi-Task Neural Network that can learn a compact embedding of the input space based on diverse training samples for multiple related tasks (i.e.,predicting for different types of coverage). The compact embedding can guide the mutation process by focusing most of the mutations on the parts of the embedding where the gradient is high. MTFuzz uncovers 11 previously unseen bugs and achieves an average of 2\texttimes{} more edge coverage compared with 5 state-of-the-art fuzzer on 10 real-world programs},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {737–749},
numpages = {13},
keywords = {Multi-task learning, Machine learning, Fuzzing},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/2365324.2365326,
author = {Shepperd, Martin},
title = {The scientific basis for prediction research},
year = {2012},
isbn = {9781450312417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2365324.2365326},
doi = {10.1145/2365324.2365326},
abstract = {In recent years there has been a huge growth in using statistical and machine learning methods to find useful prediction systems for software engineers. Of particular interest is predicting project effort and duration and defect behaviour. Unfortunately though results are often promising no single technique dominates and there are clearly complex interactions between technique, training methods and the problem domain. Since we lack deep theory our research is of necessity experimental. Minimally, as scientists, we need reproducible studies. We also need comparable studies. I will show through a meta-analysis of many primary studies that we are not presently in that situation and so the scientific basis for our collective research remains in doubt. By way of remedy I will argue that we need to address these issues of reporting protocols and expertise plus ensure blind analysis is routine.},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering},
pages = {1–2},
numpages = {2},
keywords = {defect prediction, empirical research, machine learning, software metrics},
location = {Lund, Sweden},
series = {PROMISE '12}
}

@inproceedings{10.1145/131214.131271,
author = {Gambhir, Dinesh and Frish, Ivan and Post, Micheal},
title = {Software fault isolation in wide area networks},
year = {1992},
isbn = {0897914724},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/131214.131271},
doi = {10.1145/131214.131271},
abstract = {The problem of real-time detection and isolation of errors in distributed software systems operating in a wide-area networked environment is considered. The approach presented combines the results of static software analysis with dynamic event-driven monitoring. Static software analysis is used to generate a model of the distributed system. The model describes all possible executions of the processes composing the distributed system. The event-driven monitoring algorithm upon detecting an erroneous event uses the model to isolate the distributed software process states causing the fault. Because this approach does not require the use of the network for fault isolation, it is ideal for use in the low-bandwidth, high-latency communications environments characterizing wide-area networks.},
booktitle = {Proceedings of the 1992 ACM Annual Conference on Communications},
pages = {451–458},
numpages = {8},
location = {Kansas City, Missouri, USA},
series = {CSC '92}
}

@article{10.1007/s11219-019-09490-1,
author = {Kudjo, Patrick Kwaku and Chen, Jinfu and Mensah, Solomon and Amankwah, Richard and Kudjo, Christopher},
title = {The effect of Bellwether analysis on software vulnerability severity prediction models},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-019-09490-1},
doi = {10.1007/s11219-019-09490-1},
abstract = {Vulnerability severity prediction (VSP) models provide useful insight for vulnerability prioritization and software maintenance. Previous studies have proposed a variety of machine learning algorithms as an important paradigm for VSP. However, to the best of our knowledge, there are no other existing research studies focusing on investigating how a subset of features can be used to improve VSP. To address this deficiency, this paper presents a general framework for VSP using the Bellwether analysis (i.e., exemplary data). First, we apply the natural language processing techniques to the textual descriptions of software vulnerability. Next, we developed an algorithm termed Bellvul to identify and select an exemplary subset of data (referred to as Bellwether) to be considered as the training set to yield improved prediction accuracy against the growing portfolio, within-project cases, and the k-fold cross-validation subset. Finally, we assessed the performance of four machine learning algorithms, namely, deep neural network, logistic regression, k-nearest neighbor, and random forest using the sampled instances. The prediction results of the suggested models and the benchmark techniques were assessed based on the standard classification evaluation metrics such as precision, recall, and F-measure. The experimental result shows that the Bellwether approach achieves F-measure ranging from 14.3% to 97.8%, which is an improvement over the benchmark techniques. In conclusion, the proposed approach is a promising research direction for assisting software engineers when seeking to predict instances of vulnerability records that demand much attention prior to software release.},
journal = {Software Quality Journal},
month = dec,
pages = {1413–1446},
numpages = {34},
keywords = {Severity, Machine learning algorithms, Feature selection, Software vulnerability, Bellwether}
}

@article{10.1016/j.ins.2019.04.060,
author = {Le, Tuong and Vo, Bay and Fujita, Hamido and Nguyen, Ngoc-Thanh and Baik, Sung Wook},
title = {A fast and accurate approach for bankruptcy forecasting using squared logistics loss with GPU-based extreme gradient boosting},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {494},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.04.060},
doi = {10.1016/j.ins.2019.04.060},
journal = {Inf. Sci.},
month = aug,
pages = {294–310},
numpages = {17},
keywords = {Class imbalance problem, GPU computing, Squared logistics loss, Extreme gradient boosting, Bankruptcy forecasting}
}

@inproceedings{10.1145/3121257.3121262,
author = {Czech, Mike and H\"{u}llermeier, Eyke and Jakobs, Marie-Christine and Wehrheim, Heike},
title = {Predicting rankings of software verification tools},
year = {2017},
isbn = {9781450351577},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3121257.3121262},
doi = {10.1145/3121257.3121262},
abstract = {Today, software verification tools have reached the maturity to be used for large scale programs. Different tools perform differently well on varying code. A software developer is hence faced with the problem of choosing a tool appropriate for her program at hand. A ranking of tools on programs could facilitate the choice. Such rankings can, however, so far only be obtained by running all considered tools on the program.  In this paper, we present a machine learning approach to predicting rankings of tools on programs. The method builds upon so-called label ranking algorithms, which we complement with appropriate kernels providing a similarity measure for programs. Our kernels employ a graph representation for software source code that mixes elements of control flow and program dependence graphs with abstract syntax trees. Using data sets from the software verification competition SV-COMP, we demonstrate our rank prediction technique to generalize well and achieve a rather high predictive accuracy (rank correlation &gt; 0.6).},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Software Analytics},
pages = {23–26},
numpages = {4},
keywords = {ranking, machine learning, Software verification},
location = {Paderborn, Germany},
series = {SWAN 2017}
}

@inproceedings{10.1145/3468264.3473131,
author = {Ma, Yu-Seung and Yoo, Shin and Kim, Taeho},
title = {Selecting test inputs for DNNs using differential testing with subspecialized model instances},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473131},
doi = {10.1145/3468264.3473131},
abstract = {Testing of Deep Learning (DL) models is difficult due to the lack of automated test oracle and the high cost of human labelling. Differential testing has been used as a surrogate oracle, but there is no systematic guide on how to choose the reference model to use for differential testing. We propose a novel differential testing approach based on subspecialized models, i.e., models that are trained on sliced training data only (hence specialized for the slice). A preliminary evaluation of our approach with an CNN-based EMNIST image classifier shows that it can achieve higher error detection rate with selected inputs compared to using more advanced ResNet and LeNet as the reference model for differential testing. Our approach also outperforms N-version testing, i.e., the use of the same DL model architecture trained separately but using the same data.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1467–1470},
numpages = {4},
keywords = {Test Oracle, Machine Learning, Diffrential Testing},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.5555/2486788.2486839,
author = {Nam, Jaechang and Pan, Sinno Jialin and Kim, Sunghun},
title = {Transfer defect learning},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {Many software defect prediction approaches have been proposed and most are effective in within-project prediction settings. However, for new projects or projects with limited training data, it is desirable to learn a prediction model by using sufficient training data from existing source projects and then apply the model to some target projects (cross-project defect prediction). Unfortunately, the performance of cross-project defect prediction is generally poor, largely because of feature distribution differences between the source and target projects. In this paper, we apply a state-of-the-art transfer learning approach, TCA, to make feature distributions in source and target projects similar. In addition, we propose a novel transfer defect learning approach, TCA+, by extending TCA. Our experimental results for eight open-source projects show that TCA+ significantly improves cross-project prediction performance.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {382–391},
numpages = {10},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/3452383.3452392,
author = {Mondal, Saikat and Saifullah, C M Khaled and Bhattacharjee, Avijit and Rahman, Mohammad Masudur and Roy, Chanchal K.},
title = {Early Detection and Guidelines to Improve Unanswered Questions on Stack Overflow},
year = {2021},
isbn = {9781450390460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452383.3452392},
doi = {10.1145/3452383.3452392},
abstract = {Stack Overflow is one of the largest and most popular question-answering (Q&amp;A) websites. It accumulates millions of programming related questions and answers to support the developers in software development. Unfortunately, a large number of questions are not answered at all, which might hurt the quality or purpose of this community-oriented knowledge base. Up to 29% of Stack Overflow questions do not have any answers. There have been existing attempts in detecting the unanswered questions. Unfortunately, they primarily rely on the question attributes (e.g., score, view count) that are not available during the submission of a question. Detection of the potentially unanswered questions in advance during question submission could help one improve the question and thus receive the answers in time. In this paper, we compare unanswered and answered questions quantitatively and qualitatively by analyzing a total of 4.8 million questions from Stack Overflow. We find that topics discussed in the question, the experience of the question submitter, and readability of question texts could often determine whether a question would be answered or not. Our qualitative study also reveals several other non-trivial factors that not only explain (partially) why the questions remain unanswered but also guide the novice users to improve their questions. We develop four machine learning models to predict the unanswered questions during their submission. According to the experiments, our models predict the unanswered questions with a maximum of about 79% accuracy and significantly outperform the state-of-the-art prediction models.},
booktitle = {Proceedings of the 14th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {9},
numpages = {11},
keywords = {Stack Overflow, machine learning, prediction model, question attributes, unanswered questions},
location = {Bhubaneswar, Odisha, India},
series = {ISEC '21}
}

@inproceedings{10.1145/2961111.2962601,
author = {Soltanifar, Behjat and Erdem, Atakan and Bener, Ayse},
title = {Predicting Defectiveness of Software Patches},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962601},
doi = {10.1145/2961111.2962601},
abstract = {Context: Software code review, as an engineering best practice, refers to the inspection of the code change in order to find possible defects and ensure change quality. Code reviews, however, may not guarantee finding the defects. Thus, there is a risk for a defective code change in a given patch, to pass the review process and be submitted.Goal: In this research, we aim to apply different machine learning algorithms in order to predict the defectiveness of a patch after being reviewed, at the time of its submission.Method: We built three models using three different machine learning algorithms: Logistic Regression, Na\~{A}undefinedve Bayes, and Bayesian Network model. To build the models, we consider different factors involved in review process in terms of Product, Process and People (3P).Results: Our empirical results show that, Bayesian Networks is able to better predict the defectiveness of the changed code with 76% accuracy.Conclusions: Predicting defectiveness of change code is beneficial in making patch release decisions. The Bayesian Network model outperforms the others since it capturs the relationship among the factors in the review process.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {22},
numpages = {10},
keywords = {Software Patch Defectiveness, Defect Prediction, Code review, Code Review Quality},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@inproceedings{10.1007/978-3-030-82153-1_23,
author = {Tang, Gaigai and Zhang, Long and Yang, Feng and Meng, Lianxiao and Cao, Weipeng and Qiu, Meikang and Ren, Shuangyin and Yang, Lin and Wang, Huiqiang},
title = {Interpretation of Learning-Based Automatic Source Code Vulnerability Detection Model Using LIME},
year = {2021},
isbn = {978-3-030-82152-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-82153-1_23},
doi = {10.1007/978-3-030-82153-1_23},
abstract = {The existing advanced automatic vulnerability detection methods based on source code are mainly learning-based, such as machine learning and deep learning. These models can capture the vulnerability pattern through learning, which is more automatic and intelligent. However, the outputs of many learning-based vulnerability detection models are unexplainable, even though they usually show high accuracy. It’s meaningful to verify the credibility of the models so that we can better understand and use them in practice. To alleviate the above issue, we use an interpretation method called LIME to explain the learning-based automatic vulnerability detection model. For one thing, the preprocessing methods are all interpretable, including symbolization and vector representation, where the Bag of words model is chosen for source code vector representation. For another, the vulnerability detection models we select are based on Logistic Regression and Bi-LSTM. The former is interpretable, which is used to verify the effectiveness of LIME in the field of source code vulnerability detection. The latter is unexplained that is interpreted by LIME to its credibility on source code vulnerability detection. The experimental results show that LIME can effectively explain the learning-based automatic vulnerability detection model. Moreover, we find that under the condition of local interpretation, the predictions of the model based on Bi-LSTM are credible.},
booktitle = {Knowledge Science, Engineering and Management: 14th International Conference, KSEM 2021, Tokyo, Japan, August 14–16, 2021, Proceedings, Part III},
pages = {275–286},
numpages = {12},
keywords = {Model interpretation, LIME, Bi-LSTM, Logistic regression, Machine learning, Vulnerability detection},
location = {Tokyo, Japan}
}

@inproceedings{10.5555/978-3-030-62463-7_fm,
title = {Front Matter},
year = {2020},
isbn = {978-3-030-62462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part III},
pages = {i–xv},
location = {Guangzhou, China}
}

@article{10.1016/j.eswa.2021.115428,
author = {Briones-Segovia, V\'{\i}ctor A. and Jim\'{e}nez-Villar, V\'{\i}ctor and Carrasco-Ochoa, Jes\'{u}s Ariel and Mart\'{\i}nez-Trinidad, Jos\'{e} Fco.},
title = {A new oversampling method in the string space},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {183},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115428},
doi = {10.1016/j.eswa.2021.115428},
journal = {Expert Syst. Appl.},
month = nov,
numpages = {7},
keywords = {SMOTE, Edit distance, String space, Oversampling}
}

@inproceedings{10.1007/978-3-030-58604-1_24,
author = {Sun, Youcheng and Chockler, Hana and Huang, Xiaowei and Kroening, Daniel},
title = {Explaining Image Classifiers Using Statistical Fault Localization},
year = {2020},
isbn = {978-3-030-58603-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58604-1_24},
doi = {10.1007/978-3-030-58604-1_24},
abstract = {The black-box nature of deep neural networks (DNNs) makes it impossible to understand why a particular output is produced, creating demand for “Explainable AI”. In&nbsp;this paper, we show that statistical fault localization (SFL) techniques from software engineering deliver high quality explanations of the outputs of DNNs, where we define an explanation as a minimal subset of features sufficient for making the same decision as for the original input. We present an algorithm and a tool called DeepCover, which synthesizes a ranking of the features of the inputs using SFL and constructs explanations for the decisions of the DNN based on this ranking. We compare explanations produced by DeepCover with those of the state-of-the-art tools gradcam, lime, shap, rise and extremal and show that explanations generated by DeepCover are consistently better across a broad set of experiments. On a benchmark set with known ground truth, DeepCover achieves  accuracy, which is  better than the second best extremal.},
booktitle = {Computer Vision – ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXVIII},
pages = {391–406},
numpages = {16},
keywords = {Software testing, Statistical fault localization, Explainability, Deep learning},
location = {Glasgow, United Kingdom}
}

@article{10.1016/j.jss.2009.06.036,
author = {Binkley, David and Feild, Henry and Lawrie, Dawn and Pighin, Maurizio},
title = {Increasing diversity: Natural language measures for software fault prediction},
year = {2009},
issue_date = {November, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {82},
number = {11},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.06.036},
doi = {10.1016/j.jss.2009.06.036},
abstract = {While challenging, the ability to predict faulty modules of a program is valuable to a software project because it can reduce the cost of software development, as well as software maintenance and evolution. Three language-processing based measures are introduced and applied to the problem of fault prediction. The first measure is based on the usage of natural language in a program's identifiers. The second measure concerns the conciseness and consistency of identifiers. The third measure, referred to as the QALP score, makes use of techniques from information retrieval to judge software quality. The QALP score has been shown to correlate with human judgments of software quality. Two case studies consider the language processing measures applicability to fault prediction using two programs (one open source, one proprietary). Linear mixed-effects regression models are used to identify relationships between defects and the measures. Results, while complex, show that language processing measures improve fault prediction, especially when used in combination. Overall, the models explain one-third and two-thirds of the faults in the two case studies. Consistent with other uses of language processing, the value of the three measures increases with the size of the program module considered.},
journal = {J. Syst. Softw.},
month = nov,
pages = {1793–1803},
numpages = {11},
keywords = {Linear regression models, Information retrieval, Fault prediction, Empirical software engineering, Code comprehension}
}

@article{10.1109/TCBB.2020.2980831,
author = {Singh, Rishav and Ahmed, Tanveer and Kumar, Abhinav and Singh, Amit Kumar and Pandey, Anil Kumar and Singh, Sanjay Kumar},
title = {Imbalanced Breast Cancer Classification Using Transfer Learning},
year = {2021},
issue_date = {Jan.-Feb. 2021},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {18},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2020.2980831},
doi = {10.1109/TCBB.2020.2980831},
abstract = {Accurate breast cancer detection using automated algorithms remains a problem within the literature. Although a plethora of work has tried to address this issue, an exact solution is yet to be found. This problem is further exacerbated by the fact that most of the existing datasets are imbalanced, i.e., the number of instances of a particular class far exceeds that of the others. In this paper, we propose a framework based on the notion of transfer learning to address this issue and focus our efforts on histopathological and imbalanced image classification. We use the popular VGG-19 as the base model and complement it with several state-of-the-art techniques to improve the overall performance of the system. With the ImageNet dataset taken as the source domain, we apply the learned knowledge in the target domain consisting of histopathological images. With experimentation performed on a large-scale dataset consisting of 277,524 images, we show that the framework proposed in this paper gives superior performance than those available in the existing literature. Through numerical simulations conducted on a supercomputer, we also present guidelines for work in transfer learning and imbalanced image classification.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = feb,
pages = {83–93},
numpages = {11}
}

@phdthesis{10.5555/AAI28826565,
author = {Chandrasekaran, Jaganmohan},
advisor = {Jeff, Lei,},
title = {Testing Artificial Intelligence-Based Software Systems},
year = {2021},
isbn = {9798544286103},
publisher = {The University of Texas at Arlington},
abstract = {Artificial Intelligence (AI)-based software systems are increasingly used in high-stake andsafety-critical domains, including recidivism prediction, medical diagnosis, and autonomous driving. There is an urgent need to ensure the reliability and correctness of AI-based systems. At the core of AI-based software systems is a machine learning (ML) model that is used to perform tasks such as classification and prediction.Unlike software programs, where a developer explicitly writes the decision logic, ML models learn the decision logic from a large training dataset. Furthermore, many ML models encode the decision logic in the form of mathematic functions that can be quite abstract and complex. Thus, existing software testing techniques cannot be directly applied to test AI-based applications.The goal of this dissertation is to develop methodologies for testing AI-based software systems. This dissertation makes contributions in the following areas: Test input generation: 1) A combinatorial approach for generating test configurations to test five classical machine learning algorithms. 2) A combinatorial approach for generating test data (synthetic images) to test Deep Neural Network (DNN) models used in autonomous driving cars. Test Cost Reduction: 3) An empirical study that analyzes the effect of using sampled datasets to test supervised learning algorithms. Explainable AI (XAI): 4) A software fault localization-based explainable AI (XAI) approach that produces counterfactual explanations for decisions made by image classifier models (DNN models).This dissertation is presented in an article-based format and includes five research papers. The first paper reports our work on applying combinatorial testing to test five classical machine learning algorithms. The second paper reports an extensive empirical evaluation of testing ML algorithms with sampled datasets. The third paper introduces a combinatorial testing-based approach to generating test images to test pre-trained DNN models used in autonomous driving cars. The fourth paper is an extension of the third paper. This paper presents an initial study that evaluates the performance of combinatorial testing in testing DNNs used in autonomous driving cars. The fifth paper presents an explainable AI (XAI) approach that adopts BEN, an existing software fault localization technique, and produces explanations for decisions made by ML models. All five papers have been accepted at peer-reviewed venues. Paper 1, Paper 2, Paper 3, and Paper 5 have been published, while Paper 4 is currently in press.},
note = {AAI28826565}
}

@article{10.1016/j.eswa.2019.113122,
author = {Tubishat, Mohammad and Idris, Norisma and Shuib, Liyana and Abushariah, Mohammad A.M. and Mirjalili, Seyedali},
title = {Improved Salp Swarm Algorithm based on opposition based learning and novel local search algorithm for feature selection},
year = {2020},
issue_date = {May 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {145},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113122},
doi = {10.1016/j.eswa.2019.113122},
journal = {Expert Syst. Appl.},
month = may,
numpages = {10},
keywords = {Opposition Based Learning, Algorithm, Machine Learning, Optimization, Feature selection, Classification, Salp Swarm Algorithm}
}

@inproceedings{10.5555/3504035.3504589,
author = {Zhao, Xibin and Wang, Nan and Shi, Heyuan and Wan, Hai and Huang, Jin and Gao, Yue},
title = {Hypergraph learning with cost interval optimization},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {In many classification tasks, the misclassification costs of different categories usually vary significantly. Under such circumstances, it is essential to identify the importance of different categories and thus assign different misclassifica-tion losses in many applications, such as medical diagnosis, saliency detection and software defect prediction. However, we note that it is infeasible to determine the accurate cost value without great domain knowledge. In most common cases, we may just have the information that which category is more important than the other categories, i.e., the identification of defect-prone softwares is more important than that of defect-free. To tackle these issues, in this paper, we propose a hypergraph learning method with cost interval optimization, which is able to handle cost interval when data is formulated using the high-order relationships. In this way, data correlations are modeled by a hypergraph structure, which has the merit to exploit the underlying relationships behind the data. With a cost-sensitive hypergraph structure, in order to improve the performance of the classifier without precise cost value, we further introduce cost interval optimization to hypergraph learning. In this process, the optimization on cost interval achieves better performance instead of choosing uncertain fixed cost in the learning process. To evaluate the effectiveness of the proposed method, we have conducted experiments on two groups of dataset, i.e., the NASA Metrics Data Program (NASA) dataset and UCI Machine Learning Repository (UCI) dataset. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {554},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00056,
author = {Aleithan, Reem},
title = {Explainable just-in-time bug prediction: are we there yet?},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00056},
doi = {10.1109/ICSE-Companion52605.2021.00056},
abstract = {Explaining the prediction results of software bug prediction models is a challenging task, which can provide useful information for developers to understand and fix the predicted bugs. Recently, Jirayus et al. [4] proposed to use two model-agnostic techniques (i.e., LIME and iBreakDown) to explain the prediction results of bug prediction models. Although their experiments on file-level bug prediction show promising results, the performance of these techniques on explaining the results of just-in-time (i.e., change-level) bug prediction is unknown. This paper conducts the first empirical study to explore the explainability of these model-agnostic techniques on just-in-time bug prediction models. Specifically, this study takes a three-step approach, 1) replicating previously widely used just-in-time bug prediction models, 2) applying Local Interpretability Model-agnostic Explanation Technique (LIME) and iBreakDown on the prediction results, and 3) manually evaluating the explanations for buggy instances (i.e. positive predictions) against the root cause of the bugs. The results of our experiment show that LIME and iBreakDown fail to explain defect prediction explanations for just-in-time bug prediction models, unlike file-level [4]. This paper urges for new approaches for explaining the results of just-in-time bug prediction models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {129–131},
numpages = {3},
keywords = {prediction explanation, bug prediction},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@article{10.1016/j.knosys.2021.107306,
author = {Zhou, Hao and Dong, Xianyong and Xia, Shuyin and Wang, Guoyin},
title = {Weighted oversampling algorithms for imbalanced problems and application in prediction of streamflow▪},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {229},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107306},
doi = {10.1016/j.knosys.2021.107306},
journal = {Know.-Based Syst.},
month = oct,
numpages = {13},
keywords = {Label noise, W-SMOTEs, Weight, Interpolation location, Oversampling}
}

@article{10.1155/2018/6791683,
author = {Ji, Haijin and Huang, Song and Gutierrez, Pedro Antonio},
title = {Kernel Entropy Component Analysis with Nongreedy L1-Norm Maximization},
year = {2018},
issue_date = {2018},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2018},
issn = {1687-5265},
url = {https://doi.org/10.1155/2018/6791683},
doi = {10.1155/2018/6791683},
abstract = {Kernel entropy component analysis (KECA) is a newly proposed dimensionality reduction (DR) method, which has showed superiority in many pattern analysis issues previously solved by principal component analysis (PCA). The optimized KECA (OKECA) is a state-of-the-art variant of KECA and can return projections retaining more expressive power than KECA. However, OKECA is sensitive to outliers and accused of its high computational complexities due to its inherent properties of L2-norm. To handle these two problems, we develop a new extension to KECA, namely, KECA-L1, for DR or feature extraction. KECA-L1 aims to find a more robust kernel decomposition matrix such that the extracted features retain information potential as much as possible, which is measured by L1-norm. Accordingly, we design a nongreedy iterative algorithm which has much faster convergence than OKECA’s. Moreover, a general semisupervised classifier is developed for KECA-based methods and employed into the data classification. Extensive experiments on data classification and software defect prediction demonstrate that our new method is superior to most existing KECA- and PCA-based approaches. Code has been also made publicly available.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {9}
}

@inproceedings{10.1109/ITSC48978.2021.9564771,
author = {Bernhard, Johannes and Schutera, Mark and Sax, Eric},
title = {Optimizing test-set diversity: Trajectory clustering for scenario-based testing of automated driving systems},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC48978.2021.9564771},
doi = {10.1109/ITSC48978.2021.9564771},
abstract = {The developments in automated driving have raised questions concerning the safety of automated vehicles. The reliable behavior of automated driving functions has to be proven by a testing process. While real-world testing is the evident method for verification, there are significant concerns regarding test scalability. Simulative methods are economical and safe alternatives to assess driving functions' quality. A catalog with scenarios recorded in real-world traffic for resimulation must be assembled, defining a set of requirements the driving function must pass before release. Therefore, to ensure safe behavior, the test catalog must include many diverse scenarios while reducing repetitive scenarios, as they do not pose additional challenges to the virtual vehicle and would unbalance the performance metrics. This work introduces a method to cluster and characterize vehicle behaviors based on trajectory data. The first step of the two-step bottom-up approach assigns individual coordinates of trajectories to clusters. Then, trajectory analysis is applied to histograms representing the distribution of retrieved cluster-IDs. Furthermore, we performed experiments, demonstrating the performance of our algorithm on various real-world data-sets. Using 1608 traffic scenarios, the method reduced the data-set by 61.0 %, eliminating redundant scenarios while upholding scenario space coverage. This algorithm serves as a basis for traffic scenario understanding to optimize test-set diversity.},
booktitle = {2021 IEEE International Intelligent Transportation Systems Conference (ITSC)},
pages = {1371–1378},
numpages = {8},
location = {Indianapolis, IN, USA}
}

@inproceedings{10.1007/978-3-030-27455-9_3,
author = {Joffe, Leonid and Clark, David},
title = {Constructing Search Spaces for Search-Based Software Testing Using Neural Networks},
year = {2019},
isbn = {978-3-030-27454-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27455-9_3},
doi = {10.1007/978-3-030-27455-9_3},
abstract = {A central requirement for any Search-Based Software Testing (SBST) technique is a convenient and meaningful fitness landscape. Whether one follows a targeted or a diversification driven strategy, a search landscape needs to be large, continuous, easy to construct and representative of the underlying property of interest. Constructing such a landscape is not a trivial task often requiring a significant manual effort by an expert.We present an approach for constructing meaningful and convenient fitness landscapes using neural networks (NN) – for targeted and diversification strategies alike. We suggest that output of an NN predictor can be interpreted as a fitness for a targeted strategy. The NN is trained on a corpus of execution traces and various properties of interest, prior to searching. During search, the trained NN is queried to predict an estimate of a property given an execution trace. The outputs of the NN form a convenient search space which is strongly representative of a number of properties. We believe that such a search space can be readily used for driving a search towards specific properties of interest.For a diversification strategy, we propose the use of an autoencoder; a mechanism for compacting data into an n-dimensional “latent” space. In it, datapoints are arranged according to the similarity of their salient features. We show that a latent space of execution traces possesses characteristics of a convenient search landscape: it is continuous, large and crucially, it defines a notion of similarity to arbitrary observations.},
booktitle = {Search-Based Software Engineering: 11th International Symposium, SSBSE 2019, Tallinn, Estonia, August 31 – September 1, 2019, Proceedings},
pages = {27–41},
numpages = {15},
keywords = {Neural networks, Machine learning, Fitness function, Software engineering, Search-Based Software Testing},
location = {Tallinn, Estonia}
}

@article{10.1016/j.jpdc.2017.06.022,
author = {Hussain, Shahid and Keung, Jacky and Khan, Arif Ali and Ahmad, Awais and Cuomo, Salvatore and Piccialli, Francesco and Jeon, Gwanggil and Akhunzada, Adnan},
title = {Implications of deep learning for the automation of design patterns organization},
year = {2018},
issue_date = {Jul 2018},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {117},
number = {C},
issn = {0743-7315},
url = {https://doi.org/10.1016/j.jpdc.2017.06.022},
doi = {10.1016/j.jpdc.2017.06.022},
journal = {J. Parallel Distrib. Comput.},
month = jul,
pages = {256–266},
numpages = {11},
keywords = {Classifiers, Performance, Feature set, Deep learning, Design patterns}
}

@inproceedings{10.1145/1774088.1774612,
author = {Sami, Ashkan and Fakhrahmad, Seyed Mostafa},
title = {Design-level metrics estimation based on code metrics},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774612},
doi = {10.1145/1774088.1774612},
abstract = {Fault detection based on mining code and design metrics has been an active research area for many years. Basically "module"-based metrics for source code and design level are calculated or obtained and data mining is used to build predictor models. However, in many projects due to organizational or software process models, design level metrics are not available and/or accurate. It has been shown that performance of these classifiers or predictors decline if only source code features are used for training them. Based on best of our know knowledge no set of rule to estimate design level metrics based on code level metrics has been presented since it is believed that design level metrics have additional information and cannot be estimated without access to design artifacts. In this study we present a fuzzy modeling system to find and present these relationships for projects presented in NASA Metrics Data Repository (MDP) datasets. Interestingly, we could find a set of empirical rules that govern all the projects regardless of size, programming language and software development methodology. Comparison of fault detectors built based on estimated design metrics with actual design metrics on various projects showed a very small difference in accuracy of classifiers and validated our hypothesis that estimation of design metrics based on source code attributes can become a practical exercise.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {2531–2535},
numpages = {5},
keywords = {software metrics, software defect prediction, parameter estimation, fuzzy classification, approximate dependencies},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@article{10.1007/s00354-020-00119-7,
author = {Sharma, Nonita and Dev, Jaiditya and Mangla, Monika and Wadhwa, Vaishali Mehta and Mohanty, Sachi Nandan and Kakkar, Deepti},
title = {A Heterogeneous Ensemble Forecasting Model for Disease Prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Ohmsha},
address = {JPN},
volume = {39},
number = {3},
issn = {0288-3635},
url = {https://doi.org/10.1007/s00354-020-00119-7},
doi = {10.1007/s00354-020-00119-7},
abstract = {The manuscript presents a bragging-based ensemble forecasting model for predicting the number of incidences of a disease based on past occurrences. The objectives of this research work are to enhance accuracy, reduce overfitting, and handle overdrift; the proposed model has shown promising results in terms of error metrics. The collated dataset of the diseases is collected from the official government site of Hong Kong from the year 2010 to 2019. The preprocessing is done using log transformation and z score transformation. The proposed ensemble model is applied, and its applicability to a specific disease dataset is presented. The proposed ensemble model is compared against the ensemble models, namely dynamic ensemble for time series, arbitrated dynamic ensemble, and random forest using different error metrics. The proposed model shows the reduced value of MAE (mean average error) by 27.18%, 3.07%, 11.58%, 13.46% for tuberculosis, dengue, food poisoning, and chickenpox, respectively. The comparison drawn between the proposed model and the existing models shows that the proposed ensemble model gives better accuracy in the case of all the four-disease datasets.},
journal = {New Gen. Comput.},
month = nov,
pages = {701–715},
numpages = {15},
keywords = {Bootstrapping, Bragging, Disease forecasting, Ensemble, Time series forecasting}
}

@inproceedings{10.1145/3293882.3338985,
author = {Kudjo, Patrick Kwaku and Chen, Jinfu},
title = {A cost-effective strategy for software vulnerability prediction based on bellwether analysis},
year = {2019},
isbn = {9781450362245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293882.3338985},
doi = {10.1145/3293882.3338985},
abstract = {Vulnerability Prediction Models (VPMs) aims to identify vulnerable and non-vulnerable components in large software systems. Consequently, VPMs presents three major drawbacks (i) finding an effective method to identify a representative set of features from which to construct an effective model. (ii) the way the features are utilized in the machine learning setup (iii) making an implicit assumption that parameter optimization would not change the outcome of VPMs. To address these limitations, we investigate the significant effect of the Bellwether analysis on VPMs. Specifically, we first develop a Bellwether algorithm to identify and select an exemplary subset of data to be considered as the Bellwether to yield improved prediction accuracy against the growing portfolio benchmark. Next, we build a machine learning approach with different parameter settings to show the improvement of performance of VPMs. The prediction results of the suggested models were assessed in terms of precision, recall, F-measure, and other statistical measures. The preliminary result shows the Bellwether approach outperforms the benchmark technique across the applications studied with F-measure values ranging from 51.1%-98.5%.},
booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {424–427},
numpages = {4},
keywords = {Tuning, Software vulnerability, Machine learning, Bellwether},
location = {Beijing, China},
series = {ISSTA 2019}
}

@article{10.1016/j.procs.2018.07.216,
author = {Miholca, Diana-Lucia and Czibula, Gabriela and Crivei, Liana Maria},
title = {A new incremental relational association rules mining approach},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {126},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.07.216},
doi = {10.1016/j.procs.2018.07.216},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {126–135},
numpages = {10},
keywords = {68P15, 68T05, Relational association rules 2000 MSC: 6207, Unsupervised learning, Data mining}
}

@inproceedings{10.1145/3402842.3407158,
author = {Sun, Jun and Yang, Zijiang},
title = {ObjSim: efficient testing of cyber-physical systems},
year = {2020},
isbn = {9781450380324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3402842.3407158},
doi = {10.1145/3402842.3407158},
abstract = {Cyber-physical systems (CPSs) play a critical role in automating public infrastructure and thus attract wide range of attacks. Assessing the effectiveness of defense mechanisms is challenging as realistic sets of attacks to test them against are not always available. In this short paper, we briefly describe smart fuzzing, an automated, machine learning guided technique for systematically producing test suites of CPS network attacks. Our approach uses predictive ma- chine learning models and meta-heuristic search algorithms to guide the fuzzing of actuators so as to drive the CPS into different unsafe physical states. The approach has been proven effective on two real-world CPS testbeds.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Testing, Analysis, and Verification of Cyber-Physical Systems and Internet of Things},
pages = {1–2},
numpages = {2},
keywords = {testing, network, machine learning, fuzzing, cyber-physical system},
location = {Virtual Event, USA},
series = {TAV-CPS/IoT 2020}
}

@inproceedings{10.1145/3382494.3410694,
author = {Huang, Yuekai and Wang, Junjie and Wang, Song and Liu, Zhe and Hu, Yuanzhe and Wang, Qing},
title = {Quest for the Golden Approach: An Experimental Evaluation of Duplicate Crowdtesting Reports Detection},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410694},
doi = {10.1145/3382494.3410694},
abstract = {Background: Given the invisibility and unpredictability of distributed crowdtesting processes, there is a large number of duplicate reports, and detecting these duplicate reports is an important task to help save testing effort. Although, many approaches have been proposed to automatically detect the duplicates, the comparison among them and the practical guidelines to adopt these approaches in crowdtesting remain vague.Aims: We aim at conducting the first experimental evaluation of the commonly-used and state-of-the-art approaches for duplicate detection in crowdtesting reports, and exploring which is the golden approach.Method: We begin with a systematic review of approaches for duplicate detection, and select ten state-of-the-art approaches for our experimental evaluation. We conduct duplicate detection with each approach on 414 crowdtesting projects with 59,289 reports collected from one of the largest crowdtesting platforms.Results: Machine learning based approach, i.e., ML-REP, and deep learning based approach, i.e., DL-BiMPM, are the best two approaches for duplicate reports detection in crowdtesting, while the later one is more sensitive to the size of training data and more time-consuming for model training and prediction.Conclusions: This paper provides new insights and guidelines to select appropriate duplicate detection techniques for duplicate crowdtesting reports detection.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {17},
numpages = {12},
keywords = {machine learning, information retrieval, duplicate detection, deep learning, Crowdtesting},
location = {Bari, Italy},
series = {ESEM '20}
}

@article{10.1016/j.procs.2018.05.071,
author = {Pandey, Sushant Kumar and Mishra, Ravi Bhushan and Triphathi, Anil Kumar},
title = {Software Bug Prediction Prototype Using Bayesian Network Classifier: A Comprehensive Model},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.071},
doi = {10.1016/j.procs.2018.05.071},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {1412–1421},
numpages = {10},
keywords = {Bayesian network, bug prediction, classification techniques}
}

@article{10.1007/s10489-020-01852-8,
author = {Guan, Hongjiao and Zhang, Yingtao and Xian, Min and Cheng, H. D. and Tang, Xianglong},
title = {SMOTE-WENN: Solving class imbalance and small sample problems by oversampling and distance scaling},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {3},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-01852-8},
doi = {10.1007/s10489-020-01852-8},
abstract = {Many practical applications suffer from imbalanced data classification, in which case the minority class has degraded recognition rate. The primary causes are the sample scarcity of the minority class and the intrinsic complex distribution characteristics of imbalanced datasets. The imbalanced classification problem is more serious on small sample datasets. To solve the problems of small sample and class imbalance, a hybrid resampling method is proposed. The proposed method combines an oversampling approach (synthetic minority oversampling technique, SMOTE) and a novel data cleaning approach (weighted edited nearest neighbor rule, WENN). First, SMOTE generates synthetic minority class examples using linear interpolation. Then, WENN detects and deletes unsafe majority and minority class examples using weighted distance function and k-nearest neighbor (kNN) rule. The weighted distance function scales up a commonly used distance by considering local imbalance and spacial sparsity. Extensive experiments over synthetic and real datasets validate the superiority of the proposed SMOTE-WENN compared with three state-of-the-art resampling methods.},
journal = {Applied Intelligence},
month = mar,
pages = {1394–1409},
numpages = {16},
keywords = {Data cleaning, Oversampling, Small sample datasets, Imbalanced data classification}
}

@article{10.1504/IJBRA.2017.082055,
title = {An empirical study of self-training and data balancing techniques for splice site prediction},
year = {2017},
issue_date = {January 2017},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {1},
issn = {1744-5485},
url = {https://doi.org/10.1504/IJBRA.2017.082055},
doi = {10.1504/IJBRA.2017.082055},
abstract = {Thanks to Next Generation Sequencing technologies, unlabelled data is now generated easily, while the annotation process remains expensive. Semi-supervised learning represents a cost-effective alternative to supervised learning, as it can improve supervised classifiers by making use of unlabelled data. However, semi-supervised learning has not been studied much for problems with highly skewed class distributions, which are prevalent in bioinformatics. To address this limitation, we carry out a study of a semi-supervised learning algorithm, specifically self-training based on Na\"{\i}ve Bayes, with focus on data-level approaches for handling imbalanced class distributions. Our study is conducted on the problem of predicting splice sites and it is based on datasets for which the ratio of positive to negative examples is 1-to-99. Our results show that under certain conditions semi-supervised learning algorithms are a better choice than purely supervised classification algorithms.},
journal = {Int. J. Bioinformatics Res. Appl.},
month = jan,
pages = {40–61},
numpages = {22}
}

@inproceedings{10.1145/3340531.3412157,
author = {Baril, Xavier and Cousti\'{e}, Oihana and Mothe, Josiane and Teste, Olivier},
title = {Application Performance Anomaly Detection with LSTM on Temporal Irregularities in Logs},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3412157},
doi = {10.1145/3340531.3412157},
abstract = {Performance anomalies are a core problem in modern information systems, that affects the execution of the hosted applications. The detection of these anomalies often relies on the analysis of the application execution logs. The current most effective approach is to detect samples that differ from a learnt nominal model. However, current methods often focus on detecting sequential anomalies in logs, neglecting the time elapsed between logs, which is a core component of the performance anomaly detection. In this paper, we develop a new model for performance anomaly detection that captures temporal deviations from the nominal model, by means of a sliding window data representation. This nominal model is trained by a Long Short-Term Memory neural network, which is appropriate to represent complex sequential dependencies. We assess the effectiveness of our model on both simulated and real datasets. We show that it is more robust to temporal variations than current state-of-the-art approaches, while remaining as effective.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {1961–1964},
numpages = {4},
keywords = {information system, event logs, anomaly detection},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}

@article{10.1145/2557833.2560586,
author = {Peiris, Manjula and Hill, James H.},
title = {Towards detecting software performance anti-patterns using classification techniques},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2557833.2560586},
doi = {10.1145/2557833.2560586},
abstract = {This paper presents a non-intrusive machine learning approach called Non-intrusive Performance Anti-pattern Detecter (NiPAD) for identifying and classifying software performance anti-patterns. NiPAD uses only system performance metrics-as opposed to analyzing application level performance metrics or source code and the design of a software application to identify and classify software performance anti-patterns within an application. The results of applying NiPAD to an example application show that NiPAD is able to predict the One Lane Bridge software performance anti-pattern within a software application with 0.94 accuracy.},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {1–4},
numpages = {4},
keywords = {software performance anti-patterns, machine learning, dynamic software analysis, classification}
}

@inproceedings{10.1145/1985374.1985386,
author = {M\i{}s\i{}rl\i{}, Ayse Tosun and \c{C}a\u{g}layan, Bora and Miranskyy, Andriy V. and Bener, Ay\c{s}e and Ruffolo, Nuzio},
title = {Different strokes for different folks: a case study on software metrics for different defect categories},
year = {2011},
isbn = {9781450305938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985374.1985386},
doi = {10.1145/1985374.1985386},
abstract = {Defect prediction has been evolved with variety of metric sets, and defect types. Researchers found code, churn, and network metrics as significant indicators of defects. However, all metric sets may not be informative for all defect categories such that only one metric type may represent majority of a defect category. Our previous study showed that defect category sensitive prediction models are more successful than general models, since each category has different characteristics in terms of metrics. We extend our previous work, and propose specialized prediction models using churn, code, and network metrics with respect to three defect categories. Results show that churn metrics are the best for predicting all defects. The strength of correlation for code and network metrics varies with defect category: Network metrics have higher correlations than code metrics for defects reported during functional testing and in the field, and vice versa for defects reported during system testing.},
booktitle = {Proceedings of the 2nd International Workshop on Emerging Trends in Software Metrics},
pages = {45–51},
numpages = {7},
keywords = {static code metrics, software defect prediction, network metrics, churn metrics},
location = {Waikiki, Honolulu, HI, USA},
series = {WETSoM '11}
}

@inproceedings{10.1145/3457388.3460425,
author = {Delimitrou, Christina},
title = {Leveraging ML to handle the increasing complexity of the cloud},
year = {2021},
isbn = {9781450384049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457388.3460425},
doi = {10.1145/3457388.3460425},
abstract = {Cloud services are increasingly adopting new programming models, such as microservices and serverless compute. While these frameworks offer several advantages, such as better modularity, ease of maintenance and deployment, they also introduce new hardware and software challenges.In this talk, I will briefly discuss the challenges that these new cloud models introduce in hardware and software, and present some of of our work on employing ML to improve the cloud's performance predictability and resource efficiency. I will first discuss Seer, a performance debugging system that identifies root causes of unpredictable performance in multi-tier interactive microservices, and Sage, which improves on Seer by taking a completely unsupervised learning approach to data-driven performance debugging, making it both practical and scalable.},
booktitle = {Proceedings of the 18th ACM International Conference on Computing Frontiers},
pages = {2},
numpages = {1},
location = {Virtual Event, Italy},
series = {CF '21}
}

@inproceedings{10.5555/978-3-030-62223-7_fm,
title = {Front Matter},
year = {2020},
isbn = {978-3-030-62222-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part I},
pages = {i–xxvii},
location = {Guangzhou, China}
}

@inproceedings{10.1145/2070821.2070829,
author = {Zhang, Dongmei and Dang, Yingnong and Lou, Jian-Guang and Han, Shi and Zhang, Haidong and Xie, Tao},
title = {Software analytics as a learning case in practice: approaches and experiences},
year = {2011},
isbn = {9781450310222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2070821.2070829},
doi = {10.1145/2070821.2070829},
abstract = {Software analytics is to enable software practitioners to perform data exploration and analysis in order to obtain insightful and actionable information for data-driven tasks around software and services. In this position paper, we advocate that when applying analytic technologies in practice of software analytics, one should (1) incorporate a broad spectrum of domain knowledge and expertise, e.g., management, machine learning, large-scale data processing and computing, and information visualization; and (2) investigate how practitioners take actions on the produced information, and provide effective support for such information-based action taking. Our position is based on our experiences of successful technology transfer on software analytics at Microsoft Research Asia.},
booktitle = {Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering},
pages = {55–58},
numpages = {4},
keywords = {technology transfer, software analytics, machine learning},
location = {Lawrence, Kansas, USA},
series = {MALETS '11}
}

@inproceedings{10.5555/3540261.3542395,
author = {Allamanis, Miltiadis and Jackson-Flux, Henry and Brockschmidt, Marc},
title = {Self-supervised bug detection and repair},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Machine learning-based program analyses have recently shown the promise of integrating formal and probabilistic reasoning towards aiding software development. However, in the absence of large annotated corpora, training these analyses is challenging. Towards addressing this, we present BUGLAB, an approach for self-supervised learning of bug detection and repair. BUGLAB co-trains two models: (1) a detector model that learns to detect and repair bugs in code, (2) a selector model that learns to create buggy code for the detector to use as training data. A Python implementation of BUGLAB improves by up to 30% upon baseline methods on a test dataset of 2374 real-life bugs and finds 19 previously unknown bugs in open-source software.},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {2134},
numpages = {12},
series = {NIPS '21}
}

@article{10.1016/j.infsof.2021.106652,
author = {Zhao, Kunsong and Xu, Zhou and Yan, Meng and Zhang, Tao and Yang, Dan and Li, Wei},
title = {A comprehensive investigation of the impact of feature selection techniques on crashing fault residence prediction models},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106652},
doi = {10.1016/j.infsof.2021.106652},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {16},
keywords = {Empirical study, Feature selection, Stack trace, Crash localization}
}

@article{10.1016/j.eswa.2019.113005,
author = {Ghaderi Zefrehi, Hossein and Alt\i{}n\c{c}ay, Hakan},
title = {Imbalance learning using heterogeneous ensembles},
year = {2020},
issue_date = {Mar 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {142},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113005},
doi = {10.1016/j.eswa.2019.113005},
journal = {Expert Syst. Appl.},
month = mar,
numpages = {15},
keywords = {Multiple balancing methods, Heterogeneous ensembles, Boosting, Bagging, Classifier ensembles, Imbalance learning}
}

@article{10.1007/s11219-012-9180-0,
author = {\c{C}al\i{}kl\i{}, G\"{u}l and Bener, Ay\c{s}e Ba\c{s}ar},
title = {Influence of confirmation biases of developers on software quality: an empirical study},
year = {2013},
issue_date = {June      2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-012-9180-0},
doi = {10.1007/s11219-012-9180-0},
abstract = {The thought processes of people have a significant impact on software quality, as software is designed, developed and tested by people. Cognitive biases, which are defined as patterned deviations of human thought from the laws of logic and mathematics, are a likely cause of software defects. However, there is little empirical evidence to date to substantiate this assertion. In this research, we focus on a specific cognitive bias, confirmation bias, which is defined as the tendency of people to seek evidence that verifies a hypothesis rather than seeking evidence to falsify a hypothesis. Due to this confirmation bias, developers tend to perform unit tests to make their program work rather than to break their code. Therefore, confirmation bias is believed to be one of the factors that lead to an increased software defect density. In this research, we present a metric scheme that explores the impact of developers' confirmation bias on software defect density. In order to estimate the effectiveness of our metric scheme in the quantification of confirmation bias within the context of software development, we performed an empirical study that addressed the prediction of the defective parts of software. In our empirical study, we used confirmation bias metrics on five datasets obtained from two companies. Our results provide empirical evidence that human thought processes and cognitive aspects deserve further investigation to improve decision making in software development for effective process management and resource allocation.},
journal = {Software Quality Journal},
month = jun,
pages = {377–416},
numpages = {40},
keywords = {Software psychology, Human factors, Defect prediction, Confirmation bias}
}

@inproceedings{10.1145/3416508.3417121,
author = {Villalobos-Arias, Leonardo and Quesada-L\'{o}pez, Christian and Guevara-Coto, Jose and Mart\'{\i}nez, Alexandra and Jenkins, Marcelo},
title = {Evaluating hyper-parameter tuning using random search in support vector machines for software effort estimation},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417121},
doi = {10.1145/3416508.3417121},
abstract = {Studies in software effort estimation&nbsp;(SEE) have explored the use of hyper-parameter tuning for machine learning algorithms&nbsp;(MLA) to improve the accuracy of effort estimates. In other contexts random search&nbsp;(RS) has shown similar results to grid search, while being less computationally-expensive. In this paper, we investigate to what extent the random search hyper-parameter tuning approach affects the accuracy and stability of support vector regression&nbsp;(SVR) in SEE. Results were compared to those obtained from ridge regression models and grid search-tuned models. A case study with four data sets extracted from the ISBSG 2018 repository shows that random search exhibits similar performance to grid search, rendering it an attractive alternative technique for hyper-parameter tuning. RS-tuned SVR achieved an increase of 0.227 standardized accuracy&nbsp;(SA) with respect to default hyper-parameters. In addition, random search improved prediction stability of SVR models to a minimum ratio of 0.840. The analysis showed that RS-tuned SVR attained performance equivalent to GS-tuned SVR. Future work includes extending this research to cover other hyper-parameter tuning approaches and machine learning algorithms, as well as using additional data sets.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {31–40},
numpages = {10},
keywords = {Software effort estimation, empirical study, grid search, hyper-parameter tuning, random search, support vector machines},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@inproceedings{10.5555/2820282.2820292,
author = {Thung, Ferdian and Le, Xuan-Bach D. and Lo, David},
title = {Active semi-supervised defect categorization},
year = {2015},
publisher = {IEEE Press},
abstract = {Defects are inseparable part of software development and evolution. To better comprehend problems affecting a software system, developers often store historical defects and these defects can be categorized into families. IBM proposes Orthogonal Defect Categorization (ODC) which include various classifications of defects based on a number of orthogonal dimensions (e.g., symptoms and semantics of defects, root causes of defects, etc.). To help developers categorize defects, several approaches that employ machine learning have been proposed in the literature. Unfortunately, these approaches often require developers to manually label a large number of defect examples. In practice, manually labelling a large number of examples is both time-consuming and labor-intensive. Thus, reducing the onerous burden of manual labelling while still being able to achieve good performance is crucial towards the adoption of such approaches. To deal with this challenge, in this work, we propose an active semi-supervised defect prediction approach. It is performed by actively selecting a small subset of diverse and informative defect examples to label (i.e., active learning), and by making use of both labeled and unlabeled defect examples in the prediction model learning process (i.e., semi-supervised learning). Using this principle, our approach is able to learn a good model while minimizing the manual labeling effort.To evaluate the effectiveness of our approach, we make use of a benchmark dataset that contains 500 defects from three software systems that have been manually labelled into several families based on ODC. We investigate our approach's ability in achieving good classification performance, measured in terms of weighted precision, recall, F-measure, and AUC, when only a small number of manually labelled defect examples are available. Our experiment results show that our active semi-supervised defect categorization approach is able to achieve a weighted precision, recall, F-measure, and AUC of 0.651, 0.669, 0.623, and 0.710, respectively, when only 50 defects are manually labelled. Furthermore, it outperforms an existing active multi-class classification algorithm, proposed in the machine learning community, by a substantial margin.},
booktitle = {Proceedings of the 2015 IEEE 23rd International Conference on Program Comprehension},
pages = {60–70},
numpages = {11},
location = {Florence, Italy},
series = {ICPC '15}
}

@inproceedings{10.1007/978-3-642-39742-4_2,
author = {Yao, Xin},
title = {Some Recent Work on Multi-objective Approaches to Search-Based Software Engineering},
year = {2013},
isbn = {9783642397417},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-39742-4_2},
doi = {10.1007/978-3-642-39742-4_2},
abstract = {Multi-objective algorithms have been used to solve difficult software engineering problems for a long time. This article summarises some selected recent work of applying latest meta-heuristic optimisation algorithms and machine learning algorithms to software engineering problems, including software module clustering, testing resource allocation in modular software system, protocol tuning, Java container testing, software project scheduling, software project effort estimation, and software defect prediction. References will be given, from which the details of such application of computational intelligence techniques to software engineering problems can be found.},
booktitle = {Proceedings of the 5th International Symposium on Search Based Software Engineering - Volume 8084},
pages = {4–15},
numpages = {12},
location = {St. Petersburg, Russia},
series = {SSBSE 2013}
}

@inproceedings{10.1145/3324884.3416532,
author = {Tian, Haoye and Liu, Kui and Kabor\'{e}, Abdoul Kader and Koyuncu, Anil and Li, Li and Klein, Jacques and Bissyand\'{e}, Tegawend\'{e} F.},
title = {Evaluating representation learning of code changes for predicting patch correctness in program repair},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416532},
doi = {10.1145/3324884.3416532},
abstract = {A large body of the literature of automated program repair develops approaches where patches are generated to be validated against an oracle (e.g., a test suite). Because such an oracle can be imperfect, the generated patches, although validated by the oracle, may actually be incorrect. While the state of the art explore research directions that require dynamic information or that rely on manually-crafted heuristics, we study the benefit of learning code representations in order to learn deep features that may encode the properties of patch correctness. Our empirical work mainly investigates different representation learning approaches for code changes to derive embeddings that are amenable to similarity computations. We report on findings based on embeddings produced by pre-trained and re-trained neural networks. Experimental results demonstrate the potential of embeddings to empower learning algorithms in reasoning about patch correctness: a machine learning predictor with BERT transformer-based embeddings associated with logistic regression yielded an AUC value of about 0.8 in the prediction of patch correctness on a deduplicated dataset of 1000 labeled patches. Our investigations show that learned representations can lead to reasonable performance when comparing against the state-of-the-art, PATCH-SIM, which relies on dynamic information. These representations may further be complementary to features that were carefully (manually) engineered in the literature.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {981–992},
numpages = {12},
keywords = {distributed representation learning, embeddings, machine learning, patch correctness, program repair},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/3472674.3473980,
author = {Fortz, Sophie and Temple, Paul and Devroey, Xavier and Heymans, Patrick and Perrouin, Gilles},
title = {VaryMinions: leveraging RNNs to identify variants in event logs},
year = {2021},
isbn = {9781450386258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472674.3473980},
doi = {10.1145/3472674.3473980},
abstract = {Business processes have to manage variability in their execution, e.g., to deliver the correct building permit in different municipalities. This variability is visible in event logs, where sequences of events are shared by the core process (building permit authorisation) but may also be specific to each municipality. To rationalise resources (e.g., derive a configurable business process capturing all municipalities’ permit variants) or to debug anomalous behaviour, it is mandatory to identify to which variant a given trace belongs. This paper supports this task by training Long Short Term Memory (LSTMs) and Gated Recurrent Units (GRUs) algorithms on two datasets: a configurable municipality and a travel expenses workflow. We demonstrate that variability can be identified accurately (&gt;87%) and discuss the challenges of learning highly entangled variants.},
booktitle = {Proceedings of the 5th International Workshop on Machine Learning Techniques for Software Quality Evolution},
pages = {13–18},
numpages = {6},
keywords = {Variability Mining, Recurrent Neural Networks, Configurable processes},
location = {Athens, Greece},
series = {MaLTESQuE 2021}
}

@inproceedings{10.1145/3427921.3450243,
author = {Samoaa, Hazem and Leitner, Philipp},
title = {An Exploratory Study of the Impact of Parameterization on JMH Measurement Results in Open-Source Projects},
year = {2021},
isbn = {9781450381949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427921.3450243},
doi = {10.1145/3427921.3450243},
abstract = {The Java Microbenchmarking Harness (JMH) is a widely used tool for testing performance-critical code on a low level. One of the key features of JMH is the support for user-defined parameters, which allows executing the same benchmark with different workloads. However, a benchmark configured with n parameters with m different values each requires JMH to execute the benchmark mn times (once for each combination of configured parameter values). Consequently, even fairly modest parameterization leads to a combinatorial explosion of benchmarks that have to be executed, hence dramatically increasing execution time. However, so far no research has investigated how this type of parameterization is used in practice, and how important different parameters are to benchmarking results. In this paper, we statistically study how strongly different user parameters impact benchmark measurements for 126 JMH benchmarks from five well-known open source projects. We show that 40% of the studied metric parameters have no correlation with the resulting measurement, i.e., testing with different values in these parameters does not lead to any insights. If there is a correlation, it is often strongly predictable following a power law, linear, or step function curve. Our results provide a first understanding of practical usage of user-defined JMH parameters, and how they correlate with the measurements produced by benchmarks. We further show that a machine learning model based on Random Forest ensembles can be used to predict the measured performance of an untested metric parameter value with an accuracy of 93% or higher for all but one benchmark class, demonstrating that given sufficient training data JMH performance test results for different parameterizations are highly predictable.},
booktitle = {Proceedings of the ACM/SPEC International Conference on Performance Engineering},
pages = {213–224},
numpages = {12},
keywords = {machine learning, java microbenchmarking harness (JMH), benchmark parametrization, benchmark measurements},
location = {Virtual Event, France},
series = {ICPE '21}
}

@inproceedings{10.1145/3460319.3464834,
author = {Elsner, Daniel and Hauer, Florian and Pretschner, Alexander and Reimer, Silke},
title = {Empirically evaluating readily available information for regression test optimization in continuous integration},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464834},
doi = {10.1145/3460319.3464834},
abstract = {Regression test selection (RTS) and prioritization (RTP) techniques aim to reduce testing efforts and developer feedback time after a change to the code base. Using various information sources, including test traces, build dependencies, version control data, and test histories, they have been shown to be effective. However, not all of these sources are guaranteed to be available and accessible for arbitrary continuous integration (CI) environments. In contrast, metadata from version control systems (VCSs) and CI systems are readily available and inexpensive. Yet, corresponding RTP and RTS techniques are scattered across research and often only evaluated on synthetic faults or in a specific industrial context. It is cumbersome for practitioners to identify insights that apply to their context, let alone to calibrate associated parameters for maximum cost-effectiveness. This paper consolidates existing work on RTP and unsafe RTS into an actionable methodology to build and evaluate such approaches that exclusively rely on CI and VCS metadata. To investigate how these approaches from prior research compare in heterogeneous settings, we apply the methodology in a large-scale empirical study on a set of 23 projects covering 37,000 CI logs and 76,000 VCS commits. We find that these approaches significantly outperform established RTP baselines and, while still triggering 90% of the failures, we show that practitioners can expect to save on average 84% of test execution time for unsafe RTS. We also find that it can be beneficial to limit training data, features from test history work better than change-based features, and, somewhat surprisingly, simple and well-known heuristics often outperform complex machine-learned models.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {491–504},
numpages = {14},
keywords = {software testing, regression test optimization, machine learning},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@article{10.1007/s10664-018-9611-z,
author = {Liu, Bing and Nejati, Shiva and Lucia and Briand, Lionel C.},
title = {Effective fault localization of automotive Simulink models: achieving the trade-off between test oracle effort and fault localization accuracy},
year = {2019},
issue_date = {February  2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9611-z},
doi = {10.1007/s10664-018-9611-z},
abstract = {One promising way to improve the accuracy of fault localization based on statistical debugging is to increase diversity among test cases in the underlying test suite. In many practical situations, adding test cases is not a cost-free option because test oracles are developed manually or running test cases is expensive. Hence, we require to have test suites that are both diverse and small to improve debugging. In this paper, we focus on improving fault localization of Simulink models by generating test cases. We identify four test objectives that aim to increase test suite diversity. We use four objectives in a search-based algorithm to generate diversified but small test suites. To further minimize test suite sizes, we develop a prediction model to stop test generation when adding test cases is unlikely to improve fault localization. We evaluate our approach using three industrial subjects. Our results show (1) expanding test suites used for fault localization using any of our four test objectives, even when the expansion is small, can significantly improve the accuracy of fault localization, (2) varying test objectives used to generate the initial test suites for fault localization does not have a significant impact on the fault localization results obtained based on those test suites, and (3) we identify an optimal configuration for prediction models to help stop test generation when it is unlikely to be beneficial. We further show that our optimal prediction model is able to maintain almost the same fault localization accuracy while reducing the average number of newly generated test cases by more than half.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {444–490},
numpages = {47},
keywords = {Test suite diversity, Supervised learning, Simulink models, Search-based testing, Fault localization}
}

@inproceedings{10.1145/2810146.2810149,
author = {Bowes, David and Hall, Tracy and Petri\'{c}, Jean},
title = {Different Classifiers Find Different Defects Although With Different Level of Consistency},
year = {2015},
isbn = {9781450337151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810146.2810149},
doi = {10.1145/2810146.2810149},
abstract = {BACKGROUND -- During the last 10 years hundreds of different defect prediction models have been published. The performance of the classifiers used in these models is reported to be similar with models rarely performing above the predictive performance ceiling of about 80% recall.OBJECTIVE -- We investigate the individual defects that four classifiers predict and analyse the level of prediction uncertainty produced by these classifiers.METHOD -- We perform a sensitivity analysis to compare the performance of Random Forest, Na\"{\i}ve Bayes, RPart and SVM classifiers when predicting defects in 12 NASA data sets. The defect predictions that each classifier makes is captured in a confusion matrix and the prediction uncertainty is compared against different classifiers.RESULTS -- Despite similar predictive performance values for these four classifiers, each detects different sets of defects. Some classifiers are more consistent in predicting defects than others.CONCLUSIONS -- Our results confirm that a unique sub-set of defects can be detected by specific classifiers. However, while some classifiers are consistent in the predictions they make, other classifiers vary in their predictions. Classifier ensembles with decision making strategies not based on majority voting are likely to perform best.},
booktitle = {Proceedings of the 11th International Conference on Predictive Models and Data Analytics in Software Engineering},
articleno = {3},
numpages = {10},
location = {Beijing, China},
series = {PROMISE '15}
}

@inproceedings{10.1145/3387940.3392250,
author = {Rahman, Karishma and Kahanda, Indika and Kanewala, Upulee},
title = {MRpredT: Using Text Mining for Metamorphic Relation Prediction},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3392250},
doi = {10.1145/3387940.3392250},
abstract = {Metamorphic relations (MRs) are an essential component of metamorphic testing (MT) that highly affects its fault detection effectiveness. MRs are usually identified with the help of a domain expert, which is a labor-intensive task. In this work, we explore the feasibility of a text classification-based machine learning approach to predict MRs using their program documentation as the sole input. We compare our method to our previously developed graph kernelbased machine learning approach and demonstrate that textual features extracted from program documentation are highly effective for predicting metamorphic relations for matrix calculation programs.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {420–424},
numpages = {5},
keywords = {Text classification, Metamorphic testing, Metamorphic relations},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@article{10.1007/s00500-020-05480-9,
author = {Venkatesh, R. and Balasubramanian, C. and Kaliappan, M.},
title = {RETRACTED ARTICLE: Rainfall prediction using
         generative adversarial networks with convolution neural network},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {6},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05480-9},
doi = {10.1007/s00500-020-05480-9},
abstract = {In recent days, deep learning becomes a successful approach to solving
            complex problems and analyzing the huge volume of data. The proposed system developed a
            rainfall prediction system using generative adversarial networks to analyze rainfall
            data of India and predict the future rainfall. The proposed system used a GAN network in
            which long short-term memory (LSTM) network algorithm is used as a generator and
            convolution neural network model is used as a discriminator. LSTM is much suitable to
            predict time series data such as rainfall data. The experimental results reveal that the
            proposed system provides the predicted results with 99% of accuracy. Rainfall prediction
            helps farmers to cultivate their crops and improved their economy as well as country’s
            economy.},
journal = {Soft Comput.},
month = mar,
pages = {4725–4738},
numpages = {14},
keywords = {Convolution neural network, Deep learning, Generative adversarial networks, Long short-term memory networks}
}

@inproceedings{10.1145/3238147.3238165,
author = {Udeshi, Sakshi and Arora, Pryanshu and Chattopadhyay, Sudipta},
title = {Automated directed fairness testing},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3238165},
doi = {10.1145/3238147.3238165},
abstract = {Fairness is a critical trait in decision making. As machine-learning models are increasingly being used in sensitive application domains (e.g. education and employment) for decision making, it is crucial that the decisions computed by such models are free of unintended bias. But how can we automatically validate the fairness of arbitrary machine-learning models? For a given machine-learning model and a set of sensitive input parameters, our Aeqitas approach automatically discovers discriminatory inputs that highlight fairness violation. At the core of Aeqitas are three novel strategies to employ probabilistic search over the input space with the objective of uncovering fairness violation. Our Aeqitas approach leverages inherent robustness property in common machine-learning models to design and implement scalable test generation methodologies. An appealing feature of our generated test inputs is that they can be systematically added to the training set of the underlying model and improve its fairness. To this end, we design a fully automated module that guarantees to improve the fairness of the model. We implemented Aeqitas and we have evaluated it on six stateof- the-art classifiers. Our subjects also include a classifier that was designed with fairness in mind. We show that Aeqitas effectively generates inputs to uncover fairness violation in all the subject classifiers and systematically improves the fairness of respective models using the generated test inputs. In our evaluation, Aeqitas generates up to 70% discriminatory inputs (w.r.t. the total number of inputs generated) and leverages these inputs to improve the fairness up to 94%.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {98–108},
numpages = {11},
keywords = {Software Fairness, Machine Learning, Directed Testing},
location = {Montpellier, France},
series = {ASE '18}
}

@article{10.1007/s11219-016-9339-1,
author = {Almaghairbe, Rafig and Roper, Marc},
title = {Separating passing and failing test executions by clustering anomalies},
year = {2017},
issue_date = {September 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9339-1},
doi = {10.1007/s11219-016-9339-1},
abstract = {Developments in the automation of test data generation have greatly improved efficiency of the software testing process, but the so-called oracle problem (deciding the pass or fail outcome of a test execution) is still primarily an expensive and error-prone manual activity. We present an approach to automatically detect passing and failing executions using cluster-based anomaly detection on dynamic execution data based on firstly, just a system's input/output pairs and secondly, amalgamations of input/output pairs and execution traces. The key hypothesis is that failures will group into small clusters, whereas passing executions will group into larger ones. Evaluation on three systems with a range of faults demonstrates this hypothesis to be valid--in many cases small clusters were composed of at least 60 % failures (and often more). Concentrating the failures in these small clusters substantially reduces the numbers of outputs that a developer would need to manually examine following a test run and illustrates that the approach has the potential to improve the effectiveness and efficiency of the testing process.},
journal = {Software Quality Journal},
month = sep,
pages = {803–840},
numpages = {38},
keywords = {Test oracles, Software testing, Clustering, Anomaly detection}
}

@article{10.1016/j.ins.2019.01.047,
author = {Azmi, Mohamed and Runger, George C. and Berrado, Abdelaziz},
title = {Interpretable regularized class association rules algorithm for classification in a categorical data space},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {483},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.01.047},
doi = {10.1016/j.ins.2019.01.047},
journal = {Inf. Sci.},
month = may,
pages = {313–331},
numpages = {19},
keywords = {Class association rules, Regularization, Pruning, Association rules, Ensemble learning, Classification}
}

@inproceedings{10.1145/3468264.3468623,
author = {Patra, Jibesh and Pradel, Michael},
title = {Semantic bug seeding: a learning-based approach for creating realistic bugs},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468623},
doi = {10.1145/3468264.3468623},
abstract = {When working on techniques to address the wide-spread problem of software bugs, one often faces the need for a large number of realistic bugs in real-world programs. Such bugs can either help evaluate an approach, e.g., in form of a bug benchmark or a suite of program mutations, or even help build the technique, e.g., in learning-based bug detection. Because gathering a large number of real bugs is difficult, a common approach is to rely on automatically seeded bugs. Prior work seeds bugs based on syntactic transformation patterns, which often results in unrealistic bugs and typically cannot introduce new, application-specific code tokens.  This paper presents SemSeed, a technique for automatically seeding bugs in a semantics-aware way. The key idea is to imitate how a given real-world bug would look like in other programs by semantically adapting the bug pattern to the local context. To reason about the semantics of pieces of code, our approach builds on learned token embeddings that encode the semantic similarities of identifiers and literals. Our evaluation with real-world JavaScript software shows that the approach effectively reproduces real bugs and clearly outperforms a semantics-unaware approach. The seeded bugs are useful as training data for learning-based bug detection, where they significantly improve the bug detection ability. Moreover, we show that SemSeed-created bugs complement existing mutation testing operators, and that our approach is efficient enough to seed hundreds of thousands of bugs within an hour.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {906–918},
numpages = {13},
keywords = {token embeddings, machine learning, dataset, bugs, bug injection},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@article{10.1016/j.infsof.2017.11.005,
author = {Boucher, Alexandre and Badri, Mourad},
title = {Software metrics thresholds calculation techniques to predict fault-proneness: An empirical comparison},
year = {2018},
issue_date = {Apr 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {96},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.11.005},
doi = {10.1016/j.infsof.2017.11.005},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {38–67},
numpages = {30},
keywords = {Object-oriented programming, Code quality, Cross-validation, Clustering, Machine learning, Fault-proneness prediction, Faults, Object-oriented metrics, Class-level metrics, Metrics thresholds}
}

@inbook{10.5555/3454287.3455330,
author = {Alam, Mejbah and Gottschlich, Justin and Tatbul, Nesime and Turek, Javier and Mattson, Timothy and Muzahid, Abdullah},
title = {A zero-positive learning approach for diagnosing software performance regressions},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The field of machine programming (MP), the automation of the development of software, is making notable research advances. This is, in part, due to the emergence of a wide range of novel techniques in machine learning. In this paper, we apply MP to the automation of software performance regression testing. A performance regression is a software performance degradation caused by a code change. We present AutoPerf – a novel approach to automate regression testing that utilizes three core techniques: (i) zero-positive learning, (ii) autoencoders, and (iii) hardware telemetry. We demonstrate AutoPerf's generality and efficacy against 3 types of performance regressions across 10 real performance bugs in 7 benchmark and open-source programs. On average, AutoPerf exhibits 4% profiling overhead and accurately diagnoses more performance bugs than prior state-of-the-art approaches. Thus far, AutoPerf has produced no false negatives.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {1043},
numpages = {13}
}

@article{10.1016/j.future.2018.12.016,
author = {Wang, TianTian and Wang, KeChao and Su, XiaoHong and Lei, Zhang},
title = {Invariant based fault localization by analyzing error propagation},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {94},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.12.016},
doi = {10.1016/j.future.2018.12.016},
journal = {Future Gener. Comput. Syst.},
month = may,
pages = {549–563},
numpages = {15},
keywords = {Test case selection, Error propagation, Program invariant, Software fault localization}
}

@inproceedings{10.1145/3368089.3409754,
author = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
title = {Is neuron coverage a meaningful measure for testing deep neural networks?},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409754},
doi = {10.1145/3368089.3409754},
abstract = {Recent effort to test deep learning systems has produced an intuitive and compelling test criterion called neuron coverage (NC), which resembles the notion of traditional code coverage. NC measures the proportion of neurons activated in a neural network and it is implicitly assumed that increasing NC improves the quality of a test suite. In an attempt to automatically generate a test suite that increases NC, we design a novel diversity promoting regularizer that can be plugged into existing adversarial attack algorithms. We then assess whether such attempts to increase NC could generate a test suite that (1) detects adversarial attacks successfully, (2) produces natural inputs, and (3) is unbiased to particular class predictions. Contrary to expectation, our extensive evaluation finds that increasing NC actually makes it harder to generate an effective test suite: higher neuron coverage leads to fewer defects detected, less natural inputs, and more biased prediction preferences. Our results invoke skepticism that increasing neuron coverage may not be a meaningful objective for generating tests for deep neural networks and call for a new test generation technique that considers defect detection, naturalness, and output impartiality in tandem.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {851–862},
numpages = {12},
keywords = {Testing, Software Engineering, Neuron Coverage, Machine Learning, Adversarial Attack},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1007/s10115-019-01342-5,
author = {Liu, Ruochen and Wang, Fangfang and He, Manman and Jiao, Licheng},
title = {An adjustable fuzzy classification algorithm using an improved multi-objective genetic strategy based on decomposition for imbalance dataset},
year = {2019},
issue_date = {Dec 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {61},
number = {3},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-019-01342-5},
doi = {10.1007/s10115-019-01342-5},
abstract = {In this paper, we propose an adjustable fuzzy classification algorithm using multi-objective genetic strategy based on decomposition (AFC_MOGD) to solve imbalance classification problem. In AFC_MOGD, firstly, an improved multi-objective genetic strategy based on decomposition is adopted as the basic optimization algorithm in which a new updating pattern getting good solutions is designed. Then, an adjustable parameter which is ranged in the interval [0, 1] is used to adjust complexity of each classifier artificially. Finally, a normalized method which takes class percentage into account to determine class label and rule weight of each rule is introduced so as to obtain more reasonable rules. The proposed algorithm is compared with three typical algorithms on eleven imbalance datasets in terms of area under the ROC of convex hull. The Wilcoxon signed-rank test is also carried out to show that our algorithm is superior to other algorithms.},
journal = {Knowl. Inf. Syst.},
month = dec,
pages = {1583–1605},
numpages = {23},
keywords = {Decomposition, Multi-objective optimization, Adjustable fuzzy classifiers, Imbalance dataset}
}

@inproceedings{10.1007/978-3-030-48077-6_3,
author = {Claris\'{o}, Robert and Cabot, Jordi},
title = {Diverse Scenario Exploration in Model Finders Using Graph Kernels and Clustering},
year = {2020},
isbn = {978-3-030-48076-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-48077-6_3},
doi = {10.1007/978-3-030-48077-6_3},
abstract = {Complex software systems can be described using modeling notations such as UML/OCL or Alloy. Then, some correctness properties of these systems can be checked using model finders, which compute sample scenarios either fulfilling the desired properties or illustrating potential faults. Such scenarios allow designers to validate, verify and test the system under development.Nevertheless, when asked to produce several scenarios, model finders tend to produce similar solutions. This lack of diversity impairs their effectiveness as testing or validation assets. To solve this problem, we propose the use of graph kernels, a family of methods for computing the (dis)similarity among pairs of graphs. With this metric, it is possible to cluster scenarios effectively, improving the usability of model finders and making testing and validation more efficient.},
booktitle = {Rigorous State-Based Methods: 7th International Conference, ABZ 2020, Ulm, Germany, May 27–29, 2020, Proceedings},
pages = {27–43},
numpages = {17},
keywords = {Diversity, Clustering, Graph kernels, Testing, Verification and validation, Model-driven engineering},
location = {Ulm, Germany}
}

@article{10.1007/s11063-016-9532-z,
author = {Wan, Jianwu and Wang, Hongyuan and Yang, Ming},
title = {Cost Sensitive Semi-Supervised Canonical Correlation Analysis for Multi-view Dimensionality Reduction},
year = {2017},
issue_date = {April     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {45},
number = {2},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-016-9532-z},
doi = {10.1007/s11063-016-9532-z},
abstract = {To deal with the cost sensitive and semi-supervised learning problems in Multi-view Dimensionality Reduction (MDR), we propose a Cost Sensitive Semi-Supervised Canonical Correlation Analysis $$(hbox {CS}^{3}hbox {CCA}). hbox {CS}^{3}hbox {CCA}$$(CS3CCA).CS3CCA first uses the $$L_2$$L2 norm approach to obtain the soft label for each unlabeled data, and then embed the misclassification cost into the framework of Canonical Correlation Analysis (CCA). Compared with existing CCA based methods, $$hbox {CS}^{3}hbox {CCA}$$CS3CCA has the following advantages: (1) It uses the $$L_2$$L2 norm approach to infer the soft label for unlabeled data, which is computationally efficient and effective, especially for cost sensitive face recognition. (2) The objective function of $$hbox {CS}^{3}hbox {CCA}$$CS3CCA not only maximizes the soft cost sensitive within-class correlations and minimizes the soft cost sensitive between-class correlations in the inter-view, but also considers the class imbalance problem simultaneously. With the discriminant projections learned by $$hbox {CS}^{3}hbox {CCA}$$CS3CCA, we employ it for cost sensitive face recognition. The experimental results on four well-known face data sets, including AR, Extended Yale B, PIE and ORL, demonstrate the effectiveness of $$hbox {CS}^{3}hbox {CCA}$$CS3CCA.},
journal = {Neural Process. Lett.},
month = apr,
pages = {411–430},
numpages = {20},
keywords = {Semi-supervised, Multi-view learning, Face recognition, Cost sensitive learning, Canonical correlation analysis}
}

@article{10.1007/s00521-017-2959-y,
author = {Tiwari, Sadhana and Singh, Birmohan and Kaur, Manpreet},
title = {An approach for feature selection using local searching and global optimization techniques},
year = {2017},
issue_date = {Oct 2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {28},
number = {10},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-017-2959-y},
doi = {10.1007/s00521-017-2959-y},
abstract = {Classification problems such as gene expression array analysis, text processing of Internet document, combinatorial chemistry, software defect prediction and image retrieval involve tens or hundreds of thousands of features in the dataset. However, many of these features may be irrelevant and redundant, which only worsen the performance of the learning algorithms, and this may lead to the problem of overfitting. These superfluous features only degrade the accuracy and the computation time of a classification algorithm. So, the selection of relevant and nonredundant features is an important preprocessing step of any classification problem. Most of the global optimization techniques have the ability to converge to a solution quickly, but these begin with initializing a population randomly and the choice of initial population is an important step. In this paper, local searching algorithms have been used for generating a subset of relevant and nonredundant features; thereafter, a global optimization algorithm has been used so as to remove the limitations of global optimization algorithms, like lack of consistency in classification results and very high time complexity, to some extent. The computation time and classification accuracy are improved by using a feature set obtained from sequential backward selection and mutual information maximization algorithm which is fed to a global optimization technique (genetic algorithm, differential evolution or particle swarm optimization). In this proposed work, the computation time of these global optimization techniques has been reduced by using variance as stopping criteria. The proposed approach has been tested on publicly available Sonar, Wdbc and German datasets.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {2915–2930},
numpages = {16},
keywords = {Support vector machine, Sequential backward selection, Optimization algorithms, Mutual information maximization}
}

@article{10.1007/s10115-021-01577-1,
author = {Pascual-Triana, Jos\'{e} Daniel and Charte, David and Andr\'{e}s&nbsp;Arroyo, Marta and Fern\'{a}ndez, Alberto and Herrera, Francisco},
title = {Revisiting data complexity metrics based on morphology for overlap and imbalance: snapshot, new overlap number of balls metrics and singular problems prospect},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {63},
number = {7},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-021-01577-1},
doi = {10.1007/s10115-021-01577-1},
abstract = {Data Science and Machine Learning have become fundamental assets for companies and research institutions alike. As one of its fields, supervised classification allows for class prediction of new samples, learning from given training data. However, some properties can cause datasets to be problematic to classify. In order to evaluate a dataset a priori, data complexity metrics have been used extensively. They provide information regarding different intrinsic characteristics of the data, which serve to evaluate classifier compatibility and a course of action that improves performance. However, most complexity metrics focus on just one characteristic of the data, which can be insufficient to properly evaluate the dataset towards the classifiers’ performance. In fact, class overlap, a very detrimental feature for the classification process (especially when imbalance among class labels is also present) is hard to assess. This research work focuses on revisiting complexity metrics based on data morphology. In accordance to their nature, the premise is that they provide both good estimates for class overlap, and great correlations with the classification performance. For that purpose, a novel family of metrics has been developed. Being based on ball coverage by classes, they are named after Overlap Number of Balls. Finally, some prospects for the adaptation of the former family of metrics to singular (more complex) problems are discussed.},
journal = {Knowl. Inf. Syst.},
month = jul,
pages = {1961–1989},
numpages = {29},
keywords = {Singular problems, Imbalanced classification, Morphology, Overlap, Data complexity metrics}
}

@article{10.1007/s11063-021-10607-6,
author = {Kassaymeh, Sofian and Abdullah, Salwani and Al-Laham, Mohamad and Alweshah, Mohammed and Al-Betar, Mohammed Azmi and Othman, Zalinda},
title = {Salp Swarm Optimizer for Modeling Software Reliability Prediction Problems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {6},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-021-10607-6},
doi = {10.1007/s11063-021-10607-6},
abstract = {In this paper, software effort prediction (SEP) and software test prediction (STP) (i.e., software reliability problems) are tackled by integrating the salp swarm algorithm (SSA) with a backpropagation neural network (BPNN). Software effort and test prediction problems are common in software engineering and arise when seeking to determine the actual software resources needed to develop a project. BPNN is the most popular prediction algorithm used in the literature. The performance of BPNN depends totally on the initial parameter values such as weight and biases. The main objective of this paper is to integrate SSA with the BPNN to find the optimal weight for every training cycle and thereby improve prediction accuracy. The proposed method, abbreviated as SSA-BPNN, is tested on twelve SEP datasets and two STP datasets. All datasets vary in terms of complexity and size. The results obtained by SSA-BPNN are evaluated according to twelve performance measures: MSE, RMSE, RAE, RRSE, MAE, MRE, MMRE, MdMRE, VAF(%), R2(%), ED, and MD. First, the results obtained by BPNN with SSA (i.e., SSA-BPNN) and without SSA are compared. The evaluation of the results indicates that SSA-BPNN performs better than BPNN for all datasets. In the comparative evaluation, the results of SSA-BPNN are compared against thirteen state-of-the-art methods using the same SEP and STP problem datasets. The evaluation of the results reveals that the proposed method outperforms the comparative methods for almost all datasets, both SEP and STP, in the case of most performance measures. In conclusion, integrating SSA with BPNN is a very powerful approach for solving software reliability problems that can be used widely to yield accurate prediction results.},
journal = {Neural Process. Lett.},
month = dec,
pages = {4451–4487},
numpages = {37},
keywords = {Software test estimation, Software effort estimation, Software reliability problems, Backpropagation neural network, Salp swarm optimizer, Machine learning}
}

@article{10.1016/j.eswa.2018.12.024,
author = {Raghuwanshi, Bhagat Singh and Shukla, Sanyam},
title = {Generalized class-specific kernelized extreme learning machine for multiclass imbalanced learning},
year = {2019},
issue_date = {May 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {121},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2018.12.024},
doi = {10.1016/j.eswa.2018.12.024},
journal = {Expert Syst. Appl.},
month = may,
pages = {244–255},
numpages = {12},
keywords = {Classification, Multiclass imbalanced learning, Generalized class-specific kernelized extreme learning machine, Kernelized extreme learning machine}
}

@article{10.1007/s10489-019-01423-6,
author = {Lopez-Garcia, Pedro and Masegosa, Antonio D. and Osaba, Eneko and Onieva, Enrique and Perallos, Asier},
title = {Ensemble classification for imbalanced data based on feature space partitioning and hybrid metaheuristics},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {8},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-019-01423-6},
doi = {10.1007/s10489-019-01423-6},
abstract = {One of the most challenging issues when facing a classification problem is to deal with imbalanced datasets. Recently, ensemble classification techniques have proven to be very successful in addressing this problem. We present an ensemble classification approach based on feature space partitioning for imbalanced classification. A hybrid metaheuristic called GACE is used to optimize the different parameters related to the feature space partitioning. To assess the performance of the proposal, an extensive experimentation over imbalanced and real-world datasets compares different configurations and base classifiers. Its performance is competitive with that of reference techniques in the literature.},
journal = {Applied Intelligence},
month = aug,
pages = {2807–2822},
numpages = {16},
keywords = {Imbalanced classification, Hybrid metaheuristics, Feature space partitioning, Ensemble classification}
}

@inproceedings{10.1109/ICMLA.2009.17,
author = {Altidor, Wilker and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {Wrapper-Based Feature Ranking for Software Engineering Metrics},
year = {2009},
isbn = {9780769539263},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2009.17},
doi = {10.1109/ICMLA.2009.17},
abstract = {The application of feature ranking to software engineering datasets is rare at best. In this study, we consider wrapper-based feature ranking where nine performance metrics aided by a particular learner are evaluated. We consider five learners and take two different approaches, each in conjunction with one of two different methodologies: 3-fold Cross-Validation (CV) and 3-fold Cross-Validation Risk Impact (CV-R). The classifiers are Na\i{}ve Bayes (NB), Multi Layer Perceptron (MLP), k- Nearest Neighbors (kNN), Support Vector Machines (SVM), and Logistic Regression (LR). The performance metrics used as ranking techniques are Overall Accuracy (OA), F-Measure(FM), Geometric Mean (GM), Arithmetic Mean (AM), Area under ROC (AUC), Area under PRC (PRC), Best F-Measure (BFM), Best Geometric Mean (BGM), and Best Arithmetic Mean (BAM). To evaluate the classifier performance after feature selection has been applied, we use AUC as the performance evaluator. This paper represents a preliminary report on our proposed wrapper-based feature ranking approach to software defect prediction problems.},
booktitle = {Proceedings of the 2009 International Conference on Machine Learning and Applications},
pages = {241–246},
numpages = {6},
keywords = {wrapper-based feature ranking, software engineering metrics, performance metrics, feature selection},
series = {ICMLA '09}
}

@article{10.1007/s11063-017-9703-6,
author = {Ding, Sha and Chen, Zhi and Zhao, Shi-Yuan and Lin, Tao},
title = {Pruning the Ensemble of ANN Based on Decision Tree Induction},
year = {2018},
issue_date = {August    2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {48},
number = {1},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-017-9703-6},
doi = {10.1007/s11063-017-9703-6},
abstract = {Ensemble learning is a powerful approach for achieving more accurate predictions compared with single classifier. However, this powerful classification ability is achieved at the expense of heavy storage requirements and computational burdens on the ensemble. Ensemble pruning is a crucial step for the reduction of the predictive overhead without worsening the performance of original ensemble. This paper suggests an efficient and effective ordering-based ensemble pruning based on the induction of decision tree. The suggested method maps the dataset and base classifiers to a new dataset where the ensemble pruning can be transformed to a feature selection problem. Furthermore, a set of accurate, diverse and complementary base classifiers can be selected by the induction of decision tree. Moreover, an evaluation function that deliberately favors the candidate sub-ensembles with an improved performance in classifying low margin instances has also been designed. The comparative experiments on 24 benchmark datasets demonstrate the effectiveness of our proposed method.},
journal = {Neural Process. Lett.},
month = aug,
pages = {53–70},
numpages = {18},
keywords = {Ordering-based ensemble pruning, Neural network ensemble, Margin distribution, Diversity, Decision tree induction}
}

@article{10.1016/j.neunet.2019.08.018,
author = {Shukla, Sanyam and Raghuwanshi, Bhagat Singh},
title = {Online sequential class-specific extreme learning machine for binary imbalanced learning},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {119},
number = {C},
issn = {0893-6080},
url = {https://doi.org/10.1016/j.neunet.2019.08.018},
doi = {10.1016/j.neunet.2019.08.018},
journal = {Neural Netw.},
month = nov,
pages = {235–248},
numpages = {14},
keywords = {Classification, Online sequential class-specific extreme learning machine, Imbalanced learning, Extreme learning machine}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00010,
author = {Saini, Nishrith and Britto, Ricardo},
title = {Using machine intelligence to prioritise code review requests},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00010},
doi = {10.1109/ICSE-SEIP52600.2021.00010},
abstract = {Modern Code Review (MCR) is the process of reviewing new code changes that need to be merged with an existing codebase. As a developer, one may receive many code review requests every day, i.e., the review requests need to be prioritised. Manually prioritising review requests is a challenging and time-consuming process. To address the above problem, we conducted an industrial case study at Ericsson aiming at developing a tool called Pineapple, which uses a Bayesian Network to prioritise code review requests. To validate our approach/tool, we deployed it in a live software development project at Ericsson, wherein more than 150 developers develop a telecommunication product. We focused on evaluating the predictive performance, feasibility, and usefulness of our approach. The results indicate that Pineapple has competent predictive performance (RMSE = 0.21 and MAE = 0.15). Furthermore, around 82.6% of Pineapple's users believe the tool can support code review request prioritisation by providing reliable results, and around 56.5% of the users believe it helps reducing code review lead time. As future work, we plan to evaluate Pineapple's predictive performance, usefulness, and feasibility through a longitudinal investigation.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {11–20},
numpages = {10},
keywords = {prioritisation, modern code review, machine reasoning, machine learning, machine intelligence, bayesian networks},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@inproceedings{10.1145/3464968.3468409,
author = {Jafarinejad, Foad and Narasimhan, Krishna and Mezini, Mira},
title = {NerdBug: automated bug detection in neural networks},
year = {2021},
isbn = {9781450385411},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3464968.3468409},
doi = {10.1145/3464968.3468409},
abstract = {Despite the exponential growth of deep learning software during the last decade, there is a lack of tools to test and debug issues in deep learning programs. Current static analysis tools do not address challenges specific to deep learning as observed by past research on bugs specific to this area. Existing deep learning bug detection tools focus on specific issues like shape mismatches. In this paper, we present a vision for an abstraction-based approach to detect deep learning bugs and the plan to evaluate our approach. The motivation behind the abstraction-based approach is to be able to build an intermediate version of the neural network that can be analyzed in development time to provide live feedback programmers are used to with other kind of bugs.},
booktitle = {Proceedings of the 1st ACM International Workshop on AI and Software Testing/Analysis},
pages = {13–16},
numpages = {4},
keywords = {Machine Learning, Deep Learning, Debugging, Bug Detection},
location = {Virtual, Denmark},
series = {AISTA 2021}
}

@article{10.1007/s00500-020-05197-9,
author = {Kamaraj, K. and Arvind, C. and Srihari, K.},
title = {A weight optimized artificial neural network for automated software test oracle},
year = {2020},
issue_date = {Sep 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {17},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05197-9},
doi = {10.1007/s00500-020-05197-9},
abstract = {Software testing has its main goal as designing new test case sets in a manner in which it is able to depict its maximum faults. As soon as these test cases have been designed, Oracle software provides a method in which the software has to behave for a particular test case given. Prioritization of such test cases with the execution of their components specifying inputs, their operation and their outcome will determine as to whether the application and their properties are working in the right manner. The prioritization methods are as follows: initial ordering, random ordering and finally reverse ordering that were based on fault detection abilities. For developing software applications, a test suite that was less commonly known as the suite for checking the validity of software was employed. The test suite contained a detailed set of instructions and goals for each test case collection based on the system and its configuration used during testing. Automating the generation of a test case and test oracle was researched in an extensive manner. From among the automated test oracle, the artificial neural network (ANN) was used extensively but with a high cost of computation. This work proposed a weight optimized ANN using stochastic diffusion search to find the optimal weights with a unique fitness function such that computational time is reduced and misclassification rate reduced.},
journal = {Soft Comput.},
month = sep,
pages = {13501–13511},
numpages = {11},
keywords = {Stochastic diffusion search, Test oracle, Test cases, Software testing, Soft computing, Neural science, Artificial neural network, Evolutionary algorithms}
}

@inproceedings{10.1007/978-3-030-28377-3_50,
author = {Czarnowski, Ireneusz and Jundefineddrzejowicz, Piotr},
title = {An Approach to Imbalanced Data Classification Based on Instance Selection and Over-Sampling},
year = {2019},
isbn = {978-3-030-28376-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-28377-3_50},
doi = {10.1007/978-3-030-28377-3_50},
abstract = {The paper referees to a problem of learning from class-imbalanced data. The class imbalance problem arises when the number of instances from different classes differs substantially. Instance selection aims at deciding which instances from the training set should be retained and used during the learning process. Over-sampling is an approach dedicated to duplicate minority class instances. In the paper, a hybrid approach for the imbalanced data learning using the over-sampling and instance selection techniques is proposed. Instances are selected to reduce the number of instances belonging to the majority class, while the number of instances belonging to the minority class is expanded. The process of instance selection is based on clustering, where the authors’ approach to clustering and instance selection using an agent-based population learning algorithm is applied. As a result a more balanced distribution of instances belonging to different classes is obtained and a dataset size is reduced. The proposed approach is validated experimentally using several benchmark datasets.},
booktitle = {Computational Collective Intelligence: 11th International Conference, ICCCI 2019, Hendaye, France, September 4–6, 2019, Proceedings, Part I},
pages = {601–610},
numpages = {10},
keywords = {Under-sampling, Over-sampling, Imbalanced data, Clustering, Instance selection},
location = {Hendaye, France}
}

@inproceedings{10.1145/3460120.3484813,
author = {He, Jingxuan and Sivanrupan, Gishor and Tsankov, Petar and Vechev, Martin},
title = {Learning to Explore Paths for Symbolic Execution},
year = {2021},
isbn = {9781450384544},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460120.3484813},
doi = {10.1145/3460120.3484813},
abstract = {Symbolic execution is a powerful technique that can generate tests steering program execution into desired paths. However, the scalability of symbolic execution is often limited by path explosion, i.e., the number of symbolic states representing the paths under exploration quickly explodes as execution goes on. Therefore, the effectiveness of symbolic execution engines hinges on the ability to select and explore the right symbolic states.In this work, we propose a novel learning-based strategy, called Learch, able to effectively select promising states for symbolic execution to tackle the path explosion problem. Learch directly estimates the contribution of each state towards the goal of maximizing coverage within a time budget, as opposed to relying on manually crafted heuristics based on simple statistics as a crude proxy for the objective. Moreover, Learch leverages existing heuristics in training data generation and feature extraction, and can thus benefit from any new expert-designed heuristics. We instantiated Learch in KLEE, a widely adopted symbolic execution engine. We evaluated Learch on a diverse set of programs, showing that Learch is practically effective: it covers more code and detects more security violations than existing manual heuristics, as well as combinations of those heuristics. We also show that using tests generated by Learch as initial fuzzing seeds enables the popular fuzzer AFL to find more paths and security violations.},
booktitle = {Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2526–2540},
numpages = {15},
keywords = {symbolic execution, program testing, machine learning, fuzzing},
location = {Virtual Event, Republic of Korea},
series = {CCS '21}
}

@article{10.3233/JIFS-17888,
author = {Zhai, Junhai and Zhang, Sufang},
title = {Three-way decisions model based on rough fuzzy set},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {34},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-17888},
doi = {10.3233/JIFS-17888},
abstract = {Three-way decisions model proposed by Yao gives a semantic interpretation of positive region, negative region and boundary region. This model was developed in the framework of classical rough set, the approached target concept is a crisp set, the employed knowledge is a equivalence relation. In this paper, we extend the three-way decisions model to rough fuzzy set. Specifically, the target concept is extended to a fuzzy set, while the used knowledge is also a equivalence relation. An example is given to illustrate the computation processes of the proposed three-way decisions model. The extended model can deal with the problems described by fuzzy decision tables with symbolic-valued conditional attributes and fuzzy decision attributes.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {2051–2059},
numpages = {9},
keywords = {fuzzy set, rough fuzzy set, rough set, Three-way decisions}
}

@inproceedings{10.1145/3243127.3243130,
author = {Ognawala, Saahil and Amato, Ricardo Nales and Pretschner, Alexander and Kulkarni, Pooja},
title = {Automatically assessing vulnerabilities discovered by compositional analysis},
year = {2018},
isbn = {9781450359726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243127.3243130},
doi = {10.1145/3243127.3243130},
abstract = {Testing is the most widely employed method to find vulnerabilities in real-world software programs. Compositional analysis, based on symbolic execution, is an automated testing method to find vulnerabilities in medium- to large-scale programs consisting of many interacting components. However, existing compositional analysis frameworks do not assess the severity of reported vulnerabilities. In this paper, we present a framework to analyze vulnerabilities discovered by an existing compositional analysis tool and assign CVSS3 (Common Vulnerability Scoring System v3.0) scores to them, based on various heuristics such as interaction with related components, ease of reachability, complexity of design and likelihood of accepting unsanitized input. By analyzing vulnerabilities reported with CVSS3 scores in the past, we train simple machine learning models. By presenting our interactive framework to developers of popular open-source software and other security experts, we gather feedback on our trained models and further improve the features to increase the accuracy of our predictions. By providing qualitative (based on community feedback) and quantitative (based on prediction accuracy) evidence from 21 open-source programs, we show that our severity prediction framework can effectively assist developers with assessing vulnerabilities.},
booktitle = {Proceedings of the 1st International Workshop on Machine Learning and Software Engineering in Symbiosis},
pages = {16–25},
numpages = {10},
keywords = {vulnerability assessment, symbolic execution, software testing, compositional analysis},
location = {Montpellier, France},
series = {MASES 2018}
}

@inproceedings{10.1145/3412841.3442029,
author = {Ferreira, Fabio and Silva, Luciana Lourdes and Valente, Marco Tulio},
title = {Software engineering meets deep learning: a mapping study},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442029},
doi = {10.1145/3412841.3442029},
abstract = {Deep Learning (DL) is being used nowadays in many traditional Software Engineering (SE) problems and tasks. However, since the renaissance of DL techniques is still very recent, we lack works that summarize and condense the most recent and relevant research conducted at the intersection of DL and SE. Therefore, in this paper, we describe the first results of a mapping study covering 81 papers about DL &amp; SE. Our results confirm that DL is gaining momentum among SE researchers over the years and that the top-3 research problems tackled by the analyzed papers are documentation, defect prediction, and testing.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1542–1549},
numpages = {8},
keywords = {deep learning, software engineering},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@inproceedings{10.1145/3383972.3384012,
author = {Cheng, Jing and Zhang, Hao and Qin, Kai},
title = {Safety Critical Software Reliability Model Considering Multiple Influencing Factors},
year = {2020},
isbn = {9781450376426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383972.3384012},
doi = {10.1145/3383972.3384012},
abstract = {Safety-critical software accounts for a large proportion of computer applications in high-tech fields such as aerospace, aerospace, and nuclear power. Once a failure occurs, it can seriously endanger human life, cause large-scale environmental damage, or cause huge economic losses. How to accurately evaluate the reliability of safety-critical software has become one of the problems that software reliability engineering needs to solve. Therefore, this paper takes safety-critical software as the research object. Based on the in-depth analysis of the characteristics of safety-critical software, combined with the characteristics of safety-critical software and the common model optimization and improvement ideas, the total number of software failures, the failure detection rate changes, and the troubleshooting rate is less than the correlation between faults and errors is analyzed. The fault detection and elimination process are analyzed. The influencing factors that should be considered in the reliability modeling process of safety critical software are summarized and mathematically described. A multi-influence factor is considered. Safety Critical Software Reliability Model (SCSRM). Based on the safety critical software failure data set, the comparison experiment between SCSRM and the other four software reliability models was completed. The experimental results show that SCSRM can obtain better data fitting and prediction effects in the reliability assessment scenarios of safety-critical software, and proves the validity and stability of the proposed model.},
booktitle = {Proceedings of the 2020 12th International Conference on Machine Learning and Computing},
pages = {560–566},
numpages = {7},
keywords = {Software Reliability Model, Software Reliability, Safety Critical Software},
location = {Shenzhen, China},
series = {ICMLC '20}
}

@inproceedings{10.1145/3330204.3330230,
author = {de Macedo, Charles Mendes and Ruela, Andr\'{e} Siqueira and Delgado, Karina Valdivia},
title = {Application of Clustering Algorithms for Discovering Bug Patterns in JavaScript Software},
year = {2019},
isbn = {9781450372374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3330204.3330230},
doi = {10.1145/3330204.3330230},
abstract = {Applications developed with JavaScript language are increasing every day, not only for client-side, but also for server-side and for mobile devices. In this context, the existence of tools to identify faults is fundamental in order to assist developers during the evolution of their applications. Different tools and approaches have been proposed over the years, however they have limitations to evolve over time, becoming obsolete quickly. The reason for this is the use of a fixed list of pre-defined faults that are searched in the code. The BugAID tool implements a semiautomatic strategy for discovering bug patterns by grouping the changes made during the project development. The objective of this work is to contribute to the BugAID tool, extending this tool with improvements in the extraction of characteristics to be used by the clustering algorithm. The extended module of the BugAID extraction module (BE) that extracts the characteristics is called BE+. Additionally, an evaluation of the clustering algorithms used for discovering fault patterns in JavaScript software is performed. The results show that the DBScan and Optics algorithms with BE+ presented the best results for the Rand, Jaccard and Adjusted Rand indexes, while HDBScan with BE and BE+ presented the worst result.},
booktitle = {Proceedings of the XV Brazilian Symposium on Information Systems},
articleno = {21},
numpages = {8},
keywords = {Software Quality, Pattern Recognition, Machine Learning, Data Mining, Bug Discovery},
location = {Aracaju, Brazil},
series = {SBSI '19}
}

@inproceedings{10.1007/978-3-030-77474-5_12,
author = {Nakajima, Shin},
title = {Software Testing with Statistical Partial Oracles: - Application to Neural Networks Software -},
year = {2020},
isbn = {978-3-030-77473-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77474-5_12},
doi = {10.1007/978-3-030-77474-5_12},
abstract = {With the advent of Bigdata analytics or machine learning software, the characteristics of test target programs become more divergent than before. It brings about two issues on the test oracle problems, uncertainties of the testing conditions and unknown correctness criteria. This paper proposes a new testing framework, which is general enough to account for the existing statistical metamorphic testing and is further amenable to adapt itself to the machine learning software testing. The proposed approach is illustrated with an experiment of testing neural network programs.},
booktitle = {Structured Object-Oriented Formal Language and Method: 10th International Workshop, SOFL+MSVL 2020, Singapore, March 1, 2021, Revised Selected Papers},
pages = {175–192},
numpages = {18},
location = {Singapore, Singapore}
}

@inproceedings{10.1145/3474624.3474634,
author = {Collins, Eliane and Neto, Arilo and Vincenzi, Auri and Maldonado, Jos\'{e}},
title = {Deep Reinforcement Learning based Android Application GUI Testing},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3474634},
doi = {10.1145/3474624.3474634},
abstract = {The advances in mobile computing and the market demand for new products which meet an increasingly public represent the importance to assure the quality of mobile applications. In this context, automated GUI testing has become highlighted in research. However, studies indicate that there are still limitations to achieve a large number of possible combinations of operations, transitions, functionality coverage, and failures reproduction. In this paper, a Deep Q-Network-based android application GUI testing tool (DeepGUIT) is proposed to test case generation for android mobile apps, guiding the exploration by code coverage value and new activities. The tool was evaluated with 15 open-source mobile applications. The obtained results showed higher code coverage than the state-of-the-art tools Monkey (61% average higher) and Q-testing (47% average higher), in addition, a greater number of failures.},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {186–194},
numpages = {9},
keywords = {reinforcement learning, machine learning, and automated testing, Mobile application testing},
location = {Joinville, Brazil},
series = {SBES '21}
}

@article{10.1007/s10836-020-05868-3,
author = {El Badawi, H. and Azais, Florence and Bernard, S. and Comte, M. and Kerzerho, V. and Lefevre, F.},
title = {Investigations on the Use of Ensemble Methods for Specification-Oriented Indirect Test of RF Circuits},
year = {2020},
issue_date = {Apr 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {36},
number = {2},
issn = {0923-8174},
url = {https://doi.org/10.1007/s10836-020-05868-3},
doi = {10.1007/s10836-020-05868-3},
abstract = {In order to reduce the costs of industrial testing of analog and Radio Frequency (RF) integrated circuits, a widely studied solution is indirect testing. Indeed, indirect testing is based on learning-machine algorithms to train a regression model that links the space of low-cost indirect measurements to the space of performance parameters guaranteed by datasheets, thus relaxing the constraints on expensive test equipment. This article explores the potential benefit of using ensemble learning in this context. Unlike traditional learning models that use a single model to estimate targeted parameters, ensemble-learning models involve training several individual regression models and combining their outputs to improve the predictive power of the ensemble model. Different ensemble methods based on bagging, boosting or stacking are investigated and compared to classical individual models. Experiments are performed on three RF performances of a LNA for which we have production test data and model quality is discussed in terms of goodness-of-fit, accuracy and reliability. The influence of the training set size is also explored. Finally, the efficiency of classical and ensemble models is compared in the context of a two-tier test flow that permits to tradeoff test cost and test quality.},
journal = {J. Electron. Test.},
month = apr,
pages = {189–203},
numpages = {15},
keywords = {Test efficiency, Ensemble methods, Machine-learning algorithms, RF integrated circuits, Indirect testing}
}

@article{10.1016/j.neucom.2020.01.120,
author = {Malhotra, Ruchika and Lata, Kusum},
title = {An empirical study to investigate the impact of data resampling techniques on the performance of class maintainability prediction models},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {459},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2020.01.120},
doi = {10.1016/j.neucom.2020.01.120},
journal = {Neurocomput.},
month = oct,
pages = {432–453},
numpages = {22},
keywords = {Object-oriented metrics, Search-based techniques, Machine learning techniques, Data resampling techniques, Imbalanced data, Maintainability prediction}
}

@inproceedings{10.1007/978-3-030-88106-1_7,
author = {Olsthoorn, Mitchell and Panichella, Annibale},
title = {Multi-objective Test Case Selection Through Linkage Learning-Based Crossover},
year = {2021},
isbn = {978-3-030-88105-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-88106-1_7},
doi = {10.1007/978-3-030-88106-1_7},
abstract = {Test Case Selection (TCS) aims to select a subset of the test suite to run for regression testing. The selection is typically based on past coverage and execution cost data. Researchers have successfully used multi-objective evolutionary algorithms (MOEAs), such as NSGA-II and its variants, to solve this problem. These MOEAs use traditional crossover operators to create new candidate solutions through genetic recombination. Recent studies in numerical optimization have shown that better recombinations can be made using machine learning, in particular linkage learning. Inspired by these recent advances in this field, we propose a new variant of NSGA-II, called L2-NSGA, that uses linkage learning to optimize test case selection. In particular, we use an unsupervised clustering algorithm to infer promising patterns among the solutions (subset of test suites). Then, these patterns are used in the next iterations of L2-NSGA to create solutions that preserve these inferred patterns. Our results show that our customizations make NSGA-II more effective for test case selection. The test suite sub-sets generated by L2-NSGA are less expensive and detect more faults than those generated by MOEAs used in the literature for regression testing.},
booktitle = {Search-Based Software Engineering: 13th International Symposium, SSBSE 2021, Bari, Italy, October 11–12, 2021, Proceedings},
pages = {87–102},
numpages = {16},
keywords = {Search-based software engineering, Multi-objective optimization, Test case selection, Regression testing},
location = {Bari, Italy}
}

@article{10.1049/iet-sen.2020.0025,
author = {Shatnawi, Raed},
title = {Comparison of threshold identification techniques for object‐oriented software metrics},
year = {2020},
issue_date = {December 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {6},
url = {https://doi.org/10.1049/iet-sen.2020.0025},
doi = {10.1049/iet-sen.2020.0025},
abstract = {Quality assurance is a continuous process throughout the project lifecycle from inception till post‐delivery. Software metrics are tools to help developers in achieving software quality objectives. Software metrics are used to predict the fault‐proneness of classes in software using machine‐learning and statistical techniques. However, these methodologies are difficult for daily tasks. Simpler and on the fly methodologies such as threshold values are needed. Metric thresholds can be used to control software quality and to recommend improvements on software code. Thresholds detect the parts of software that need more verification and validation. Many threshold identification techniques were proposed in previous research. However, the techniques do not provide consistent thresholds. The authors compare eight threshold identification techniques to diagnose software fault‐proneness. The eight techniques are derived from diagnosis measures such as specificity, sensitivity, recall and precision. Five threshold identification techniques have derived thresholds that are skewed and have large standard deviations. Only three techniques are selected for threshold identification based on consistency and variation in selecting thresholds of software metrics in the systems under study. These techniques find thresholds that have the least variation among the studied techniques. The median of the 11 systems is selected as a representative of all thresholds.},
journal = {IET Software},
month = oct,
pages = {727–738},
numpages = {12},
keywords = {software validation, software verification, machine learning, project lifecycle, software fault proneness, software code, metric thresholds, software quality assurance, statistical techniques, object oriented software metrics, threshold identification techniques, program verification, object‐oriented methods, statistical analysis, product life cycle management, project management, software metrics, software fault tolerance, software quality, learning (artificial intelligence)}
}

@inproceedings{10.1007/978-3-030-91265-9_8,
author = {Lu, Yuteng and Sun, Weidi and Sun, Meng},
title = {Mutation Testing of Reinforcement Learning Systems},
year = {2021},
isbn = {978-3-030-91264-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91265-9_8},
doi = {10.1007/978-3-030-91265-9_8},
abstract = {Reinforcement Learning (RL), one of the most active research areas in artificial intelligence, focuses on goal-directed learning from interaction with an uncertain environment. RL systems play an increasingly important role in many aspects of society. Therefore, its safety issues have received more and more attention. Testing has achieved great success in ensuring safety of the traditional software systems. However, current testing approaches hardly consider RL systems. To fill this gap, we propose the first Mutation Testing technique specialized for RL systems. We define a series of mutation operators simulating possible problems RL systems may encounter. Next, we design test environments that could reveal possible problems within the RL systems. The mutation score specialized for RL systems is proposed to analyze the extent of potential faults and evaluate the quality of test environments. Our evaluation in three popular environments, namely FrozenLake, CartPole, and MountainCar demonstrates the practicability of the proposed techniques.},
booktitle = {Dependable Software Engineering. Theories, Tools, and Applications: 7th International Symposium, SETTA 2021, Beijing, China, November 25–27, 2021, Proceedings},
pages = {143–160},
numpages = {18},
keywords = {AI Safety, Reinforcement Learning, Mutation Testing},
location = {Beijing, China}
}

@article{10.1016/j.infsof.2018.02.005,
author = {Agrawal, Amritanshu and Fu, Wei and Menzies, Tim},
title = {What is wrong with topic modeling? And how to fix it using search-based software engineering},
year = {2018},
issue_date = {Jun 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {98},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2018.02.005},
doi = {10.1016/j.infsof.2018.02.005},
journal = {Inf. Softw. Technol.},
month = jun,
pages = {74–88},
numpages = {15},
keywords = {Differential evolution, Tuning, LDA, Stability, Topic modeling}
}

@article{10.1016/j.ins.2019.10.014,
author = {Zheng, Ming and Li, Tong and Zhu, Rui and Tang, Yahui and Tang, Mingjing and Lin, Leilei and Ma, Zifei},
title = {Conditional Wasserstein generative adversarial network-gradient penalty-based approach to alleviating imbalanced data classification},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {512},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.10.014},
doi = {10.1016/j.ins.2019.10.014},
journal = {Inf. Sci.},
month = feb,
pages = {1009–1023},
numpages = {15},
keywords = {WGAN-GP, GAN, SMOTE, Oversampling approach, Imbalanced learning}
}

@article{10.1007/s10489-018-1323-y,
author = {Singh, Deepak and Singh, Pradeep and Sisodia, Dilip Singh},
title = {Evolutionary based ensemble framework for realizing transfer learning in HIV-1 Protease cleavage sites prediction},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {4},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-018-1323-y},
doi = {10.1007/s10489-018-1323-y},
abstract = {The role of human immunodeficiency virus (HIV) protease in viral maturation is indispensable as the drug therapy primarily targets the HIV protease for the treatment of human immunodeficiency virus infection. Protease inhibitors are designed to block the active site of the protease, thereby restraining the replication of the viral particle. However, designing efficient inhibitors is challenging due to little or no similarity of the sequence among the cleaved sites and availability of few experimentally-verified sites. In order to learn the sequence structure, support vector machines have been comprehensively used however insufficient training data degrades the performance. Thus, a cross-domain approach is adopted by the proposed ensemble model for predicting the HIV-1 protease cleavage sites. In this study, a method for combining multiple weighted classifiers optimally by incorporating the knowledge derived from various amino acid encoding techniques is proposed. As a result, each classifier pair with a specific type of heterogeneous information which is generated by the different encoding method, and the final prediction could be obtained by aggregating the locally trained classifiers. The optimally coupled sequence of features and classifiers that characterized the heterogeneous feature is achieved promptly by genetic algorithm. Furthermore, the efficiency of the model is verified by the tests conducted on the four HIV-1 protease datasets offered at UCI machine learning database. The performance parameters such as average accuracy, standard deviation, and area under curve have been evaluated on the proposed model to justify the advancements over the other state- of-the-art methods. In addition, Friedman and post hoc tests were conducted to show the significant improvement achieved by the proposed framework. These results quantified the enhancement of the proposed ensemble model performance.},
journal = {Applied Intelligence},
month = apr,
pages = {1260–1282},
numpages = {23},
keywords = {Transfer learning, HIV-1 proteases, Genetic algorithm, Ensemble learner, Cross-domain adaptation}
}

@article{10.1016/j.infsof.2012.10.003,
author = {Turhan, Burak and Tosun M\i{}s\i{}rl\i{}, Ay\c{s}e and Bener, Ay\c{s}e},
title = {Empirical evaluation of the effects of mixed project data on learning defect predictors},
year = {2013},
issue_date = {June, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {6},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2012.10.003},
doi = {10.1016/j.infsof.2012.10.003},
abstract = {Context: Defect prediction research mostly focus on optimizing the performance of models that are constructed for isolated projects (i.e. within project (WP)) through retrospective analyses. On the other hand, recent studies try to utilize data across projects (i.e. cross project (CP)) for building defect prediction models for new projects. There are no cases where the combination of within and cross (i.e. mixed) project data are used together. Objective: Our goal is to investigate the merits of using mixed project data for binary defect prediction. Specifically, we want to check whether it is feasible, in terms of defect detection performance, to use data from other projects for the cases (i) when there is an existing within project history and (ii) when there are limited within project data. Method: We use data from 73 versions of 41 projects that are publicly available. We simulate the two above-mentioned cases, and compare the performances of naive Bayes classifiers by using within project data vs. mixed project data. Results: For the first case, we find that the performance of mixed project predictors significantly improves over full within project predictors (p-value&lt;0.001), however the effect size is small (Hedges' g=0.25). For the second case, we found that mixed project predictors are comparable to full within project predictors, using only 10% of available within project data (p-value=0.002, g=0.17). Conclusion: We conclude that the extra effort associated with collecting data from other projects is not feasible in terms of practical performance improvement when there is already an established within project defect predictor using full project history. However, when there is limited project history, e.g. early phases of development, mixed project predictions are justifiable as they perform as good as full within project models.},
journal = {Inf. Softw. Technol.},
month = jun,
pages = {1101–1118},
numpages = {18},
keywords = {Within project, Product metrics, Mixed project, Fault prediction, Defect prediction, Cross project}
}

@inproceedings{10.1007/978-3-030-82136-4_43,
author = {Zhu, Ziye and Wang, Yu and Li, Yun},
title = {TroBo: A Novel Deep Transfer Model for&nbsp;Enhancing Cross-Project Bug&nbsp;Localization},
year = {2021},
isbn = {978-3-030-82135-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-82136-4_43},
doi = {10.1007/978-3-030-82136-4_43},
abstract = {Bug localization, which aims to locate buggy files in the software project by leveraging bug reports, plays an important role in software quality control. Recently, many automatic bug localization methods based on historical bug-fix data (i.e., bug reports labeled with corresponding buggy code files) have been proposed. However, the lack of bug-fix data for software projects in the early stages of development limits the performance of most existing supervised learning methods. To address this issue, we propose a deep transfer bug localization model called TroBo, which can transfer shared knowledge from label-rich source project to the target project. Specifically, we accomplish the knowledge transfer on both the bug report and code file. For processing bug reports, which belong to informal text data, we design a soft attention-based module to alleviate the noise problem. For processing code files, we apply an adversarial strategy to learn the project-shared features, and additionally extract project-exclusive features for each project. Furthermore, a project-aware classifier is introduced in TroBo to avoid redundancy between shared and exclusive features. Extensive experiments on four large-scale real-world projects demonstrate that our model significantly outperforms the state-of-the-art techniques.},
booktitle = {Knowledge Science, Engineering and Management: 14th International Conference, KSEM 2021, Tokyo, Japan, August 14–16, 2021, Proceedings, Part I},
pages = {529–541},
numpages = {13},
keywords = {Bug-fix data, Attention mechanism, Adversarial training, Transfer learning, Bug localization},
location = {Tokyo, Japan}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00027,
author = {Usman, Muhammad and Noller, Yannic and P\u{a}s\u{a}reanu, Corina S. and Sun, Youcheng and Gopinath, Divya},
title = {NeuroSPF: a tool for the symbolic analysis of neural networks},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00027},
doi = {10.1109/ICSE-Companion52605.2021.00027},
abstract = {This paper presents NeuroSPF, a tool for the symbolic analysis of neural networks. Given a trained neural network model, the tool extracts the architecture and model parameters and translates them into a Java representation that is amenable for analysis using the Symbolic PathFinder symbolic execution tool. Notably, NeuroSPF encodes specialized peer classes for parsing the model's parameters, thereby enabling efficient analysis. With NeuroSPF the user has the flexibility to specify either the inputs or the network internal parameters as symbolic, promoting the application of program analysis and testing approaches from software engineering to the field of machine learning. For instance, NeuroSPF can be used for coverage-based testing and test generation, finding adversarial examples and also constraint-based repair of neural networks, thus improving the reliability of neural networks and of the applications that use them. Video URL: https://youtu.be/seal8fG78LI},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {25–28},
numpages = {4},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@article{10.1145/3345628,
author = {Kim, Yunho and Mun, Seokhyeon and Yoo, Shin and Kim, Moonzoo},
title = {Precise Learn-to-Rank Fault Localization Using Dynamic and Static Features of Target Programs},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3345628},
doi = {10.1145/3345628},
abstract = {Finding the root cause of a bug requires a significant effort from developers. Automated fault localization techniques seek to reduce this cost by computing the suspiciousness scores (i.e., the likelihood of program entities being faulty). Existing techniques have been developed by utilizing input features of specific types for the computation of suspiciousness scores, such as program spectrum or mutation analysis results. This article presents a novel learn-to-rank fault localization technique called PRecise machINe-learning-based fault loCalization tEchnique (PRINCE). PRINCE uses genetic programming (GP) to combine multiple sets of localization input features that have been studied separately until now. For dynamic features, PRINCE encompasses both Spectrum Based Fault Localization (SBFL) and Mutation Based Fault Localization (MBFL) techniques. It also uses static features, such as dependency information and structural complexity of program entities. All such information is used by GP to train a ranking model for fault localization. The empirical evaluation on 65 real-world faults from CoREBench, 84 artificial faults from SIR, and 310 real-world faults from Defects4J shows that PRINCE outperforms the state-of-the-art SBFL, MBFL, and learn-to-rank techniques significantly. PRINCE localizes a fault after reviewing 2.4% of the executed statements on average (4.2 and 3.0 times more precise than the best of the compared SBFL and MBFL techniques, respectively). Also, PRINCE ranks 52.9% of the target faults within the top ten suspicious statements.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = oct,
articleno = {23},
numpages = {34},
keywords = {source file characteristics, mutation analysis, machine learning, Fault localization}
}

@article{10.1504/ijcse.2019.101343,
author = {Otoom, Ahmed Fawzi and Al-Shdaifat, Doaa and Hammad, Maen and Abdallah, Emad E. and Aljammal, Ashraf},
title = {Automated labelling and severity prediction of software bug reports},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {19},
number = {3},
issn = {1742-7185},
url = {https://doi.org/10.1504/ijcse.2019.101343},
doi = {10.1504/ijcse.2019.101343},
abstract = {Our main aim is to develop an intelligent classifier that is capable of predicting the severity and label (type) of a newly submitted bug report through a bug tracking system. For this purpose, we build two datasets that are based on 350 bug reports from the open-source community (Eclipse, Mozilla, and Gnome). These datasets are characterised with various textual features. Based on this information, we train variety of discriminative models that are used for automated labelling and severity prediction of a newly submitted bug report. A boosting algorithm is also implemented for an enhanced performance. The classification performance is measured using accuracy and a set of other measures. For automated labelling, the accuracy reaches around 91% with the AdaBoost algorithm and cross validation test. On the other hand, for severity prediction, the classification accuracy reaches around 67% with the AdaBoost algorithm and cross validation test. Overall, the results are encouraging.},
journal = {Int. J. Comput. Sci. Eng.},
month = jan,
pages = {334–342},
numpages = {8},
keywords = {bug labelling, machine learning, software bugs, severity prediction}
}

@article{10.1016/j.jksuci.2017.07.006,
author = {Lal, Sangeeta and Sardana, Neetu and Sureka, Ashish},
title = {Three-level learning for improving cross-project logging prediction for if-blocks},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {31},
number = {4},
issn = {1319-1578},
url = {https://doi.org/10.1016/j.jksuci.2017.07.006},
doi = {10.1016/j.jksuci.2017.07.006},
journal = {J. King Saud Univ. Comput. Inf. Sci.},
month = oct,
pages = {481–496},
numpages = {16}
}

@inproceedings{10.1145/3368089.3409687,
author = {Kampmann, Alexander and Havrikov, Nikolas and Soremekun, Ezekiel O. and Zeller, Andreas},
title = {When does my program do this? learning circumstances of software behavior},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409687},
doi = {10.1145/3368089.3409687},
abstract = {A program fails. Under which circumstances does the failure occur? Our Alhazenapproach starts with a run that exhibits a particular behavior and automatically determines input features associated with the behavior in question: (1) We use a grammar to parse the input into individual elements. (2) We use a decision tree learner to observe and learn which input elements are associated with the behavior in question. (3) We use the grammar to generate additional inputs to further strengthen or refute hypotheses as learned associations. (4) By repeating steps 2&nbsp;and&nbsp;3, we obtain a theory that explains and predicts the given behavior. In our evaluation using inputs for find, grep, NetHack, and a JavaScript transpiler, the theories produced by Alhazen predict and produce failures with high accuracy and allow developers to focus on a small set of input features: “grep fails whenever the --fixed-strings option is used in conjunction with an empty search string.”},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1228–1239},
numpages = {12},
keywords = {software behavior, machine learning, error diagnosis, debugging},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1016/j.asoc.2018.01.042,
author = {Czibula, Gabriela and Czibula, Istvan Gergely and Marian, Zsuzsanna},
title = {An effective approach for determining the class integration test order using reinforcement learning},
year = {2018},
issue_date = {Apr 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {65},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2018.01.042},
doi = {10.1016/j.asoc.2018.01.042},
journal = {Appl. Soft Comput.},
month = apr,
pages = {517–530},
numpages = {14},
keywords = {Reinforcement learning, Machine learning, Class integration test order identification, Integration testing, 68T05, 68N30, 68M15}
}

@article{10.1145/3398267,
author = {Huang, Qicheng and Fang, Chenlei and Mittal, Soumya and Blanton, R. D. (Shawn)},
title = {Towards Smarter Diagnosis: A Learning-based Diagnostic Outcome Previewer},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {5},
issn = {1084-4309},
url = {https://doi.org/10.1145/3398267},
doi = {10.1145/3398267},
abstract = {Given the inherent perturbations during the fabrication process of integrated circuits that lead to yield loss, diagnosis of failing chips is a mitigating method employed during both yield ramping and high-volume manufacturing for yield learning. However, various uncertainties in the fabrication process bring a number of challenges, resulting in diagnosis with undesirable outcomes or low efficiency, including, for example, diagnosis failure, bad resolution, and extremely long runtime. It would therefore be very beneficial to have a comprehensive preview of diagnostic outcomes beforehand, which allows fail logs to be prioritized in a more reasonable way for smarter allocation of diagnosis resources. In this work, we propose a learning-based previewer, which is able to predict five aspects of diagnostic outcomes for a failing IC, including diagnosis success, defect count, failure type, resolution, and runtime magnitude. The previewer consists of three classification models and one regression model, where Random Forest classification and regression are used. Experiments on a 28 nm test chip and a high-volume 90 nm part demonstrate that the predictors can provide accurate prediction results, and in a virtual application scenario the overall previewer can bring up to 9\texttimes{} speed-up for the test chip and 6\texttimes{} for the high-volume part.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = aug,
articleno = {43},
numpages = {20},
keywords = {diagnosis preview, diagnosis economics, Random forest}
}

@inproceedings{10.1145/3210459.3210473,
author = {Mi, Qing and Keung, Jacky and Xiao, Yan and Mensah, Solomon and Mei, Xiupei},
title = {An Inception Architecture-Based Model for Improving Code Readability Classification},
year = {2018},
isbn = {9781450364034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210459.3210473},
doi = {10.1145/3210459.3210473},
abstract = {The process of classifying a piece of source code into a Readable or Unreadable class is referred to as Code Readability Classification. To build accurate classification models, existing studies focus on handcrafting features from different aspects that intuitively seem to correlate with code readability, and then exploring various machine learning algorithms based on the newly proposed features. On the contrary, our work opens up a new way to tackle the problem by using the technique of deep learning. Specifically, we propose IncepCRM, a novel model based on the Inception architecture that can learn multi-scale features automatically from source code with little manual intervention. We apply the information of human annotators as the auxiliary input for training IncepCRM and empirically verify the performance of IncepCRM on three publicly available datasets. The results show that: 1) Annotator information is beneficial for model performance as confirmed by robust statistical tests (i.e., the Brunner-Munzel test and Cliff's delta); 2) IncepCRM can achieve an improved accuracy against previously reported models across all datasets. The findings of our study confirm the feasibility and effectiveness of deep learning for code readability classification.},
booktitle = {Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018},
pages = {139–144},
numpages = {6},
keywords = {Inception Architecture, Empirical Software Engineering, Deep Learning, Code Readability Classification},
location = {Christchurch, New Zealand},
series = {EASE '18}
}

@article{10.1016/j.ins.2011.09.034,
author = {Yu, Lean},
title = {An evolutionary programming based asymmetric weighted least squares support vector machine ensemble learning methodology for software repository mining},
year = {2012},
issue_date = {May, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {191},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2011.09.034},
doi = {10.1016/j.ins.2011.09.034},
abstract = {In this paper, a novel evolutionary programming (EP) based asymmetric weighted least squares support vector machine (LSSVM) ensemble learning methodology is proposed for software repository mining. In this methodology, an asymmetric weighted LSSVM model is first proposed. Then the process of building the EP-based asymmetric weighted LSSVM ensemble learning methodology is described in detail. Two publicly available software defect datasets are finally used for illustration and verification of the effectiveness of the proposed EP-based asymmetric weighted LSSVM ensemble learning methodology. Experimental results reveal that the proposed EP-based asymmetric weighted LSSVM ensemble learning methodology can produce promising classification accuracy in software repository mining, relative to other classification methods listed in this study.},
journal = {Inf. Sci.},
month = may,
pages = {31–46},
numpages = {16},
keywords = {Software repository mining, Evolutionary programming, Ensemble learning algorithm, Asymmetric weighted least squares support vector machine}
}

@article{10.34768/amcs-2021-0046,
author = {Piundefinedta, Piotr and Szmuc, Tomasz},
title = {Applications of Rough Sets in Big Data Analysis: An Overview},
year = {2021},
issue_date = {Dec 2021},
publisher = {Walter de Gruyter &amp; Co.},
address = {USA},
volume = {31},
number = {4},
issn = {1641-876X},
url = {https://doi.org/10.34768/amcs-2021-0046},
doi = {10.34768/amcs-2021-0046},
abstract = {Big data, artificial intelligence and the Internet of things (IoT) are still very popular areas in current research and industrial applications. Processing massive amounts of data generated by the IoT and stored in distributed space is not a straightforward task and may cause many problems. During the last few decades, scientists have proposed many interesting approaches to extract information and discover knowledge from data collected in database systems or other sources. We observe a permanent development of machine learning algorithms that support each phase of the data mining process, ensuring achievement of better results than before. Rough set theory (RST) delivers a formal insight into information, knowledge, data reduction, uncertainty, and missing values. This formalism, formulated in the 1980s and developed by several researches, can serve as a theoretical basis and practical background for dealing with ambiguities, data reduction, building ontologies, etc. Moreover, as a mature theory, it has evolved into numerous extensions and has been transformed through various incarnations, which have enriched expressiveness and applicability of the related tools. The main aim of this article is to present an overview of selected applications of RST in big data analysis and processing. Thousands of publications on rough sets have been contributed; therefore, we focus on papers published in the last few years. The applications of RST are considered from two main perspectives: direct use of the RST concepts and tools, and jointly with other approaches, i.e., fuzzy sets, probabilistic concepts, and deep learning. The latter hybrid idea seems to be very promising for developing new methods and related tools as well as extensions of the application area.},
journal = {Int. J. Appl. Math. Comput. Sci.},
month = dec,
pages = {659–683},
numpages = {25},
keywords = {tools, data mining, deep learning, big data analysis, rough sets theory}
}

@article{10.1016/j.future.2018.09.051,
author = {Viegas, Eduardo and Santin, Altair and Bessani, Alysson and Neves, Nuno},
title = {BigFlow: Real-time and reliable anomaly-based intrusion detection for high-speed networks},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {93},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.09.051},
doi = {10.1016/j.future.2018.09.051},
journal = {Future Gener. Comput. Syst.},
month = apr,
pages = {473–485},
numpages = {13},
keywords = {Anomaly-based intrusion detection, Classification reliability, Stream learning, Data stream}
}

@article{10.1145/3483424,
author = {Notaro, Paolo and Cardoso, Jorge and Gerndt, Michael},
title = {A Survey of AIOps Methods for Failure Management},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3483424},
doi = {10.1145/3483424},
abstract = {Modern society is increasingly moving toward complex and distributed computing systems. The increase in scale and complexity of these systems challenges O&amp;M teams that perform daily monitoring and repair operations, in contrast with the increasing demand for reliability and scalability of modern applications. For this reason, the study of automated and intelligent monitoring systems has recently sparked much interest across applied IT industry and academia. Artificial Intelligence for IT Operations (AIOps) has been proposed to tackle modern IT administration challenges thanks to Machine Learning, AI, and Big Data. However, AIOps as a research topic is still largely unstructured and unexplored, due to missing conventions in categorizing contributions for their data requirements, target goals, and components. In this work, we focus on AIOps for Failure Management (FM), characterizing and describing 5 different categories and 14 subcategories of contributions, based on their time intervention window and the target problem being solved. We review 100 FM solutions, focusing on applicability requirements and the quantitative results achieved, to facilitate an effective application of AIOps solutions. Finally, we discuss current development problems in the areas covered by AIOps and delineate possible future trends for AI-based failure management.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = nov,
articleno = {81},
numpages = {45},
keywords = {artificial intelligence, failure management, IT operations and maintenance, AIOps}
}

@inproceedings{10.1007/978-3-030-59592-0_9,
author = {Meng, Lun and Sun, Yao and Zhang, Shudong},
title = {Midiag: A Sequential Trace-Based Fault Diagnosis Framework for Microservices},
year = {2020},
isbn = {978-3-030-59591-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59592-0_9},
doi = {10.1007/978-3-030-59592-0_9},
abstract = {Cloud applications are often deployed in shared data centers to optimize resource allocation and improve management efficiency. However, since a cloud application often has a large amount of different microservices, it is difficult for operators to analyze these microservices with a unified model. To deal with the above problem, this paper proposes a sequential trace-based fault diagnosis framework called as Midiag by mining the patterns of microservices’ system call sequences. Midiag collects system calls with a non-invasive lightweight tool, and then uses k-means to cluster system call sequences as patterns with the longest common subsequence. The GRU-based neural network is employed to model the patterns of system call sequences to predict the next system call, and thus we can diagnose faults by comparing the predicted next system call and the actual next one in the specific pattern. We have validated Midiag with many different types of applications deployed in containers. The results demonstrate that Midiag can well classify these applications as different types and accurately diagnose the injected faults.},
booktitle = {Services Computing – SCC 2020: 17th International Conference, Held as Part of the Services Conference Federation, SCF 2020, Honolulu, HI, USA, September 18–20, 2020, Proceedings},
pages = {137–144},
numpages = {8},
keywords = {Fault diagnosis, System call, Microservices, Cloud applications},
location = {Honolulu, HI, USA}
}

@inproceedings{10.5555/3016387.3016470,
author = {Elmishali, Amir and Stern, Roni and Kalech, Meir},
title = {Data-augmented software diagnosis},
year = {2016},
publisher = {AAAI Press},
abstract = {Software fault prediction algorithms predict which software components is likely to contain faults using machine learning techniques. Software diagnosis algorithm identify the faulty software components that caused a failure using model-based or spectrum based approaches. We show how software fault prediction algorithms can be used to improve software diagnosis. The resulting data-augmented diagnosis algorithm overcomes key problems in software diagnosis algorithms: ranking diagnoses and distinguishing between diagnoses with high probability and low probability. We demonstrate the efficiency of the proposed approach empirically on three open sources domains, showing significant increase in accuracy of diagnosis and efficiency of troubleshooting. These encouraging results suggests broader use of data-driven methods to complement and improve existing model-based methods.},
booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
pages = {4003–4009},
numpages = {7},
location = {Phoenix, Arizona},
series = {AAAI'16}
}

@inproceedings{10.1007/978-3-030-87007-2_26,
author = {Szamosv\"{o}lgyi, Zsolt J\'{a}nos and V\'{a}radi, Endre Tam\'{a}s and T\'{o}th, Zolt\'{a}n and J\'{a}sz, Judit and Ferenc, Rudolf},
title = {Assessing Ensemble Learning Techniques in Bug Prediction},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_26},
doi = {10.1007/978-3-030-87007-2_26},
abstract = {The application of ensemble learning techniques is continuously increasing, since they have proven to be superior over traditional machine learning techniques in various domains. These algorithms could be employed for bug prediction purposes as well. Existing studies investigated the performance of ensemble learning techniques only for PROMISE and the NASA MDP public datasets; however, it is important to evaluate the ensemble learning techniques on additional public datasets in order to test the generalizability of the techniques. We investigated the performance of the two most widely-used ensemble learning techniques AdaBoost and Bagging on the Unified Bug Dataset, which encapsulates 3 class level public bug datasets in a uniformed format with a common set of software product metrics used as predictors. Additionally, we investigated the effect of using 3 different resampling techniques on the dataset. Finally, we studied the performance of using Decision Tree and Na\"{\i}ve Bayes as the weak learners in the ensemble learning. We also fine tuned the parameters of the weak learners to have the best possible end results.We experienced that AdaBoost with Decision Tree weak learner outperformed other configurations. We could achieve 54.61% F-measure value (81.96% Accuracy, 50.92% Precision, 58.90% Recall) with the configuration of 300 estimators and 0.05 learning rate. Based on the needs, one can apply RUS resampling to get a recall value up&nbsp;to 75.14% (of course losing precision at the same time).},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {368–381},
numpages = {14},
keywords = {Unified bug dataset, Resampling, Bug prediction, AdaBoost},
location = {Cagliari, Italy}
}

@article{10.1145/3127360.3127368,
author = {Kumar, Lov and Behera, Ranjan Kumar and Rath, Santanu and Sureka, Ashish},
title = {Transfer Learning for Cross-Project Change-Proneness Prediction in Object-Oriented Software Systems: A Feasibility Analysis},
year = {2017},
issue_date = {July 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3127360.3127368},
doi = {10.1145/3127360.3127368},
abstract = {Change-prone classes or modules are defined as regions of the source code which are more likely to change as a result of a software development of maintenance activity. Automatic identification of change-prone classes are useful for the software development team as they can focus their testing efforts on areas within the source code which are more likely to change. Several machine learning techniques have been proposed for predicting change-prone classes based on the application of source code metrics as indicators. However, most of the work has focused on within-project training and model building. There are several real word scenario in which sufficient training dataset is not available for model building such as in the case of a new project. Cross-project prediction is an approach which consists of training a model from dataset belonging to one project and testing it on dataset belonging to a different project. Cross-project change-proneness prediction is relatively unexplored.We propose a machine learning based approach for cross-project change-proneness prediction. We conduct experiments on 10 open-source Eclipse plug-ins and demonstrate the effectiveness of our approach. We frame several research questions comparing the performance of within project and cross project prediction and also propose a Genetic Algorithm (GA) based approach for identifying the best set of source code metrics. We conclude that for within project experimental setting, Random Forest (RF) technique results in the best precision. In case of cross-project change-proneness prediction, our analysis reveals that the NDTF ensemble method performs higher than other individual classifiers (such as decision tree and logistic regression) and ensemble methods in the experimental dataset. We conduct a comparison of within-project, cross-project without GA and cross-project with GA and our analysis reveals that cross-project with GA performs best followed by within-project and then cross-project without GA.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–11},
numpages = {11}
}

@mastersthesis{10.5555/AAI28027666,
author = {Brumfield, Marcus and Williams, Byron and Bhowmik, Tanmay},
advisor = {Stefano, Iannucci,},
title = {A Deep Learning Approach to Predict Software Bugs Using Micro Patterns and Software Metrics},
year = {2020},
isbn = {9798664731248},
publisher = {Mississippi State University},
address = {USA},
abstract = {Software bugs prediction is one of the most active research areas in the software engineering community. The process of testing and debugging code proves to be costly during the software development life cycle. Software metrics measure the quality of source code to identify software bugs and vulnerabilities. Traceable code patterns are able to de- scribe code at a finer granularity level to measure quality. Micro patterns will be used in this research to mechanically describe java code at the class level. Machine learning has also been introduced for bug prediction to localize source code for testing and debugging. Deep Learning is a branch of Machine Learning that is relatively new. This research looks to improve the prediction of software bugs by utilizing micro patterns with deep learning techniques. Software bug prediction at a finer granularity level will enable developers to localize code to test and debug during the development process.},
note = {AAI28027666}
}

@article{10.1007/s11219-010-9128-1,
author = {M\i{}s\i{}rl\i{}, Ay\c{s}e Tosun and Bener, Ay\c{s}e Ba\c{s}ar and Turhan, Burak},
title = {An industrial case study of classifier ensembles for locating software defects},
year = {2011},
issue_date = {September 2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-010-9128-1},
doi = {10.1007/s11219-010-9128-1},
abstract = {As the application layer in embedded systems dominates over the hardware, ensuring software quality becomes a real challenge. Software testing is the most time-consuming and costly project phase, specifically in the embedded software domain. Misclassifying a safe code as defective increases the cost of projects, and hence leads to low margins. In this research, we present a defect prediction model based on an ensemble of classifiers. We have collaborated with an industrial partner from the embedded systems domain. We use our generic defect prediction models with data coming from embedded projects. The embedded systems domain is similar to mission critical software so that the goal is to catch as many defects as possible. Therefore, the expectation from a predictor is to get very high probability of detection (pd). On the other hand, most embedded systems in practice are commercial products, and companies would like to lower their costs to remain competitive in their market by keeping their false alarm (pf) rates as low as possible and improving their precision rates. In our experiments, we used data collected from our industry partners as well as publicly available data. Our results reveal that ensemble of classifiers significantly decreases pf down to 15% while increasing precision by 43% and hence, keeping balance rates at 74%. The cost-benefit analysis of the proposed model shows that it is enough to inspect 23% of the code on local datasets to detect around 70% of defects.},
journal = {Software Quality Journal},
month = sep,
pages = {515–536},
numpages = {22},
keywords = {Static code attributes, Ensemble of classifiers, Embedded software, Defect prediction}
}

@article{10.1016/j.infsof.2017.08.004,
title = {MULTI},
year = {2018},
issue_date = {January 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {93},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.08.004},
doi = {10.1016/j.infsof.2017.08.004},
abstract = {Context: Just-in-time software defect prediction (JIT-SDP) aims to conduct defect prediction on code changes, which have finer granularity. A recent study by Yang etal. has shown that there exist some unsupervised methods, which are comparative to supervised methods in effort-aware JIT-SDP.Objective: However, we still believe that supervised methods should have better prediction performance since they effectively utilize the gathered defect prediction datasets. Therefore we want to design a new supervised method for JIT-SDP with better performance.Method: In this article, we propose a multi-objective optimization based supervised method MULTI to build JIT-SDP models. In particular, we formalize JIT-SDP as a multi-objective optimization problem. One objective is designed to maximize the number of identified buggy changes and another object is designed to minimize the efforts in software quality assurance activities. There exists an obvious conflict between these two objectives. MULTI uses logistic regression to build the models and uses NSGA-II to generate a set of non-dominated solutions, which each solution denotes the coefficient vector for the logistic regression.Results: We design and conduct a large-scale empirical studies to compare MULTI with 43 state-of-the-art supervised and unsupervised methods under the three commonly used performance evaluation scenarios: cross-validation, cross-project-validation, and timewise-cross-validation. Based on six open-source projects with 227,417 changes in total, our experimental results show that MULTI can perform significantly better than all of the state-of-the-art methods when considering ACC and POPT performance metrics.Conclusion: By using multi-objective optimization, MULTI can perform significantly better than the state-of-the-art supervised and unsupervised methods in the three performance evaluation scenarios. The results confirm that supervised methods are still promising in effort-aware JIT-SDP.},
journal = {Inf. Softw. Technol.},
month = jan,
pages = {1–13},
numpages = {13}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00036,
author = {Beller, Moritz and Wong, Chu-Pan and Bader, Johannes and Scott, Andrew and Machalica, Mateusz and Chandra, Satish and Meijer, Erik},
title = {What it would take to use mutation testing in industry: a study at Facebook},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00036},
doi = {10.1109/ICSE-SEIP52600.2021.00036},
abstract = {Traditionally, mutation testing generates an abundance of small deviations of a program, called mutants. At industrial systems the scale and size of Facebook's, doing this is infeasible. We should not create mutants that the test suite would likely fail on or that give no actionable signal to developers. To tackle this problem, in this paper, we semi-automatically learn error-inducing patterns from a corpus of common Java coding errors and from changes that caused operational anomalies at Facebook specifically. We combine the mutations with instrumentation that measures which tests exactly visited the mutated piece of code. Results on more than 15,000 generated mutants show that more than half of the generated mutants survive Facebook's rigorous test suite of unit, integration, and system tests. Moreover, in a case study with 26 developers, all but two expressed that the mutation exposed a lack of testing in principle. As such, almost half of the 26 would actually act on the mutant presented to them by adapting an existing or creating a new test. The others did not for a variety of reasons often outside the scope of mutation testing. It remains a practical challenge how we can include such external information to increase the actionability rate on mutants.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {268–277},
numpages = {10},
keywords = {mutation testing, mutation monkey, machine learning, getafix},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@inproceedings{10.1145/3475716.3475789,
author = {Huang, Yuekai and Wang, Junjie and Wang, Song and Liu, Zhe and Wang, Dandan and Wang, Qing},
title = {Characterizing and Predicting Good First Issues},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475789},
doi = {10.1145/3475716.3475789},
abstract = {Background. Where to start contributing to a project is a critical challenge for newcomers of open source projects. To support newcomers, GitHub utilizes the Good First Issue (GFI) label, with which project members can manually tag issues in an open source project that are suitable for the newcomers. However, manually labeling GFIs is time- and effort-consuming given the large number of candidate issues. In addition, project members need to have a close understanding of the project to label GFIs accurately.Aims. This paper aims at providing a thorough understanding of the characteristics of GFIs and an automatic approach in GFIs prediction, to reduce the burden of project members and help newcomers easily onboard.Method. We first define 79 features to characterize the GFIs and further analyze the correlation between each feature and GFIs. We then build machine learning models to predict GFIs with the proposed features.Results. Experiments are conducted with 74,780 issues from 10 open source projects from GitHub. Results show that features related to the semantics, readability, and text richness of issues can be used to effectively characterize GFIs. Our prediction model achieves a median AUC of 0.88. Results from our user study further prove its potential practical value.Conclusions. This paper provides new insights and practical guidelines to facilitate the understanding of GFIs and the automation of GFIs labeling.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {13},
numpages = {12},
keywords = {Open Source Software, Newcomers, Machine Learning, Issue Report},
location = {Bari, Italy},
series = {ESEM '21}
}

@article{10.1007/s00500-019-03757-2,
author = {Tsai, Cheng-Jung},
title = {New feature selection and voting scheme to improve classification accuracy},
year = {2019},
issue_date = {Nov 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {22},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-019-03757-2},
doi = {10.1007/s00500-019-03757-2},
abstract = {Classification is a classic technique employed in data mining. Many ensemble learning methods have been introduced to improve the predictive accuracy of classification. A typical ensemble learning method consists of three steps: selection, building, and integration. Of the three steps, the first and third significantly affect the predictive accuracy of the classification. In this paper, we propose a new selection and integration scheme. Our method can improve the accuracy of subtrees and maintain their diversity. Through a new voting scheme, the predictive accuracy of ensemble learning is improved. We also theoretically analyzed the selection and integration steps of our method. The results of experimental analyses show that our method can achieve better accuracy than two state-of-the-art tree-based ensemble learning approaches.},
journal = {Soft Comput.},
month = nov,
pages = {12017–12030},
numpages = {14},
keywords = {Voting, Feature selection, Ensemble learning, Decision tree, Classification, Data mining}
}

@article{10.1145/3477127.3477131,
author = {Won, Kwanghee and Choi, Hyung-do and Shin, Sung},
title = {Deep learning-based semantic classification of EMF-related scientific literature},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {2},
issn = {1559-6915},
url = {https://doi.org/10.1145/3477127.3477131},
doi = {10.1145/3477127.3477131},
abstract = {Semantic classification of scientific literature using machine learning approaches is challenging due to the difficulties in labeling data and the length of the texts [2, 7]. Most of the work has been done for keyword-based categorization tasks, which take care of occurrence of important terms, whereas semantic classification requires understanding of terms and the meaning of sentences in a context. In this study, we have evaluated neural network models on a semantic classification task using 1091 labeled EMF-related scientific papers listed in the Powerwatch study. The EMF-related papers are labeled into three categories: positive, null finding, and neither. We have conducted neural architecture and hyperparameter search to find the most suitable model for the task. In experiments, we compared the performance of several neural network models in terms of classification accuracy. In addition, we have tested two different types of attention mechanisms. First, a Fully Convolutional Neural Network (FCN) has been used to identify important sentences in the text for the semantic classification. Second, the Transformer, a self-attention-based model, has been tested on the dataset. The experimental result showed that the BiLSTM performed best on both unbalanced and balanced data and the FCN was able to identify important parts in input texts.},
journal = {SIGAPP Appl. Comput. Rev.},
month = jul,
pages = {48–56},
numpages = {9},
keywords = {semantic classification, fully convolutional network, deep neural network, attention model}
}

@article{10.1016/j.jss.2014.08.032,
author = {Wang, Yabin and Gao, Ruizhi and Chen, Zhenyu and Wong, W. Eric and Luo, Bin},
title = {WAS},
year = {2014},
issue_date = {December 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {98},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.08.032},
doi = {10.1016/j.jss.2014.08.032},
abstract = {We propose WAS - a novel clustering test selection strategy.WAS significantly reduces the cost of examining test results manually.Clustering effectiveness is improved by assigning weights to execution profiles.WAS outperforms other CTS strategies in terms of both recall and precision.WAS outperforms other CTS strategies in both single and multiple bug conditions. In past decades, many techniques have been proposed to generate and execute test cases automatically. However, when a test oracle does not exist, execution results have to be examined manually. With increasing functionality and complexity of today's software, this process can be extremely time-consuming and mistake-prone. A CTS-based (cluster test selection) strategy provides a feasible solution to mitigate such deficiency by examining the execution results only with respect to a small number of selected test cases. It groups test cases with similar execution profiles into the same cluster and selects them from each cluster. Some well-known CTS-based strategies are one per cluster, n (a predefined value which is greater than 1) per cluster, adaptive sampling, and execution-spectra-based sampling (ESBS). The ultimate goal is to reduce testing cost by quickly identifying the executions that are likely to fail. However, improperly grouping the test cases will significantly diminish the effectiveness of these strategies (by examining results of more successful executions and fewer failed executions). To overcome this problem, we propose a weighted attribute-based strategy (WAS). Instead of clustering test cases based on the similarity of their execution profiles only once like the aforementioned CTS-based strategies, WAS will conduct more than one iteration of clustering using weighted execution profiles by also considering the suspiciousness of each program element (statement, basic block, decision, etc.), where the suspiciousness in terms of the likelihood of containing bugs can be computed by using various software fault localization techniques. Case studies using seven programs (make, ant, sed, flex, grep, gzip, and space) and four CTS-based strategies (one per cluster sampling, n per cluster sampling, adaptive sampling, and ESBS) were conducted to evaluate the effectiveness of WAS on 184 faulty versions containing either single or multiple bugs. Experimental results suggest that the proposed WAS strategy outperforms other four CTS-based strategies with respect to both recall and precision such that output verification is focused more strongly on failed executions.},
journal = {J. Syst. Softw.},
month = dec,
pages = {44–58},
numpages = {15},
keywords = {Weighted execution profile, Software fault localization, Cluster test selection}
}

@inproceedings{10.1109/MSR.2017.4,
author = {Rajbahadur, Gopi Krishnan and Wang, Shaowei and Kamei, Yasutaka and Hassan, Ahmed E.},
title = {The impact of using regression models to build defect classifiers},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.4},
doi = {10.1109/MSR.2017.4},
abstract = {It is common practice to discretize continuous defect counts into defective and non-defective classes and use them as a target variable when building defect classifiers (discretized classifiers). However, this discretization of continuous defect counts leads to information loss that might affect the performance and interpretation of defect classifiers. Another possible approach to build defect classifiers is through the use of regression models then discretizing the predicted defect counts into defective and non-defective classes (regression-based classifiers).In this paper, we compare the performance and interpretation of defect classifiers that are built using both approaches (i.e., discretized classifiers and regression-based classifiers) across six commonly used machine learning classifiers (i.e., linear/logistic regression, random forest, KNN, SVM, CART, and neural networks) and 17 datasets. We find that: i) Random forest based classifiers outperform other classifiers (best AUC) for both classifier building approaches; ii) In contrast to common practice, building a defect classifier using discretized defect counts (i.e., discretized classifiers) does not always lead to better performance.Hence we suggest that future defect classification studies should consider building regression-based classifiers (in particular when the defective ratio of the modeled dataset is low). Moreover, we suggest that both approaches for building defect classifiers should be explored, so the best-performing classifier can be used when determining the most influential features.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {135–145},
numpages = {11},
keywords = {random forest, non-discretization, model interpretation, discretization, classification via regression, bug prediction},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1109/ICSE.2019.00054,
author = {Philip, Adithya Abraham and Bhagwan, Ranjita and Kumar, Rahul and Maddila, Chandra Sekhar and Nagappan, Nachiappan},
title = {FastLane: test minimization for rapidly deployed large-scale online services},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00054},
doi = {10.1109/ICSE.2019.00054},
abstract = {Today, we depend on numerous large-scale services for basic operations such as email. These services, built on the basis of Continuous Integration/Continuous Deployment (CI/CD) processes, are extremely dynamic: developers continuously commit code and introduce new features, functionality and fixes. Hundreds of commits may enter the code-base in a single day. Therefore one of the most time-critical, yet resource-intensive tasks towards ensuring code-quality is effectively testing such large code-bases.This paper presents FastLane, a system that performs data-driven test minimization. FastLane uses light-weight machine-learning models built upon a rich history of test and commit logs to predict test outcomes. Tests for which we predict outcomes need not be explicitly run, thereby saving us precious test-time and resources. Our evaluation on a large-scale email and collaboration platform service shows that our techniques can save 18.04%, i.e., almost a fifth of test-time while obtaining a test outcome accuracy of 99.99%.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {408–418},
numpages = {11},
keywords = {test prioritization, machine learning, commit risk},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1504/ijcse.2021.115645,
author = {Panda, Rama Ranjan and Nagwani, Naresh Kumar},
title = {Multi-label software bug categorisation based on fuzzy similarity},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {24},
number = {3},
issn = {1742-7185},
url = {https://doi.org/10.1504/ijcse.2021.115645},
doi = {10.1504/ijcse.2021.115645},
abstract = {The efficiency of the software depends on timely detection of bugs. For better quality and low-cost development bug fixing time should be minimised. Categorisation of software bugs helps to understand the root cause of software bugs and to improve triaging. As the software development approach is modular and multi-skilled, it is possible that one software bug can affect multiple modules, and multiple developers can fix newly reported bugs. Hence, a multi-label categorisation of software bugs is needed. Fuzzy similarity techniques can be helpful in understanding the belongingness of software bugs in multiple categories. In this paper a multi-label fuzzy similarity based categorisation technique is presented for effective categorisation of software bugs. Fuzzy similarity between a pair of bugs is computed and, based on a user defined threshold value, the bugs are categorised. Experiments are performed on software bug data sets, and the performance of the proposed classifier is evaluated.},
journal = {Int. J. Comput. Sci. Eng.},
month = jan,
pages = {244–258},
numpages = {14},
keywords = {software bug repository, MLC, multi-label classification, fuzzy similarity, software bug classification, software bug mining}
}

@inproceedings{10.1145/3468264.3473931,
author = {Lampel, Johannes and Just, Sascha and Apel, Sven and Zeller, Andreas},
title = {When life gives you oranges: detecting and diagnosing intermittent job failures at Mozilla},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473931},
doi = {10.1145/3468264.3473931},
abstract = {Continuous delivery of cloud systems requires constant running of jobs (build processes, tests, etc.). One issue that plagues this continuous integration (CI) process are intermittent failures - non-deterministic, false alarms that do not result from a bug in the software or job specification, but rather from issues in the underlying infrastructure. At Mozilla, such intermittent failures are called oranges as a reference to the color of the build status indicator. As such intermittent failures disrupt CI and lead to failures, they erode the developers' trust in the jobs. We present a novel approach that automatically classifies failing jobs to determine whether job execution failures arise from an actual software bug or were caused by flakiness in the job (e.g., test) or the underlying infrastructure. For this purpose, we train classification models using job telemetry data to diagnose failure patterns involving features such as runtime, cpu load, operating system version, or specific platform with high precision. In an evaluation on a set of Mozilla CI jobs, our approach achieves precision scores of 73%, on average, across all data sets with some test suites achieving precision scores good enough for fully automated classification (i.e., precision scores of up to 100%), and recall scores of 82% on average (up to 94%).},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1381–1392},
numpages = {12},
keywords = {machine learning, intermittent failures, flaky tests, continuous integration, Software testing},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1007/978-3-030-83903-1_14,
author = {Piazzesi, Niccol\`{o} and Hong, Massimo and Ceccarelli, Andrea},
title = {Attack and Fault Injection in Self-driving Agents on the Carla Simulator – Experience Report},
year = {2021},
isbn = {978-3-030-83902-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-83903-1_14},
doi = {10.1007/978-3-030-83903-1_14},
abstract = {Machine Learning applications are acknowledged at the foundation of autonomous driving, because they are the enabling technology for most driving tasks. However, the inclusion of trained agents in automotive systems exposes the vehicle to novel attacks and faults, that can result in safety threats to the driving tasks. In this paper we report our experimental campaign on the injection of adversarial attacks and software faults in a self-driving agent running in a driving simulator. We show that adversarial attacks and faults injected in the trained agent can lead to erroneous decisions and severely jeopardize safety. The paper shows a feasible and easily-reproducible approach based on open source simulator and tools, and the results clearly motivate the need of both protective measures and extensive testing campaigns.},
booktitle = {Computer Safety, Reliability, and Security: 40th International Conference, SAFECOMP 2021, York, UK, September 8–10, 2021, Proceedings},
pages = {210–225},
numpages = {16},
keywords = {Self-driving, Machine Learning, Trained agent, Adversarial attacks, Faults, Injection, Simulation},
location = {York, United Kingdom}
}

@article{10.1007/s13319-019-0215-1,
author = {Deotale, Nilesh Tejram and Sarode, Tanuja K.},
title = {Fabric Defect Detection Adopting Combined GLCM, Gabor Wavelet Features and Random Decision Forest},
year = {2019},
issue_date = {March     2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {10},
number = {1},
issn = {2092-6731},
url = {https://doi.org/10.1007/s13319-019-0215-1},
doi = {10.1007/s13319-019-0215-1},
journal = {3D Res.},
month = mar,
articleno = {215},
numpages = {13},
keywords = {Random decision forest, Gabor wavelet, GLCM, Feature extraction, Fabric defect detection}
}

@article{10.1007/s00500-020-05005-4,
author = {Malhotra, Ruchika and Lata, Kusum},
title = {A systematic literature review on empirical studies towards prediction of software maintainability},
year = {2020},
issue_date = {Nov 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {21},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05005-4},
doi = {10.1007/s00500-020-05005-4},
abstract = {Software maintainability prediction in the earlier stages of software development involves the construction of models for the accurate estimation of maintenance effort. This guides the software practitioners to manage the resources optimally. This study aims at systematically reviewing the prediction models from January 1990 to October 2019 for predicting software maintainability. We analyze the effectiveness of these models according to various aspects. To meet the goal of the research, we have identified 36 research papers. On investigating these papers, we found that various machine learning (ML), statistical (ST), and hybridized (HB) techniques have been applied to develop prediction models to predict software maintainability. The significant finding of this review is that the overall performance of ML-based models is better than that of ST models. The use of HB techniques for prediction of software maintainability is limited. The results of this review revealed that software maintainability prediction (SMP) models developed using ML techniques outperformed models developed using ST techniques. Also, the prediction performance of few models developed using HB techniques is encouraging, yet no conclusive results about the performance of HB techniques could be reported because different HB techniques are applied in a few studies.},
journal = {Soft Comput.},
month = nov,
pages = {16655–16677},
numpages = {23},
keywords = {Hybridized techniques, Statistical techniques, Machine learning techniques, Software maintainability, Software maintenance}
}

@article{10.1007/s11192-019-03167-z,
author = {Wang, Pancheng and Li, Shasha and Zhou, Haifang and Tang, Jintao and Wang, Ting},
title = {Cited text spans identification with an improved balanced ensemble model},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {120},
number = {3},
issn = {0138-9130},
url = {https://doi.org/10.1007/s11192-019-03167-z},
doi = {10.1007/s11192-019-03167-z},
abstract = {Scientific summarization aims to provide condensed summary of important contributions of scientific papers. This problem has been extensively explored and recent interest has been aroused to taking advantage of the cited text spans to generate summaries. Cited text spans are the texts in the cited paper that most accurately reflect the citation. They can be viewed as important aspects of the cited paper which are annotated by academic community. Hence, identifying cited text spans is of vital importance for providing a different scientific summarization. In this paper, we explore three potential improvements towards our previous work which is a two-layer ensemble model to tackle the cited text spans identification problem. We first view cited text spans identification as an imbalanced classification problem and carry out comparison on preprocessing methods to handle the imbalanced dataset. Then we propose RANdom Sampling Aggregating&nbsp;(RANSA) algorithm to train classifiers in the first ensemble layer model. Finally, an improved stacking framework Hybrid-Stacking is applied to combine the models of the first layer. Our new ensemble model overcomes flaws of the previous work, and shows improved performance on cited text spans identification.},
journal = {Scientometrics},
month = sep,
pages = {1111–1145},
numpages = {35},
keywords = {Stacking, Ensemble, Cited text spans, Scientific summarization}
}

@inproceedings{10.1109/SMC-IT.2006.79,
author = {Yairi, Takehisa and Kawahara, Yoshinobu and Fujimaki, Ryohei and Sato, Yuichi and Machida, Kazuo},
title = {Telemetry-mining: A Machine Learning Approach to Anomaly Detection and Fault Diagnosis for Space Systems},
year = {2006},
isbn = {0769526446},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SMC-IT.2006.79},
doi = {10.1109/SMC-IT.2006.79},
abstract = {For any space mission, safety and reliability are the most important issues. To tackle this problem, we have studied anomaly detection and fault diagnosis methods for spacecraft systems based on machine learning (ML) and data mining (DM) technology. In these methods, the knowledge or model which is necessary for monitoring a spacecraft system is (semi-)automatically acquired from the spacecraft telemetry data. In this paper, we first overview the anomaly detection / diagnosis problem in the spacecraft systems and conventional techniques such as limit-check, expert systems and model-based diagnosis. Then we explain the concept of ML/DM-based approach to this problem, and introduce several anomaly detection / diagnosis methods which have been developed by us.},
booktitle = {Proceedings of the 2nd IEEE International Conference on Space Mission Challenges for Information Technology},
pages = {466–476},
numpages = {11},
series = {SMC-IT '06}
}

@inproceedings{10.1145/3460319.3464813,
author = {Luo, Sicheng and Xu, Hui and Bi, Yanxiang and Wang, Xin and Zhou, Yangfan},
title = {Boosting symbolic execution via constraint solving time prediction (experience paper)},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464813},
doi = {10.1145/3460319.3464813},
abstract = {Symbolic execution is an essential approach for automated test case generation. However, the approach is generally not scalable to large programs. One critical reason is that the constraint solving problems in symbolic execution are generally hard. Consequently, the symbolic execution process may get stuck in solving such hard problems. To mitigate this issue, symbolic execution tools generally rely on a timeout threshold to terminate the solving. Such a timeout is generally set to a fixed, predefined value, e.g., five minutes in angr. Nevertheless, how to set a proper timeout is critical to the tool’s efficiency. This paper proposes an approach to tackle the problem by predicting the time required for solving a constraint model so that the symbolic execution engine could base on the information to determine whether to continue the current solving process. Due to the cost of the prediction itself, our approach triggers the predictor only when the solving time has exceeded a relatively small value. We have shown that such a predictor can achieve promising performance with several different machine learning models and datasets. By further employing an adaptive design, the predictor can achieve an F1-score ranging from 0.743 to 0.800 on these datasets. We then apply the predictor to eight programs and conduct simulation experiments. Results show that the efficiency of constraint solving for symbolic execution can be improved by 1.25x to 3x, depending on the distribution of the hardness of their constraint models.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {336–347},
numpages = {12},
keywords = {Symbolic execution, SMT solving, Adaptive machine learning},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@article{10.5555/2873642.2873720,
author = {Hentech, Rim and Jenhani, Ilyes and Elouedi, Zied},
title = {Possibilistic AIRS induction from uncertain data},
year = {2016},
issue_date = {January   2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {1},
issn = {1432-7643},
abstract = {This paper presents a new approach in machine learning, especially, in supervised classification and reasoning under uncertainty. For many classification problems, uncertainty is often inherent in modeling applications and should be treated carefully and not rejected to make better decisions. Artificial immune recognition system (AIRS) is a well-known classifier that has provided good results with certain data. However, this method is not able to cope with uncertainty. To overcome this limitation, we propose a new classification approach combining the AIRS and possibility theory. The new approach is allowing to deal with uncertain attribute and also class values of training instances. The uncertainty is expressed via possibility distributions. Experimentations on real datasets from the U.C.I machine learning repository show good performances of the proposed approach.},
journal = {Soft Comput.},
month = jan,
pages = {3–17},
numpages = {15},
keywords = {Possibility theory, Classification under uncertainty, Artificial immune recognition system}
}

@inproceedings{10.1109/ICSE.2019.00069,
author = {Cui, Di and Liu, Ting and Cai, Yuanfang and Zheng, Qinghua and Feng, Qiong and Jin, Wuxia and Guo, Jiaqi and Qu, Yu},
title = {Investigating the impact of multiple dependency structures on software defects},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00069},
doi = {10.1109/ICSE.2019.00069},
abstract = {Over the past decades, numerous approaches were proposed to help practitioner to predict or locate defective files. These techniques often use syntactic dependency, history co-change relation, or semantic similarity. The problem is that, it remains unclear whether these different dependency relations will present similar accuracy in terms of defect prediction and localization. In this paper, we present our systematic investigation of this question from the perspective of software architecture. Considering files involved in each dependency type as an individual design space, we model such a design space using one DRSpace. We derived 3 DRSpaces for each of the 117 Apache open source projects, with 643,079 revision commits and 101,364 bug reports in total, and calculated their interactions with defective files. The experiment results are surprising: the three dependency types present significantly different architectural views, and their interactions with defective files are also drastically different. Intuitively, they play completely different roles when used for defect prediction/localization. The good news is that the combination of these structures has the potential to improve the accuracy of defect prediction/localization. In summary, our work provides a new perspective regarding to which type(s) of relations should be used for the task of defect prediction/localization. These quantitative and qualitative results also advance our knowledge of the relationship between software quality and architectural views formed using different dependency types.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {584–595},
numpages = {12},
keywords = {software structure, software quality, software maintenance},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1007/s00766-015-0232-4,
author = {Dargan, John L. and Wasek, James S. and Campos-Nanez, Enrique},
title = {Systems performance prediction using requirements quality attributes classification},
year = {2016},
issue_date = {November  2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {4},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-015-0232-4},
doi = {10.1007/s00766-015-0232-4},
abstract = {Poor requirements definition can adversely impact system cost and performance for government acquisition programs. This can be mitigated by ensuring requirements statements are written in a clear and unambiguous manner with high linguistic quality. This paper introduces a statistical model that uses requirements quality factors to predict system operational performance. This work explores four classification techniques (Logistic Regression, Na\"{\i}ve Bayes Classifier, Support Vector Machine, and K-Nearest Neighbor) to develop the predictive model. This model is created using empirical data from current major acquisition programs within the federal government. Operational Requirements Documents and Operational Test Reports are the data sources, respectively, for the system requirements statements and the accompanying operational test results used for model development. A commercial-off-the-shelf requirements quality analysis tool is used to determine the requirements linguistic quality metrics used in the model. Subsequent to model construction, the predictive value of the model is confirmed through execution of a sensitivity analysis, cross-validation of the data, and an overfitting analysis. Lastly, Receiver Operating Characteristics are examined to determine the best performing model. In all, the results establish that requirements quality is indeed a predictive factor for end-system operational performance, and the resulting statistical model can influence requirements development based on likelihood of successful operational performance.},
journal = {Requir. Eng.},
month = nov,
pages = {553–572},
numpages = {20},
keywords = {Requirements quality attributes, Requirements engineering, Requirements definition, Poor requirements, Natural language requirements}
}

@article{10.1016/j.eswa.2020.114134,
author = {Yang, Xueqi and Yu, Zhe and Wang, Junjie and Menzies, Tim},
title = {Understanding static code warnings: An incremental AI approach},
year = {2021},
issue_date = {Apr 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {167},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2020.114134},
doi = {10.1016/j.eswa.2020.114134},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {12},
keywords = {Selection process, Static analysis, Active learning, Actionable warning identification}
}

@inproceedings{10.1145/3485832.3488018,
author = {Koo, Hyungjoon and Park, Soyeon and Kim, Taesoo},
title = {A Look Back on a Function Identification Problem},
year = {2021},
isbn = {9781450385794},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485832.3488018},
doi = {10.1145/3485832.3488018},
abstract = {A function recognition problem serves as a basis for further binary analysis and many applications. Although common challenges for function detection are well known, prior works have repeatedly claimed a noticeable result with a high precision and recall. In this paper, we aim to fill the void of what has been overlooked or misinterpreted by closely looking into the previous datasets, metrics, and evaluations with varying case studies. Our major findings are that i)&nbsp;a common corpus like GNU utilities is insufficient to represent the effectiveness of function identification, ii)&nbsp;it is difficult to claim, at least in the current form, that an ML-oriented approach is scientifically superior to deterministic ones like IDA or Ghidra, iii)&nbsp;the current metrics may not be reasonable enough to measure varying function detection cases, and iv)&nbsp;the capability of recognizing functions depends on each tool’s strategic or peculiar choice. We perform re-evaluation of existing approaches on our own dataset, demonstrating that not a single state-of-the-art tool dominates all the others. In conclusion, a function detection problem has not yet been fully addressed, and we need a better methodology and metric to make advances in the field of function identification.},
booktitle = {Proceedings of the 37th Annual Computer Security Applications Conference},
pages = {158–168},
numpages = {11},
keywords = {Binary, Function Identification, Function Recognition, Lookback, ML-oriented},
location = {Virtual Event, USA},
series = {ACSAC '21}
}

@article{10.1016/j.infsof.2019.05.009,
author = {Nashaat, Mona and Ghosh, Aindrila and Miller, James and Quader, Shaikh and Marston, Chad},
title = {M-Lean: An end-to-end development framework for predictive models in B2B scenarios},
year = {2019},
issue_date = {Sep 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {113},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.05.009},
doi = {10.1016/j.infsof.2019.05.009},
journal = {Inf. Softw. Technol.},
month = sep,
pages = {131–145},
numpages = {15},
keywords = {Case study, User trust, Business-to-business, Machine learning, Big data}
}

@inproceedings{10.5555/3298239.3298469,
author = {Wu, Fei and Jing, Xiao-Yuan and Shan, Shiguang and Zuo, Wangmeng and Yang, Jing-Yu},
title = {Multiset feature learning for highly imbalanced data classification},
year = {2017},
publisher = {AAAI Press},
abstract = {With the expansion of data, increasing imbalanced data has emerged. When the imbalance ratio of data is high, most existing imbalanced learning methods decline in classification performance. To address this problem, a few highly imbalanced learning methods have been presented. However, most of them are still sensitive to the high imbalance ratio. This work aims to provide an effective solution for the highly imbalanced data classification problem. We conduct highly imbalanced learning from the perspective of feature learning. We partition the majority class into multiple blocks with each being balanced to the minority class and combine each block with the minority class to construct a balanced sample set. Multiset feature learning (MFL) is performed on these sets to learn discriminant features. We thus propose an uncorrelated cost-sensitive multiset learning (UCML) approach. UCML provides a multiple sets construction strategy, incorporates the cost-sensitive factor into MFL, and designs a weighted uncorrelated constraint to remove the correlation among multiset features. Experiments on five highly imbalanced datasets indicate that: UCML outperforms state-of-the-art imbalanced learning methods.},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
pages = {1583–1589},
numpages = {7},
location = {San Francisco, California, USA},
series = {AAAI'17}
}

@article{10.1145/3428283,
author = {Brody, Shaked and Alon, Uri and Yahav, Eran},
title = {A structural model for contextual code changes},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428283},
doi = {10.1145/3428283},
abstract = {We address the problem of predicting edit completions based on a learned model that was trained on past edits. Given a code snippet that is partially edited, our goal is to predict a completion of the edit for the rest of the snippet. We refer to this task as the EditCompletion task and present a novel approach for tackling it. The main idea is to directly represent structural edits. This allows us to model the likelihood of the edit itself, rather than learning the likelihood of the edited code. We represent an edit operation as a path in the program’s Abstract Syntax Tree (AST), originating from the source of the edit to the target of the edit. Using this representation, we present a powerful and lightweight neural model for the EditCompletion task. We conduct a thorough evaluation, comparing our approach to a variety of representation and modeling approaches that are driven by multiple strong models such as LSTMs, Transformers, and neural CRFs. Our experiments show that our model achieves a 28% relative gain over state-of-the-art sequential models and 2\texttimes{} higher accuracy than syntactic models that learn to generate the edited code, as opposed to modeling the edits directly. Our code, dataset, and trained models are publicly available at &lt;a&gt;https://github.com/tech-srl/c3po/&lt;/a&gt; .},
journal = {Proc. ACM Program. Lang.},
month = nov,
articleno = {215},
numpages = {28},
keywords = {Neural Models of Code, Machine Learning, Edit Completions}
}

@inproceedings{10.1007/978-3-030-31517-7_17,
author = {Bagheri, Babak and Rezaalipour, Mohammad and Vahidi-Asl, Mojtaba},
title = {An Approach to Generate Effective Fault Localization Methods for Programs},
year = {2019},
isbn = {978-3-030-31516-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31517-7_17},
doi = {10.1007/978-3-030-31517-7_17},
abstract = {Software Debugging is a tedious and costly task in software development life-cycle. Thus, various automated fault localization approaches have been proposed to address this problem, among which, spectrum-based fault localization has attracted a lot of attention. Using various formulas, known as ranking metrics, spectrum-based fault localization techniques assign scores to the entities of programs (e.g., statements) based on their suspiciousness of being the root cause of failures. Despite the obvious advantages of spectrum-based fault localization techniques, such as being lightweight, they cannot effectively locate faults in every program owing to the fact that they do not consider the characteristics of the programs. We believe that program characteristics can be helpful at finding the right ranking metrics for programs, and they can assist at combining several existing ones to produce a customized ranking metric specific to a given program.In this paper, we have proposed an approach which combines 40 different ranking metrics to generate a new ranking metric specific to a given program. Employing mutation testing operators, the proposed approach retrieves information from the program and then, using different preferential voting systems, it combines various ranking metrics based on the collected information. We have evaluated our approach on 154 faulty versions from eight different programs of Space and Siemens test suite and compare it with nine state-of-the-art ranking metrics. The experimental results indicate that the ranking metrics generated by our approach is superior with respect to evaluation metrics such as the Exam score and TOP-N.},
booktitle = {Fundamentals of Software Engineering: 8th International Conference, FSEN 2019, Tehran, Iran, May 1-3, 2019, Revised Selected Papers},
pages = {244–259},
numpages = {16},
keywords = {Preferential voting system, Ranking metric, Mutation testing, Spectrum-based fault localization, Software fault localization},
location = {Tehran, Iran}
}

@article{10.1155/2018/6798042,
author = {Guo, Huaping and Diao, Xiaoyu and Liu, Hongbing and Gutierrez, Pedro Antonio},
title = {Embedding Undersampling Rotation Forest for Imbalanced Problem},
year = {2018},
issue_date = {2018},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2018},
issn = {1687-5265},
url = {https://doi.org/10.1155/2018/6798042},
doi = {10.1155/2018/6798042},
abstract = {Rotation Forest is an ensemble learning approach achieving better performance comparing to Bagging and Boosting through building accurate and diverse classifiers using rotated feature space. However, like other conventional classifiers, Rotation Forest does not work well on the imbalanced data which are characterized as having much less examples of one class (minority class) than the other (majority class), and the cost of misclassifying minority class examples is often much more expensive than the contrary cases. This paper proposes a novel method called Embedding Undersampling Rotation Forest (EURF) to handle this problem (1) sampling subsets from the majority class and learning a projection matrix from each subset and (2) obtaining training sets by projecting re-undersampling subsets of the original data set to new spaces defined by the matrices and constructing an individual classifier from each training set. For the first method, undersampling is to force the rotation matrix to better capture the features of the minority class without harming the diversity between individual classifiers. With respect to the second method, the undersampling technique aims to improve the performance of individual classifiers on the minority class. The experimental results show that EURF achieves significantly better performance comparing to other state-of-the-art methods.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {15}
}

@article{10.1016/j.jksuci.2014.03.024,
author = {Vinodhini, G. and Chandrasekaran, R.M.},
title = {A comparative performance evaluation of neural network based approach for sentiment classification of online reviews},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {28},
number = {1},
issn = {1319-1578},
url = {https://doi.org/10.1016/j.jksuci.2014.03.024},
doi = {10.1016/j.jksuci.2014.03.024},
abstract = {The aim of sentiment classification is to efficiently identify the emotions expressed in the form of text messages. Machine learning methods for sentiment classification have been extensively studied, due to their predominant classification performance. Recent studies suggest that ensemble based machine learning methods provide better performance in classification. Artificial neural networks (ANNs) are rarely being investigated in the literature of sentiment classification. This paper compares neural network based sentiment classification methods (back propagation neural network (BPN), probabilistic neural network (PNN) &amp; homogeneous ensemble of PNN (HEN)) using varying levels of word granularity as features for feature level sentiment classification. They are validated using a dataset of product reviews collected from the Amazon reviews website. An empirical analysis is done to compare results of ANN based methods with two statistical individual methods. The methods are evaluated using five different quality measures and results show that the homogeneous ensemble of the neural network method provides better performance. Among the two neural network approaches used, probabilistic neural networks (PNNs) outperform in classifying the sentiment of the product reviews. The integration of neural network based sentiment classification methods with principal component analysis (PCA) as a feature reduction technique provides superior performance in terms of training time also.},
journal = {J. King Saud Univ. Comput. Inf. Sci.},
month = jan,
pages = {2–12},
numpages = {11},
keywords = {Text classification, Support vector machine, Sentiment analysis, Opinion mining, Artificial neural networks}
}

@article{10.1016/j.dss.2015.03.004,
author = {De Cnudde, Sofie and Martens, David},
title = {Loyal to your city? A data mining analysis of a public service loyalty program},
year = {2015},
issue_date = {May 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {73},
number = {C},
issn = {0167-9236},
url = {https://doi.org/10.1016/j.dss.2015.03.004},
doi = {10.1016/j.dss.2015.03.004},
abstract = {Customer loyalty programs are largely present in the private sector and have been elaborately studied. Applications from the private sector have found resonance in a public setting, however, simply extrapolating research results is not acceptable, as their rationale inherently differs. This study focuses on data from a loyalty program issued by the city of Antwerp (Belgium). The aim of the loyalty card entails large citizen participation, however, an active user base of only 20% is reached. Predictive techniques are employed to increase this number. Using spatial behavioral user information, a Naive Bayes classifier and a Support Vector Machine are used which result in models capable of predicting whether a user will actively use its card, whether a user will defect in the near future and which locations a user will visit. Also, a projection of spatial behavioral data onto even more fine-grained spatio-temporal data is performed. The results are promising: the best model achieves an AUC value of 92.5%, 85.5% and 88.12% (averaged over five locations) for the predictions, respectively. Moreover, as behavior is modeled in more detail, better predictions are made. Two main contributions are made in this study. First, as a theoretical contribution, fine-grained behavioral data contributes to a more sound decision-making process. Second, as a practical contribution, the city of Antwerp can now make tailored strategic decisions to increase its active user base. The visiting behavior of users of a government-issued loyalty card is analyzed.The visiting behavior of users is modeled in a spatial and a spatio-temporal fashion.Naive Bayes classifier and Support Vector Machine are trained for predictive models.Using temporal data down to the most fine-grained level leads to better predictions.We report promising results regarding location, loyalty and defect prediction.},
journal = {Decis. Support Syst.},
month = may,
pages = {74–84},
numpages = {11},
keywords = {Loyalty card, Knowledge discovery, Data mining, CRM, Behavioral data}
}

@article{10.1007/s10489-017-1106-x,
author = {Xia, Xin and Lin, Tao and Chen, Zhi},
title = {Maximum relevancy maximum complementary based ordered aggregation for ensemble pruning},
year = {2018},
issue_date = {September 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {48},
number = {9},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-017-1106-x},
doi = {10.1007/s10489-017-1106-x},
abstract = {Ensemble methods have delivered exceptional performance in various applications. However, this exceptional performance is achieved at the expense of heavy storage requirements and slower predictions. Ensemble pruning aims at reducing the complexity of this popular learning paradigm without worsening its performance. This paper presents an efficient and effective ordering-based ensemble pruning methods which ranks all the base classifiers with respect to a maximum relevancy maximum complementary (MRMC) measure. The MRMC measure evaluates the base classifier's classification ability as well as its complementariness to the ensemble, and thereby a set of accurate and complementary base classifiers can be selected. Moreover, an evaluation function that deliberately favors the candidate sub-ensembles with a better performance in classifying low margin instances has also been proposed. Experiments performed on 25 benchmark datasets demonstrate the effectiveness of our proposed method.},
journal = {Applied Intelligence},
month = sep,
pages = {2568–2579},
numpages = {12},
keywords = {Ordering-based ensemble pruning, Mutual information, Margin distribution, Diversity}
}

@article{10.1016/j.csi.2017.02.003,
title = {An empirical analysis of the effectiveness of software metrics and fault prediction model for identifying faulty classes},
year = {2017},
issue_date = {August 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {53},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2017.02.003},
doi = {10.1016/j.csi.2017.02.003},
abstract = {Software fault prediction models are used to predict faulty modules at the very early stage of software development life cycle. Predicting fault proneness using source code metrics is an area that has attracted several researchers' attention. The performance of a model to assess fault proneness depends on the source code metrics which are considered as the input for the model. In this work, we have proposed a framework to validate the source code metrics and identify a suitable set of source code metrics with the aim to reduce irrelevant features and improve the performance of the fault prediction model. Initially, we applied a t-test analysis and univariate logistic regression analysis to each source code metric to evaluate their potential for predicting fault proneness. Next, we performed a correlation analysis and multivariate linear regression stepwise forward selection to find the right set of source code metrics for fault prediction. The obtained set of source code metrics are considered as the input to develop a fault prediction model using a neural network with five different training algorithms and three different ensemble methods. The effectiveness of the developed fault prediction models are evaluated using a proposed cost evaluation framework. We performed experiments on fifty six Open Source Java projects. The experimental results reveal that the model developed by considering the selected set of source code metrics using the suggested source code metrics validation framework as the input achieves better results compared to all other metrics. The experimental results also demonstrate that the fault prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low 48.89%, median- 39.26%, and high 27.86%). HighlightsFault prediction improve the effectiveness of software quality assurance activities.This paper focus on building an effective fault prediction tool.Fault prediction model using ANN and ensemble methods.We perform experiments on 56 Open Source Java projects.Fault prediction model is best suitable for projects with faulty classes less than the threshold value.},
journal = {Comput. Stand. Interfaces},
month = aug,
pages = {1–32},
numpages = {32}
}

@article{10.1016/j.jss.2017.07.006,
author = {Lu, Wei and Li, Zhe and Chu, Jinghui},
title = {Adaptive Ensemble Undersampling-Boost},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {132},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.07.006},
doi = {10.1016/j.jss.2017.07.006},
abstract = {We propose a framework for imbalanced classification tasks with ensemble learning.We propose a weight modification method to give each classifier an adaptive weight.We introduce OTSU algorithm to determine the optimal threshold adaptively.We make comparisons between our proposals and several state-of-the-art algorithms. As one of the most challenging and attractive problems in the pattern recognition and machine intelligence field, imbalanced classification has received a large amount of research attention for many years. In binary classification tasks, one class usually tends to be underrepresented when it consists of far fewer patterns than the other class, which results in undesirable classification results, especially for the minority class. Several techniques, including resampling, boosting and cost-sensitive methods have been proposed to alleviate this problem. Recently, some ensemble methods that focus on combining individual techniques to obtain better performance have been observed to present better classification performance on the minority class. In this paper, we propose a novel ensemble framework called Adaptive Ensemble Undersampling-Boost for imbalanced learning. Our proposal combines the Ensemble of Undersampling (EUS) technique, Real Adaboost, cost-sensitive weight modification, and adaptive boundary decision strategy to build a hybrid algorithm. The superiority of our method over other state-of-the-art ensemble methods is demonstrated by experiments on 18 real world data sets with various data distributions and different imbalance ratios. Given the experimental results and further analysis, our proposal is proven to be a promising alternative that can be applied to various imbalanced classification domains.},
journal = {J. Syst. Softw.},
month = oct,
pages = {272–282},
numpages = {11},
keywords = {Voting algorithm, Real Adaboost, Imbalanced data sets, Ensemble Undersampling, Classification, Adaptive decision boundary, 07.05.Kf}
}

@article{10.1007/s11219-010-9112-9,
author = {Bak\i{}r, Ay\c{s}e and Turhan, Burak and Bener, Ay\c{s}e},
title = {A comparative study for estimating software development effort intervals},
year = {2011},
issue_date = {September 2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-010-9112-9},
doi = {10.1007/s11219-010-9112-9},
abstract = {Software cost/effort estimation is still an open challenge. Many researchers have proposed various methods that usually focus on point estimates. Until today, software cost estimation has been treated as a regression problem. However, in order to prevent overestimates and underestimates, it is more practical to predict the interval of estimations instead of the exact values. In this paper, we propose an approach that converts cost estimation into a classification problem and that classifies new software projects in one of the effort classes, each of which corresponds to an effort interval. Our approach integrates cluster analysis with classification methods. Cluster analysis is used to determine effort intervals while different classification algorithms are used to find corresponding effort classes. The proposed approach is applied to seven public datasets. Our experimental results show that the hit rate obtained for effort estimation are around 90---100%, which is much higher than that obtained by related studies. Furthermore, in terms of point estimation, our results are comparable to those in the literature although a simple mean/median is used for estimation. Finally, the dynamic generation of effort intervals is the most distinctive part of our study, and it results in time and effort gain for project managers through the removal of human intervention.},
journal = {Software Quality Journal},
month = sep,
pages = {537–552},
numpages = {16},
keywords = {Software effort estimation, Machine learning, Interval prediction, Cluster analysis, Classification}
}

@inproceedings{10.1145/2970276.2970339,
author = {Krishna, Rahul and Menzies, Tim and Fu, Wei},
title = {Too much automation? the bellwether effect and its implications for transfer learning},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970339},
doi = {10.1145/2970276.2970339},
abstract = {Transfer learning: is the process of translating quality predictors learned in one data set to another. Transfer learning has been the subject of much recent research. In practice, that research means changing models all the time as transfer learners continually exchange new models to the current project. This paper offers a very simple bellwether transfer learner. Given N data sets, we find which one produce the best predictions on all the others. This bellwether data set is then used for all subsequent predictions (or, until such time as its predictions start failing-- at which point it is wise to seek another bellwether). Bellwethers are interesting since they are very simple to find (just wrap a for-loop around standard data miners). Also, they simplify the task of making general policies in SE since as long as one bellwether remains useful, stable conclusions for N data sets can be achieved just by reasoning over that bellwether. From this, we conclude (1) this bellwether method is a useful (and very simple) transfer learning method; (2) bellwethers are a baseline method against which future transfer learners should be compared; (3) sometimes, when building increasingly complex automatic methods, researchers should pause and compare their supposedly more sophisticated method against simpler alternatives.},
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {122–131},
numpages = {10},
keywords = {Transfer learning, Defect Prediction, Data Mining},
location = {Singapore, Singapore},
series = {ASE '16}
}

@article{10.1155/2021/9948808,
author = {Li, Chao and Li, Jun and Li, Yafei and He, Lingmin and Fu, Xiaokang and Chen, Jingjing and Zhou, Xiaokang},
title = {Fabric Defect Detection in Textile Manufacturing: A Survey of the State of the Art},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/9948808},
doi = {10.1155/2021/9948808},
abstract = {Defects in the textile manufacturing process lead to a great waste of resources and further affect the quality of textile products. Automated quality guarantee of textile fabric materials is one of the most important and demanding computer vision tasks in textile smart manufacturing. This survey presents a thorough overview of algorithms for fabric defect detection. First, this review briefly introduces the importance and inevitability of fabric defect detection towards the era of manufacturing of artificial intelligence. Second, defect detection methods are categorized into traditional algorithms and learning-based algorithms, and traditional algorithms are further categorized into statistical, structural, spectral, and model-based algorithms. The learning-based algorithms are further divided into conventional machine learning algorithms and deep learning algorithms which are very popular recently. A systematic literature review on these methods is present. Thirdly, the deployments of fabric defect detection algorithms are discussed in this study. This paper provides a reference for researchers and engineers on fabric defect detection in textile manufacturing.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {13}
}

@inproceedings{10.1109/ITSC.2019.8917119,
author = {Batsch, Felix and Daneshkhah, Alireza and Cheah, Madeline and Kanarachos, Stratis and Baxendale, Anthony},
title = {Performance Boundary Identification for the Evaluation of Automated Vehicles using Gaussian Process Classification},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC.2019.8917119},
doi = {10.1109/ITSC.2019.8917119},
abstract = {Safety is an essential aspect in the facilitation of automated vehicle deployment. Current testing practices are not enough, and going beyond them leads to infeasible testing requirements, such as needing to drive billions of kilometres on public roads. Automated vehicles are exposed to an indefinite number of scenarios. Handling of the most challenging scenarios should be tested, which leads to the question of how such corner cases can be determined. We propose an approach to identify the performance boundary, where these corner cases are located, using Gaussian Process Classification. We also demonstrate the classification on an exemplary traffic jam approach scenario, showing that it is feasible and would lead to more efficient testing practices.},
booktitle = {2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
pages = {419–424},
numpages = {6},
location = {Auckland, New Zealand}
}

@article{10.1007/s00500-020-05297-6,
author = {Wickramasinghe, Indika and Kalutarage, Harsha},
title = {Naive Bayes: applications, variations and vulnerabilities: a review of literature with code snippets for implementation},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {3},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05297-6},
doi = {10.1007/s00500-020-05297-6},
abstract = {Na\"{\i}ve Bayes (NB) is a well-known probabilistic classification algorithm. It is a simple but efficient algorithm with a wide variety of real-world applications, ranging from product recommendations through medical diagnosis to controlling autonomous vehicles. Due to the failure of real data satisfying the assumptions of NB, there are available variations of NB to cater general data. With the unique applications for each variation of NB, they reach different levels of accuracy. This manuscript surveys the latest applications of NB and discusses its variations in different settings. Furthermore, recommendations are made regarding the applicability of NB while exploring the robustness of the algorithm. Finally, an attempt is given to discuss the pros and cons of NB algorithm and some vulnerabilities, with related computing code for implementation.},
journal = {Soft Comput.},
month = feb,
pages = {2277–2293},
numpages = {17},
keywords = {R code snippets, Machine learning vulnerabilities, Probabilistic classification, Na\"{\i}ve Bayes}
}

@inproceedings{10.1007/978-3-030-22744-9_20,
author = {Chora\'{s}, Micha\l{} and Pawlicki, Marek and Kozik, Rafa\l{}},
title = {Recognizing Faults in Software Related Difficult Data},
year = {2019},
isbn = {978-3-030-22743-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-22744-9_20},
doi = {10.1007/978-3-030-22744-9_20},
abstract = {In this paper we have investigated the use of numerous machine learning algorithms, with emphasis on multilayer artificial neural networks in the domain of software source code fault prediction. The main contribution lies in enhancing the data pre-processing step as the partial solution for handling software related difficult data. Before we put the data into an Artificial Neural Network, we are implementing PCA (Principal Component Analysis) and k-means clustering. The data-clustering step improves the quality of the whole dataset. Using the presented approach we were able to obtain 10% increase of accuracy of the fault detection. In order to ensure the most reliable results, we implement 10-fold cross-validation methodology during experiments. We have also evaluated a wide range of hyperparameter setups for the network, and compared the results to the state of the art, cost-sensitive approaches - Random Forest, AdaBoost, RepTrees and GBT.},
booktitle = {Computational Science – ICCS 2019: 19th International Conference, Faro, Portugal, June 12–14, 2019, Proceedings, Part III},
pages = {263–272},
numpages = {10},
keywords = {Data clustering, ANN, Faults detection, Pattern recognition},
location = {Faro, Portugal}
}

@article{10.1016/j.eswa.2016.05.018,
author = {Arar, \"{O}mer Faruk and Ayan, K\"{u}r\c{s}at},
title = {Deriving thresholds of software metrics to predict faults on open source software},
year = {2016},
issue_date = {November 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {61},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.05.018},
doi = {10.1016/j.eswa.2016.05.018},
abstract = {We empirically examined if there are effective thresholds for software metrics.Open-source software systems were used as benchmarking datasets.The learner model was created using logistic regression and the Bender method.Experimental results revealed that some metrics have effective threshold values. Object-oriented metrics aim to exhibit the quality of source code and give insight to it quantitatively. Each metric assesses the code from a different aspect. There is a relationship between the quality level and the risk level of source code. The objective of this paper is to empirically examine whether or not there are effective threshold values for source code metrics. It is targeted to derive generalized thresholds that can be used in different software systems. The relationship between metric thresholds and fault-proneness was investigated empirically in this study by using ten open-source software systems. Three types of fault-proneness were defined for the software modules: non-fault-prone, more-than-one-fault-prone, and more-than-three-fault-prone. Two independent case studies were carried out to derive two different threshold values. A single set was created by merging ten datasets and was used as training data by the model. The learner model was created using logistic regression and the Bender method. Results revealed that some metrics have threshold effects. Seven metrics gave satisfactory results in the first case study. In the second case study, eleven metrics gave satisfactory results. This study makes contributions primarily for use by software developers and testers. Software developers can see classes or modules that require revising; this, consequently, contributes to an increment in quality for these modules and a decrement in their risk level. Testers can identify modules that need more testing effort and can prioritize modules according to their risk levels.},
journal = {Expert Syst. Appl.},
month = nov,
pages = {106–121},
numpages = {16},
keywords = {Threshold, Software quality metrics, Software fault prediction, Machine learning, Logistic regression, Bender method}
}

@inproceedings{10.5555/3507788.3507804,
author = {Ria and Grigoriou, Marios-Stavros and Kontogiannis, Kostas and Giammaria, Alberto and Brealey, Chris},
title = {Process-metrics trends analysis for evaluating file-level error proneness},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {Assessing the likelihood of a source code file being buggy or healthy in upcoming commits given its past behavior and its interaction with other files, has been an area where the software engineering community has paid significant attention over the years. Early efforts aimed on associating software metrics with maintainability indexes, while more recent efforts focused on the use of machine learning for classifying a software module as error prone or not. In most approaches to date, this analysis is primarily based on source code metrics or on information extracted from the system's source code, and to a lesser extend on information that relates to process metrics. In this paper, we propose a process-metrics based method for predicting the behavior of a file, based both on its GitHub commits and its interdependences with other co-committed files. More specifically, for each file and for each commit a file participates in, we compute a dependency score this file has with its other co-committed files. This score is appropriately amplified if the file is participating in a bug-fixing commit, or decayed over time if it does not. By examining, over several open source systems, the trend of that dependency score for every file as a product of time, for files whose outcome is known and that are used as gold standard, we report statistics which shed light on estimating the likelihood of whether these trends can predict the future behavior of a file or not.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {113–122},
numpages = {10},
location = {Toronto, Canada},
series = {CASCON '21}
}

@article{10.1002/smr.2158,
author = {Grano, Giovanni and Titov, Timofey V. and Panichella, Sebastiano and Gall, Harald C.},
title = {Branch coverage prediction in automated testing},
year = {2019},
issue_date = {September 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {9},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2158},
doi = {10.1002/smr.2158},
abstract = {Software testing is crucial in continuous integration (CI). Ideally, at every commit, all the test cases should be executed, and moreover, new test cases should be generated for the new source code. This is especially true in a Continuous Test Generation (CTG) environment, where the automatic generation of test cases is integrated into the continuous integration pipeline. In this context, developers want to achieve a certain minimum level of coverage for every software build. However, executing all the test cases and, moreover, generating new ones for all the classes at every commit is not feasible. As a consequence, developers have to select which subset of classes has to be tested and/or targeted by test‐case generation. We argue that knowing a priori the branch coverage that can be achieved with test‐data generation tools can help developers into taking informed decision about those issues. In this paper, we investigate the possibility to use source‐code metrics to predict the coverage achieved by test‐data generation tools. We use four different categories of source‐code features and assess the prediction on a large data set involving more than 3'000 Java classes. We compare different machine learning algorithms and conduct a fine‐grained feature analysis aimed at investigating the factors that most impact the prediction accuracy. Moreover, we extend our investigation to four different search budgets. Our evaluation shows that the best model achieves an average 0.15 and 0.21 MAE on nested cross‐validation over the different budgets, respectively, on evosuite and randoop. Finally, the discussion of the results demonstrate the relevance of coupling‐related features for the prediction accuracy.In this paper, we predict the coverage achieved by test‐data generator tools using source‐code metrics. We build a Random Forest Regressor model with an average MAE of 0.2. This results substantially improve the performance of the state‐of‐art predictor.


image
image},
journal = {J. Softw. Evol. Process},
month = oct,
numpages = {18},
keywords = {software testing, machine learning, coverage prediction, automated software testing}
}

@inproceedings{10.5555/1193212.1193789,
author = {Mertik, Matej and Lenic, Mitja and Stiglic, Gregor and Kokol, Peter},
title = {Estimating Software Quality with Advanced Data Mining Techniques},
year = {2006},
isbn = {0769527035},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Current software quality estimation models often involve the use of supervised learning methods for building a software fault prediction models. In such models, dependent variable usually represents a software quality measurement indicating the quality of a module by risk-basked class membership, or the number of faults. Independent variables include various software metrics as McCabe, Error Count, Halstead, Line of Code, etc... In this paper we present the use of advanced tool for data mining called Multimethod on the case of building software fault prediction model. Multimethod combines different aspects of supervised learning methods in dynamical environment and therefore can improve accuracy of generated prediction model. We demonstrate the use Multimethod tool on the real data from the Metrics Data Project Data (MDP) Repository. Our preliminary empirical results show promising potentials of this approach in predicting software quality in a software measurement and quality dataset.},
booktitle = {Proceedings of the International Conference on Software Engineering Advances},
pages = {19},
keywords = {Supervised learning, Software quality, Software fault prediction models, Multimethod data mining},
series = {ICSEA '06}
}

@inproceedings{10.1109/ICMLA.2011.133,
author = {Wang, Huanjing and Khoshgoftaaar, Taghi M. and Liang, Qianhui (Althea)},
title = {Stability and Classification Performance of Feature Selection Techniques},
year = {2011},
isbn = {9780769546070},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2011.133},
doi = {10.1109/ICMLA.2011.133},
abstract = {Feature selection techniques can be evaluated based on either model performance or the stability (robustness) of the technique. The ideal situation is to choose a feature selection technique that is robust to change, while also ensuring that models built with the selected features perform well. One domain where feature selection is especially important is software defect prediction, where large numbers of metrics collected from previous software projects are used to help engineers focus their efforts on the most faulty modules. This study presents a comprehensive empirical examination of seven filter-based feature ranking techniques (rankers) applied to nine real-world software measurement datasets of different sizes. Experimental results demonstrate that signal-to-noise ranker performed moderately in terms of robustness and was the best ranker in terms of model performance. The study also shows that although Relief was the most stable feature selection technique, it performed significantly worse than other rankers in terms of model performance.},
booktitle = {Proceedings of the 2011 10th International Conference on Machine Learning and Applications  and  Workshops - Volume 01},
pages = {151–156},
numpages = {6},
keywords = {stability, feature ranking, classification},
series = {ICMLA '11}
}

@article{10.4018/IJSI.2021070105,
author = {Jo, Jun-Hyuk and Lee, Jihyun and Jaffari, Aman and Kim, Eunmi},
title = {Fault Localization With Data Flow Information and an Artificial Neural Network},
year = {2021},
issue_date = {Jul 2021},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {3},
issn = {2166-7160},
url = {https://doi.org/10.4018/IJSI.2021070105},
doi = {10.4018/IJSI.2021070105},
abstract = {Fault localization is a technique for identifying the exact source code line with faults. It typically requires a lot of time and cost because, to locate the fault, a developer must track the execution of the failed program line by line. To reduce the fault localization efforts, many methods have been proposed. However, their localized suspicious code range is wide, and their fault localization effect is not high. To cope with this limitation, this paper computes the degree of fault suspiciousness of statements by using an artificial neural network and information of the executed test case, such as statement coverage, execution result, and definition-use pair. Compared to the approach that uses only statement coverage as input data for training an artificial neural network, the experiment results show higher accuracy in 15 types of faults out of 29 real fault types in the approach that the definition-use pair included.},
journal = {Int. J. Softw. Innov.},
month = jul,
pages = {66–78},
numpages = {13},
keywords = {Software Verification, Software Testing, Fault Suspiciousness, Fault Localization, Du-Pair, Definition-Use, Data Flow Coverage, Artificial Neural Network}
}

@inproceedings{10.1007/978-3-030-76352-7_27,
author = {Lyu, Michael R. and Su, Yuxin},
title = {Software Reliability Engineering for Resilient Cloud Operations},
year = {2020},
isbn = {978-3-030-76351-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-76352-7_27},
doi = {10.1007/978-3-030-76352-7_27},
abstract = {In the last decade, cloud environments become the most sophisticated software systems. Due to the inevitable occurrences of failures, software reliability engineering is top priority for cloud developers and maintainers. In this essay, we introduce several frameworks to provide resilient cloud operations from different development phases, ranging from fault prevention before deployment and fault removal at run-time.},
booktitle = {Service-Oriented Computing  – ICSOC 2020 Workshops: AIOps, CFTIC, STRAPS, AI-PA, AI-IOTS, and Satellite Events, Dubai, United Arab Emirates, December 14–17, 2020, Proceedings},
pages = {264–268},
numpages = {5},
keywords = {Fault removal, Fault prevention, Resilient cloud operation, Software reliability engineering},
location = {Dubai, United Arab Emirates}
}

@article{10.1007/s11390-019-1960-6,
author = {Alqmase, Mohammed and Alshayeb, Mohammad and Ghouti, Lahouari},
title = {Threshold Extraction Framework for Software Metrics},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {5},
issn = {1000-9000},
url = {https://doi.org/10.1007/s11390-019-1960-6},
doi = {10.1007/s11390-019-1960-6},
abstract = {Software metrics are used to measure different attributes of software. To practically measure software attributes using these metrics, metric thresholds are needed. Many researchers attempted to identify these thresholds based on personal experiences. However, the resulted experience-based thresholds cannot be generalized due to the variability in personal experiences and the subjectivity of opinions. The goal of this paper is to propose an automated clustering framework based on the expectation maximization (EM) algorithm where clusters are generated using a simplified 3-metric set (LOC, LCOM, and CBO). Given these clusters, different threshold levels for software metrics are systematically determined such that each threshold reflects a specific level of software quality. The proposed framework comprises two major steps: the clustering step where the software quality historical dataset is decomposed into a fixed set of clusters using the EM algorithm, and the threshold extraction step where thresholds, specific to each software metric in the resulting clusters, are estimated using statistical measures such as the mean (μ) and the standard deviation (σ) of each software metric in each cluster. The paper’s findings highlight the capability of EM-based clustering, using a minimum metric set, to group software quality datasets according to different quality levels.},
journal = {J. Comput. Sci. Technol.},
month = sep,
pages = {1063–1078},
numpages = {16},
keywords = {empirical study, expectation maximization, metric threshold}
}

@inproceedings{10.1007/978-3-540-69566-0_21,
author = {Catal, Cagatay and Diri, Banu},
title = {A Fault Prediction Model with Limited Fault Data to Improve Test Process},
year = {2008},
isbn = {9783540695646},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-69566-0_21},
doi = {10.1007/978-3-540-69566-0_21},
abstract = {Software fault prediction models are used to identify the fault-prone software modules and produce reliable software. Performance of a software fault prediction model is correlated with available software metrics and fault data. In some occasions, there may be few software modules having fault data and therefore, prediction models using only labeled data can not provide accurate results. Semi-supervised learning approaches which benefit from unlabeled and labeled data may be applied in this case. In this paper, we propose an artificial immune system based semi-supervised learning approach. Proposed approach uses a recent semi-supervised algorithm called YATSI (Yet Another Two Stage Idea) and in the first stage of YATSI, AIRS (Artificial Immune Recognition Systems) is applied. In addition, AIRS, RF (Random Forests) classifier, AIRS based YATSI, and RF based YATSI are benchmarked. Experimental results showed that while YATSI algorithm improved the performance of AIRS, it diminished the performance of RF for unbalanced datasets. Furthermore, performance of AIRS based YATSI is comparable with RF which is the best machine learning classifier according to some researches.},
booktitle = {Proceedings of the 9th International Conference on Product-Focused Software Process Improvement},
pages = {244–257},
numpages = {14},
keywords = {software fault prediction, artificial immune systems, YATSI, Semi-supervised learning, AIRS},
location = {Monte Porzio Catone, Italy},
series = {PROFES '08}
}

@article{10.1007/s10515-021-00287-w,
author = {Gadelha, Guilherme and Ramalho, Franklin and Massoni, Tiago},
title = {Traceability recovery between bug reports and test cases-a Mozilla Firefox case study},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-021-00287-w},
doi = {10.1007/s10515-021-00287-w},
abstract = {Automatic recovery of traceability between software artifacts may promote early detection of issues and better calculate change impact. Information Retrieval (IR) techniques have been proposed for the task, but they differ considerably in input parameters and results. It is difficult to assess results when those techniques are applied in isolation, usually in small or medium-sized software projects. Recently, multilayered approaches to machine learning, in special Deep Learning (DL), have achieved success in text classification through their capacity to model complex relationships among data. In this article, we apply several IR and DL techniques for investing automatic traceability between bug reports and manual test cases, using historical data from the Mozilla Firefox’s Quality Assurance (QA) team. In this case study, we assess the following IR techniques: LSI, LDA, and BM25, in addition to a DL architecture called Convolutional Neural Networks (CNNs), through the use of Word Embeddings. In this context of traceability, we observe poor performances from three out of the four studied techniques. Only the LSI technique presented acceptable results, standing out even over the state-of-the-art BM25 technique. The obtained results suggest that the semi-automatic application of the LSI technique – with an appropriate combination of thresholds – may be feasible for real-world software projects.},
journal = {Automated Software Engg.},
month = nov,
numpages = {46},
keywords = {Deep learning, Information retrieval, Traceability, Test cases, System features, Bug reports}
}

@inproceedings{10.1145/3338906.3338941,
author = {Jimenez, Matthieu and Rwemalika, Renaud and Papadakis, Mike and Sarro, Federica and Le Traon, Yves and Harman, Mark},
title = {The importance of accounting for real-world labelling when predicting software vulnerabilities},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338941},
doi = {10.1145/3338906.3338941},
abstract = {Previous work on vulnerability prediction assume that predictive models are trained with respect to perfect labelling information (includes labels from future, as yet undiscovered vulnerabilities). In this paper we present results from a comprehensive empirical study of 1,898 real-world vulnerabilities reported in 74 releases of three security-critical open source systems (Linux Kernel, OpenSSL and Wiresark). Our study investigates the effectiveness of three previously proposed vulnerability prediction approaches, in two settings: with and without the unrealistic labelling assumption. The results reveal that the unrealistic labelling assumption can profoundly mis- lead the scientific conclusions drawn; suggesting highly effective and deployable prediction results vanish when we fully account for realistically available labelling in the experimental methodology. More precisely, MCC mean values of predictive effectiveness drop from 0.77, 0.65 and 0.43 to 0.08, 0.22, 0.10 for Linux Kernel, OpenSSL and Wiresark, respectively. Similar results are also obtained for precision, recall and other assessments of predictive efficacy. The community therefore needs to upgrade experimental and empirical methodology for vulnerability prediction evaluation and development to ensure robust and actionable scientific findings.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {695–705},
numpages = {11},
keywords = {Software Vulnerabilities, Prediction Modelling, Machine Learning},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1016/j.compeleceng.2019.02.022,
author = {McKinnel, Dean Richard and Dargahi, Tooska and Dehghantanha, Ali and Choo, Kim-Kwang Raymond},
title = {A systematic literature review and meta-analysis on artificial intelligence in penetration testing and vulnerability assessment},
year = {2019},
issue_date = {May 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {75},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.02.022},
doi = {10.1016/j.compeleceng.2019.02.022},
journal = {Comput. Electr. Eng.},
month = may,
pages = {175–188},
numpages = {14},
keywords = {Meta-analysis, Machine learning, Systematic literature review, Artificial intelligence, Vulnerability assessment, Penetration testing}
}

@inproceedings{10.1145/3127005.3127007,
author = {Minku, Leandro L. and Hou, Siqing},
title = {Clustering Dycom: An Online Cross-Company Software Effort Estimation Study},
year = {2017},
isbn = {9781450353052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127005.3127007},
doi = {10.1145/3127005.3127007},
abstract = {Background: Software Effort Estimation (SEE) can be formulated as an online learning problem, where new projects are completed over time and may become available for training. In this scenario, a Cross-Company (CC) SEE approach called Dycom can drastically reduce the number of Within-Company (WC) projects needed for training, saving the high cost of collecting such training projects. However, Dycom relies on splitting CC projects into different subsets in order to create its CC models. Such splitting can have a significant impact on Dycom's predictive performance. Aims: This paper investigates whether clustering methods can be used to help finding good CC splits for Dycom. Method: Dycom is extended to use clustering methods for creating the CC subsets. Three different clustering methods are investigated, namely Hierarchical Clustering, K-Means, and Expectation-Maximisation. Clustering Dycom is compared against the original Dycom with CC subsets of different sizes, based on four SEE databases. A baseline WC model is also included in the analysis. Results: Clustering Dycom with K-Means can potentially help to split the CC projects, managing to achieve similar or better predictive performance than Dycom. However, K-Means still requires the number of CC subsets to be pre-defined, and a poor choice can negatively affect predictive performance. EM enables Dycom to automatically set the number of CC subsets while still maintaining or improving predictive performance with respect to the baseline WC model. Clustering Dycom with Hierarchical Clustering did not offer significant advantage in terms of predictive performance. Conclusion: Clustering methods can be an effective way to automatically generate Dycom's CC subsets.},
booktitle = {Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {12–21},
numpages = {10},
keywords = {Software effort estimation, concept drift, cross-company learning, ensembles, online learning},
location = {Toronto, Canada},
series = {PROMISE}
}

@inproceedings{10.1007/978-3-030-96600-3_13,
author = {B\u{a}dic\u{a}, Amelia and B\u{a}dic\u{a}, Costin and Bolanowski, Marek and Fidanova, Stefka and Ganzha, Maria and Harizanov, Stanislav and Ivanovic, Mirjana and Lirkov, Ivan and Paprzycki, Marcin and Paszkiewicz, Andrzej and Tomczyk, Kacper},
title = {Cascaded Anomaly Detection with Coarse Sampling in Distributed Systems},
year = {2021},
isbn = {978-3-030-96599-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-96600-3_13},
doi = {10.1007/978-3-030-96600-3_13},
abstract = {In this contribution, analysis of usefulness of selected parameters of a distributed information system, for early detection of anomalies in its operation, is considered. Use of statistical analysis, or machine learning (ML), can result in high computational complexity and requirement to transfer large amount of data from the monitored system’s elements. This enforces monitoring of only major components (e.g., access link, key machine components, filtering of selected traffic parameters). To overcome this limitation, a model in which an arbitrary number of elements could be monitored, using microservices, is proposed. For this purpose, it is necessary to determine the sampling threshold value and the influence of sampling coarseness on the quality of anomaly detection. To validate the proposed approach, the ST4000DM000 (Disk failure) and CICIDS2017 (DDoS) datasets were used, to study effects of limiting the number of parameters and the sampling rate reduction on the detection performance of selected classic ML algorithms. Moreover, an example of microservice architecture for coarse network anomaly detection for a network node is presented.},
booktitle = {Big-Data-Analytics in Astronomy, Science, and Engineering: 9th International Conference on Big Data Analytics, BDA 2021, Virtual Event, December 7–9, 2021, Proceedings},
pages = {181–200},
numpages = {20},
keywords = {Computer network management, Complex distributed system, Anomaly prediction, Anomaly detection}
}

@inproceedings{10.1145/3345629.3345635,
author = {Wang, Song and Bansal, Chetan and Nagappan, Nachiappan and Philip, Adithya Abraham},
title = {Leveraging Change Intents for Characterizing and Identifying Large-Review-Effort Changes},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345635},
doi = {10.1145/3345629.3345635},
abstract = {Code changes to software occur due to various reasons such as bug fixing, new feature addition, and code refactoring. In most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis.In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (LRE) changes regarding review effort---changes with large review effort. Specifically, we first propose a feedback-driven and heuristics-based approach to obtain change intents. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying LRE changes. We conduct our study on a large-scale project from Microsoft and three large-scale open source projects, i.e., Qt, Android, and OpenStack. Our results show that, (i) code changes with some intents are more likely to be LRE changes, (ii) machine learning based prediction models can efficiently help identify LRE changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average. The tool developed in this study has already been used in Microsoft to provide the review effort and intent information of changes for reviewers to accelerate the review process.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {46–55},
numpages = {10},
keywords = {Code review, change intent, machine learning, review effort},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1145/3395363.3397355,
author = {Liu, Hui and Shen, Mingzhu and Jin, Jiahao and Jiang, Yanjie},
title = {Automated classification of actions in bug reports of mobile apps},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3397355},
doi = {10.1145/3395363.3397355},
abstract = {When users encounter problems with mobile apps, they may commit such problems to developers as bug reports. To facilitate the processing of bug reports, researchers proposed approaches to validate the reported issues automatically according to the steps to reproduce specified in bug reports. Although such approaches have achieved high success rate in reproducing the reported issues, they often rely on a predefined vocabulary to identify and classify actions in bug reports. However, such manually constructed vocabulary and classification have significant limitations. It is challenging for the vocabulary to cover all potential action words because users may describe the same action with different words. Besides that, classification of actions solely based on the action words could be inaccurate because the same action word, appearing in different contexts, may have different meaning and thus belongs to different action categories. To this end, in this paper we propose an automated approach, called MaCa, to identify and classify action words in Mobile apps’ bug reports. For a given bug report, it first identifies action words based on natural language processing. For each of the resulting action words, MaCa extracts its contexts, i.e., its enclosing segment, the associated UI target, and the type of its target element by both natural language processing and static analysis of the associated app. The action word and its contexts are then fed into a machine learning based classifier that predicts the category of the given action word in the given context. To train the classifier, we manually labelled 1,202 actions words from 525 bug reports that are associated with 207 apps. Our evaluation results on manually labelled data suggested that MaCa was accurate with high accuracy varying from 95% to 96.7%. We also investigated to what extent MaCa could further improve existing approaches (i.e., Yakusu and ReCDroid) in reproducing bug reports. Our evaluation results suggested that integrating MaCa into existing approaches significantly improved the success rates of ReCDroid and Yakusu by 22.7% = (69.2%-56.4%)/56.4% and 22.9%= (62.7%-51%)/51%, respectively.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {128–140},
numpages = {13},
keywords = {Test Case Generation, Mobile Testing, Classification, Bug report},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@inproceedings{10.1145/3361242.3361261,
author = {Zhu, Jing and Rong, Guoping and Huang, Guocheng and Gu, Shenghui and Zhang, He and Shao, Dong},
title = {JLLAR: A Logging Recommendation Plug-in Tool for Java},
year = {2019},
isbn = {9781450377010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361242.3361261},
doi = {10.1145/3361242.3361261},
abstract = {Logs are the execution results of logging statements in software systems after being triggered by various events, which is able to capture the dynamic behavior of software systems during runtime and provide important information for software analysis, e.g., issue tracking, performance monitoring, etc. Obviously, to meet this purpose, the quality of the logs is critical, which requires appropriately placement of logging statements. Existing research on this topic reveals that where to log? and what to log? are two most concerns when conducting logging practice in software development, which mainly relies on developers' personal skills, expertise and preference, rendering several problems impacting the quality of the logs inevitably. One of the reasons leading to this phenomenon might be that several recognized best practices(strategies as well) are easily neglected by software developers. Especially in those software projects with relatively large number of participants. To address this issue, we designed and implemented a plug-in tool (i.e., JLLAR) based on the Intellij IDEA, which applied machine learning technology to identify and create a set of rules reflecting commonly recognized logging practices. Based on this rule set, JLLAR can be used to scan existing source code to identify issues regarding the placement of logging statements. Moreover, JLLAR also provides automatic code completion and semi code completion (i.e., to provide recommendations) regarding logging practice to support software developers during coding.},
booktitle = {Proceedings of the 11th Asia-Pacific Symposium on Internetware},
articleno = {16},
numpages = {6},
keywords = {tool, machine learning, logging practice},
location = {Fukuoka, Japan},
series = {Internetware '19}
}

@article{10.1007/s11219-011-9132-0,
author = {Gao, Kehan and Khoshgoftaar, Taghi M. and Seliya, Naeem},
title = {Predicting high-risk program modules by selecting the right software measurements},
year = {2012},
issue_date = {March     2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-011-9132-0},
doi = {10.1007/s11219-011-9132-0},
abstract = {A timely detection of high-risk program modules in high-assurance software is critical for avoiding the high consequences of operational failures. While software risk can initiate from external sources, such as management or outsourcing, software quality is adversely affected when internal software risks are realized, such as improper practice of standard software processes or lack of a defined software quality infrastructure. Practitioners employ various techniques to identify and rectify high-risk or low-quality program modules. Effectiveness of detecting such modules is affected by the software measurements used, making feature selection an important step during software quality prediction. We use a wrapper-based feature ranking technique to select the optimal set of software metrics to build defect prediction models. We also address the adverse effects of class imbalance (very few low-quality modules compared to high-quality modules), a practical problem observed in high-assurance systems. Applying a data sampling technique followed by feature selection is a relatively unique contribution of our work. We present a comprehensive investigation on the impact of data sampling followed by attribute selection on the defect predictors built with imbalanced data. The case study data are obtained from several real-world high-assurance software projects. The key results are that attribute selection is more efficient when applied after data sampling, and defect prediction performance generally improves after applying data sampling and feature selection.},
journal = {Software Quality Journal},
month = mar,
pages = {3–42},
numpages = {40},
keywords = {Wrapper-based feature ranking, Software quality classification, Performance metrics, Imbalanced data, Feature selection, Data sampling}
}

@article{10.1016/j.jss.2019.01.056,
author = {Liu, Yong and Li, Meiying and Wu, Yonghao and Li, Zheng},
title = {A weighted fuzzy classification approach to identify and manipulate coincidental correct test cases for fault localization},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {151},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.01.056},
doi = {10.1016/j.jss.2019.01.056},
journal = {J. Syst. Softw.},
month = may,
pages = {20–37},
numpages = {18},
keywords = {K-Nearest Neighbor, Fuzzy classification, Coincidental correct test cases, Coverage-Based fault localization, Software debugging}
}

@article{10.1016/j.neucom.2018.04.088,
author = {de Morais, Romero F.A.B. and Vasconcelos, Germano C.},
title = {Boosting the performance of over-sampling algorithms through under-sampling the minority class},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {343},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.04.088},
doi = {10.1016/j.neucom.2018.04.088},
journal = {Neurocomput.},
month = may,
pages = {3–18},
numpages = {16},
keywords = {Noisy data, Under-sampling, Over-sampling, Imbalanced learning}
}

@article{10.1007/s10664-019-09686-w,
author = {Minku, Leandro L.},
title = {A novel online supervised hyperparameter tuning procedure applied to cross-company software effort estimation},
year = {2019},
issue_date = {Oct 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09686-w},
doi = {10.1007/s10664-019-09686-w},
abstract = {Software effort estimation is an online supervised learning problem, where new training projects may become available over time. In this scenario, the Cross-Company (CC) approach Dycom can drastically reduce the number of Within-Company (WC) projects needed for training, saving their collection cost. However, Dycom requires CC projects to be split into subsets. Both the number and composition of such subsets can affect Dycom’s predictive performance. Even though clustering methods could be used to automatically create CC subsets, there are no procedures for automatically tuning the number of clusters over time in online supervised scenarios. This paper proposes the first procedure for that. An investigation of Dycom using six clustering methods and three automated tuning procedures is performed, to check whether clustering with automated tuning can create well performing CC splits. A case study with the ISBSG Repository shows that the proposed tuning procedure in combination with a simple threshold-based clustering method is the most successful in enabling Dycom to drastically reduce (by a factor of 10) the number of required WC training projects, while maintaining (or even improving) predictive performance in comparison with a corresponding WC model. A detailed analysis is provided to understand the conditions under which this approach does or does not work well. Overall, the proposed online supervised tuning procedure was generally successful in enabling a very simple threshold-based clustering approach to obtain the most competitive Dycom results. This demonstrates the value of automatically tuning hyperparameters over time in a supervised way.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {3153–3204},
numpages = {52},
keywords = {Hyperparameter tuning, Online learning, Concept drift, Transfer learning, Cross-company learning, Software effort estimation}
}

@article{10.1016/j.asoc.2017.03.016,
author = {Zhang, Zhong-Liang and Luo, Xing-Gang and Garca, Salvador and Herrera, Francisco},
title = {Cost-Sensitive back-propagation neural networks with binarization techniques in addressing multi-class problems and non-competent classifiers},
year = {2017},
issue_date = {July 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {56},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.03.016},
doi = {10.1016/j.asoc.2017.03.016},
abstract = {A novel method based on cost-sensitive neural networks with binarization techniques for multi-class problems is developed.The effect of aggregation methods for the proposed method is studied.The positive synergy between the management of non-competent classifiers and the proposed method is found.The effectiveness of our method tested on three different kinds of cost matrices is investigated.In this study, 25 real-world applications, from KEEL dataset repository, are selected for the experimental study. Multi-class classification problems can be addressed by using decomposition strategy. One of the most popular decomposition techniques is the One-vs-One (OVO) strategy, which consists of dividing multi-class classification problems into as many as possible pairs of easier-to-solve binary sub-problems. To discuss the presence of classes with different cost, in this paper, we examine the behavior of an ensemble of Cost-Sensitive Back-Propagation Neural Networks (CSBPNN) with OVO binarization techniques for multi-class problems. To implement this, the original multi-class cost-sensitive problem is decomposed into as many sub-problems as possible pairs of classes and each sub-problem is learnt in an independent manner using CSBPNN. Then a combination method is used to aggregate the binary cost-sensitive classifiers. To verify the synergy of the binarization technique and CSBPNN for multi-class cost-sensitive problems, we carry out a thorough experimental study. Specifically, we first develop the study to check the effectiveness of the OVO strategy for multi-class cost-sensitive learning problems. Then, we develop a comparison of several well-known aggregation strategies in our scenario. Finally, we explore whether further improvement can be achieved by using the management of non-competent classifiers. The experimental study is performed with three types of cost matrices and proper statistical analysis is employed to extract the meaningful findings.},
journal = {Appl. Soft Comput.},
month = jul,
pages = {357–367},
numpages = {11},
keywords = {One-vs-one, Neural networks, Dynamic classifier selection, Cost-sensitive learning, Aggregation strategies}
}

@article{10.1155/2020/8853971,
author = {Liu, Chunbo and Ren, Yitong and Liang, Mengmeng and Gu, Zhaojun and Wang, Jialiang and Pan, Lanlan and Wang, Zhi and Meng, Weizhi},
title = {Detecting Overlapping Data in System Logs Based on Ensemble Learning Method},
year = {2020},
issue_date = {2020},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2020},
issn = {1530-8669},
url = {https://doi.org/10.1155/2020/8853971},
doi = {10.1155/2020/8853971},
abstract = {Machine learning techniques are essential for system log anomaly detection. It is prone to the phenomenon of class overlap because of too many similar system log data. The occurrence of this phenomenon will have a serious impact on the anomaly detection of the system logs. To solve the problem of class overlap in system logs, this paper proposes an anomaly detection model for class overlap problem on system logs. We first calculate the relationship between the sample data and the membership of different classes, normal or anomaly, and use the fuzziness to separate the sample data of the overlapping parts of the classes from the data of the other parts. AdaBoost, an ensemble learning approach, is used to detect overlapping data. Compared with machine learning algorithms, ensemble learning can better classify the data of the overlapping parts, so as to achieve the purpose of detecting the anomalies of the system logs. We also discussed the possible impact of different voting methods on ensemble learning results. Experimental results show that our model can be effectively applied in a variety of basic algorithms, and the results of each measure have been improved.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {8}
}

@inproceedings{10.1145/3387904.3389252,
author = {Wu, Liwei and Li, Fei and Wu, Youhua and Zheng, Tao},
title = {GGF: A Graph-based Method for Programming Language Syntax Error Correction},
year = {2020},
isbn = {9781450379588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387904.3389252},
doi = {10.1145/3387904.3389252},
abstract = {Syntax errors combined with obscure error messages generated by compilers usually annoy programmers and cause them to waste a lot of time on locating errors. The existing models do not utilize the structure in the code and just treat the code as token sequences. It causes low accuracy and poor performance on this task. In this paper, we propose a novel deep supervised learning model, called Graph-based Grammar Fix(GGF), to help programmers locate and fix the syntax errors. GGF treats the code as a mixture of the token sequences and graphs. The graphs build upon the Abstract Syntax Tree (AST) structure information. GGF encodes an erroneous code with its sub-AST structure, predicts the error position using pointer network and generates the right token. We utilized the DeepFix dataset which contains 46500 correct C programs and 6975 programs with errors written by students taking an introductory programming course. GGF is trained with the correct programs from the DeepFix dataset with intentionally injected syntax errors. After training, GGF could fix 4054 (58.12%) of the erroneous code, while the existing state of the art tool DeepFix fixes 1365 (19.57%) of the erroneous code.},
booktitle = {Proceedings of the 28th International Conference on Program Comprehension},
pages = {139–148},
numpages = {10},
keywords = {Syntax Error Correction, GGNN, Deep Learning},
location = {Seoul, Republic of Korea},
series = {ICPC '20}
}

@article{10.1007/s10664-021-09996-y,
author = {Laaber, Christoph and Basmaci, Mikael and Salza, Pasquale},
title = {Predicting unstable software benchmarks using static source code features},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09996-y},
doi = {10.1007/s10664-021-09996-y},
abstract = {Software benchmarks are only as good as the performance measurements they yield. Unstable benchmarks show high variability among repeated measurements, which causes uncertainty about the actual performance and complicates reliable change assessment. However, if a benchmark is stable or unstable only becomes evident after it has been executed and its results are available. In this paper, we introduce a machine-learning-based approach to predict a benchmark’s stability without having to execute it. Our approach relies on 58 statically-computed source code features, extracted for benchmark code and code called by a benchmark, related to (1) meta information, e.g., lines of code (LOC), (2) programming language elements, e.g., conditionals or loops, and (3) potentially performance-impacting standard library calls, e.g., file and network input/output (I/O). To assess our approach’s effectiveness, we perform a large-scale experiment on 4,461 Go benchmarks coming from 230 open-source software (OSS) projects. First, we assess the prediction performance of our machine learning models using 11 binary classification algorithms. We find that Random Forest performs best with good prediction performance from 0.79 to 0.90, and 0.43 to 0.68, in terms of AUC and MCC, respectively. Second, we perform feature importance analyses for individual features and feature categories. We find that 7 features related to meta-information, slice usage, nested loops, and synchronization application programming interfaces (APIs) are individually important for good predictions; and that the combination of all features of the called source code is paramount for our model, while the combination of features of the benchmark itself is less important. Our results show that although benchmark stability is affected by more than just the source code, we can effectively utilize machine learning models to predict whether a benchmark will be stable or not ahead of execution. This enables spending precious testing time on reliable benchmarks, supporting developers to identify unstable benchmarks during development, allowing unstable benchmarks to be repeated more often, estimating stability in scenarios where repeated benchmark execution is infeasible or impossible, and warning developers if new benchmarks or existing benchmarks executed in new environments will be unstable.},
journal = {Empirical Softw. Engg.},
month = nov,
numpages = {53},
keywords = {Go, Machine learning for software engineering, Source code features, Performance variability, Software benchmarking, Performance testing}
}

@article{10.1016/j.patcog.2016.08.023,
author = {Zhang, Xiuzhen and Li, Yuxuan and Kotagiri, Ramamohanarao and Wu, Lifang and Tari, Zahir and Cheriet, Mohamed},
title = {KRNN},
year = {2017},
issue_date = {February 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {62},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2016.08.023},
doi = {10.1016/j.patcog.2016.08.023},
abstract = {Imbalanced classification is a challenging problem. Re-sampling and cost-sensitive learning are global strategies for generality-oriented algorithms such as the decision tree, targeting inter-class imbalance. We research local strategies for the specificity-oriented learning algorithms like the k Nearest Neighbour (KNN) to address the within-class imbalance issue of positive data sparsity. We propose an algorithm k Rare-class Nearest Neighbour, or KRNN, by directly adjusting the induction bias of KNN. We propose to form dynamic query neighbourhoods, and to further adjust the positive posterior probability estimation to bias classification towards the rare class. We conducted extensive experiments on thirty real-world and artificial datasets to evaluate the performance of KRNN. Our experiments showed that KRNN significantly improved KNN for classification of the rare class, and often outperformed re-sampling and cost-sensitive learning strategies with generality-oriented base learners. HighlightsNearest neighbour classification algorithm for accurate rare-class classification.Dynamic nearest neighbourhood formulation.Adjusted posterior class probability estimation biased for the rare class.},
journal = {Pattern Recogn.},
month = feb,
pages = {33–44},
numpages = {12},
keywords = {Re-sampling, Nearest neighbour classification, KNN, Imbalanced classification, Cost-sensitive learning}
}

@article{10.4018/IJDST.2019040101,
author = {Banerjee, Soumya and Kumar, Nishi Kant},
title = {Exploring Visual Analytics to Measure Reliability for IoT Oriented Pollution Detection Software Perspectives},
year = {2019},
issue_date = {Apr 2019},
publisher = {IGI Global},
address = {USA},
volume = {10},
number = {2},
issn = {1947-3532},
url = {https://doi.org/10.4018/IJDST.2019040101},
doi = {10.4018/IJDST.2019040101},
abstract = {The measurement of the reliability of such IoT based application requires an embedded analysis. The parameters are the number of imprecise or faulty measures as well as the identification of core modules. This article investigates that how far visual introspection can assist in troubleshooting of IoT-based software bugs. This specific requirement improvises a new idea, where the shape of the plots with actual data can indicate the cause of the error and further they can be patched if the software repairing strategies are implemented adjudging the visual analytics. It is quite indifferent to analyze faults for existing applications as a variation of topological and practicing parameters which takes substantial numbers of iterations and observations. Categorically, the present use-case establishes the fact to analyze and infer concerning the shape of the visual plots derived from embedded modules.},
journal = {Int. J. Distrib. Syst. Technol.},
month = apr,
pages = {1–19},
numpages = {19},
keywords = {Visual Analytics, Reliability, Machine Learning, IoT And Web}
}

@article{10.1007/s11219-018-9430-x,
author = {Gergely, Tam\'{a}s and Balogh, Gergo? and Horv\'{a}th, Ferenc and Vancsics, B\'{e}la and Besz\'{e}des, \'{A}rp\'{a}d and Gyim\'{o}thy, Tibor},
title = {Differences between a static and a dynamic test-to-code traceability recovery method},
year = {2019},
issue_date = {June      2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9430-x},
doi = {10.1007/s11219-018-9430-x},
abstract = {Recovering test-to-code traceability links may be required in virtually every phase of development. This task might seem simple for unit tests thanks to two fundamental unit testing guidelines: isolation (unit tests should exercise only a single unit) and separation (they should be placed next to this unit). However, practice shows that recovery may be challenging because the guidelines typically cannot be fully followed. Furthermore, previous works have already demonstrated that fully automatic test-to-code traceability recovery for unit tests is virtually impossible in a general case. In this work, we propose a semi-automatic method for this task, which is based on computing traceability links using static and dynamic approaches, comparing their results and presenting the discrepancies to the user, who will determine the final traceability links based on the differences and contextual information. We define a set of discrepancy patterns, which can help the user in this task. Additional outcomes of analyzing the discrepancies are structural unit testing issues and related refactoring suggestions. For the static test-to-code traceability, we rely on the physical code structure, while for the dynamic, we use code coverage information. In both cases, we compute combined test and code clusters which represent sets of mutually traceable elements. We also present an empirical study of the method involving 8 non-trivial open source Java systems.},
journal = {Software Quality Journal},
month = jun,
pages = {797–822},
numpages = {26},
keywords = {Unit testing, Traceability link recovery, Test-to-code traceability, Structural test smells, Refactoring, Code coverage}
}

@article{10.1016/j.ins.2016.11.014,
author = {Lee, Wonji and Jun, Chi-Hyuck and Lee, Jong-Seok},
title = {Instance categorization by support vector machines to adjust weights in AdaBoost for imbalanced data classification},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {381},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2016.11.014},
doi = {10.1016/j.ins.2016.11.014},
abstract = {We proposed an improved weighted SVM for imbalanced classification.Different factor scores are computed by categorizing instances based on the SVM margin.Numerical experiments showed the proposed method outperforming the existing approaches in terms of F-measure AUC. To address class imbalance in data, we propose a new weight adjustment factor that is applied to a weighted support vector machine (SVM) as a weak learner of the AdaBoost algorithm. Different factor scores are computed by categorizing instances based on the SVM margin and are assigned to related instances. The SVM margin is used to define borderline and noisy instances, and the factor scores are assigned to only borderline instances and positive noise. The adjustment factor is then employed as a multiplier to the instance weight in the AdaBoost algorithm when learning a weighted SVM. Using 10 real class-imbalanced datasets, we compare the proposed method to a standard SVM and other SVMs combined with various sampling and boosting methods. Numerical experiments show that the proposed method outperforms existing approaches in terms of F-measure and area under the receiver operating characteristic curve, which means that the proposed method is useful for relaxing the class-imbalance problem by addressing well-known degradation issues such as overlap, small disjunct, and data shift problems.},
journal = {Inf. Sci.},
month = mar,
pages = {92–103},
numpages = {12},
keywords = {Weight adjustment, SVM, Instance categorization, Class imbalance, AdaBoost}
}

@inproceedings{10.1109/ISSRE.2009.16,
author = {Snipes, Will and Robinson, Brian and Brooks, Penelope},
title = {Approximating Deployment Metrics to Predict Field Defects and Plan Corrective Maintenance Activities},
year = {2009},
isbn = {9780769538785},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2009.16},
doi = {10.1109/ISSRE.2009.16},
abstract = {Abstract-Corrective maintenance activities are a common cause of schedule delays in software development projects. Organizations frequently fail to properly plan the effort required to fix field defects. This study aims to provide relevant guidance to software development organizations on planning for these corrective maintenance activities by correlating metrics that are available prior to release with parameters of the selected software reliability model that has historically best fit the product’s field defect data. Many organizations do not have adequate historical data, especially historical deployment and field usage information. The study identifies a set of metrics calculable from available data to approximate these missing predictor categories. Two key metrics estimable prior to release surfaced with potentially useful correlations, (1) the number of periods until the next release and (2) the peak deployment percentage. Finally, these metrics were used in a case study to plan corrective maintenance efforts on current development releases.},
booktitle = {Proceedings of the 2009 20th International Symposium on Software Reliability Engineering},
pages = {90–98},
numpages = {9},
keywords = {metrics, maintenance effort, defect prediction},
series = {ISSRE '09}
}

@article{10.1016/j.eswa.2015.01.069,
author = {Dess\`{\i}, Nicoletta and Pes, Barbara},
title = {Similarity of feature selection methods},
year = {2015},
issue_date = {June 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {10},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.01.069},
doi = {10.1016/j.eswa.2015.01.069},
abstract = {We empirically investigated the similarity among feature selection methods.Extensive experiments were carried out across high dimensional classification tasks.We obtained useful insight into the pattern of agreement of eight popular methods. In the past two decades, the dimensionality of datasets involved in machine learning and data mining applications has increased explosively. Therefore, feature selection has become a necessary step to make the analysis more manageable and to extract useful knowledge about a given domain. A large variety of feature selection techniques are available in literature, and their comparative analysis is a very difficult task. So far, few studies have investigated, from a theoretical and/or experimental point of view, the degree of similarity/dissimilarity among the available techniques, namely the extent to which they tend to produce similar results within specific application contexts. This kind of similarity analysis is of crucial importance when two or more methods are combined in an ensemble fashion: indeed the ensemble paradigm is beneficial only if the involved methods are capable of giving different and complementary representations of the considered domain. This paper gives a contribution in this direction by proposing an empirical approach to evaluate the degree of consistency among the outputs of different selection algorithms in the context of high dimensional classification tasks. Leveraging on a proper similarity index, we systematically compared the feature subsets selected by eight popular selection methods, representatives of different selection approaches, and derived a similarity trend for feature subsets of increasing size. Through an extensive experimentation involving sixteen datasets from three challenging domains (Internet advertisements, text categorization and micro-array data classification), we obtained useful insight into the pattern of agreement of the considered methods. In particular, our results revealed how multivariate selection approaches systematically produce feature subsets that overlap to a small extent with those selected by the other methods.},
journal = {Expert Syst. Appl.},
month = jun,
pages = {4632–4642},
numpages = {11},
keywords = {Similarity measures, Knowledge discovery, Feature selection, Data mining}
}

@inproceedings{10.1145/3468264.3473494,
author = {Chakraborty, Mohna},
title = {Does reusing pre-trained NLP model propagate bugs?},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473494},
doi = {10.1145/3468264.3473494},
abstract = {In this digital era, the textual content has become a seemingly ubiquitous part of our life. Natural Language Processing (NLP) empowers machines to comprehend the intricacies of textual data and eases human-computer interaction. Advancement in language modeling, continual learning, availability of a large amount of linguistic data, and large-scale computational power have made it feasible to train models for downstream tasks related to text analysis, including safety-critical ones, e.g., medical, airlines, etc. Compared to other deep learning (DL) models, NLP-based models are widely reused for various tasks. However, the reuse of pre-trained models in a new setting is still a complex task due to the limitations of the training dataset, model structure, specification, usage, etc. With this motivation, we study BERT, a vastly used language model (LM), from the direction of reusing in the code. We mined 80 posts from Stack Overflow related to BERT and found 4 types of bugs observed in clients’ code. Our results show that 13.75% are fairness, 28.75% are parameter, 15% are token, and 16.25% are version-related bugs.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1686–1688},
numpages = {3},
keywords = {Reuse, NLP, Deep Learning, Bug, BERT},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1109/MSR.2019.00018,
author = {Kiehn, Max and Pan, Xiangyi and Camci, Fatih},
title = {Empirical study in using version histories for change risk classification},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00018},
doi = {10.1109/MSR.2019.00018},
abstract = {Many techniques have been proposed for mining software repositories, predicting code quality and evaluating code changes. Prior work has established links between code ownership and churn metrics, and software quality at file and directory level based on changes that fix bugs. Other metrics have been used to evaluate individual code changes based on preceding changes that induce fixes. This paper combines the two approaches in an empirical study of assessing risk of code changes using established code ownership and churn metrics with fix inducing changes on a large proprietary code repository. We establish a machine learning model for change risk classification which achieves average precision of 0.76 using metrics from prior works and 0.90 using a wider array of metrics. Our results suggest that code ownership metrics can be applied in change risk classification models based on fix inducing changes.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {58–62},
numpages = {5},
keywords = {machine learning, file metrics, code ownership, change risk},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@article{10.1145/3276517,
author = {Pradel, Michael and Sen, Koushik},
title = {DeepBugs: a learning approach to name-based bug detection},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {OOPSLA},
url = {https://doi.org/10.1145/3276517},
doi = {10.1145/3276517},
abstract = {Natural language elements in source code, e.g., the names of variables and functions, convey useful information. However, most existing bug detection tools ignore this information and therefore miss some classes of bugs. The few existing name-based bug detection approaches reason about names on a syntactic level and rely on manually designed and tuned algorithms to detect bugs. This paper presents DeepBugs, a learning approach to name-based bug detection, which reasons about names based on a semantic representation and which automatically learns bug detectors instead of manually writing them. We formulate bug detection as a binary classification problem and train a classifier that distinguishes correct from incorrect code. To address the challenge that effectively learning a bug detector requires examples of both correct and incorrect code, we create likely incorrect code examples from an existing corpus of code through simple code transformations. A novel insight learned from our work is that learning from artificially seeded bugs yields bug detectors that are effective at finding bugs in real-world code. We implement our idea into a framework for learning-based and name-based bug detection. Three bug detectors built on top of the framework detect accidentally swapped function arguments, incorrect binary operators, and incorrect operands in binary operations. Applying the approach to a corpus of 150,000 JavaScript files yields bug detectors that have a high accuracy (between 89% and 95%), are very efficient (less than 20 milliseconds per analyzed file), and reveal 102 programming mistakes (with 68% true positive rate) in real-world code.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {147},
numpages = {25},
keywords = {Natural language, Name-based program analysis, Machine learning, JavaScript, Bug detection}
}

@inproceedings{10.1145/3338906.3340450,
author = {Chen, Jianfeng and Chakraborty, Joymallya and Clark, Philip and Haverlock, Kevin and Cherian, Snehit and Menzies, Tim},
title = {Predicting breakdowns in cloud services (with SPIKE)},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3340450},
doi = {10.1145/3338906.3340450},
abstract = {Maintaining web-services is a mission-critical task where any down- time means loss of revenue and reputation (of being a reliable service provider). In the current competitive web services market, such a loss of reputation causes extensive loss of future revenue.  To address this issue, we developed SPIKE, a data mining tool which can predict upcoming service breakdowns, half an hour into the future. Such predictions let an organization alert and assemble the tiger team to address the problem (e.g. by reconguring cloud hardware in order to reduce the likelihood of that breakdown).  SPIKE utilizes (a) regression tree learning (with CART); (b) synthetic minority over-sampling (to handle how rare spikes are in our data); (c) hyperparameter optimization (to learn best settings for our local data) and (d) a technique we called “topology sampling” where training vectors are built from extensive details of an individual node plus summary details on all their neighbors.  In the experiments reported here, SPIKE predicted service spikes 30 minutes into future with recalls and precision of 75% and above. Also, SPIKE performed relatively better than other widely-used learning methods (neural nets, random forests, logistic regression).},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {916–924},
numpages = {9},
keywords = {parameter tuning, optimization, data mining, Cloud},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1145/3433928,
author = {Vandehei, Bailey and Costa, Daniel Alencar Da and Falessi, Davide},
title = {Leveraging the Defects Life Cycle to Label Affected Versions and Defective Classes},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3433928},
doi = {10.1145/3433928},
abstract = {Two recent studies explicitly recommend labeling defective classes in releases using the affected versions (AV) available in issue trackers (e.g., Jira). This practice is coined as the realistic approach. However, no study has investigated whether it is feasible to rely on AVs. For example, how available and consistent is the AV information on existing issue trackers? Additionally, no study has attempted to retrieve AVs when they are unavailable. The aim of our study is threefold: (1) to measure the proportion of defects for which the realistic method is usable, (2) to propose a method for retrieving the AVs of a defect, thus making the realistic approach usable when AVs are unavailable, (3) to compare the accuracy of the proposed method versus three SZZ implementations. The assumption of our proposed method is that defects have a stable life cycle in terms of the proportion of the number of versions affected by the defects before discovering and fixing these defects. Results related to 212 open-source projects from the Apache ecosystem, featuring a total of about 125,000 defects, reveal that the realistic method cannot be used in the majority (51%) of defects. Therefore, it is important to develop automated methods to retrieve AVs. Results related to 76 open-source projects from the Apache ecosystem, featuring a total of about 6,250,000 classes, affected by 60,000 defects, and spread over 4,000 versions and 760,000 commits, reveal that the proportion of the number of versions between defect discovery and fix is pretty stable (standard deviation &lt;2)—across the defects of the same project. Moreover, the proposed method resulted significantly more accurate than all three SZZ implementations in (i) retrieving AVs, (ii) labeling classes as defective, and (iii) in developing defects repositories to perform feature selection. Thus, when the realistic method is unusable, the proposed method is a valid automated alternative to SZZ for retrieving the origin of a defect. Finally, given the low accuracy of SZZ, researchers should consider re-executing the studies that have used SZZ as an oracle and, in general, should prefer selecting projects with a high proportion of available and consistent AVs.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {24},
numpages = {35},
keywords = {developing defects repository, defect origin, SZZ, Affected version}
}

@inproceedings{10.1007/978-3-030-72013-1_15,
author = {Sotoudeh, Matthew and Thakur, Aditya V.},
title = {SyReNN: A Tool for Analyzing Deep Neural Networks},
year = {2021},
isbn = {978-3-030-72012-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-72013-1_15},
doi = {10.1007/978-3-030-72013-1_15},
abstract = {Deep Neural Networks (DNNs) are rapidly gaining popularity in a variety of important domains. Formally, DNNs are complicated vector-valued functions which come in a variety of sizes and applications. Unfortunately, modern DNNs have been shown to be vulnerable to a variety of attacks and buggy behavior. This has motivated recent work in formally analyzing the properties of such DNNs. This paper introduces SyReNN, a tool for understanding and analyzing a DNN by computing its symbolic representation. The key insight is to decompose the DNN into linear functions. Our tool is designed for analyses using low-dimensional subsets of the input space, a unique design point in the space of DNN analysis tools. We describe the tool and the underlying theory, then evaluate its use and performance on three case studies: computing Integrated Gradients, visualizing a DNN’s decision boundaries, and patching a DNN.},
booktitle = {Tools and Algorithms for the Construction and Analysis of Systems: 27th International Conference, TACAS 2021, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2021,  Luxembourg City, Luxembourg, March 27 – April 1, 2021, Proceedings, Part II},
pages = {281–302},
numpages = {22},
keywords = {Integrated Gradients, Symbolic representation, Deep Neural Networks},
location = {Luxembourg City, Luxembourg}
}

@inproceedings{10.1007/978-3-030-63618-0_5,
author = {Scott, Joseph and Mora, Federico and Ganesh, Vijay},
title = {BanditFuzz: A Reinforcement-Learning Based Performance Fuzzer for SMT Solvers},
year = {2020},
isbn = {978-3-030-63617-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63618-0_5},
doi = {10.1007/978-3-030-63618-0_5},
abstract = {Satisfiability Modulo Theories (SMT) solvers are fundamental tools that are used widely in software engineering, verification, and security research. Precisely because of their widespread use, it is imperative we develop efficient and systematic methods to test them. To this end, we present a reinforcement-learning based fuzzing system, BanditFuzz, that learns grammatical constructs of well-formed inputs that may cause performance slowdown in SMT solvers. To the best of our knowledge, BanditFuzz is the first machine-learning based performance fuzzer for SMT solvers.BanditFuzz takes the following as input: a grammar G describing well-formed inputs to a set of distinct solvers (say, a target solver T and a reference solver R) that implement the same specification, and a fuzzing objective (e.g., aim to maximize the relative performance difference between T and R). BanditFuzz outputs a list of grammatical constructs that are ranked in descending order by how likely they are to increase the performance difference between solvers T and R. Using BanditFuzz, we constructed two benchmark suites (with 400 floating-point and 300 string instances) that expose performance issues in all considered solvers, namely, Z3, CVC4, Colibri, MathSAT, Z3seq, and Z3str3. We also performed a comparison of BanditFuzz against random, mutation, and evolutionary fuzzing methods and observed up&nbsp;to a 81% improvement based on PAR-2 scores used in SAT competitions. That is, relative to other fuzzing methods considered, BanditFuzz was found to be more efficient at constructing inputs with wider performance margin between a target and a set of reference solvers.},
booktitle = {Software Verification: 12th International Conference, VSTTE 2020, and 13th International Workshop, NSV 2020, Los Angeles, CA, USA, July 20–21, 2020, Revised Selected Papers},
pages = {68–86},
numpages = {19},
location = {Los Angeles, CA, USA}
}

@article{10.1016/j.patcog.2014.11.014,
author = {Sun, Zhongbin and Song, Qinbao and Zhu, Xiaoyan and Sun, Heli and Xu, Baowen and Zhou, Yuming},
title = {A novel ensemble method for classifying imbalanced data},
year = {2015},
issue_date = {May 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {48},
number = {5},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2014.11.014},
doi = {10.1016/j.patcog.2014.11.014},
abstract = {The class imbalance problems have been reported to severely hinder classification performance of many standard learning algorithms, and have attracted a great deal of attention from researchers of different fields. Therefore, a number of methods, such as sampling methods, cost-sensitive learning methods, and bagging and boosting based ensemble methods, have been proposed to solve these problems. However, these conventional class imbalance handling methods might suffer from the loss of potentially useful information, unexpected mistakes or increasing the likelihood of overfitting because they may alter the original data distribution. Thus we propose a novel ensemble method, which firstly converts an imbalanced data set into multiple balanced ones and then builds a number of classifiers on these multiple data with a specific classification algorithm. Finally, the classification results of these classifiers for new data are combined by a specific ensemble rule. In the empirical study, different class imbalance data handling methods including three conventional sampling methods, one cost-sensitive learning method, six Bagging and Boosting based ensemble methods, our previous method EM1vs1 and two fuzzy-rule based classification methods were compared with our method. The experimental results on 46 imbalanced data sets show that our proposed method is usually superior to the conventional imbalance data handling methods when solving the highly imbalanced problems. HighlightsWe propose a novel ensemble method to handle imbalanced binary data.The method turns imbalanced data learning into multiple balanced data learning.Our method usually performs better than the conventional methods on imbalanced data.},
journal = {Pattern Recogn.},
month = may,
pages = {1623–1637},
numpages = {15},
keywords = {Imbalanced data, Ensemble learning, Classification}
}

@inproceedings{10.1145/2590748.2590755,
author = {Rathore, Santosh Singh and Gupta, Atul},
title = {A comparative study of feature-ranking and feature-subset selection techniques for improved fault prediction},
year = {2014},
isbn = {9781450327763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2590748.2590755},
doi = {10.1145/2590748.2590755},
abstract = {The quality of a fault prediction model depends on the software metrics that are used to build the prediction model. Feature selection represents a process of selecting a subset of relevant features that may lead to build improved prediction models. Feature selection techniques can be broadly categorized into two subcategories: feature-ranking and feature-subset selection. In this paper, we present a comparative investigation of seven feature-ranking techniques and eight feature-subset selection techniques for improved fault prediction. The performance of these feature selection techniques is evaluated using two popular machine-learning classifiers: Naive Bayes and Random Forest, over fourteen software project's fault-datasets obtained from the PROMISE data repository. The performances were measured using F-measure and AUC values. Our results demonstrated that feature-ranking techniques produced better results compared to feature-subset selection techniques. Among, the feature-ranking techniques used in the study, InfoGain and PCA techniques provided the best performance over all the datasets, while for feature-subset selection techniques ClassifierSubsetEval and Logistic Regression produced better results against their peers.},
booktitle = {Proceedings of the 7th India Software Engineering Conference},
articleno = {7},
numpages = {10},
keywords = {wrappers, software metrics, filters, feature-ranking, feature selection, fault prediction},
location = {Chennai, India},
series = {ISEC '14}
}

@inproceedings{10.1145/3427228.3427269,
author = {Das, Sanjeev and James, Kedrian and Werner, Jan and Antonakakis, Manos and Polychronakis, Michalis and Monrose, Fabian},
title = {A Flexible Framework for Expediting Bug Finding by Leveraging Past (Mis-)Behavior to Discover New Bugs},
year = {2020},
isbn = {9781450388580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427228.3427269},
doi = {10.1145/3427228.3427269},
abstract = {Among various fuzzing approaches, coverage-guided grey-box fuzzing is perhaps the most prominent, due to its ease of use and effectiveness. Using this approach, the selection of inputs focuses on maximizing program coverage, e.g., in terms of the different branches that have been traversed. In this work, we begin with the observation that selecting any input that explores a new path, and giving equal weight to all paths, can lead to severe inefficiencies. For instance, although seemingly “new” crashes involving previously unexplored paths may be discovered, these often have the same root cause and actually correspond to the same bug. To address these inefficiencies, we introduce a framework that incorporates a tighter feedback loop to guide the fuzzing process in exploring truly diverse code paths. Our framework employs (i) a vulnerability-aware selection of coverage metrics for enhancing the effectiveness of code exploration, (ii) crash deduplication information for early feedback, and (iii) a configurable input culling strategy that interleaves multiple strategies to achieve comprehensiveness. A novel aspect of our work is the use of hardware performance counters to derive coverage metrics. We present an approach for assessing and selecting the hardware events that can be used as a meaningful coverage metric for a target program. The results of our empirical evaluation using real-world programs demonstrate the effectiveness of our approach: in some cases, we explore fewer than 50% of the paths compared to a base fuzzer (AFL, MOpt, and Fairfuzz), yet on average, we improve new bug discovery by 31%, and find the same bugs (as the base) 3.3 times faster. Moreover, although we specifically chose applications that have been subject to recent fuzzing campaigns, we still discovered 9 new vulnerabilities.},
booktitle = {Proceedings of the 36th Annual Computer Security Applications Conference},
pages = {345–359},
numpages = {15},
keywords = {Machine Learning, Hardware Performance Counters, Fuzzing},
location = {Austin, USA},
series = {ACSAC '20}
}

@inproceedings{10.1109/ITSC.2018.8569661,
author = {Jenkins, Ian Rhys and Gee, Ludvig Oliver and Knauss, Alessia and Yin, Hang and Schroeder, Jan},
title = {Accident Scenario Generation with Recurrent Neural Networks},
year = {2018},
isbn = {978-1-7281-0321-1},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC.2018.8569661},
doi = {10.1109/ITSC.2018.8569661},
abstract = {There is a lack of approaches to derive accident scenarios automatically for the testing of Autonomous Drive systems. Current approaches that generate test scenarios do not scale due to the manual work required. Machine learning provides the possibility to automate such tasks. In this paper, an automated approach based on Recurrent Neural Networks to generate accident scenarios is presented. Based on a prototype, our approach is evaluated on temporal data from simulated in-vehicle and V2X data to automatically generate new accident scenarios. The results confirm that generated scenarios resemble the accidents that took place in an exclusive test set.},
booktitle = {2018 21st International Conference on Intelligent Transportation Systems (ITSC)},
pages = {3340–3345},
numpages = {6},
location = {Maui, HI, USA}
}

@inproceedings{10.5555/1802408.1802422,
author = {Snipes, Will and Robinson, Brian and Brooks, Penelope},
title = {Approximating deployment metrics to predict field defects and plan corrective maintenance activities},
year = {2009},
isbn = {9781424453757},
publisher = {IEEE Press},
abstract = {Corrective maintenance activities are a common cause of schedule delays in software development projects. Organizations frequently fail to properly plan the effort required to fix field defects. This study aims to provide relevant guidance to software development organizations on planning for these corrective maintenance activities by correlating metrics that are available prior to release with parameters of the selected software reliability model that has historically best fit the product's field defect data. Many organizations do not have adequate historical data, especially historical deployment and field usage information. The study identifies a set of metrics calculable from available data to approximate these missing predictor categories. Two key metrics estimable prior to release surfaced with potentially useful correlations, (1) the number of periods until the next release and (2) the peak deployment percentage. Finally, these metrics were used in a case study to plan corrective maintenance efforts on current development releases.},
booktitle = {Proceedings of the 20th IEEE International Conference on Software Reliability Engineering},
pages = {90–98},
numpages = {9},
keywords = {defect prediction, maintenance effort, metrics, reliability},
location = {Bengaluru-Mysuru, India},
series = {ISSRE'09}
}

@article{10.1016/j.knosys.2014.04.033,
author = {Sheng, Victor S. and Gu, Bin and Fang, Wei and Wu, Jian},
title = {Cost-sensitive learning for defect escalation},
year = {2014},
issue_date = {August 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {66},
number = {1},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2014.04.033},
doi = {10.1016/j.knosys.2014.04.033},
abstract = {While most software defects (i.e., bugs) are corrected and tested as part of the prolonged software development cycle, enterprise software venders often have to release software products before all reported defects are corrected, due to deadlines and limited resources. A small number of these reported defects will be escalated by customers whose businesses are seriously impacted. Escalated defects must be resolved immediately and individually by the software vendors at a very high cost. The total costs can be even greater, including loss of reputation, satisfaction, loyalty, and repeat revenue. In this paper, we develop a Software defecT Escalation Prediction (STEP) system to mine historical defect report data and predict the escalation risk of current defect reports for maximum net profit. More specifically, we first describe a simple and general framework to convert the maximum net profit problem to cost-sensitive learning. We then apply and compare four well-known cost-sensitive learning approaches for STEP. Our experiments suggest that cost-sensitive decision trees (CSTree) is the best methods for producing the highest positive net profit.},
journal = {Know.-Based Syst.},
month = aug,
pages = {146–155},
numpages = {10},
keywords = {cost-sensitive learning, data mining, defect escalation, machine learning, software defect escalation prediction}
}

@inproceedings{10.1145/2896921.2896923,
author = {Felbinger, Hermann and Wotawa, Franz and Nica, Mihai},
title = {Empirical study of correlation between mutation score and model inference based test suite adequacy assessment},
year = {2016},
isbn = {9781450341516},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896921.2896923},
doi = {10.1145/2896921.2896923},
abstract = {In this paper we investigate a method for test suite evaluation that is based on an inferred model from the test suite. The idea is to use the similarity between the inferred model and the system under test as a measure of test suite adequacy, which is the ability of a test suite to expose errors in the system under test. We define similarity using the root mean squared error computed from the differences of the system under test output and the model output for certain inputs not used for model inference. In the paper we introduce the approach and provide results of an experimental evaluation where we compare the similarity with the mutation score. We used the Pearson Correlation coefficient to calculate whether a linear correlation between mutation score and root mean squared error exists. As a result we obtain that in certain cases the computed similarity strongly correlates with the mutation score.},
booktitle = {Proceedings of the 11th International Workshop on Automation of Software Test},
pages = {43–49},
numpages = {7},
keywords = {machine learning, mutation score, software test},
location = {Austin, Texas},
series = {AST '16}
}

@inproceedings{10.1109/ICISSEC.2015.7370965,
author = {Tamura, Yoshinobu and Nobukawa, Yumi and Yamada, Shigeru},
title = {A Method of Reliability Assessment Based on Neural Network and Fault Data Clustering for Cloud with Big Data},
year = {2015},
isbn = {9781467386111},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICISSEC.2015.7370965},
doi = {10.1109/ICISSEC.2015.7370965},
abstract = {In the mobile clouds, the data size recorded in database software becomes large. Considering the software reliability of cloud computing with big data, it is important for the software managers to assess the relationship among the database software and cloud software, because the cloud software collaborate closely with the database software by using the internet network. In this paper, we propose a method of software reliability assessment based on the fault data clustering and neural network in cloud computing environment with big data. We perform a cluster analysis for the software fault data by using k-means clustering. Also, we propose the estimation method of the cumulative numbers of detected faults based on the neural network by using the results of cluster analysis. Moreover, we show several numerical examples of software reliability assessment in the cloud computing environment with big data.},
booktitle = {Proceedings of the 2015 2nd International Conference on Information Science and Security (ICISS)},
pages = {1–4},
numpages = {4},
series = {ICISS '15}
}

@inproceedings{10.1145/3287921.3287958,
author = {Van Thuy, Hoang and Anh, Phan Viet and Hoai, Nguyen Xuan},
title = {Automated Large Program Repair based on Big Code},
year = {2018},
isbn = {9781450365390},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287921.3287958},
doi = {10.1145/3287921.3287958},
abstract = {The task of automatic program repair is to automatically localize and generate the correct patches for the bugs. A prominent approach is to produce a space of candidate patches, then find and validate candidates on test case sets. However, searching for the correct candidates is really challenging, since the search space is dominated by incorrect patches and its size is huge.This paper presents several methods to improve the automated program repair system Prophet, called Prophet+. Our approach contributes three improvements over Prophet: 1) extract twelve relations of statements and blocks for Bi-gram model using Big code, 2) prune the search space, 3) develop an algorithm to re-rank candidate patches in the search space. The experimental results show that our proposed system enhances the performance of Prophet, recognized as the state-of-the-art system, significantly. Specifically, for the top 1, our system generates the correct patches for 17 over 69 bugs while the number achieved by Prophet is 15.},
booktitle = {Proceedings of the 9th International Symposium on Information and Communication Technology},
pages = {375–381},
numpages = {7},
keywords = {Automated Program Repair, Bigcode, Machine Learning, N-gram},
location = {Danang City, Viet Nam},
series = {SoICT '18}
}

@inproceedings{10.1007/978-3-030-78292-4_1,
author = {Abhinav, Kumar and Sharvani, Vijaya and Dubey, Alpana and D’Souza, Meenakshi and Bhardwaj, Nitish and Jain, Sakshi and Arora, Veenu},
title = {RepairNet: Contextual Sequence-to-Sequence Network for Automated Program Repair},
year = {2021},
isbn = {978-3-030-78291-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78292-4_1},
doi = {10.1007/978-3-030-78292-4_1},
abstract = {Compile-time errors can wreak havoc for programmers – seasoned and novice. Often developers spend a lot of time debugging them. An automated system to repair such errors can be a useful aid to the developers for their productivity. In this work, we propose a deep generative model, RepairNet, that automatically repairs programs that fail at compile time. RepairNet is based on sequence-to-sequence modeling and uses both code and error messages to repair the program. We evaluated the effectiveness of our system on 6,971 erroneous submissions for 93 programming tasks. RepairNet outperforms the existing state-of-the-art technique, MACER, with 17% relative improvement of repair accuracy. Our approach can fix 66.4% of the erroneous submissions completely and 14.2% partially.},
booktitle = {Artificial Intelligence in Education: 22nd International Conference, AIED 2021, Utrecht, The Netherlands, June 14–18, 2021, Proceedings, Part I},
pages = {3–15},
numpages = {13},
keywords = {Program repair, Sequence modeling, Bug fixing},
location = {Utrecht, The Netherlands}
}

@article{10.1016/j.knosys.2015.06.018,
author = {Jin, Liuqian and Liu, Jun and Xu, Yang and Fang, Xin},
title = {A novel rule base representation and its inference method using the evidential reasoning approach},
year = {2015},
issue_date = {October 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {87},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.06.018},
doi = {10.1016/j.knosys.2015.06.018},
abstract = {In this paper, a novel rule base, Certainty Rule Base (CeRB), and its inference method are proposed. This rule base is firstly designed with certainty degrees embedded in the antecedent terms as well as in the consequent terms. CeRB is shown to be capable of capturing vagueness, incompleteness, uncertainty, and nonlinear causal relationships in an integrated way. Secondly, the CeRB inference method using the evidential reasoning approach is provided. The overall representation and inference framework offer a further improvement and a great extension of the recently uncertainty inference methods. Namely, the knowledge is represented by CeRB and the evidential reasoning approach is applied to the rule combination. In the end, two case studies including a numerical example and a software defect prediction are provided to illustrate the proposed CeRB representation, generation and inference procedure as well as demonstrate its high performance by comparing with some existing approaches.},
journal = {Know.-Based Syst.},
month = oct,
pages = {80–91},
numpages = {12},
keywords = {Certainty rule base, Evidential reasoning approach, Representation of knowledge, Similarity measure, Uncertainty inference method}
}

@inproceedings{10.5555/3540261.3541769,
author = {Wang, Feng and Wei, Guoyizhe and Liu, Qiao and Ou, Jinxiang and Wei, Xian and Lv, Hairong},
title = {Boost neural networks by checkpoints},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Training multiple deep neural networks (DNNs) and averaging their outputs is a simple way to improve the predictive performance. Nevertheless, the multiplied training cost prevents this ensemble method to be practical and efficient. Several recent works attempt to save and ensemble the checkpoints of DNNs, which only requires the same computational cost as training a single network. However, these methods suffer from either marginal accuracy improvements due to the low diversity of checkpoints or high risk of divergence due to the cyclical learning rates they adopted. In this paper, we propose a novel method to ensemble the checkpoints, where a boosting scheme is utilized to accelerate model convergence and maximize the checkpoint diversity. We theoretically prove that it converges by reducing exponential loss. The empirical evaluation also indicates our proposed ensemble outperforms single model and existing ensembles in terms of accuracy and efficiency. With the same training budget, our method achieves 4.16% lower error on Cifar-100 and 6.96% on Tiny-ImageNet with ResNet-110 architecture. Moreover, the adaptive sample weights in our method make it an effective solution to address the imbalanced class distribution. In the experiments, it yields up to 5.02% higher accuracy over single EfficientNet-B0 on the imbalanced datasets.},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {1508},
numpages = {11},
series = {NIPS '21}
}

@article{10.1016/j.eswa.2017.08.004,
author = {Wangchamhan, Tanachapong and Chiewchanwattana, Sirapat and Sunat, Khamron},
title = {Efficient algorithms based on the k-means and Chaotic League Championship Algorithm for numeric, categorical, and mixed-type data clustering},
year = {2017},
issue_date = {December 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {90},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2017.08.004},
doi = {10.1016/j.eswa.2017.08.004},
abstract = {The search algorithm C-LCA is done by adding two chaotic parameters into the LCA.The search clustering using CS-LCA and the KSC-LCA algorithms are proposed.The Gower distance and a mechanism are adopted for handling the mixed-type data.The search clustering CS-LCA ranks first for the pure categorical data.The KSC-LCA ranks first for the pure numeric and mixed-type data. The success rates of the expert or intelligent systems depend on the selection of the correct data clusters. The k-means algorithm is a well-known method in solving data clustering problems. It suffers not only from a high dependency on the algorithm's initial solution but also from the used distance function. A number of algorithms have been proposed to address the centroid initialization problem, but the produced solution does not produce optimum clusters. This paper proposes three algorithms (i) the search algorithm C-LCA that is an improved League Championship Algorithm (LCA), (ii) a search clustering using C-LCA (SC-LCA), and (iii) a hybrid-clustering algorithm called the hybrid of k-means and Chaotic League Championship Algorithm (KSC-LCA) and this algorithm has of two computation stages. The C-LCA employs chaotic adaptation for the retreat and approach parameters, rather than constants, which can enhance the search capability. Furthermore, to overcome the limitation of the original k-means algorithm using the Euclidean distance that cannot handle the categorical attribute type properly, we adopt the Gower distance and the mechanism for handling a discrete value requirement of the categorical value attribute. The proposed algorithms can handle not only the pure numeric data but also the mixed-type data and can find the best centroids containing categorical values. Experiments were conducted on 14 datasets from the UCI repository. The SC-LCA and KSC-LCA competed with 16 established algorithms including the k-means, k-means++, global k-means algorithms, four search clustering algorithms and nine hybrids of k-means algorithm with several state-of-the-art evolutionary algorithms. The experimental results show that the SC-LCA produces the cluster with the highest F-Measure on the pure categorical dataset and the KSC-LCA produces the cluster with the highest F-Measure for the pure numeric and mixed-type tested datasets. Out of 14 datasets, there were 13 centroids produced by the SC-LCA that had better F-Measures than that of the k-means algorithm. On the Tic-Tac-Toe dataset containing only categorical attributes, the SC-LCA can achieve an F-Measure of 66.61 that is 21.74 points over that of the k-means algorithm (44.87). The KSC-LCA produced better centroids than k-means algorithm in all 14 datasets; the maximum F-Measure improvement was 11.59 points. However, in terms of the computational time, the SC-LCA and KSC-LCA took more NFEs than the k-means and its variants but the KSC-LCA ranks first and SC-LCA ranks fourth among the hybrid clustering and the search clustering algorithms that we tested. Therefore, the SC-LCA and KSC-LCA are general and effective clustering algorithms that could be used when an expert or intelligent system requires an accurate high-speed cluster selection.},
journal = {Expert Syst. Appl.},
month = dec,
pages = {146–167},
numpages = {22},
keywords = {Chaos optimization algorithms (COA), Data clustering, Hybrid clustering algorithm, League Championship Algorithm (LCA), Mixed-type data, Search clustering algorithm}
}

@article{10.1145/2421648.2421653,
author = {Basak, Jayanta and Wadhwani, Kushal and Voruganti, Kaladhar and Narayanamurthy, Srinivasan and Mathur, Vipul and Nandi, Siddhartha},
title = {Model building for dynamic multi-tenant provider environments},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0163-5980},
url = {https://doi.org/10.1145/2421648.2421653},
doi = {10.1145/2421648.2421653},
abstract = {Increasingly, storage vendors are finding it difficult to leverage existing white-box and black-box modeling techniques to build robust system models that can predict system behavior in the emerging dynamic and multi-tenant data centers. White-box models are becoming brittle because the model builders are not able to keep up with the innovations in the storage system stack, and black-box models are becoming brittle because it is increasingly difficult to a priori train the model for the dynamic and multi-tenant data center environment. Thus, there is a need for innovation in system model building area.In this paper we present a machine learning based blackbox modeling algorithm called M-LISP that can predict system behavior in untrained region for these emerging multitenant and dynamic data center environments. We have implemented and analyzed M-LISP in real environments and the initial results look very promising. We also provide a survey of some common machine learning algorithms and how they fare with respect to satisfying the modeling needs of the new data center environments.},
journal = {SIGOPS Oper. Syst. Rev.},
month = dec,
pages = {20–31},
numpages = {12},
keywords = {black-box, machine learning, resource modeling, storage management}
}

@inproceedings{10.1109/LATW.2011.5985890,
author = {Lenz, Alexandre Rafael and Pozo, Aurora and Vergilio, Silvia Regina},
title = {An approach for clustering test data},
year = {2011},
isbn = {9781457714894},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/LATW.2011.5985890},
doi = {10.1109/LATW.2011.5985890},
abstract = {The existing test techniques and criteria are considered complementary because they can reveal different kinds of faults and test specific aspects of the program. The functional criteria, such as Category Partition, are difficult to be automated, and are usually manually applied. Structural and fault-based testing criteria generally provide measures to evaluate the test data being used. The existing supporting tools produce a lot of information including: input and produced output, structural coverage, mutation score, faults revealed, etc. However, such information is not linked to functional aspects of the software. In this work, we present an approach based on machine learning clustering techniques that uses the test results for clustering test data. It allows the automation of functional test, since the obtained clusters can be considered equivalence classes. In addition to this, they relate test results from the application of different test techniques. A study case is described, and the use of the clusters is illustrated during regression test for ordering and reduction of test sets.},
booktitle = {Proceedings of the 2011 12th Latin American Test Workshop},
pages = {1–6},
numpages = {6},
keywords = {category partition, fault-based testing criteria, faults revealed, functional criteria, functional test automation, input-and-produced output, machine learning clustering techniques, mutation score, software test, structural coverage, structural testing criteria, test data clustering, test techniques},
series = {LATW '11}
}

@article{10.1016/j.procs.2020.03.274,
author = {Taneja, Divya and Singh, Rajvir and Singh, Ajmer and Malik, Himanshu},
title = {A Novel technique for test case minimization in object oriented testing},
year = {2020},
issue_date = {2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {167},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2020.03.274},
doi = {10.1016/j.procs.2020.03.274},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {2221–2228},
numpages = {8},
keywords = {Object oriented metrics, Test Case Minimization, machine learning, object oriented testing}
}

@article{10.1016/j.ins.2019.01.041,
author = {Chen, Hongmei and Li, Tianrui and Fan, Xin and Luo, Chuan},
title = {Feature selection for imbalanced data based on neighborhood rough sets},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {483},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.01.041},
doi = {10.1016/j.ins.2019.01.041},
journal = {Inf. Sci.},
month = may,
pages = {1–20},
numpages = {20},
keywords = {Rough set theory, Feature selection, Imbalanced data, Discernibility matrix}
}

@article{10.1016/j.jss.2021.111062,
author = {Luu, Quang-Hung and Lau, Man F. and Ng, Sebastian P.H. and Chen, Tsong Yueh},
title = {Testing multiple linear regression systems with metamorphic testing},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111062},
doi = {10.1016/j.jss.2021.111062},
journal = {J. Syst. Softw.},
month = dec,
numpages = {21},
keywords = {Multiple linear regression, Metamorphic testing, Metamorphic relation}
}

@inproceedings{10.1145/259526.259548,
author = {Cheatham, Thomas J. and Yoo, Jungsoon P. and Wahl, Nancy J.},
title = {Software testing: a machine learning experiment},
year = {1995},
isbn = {0897917375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/259526.259548},
doi = {10.1145/259526.259548},
booktitle = {Proceedings of the 1995 ACM 23rd Annual Conference on Computer Science},
pages = {135–141},
numpages = {7},
location = {Nashville, Tennessee, USA},
series = {CSC '95}
}

@inproceedings{10.5555/3504035.3504584,
author = {Zhang, Xuezhou and Zhu, Xiaojin and Wright, Stephen},
title = {Training set debugging using trusted items},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {Training set bugs are flaws in the data that adversely affect machine learning. The training set is usually too large for manual inspection, but one may have the resources to verify a few trusted items. The set of trusted items may not by itself be adequate for learning, so we propose an algorithm that uses these items to identify bugs in the training set and thus improves learning. Specifically, our approach seeks the smallest set of changes to the training set labels such that the model learned from this corrected training set predicts labels of the trusted items correctly. We flag the items whose labels are changed as potential bugs, whose labels can be checked for veracity by human experts. To find the bugs in this way is a challenging combinatorial bilevel optimization problem, but it can be relaxed into a continuous optimization problem. Experiments on toy and real data demonstrate that our approach can identify training set bugs effectively and suggest appropriate changes to the labels. Our algorithm is a step toward trustworthy machine learning.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {549},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@article{10.1016/j.neucom.2015.10.042,
author = {Zakaryazad, Ashkan and Duman, Ekrem},
title = {A profit-driven Artificial Neural Network (ANN) with applications to fraud detection and direct marketing},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {175},
number = {PA},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2015.10.042},
doi = {10.1016/j.neucom.2015.10.042},
abstract = {The rapid growth in data capture and computational power has led to an increasing focus on data-driven research. So far, most of the research is focused on predictive modeling using statistical optimization, while profit maximization has been given less priority. It is exactly this gap that will be addressed in this study by taking a profit-driven approach to develop a profit-driven Artificial Neural Network (ANN) classification technique. In order to do this, we have first introduced an ANN model with a new penalty function which gives variable penalties to the misclassification of instances considering their individual importance (profit of correctly classification and/or cost of misclassification) and then we have considered maximizing the total net profit. In order to generate individual penalties, we have modified the sum of squared errors (SSE) function by changing its values with respect to profit of each instance. We have implemented different versions of ANN of which five of them are new ones contributed in this study and two benchmarks from relevant literature. We appraise the effectiveness of the proposed models on two real-life data sets from fraud detection and a University of California Irvine (UCI) repository data set about bank direct marketing. For the comparison, we have considered both statistical and profit-driven performance metrics. Empirical results revealed that, although in most cases the statistical performance of new models are not better than previous ones, they turn out to be better when profit is the concern.},
journal = {Neurocomput.},
month = jan,
pages = {121–131},
numpages = {11},
keywords = {Individual profit and cost, Neural network, Profit-driven neural network, Sum of squared errors (SSE)}
}

@article{10.1016/j.neucom.2021.06.082,
author = {Ye, Aoshuang and Wang, Lina and Zhao, Lei and Ke, Jianpeng and Wang, Wenqi and Liu, Qinliang},
title = {RapidFuzz: Accelerating fuzzing via Generative Adversarial Networks},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {460},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.06.082},
doi = {10.1016/j.neucom.2021.06.082},
journal = {Neurocomput.},
month = oct,
pages = {195–204},
numpages = {10},
keywords = {AFL, Fuzzing, Generative Adversarial Networks}
}

@article{10.1016/j.dss.2015.02.003,
author = {Hu, Yong and Feng, Bin and Mo, Xizhu and Zhang, Xiangzhou and Ngai, E.W.T. and Fan, Ming and Liu, Mei},
title = {Cost-sensitive and ensemble-based prediction model for outsourced software project risk prediction},
year = {2015},
issue_date = {April 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {72},
number = {C},
issn = {0167-9236},
url = {https://doi.org/10.1016/j.dss.2015.02.003},
doi = {10.1016/j.dss.2015.02.003},
abstract = {Nowadays software is mainly developed through outsourcing and it has become one of the most important business practice strategies for the software industry. However, outsourcing projects are often affiliated with high failure rate. Therefore to ensure success in outsourcing projects, past research has aimed to develop intelligent risk prediction models to evaluate the success rate and cost-effectiveness of software projects. In this study, we first summarized related work over the past 20years and observed that all existing prediction models assume equal misclassification costs, neglecting actual situations in the management of software projects. In fact, overlooking project failure is far more serious than the misclassification of a success-prone project as a failure. Moreover, ensemble learning, a technique well-recognized to improve prediction performance in other fields, has not yet been comprehensively studied in software project risk prediction. This study aims to close the research gaps by exploring cost-sensitive analysis and classifier ensemble methods. Comparative analysis with T-test on 60 different risk prediction models using 327 outsourced software project samples suggests that the ideal model is a homogeneous ensemble model of decision trees (DT) based on bagging. Interestingly, DT underperformed Support Vector Machine (SVM) in accuracy (i.e., assuming equal misclassification cost), but outperformed in cost-sensitive analysis under the proposed framework. In conclusion, this study proposes the first cost-sensitive and ensemble-based hybrid modeling framework (COSENS) for software project risk prediction. In addition, it establishes a new rigorous evaluation standard for assessing software risk prediction models by considering misclassification costs. Display Omitted The first cost-sensitive and ensemble framework to predict software project riskA comprehensive T-test method was used for rigorous performance comparison.A total of 60 models were built and compared based on 327 real project samples.Decision tree underperformed SVM in accuracy, but outperformed in cost analysis.A new rigorous model standard for software project risk analysis is established.},
journal = {Decis. Support Syst.},
month = apr,
pages = {11–23},
numpages = {13},
keywords = {COSENS, Cost-sensitive, Ensemble, Outsourced software project, Risk management, Risk prediction}
}

@article{10.3233/JIFS-181998,
author = {Jahan, Hosney and Feng, Ziliang and Mahmud, S.M. Hasan and Dong, Penglin},
title = {Version specific test case prioritization approach based on artificial neural network},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {36},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-181998},
doi = {10.3233/JIFS-181998},
abstract = {Regression testing involves validating a software system after modification to ensure that the previous bugs have been fixed and no new error has been raised. Finding faults early and increasing the fault detection rate are the main objectives of regression testing. A common technique involves re-executing the whole test suite, which is time consuming. Test case prioritization aims to schedule the test cases in an order that could achieve the regression testing goals early in the testing phase. Recently, machine learning techniques have been extensively used in regression testing to make it more effective and efficient. In this paper, we propose and investigate whether an Artificial Neural Network (ANN)-based approach can improve the version specific test case prioritization approach. The proposed approach utilizes the combination of test cases complexity information and software modification information with an ANN, for early detection of critical faults. Three new factors have been proposed, based on which an ANN is trained and finally it can automatically assign priorities to new test cases. The proposed approach is empirically evaluated with two software applications. Effectiveness metrics, such as fault detection rate, accuracy, precision, and recall are examined. The results suggest that the proposed approach is both effective and feasible.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6181–6194},
numpages = {14},
keywords = {Regression testing, test case prioritization, artificial neural network, fault detection capability}
}

@inproceedings{10.1145/1137983.1138012,
author = {Knab, Patrick and Pinzger, Martin and Bernstein, Abraham},
title = {Predicting defect densities in source code files with decision tree learners},
year = {2006},
isbn = {1595933972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1137983.1138012},
doi = {10.1145/1137983.1138012},
abstract = {With the advent of open source software repositories the data available for defect prediction in source files increased tremendously. Although traditional statistics turned out to derive reasonable results the sheer amount of data and the problem context of defect prediction demand sophisticated analysis such as provided by current data mining and machine learning techniques.In this work we focus on defect density prediction and present an approach that applies a decision tree learner on evolution data extracted from the Mozilla open source web browser project. The evolution data includes different source code, modification, and defect measures computed from seven recent Mozilla releases. Among the modification measures we also take into account the change coupling, a measure for the number of change-dependencies between source files. The main reason for choosing decision tree learners, instead of for example neural nets, was the goal of finding underlying rules which can be easily interpreted by humans. To find these rules, we set up a number of experiments to test common hypotheses regarding defects in software entities. Our experiments showed, that a simple tree learner can produce good results with various sets of input data.},
booktitle = {Proceedings of the 2006 International Workshop on Mining Software Repositories},
pages = {119–125},
numpages = {7},
keywords = {data mining, decision tree learner, defect prediction},
location = {Shanghai, China},
series = {MSR '06}
}

@inproceedings{10.1145/2989238.2989242,
author = {Dehghan, Ali and Blincoe, Kelly and Damian, Daniela},
title = {A hybrid model for task completion effort estimation},
year = {2016},
isbn = {9781450343954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2989238.2989242},
doi = {10.1145/2989238.2989242},
abstract = {Predicting time and effort of software task completion has been an active area of research for a long time. Previous studies have proposed predictive models based on either text data or metadata of software tasks to estimate either completion time or completion effort of software tasks, but there is a lack of focus in the literature on integrating all sets of attributes together to achieve better performing models. We first apply the previously proposed models on the datasets of two IBM commercial projects called RQM and RTC to find the best performing model in predicting task completion effort on each set of attributes. Then we propose an approach to create a hybrid model based on selected individual predictors to achieve more accurate and stable results in early prediction of task completion effort and to make sure the model is not bounded to some attributes and consequently is adoptable to a larger number of tasks. Categorizing task completion effort values into Low and High labels based on their measured median value, we show that our hybrid model provides 3-8% more accuracy in early prediction of task completion effort compared to the best individual predictors.},
booktitle = {Proceedings of the 2nd International Workshop on Software Analytics},
pages = {22–28},
numpages = {7},
keywords = {Mining software repositories, effort estimation, ensemble learning, machine learning, task completion effort},
location = {Seattle, WA, USA},
series = {SWAN 2016}
}

@article{10.5555/1718140.1718142,
author = {Podgorelec, Vili},
title = {Improved mining of software complexity data on evolutionary filtered training sets},
year = {2009},
issue_date = {November 2009},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
volume = {6},
number = {11},
issn = {1790-0832},
abstract = {With the evolution of information technology and software systems, software reliability has become one of the most important topics of software engineering. As the dependency of society on software systems increase, so increases also the importance of efficient software fault prediction. In this paper we present a new approach to improving the classification of faulty software modules. The proposed approach is based on filtering training sets with the introduction of data outliers identification and removal method. The method uses an ensemble of evolutionary induced decision trees to identify the outliers. We argue that a classifier trained by a filtered dataset captures a more general knowledge model and should therefore perform better also on unseen cases. The proposed method is applied on a real-world software reliability analysis dataset and the obtained results are discussed.},
journal = {WSEAS Trans. Info. Sci. and App.},
month = nov,
pages = {1751–1760},
numpages = {10},
keywords = {classification, data mining, evolutionary decision trees, filtering training sets, search-based software engineering, software fault prediction}
}

@inproceedings{10.1145/3148453.3306274,
author = {Ali, Kamran and Xia, Xiaoling},
title = {Revisiting and Rethinking on the Technical Aspects of Software Requirements},
year = {2018},
isbn = {9781450363525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3148453.3306274},
doi = {10.1145/3148453.3306274},
abstract = {Software Requirement specification document is the building block in software development. SRS plays a significantly important role for developing any type of Software. This is the first deliverable to the client. This paper presents the key features and technical aspects of SRS document which help in resolving myriad problems which occur during designing and developing of Software Application. In this study, we will cover major areas of SRS document which will be of crucial help to whole project team for programming any sort of application like web application, mobile application and desktop application.},
booktitle = {Proceedings of the International Conference on Information Technology and Electrical Engineering 2018},
articleno = {35},
numpages = {4},
keywords = {Human errors, Software Engineering, Software fault, Software requirement specification},
location = {Xiamen, Fujian, China},
series = {ICITEE '18}
}

@article{10.1145/3375572.3375582,
author = {Fontana, Francesca Arcelli and Perrouin, Gilles and Ampatzoglou, Apostolos and Archer, Mathieu and Walter, Bartosz and Cordy, Maxime and Palomba, Fabio and Devroey, Xavier},
title = {MALTESQUE 2019 Workshop Summary},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3375572.3375582},
doi = {10.1145/3375572.3375582},
abstract = {Welcome to the third edition of the workshop on Machine Learn- ing Techniques for Software Quality Evaluation (MaLTeSQuE 2019), held in Tallinn, Estonia, August 27th, 2019, co-located with ESEC / FSE 2019. This year MALTESQUE merged with the MASES (Machine Learning and Software Engineering in Symbiosis) work- shop, co-located with the ASE 2018 conference. Ten papers from all over the world were submitted, seven of them were accepted. The program also featured a keynote by Lionel Briand on the use of machine learning to improve software testing.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {34–35},
numpages = {2}
}

@inproceedings{10.1145/2970276.2970300,
author = {Wang, Junjie and Wang, Song and Cui, Qiang and Wang, Qing},
title = {Local-based active classification of test report to assist crowdsourced testing},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2970300},
doi = {10.1145/2970276.2970300},
abstract = {In crowdsourced testing, an important task is to identify the test reports that actually reveal fault - true fault, from the large number of test reports submitted by crowd workers. Most existing approaches towards this problem utilized supervised machine learning techniques, which often require users to manually label a large amount of training data. Such process is time-consuming and labor-intensive. Thus, reducing the onerous burden of manual labeling while still being able to achieve good performance is crucial. Active learning is one potential technique to address this challenge, which aims at training a good classifier with as few labeled data as possible. Nevertheless, our observation on real industrial data reveals that existing active learning approaches generate poor and unstable performances on crowdsourced testing data. We analyze the deep reason and find that the dataset has significant local biases. To address the above problems, we propose LOcal-based Active ClassiFication (LOAF) to classify true fault from crowdsourced test reports. LOAF recommends a small portion of instances which are most informative within local neighborhood, and asks user their labels, then learns classifiers based on local neighborhood. Our evaluation on 14,609 test reports of 34 commercial projects from one of the Chinese largest crowdsourced testing platforms shows that our proposed LOAF can generate promising results. In addition, its performance is even better than existing supervised learning approaches which built on large amounts of labelled historical data. Moreover, we also implement our approach and evaluate its usefulness using real-world case studies. The feedbacks from testers demonstrate its practical value.},
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {190–201},
numpages = {12},
keywords = {Active Learning, Crowdsourced Testing, Test Report Classification},
location = {Singapore, Singapore},
series = {ASE '16}
}

@inproceedings{10.5555/3370272.3370296,
author = {Sabor, Korosh K. and Hamou-Lhadj, Abdelwahab and Trabelsi, Abdelaziz and Hassine, Jameleddine},
title = {Predicting bug report fields using stack traces and categorical attributes},
year = {2019},
publisher = {IBM Corp.},
address = {USA},
abstract = {Studies have shown that the lack of information about a bug often delays the bug report (BR) resolution process. Existing approaches rely mainly on BR descriptions as the main features for predicting BR fields. BR descriptions, however, tend to be informal and not always reliable. In this study, we show that the use of stack traces, a more formal source, and categorical features of BRs provides better accuracy than BR descriptions. We focus on the prediction of faulty components and products, two important BR fields, often used by developers to investigate a bug. Our method relies on mining historical BRs in order to predict faulty components and products of new incoming bugs. We map stack traces of historical BRs to feature vectors, weighted using TF-IDF. The vectors, together with a selected set of BR categorical information, are then fed to a classification algorithm. The method also tackles the problem of unbalanced data. Our approach achieves an average accuracy of 58% (when predicting faulty components) and 60% (when predicting faulty products) on Eclipse dataset and 70% (when predicting faulty components) and 70% (when predicting faulty products) on Gnome dataset. For both datasets, our approach improves over the method that uses BR descriptions by a large margin, up to an average of 46%.},
booktitle = {Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering},
pages = {224–233},
numpages = {10},
keywords = {machine learning, mining software repositories, software bugs reports, software maintenance and evolution},
location = {Toronto, Ontario, Canada},
series = {CASCON '19}
}

@inproceedings{10.1109/ASE.2009.76,
author = {Shivaji, Shivkumar and Jr., E. James Whitehead and Akella, Ram and Kim, Sunghun},
title = {Reducing Features to Improve Bug Prediction},
year = {2009},
isbn = {9780769538914},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2009.76},
doi = {10.1109/ASE.2009.76},
abstract = {Recently, machine learning classifiers have emerged as a way to predict the existence of a bug in a change made to a source code file. The classifier is first trained on software history data, and then used to predict bugs. Two drawbacks of existing classifier-based bug prediction are potentially insufficient accuracy for practical use, and use of a large number of features. These large numbers of features adversely impact scalability and accuracy of the approach. This paper proposes a feature selection technique applicable to classification-based bug prediction. This technique is applied to predict bugs in software changes, and performance of Naive Bayes and Support Vector Machine (SVM) classifiers is characterized.},
booktitle = {Proceedings of the 24th IEEE/ACM International Conference on Automated Software Engineering},
pages = {600–604},
numpages = {5},
keywords = {Bug prediction, Feature Selection, Machine Learning, Reliability},
series = {ASE '09}
}

@article{10.4018/IJDWM.2020040104,
author = {Wang, TianTian and Wang, KeChao and Su, XiaoHong and Liu, Lin},
title = {Data Mining in Programs: Clustering Programs Based on Structure Metrics and Execution Values},
year = {2020},
issue_date = {Apr 2020},
publisher = {IGI Global},
address = {USA},
volume = {16},
number = {2},
issn = {1548-3924},
url = {https://doi.org/10.4018/IJDWM.2020040104},
doi = {10.4018/IJDWM.2020040104},
abstract = {Software exists in various control systems, such as security-critical systems and so on. Existing program clustering methods are limited in identifying functional equivalent programs with different syntactic representations. To solve this problem, firstly, a clustering method based on structured metric vectors was proposed to quickly identify structurally similar programs from a large number of existing programs. Next, a clustering method based on similar execution value sequences was proposed, to accurately identify the functional equivalent programs with code variations. This approach has been applied in automatic program repair, to identify sample programs from a large pool of template programs. The average purity value is 0.95576 and the average entropy is 0.15497. This means that the clustering partition is consistent with the expected partition.},
journal = {Int. J. Data Warehous. Min.},
month = apr,
pages = {48–63},
numpages = {16},
keywords = {Clustering, Data Mining, Program Repair, Structural Metrics, Value Sequence}
}

@article{10.1007/s11219-018-9439-1,
author = {K\i{}ra\c{c}, M. Furkan and Aktemur, Bar\i{}\c{s} and S\"{o}zer, Hasan and Gebizli, Ceren \c{S}ahin},
title = {Automatically learning usage behavior and generating event sequences for black-box testing of reactive systems},
year = {2019},
issue_date = {June      2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9439-1},
doi = {10.1007/s11219-018-9439-1},
abstract = {We propose a novel technique based on recurrent artificial neural networks to generate test cases for black-box testing of reactive systems. We combine functional testing inputs that are automatically generated from a model together with manually-applied test cases for robustness testing. We use this combination to train a long short-term memory (LSTM) network. As a result, the network learns an implicit representation of the usage behavior that is liable to failures. We use this network to generate new event sequences as test cases. We applied our approach in the context of an industrial case study for the black-box testing of a digital TV system. LSTM-generated test cases were able to reveal several faults, including critical ones, that were not detected with existing automated or manual testing activities. Our approach is complementary to model-based and exploratory testing, and the combined approach outperforms random testing in terms of both fault coverage and execution time.},
journal = {Software Quality Journal},
month = jun,
pages = {861–883},
numpages = {23},
keywords = {Black-box testing, Learning usage behavior, Long short-term memory networks, Recurrent neural networks, Test case generation}
}

@article{10.1007/s11704-020-0190-y,
author = {Zhang, Guozhen and Liu, Yi and Yang, Hailong and Xu, Jun and Qian, Depei},
title = {User-level failure detection and auto-recovery of parallel programs in HPC systems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {6},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-020-0190-y},
doi = {10.1007/s11704-020-0190-y},
abstract = {As the mean-time-between-failures (MTBF) continues to decline with the increasing number of components on large-scale high performance computing (HPC) systems, program failures might occur during the execution period with high probability. Ensuring successful execution of the HPC programs has become an issue that the unprivileged users should be concerned. From the user perspective, if the program failure cannot be detected and handled in time, it would waste resources and delay the progress of program execution. Unfortunately, the unprivileged users are unable to perform program state checking due to execution control by the job management system as well as the limited privilege. Currently, automated tools for supporting user-level failure detection and auto-recovery of parallel programs in HPC systems are missing. This paper proposes an innovative method for the unprivileged user to achieve failure detection of job execution and automatic resubmission of failed jobs. The state checker in our method is encapsulated as an independent job to reduce interference with the user jobs. In addition, we propose a dual-checker mechanism to improve the robustness of our approach. We implement the proposed method as a tool named automatic re-launcher (ARL) and evaluate it on the Tianhe-2 system. Experiment results show that ARL can detect the execution failures effectively on Tianhe-2 system. In addition, the communication and performance overhead caused by ARL is negligible. The good scalability of ARL makes it applicable for large-scale HPC systems.},
journal = {Front. Comput. Sci.},
month = dec,
numpages = {12},
keywords = {high performance computing, parallel program, failure detection, failure auto-recovery}
}

@inproceedings{10.1007/978-3-030-87007-2_14,
author = {Peng\H{o}, Edit},
title = {Examining the Bug Prediction Capabilities of Primitive Obsession Metrics},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_14},
doi = {10.1007/978-3-030-87007-2_14},
abstract = {Bug prediction is an approach that helps make bug detection more automated during software development. Based on a bug dataset a prediction model is built to locate future bugs. Bug datasets contain information about previous defects in the code, process metrics, or source code metrics, etc. As code smells can indicate potential flaws in the source code, they can be used for bug prediction as well.In our previous work, we introduced several source code metrics to detect and describe the occurrence of Primitive Obsession in Java. This paper is a further study on three of the Primitive Obsession metrics. We integrated them into an existing, source code metrics-based bug dataset, and studied the effectiveness of the prediction built upon it. We performed a 10 fold cross-validation on the whole dataset and a cross-project validation as well. We compared the new models with the results of the original dataset. While the cross-validation showed no significant change, in the case of the cross-project validation, we have found that the amount of improvement exceeded the amount of deterioration by 5%. Furthermore, the variance added to the dataset was confirmed by correlation and PCA calculations.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {185–200},
numpages = {16},
keywords = {Bug prediction, Code smells, Primitive obsession, Static analysis, Refactoring},
location = {Cagliari, Italy}
}

@inproceedings{10.1145/3183440.3183487,
author = {Saha, Ripon K. and Yoshida, Hiroaki and Prasad, Mukul R. and Tokumoto, Susumu and Takayama, Kuniharu and Nanba, Isao},
title = {Elixir: an automated repair tool for Java programs},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183487},
doi = {10.1145/3183440.3183487},
abstract = {Object-oriented (OO) languages, by design, make heavy use of method invocations (MI). Unsurprisingly, a large fraction of OO-program bug patches also involve method invocations. However, current program repair techniques incorporate MIs in very limited ways, ostensibly to avoid searching the huge repair space that method invocations afford. To address this challenge, in previous work, we proposed a generate-and-validate repair technique which can effectively synthesize patches from a repair space rich in method invocation expressions, by using a machine-learned model to rank the space of concrete repairs. In this paper we describe the tool Elixir that instantiates this technique for the repair of Java programs. We describe the architecture, user-interface, and salient features of Elixir, and specific use-cases it can be applied in. We also report on our efforts towards practical deployment of Elixir within our organization, including the initial results of a trial of Elixir on a project of interest to potential customers. A video demonstrating Elixir is available at: https://elixir-tool.github.io/demo-video.html},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {77–80},
numpages = {4},
keywords = {OOP, automatic program repair, machine learning},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3278142.3278147,
author = {Falessi, Davide and Moede, Max Jason},
title = {Facilitating feasibility analysis: the pilot defects prediction dataset maker},
year = {2018},
isbn = {9781450360562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278142.3278147},
doi = {10.1145/3278142.3278147},
abstract = {Our industrial experience in institutionalizing defect prediction models in the software industry shows that the first step is to measure prediction metrics and defects to assess the feasibility of the tool, i.e., if the accuracy of the defect prediction tool is higher than of a random predictor. However, computing prediction metrics is time consuming and error prone. Thus, the feasibility analysis has a cost which needs some initial investment by the potential clients. This initial investment acts as a barrier for convincing potential clients of the benefits of institutionalizing a software prediction model. To reduce this barrier, in this paper we present the Pilot Defects Prediction Dataset Maker (PDPDM), a desktop application for measuring metrics to use for defect prediction. PDPDM receives as input the repository’s information of a software project, and it provides as output, in an easy and replicable way, a dataset containing a set of 17 well-defined product and process metrics, that have been shown to be useful for defect prediction, such as size and smells. PDPDM avoids the use of outdated datasets and it allows researchers and practitioners to create defect datasets without the need to write any lines of code.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Software Analytics},
pages = {15–18},
numpages = {4},
keywords = {Defects prediction},
location = {Lake Buena Vista, FL, USA},
series = {SWAN 2018}
}

@article{10.1155/2021/8325417,
author = {Amara, Dalila and Fatnassi, Ezzeddine and Ben Arfa Rabai, Latifa and Brada, P\v{r}emek},
title = {An Empirical Assessment and Validation of Redundancy Metrics Using Defect Density as Reliability Indicator},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/8325417},
doi = {10.1155/2021/8325417},
abstract = {Software metrics which are language-dependent are proposed as quantitative measures to assess internal quality factors for both method and class levels like cohesion and complexity. The external quality factors like reliability and maintainability are in general predicted using different metrics of internal attributes. Literature review shows a lack of software metrics which are proposed for reliability measurement and prediction. In this context, a suite of four semantic language-independent metrics was proposed by Mili et al. (2014) to assess program redundancy using Shannon entropy measure. The main objective of these metrics is to monitor program reliability. Despite their important purpose, they are manually computed and only theoretically validated. Therefore, this paper aims to assess the redundancy metrics and empirically validate them as significant reliability indicators. As software reliability is an external attribute that cannot be directly evaluated, we employ other measurable quality factors that represent direct reflections of this attribute. Among these factors, defect density is widely used to measure and predict software reliability based on software metrics. Therefore, a linear regression technique is used to show the usefulness of these metrics as significant indicators of software defect density. A quantitative model is then proposed to predict software defect density based on redundancy metrics in order to monitor software reliability.},
journal = {Sci. Program.},
month = jan,
numpages = {20}
}

@inproceedings{10.1109/IRI51335.2021.00017,
author = {Gudaparthi, Hemanth and Niu, Nan and Wang, Boyang and Savolainen, Juha},
title = {Reliability of Convolutional Neural Networks: Failure Metrics with Metamorphic Test Cases},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IRI51335.2021.00017},
doi = {10.1109/IRI51335.2021.00017},
abstract = {The data-driven software development paradigm and the uncertain nature of deep neural networks bring new challenges for reliability engineering. In autonomous driving and other safety-critical domains, high reliability must be assured. However, failure metrics measuring reliability post deployment can be costly. To explore more efficient ways of assessing reliability, we leverage metamorphic testing where a follow-up test case (TC) can be automatically generated to account for unseen conditions once a source TC is given. We further determine source TCs by investigating various TC prioritization strategies based on risk, fault, similarity, and coverage. Our experiment on a convolutional neural network's image classifications shows that TC priorities determined by code coverage are prominent in exposing reliability issues, combined with the metamorphic TCs generated by semantic input data changes. The results also show that, in order to safely operate the neural networks, reliability engineers shall pay attention to the potential network structural changes and the evolving requirements-level risks.},
booktitle = {2021 IEEE 22nd International Conference on Information Reuse and Integration for Data Science (IRI)},
pages = {75–82},
numpages = {8},
location = {Las Vegas, NV, USA}
}

@inproceedings{10.1007/978-3-030-81682-7_9,
author = {Rosenbauer, Lukas and P\"{a}tzel, David and Stein, Anthony and H\"{a}hner, J\"{o}rg},
title = {An Organic Computing System for&nbsp;Automated Testing},
year = {2021},
isbn = {978-3-030-81681-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-81682-7_9},
doi = {10.1007/978-3-030-81682-7_9},
abstract = {Testing is a vital part of the development of a new software product. With the rise of test automation, companies more and more rely on large sets of test cases. This leads to situations in which it is unfeasible to run all tests due to a limited time budget which eventually results in the need for selecting an optimal subset of tests to execute. Recently, this test selection problem has been approached using machine learning methods. In this work, we design an Organic Computing (OC) system which makes use of these methods. While OC design techniques have originally been targeted at creating embedded systems, we show that these methodologies can be employed to software verification as well. We are able to demonstrate that the implemented system is a robust and highly autonomous solution which fits modern development practices such as continuous integration well.},
booktitle = {Architecture of Computing Systems: 34th International Conference, ARCS 2021, Virtual Event, June 7–8, 2021, Proceedings},
pages = {135–149},
numpages = {15},
keywords = {System architecture, Testing, Continuous integration, Organic computing}
}

@inproceedings{10.1145/2915970.2916004,
author = {Pfahl, Dietmar and Karus, Siim and Stavnycha, Myroslava},
title = {Improving expert prediction of issue resolution time},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2916004},
doi = {10.1145/2915970.2916004},
abstract = {Predicting the resolution times of issue reports in software development is important, because it helps allocate resources adequately. However, issue resolution time (IRT) prediction is difficult and prediction quality is limited. A common approach in industry is to base predictions on expert knowledge. While this manual approach requires the availability and effort of experts, automated approaches using data mining and machine learning techniques require a small upfront investment for setting up the data collection and analysis infrastructure as well as the availability of sufficient past data for model building. Several approaches for automated IRT prediction have been proposed and evaluated. The aim of our study was (1) to compare the prediction quality of expert-based IRT prediction in a software company located in Estonia with that of various fully automated IRT prediction approaches proposed and used by other researchers, including k-means clustering, k-nearest neighbor classification, Na\"{\i}ve Bayes classification, decision trees, random forest (RF) and ordered logistic regression (OLR), and (2) to improve the current IRT prediction quality in the company at hand. For our study, we analyzed issue reports collected by the company in the period from April 2011 to January 2015. Regarding our first goal, we found that experts in the case company were able to predict IRTs approximately 50% of the time within the range of ±10% of the actual IRTs. In addition, 67% of the experts' predictions have an absolute error that is less or equal 0.5 hours. When applying the automated approaches used by other researchers to the company's data, we observed lower predictive quality as compared to IRT predictions made by the company's experts, even for the best-performing approaches RF and OLR. Regarding our second goal, after unsuccessfully experimenting with improvements to the RF and OLR based approaches, we managed to develop models based on text analysis that achieved a prediction quality at par or better than that achieved by company experts.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {42},
numpages = {6},
keywords = {expert prediction, issue report, k-means, k-nearest neighbors, latent semantic analysis, machine learning, na\"{\i}ve bayes classifier, ordered logistic regression, random forest, resolution time},
location = {Limerick, Ireland},
series = {EASE '16}
}

@inproceedings{10.1007/978-3-030-30508-6_55,
author = {Wang, Chunyan and Ge, Weimin and Li, Xiaohong and Feng, Zhiyong},
title = {DCT: Differential Combination Testing of Deep Learning Systems},
year = {2019},
isbn = {978-3-030-30507-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30508-6_55},
doi = {10.1007/978-3-030-30508-6_55},
abstract = {Deep learning (DL) systems are increasingly used in security-related fields, where the accuracy and predictability of DL systems are critical. However the DL models are difficult to test and existing DL testing relies heavily on manually labeled data and often fails to expose erroneous behavior for corner inputs. In this paper, we propose Differential Combination Testing (DCT), an automated DL testing tool for systematically detecting the erroneous behavior of more corner cases without relying on manually labeled input data or manually checking the correctness of the output behavior. Our tool aims at automatically generating test cases, that is, applying image combination transformations to seed images to systematically generate synthetic images that can achieve high neuron coverage and trigger inconsistencies between multiple similar DL models. In addition, DCT utilizes multiple DL models with similar functions as cross-references, so that input data no longer must be manually marked and the correctness of output behavior can be automatically checked. The results show that DCT can find thousands of erroneous corner behaviors in the most commonly used DL models effectively and quickly, which can better detect the reliability and robustness of DL systems.},
booktitle = {Artificial Neural Networks and Machine Learning – ICANN 2019: Image Processing: 28th International Conference on Artificial Neural Networks, Munich, Germany, September 17–19, 2019, Proceedings, Part III},
pages = {697–710},
numpages = {14},
keywords = {Deep learning, Differential testing, Image transformation, Deep neural networks},
location = {Munich, Germany}
}

@inproceedings{10.1109/ICSE.2019.00075,
author = {Yatish, Suraj and Jiarpakdee, Jirayus and Thongtanunam, Patanamon and Tantithamthavorn, Chakkrit},
title = {Mining software defects: should we consider affected releases?},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00075},
doi = {10.1109/ICSE.2019.00075},
abstract = {With the rise of the Mining Software Repositories (MSR) field, defect datasets extracted from software repositories play a foundational role in many empirical studies related to software quality. At the core of defect data preparation is the identification of post-release defects. Prior studies leverage many heuristics (e.g., keywords and issue IDs) to identify post-release defects. However, such the heuristic approach is based on several assumptions, which pose common threats to the validity of many studies. In this paper, we set out to investigate the nature of the difference of defect datasets generated by the heuristic approach and the realistic approach that leverages the earliest affected release that is realistically estimated by a software development team for a given defect. In addition, we investigate the impact of defect identification approaches on the predictive accuracy and the ranking of defective modules that are produced by defect models. Through a case study of defect datasets of 32 releases, we find that that the heuristic approach has a large impact on both defect count datasets and binary defect datasets. Surprisingly, we find that the heuristic approach has a minimal impact on defect count models, suggesting that future work should not be too concerned about defect count models that are constructed using heuristic defect datasets. On the other hand, using defect datasets generated by the realistic approach lead to an improvement in the predictive accuracy of defect classification models.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {654–665},
numpages = {12},
keywords = {defect prediction models, empirical software engineering, mining software repositories, software quality},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1109/ICTAI.2006.23,
author = {Challagulla, Venkata U. B. and Bastani, Farokh B. and Yen, I-Ling},
title = {A Unified Framework for Defect Data Analysis Using the MBR Technique},
year = {2006},
isbn = {0769527280},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICTAI.2006.23},
doi = {10.1109/ICTAI.2006.23},
abstract = {Failures of mission-critical software systems can have catastrophic consequences and, hence, there is strong need for scientifically rigorous methods for assuring high system reliability. To reduce the V&amp;V cost for achieving high confidence levels, quantitatively based software defect prediction techniques can be used to effectively estimate defects from prior data. Better prediction models facilitate better project planning and risk/cost estimation. Memory Based Reasoning (MBR) is one such classifier that quantitatively solves new cases by reusing knowledge gained from past experiences. However, it can have different configurations by varying its input parameters, giving potentially different predictions. To overcome this problem, we develop a framework that derives the optimal configuration of an MBR classifier for software defect data, by logical variation of its configuration parameters. We observe that this adaptive MBR technique provides a flexible and effective environment for accurate prediction of mission-critical software defect data.},
booktitle = {Proceedings of the 18th IEEE International Conference on Tools with Artificial Intelligence},
pages = {39–46},
numpages = {8},
series = {ICTAI '06}
}

@inproceedings{10.1145/3460319.3464801,
author = {Dunn, Isaac and Pouget, Hadrien and Kroening, Daniel and Melham, Tom},
title = {Exposing previously undetectable faults in deep neural networks},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464801},
doi = {10.1145/3460319.3464801},
abstract = {Existing methods for testing DNNs solve the oracle problem by constraining the raw features (e.g. image pixel values) to be within a small distance of a dataset example for which the desired DNN output is known. But this limits the kinds of faults these approaches are able to detect. In this paper, we introduce a novel DNN testing method that is able to find faults in DNNs that other methods cannot. The crux is that, by leveraging generative machine learning, we can generate fresh test inputs that vary in their high-level features (for images, these include object shape, location, texture, and colour). We demonstrate that our approach is capable of detecting deliberately injected faults as well as new faults in state-of-the-art DNNs, and that in both cases, existing methods are unable to find these faults.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {56–66},
numpages = {11},
keywords = {Deep Learning, Generative Adversarial Networks, Robustness},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1007/978-3-030-52237-7_9,
author = {Chhatbar, Darshak and Ahmed, Umair Z. and Kar, Purushottam},
title = {MACER: A Modular Framework for Accelerated Compilation Error Repair},
year = {2020},
isbn = {978-3-030-52236-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-52237-7_9},
doi = {10.1007/978-3-030-52237-7_9},
abstract = {Automated compilation error repair, the problem of suggesting fixes to buggy programs that fail to compile, has pedagogical applications for novice programmers who find compiler error messages cryptic and unhelpful. Existing works frequently involve black-box application of generative models, e.g. sequence-to-sequence prediction (TRACER) or reinforcement learning (RLAssist). Although convenient, this approach is inefficient at targeting specific error types as well as increases training costs. We present MACER, a novel technique for accelerated error repair based on a modular segregation of the repair process into repair identification and repair application. MACER uses powerful yet inexpensive learning techniques such as multi-label classifiers and rankers to first identify the type of repair required and then apply the suggested repair. Experiments indicate that this fine-grained approach offers not only superior error correction, but also much faster training and prediction. On a benchmark dataset of 4K buggy programs collected from actual student submissions, MACER outperforms existing methods by 20% at suggesting fixes for popular errors while being competitive or better at other errors. MACER offers a training time speedup of  over TRACER and  over RLAssist, and a test time speedup of  over both.},
booktitle = {Artificial Intelligence in Education: 21st International Conference, AIED 2020, Ifrane, Morocco, July 6–10, 2020, Proceedings, Part I},
pages = {106–117},
numpages = {12},
keywords = {Introductory programming, Compilation error, Program repair, Multi-label learning, Structured prediction},
location = {Ifrane, Morocco}
}

@phdthesis{10.5555/AAI28001695,
author = {Tizpaz Niari, Saeid and Somenzi, Fabio and Sankaranarayanan, Sriram and Chang, Bor-Yuh Evan and Chaudhuri, Swarat},
advisor = {Pavol, Cerny, and Ashutosh, Trivedi,},
title = {Differential Performance Debugging},
year = {2020},
isbn = {9798664764444},
publisher = {University of Colorado at Boulder},
address = {USA},
abstract = {Differential performance bugs are manifested when the runtime behavior of systems, such as execution time, is unexpectedly different for two or more similar inputs. These bugs are notoriously difficult to detect, explain, and fix since they arise from the performance differential between multiple executions of the system. Differential performance bugs give rise to both performance and security issues: they may lead to poor user experiences, waste crucial hardware resources, and leak confidential information via these differentials.This thesis introduces differential performance debugging, a framework to discover, localize, and mitigate differential performance bugs with a focus on timing side channels and performance defects in web applications and machine learning libraries.We formalize and study the core computational problem in the differential performance debugging as the discriminant learning problem. After establishing its intractability, we propose two data-driven approaches to infer discriminants efficiently. The first approach views the data as independent points and employs clustering algorithms with off-the-shelf decision trees in a novel approach called discriminant regression trees. The second approach views the data as functional points and generalizes the clustering and decision tree inferences with functional data models. We choose decision trees as the core component in the debugging mostly due to their simplicity in the interpretation for (human) users involved in the process as well as for automatic mitigations.These techniques have been implemented in a set of tools to debug and mitigate differential performance defects. On a set of micro-benchmarks, the thesis shows that the differential performance debugging outperforms state-of-the-art techniques in detecting bugs, localizing the root causes, and mitigating them. On the set of larger case studies, the tools have found and explained multiple performance bugs in popular machine learning frameworks such as scikit-learn and side-channel vulnerabilities in critical Java libraries such as OpenJDK and Jetty. The developers have since used the results to fix multiple bugs in their implementations.},
note = {AAI28001695}
}

@inproceedings{10.1145/3361242.3361243,
author = {Wang, Yuehuan and Li, Zenan and Xu, Jingwei and Yu, Ping and Ma, Xiaoxing},
title = {Fast Robustness Prediction for Deep Neural Network},
year = {2019},
isbn = {9781450377010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361242.3361243},
doi = {10.1145/3361242.3361243},
abstract = {Deep neural networks (DNNs) have achieved impressive performance in many difficult tasks. However, DNN models are essentially uninterpretable to humans, and unfortunately prone to adversarial attacks, which hinders their adoption in security and safety-critical scenarios. The robustness of a DNN model, which measures its stableness against adversarial attacks, becomes an important topic in both the machine learning and the software engineering communities. Analytical evaluation of DNN robustness is difficult due to the high-dimensionality of inputs, the huge amount of parameters, and the nonlinear network structure. In practice, the degree of robustness of DNNs is empirically approximated with adversarial searching, which is computationally expensive and cannot be applied in resource constrained settings such as embedded computing. In this paper, we propose to predict the robustness of a DNN model for each input with another DNN model, which takes the output of neurons of the former model as input. We train a regression model to encode the connections between output of the penultimate layer of a DNN model and its robustness. With this trained model, the robustness for an input can be predicted instantaneously. Experiments with MNIST and CIFAR10 datasets and LeNet, VGG and ResNet DNN models were conducted to evaluate the efficacy of the proposed approach. The results indicated that our approach achieved 0.05-0.21 mean absolute errors and significantly outperformed confidence and surprise adequacy-based approaches.},
booktitle = {Proceedings of the 11th Asia-Pacific Symposium on Internetware},
articleno = {11},
numpages = {10},
keywords = {Deep Neural Networks, Prediction, Robustness},
location = {Fukuoka, Japan},
series = {Internetware '19}
}

@article{10.1007/s00521-021-05954-3,
author = {Lin, Guanjun and Xiao, Wei and Zhang, Leo Yu and Gao, Shang and Tai, Yonghang and Zhang, Jun},
title = {Deep neural-based vulnerability discovery demystified: data, model and performance},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {20},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05954-3},
doi = {10.1007/s00521-021-05954-3},
abstract = {Detecting source-code level vulnerabilities at the development phase is a cost-effective solution to prevent potential attacks from happening at the software deployment stage. Many machine learning, including deep learning-based solutions, have been proposed to aid the process of vulnerability discovery. However, these approaches were mainly evaluated on self-constructed/-collected datasets. It is difficult to evaluate the effectiveness of proposed approaches due to lacking a unified baseline dataset. To bridge this gap, we construct a function-level vulnerability dataset from scratch, providing in source-code-label pairs. To evaluate the constructed dataset, a function-level vulnerability detection framework is built to incorporate six mainstream neural network models as vulnerability detectors. We perform experiments to investigate the performance behaviors of the neural model-based detectors using source code as raw input with continuous Bag-of-Words neural embeddings. Empirical results reveal that the variants of recurrent neural networks and convolutional neural network perform well on our dataset, as the former is capable of handling contextual information and the latter learns features from small context windows. In terms of generalization ability, the fully connected network outperforms the other network architectures. The performance evaluation can serve as a reference benchmark for neural model-based vulnerability detection at function-level granularity. Our dataset can serve as ground truth for ML-based function-level vulnerability detection and a baseline for evaluating relevant approaches.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {13287–13300},
numpages = {14},
keywords = {Vulnerability discovery, Deep learning, Function-level, Baseline dataset, Performance evaluation}
}

@inproceedings{10.1145/3293882.3330574,
author = {Li, Xia and Li, Wei and Zhang, Yuqun and Zhang, Lingming},
title = {DeepFL: integrating multiple fault diagnosis dimensions for deep fault localization},
year = {2019},
isbn = {9781450362245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293882.3330574},
doi = {10.1145/3293882.3330574},
abstract = {Learning-based fault localization has been intensively studied recently. Prior studies have shown that traditional Learning-to-Rank techniques can help precisely diagnose fault locations using various dimensions of fault-diagnosis features, such as suspiciousness values computed by various off-the-shelf fault localization techniques. However, with the increasing dimensions of features considered by advanced fault localization techniques, it can be quite challenging for the traditional Learning-to-Rank algorithms to automatically identify effective existing/latent features. In this work, we propose DeepFL, a deep learning approach to automatically learn the most effective existing/latent features for precise fault localization. Although the approach is general, in this work, we collect various suspiciousness-value-based, fault-proneness-based and textual-similarity-based features from the fault localization, defect prediction and information retrieval areas, respectively. DeepFL has been studied on 395 real bugs from the widely used Defects4J benchmark. The experimental results show DeepFL can significantly outperform state-of-the-art TraPT/FLUCCS (e.g., localizing 50+ more faults within Top-1). We also investigate the impacts of deep model configurations (e.g., loss functions and epoch settings) and features. Furthermore, DeepFL is also surprisingly effective for cross-project prediction.},
booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {169–180},
numpages = {12},
keywords = {Deep learning, Fault localization, Mutation testing},
location = {Beijing, China},
series = {ISSTA 2019}
}

@inproceedings{10.1145/1540438.1540446,
author = {Tosun, Ay\c{s}e and Turhan, Burak and Bener, Ay\c{s}e},
title = {Validation of network measures as indicators of defective modules in software systems},
year = {2009},
isbn = {9781605586342},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1540438.1540446},
doi = {10.1145/1540438.1540446},
abstract = {In ICSE'08, Zimmermann and Nagappan show that network measures derived from dependency graphs are able to identify critical binaries of a complex system that are missed by complexity metrics. The system used in their analysis is a Windows product. In this study, we conduct additional experiments on public data to reproduce and validate their results. We use complexity and network metrics from five additional systems. We examine three small scale embedded software and two versions of Eclipse to compare defect prediction performance of these metrics. We select two different granularity levels to perform our experiments: function-level and source file-level. In our experiments, we observe that network measures are important indicators of defective modules for large and complex systems, whereas they do not have significant effects on small scale projects.},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
articleno = {5},
numpages = {9},
keywords = {code metrics, defect prediction, network metrics, public datasets},
location = {Vancouver, British Columbia, Canada},
series = {PROMISE '09}
}

@inproceedings{10.1145/3387940.3391464,
author = {Briem, J\'{o}n Arnar and Smit, Jordi and Sellik, Hendrig and Rapoport, Pavel and Gousios, Georgios and Aniche, Maur\'{\i}cio},
title = {OffSide: Learning to Identify Mistakes in Boundary Conditions},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391464},
doi = {10.1145/3387940.3391464},
abstract = {Mistakes in boundary conditions are the cause of many bugs in software. These mistakes happen when, e.g., developers make use of '&lt;' or '&gt;' in cases where they should have used '&lt;=' or '&gt;='. Mistakes in boundary conditions are often hard to find and manually detecting them might be very time-consuming for developers. While researchers have been proposing techniques to cope with mistakes in the boundaries for a long time, the automated detection of such bugs still remains a challenge. We conjecture that, for a tool to be able to precisely identify mistakes in boundary conditions, it should be able to capture the overall context of the source code under analysis. In this work, we propose a deep learning model that learn mistakes in boundary conditions and, later, is able to identify them in unseen code snippets. We train and test a model on over 1.5 million code snippets, with and without mistakes in different boundary conditions. Our model shows an accuracy from 55% up to 87%. The model is also able to detect 24 out of 41 real-world bugs; however, with a high false positive rate. The existing state-of-the-practice linter tools are not able to detect any of the bugs. We hope this paper can pave the road towards deep learning models that will be able to support developers in detecting mistakes in boundary conditions.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {203–208},
numpages = {6},
keywords = {boundary testing, deep learning for software testing, machine learning for software engineering, machine learning for software testing, software engineering, software testing},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@article{10.1145/2853073.2853083,
author = {Rathore, Santosh Singh and Kumar, Sandeep},
title = {A Decision Tree Regression based Approach for the Number of Software Faults Prediction},
year = {2016},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2853073.2853083},
doi = {10.1145/2853073.2853083},
abstract = {Software fault prediction is an important activity to make software quality assurance (SQA) process more efficient, economic and targeted. Most of earlier works related to software fault prediction have focused on classifying software modules as faulty or non-faulty. However, prediction of the number of faults in a given software module is not adequately investigated. In this paper, we explore the capability of decision tree regression (DTR) for the number of faults prediction in two different scenarios, intra-release prediction and inter-releases prediction for the given software system. The experimental study is performed over five open-source software projects with their nineteen releases collected from the PROMISE data repository. The predictive accuracy of DTR is evaluated using absolute error and relative error, prediction at level l and goodness-of-t measure. The results show that decision tree regression produced significant prediction accuracy for the number of faults prediction in both the considered scenarios. The relative comparison of intra-release and inter-releases fault prediction shows that intra-project prediction produced better accuracy compared to inter-releases prediction across all the datasets},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {1–6},
numpages = {6},
keywords = {Decision Tree Regression, Number of Faults Prediction, Software Fault Prediction}
}

@inproceedings{10.1109/AUTEST.2018.8532509,
author = {Wright, R. Glenn and Kirkland, Larry V.},
title = {A Signals Intelligence Approach to Automated Assessment of Instrument Capabilities},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AUTEST.2018.8532509},
doi = {10.1109/AUTEST.2018.8532509},
abstract = {This paper describes a novel approach using machine learning and artificial intelligence techniques to analyze, describe and assess stimulus and sensor signal characteristics to create a robust and comprehensive description of Automatic Test Equipment (ATE) instrument capabilities. This approach results in a machine language representation providing a more thorough and accurate assessment of ATE stimulus and sensor capabilities that supports digital, analog, and radio frequency (RF) signals and is especially useful for complex RADAR, SONAR, Infrared and other signals where English and natural language descriptions are difficult or impossible to construct. This is accomplished within the structure of IEEE-Std 1641–2010, Signal and Test Definition, with extensions proposed to support machine language renderings of signal descriptions. This approach facilitates use of generic and commercial automated tools and enhances the possibility for interoperability of tools and test programs across DoD ATE.},
booktitle = {2018 IEEE AUTOTESTCON},
pages = {1–8},
numpages = {8},
location = {National Harbor (Oxon Hill), MD, USA}
}

@article{10.1007/s00521-020-05039-7,
author = {Zakeri Nasrabadi, Morteza and Parsa, Saeed and Kalaee, Akram},
title = {Format-aware learn&amp;fuzz: deep test data generation for efficient fuzzing},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {5},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05039-7},
doi = {10.1007/s00521-020-05039-7},
abstract = {Appropriate test data are a crucial factor to succeed in fuzz testing. Most of the real-world applications, however, accept complex structure inputs containing data surrounded by meta-data which is processed in several stages comprising of the parsing and rendering (execution). The complex structure of some input files makes it difficult to generate efficient test data automatically. The success of deep learning to cope with complex tasks, specifically generative tasks, has motivated us to exploit it in the context of test data generation for complicated structures such as PDF files. In this respect, a neural language model (NLM) based on deep recurrent neural networks (RNNs) is used to learn the structure of complex inputs. To target both the parsing and rendering steps of the software under test (SUT), our approach generates new test data while distinguishing between data and meta-data that significantly improve the input fuzzing. To assess the proposed approach, we have developed a modular file format fuzzer, IUST-DeepFuzz. Our experimental results demonstrate the relatively high coverage of MuPDF code by our proposed fuzzer, IUST-DeepFuzz, in comparison with the state-of-the-art tools such as learn&amp;fuzz, AFL, Augmented-AFL, and random fuzzing. In summary, our experiments with many deep learning models revealed the fact that the simpler the deep learning models applied to generate test data, the higher the code coverage of the software under test will be.},
journal = {Neural Comput. Appl.},
month = mar,
pages = {1497–1513},
numpages = {17},
keywords = {Test data generation, File format fuzzing, Code coverage, Neural language model, Recurrent neural network, Deep learning}
}

@article{10.1002/smr.2312,
author = {Zhang, Zhuo and Lei, Yan and Mao, Xiaoguang and Yan, Meng and Xu, Ling and Wen, Junhao},
title = {Improving deep‐learning‐based fault localization with resampling},
year = {2021},
issue_date = {March 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {3},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2312},
doi = {10.1002/smr.2312},
abstract = {Many fault localization approaches recently utilize deep learning to learn an effective localization model showing a fresh perspective with promising results. However, localization models are generally learned from class imbalance datasets; that is, the number of failing test cases is much fewer than passing test cases. It may be highly susceptible to affect the accuracy of learned localization models. Thus, in this paper, we explore using data resampling to reduce the negative effect of the imbalanced class problem and improve the accuracy of learned models of deep‐learning‐based fault localization. Specifically, for deep‐learning‐based fault localization, its learning feature may require duplicate essential data to enhance the weak but beneficial experience incurred by the class imbalance datasets. We leverage the property of test cases (i.e., passing or failing) to identify failing test cases as the duplicate essential data and propose an iterative oversampling approach to resample failing test cases for producing a class balanced test suite. We apply the test case resampling to representative localization models using deep learning. Our empirical results on eight large‐sized programs with real faults and four large‐sized programs with seeded faults show that the test case resampling significantly improves fault localization effectiveness.},
journal = {J. Softw. Evol. Process},
month = mar,
numpages = {18},
keywords = {fault localization, debugging, neural networks, deep learning, resampling}
}

@inproceedings{10.1145/3210459.3210469,
author = {Xiao, Yan and Keung, Jacky and Mi, Qing and Bennin, Kwabena E.},
title = {Bug Localization with Semantic and Structural Features using Convolutional Neural Network and Cascade Forest},
year = {2018},
isbn = {9781450364034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210459.3210469},
doi = {10.1145/3210459.3210469},
abstract = {Background: Correctly localizing buggy files for bug reports together with their semantic and structural information is a crucial task, which would essentially improve the accuracy of bug localization techniques. Aims: To empirically evaluate and demonstrate the effects of both semantic and structural information in bug reports and source files on improving the performance of bug localization, we propose CNN_Forest involving convolutional neural network and ensemble of random forests that have excellent performance in the tasks of semantic parsing and structural information extraction. Method: We first employ convolutional neural network with multiple filters and an ensemble of random forests with multi-grained scanning to extract semantic and structural features from the word vectors derived from bug reports and source files. And a subsequent cascade forest (a cascade of ensembles of random forests) is used to further extract deeper features and observe the correlated relationships between bug reports and source files. CNNLForest is then empirically evaluated over 10,754 bug reports extracted from AspectJ, Eclipse UI, JDT, SWT, and Tomcat projects. Results: The experiments empirically demonstrate the significance of including semantic and structural information in bug localization, and further show that the proposed CNN_Forest achieves higher Mean Average Precision and Mean Reciprocal Rank measures than the best results of the four current state-of-the-art approaches (NPCNN, LR+WE, DNNLOC, and BugLocator). Conclusion: CNNLForest is capable of defining the correlated relationships between bug reports and source files, and we empirically show that semantic and structural information in bug reports and source files are crucial in improving bug localization.},
booktitle = {Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018},
pages = {101–111},
numpages = {11},
keywords = {bug localization, cascade forest, convolutional neural network, semantic information, structural information, word embedding},
location = {Christchurch, New Zealand},
series = {EASE '18}
}

@inproceedings{10.1109/ICSE43902.2021.00107,
author = {Jiang, Nan and Lutellier, Thibaud and Tan, Lin},
title = {CURE: Code-Aware Neural Machine Translation for Automatic Program Repair},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00107},
doi = {10.1109/ICSE43902.2021.00107},
abstract = {Automatic program repair (APR) is crucial to improve software reliability. Recently, neural machine translation (NMT) techniques have been used to fix software bugs automatically. While promising, these approaches have two major limitations. Their search space often does not contain the correct fix, and their search strategy ignores software knowledge such as strict code syntax. Due to these limitations, existing NMT-based techniques underperform the best template-based approaches.We propose CURE, a new NMT-based APR technique with three major novelties. First, CURE pre-trains a programming language (PL) model on a large software codebase to learn developer-like source code before the APR task. Second, CURE designs a new code-aware search strategy that finds more correct fixes by focusing on compilable patches and patches that are close in length to the buggy code. Finally, CURE uses a subword tokenization technique to generate a smaller search space that contains more correct fixes.Our evaluation on two widely-used benchmarks shows that CURE correctly fixes 57 Defects4J bugs and 26 QuixBugs bugs, outperforming all existing APR techniques on both benchmarks.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1161–1173},
numpages = {13},
keywords = {automatic program repair, software reliability},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3460620.3460754,
author = {Cheruvu, Aravind and Vangipuram, Radhakrishna},
title = {A Survey of Similarity Measures for Time stamped Temporal Datasets},
year = {2021},
isbn = {9781450388382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460620.3460754},
doi = {10.1145/3460620.3460754},
abstract = {Temporal transactional databases are transactional databases which store data in a temporal aspect. Usage of similarity of measures in temporal data mining tasks have gained significant importance to retrieve information and interesting patterns in data. It is always crucial to understand and decide what similarity measure we should use while performing a data mining task and this is always driven by the actual data and nature of the temporal data sets. The main objective of this research is to perform a detailed survey of the various similarity measures used in the temporal data mining in recent research contributions. This paper also provides insights on how these similarity measures are used in the Temporal association rule mining algorithms based on the works carried out in the literature.},
booktitle = {International Conference on Data Science, E-Learning and Information Systems 2021},
pages = {193–197},
numpages = {5},
keywords = {algorithms, digitization, industry manufacturing, optimization},
location = {Ma'an, Jordan},
series = {DATA'21}
}

@inproceedings{10.5555/3489146.3489169,
author = {Zhu, Hongyu and Phanishayee, Amar and Pekhimenko, Gennady},
title = {Daydream: accurately estimating the efficacy of optimizations for DNN training},
year = {2020},
isbn = {978-1-939133-14-4},
publisher = {USENIX Association},
address = {USA},
abstract = {Modern deep neural network (DNN) training jobs use complex and heterogeneous software/hardware stacks. The efficacy of software-level optimizations can vary significantly when used in different deployment configurations. It is onerous and error-prone for ML practitioners and system developers to implement each optimization separately, and determine which ones will improve performance in their own configurations. Unfortunately, existing profiling tools do not aim to answer predictive questions such as "How will optimization X affect the performance of my model?". We address this critical limitation, and proposes a new profiling tool, Daydream, to help programmers efficiently explore the efficacy of DNN optimizations. Daydream models DNN execution with a fine-grained dependency graph based on low-level traces collected by CUPTI [49], and predicts runtime by simulating execution based on the dependency graph. Daydream maps the low-level traces using DNN domain-specific knowledge and introduces a set of graph-transformation primitives that can easily model a wide variety of optimizations. We show that Daydream is able to model most mainstream DNN optimization techniques and accurately predict the efficacy of optimizations that will result in significant performance improvements.},
booktitle = {Proceedings of the 2020 USENIX Conference on Usenix Annual Technical Conference},
articleno = {23},
numpages = {16},
series = {USENIX ATC'20}
}

@inproceedings{10.1109/ICSE43902.2021.00046,
author = {Wang, Zan and You, Hanmo and Chen, Junjie and Zhang, Yingyi and Dong, Xuyuan and Zhang, Wenbin},
title = {Prioritizing Test Inputs for Deep Neural Networks via Mutation Analysis},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00046},
doi = {10.1109/ICSE43902.2021.00046},
abstract = {Deep Neural Network (DNN) testing is one of the most widely-used ways to guarantee the quality of DNNs. However, labeling test inputs to check the correctness of DNN prediction is very costly, which could largely affect the efficiency of DNN testing, even the whole process of DNN development. To relieve the labeling-cost problem, we propose a novel test input prioritization approach (called PRIMA) for DNNs via intelligent mutation analysis in order to label more bug-revealing test inputs earlier for a limited time, which facilitates to improve the efficiency of DNN testing. PRIMA is based on the key insight: a test input that is able to kill many mutated models and produce different prediction results with many mutated inputs, is more likely to reveal DNN bugs, and thus it should be prioritized higher. After obtaining a number of mutation results from a series of our designed model and input mutation rules for each test input, PRIMA further incorporates learning-to-rank (a kind of supervised machine learning to solve ranking problems) to intelligently combine these mutation results for effective test input prioritization. We conducted an extensive study based on 36 popular subjects by carefully considering their diversity from five dimensions (i.e., different domains of test inputs, different DNN tasks, different network structures, different types of test inputs, and different training scenarios). Our experimental results demonstrate the effectiveness of PRIMA, significantly outperforming the state-of-the-art approaches (with the average improvement of 8.50%~131.01% in terms of prioritization effectiveness). In particular, we have applied PRIMA to the practical autonomous-vehicle testing in a large motor company, and the results on 4 real-world scene-recognition models in autonomous vehicles further confirm the practicability of PRIMA.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {397–409},
numpages = {13},
keywords = {Deep Learning Testing, Deep Neural Network, Label, Mutation, Test Prioritization},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1145/3385187,
author = {Li, Yangguang and Jiang, Zhen Ming (Jack) and Li, Heng and Hassan, Ahmed E. and He, Cheng and Huang, Ruirui and Zeng, Zhengda and Wang, Mian and Chen, Pinan},
title = {Predicting Node Failures in an Ultra-Large-Scale Cloud Computing Platform: An AIOps Solution},
year = {2020},
issue_date = {April 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3385187},
doi = {10.1145/3385187},
abstract = {Many software services today are hosted on cloud computing platforms, such as Amazon EC2, due to many benefits like reduced operational costs. However, node failures in these platforms can impact the availability of their hosted services and potentially lead to large financial losses. Predicting node failures before they actually occur is crucial, as it enables DevOps engineers to minimize their impact by performing preventative actions. However, such predictions are hard due to many challenges like the enormous size of the monitoring data and the complexity of the failure symptoms. AIOps (Artificial Intelligence for IT Operations), a recently introduced approach in DevOps, leverages data analytics and machine learning to improve the quality of computing platforms in a cost-effective manner. However, the successful adoption of such AIOps solutions requires much more than a top-performing machine learning model. Instead, AIOps solutions must be trustable, interpretable, maintainable, scalable, and evaluated in context. To cope with these challenges, in this article we report our process of building an AIOps solution for predicting node failures for an ultra-large-scale cloud computing platform at Alibaba. We expect our experiences to be of value to researchers and practitioners, who are interested in building and maintaining AIOps solutions for large-scale cloud computing platforms.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {13},
numpages = {24},
keywords = {AIOps, cloud computing, failure prediction, ultra-large-scale platforms}
}

@article{10.4018/IJOSSP.2016040103,
author = {Sureka, Ashish and Lal, Sangeeta and Sardana, Neetu},
title = {Improving Logging Prediction on Imbalanced Datasets: A Case Study on Open Source Java Projects},
year = {2016},
issue_date = {April 2016},
publisher = {IGI Global},
address = {USA},
volume = {7},
number = {2},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2016040103},
doi = {10.4018/IJOSSP.2016040103},
abstract = {Logging is an important yet tough decision for OSS developers. Machine-learning models are useful in improving several steps of OSS development, including logging. Several recent studies propose machine-learning models to predict logged code construct. The prediction performances of these models are limited due to the class-imbalance problem since the number of logged code constructs is small as compared to non-logged code constructs. No previous study analyzes the class-imbalance problem for logged code construct prediction. The authors first analyze the performances of J48, RF, and SVM classifiers for catch-blocks and if-blocks logged code constructs prediction on imbalanced datasets. Second, the authors propose LogIm, an ensemble and threshold-based machine-learning model. Third, the authors evaluate the performance of LogIm on three open-source projects. On average, LogIm model improves the performance of baseline classifiers, J48, RF, and SVM, by 7.38%, 9.24%, and 4.6% for catch-blocks, and 12.11%, 14.95%, and 19.13% for if-blocks logging prediction.},
journal = {Int. J. Open Source Softw. Process.},
month = apr,
pages = {43–71},
numpages = {29},
keywords = {Data Sampling, Debugging, Ensemble Methods, Imbalanced Data, Logging, Machine Learning, Open Source, Tracing}
}

@article{10.1016/j.compind.2016.09.004,
author = {Noyel, Mlanie and Thomas, Philippe and Thomas, Andr and Charpentier, Patrick},
title = {Reconfiguration process for neuronal classification models},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {83},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2016.09.004},
doi = {10.1016/j.compind.2016.09.004},
abstract = {A relearning procedure to adapt neural network model to a change is proposed.This procedure combines control chart and Page Hinkley test.Control chart is used to detect a change.Page-Hinkley test is used to design the relearning dataset.All this procedure is applied to a real case of quality monitoring. In the context of smart industries, learning machines currently have various uses such as self-reconfiguration or self-quality improvement, which can be classification forecasting problems. In this case, learning machines are tools that facilitate the modeling of the physical system. Thus, it is obvious that the model must evolve with changes in the physical system, thereby leading to adaptability/reconfigurability problems. Among the various tools reported previously, real-time systems seem to be the best solution because they can evolve autonomously according to the behavior of the physical system. In the present study, we propose a method for using learning machines efficiently in an evolving context. This method is divided into two components: (1) model conception by defining the objective function and influential factors, setting up data collection, and learning using multilayer perceptrons; and (2) monitoring system conception with the aim of tracking the misclassification rate, determining whether the physical system is drifting, and reacting by model adaptation based on the control charts. This paper focuses on the model monitoring procedure because the model conception procedure is quite classical. The proposed method was applied to a benchmark derived from previous research and then to an industrial case of defect prevention on a robotic coating line for which other methods have proved unsuccessful.},
journal = {Comput. Ind.},
month = dec,
pages = {78–91},
numpages = {14},
keywords = {Classification, Control chart, Learning, Multilayer perceptron, Neural network, Quality, Relearning}
}

@inproceedings{10.1109/SBST.2015.8,
author = {Feldt, Robert and Poulding, Simon},
title = {Broadening the Search in Search-Based Software Testing: It Need Not Be Evolutionary},
year = {2015},
isbn = {9781467370790},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SBST.2015.8},
doi = {10.1109/SBST.2015.8},
abstract = {Search-based software testing (SBST) can potentially help software practitioners create better test suites using less time and resources by employing powerful methods for search and optimization. However, research on SBST has typically focused on only a few search approaches and basic techniques. A majority of publications in recent years use some form of evolutionary search, typically a genetic algorithm, or, alternatively, some other optimization algorithm inspired from nature. This paper argues that SBST researchers and practitioners should not restrict themselves to a limited choice of search algorithms or approaches to optimization. To support our argument we empirically investigate three alternatives and compare them to the de facto SBST standards in regards to performance, resource efficiency and robustness on different test data generation problems: classic algorithms from the optimization literature, bayesian optimization with gaussian processes from machine learning, and nested monte carlo search from game playing / reinforcement learning. In all cases we show comparable and sometimes better performance than the current state-of-the-SBST-art. We conclude that SBST researchers should consider a more general set of solution approaches, more consider combinations and hybrid solutions and look to other areas for how to develop the field.},
booktitle = {Proceedings of the 2015 IEEE/ACM 8th International Workshop on Search-Based Software Testing},
pages = {1–7},
numpages = {7},
keywords = {Machine learning, Operations research, Reinforcement learning, Search-based software testing},
series = {SBST '15}
}

@inproceedings{10.1109/ITSC48978.2021.9564550,
author = {Ning, Pengfei and Tang, Tao and Zhu, Li},
title = {A Deep Learning-Based Test Sequence Automatic Generation Method for Automatic Train Operation in High-Speed Railway System},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC48978.2021.9564550},
doi = {10.1109/ITSC48978.2021.9564550},
abstract = {The automatic train operation (ATO) system for high-speed railway (HSR) can further reduce operation costs, and increase railway transport capacity, which is the future development direction. Testing is an essential technical method to ensure the functional correctness of the ATO system in HSR. Test sequences guide the entire test work, and their quality has a significant effect on test quality and efficiency. Testers connect test cases into test sequences based on train operation control system principles and test experiences. However, the process is redundant and complicated. Aiming at efficiency and automation of test sequences generation, we propose a test sequence automatic generation method based on the encoder-decoder model with an attention mechanism. Concretely, the model can learn the representation of the source text through an encoder component, and the attention mechanism allowing it selectively search for a part of the source feature to predict a target test case during encoding process. Experiments are conducted by using the Beijing-Shenyang HSR test sequences to train the neural network model. We find that the proposed model can transform the natural language into test sequences effectively and achieve better precision performance in the test dataset. Finally, we verify the feasibility of this method by comparing and analyzing the differences between the sequences generated by the model and the test sequences manually edited quantitatively and qualitatively.},
booktitle = {2021 IEEE International Intelligent Transportation Systems Conference (ITSC)},
pages = {1792–1796},
numpages = {5},
location = {Indianapolis, IN, USA}
}

@inproceedings{10.1145/3460620.3460752,
author = {M.S.B, Phridviraj and C.V, Guru Rao and Vangipuram, Radhakrishna and Cheruvu, Aravind},
title = {Similarity Association Pattern Mining in Transaction Databases},
year = {2021},
isbn = {9781450388382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460620.3460752},
doi = {10.1145/3460620.3460752},
abstract = {Association pattern mining is a method of finding interesting relationships or patterns between item sets present in each of the transactions of the transactional databases. Current researchers in this area are focusing on the data mining task of finding frequent patterns among the item sets based on the interestingness measures like the support and confidence which is called as Frequent pattern mining. Till date, in existing frequent pattern mining algorithms, an itemset is said to be frequent if the support of the itemset satisfies the minimum support input. In this paper, the objective of our algorithm is to find interesting patterns among the item sets based on a Gaussian similarity for an input reference threshold which is first of its kind in the research literature. This study is limited to outlining na\"{\i}ve approach of mining frequent itemsets which requires validating every itemset to verify if the itemset is frequent or not.},
booktitle = {International Conference on Data Science, E-Learning and Information Systems 2021},
pages = {180–184},
numpages = {5},
keywords = {algorithms, digitization, industry manufacturing, optimization},
location = {Ma'an, Jordan},
series = {DATA'21}
}

@inproceedings{10.1145/2856636.2856637,
author = {Lal, Sangeeta and Sureka, Ashish},
title = {LogOpt: Static Feature Extraction from Source Code for Automated Catch Block Logging Prediction},
year = {2016},
isbn = {9781450340182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2856636.2856637},
doi = {10.1145/2856636.2856637},
abstract = {Software logging is an important software development practice which is used to trace important software execution points. This execution information can provide important insight to developer while software debugging. Inspite of many benefits logging is often done in an ad-hoc manner based only on knowledge and experience of software developer because of lack of formal guidelines and training required for making strategic logging decision. It is known that appropriate logging is beneficial for developers but inappropriate logging can have adverse effect on the system. Excessive logging can not only cause performance and cost overhead, it can also lessen the benefit of logging by producing tons of useless logs. Sparse logging can make logging ineffective by leaving out important information. In order to lessen the load of software developers and to improve the quality of software logging, in this work we propose 'LogOpt' tool to help developers in making informed logging decision. LogOpt uses static features from source code to make catch block logging decision. LogOpt is a machine learning based framework which learns the characteristics of logged and unlogged training instance to make informed logging decision. We manually analyze snippets of logged and unlogged source code and extracted 46 distinguishing features important in making logging decision. We evaluated LogOpt on two large open source projects Apache Tomcat and CloudStack (nearly 1.41M LOC). Results show that LogOpt is effective for automated logging task.},
booktitle = {Proceedings of the 9th India Software Engineering Conference},
pages = {151–155},
numpages = {5},
keywords = {Debugging, Logging, Machine Learning, Source Code Analysis, Tracing},
location = {Goa, India},
series = {ISEC '16}
}

@inproceedings{10.1007/978-3-031-04673-5_10,
author = {Tazl, Oliver A. and Wotawa, Franz},
title = {Metamorphic Testing of&nbsp;Logic Theorem Prover},
year = {2021},
isbn = {978-3-031-04672-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-04673-5_10},
doi = {10.1007/978-3-031-04673-5_10},
abstract = {The use of Artificial Intelligence methodologies including machine learning for object recognition and other tasks as well as reasoning has recently gained more attention. This is due to the fact of applications like autonomous driving but also apps for providing recommendations or schedules. In this paper, we focus on testing applications utilizing logic theorem proving for implementing their functionalities. Testing logic theorem prover is important in order to assure that the obtained results are correct and complete as specified. We show how metamorphic testing can be used in this context. In particular, the proposed method takes a logic sentence and modifies it without changing its logical status, i.e., satisfiability. The testing method can be applied to assure the correctness of reasoning via generating logic sentences of arbitrary sizes, but also for performance testing. We applied the presented testing method to 2 different theorem provers and report on obtained results.},
booktitle = {Testing Software and Systems: 33rd IFIP WG 6.1 International Conference, ICTSS 2021, London, UK, November 10–12, 2021, Proceedings},
pages = {131–137},
numpages = {7},
keywords = {Test automation, Theorem prover testing, Metamorphic testing, Test case generation},
location = {London, United Kingdom}
}

@inproceedings{10.1145/2889160.2889164,
author = {Luo, Qi and Poshyvanyk, Denys and Nair, Aswathy and Grechanik, Mark},
title = {FOREPOST: a tool for detecting performance problems with feedback-driven learning software testing},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889164},
doi = {10.1145/2889160.2889164},
abstract = {A goal of performance testing is to find situations when applications unexpectedly exhibit worsened characteristics for certain combinations of input values. A fundamental question of performance testing is how to select a manageable subset of the input data faster to find performance problems in applications automatically.We present a novel tool, FOREPOST, for finding performance problems in applications automatically using black-box software testing. In this paper, we demonstrate how FOREPOST extracts rules from execution traces of applications by using machine learning algorithms, and then uses these rules to select test input data automatically to steer applications towards computationally intensive paths and to find performance problems. FOREPOST is available in our online appendix (http://www.cs.wm.edu/semeru/data/ICSE16-FOREPOST), which contains the tool, source code and demo video.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {593–596},
numpages = {4},
keywords = {black-box testing, machine learning, performance testing},
location = {Austin, Texas},
series = {ICSE '16}
}

@article{10.1007/s11334-020-00383-2,
author = {Althar, Raghavendra Rao and Samanta, Debabrata},
title = {The realist approach for evaluation of computational intelligence in software engineering},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {1},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-020-00383-2},
doi = {10.1007/s11334-020-00383-2},
abstract = {Secured software development must employ a security mindset across software engineering practices. Software security must be considered during the requirements phase so that it is included throughout the development phase. Do the requirements gathering team get the proper input from the technical team? This paper unearths some of the data sources buried within software development phases and describes the potential approaches to understand them. Concepts such as machine learning and deep learning are explored to understand the data sources and explore how these learnings can be provided to the requirements gathering team. This knowledge system will help bring objectivity in the conversations between the requirements gathering team and the customer's business team. A literature review is also done to secure requirements management and identify the possible gaps in providing future research direction to enhance our understanding. Feature engineering in the landscape of software development is explored to understand the data sources. Experts offer their insight on the root cause of the lack of security focus in requirements gathering practices. The core theme is statistical modeling of all the software artifacts that hold information related to the software development life cycle. Strengthening of some traditional methods like threat modeling is also a key area explored. Subjectivity involved in these approaches can be made more objective.},
journal = {Innov. Syst. Softw. Eng.},
month = mar,
pages = {17–27},
numpages = {11},
keywords = {Software engineering, Data science, Computational intelligence, Software requirements management, Threat modeling}
}

@article{10.1007/s10115-017-1059-8,
author = {Li, Yun and Li, Tao and Liu, Huan},
title = {Recent advances in feature selection and its applications},
year = {2017},
issue_date = {December  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {53},
number = {3},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-017-1059-8},
doi = {10.1007/s10115-017-1059-8},
abstract = {Feature selection is one of the key problems for machine learning and data mining. In this review paper, a brief historical background of the field is given, followed by a selection of challenges which are of particular current interests, such as feature selection for high-dimensional small sample size data, large-scale data, and secure feature selection. Along with these challenges, some hot topics for feature selection have emerged, e.g., stable feature selection, multi-view feature selection, distributed feature selection, multi-label feature selection, online feature selection, and adversarial feature selection. Then, the recent advances of these topics are surveyed in this paper. For each topic, the existing problems are analyzed, and then, current solutions to these problems are presented and discussed. Besides the topics, some representative applications of feature selection are also introduced, such as applications in bioinformatics, social media, and multimedia retrieval.},
journal = {Knowl. Inf. Syst.},
month = dec,
pages = {551–577},
numpages = {27},
keywords = {Data mining, Feature selection, Survey}
}

@article{10.1007/s10115-011-0447-8,
author = {Masud, Mohammad M. and Woolam, Clay and Gao, Jing and Khan, Latifur and Han, Jiawei and Hamlen, Kevin W. and Oza, Nikunj C.},
title = {Facing the reality of data stream classification: coping with scarcity of labeled data},
year = {2012},
issue_date = {October   2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {1},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-011-0447-8},
doi = {10.1007/s10115-011-0447-8},
abstract = {Recent approaches for classifying data streams are mostly based on supervised learning algorithms, which can only be trained with labeled data. Manual labeling of data is both costly and time consuming. Therefore, in a real streaming environment where large volumes of data appear at a high speed, only a small fraction of the data can be labeled. Thus, only a limited number of instances will be available for training and updating the classification models, leading to poorly trained classifiers. We apply a novel technique to overcome this problem by utilizing both unlabeled and labeled instances to train and update the classification model. Each classification model is built as a collection of micro-clusters using semi-supervised clustering, and an ensemble of these models is used to classify unlabeled data. Empirical evaluation of both synthetic and real data reveals that our approach outperforms state-of-the-art stream classification algorithms that use ten times more labeled data than our approach.},
journal = {Knowl. Inf. Syst.},
month = oct,
pages = {213–244},
numpages = {32},
keywords = {Concept drift, Data stream classification, Ensemble classification, Semi-supervised clustering}
}

@inproceedings{10.1007/978-3-030-57628-8_17,
author = {Granig, Wolfgang and Jak\v{s}i\'{c}, Stefan and Lewitschnig, Horst and Mateis, Cristinel and Ni\v{c}kovi\'{c}, Dejan},
title = {Weakness Monitors for Fail-Aware Systems},
year = {2020},
isbn = {978-3-030-57627-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-57628-8_17},
doi = {10.1007/978-3-030-57628-8_17},
abstract = {Fail-awareness is the ability of a system to detect an upcoming failure before it actually happens. In this paper, we propose a weakness monitoring approach for observing a complex system during its operation, identifying possible degradation of its behavior, and finally raising an alarm in case of an estimated upcoming failure before the system actually goes out of its specification. Our procedure uses online linear regression to monitor trends over time – it is used to optimize the system service. We evaluate our approach on three case studies from the automotive and avionics domains.},
booktitle = {Formal Modeling and Analysis of Timed Systems: 18th International Conference, FORMATS 2020, Vienna, Austria, September 1–3, 2020, Proceedings},
pages = {283–299},
numpages = {17},
location = {Vienna, Austria}
}

@article{10.1007/s10664-018-9656-z,
author = {Blincoe, Kelly and Dehghan, Ali and Salaou, Abdoul-Djawadou and Neal, Adam and Linaker, Johan and Damian, Daniela},
title = {High-level software requirements and iteration changes: a predictive model},
year = {2019},
issue_date = {Jun 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9656-z},
doi = {10.1007/s10664-018-9656-z},
abstract = {Knowing whether a software feature will be completed in its planned iteration can help with release planning decisions. However, existing research has focused on predictions of only low-level software tasks, like bug fixes. In this paper, we describe a mixed-method empirical study on three large IBM projects. We investigated the types of iteration changes that occur. We show that up to 54% of high-level requirements do not make their planned iteration. Requirements are most often pushed out to the next iteration, but high-level requirements are also commonly moved to the next minor or major release or returned to the product or release backlog. We developed and evaluated a model that uses machine learning to predict if a high-level requirement will be completed within its planned iteration. The model includes 29 features that were engineered based on prior work, interviews with IBM developers, and domain knowledge. Predictions were made at four different stages of the requirement lifetime. Our model is able to achieve up to 100% precision. We ranked the importance of our model features and found that some features are highly dependent on project and prediction stage. However, some features (e.g., the time remaining in the iteration and creator of the requirement) emerge as important across all projects and stages. We conclude with a discussion on future research directions.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {1610–1648},
numpages = {39},
keywords = {Completion prediction, Machine learning, Mining software repositories, Release planning, Software requirements}
}

@article{10.4018/IJIRR.2014100104,
author = {Muqasqas, Saed A. and Radaideh, Qasem A. Al and Abul-Huda, Bilal A.},
title = {A Hybrid Classification Approach Based on Decision Tree and Na\"{\i}ve Bays Methods},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {4},
number = {4},
issn = {2155-6377},
url = {https://doi.org/10.4018/IJIRR.2014100104},
doi = {10.4018/IJIRR.2014100104},
abstract = {Data classification as one of the main tasks of data mining has an important role in many fields. Classification techniques differ mainly in the accuracy of their models, which depends on the method adopted during the learning phase. Several researchers attempted to enhance the classification accuracy by combining different classification methods in the same learning process; resulting in a hybrid-based classifier. In this paper, the authors propose and build a hybrid classifier technique based on Na\"{\i}ve Bayes and C4.5 classifiers. The main goal of the proposed model is to reduce the complexity of the NBTree technique, which is a well known hybrid classification technique, and to improve the overall classification accuracy. Thirty six samples of UCI datasets were used in evaluation. Results have shown that the proposed technique significantly outperforms the NBTree technique and some other classifiers proposed in the literature in term of classification accuracy. The proposed classification approach yields an overall average accuracy equal to 85.70% over the 36 datasets.},
journal = {Int. J. Inf. Retr. Res.},
month = oct,
pages = {61–72},
numpages = {12}
}

@phdthesis{10.5555/AAI29186291,
author = {Wu, Weibin and Wei, Meng, and Ching, Lee, Pak and Song, Chen, Chu},
advisor = {Michael, Lyu, Rung Tsong and Irwin, King, Kuo Chin},
title = {On the Robustness and Interpretability of Deep Learning Models},
year = {2021},
isbn = {9798426803503},
publisher = {The Chinese University of Hong Kong (Hong Kong)},
abstract = {The enormous success of deep neural networks (DNNs) popularizes the deployment of DNNs in a broad spectrum of safety-and security-sensitive applications, like autonomous driving and medical diagnosis. Therefore, studying the robustness and interpretability of the underlying DNN models is of paramount importance. Unfortunately, due to the large-scale and black-box nature of DNNs, it is challenging to investigate the robustness and interpretability of DNNs. In this thesis, we endeavor to address these problems from multiple facets. In short, we explore two primary scenarios regarding the robustness of DNNs: accidental failures and intentional ones. We also explore providing global explanations for DNNs in pursuit of promoting their interpretability.Firstly, we focus on improving the robustness of DNNs against accidental failures, where DNNs frequently manifest erroneous behaviors in real-world corner cases, like abnormal weather conditions. Existing countermeasures usually center on improving the testing and bug-fixing practice. However, it is scarcely viable to build an omnipotent DNN that can handle all possible cases, so anomaly detection is indispensable in practice. Motivated by the idea of data validation in traditional software, we propose Deep Validation (DV), the first framework for detecting real-world error-inducing corner cases in DNNs. Deep Validation can achieve excellent detection results against various corner case scenarios.Secondly, we evaluate the robustness of undefended DNNs against intentional failures, where attackers craft adversarial samples to fool victim models into wrong predictions. We center on transfer-based attacks against image classifiers, where attackers are restricted to craft adversarial images based on local proxy models without the feedback information from the remote target ones. However, under such a constrained but practical setup, the synthesized adversarial samples often achieve limited success due to overfitting to the employed local model. We propose a novel mechanism to alleviate the overfitting issue, called Attention-guided Transfer Attack (ATA). Experimental results confirm that our method can markedly promote the transferability of adversarial instances.Thirdly, we turn to assess the robustness of defended DNNs against intentional failures. We also consider transfer-based attacks as before. Since adversarial noises are usually purposeful perturbations of small magnitude, previous attacks hardly survive under defenses, like transformation-based ones. To better evaluate the susceptibility of existing defenses, we propose a novel attack method named Adversarial Transformation-enhanced Transfer Attack (ATTA). It is motivated by the data augmentation methodology to improve the generalization of models. Extensive experiments show that our scheme outshines previous proposals in evaluating the robustness of defended DNNs against transfer-based attacks.Lastly, we cover how to promote the interpretability of DNNs. In addition to being a scientific problem itself towards building safe and dependable DNNs, elevating the interpretability of DNNs is conducive to spot robustness issues and promote the robustness of DNNs. Specifically, we concentrate on offering global explanations, which contribute to understanding model predictions on a whole category of samples. However, existing methods overwhelmingly conduct separate input attribution or rely on local approximations of models, making them fail to offer faithful global explanations of DNNs. To overcome such drawbacks, we propose a novel two-stage framework: Attacking for Interpretability (AfI), which explains model decisions in terms of the importance of user-defined concepts. Experimental comparisons corroborate that AfI can provide more accurate estimations of concept importance than existing proposals.},
note = {AAI29186291}
}

@inproceedings{10.1145/3345629.3345631,
author = {Amit, Idan and Feitelson, Dror G.},
title = {Which Refactoring Reduces Bug Rate?},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345631},
doi = {10.1145/3345629.3345631},
abstract = {We present a methodology to identify refactoring operations that reduce the bug rate in the code. The methodology is based on comparing the bug fixing rate in certain time windows before and after the refactoring. We analyzed 61,331 refactor commits from 1,531 large active GitHub projects. When comparing three-month windows, the bug rate is substantially reduced in 17% of the files of analyzed refactors, compared to 12% of the files in random commits. Within this group, implementing 'todo's provides the most benefits. Certain operations like reuse, upgrade, and using enum and namespaces are also especially beneficial.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {12–15},
numpages = {4},
keywords = {Code quality, machine learning, refactoring},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1145/3468264.3473935,
author = {Ye, Jiaming and Chen, Ke and Xie, Xiaofei and Ma, Lei and Huang, Ruochen and Chen, Yingfeng and Xue, Yinxing and Zhao, Jianjun},
title = {An empirical study of GUI widget detection for industrial mobile games},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473935},
doi = {10.1145/3468264.3473935},
abstract = {With the widespread adoption of smartphones in our daily life, mobile games experienced increasing demand over the past years. Meanwhile, the quality of mobile games has been continuously drawing more and more attention, which can greatly affect the player experience. For better quality assurance, general-purpose testing has been extensively studied for mobile apps. However, due to the unique characteristic of mobile games, existing mobile testing techniques may not be directly suitable and applicable. To better understand the challenges in mobile game testing, in this paper, we first initiate an early step to conduct an empirical study towards understanding the challenges and pain points of mobile game testing process at our industrial partner NetEase Games. Specifically, we first conduct a survey from the mobile test development team at NetEase Games via both scrum interviews and questionnaires. We found that accurate and effective GUI widget detection for mobile games could be the pillar to boost the automation of mobile game testing and other downstream analysis tasks in practice.  We then continue to perform comparative studies to investigate the effectiveness of state-of-the-art general-purpose mobile app GUI widget detection methods in the context of mobile games. To this end, we also develop a technique to automatically collect GUI widgets region information of industrial mobile games, which is equipped with a heuristic-based data cleaning method for quality refinement of the labeling results. Our evaluation shows that: (1) Existing GUI widget detection methods for general-purpose mobile apps cannot perform well on industrial mobile games. (2) Mobile game exhibits obvious difference from other general-purpose mobile apps in the perspective GUI widgets. Our further in-depth analysis reveals high diversity and density characteristics of mobile game GUI widgets could be the major reasons that post the challenges for existing methods, which calls for new research methods and better industry practices. To enable further research along this line, we construct the very first GUI widget detection benchmark, specially designed for mobile games, incorporating both our collected dataset and the state-of-the-art widget detection methods for mobile apps, which could also be the basis for further study of many downstream quality assurance tasks (e.g., testing and analysis) for mobile games.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1427–1437},
numpages = {11},
keywords = {Deep Learning, GUI Detection, Game Testing},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1007/978-3-030-26250-1_27,
author = {Woehrle, Matthias and Gladisch, Christoph and Heinzemann, Christian},
title = {Open Questions in Testing of Learned Computer Vision Functions for Automated Driving},
year = {2019},
isbn = {978-3-030-26249-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-26250-1_27},
doi = {10.1007/978-3-030-26250-1_27},
abstract = {Vision is an important sensing modality in automated driving. Deep learning-based approaches have gained popularity for different computer vision (CV) tasks such as semantic segmentation and object detection. However, the black-box nature of deep neural nets (DNN) is a challenge for practical software verification. With this paper, we want to initiate a discussion in the academic community about research questions w.r.t. software testing of DNNs for safety-critical CV tasks. To this end, we provide an overview of related work from various domains, including software testing, machine learning and computer vision and derive a set of open research questions to start discussion between the fields.},
booktitle = {Computer Safety, Reliability, and Security: SAFECOMP 2019 Workshops, ASSURE, DECSoS, SASSUR, STRIVE, and WAISE, Turku, Finland, September 10, 2019, Proceedings},
pages = {333–345},
numpages = {13},
location = {Turku, Finland}
}

@inproceedings{10.1145/2597073.2597080,
author = {Tulsian, Varun and Kanade, Aditya and Kumar, Rahul and Lal, Akash and Nori, Aditya V.},
title = {MUX: algorithm selection for software model checkers},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597080},
doi = {10.1145/2597073.2597080},
abstract = {With the growing complexity of modern day software, software model checking has become a critical technology for ensuring correctness of software. As is true with any promising technology, there are a number of tools for software model checking. However, their respective performance trade-offs are difficult to characterize accurately – making it difficult for practitioners to select a suitable tool for the task at hand. This paper proposes a technique called MUX that addresses the problem of selecting the most suitable software model checker for a given input instance. MUX performs machine learning on a repository of software verification instances. The algorithm selector, synthesized through machine learning, uses structural features from an input instance, comprising a program-property pair, at runtime and determines which tool to use.  We have implemented MUX for Windows device drivers and evaluated it on a number of drivers and model checkers. Our results are promising in that the algorithm selector not only avoids a significant number of timeouts but also improves the total runtime by a large margin, compared to any individual model checker. It also outperforms a portfolio-based algorithm selector being used in Microsoft at present. Besides, MUX identifies structural features of programs that are key factors in determining performance of model checkers.},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {132–141},
numpages = {10},
keywords = {Algorithm selection, machine learning, software model checking},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1109/ICPC.2015.15,
author = {Thung, Ferdian and Le, Xuan-Bach D. and Lo, David},
title = {Active Semi-supervised Defect Categorization},
year = {2015},
isbn = {9781467381598},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICPC.2015.15},
doi = {10.1109/ICPC.2015.15},
abstract = {Defects are inseparable part of software development and evolution. To better comprehend problems affecting a software system, developers often store historical defects and these defects can be categorized into families. IBM proposes Orthogonal Defect Categorization (ODC) which include various classifications of defects based on a number of orthogonal dimensions (e.g., Symptoms and semantics of defects, root causes of defects, etc.). To help developers categorize defects, several approaches that employ machine learning have been proposed in the literature. Unfortunately, these approaches often require developers to manually label a large number of defect examples. In practice, manually labelling a large number of examples is both time-consuming and labor-intensive. Thus, reducing the onerous burden of manual labelling while still being able to achieve good performance is crucial towards the adoption of such approaches. To deal with this challenge, in this work, we propose an active semi-supervised defect prediction approach. It is performed by actively selecting a small subset of diverse and informative defect examples to label (i.e., Active learning), and by making use of both labeled and unlabeled defect examples in the prediction model learning process (i.e., Semi-supervised learning). Using this principle, our approach is able to learn a good model while minimizing the manual labeling effort. To evaluate the effectiveness of our approach, we make use of a benchmark dataset that contains 500 defects from three software systems that have been manually labelled into several families based on ODC. We investigate our approach's ability in achieving good classification performance, measured in terms of weighted precision, recall, F-measure, and AUC, when only a small number of manually labelled defect examples are available. Our experiment results show that our active semi-supervised defect categorization approach is able to achieve a weighted precision, recall, F-measure, and AUC of 0.651, 0.669, 0.623, and 0.710, respectively, when only 50 defects are manually labelled. Furthermore, it outperforms an existing active multi-class classification algorithm, proposed in the machine learning community, by a substantial margin.},
booktitle = {Proceedings of the 2015 IEEE 23rd International Conference on Program Comprehension},
pages = {60–70},
numpages = {11},
keywords = {active learning, clustering, defect categorization, semi supervised learning, support vector machine},
series = {ICPC '15}
}

@article{10.1007/s11219-016-9334-6,
author = {S\"{o}ylemez, Mehmet and Tarhan, Ayca},
title = {Challenges of software process and product quality improvement: catalyzing defect root-cause investigation by process enactment data analysis},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9334-6},
doi = {10.1007/s11219-016-9334-6},
abstract = {It is claimed by software quality management that the quality of a software product is highly influenced by the quality of the software process followed to develop it. Since measurement of the software process is a challenging task, it is frequently the defects in the software product that are used to measure development quality. By extracting semantic information from defect records, practitioners can investigate and address root causes of software defects to improve development process and product quality. Investigating root causes requires effort for a detailed analysis into the components of the development process that originated the software defects, and is therefore encouraged only at higher maturity levels by most known process improvement models such as Capability Maturity Model Integration (CMMI). This practice, however, postpones the benefits that root-cause analysis would bring in gaining process awareness to improve the software development process and product quality in emergent organizations or organizations residing at lower maturity levels (MLs). In this article, we present a method for and results from applying root-cause analysis for software defects recorded in a software-intensive project of a CMMI ML3 certified institute. The suggested method combines process enactment data collection and analysis with Orthogonal Defect Classification which is a known technique in defect root-cause analysis. Prior to and after implementing the method in the study, defect attributes were analyzed and compared in order to understand any improvements in development performance and product quality. The results of the comparison indicate that the suggested method was efficient in the effort it required and effective in improving development performance and product quality. Defect triggers have become more active in identifying software defects in the earlier phases of software development, and the cost of quality due to software defects has decreased in consequence.},
journal = {Software Quality Journal},
month = jun,
pages = {779–807},
numpages = {29},
keywords = {Causal analysis, Orthogonal defect classification, Process enactment, Process improvement, Product quality, Software defect, Software process}
}

@inproceedings{10.5555/1882011.1882054,
author = {Luo, Yunfeng and Ben, Kerong and Mi, Lei},
title = {Software metrics reduction for fault-proneness prediction of software modules},
year = {2010},
isbn = {3642156711},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {It would be valuable to use metrics to identify the fault-proneness of software modules. However, few research works are on how to select appropriate metrics for fault-proneness prediction currently. We conduct a large-scale comparative experiment of nine different software metrics reduction methods over eleven public-domain data sets from the NASA metrics data repository. The Naive Bayes data miner, with a log-filtering preprocessor on the numeric data, is utilized to construct the prediction model. Comparisons are based on the analysis of variance. Our conclusion is that, reduction methods of software metrics are important to build adaptable and robust software fault-proneness prediction models. Given our results on Naive Bayes and log-filtering, discrete wavelet transformation outperforms other reduction methods, and correlationbased feature selection with genetic search algorithm and information gain can also obtain better predicted performance.},
booktitle = {Proceedings of the 2010 IFIP International Conference on Network and Parallel Computing},
pages = {432–441},
numpages = {10},
keywords = {analysis of variance, metrics reduction, software fault-proneness},
location = {Zhengzhou, China},
series = {NPC'10}
}

@inbook{10.5555/3454287.3455351,
author = {Gupta, Rahul and Kanade, Aditya and Shevade, Shirish},
title = {Neural attribution for semantic bug-localization in student programs},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Providing feedback is an integral part of teaching. Most open online courses on programming make use of automated grading systems to support programming assignments and give real-time feedback. These systems usually rely on test results to quantify the programs' functional correctness. They return failing tests to the students as feedback. However, students may find it difficult to debug their programs if they receive no hints about where the bug is and how to fix it. In this work, we present NeuralBugLocator, a deep learning based technique, that can localize the bugs in a faulty program with respect to a failing test, without even running the program. At the heart of our technique is a novel tree convolutional neural network which is trained to predict whether a program passes or fails a given test. To localize the bugs, we analyze the trained network using a state-of-the-art neural prediction attribution technique and see which lines of the programs make it predict the test outcomes. Our experiments show that NeuralBugLocator is generally more accurate than two state-of-the-art program-spectrum based and one syntactic difference based bug-localization baselines.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {1064},
numpages = {11}
}

@inproceedings{10.1109/ACCT.2012.27,
author = {Gupta, Deepak and Goyal, Vinay Kr. and Mittal, Harish},
title = {Analysis of Clustering Techniques for Software Quality Prediction},
year = {2012},
isbn = {9780769546407},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ACCT.2012.27},
doi = {10.1109/ACCT.2012.27},
abstract = {Clustering is the unsupervised classification of patterns into groups. A clustering algorithm partitions a data set into several groups such that similarity within a group is larger than among groups The clustering problem has been addressed in many contexts and by researchers in many disciplines, this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. There is need to develop some methods to build the software fault prediction model based on unsupervised learning which can help to predict the fault-- proneness of a program modules when fault labels for modules are not present. One of the such method is use of clustering techniques. This paper presents a case study of different clustering techniques and analyzes their performance.},
booktitle = {Proceedings of the 2012 Second International Conference on Advanced Computing &amp; Communication Technologies},
pages = {6–9},
numpages = {4},
keywords = {Fuzzy C-means, Hierarchical, K-means, Mountain, SOM, Subtractive clustering},
series = {ACCT '12}
}

@inproceedings{10.1145/3377812.3382175,
author = {Pan, Rangeet},
title = {Does fixing bug increase robustness in deep learning?},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3382175},
doi = {10.1145/3377812.3382175},
abstract = {Deep Learning (DL) based systems are utilized vastly. Developers update the code to fix the bugs in the system. How these code fixing techniques impacts the robustness of these systems has not been clear. Does fixing code increase the robustness? Do they deteriorate the learning capability of the DL based systems? To answer these questions, we studied 321 Stack Overflow posts based on a published dataset. In this study, we built a classification scheme to analyze how bug-fixes changed the robustness of the DL model and found that most of the bug-fixes can increase the robustness. We also found evidence of bug-fixing that decrease the robustness. Our preliminary result suggests that 12.5% and 2.4% of the bug-fixes in Stack Overflow posts caused the increase and the decrease of the robustness of DL models, respectively.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {146–148},
numpages = {3},
keywords = {bug fix, bugs, deep neural networks, robustness},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1109/ICSE-SEIP.2017.13,
author = {Ziftci, Celal and Reardon, Jim},
title = {Who broke the build? automatically identifying changes that induce test failures in continuous integration at Google scale},
year = {2017},
isbn = {9781538627174},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2017.13},
doi = {10.1109/ICSE-SEIP.2017.13},
abstract = {Quickly identifying and fixing code changes that introduce regressions is critical to keep the momentum on software development, especially in very large scale software repositories with rapid development cycles, such as at Google. Identifying and fixing such regressions is one of the most expensive, tedious, and time consuming tasks in the software development life-cycle. Therefore, there is a high demand for automated techniques that can help developers identify such changes while minimizing manual human intervention. Various techniques have recently been proposed to identify such code changes. However, these techniques have shortcomings that make them unsuitable for rapid development cycles as at Google. In this paper, we propose a novel algorithm to identify code changes that introduce regressions, and discuss case studies performed at Google on 140 projects. Based on our case studies, our algorithm automatically identifies the change that introduced the regression in the top-5 among thousands of candidates 82% of the time, and provides considerable savings on manual work developers need to perform.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track},
pages = {113–122},
numpages = {10},
keywords = {ranking, software changes, software debugging, software fault diagnosis, software testing, software tools},
location = {Buenos Aires, Argentina},
series = {ICSE-SEIP '17}
}

@inproceedings{10.5555/2946711.2946727,
author = {Mayo, Michael and Spacey, Simon},
title = {Predicting Regression Test Failures Using Genetic Algorithm-Selected Dynamic Performance Analysis Metrics},
year = {2013},
isbn = {9783642397417},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {A novel framework for predicting regression test failures is proposed. The basic principle embodied in the framework is to use performance analysis tools to capture the runtime behaviour of a program as it executes each test in a regression suite. The performance information is then used to build a dynamically predictive model of test outcomes. Our framework is evaluated using a genetic algorithm for dynamic metric selection in combination with state-of-the-art machine learning classifiers. We show that if a program is modified and some tests subsequently fail, then it is possible to predict with considerable accuracy which of the remaining tests will also fail which can be used to help prioritise tests in time constrained testing environments.},
booktitle = {Proceedings of the 5th International Symposium on Search Based Software Engineering - Volume 8084},
pages = {158–171},
numpages = {14},
keywords = {genetic metric selection, machine learning, program analysis, regression testing, test failure prediction},
location = {St. Petersburg, Russia},
series = {SSBSE 2013}
}

@inproceedings{10.1007/978-3-030-41579-2_13,
author = {Lin, Guanjun and Xiao, Wei and Zhang, Jun and Xiang, Yang},
title = {Deep Learning-Based Vulnerable Function Detection: A Benchmark},
year = {2019},
isbn = {978-3-030-41578-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-41579-2_13},
doi = {10.1007/978-3-030-41579-2_13},
abstract = {The application of Deep Learning (DL) technique for code analysis enables the rich and latent patterns within software code to be revealed, facilitating various downstream tasks such as the software defect and vulnerability detection. Many DL architectures have been applied for identifying vulnerable code segments in recent literature. However, the proposed studies were evaluated on self-constructed/-collected datasets. There is a lack of unified performance criteria, acting as a baseline for measuring the effectiveness of the proposed DL-based approaches. This paper proposes a benchmarking framework for building and testing DL-based vulnerability detectors, providing six built-in mainstream neural network models with three embedding solutions available for selection. The framework also offers easy-to-use APIs for integration of new network models and embedding methods. In addition, we constructed a real-world vulnerability ground truth dataset containing manually labelled 1,471 vulnerable functions and 1,320 vulnerable files from nine open-source software projects. With the proposed framework and the ground truth dataset, researchers can conveniently establish a vulnerability detection baseline system for comparison and evaluation. This paper also includes usage examples of the proposed framework, aiming to investigate the performance behaviours of mainstream neural network models and providing a reference for DL-based vulnerability detection at function-level.},
booktitle = {Information and Communications Security: 21st International Conference, ICICS 2019, Beijing, China, December 15–17, 2019, Revised Selected Papers},
pages = {219–232},
numpages = {14},
keywords = {Vulnerability detection, Neural network, Function-level detection},
location = {Beijing, China}
}

@article{10.1016/j.eswa.2015.01.029,
author = {Hou, Yi and Edara, Praveen and Sun, Carlos},
title = {Situation assessment and decision making for lane change assistance using ensemble learning methods},
year = {2015},
issue_date = {May 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {8},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.01.029},
doi = {10.1016/j.eswa.2015.01.029},
abstract = {Lane change assistance system was developed using ensemble learning methods.Proposed system has potential to prevent lane change crashes and thus reducing injuries and fatalities.Random forest and AdaBoost outperformed Bayes/Decision tree classifier.Higher classification accuracy and lower false positive rates achieved.Accuracies of 99.1% and 98.7% were achieved for lane keeping. Lane change maneuvers contribute to a significant number of road traffic accidents. Advanced driver assistance systems (ADAS) that can assess a traffic situation and warn drivers of unsafe lane changes can offer additional safety and convenience. In addition, ADAS can be extended for use in automatic lane changing in driverless vehicles. This paper investigated two ensemble learning methods, random forest, and AdaBoost, for developing a lane change assistance system. The focus on increasing the accuracy of safety critical lane change events has a significant impact on lowering the occurrence of crashes. This is the first study to explore ensemble learning methods for modeling lane changes using a comprehensive set of variables. Detailed vehicle trajectory data from the Next Generation Simulation (NGSIM) dataset in the US were used for model development and testing. The results showed that both ensemble learning methods produced higher classification accuracy and lower false positive rates than the Bayes/Decision tree classifier used in the literature. The impact of misclassification of lane changing events was also studied. A sensitivity analysis performed by varying the accuracy of lane changing showed that the lane keeping accuracy can be increased to as high as 99.1% for the AdaBoost system and 98.7% for the random forest system. The corresponding true positive rates were 96.3% and 94.6%. High accuracy of lane keeping and high true positive rates are desirable due to their safety implications.},
journal = {Expert Syst. Appl.},
month = may,
pages = {3875–3882},
numpages = {8},
keywords = {Adaboost, Intelligent transportation system, Lane changing assistance, Random forest}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00091,
author = {Dola, Swaroopa and Dwyer, Matthew B. and Soffa, Mary Lou},
title = {Artifact: distribution-aware testing of neural networks using generative models},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00091},
doi = {10.1109/ICSE-Companion52605.2021.00091},
abstract = {The artifact used for the experimental evaluation of Distribution-Aware Testing of Neural Networks Using Generative Models is publicly available on GitHub and it is reusable. The artifact consists of python scripts, trained deep neural network model files and data required for running the experiments. It is also provided as a VirtualBox VM image for reproducing the paper results. Users should be familiar with using VirtualBox software and Linux platform to reproduce or reuse the artifact.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {205–206},
numpages = {2},
keywords = {deep neural networks, input validation, test coverage, test generation},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@article{10.1145/2557833.2557849,
author = {Malhotra, Ruchika and Agrawal, Anushree},
title = {CMS tool: calculating defect and change data from software project repositories},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2557833.2557849},
doi = {10.1145/2557833.2557849},
abstract = {Defect and change prediction is a very important activity in software development. Predicting erroneous classes of the system early in the software development life cycle will enable early identification of risky classes in the initial phases. This will assist software practitioners in designing and developing software systems of better quality with focused resources and hence take necessary corrective design actions. In this work we describe a framework to develop and calculate the defect fixes and changes made during various versions of a software system. We develop a tool, Configuration Management System (CMS), which uses log files obtained from a Concurrent Versioning System (CVS) repository in order to collect the number of defects from each class. The tool also calculates the number of changes made during each version of the software. This tool will also assist software practitioners and researchers in collecting defect and change data for software systems.},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {1–5},
numpages = {5},
keywords = {CVS, change prediction, defect prediction, software project repositories}
}

@inproceedings{10.1007/978-3-030-58811-3_69,
author = {Hegedundefineds, P\'{e}ter},
title = {Inspecting JavaScript Vulnerability Mitigation Patches with Automated Fix Generation in Mind},
year = {2020},
isbn = {978-3-030-58810-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58811-3_69},
doi = {10.1007/978-3-030-58811-3_69},
abstract = {Software security has become a primary concern for both the industry and academia in recent years. As dependency on critical services provided by software systems grows globally, a potential security threat in such systems poses higher and higher risks (e.g. economical damage, a threat to human life, criminal activity).Finding potential security vulnerabilities at the code level automatically is a very popular approach to aid security testing. However, most of the methods based on machine learning and statistical models stop at listing potentially vulnerable code parts and leave their validation and mitigation to the developers. Automatic program repair could fill this gap by automatically generating vulnerability mitigation code patches. Nonetheless, it is still immature, especially in targeting security-relevant fixes.In this work, we try to establish a path towards automatic vulnerability fix generation techniques in the context of JavaScript programs. We inspect 361 actual vulnerability mitigation patches collected from vulnerability databases and GitHub. We found that vulnerability mitigation patches are not short on average and in many cases affect not just program code but test code as well. These results point towards that a general automatic repair approach targeting all the different types of vulnerabilities is not feasible. The analysis of the code properties and fix patterns for different vulnerability types might help in setting up a more realistic goal in the area of automatic JavaScript vulnerability repair.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part IV},
pages = {975–988},
numpages = {14},
keywords = {Security, Vulnerability, JavaScript, Prediction models, Automatic repair},
location = {Cagliari, Italy}
}

@article{10.1007/s00521-020-05028-w,
author = {Pimenidis, Elias and Jayne, Chrisina},
title = {Special issue on engineering applications of neural networks},
year = {2020},
issue_date = {Aug 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05028-w},
doi = {10.1007/s00521-020-05028-w},
journal = {Neural Comput. Appl.},
month = aug,
pages = {12241–12242},
numpages = {2}
}

@article{10.1007/s10462-012-9348-9,
author = {Elish, Mahmoud O.},
title = {A comparative study of fault density prediction in aspect-oriented systems using MLP, RBF, KNN, RT, DENFIS and SVR models},
year = {2014},
issue_date = {December  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {42},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-012-9348-9},
doi = {10.1007/s10462-012-9348-9},
abstract = {This paper investigates and empirically evaluates and compares six popular computational intelligence models in the context of fault density prediction in aspect-oriented systems. These models are multi-layer perceptron (MLP), radial basis function (RBF), k-nearest neighbor (KNN), regression tree (RT), dynamic evolving neuro-fuzzy inference system (DENFIS), and support vector regression (SVR). The models were trained and tested, using leave-one-out procedure, on a dataset that consists of twelve aspect-level metrics (explanatory variables) that measure different structural properties of an aspect. It was observed that the DENFIS, SVR, and RT models were more accurate in predicting fault density compared to the MLP, RBF, and KNN models. The MLP model was the worst model, and all the other models were significantly better than it.},
journal = {Artif. Intell. Rev.},
month = dec,
pages = {695–703},
numpages = {9},
keywords = {Aspect-oriented software, Computational intelligence, Fault density prediction}
}

@article{10.1145/3488269,
author = {Lyu, Yingzhe and Rajbahadur, Gopi Krishnan and Lin, Dayi and Chen, Boyuan and Jiang, Zhen Ming (Jack)},
title = {Towards a Consistent Interpretation of AIOps Models},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3488269},
doi = {10.1145/3488269},
abstract = {Artificial Intelligence for IT Operations (AIOps) has been adopted in organizations in various tasks, including interpreting models to identify indicators of service failures. To avoid misleading practitioners, AIOps model interpretations should be consistent (i.e., different AIOps models on the same task agree with one another on feature importance). However, many AIOps studies violate established practices in the machine learning community when deriving interpretations, such as interpreting models with suboptimal performance, though the impact of such violations on the interpretation consistency has not been studied.In this article, we investigate the consistency of AIOps model interpretation along three dimensions: internal consistency, external consistency, and time consistency. We conduct a case study on two AIOps tasks: predicting Google cluster job failures and Backblaze hard drive failures. We find that the randomness from learners, hyperparameter tuning, and data sampling should be controlled to generate consistent interpretations. AIOps models with AUCs greater than 0.75 yield more consistent interpretation compared to low-performing models. Finally, AIOps models that are constructed with the Sliding Window or Full History approaches have the most consistent interpretation with the trends presented in the entire datasets. Our study provides valuable guidelines for practitioners to derive consistent AIOps model interpretation.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {16},
numpages = {38},
keywords = {AIOps, model interpretation}
}

@article{10.1016/j.ijar.2015.11.005,
title = {Neighborhood based decision-theoretic rough set models},
year = {2016},
issue_date = {February 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {69},
number = {C},
issn = {0888-613X},
url = {https://doi.org/10.1016/j.ijar.2015.11.005},
doi = {10.1016/j.ijar.2015.11.005},
abstract = {As an extension of Pawlak rough set model, decision-theoretic rough set model (DTRS) adopts the Bayesian decision theory to compute the required thresholds in probabilistic rough set models. It gives a new semantic interpretation of the positive, boundary and negative regions by using three-way decisions. DTRS has been widely discussed and applied in data mining and decision making. However, one limitation of DTRS is its lack of ability to deal with numerical data directly. In order to overcome this disadvantage and extend the theory of DTRS, this paper proposes a neighborhood based decision-theoretic rough set model (NDTRS) under the framework of DTRS. Basic concepts of NDTRS are introduced. A positive region related attribute reduct and a minimum cost attribute reduct in the proposed model are defined and analyzed. Experimental results show that our methods can get a short reduct. Furthermore, a new neighborhood classifier based on three-way decisions is constructed and compared with other classifiers. Comparison experiments show that the proposed classifier can get a high accuracy and a low misclassification cost. A neighborhood based decision-theoretic rough set model is proposed to handle with numerical data with noise.Two kinds of attribute reducts are defined: positive region related attribute reduct and minimum cost attribute reduct.A three-way decisions based neighborhood classifier is proposed.},
journal = {Int. J. Approx. Reasoning},
month = feb,
pages = {1–17},
numpages = {17}
}

@article{10.1016/j.infsof.2019.05.007,
author = {Ebrahimi, Neda and Trabelsi, Abdelaziz and Islam, Md. Shariful and Hamou-Lhadj, Abdelwahab and Khanmohammadi, Kobra},
title = {An HMM-based approach for automatic detection and classification of duplicate bug reports},
year = {2019},
issue_date = {Sep 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {113},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.05.007},
doi = {10.1016/j.infsof.2019.05.007},
journal = {Inf. Softw. Technol.},
month = sep,
pages = {98–109},
numpages = {12},
keywords = {Duplicate bug reports, Stack traces, Hidden Markov models, Machine learning, Mining software repositories}
}

@article{10.1109/MC.2021.3092479,
author = {Serpanos, Dimitrios and Katsigiannis, Konstantinos},
title = {Fuzzing: Cyberphysical System Testing for Security and Dependability},
year = {2021},
issue_date = {Sept. 2021},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {54},
number = {9},
issn = {0018-9162},
url = {https://doi.org/10.1109/MC.2021.3092479},
doi = {10.1109/MC.2021.3092479},
abstract = {Fuzz testing enables automated remote testing of cyberphysical and Internet of Things systems. The selection of effective test vector sequences is critical and a natural domain for the employment of artificial intelligence and machine learning techniques that incorporate successful selection criteria.},
journal = {Computer},
month = sep,
pages = {86–89},
numpages = {4}
}

@article{10.1007/s11219-019-09467-0,
author = {Du, Xiaoting and Zhou, Zenghui and Yin, Beibei and Xiao, Guanping},
title = {Cross-project bug type prediction based on transfer learning},
year = {2020},
issue_date = {Mar 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-019-09467-0},
doi = {10.1007/s11219-019-09467-0},
abstract = {The prediction of bug types provides useful insights into the software maintenance process. It can improve the efficiency of software testing and help developers adopt corresponding strategies to fix bugs before releasing software projects. Typically, the prediction tasks are performed through machine learning classifiers, which rely heavily on labeled data. However, for a software project that has insufficient labeled data, it is difficult to train the classification model for predicting bug types. Although labeled data of other projects can be used as training data, the results of the cross-project prediction are often poor. To solve this problem, this paper proposes a cross-project bug type prediction framework based on transfer learning. Transfer learning breaks the assumption of traditional machine learning methods that the training set and the test set should follow the same distribution. Our experiments show that the results of cross-project bug type prediction have significant improvement by adopting transfer learning. In addition, we have studied the factors that influence the prediction results, including different pairs of source and target projects, and the number of bug reports in the source project.},
journal = {Software Quality Journal},
month = mar,
pages = {39–57},
numpages = {19},
keywords = {Bug prediction, Cross-project, Bug report, Transfer learning}
}

@article{10.1002/spe.2263,
author = {Kumar, Manoj and Sharma, Arun and Kumar, Rajesh},
title = {An empirical evaluation of a three-tier conduit framework for multifaceted test case classification and selection using fuzzy-ant colony optimisation approach},
year = {2015},
issue_date = {July 2015},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {45},
number = {7},
issn = {0038-0644},
url = {https://doi.org/10.1002/spe.2263},
doi = {10.1002/spe.2263},
abstract = {The test case optimisation is an NP-complete, knowledge-driven, data-driven, and multidimensional search space partitioning and dimension reduction problem. In the multifaceted test case classification, partitioning and reducing the multidimensional test case fitness search space is the critical problem. The vague nature of fitness parameters, conflicting nature objectives, and ambiguity in the test case fitness evaluation have created and increased the uncertainty, the imprecision, and the incompleteness in the test case classification and selection. Because of the increasing ambiguity, the complexity, and the cost of software testing, automated test case classification and selection has emerged as an appropriate tool to classify test cases into predefined categories using the multifaceted concept. Most of the test cases affecting the performance of the classifier are irrelevant and redundant. A strong need therefore exists to devise an intelligent technique to identify and remove test cases affecting the performance of the classifier. For increasing the performance of classifier, multifaceted test case selection is used to reduce fitness search space to be searched. In this paper, a three-tier sequential framework is proposed for a multifaceted test case classification and selection. The first stage of the proposed framework is the fuzzy synthesis-based filtration approach for multifaceted test case fitness evaluation and classification. The second stage of the proposed framework is the fuzzy entropy-based filtration technique with a backward search strategy, used for estimating and reducing the ambiguity in test case fitness evaluation, classification, and selection. The third stage of the proposed framework is the ant colony optimisation-based wrapper technique with a forward search strategy, employed to select test cases from the output reduced test suite by the second stage. The proposed framework is tested on artefacts of benchmark applications. The results of the empirical study clearly show that the third stage of our proposed method outperforms the second and first stages, and the performance of the algorithms used in all three stages increases on average as the stages are escalating. The classification accuracy is enhanced by reducing the ambiguity in fitness and the classification of test cases, increasing the number of test cases accurately classified, and reducing the number in the test case pool to be exercised. Copyright © 2014 John Wiley &amp; Sons, Ltd.},
journal = {Softw. Pract. Exper.},
month = jul,
pages = {949–971},
numpages = {23},
keywords = {ambiguity, fitness evaluation index, fuzzy entropy, multidimensional fitness search space, multifaceted classification, test case fitness, test cases}
}

@article{10.1007/s10664-014-9303-2,
author = {Russo, Barbara and Succi, Giancarlo and Pedrycz, Witold},
title = {Mining system logs to learn error predictors: a case study of a telemetry system},
year = {2015},
issue_date = {August    2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9303-2},
doi = {10.1007/s10664-014-9303-2},
abstract = {Predicting system failures can be of great benefit to managers that get a better command over system performance. Data that systems generate in the form of logs is a valuable source of information to predict system reliability. As such, there is an increasing demand of tools to mine logs and provide accurate predictions. However, interpreting information in logs poses some challenges. This study discusses how to effectively mining sequences of logs and provide correct predictions. The approach integrates different machine learning techniques to control for data brittleness, provide accuracy of model selection and validation, and increase robustness of classification results. We apply the proposed approach to log sequences of 25 different applications of a software system for telemetry and performance of cars. On this system, we discuss the ability of three well-known support vector machines - multilayer perceptron, radial basis function and linear kernels - to fit and predict defective log sequences. Our results show that a good analysis strategy provides stable, accurate predictions. Such strategy must at least require high fitting ability of models used for prediction. We demonstrate that such models give excellent predictions both on individual applications - e.g., 1 % false positive rate, 94 % true positive rate, and 95 % precision - and across system applications - on average, 9 % false positive rate, 78 % true positive rate, and 95 % precision. We also show that these results are similarly achieved for different degree of sequence defectiveness. To show how good are our results, we compare them with recent studies in system log analysis. We finally provide some recommendations that we draw reflecting on our study.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {879–927},
numpages = {49},
keywords = {Classification and prediction of defective log sequences, Data mining, Information gain, Log analysis, Software maintenance, System logs}
}

@inproceedings{10.1145/2568225.2568269,
author = {Rahman, Foyzur and Khatri, Sameer and Barr, Earl T. and Devanbu, Premkumar},
title = {Comparing static bug finders and statistical prediction},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568269},
doi = {10.1145/2568225.2568269},
abstract = {The all-important goal of delivering better software at lower cost has led to a vital, enduring quest for ways to find and remove defects efficiently and accurately. To this end, two parallel lines of research have emerged over the last years. Static analysis seeks to find defects using algorithms that process well-defined semantic abstractions of code. Statistical defect prediction uses historical data to estimate parameters of statistical formulae modeling the phenomena thought to govern defect occurrence and predict where defects are likely to occur. These two approaches have emerged from distinct intellectual traditions and have largely evolved independently, in “splendid isolation”. In this paper, we evaluate these two (largely) disparate approaches on a similar footing. We use historical defect data to apprise the two approaches, compare them, and seek synergies. We find that under some accounting principles, they provide comparable benefits; we also find that in some settings, the performance of certain static bug-finders can be enhanced using information provided by statistical defect prediction.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {424–434},
numpages = {11},
keywords = {Empirical Research, Empirical Software Engineering, Fault Prediction, Inspection, Software Quality},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@inproceedings{10.1145/2593929.2600116,
author = {Harman, Mark and Jia, Yue and Langdon, William B. and Petke, Justyna and Moghadam, Iman Hemati and Yoo, Shin and Wu, Fan},
title = {Genetic improvement for adaptive software engineering (keynote)},
year = {2014},
isbn = {9781450328647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593929.2600116},
doi = {10.1145/2593929.2600116},
abstract = {This paper presents a brief outline of an approach to online genetic improvement. We argue that existing progress in genetic improvement can be exploited to support adaptivity. We illustrate our proposed approach with a 'dreaming smart device' example that combines online and offline machine learning and optimisation.},
booktitle = {Proceedings of the 9th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {1–4},
numpages = {4},
keywords = {Artificial Intelligence, Genetic Improvement, Machine Learning, Search Based Software Engineering},
location = {Hyderabad, India},
series = {SEAMS 2014}
}

@inproceedings{10.1145/3377811.3380361,
author = {Hoang, Thong and Kang, Hong Jin and Lo, David and Lawall, Julia},
title = {CC2Vec: distributed representations of code changes},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380361},
doi = {10.1145/3377811.3380361},
abstract = {Existing work on software patches often use features specific to a single task. These works often rely on manually identified features, and human effort is required to identify these features for each task. In this work, we propose CC2Vec, a neural network model that learns a representation of code changes guided by their accompanying log messages, which represent the semantic intent of the code changes. CC2Vec models the hierarchical structure of a code change with the help of the attention mechanism and uses multiple comparison functions to identify the differences between the removed and added code.To evaluate if CC2Vec can produce a distributed representation of code changes that is general and useful for multiple tasks on software patches, we use the vectors produced by CC2Vec for three tasks: log message generation, bug fixing patch identification, and just-in-time defect prediction. In all tasks, the models using CC2Vec outperform the state-of-the-art techniques.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {518–529},
numpages = {12},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1007/s11042-016-3605-x,
author = {Aminikhanghahi, Samaneh and Shin, Sung and Wang, Wei and Jeon, Soon I. and Son, Seong H.},
title = {A new fuzzy Gaussian mixture model (FGMM) based algorithm for mammography tumor image classification},
year = {2017},
issue_date = {Apr 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {7},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-016-3605-x},
doi = {10.1007/s11042-016-3605-x},
abstract = {Computer aided diagnosis systems are recently introduced to increase the accuracy of mammography interpretation. This paper introduces a new classification algorithm based on Fuzzy Gaussian Mixture Model (FGMM) by combining the power of Gaussian Mixture Model (GMM) and Fuzzy Logic System (FLS) for computer aided diagnosis system, to classify the detected regions in mammogram images into malignant or benign categories. The experimental results are obtained from a data set of 300 images taken from the Digital Database for Screening Mammography (DDSM, University of South Florida) for different classes. Confusion matrix analysis is used to measure the performance of the proposed FGMM system. The results show that the proposed FGMM classifier has achieved an overall Matthews Correlation Coefficient (MCC) classification quality of 86.16 %, with 93 % accuracy, 90 % sensitivity and 96 % specificity, and outperformed other classifiers in all aspects. The experimental results obtained from the developed classifier prove that the proposed technique will improve the diagnostic accuracy and reliability of radiologists' image interpretation in the diagnosis of breast cancer. The resulting breast cancer Computer Aided Diagnosis (CAD) detection system is a promising tool to provide preliminary decision support information to physicians for further diagnosis.},
journal = {Multimedia Tools Appl.},
month = apr,
pages = {10191–10205},
numpages = {15},
keywords = {Classification, Fuzzy, Gaussian mixture model, Mammography}
}

@inproceedings{10.5555/2623201.2623217,
author = {Pingclasai, Natthakul and Hata, Hideaki and Matsumoto, Ken-ichi},
title = {Classifying Bug Reports to Bugs and Other Requests Using Topic Modeling},
year = {2013},
isbn = {9781479921447},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Bug reports are widely used in several research areas such as bug prediction, bug triaging, and etc. The performance of these studies relies on the information from bug reports. Previous study showed that a significant number of bug reports are actually misclassified between bugs and non-bugs. However, classifying bug reports is a time-consuming task. In the previous study, researchers spent 90 days to classify manually more than 7,000 bug reports. To tackle this problem, we propose automatic bug report classification techniques. We apply topic modeling to the corpora of pre-processed bug reports of three open-source software projects with decision tree, naive Bayes classifier, and logistic regression. The performance in classification, measured in F-measure score, varies between 0.66-0.76, 0.65-0.77, and 0.71-0.82 for HTTPClient, Jackrabbit, and Lucene project respectively.},
booktitle = {Proceedings of the 2013 20th Asia-Pacific Software Engineering Conference (APSEC) - Volume 02},
pages = {13–18},
numpages = {6},
keywords = {bug classification, bug reports, topic modeling},
series = {APSEC '13}
}

@article{10.1007/s10664-011-9182-8,
author = {Turhan, Burak},
title = {On the dataset shift problem in software engineering prediction models},
year = {2012},
issue_date = {February  2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {1–2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-011-9182-8},
doi = {10.1007/s10664-011-9182-8},
abstract = {A core assumption of any prediction model is that test data distribution does not differ from training data distribution. Prediction models used in software engineering are no exception. In reality, this assumption can be violated in many ways resulting in inconsistent and non-transferrable observations across different cases. The goal of this paper is to explain the phenomena of conclusion instability through the dataset shift concept from software effort and fault prediction perspective. Different types of dataset shift are explained with examples from software engineering, and techniques for addressing associated problems are discussed. While dataset shifts in the form of sample selection bias and imbalanced data are well-known in software engineering research, understanding other types is relevant for possible interpretations of the non-transferable results across different sites and studies. Software engineering community should be aware of and account for the dataset shift related issues when evaluating the validity of research outcomes.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {62–74},
numpages = {13},
keywords = {Dataset shift, Defect prediction, Effort estimation, Prediction models}
}

@inproceedings{10.1109/ICRCCS.2009.19,
author = {Huang, Peng and Zhu, Jie},
title = {Predicting Defect-Prone Software Modules at Different Logical Levels},
year = {2010},
isbn = {9780769539270},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICRCCS.2009.19},
doi = {10.1109/ICRCCS.2009.19},
abstract = {Effective software defect estimation can bring cost reduction and efficient resources allocation in software development and testing. Usually, estimation of defect-prone modules is based on the supervised learning of the modules at the same logical level. Various practical issues may limit the availability or quality of the attribute-value vectors extracting from the high-level modules by software metrics. In this paper, the problem of estimating the defect in high-level software modules is investigated with a multi-instance learning (MIL) perspective. In detail, each high-level module is regarded as a bag of its low-level components, and the learning task is to estimate the defect-proneness of the bags. Several typical supervised learning and MIL algorithms are evaluated on a mission critical project from NASA. Compared to the selected supervised schemas, the MIL methods improve the performance of the software defect estimation models.},
booktitle = {Proceedings of the 2009 International Conference on Research Challenges in Computer Science},
pages = {37–40},
numpages = {4},
keywords = {kernel methods, multi-instance learning, software defect estimation, support vector machine},
series = {ICRCCS '09}
}

@article{10.4018/jitr.2015040102,
author = {Dess\`{\i}, Nicoletta and Pes, Barbara and Cannas, Laura Maria},
title = {An Evolutionary Approach for Balancing Effectiveness and Representation Level in Gene Selection},
year = {2015},
issue_date = {April 2015},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {2},
issn = {1938-7857},
url = {https://doi.org/10.4018/jitr.2015040102},
doi = {10.4018/jitr.2015040102},
abstract = {As data mining develops and expands to new application areas, feature selection also reveals various aspects to be considered. This paper underlines two aspects that seem to categorize the large body of available feature selection algorithms: the effectiveness and the representation level. The effectiveness deals with selecting the minimum set of variables that maximize the accuracy of a classifier and the representation level concerns discovering how relevant the variables are for the domain of interest. For balancing the above aspects, the paper proposes an evolutionary framework for feature selection that expresses a hybrid method, organized in layers, each of them exploits a specific model of search strategy. Extensive experiments on gene selection from DNA-microarray datasets are presented and discussed. Results indicate that the framework compares well with different hybrid methods proposed in literature as it has the capability of finding well suited subsets of informative features while improving classification accuracy.},
journal = {J. Inf. Technol. Res.},
month = apr,
pages = {16–33},
numpages = {18},
keywords = {Bioinformatics, Feature Selection, Genetic Algorithms, High-Dimensional Data, Microarray Data Analysis}
}

@article{10.1109/MS.2020.2987044,
author = {Zhang, Tao and Liu, Ying and Gao, Jerry and Gao, Li Peng and Cheng, Jing},
title = {Deep Learning-Based Mobile Application Isomorphic GUI Identification for Automated Robotic Testing},
year = {2020},
issue_date = {July-Aug. 2020},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {37},
number = {4},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2020.2987044},
doi = {10.1109/MS.2020.2987044},
abstract = {Fully black-box robotic testing is needed given the popularity of mobile applications. A critical constraining issue for generating graphical user interface (GUI) models is identifying isomorphic GUIs. We present a deep learningbased end-to-end trainable model to determine the similarity between GUIs and identify isomorphic GUIs.},
journal = {IEEE Softw.},
month = jul,
pages = {67–74},
numpages = {8}
}

@inproceedings{10.1109/AST.2017.7,
author = {Al-Hajjaji, Mustafa and Kr\"{u}ger, Jacob and Schulze, Sandro and Leich, Thomas and Saake, Gunter},
title = {Efficient product-line testing using cluster-based product prioritization},
year = {2017},
isbn = {9781538615485},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AST.2017.7},
doi = {10.1109/AST.2017.7},
abstract = {A software product-line comprises a set of products that share a common set of features. These features can be reused to customize a product to satisfy specific needs of certain customers or markets. As the number of possible products increases exponentially for new features, testing all products is infeasible. Existing testing approaches reduce their effort by restricting the number of products (sampling) and improve their effectiveness by considering the order of tests (prioritization). In this paper, we propose a cluster-based prioritization technique to sample similar products with respect to the feature selection. We evaluate our approach using feature models of different sizes and show that cluster-based prioritization can enhance the effectiveness of product-line testing.},
booktitle = {Proceedings of the 12th International Workshop on Automation of Software Testing},
pages = {16–22},
numpages = {7},
location = {Buenos Aires, Argentina},
series = {AST '17}
}

@article{10.1016/j.neucom.2021.05.039,
author = {Nie, Lun Yiu and Gao, Cuiyun and Zhong, Zhicong and Lam, Wai and Liu, Yang and Xu, Zenglin},
title = {CoreGen: Contextualized Code Representation Learning for Commit Message Generation},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {459},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.05.039},
doi = {10.1016/j.neucom.2021.05.039},
journal = {Neurocomput.},
month = oct,
pages = {97–107},
numpages = {11},
keywords = {Commit message generation, Code representation learning, Code-to-text generation, Self-supervised learning, Contextualized code representation}
}

@inproceedings{10.1145/3196321.3196326,
author = {Li, Xiaochen and Jiang, He and Liu, Dong and Ren, Zhilei and Li, Ge},
title = {Unsupervised deep bug report summarization},
year = {2018},
isbn = {9781450357142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196321.3196326},
doi = {10.1145/3196321.3196326},
abstract = {Bug report summarization is an effective way to reduce the considerable time in wading through numerous bug reports. Although some supervised and unsupervised algorithms have been proposed for this task, their performance is still limited, due to the particular characteristics of bug reports, including the evaluation behaviours in bug reports, the diverse sentences in software language and natural language, and the domain-specific predefined fields. In this study, we conduct the first exploration of the deep learning network on bug report summarization. Our approach, called DeepSum, is a novel stepped auto-encoder network with evaluation enhancement and predefined fields enhancement modules, which successfully integrates the bug report characteristics into a deep neural network. DeepSum is unsupervised. It significantly reduces the efforts on labeling huge training sets. Extensive experiments show that DeepSum outperforms the comparative algorithms by up to 13.2% and 9.2% in terms of F-score and Rouge-n metrics respectively over the public datasets, and achieves the state-of-the-art performance. Our work shows promising prospects for deep learning to summarize millions of bug reports.},
booktitle = {Proceedings of the 26th Conference on Program Comprehension},
pages = {144–155},
numpages = {12},
keywords = {bug report summarization, deep learning, mining software repositories, unsupervised learning},
location = {Gothenburg, Sweden},
series = {ICPC '18}
}

