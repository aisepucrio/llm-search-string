@inproceedings{10.1007/978-3-030-90785-3_16,
author = {Wang, Baoping and Wang, Wennan and Zhu, Linkai and Liu, Wenjian},
title = {Research on Cross-Project Software Defect Prediction Based on Machine Learning},
year = {2021},
isbn = {978-3-030-90784-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90785-3_16},
doi = {10.1007/978-3-030-90785-3_16},
abstract = {In recent years, machine learning technology has developed vigorously. The research on software defect prediction in the field of software engineering is increasingly adopting various algorithms of machine learning. This article has carried out a systematic literature review on the field of defect prediction. First, this article studies the development process of defect prediction, from correlation to prediction model. then this article studies the development process of cross-project defect prediction based on machine learning algorithms (naive Bayes, decision tree, random forest, neural network, etc.). Finally, this paper looks forward to the research difficulties and future directions of software defect prediction, such as imbalance in classification, cost of data labeling, and cross-project data distribution.},
booktitle = {Advances in Web-Based Learning – ICWL 2021: 20th International Conference, ICWL 2021, Macau, China, November 13–14, 2021, Proceedings},
pages = {160–165},
numpages = {6},
keywords = {Machine learning, Software defect prediction model, Metric},
location = {Macau, China}
}

@inproceedings{10.1145/3387940.3391463,
author = {Omri, Safa and Sinz, Carsten},
title = {Deep Learning for Software Defect Prediction: A Survey},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391463},
doi = {10.1145/3387940.3391463},
abstract = {Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {209–214},
numpages = {6},
keywords = {deep learning, machine learning, software defect prediction, software quality assurance, software testing},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3368926.3369711,
author = {Ha, Duy-An and Chen, Ting-Hsuan and Yuan, Shyan-Ming},
title = {Unsupervised methods for Software Defect Prediction},
year = {2019},
isbn = {9781450372459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368926.3369711},
doi = {10.1145/3368926.3369711},
abstract = {Software Defect Prediction (SDP) aims to assess software quality by using machine learning techniques. Recently, by proposing the connectivity-based unsupervised learning method, Zhang et al. have been proven that unsupervised classification has great potential to apply to this problem. Inspiring by this idea, in our work we try to replicate the results of Zhang et al.'s experiment and attempt to improve the performance by examining different techniques at each step of the approach using unsupervised learning methods to solve the SDP problem. Specifically, we try to follow the steps of the experiment described in their work strictly and examine three other clustering methods with four other ways for feature selection besides using all. To the best of our knowledge, these methods are first applied in SDP to evaluate their predictive power. For replicating the results, generally results in our experiments are not as good as the previous work. It may be due to we do not know which features are used in their experiment exactly. Fluid clustering and spectral clustering give better results than Newman clustering and CNM clustering in our experiments. Additionally, the experiments also show that using Kernel Principal Component Analysis (KPCA) or Non-Negative Matrix Factorization (NMF) for feature selection step gives better performance than using all features in the case of unlabeled data. Lastly, to make replicating our work easy, a lightweight framework is created and released on Github.},
booktitle = {Proceedings of the 10th International Symposium on Information and Communication Technology},
pages = {49–55},
numpages = {7},
keywords = {Community Structure Detection, Machine Learning, Software Defect Prediction, Software Engineering, Unsupervised Learning},
location = {Hanoi, Ha Long Bay, Viet Nam},
series = {SoICT '19}
}

@inproceedings{10.1145/3474198.3478215,
author = {Du, Xiaozhi and Yue, Hehe and Dong, Honglei},
title = {Software Defect Prediction Method based on Hybrid Sampling},
year = {2022},
isbn = {9781450390149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474198.3478215},
doi = {10.1145/3474198.3478215},
abstract = {Software defect prediction is an essential technology to provide guidance and assistance for software testers and developers. However, the problem of imbalanced data sets limits the effect and application of the software defect prediction. To address this issue, this paper proposes a software defect prediction method based on hybrid sampling, which combines the strategies of over-sampling with under-sampling. For minority class, over-sampling uses k-means to cluster samples, then adopts SMOTE to generate artificial data based on safe areas of the clustering outcome. For majority class, under-sampling uses logistic regression classifier to get the misclassification probability of each sample and its instance hardness value. Then the samples, whose instance hardness values are lower than the threshold, are removed from the datasets. The experimental results show that our method is superior to the previous methods. Compared with SMOTE-kNN, SMOTE-Tomek, SMOTE and DBSMOTE, the accuracy of our method is improved by 17.60%, 6.99%, 8.66% and 26.18% on average respectively.},
booktitle = {International Conference on Frontiers of Electronics, Information and Computation Technologies},
articleno = {93},
numpages = {9},
keywords = {Data imbalance, Hybrid sampling, Software defect prediction},
location = {Changsha, China},
series = {ICFEICT 2021}
}

@inproceedings{10.1145/3416508.3417114,
author = {Aljamaan, Hamoud and Alazba, Amal},
title = {Software defect prediction using tree-based ensembles},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417114},
doi = {10.1145/3416508.3417114},
abstract = {Software defect prediction is an active research area in software engineering. Accurate prediction of software defects assists software engineers in guiding software quality assurance activities. In machine learning, ensemble learning has been proven to improve the prediction performance over individual machine learning models. Recently, many Tree-based ensembles have been proposed in the literature, and their prediction capabilities were not investigated in defect prediction. In this paper, we will empirically investigate the prediction performance of seven Tree-based ensembles in defect prediction. Two ensembles are classified as bagging ensembles: Random Forest and Extra Trees, while the other five ensembles are boosting ensembles: Ada boost, Gradient Boosting, Hist Gradient Boosting, XGBoost and CatBoost. The study utilized 11 publicly available MDP NASA software defect datasets. Empirical results indicate the superiority of Tree-based bagging ensembles: Random Forest and Extra Trees ensembles over other Tree-based boosting ensembles. However, none of the investigated Tree-based ensembles was significantly lower than individual decision trees in prediction performance. Finally, Adaboost ensemble was the worst performing ensemble among all Tree-based ensembles.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {1–10},
numpages = {10},
keywords = {Bagging, Boosting, Classification, Ensemble Learning, Machine Learning, Prediction, Software Defect},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@article{10.3233/KES-210061,
author = {Shatnawi, Raed},
title = {Software fault prediction using machine learning techniques with metric thresholds},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {25},
number = {2},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-210061},
doi = {10.3233/KES-210061},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {159–172},
numpages = {14},
keywords = {Fault prediction, software metrics, threshold values, machine learning}
}

@article{10.1007/s00521-020-04960-1,
author = {Wang, Kechao and Liu, Lin and Yuan, Chengjun and Wang, Zhifei},
title = {Software defect prediction model based on LASSO–SVM},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {14},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04960-1},
doi = {10.1007/s00521-020-04960-1},
abstract = {A software defect report is a bug in the software system that developers and users submit to the software defect library during software development and maintenance. Managing a software defect report that is overwhelming is a challenging task. The traditional method is manual identification, which is time-consuming and laborious and delays the repair of important software defects. Based on the above background, the purpose of this paper is to study the software defect prediction (SDP) model based on LASSO–SVM. In this paper, the problem of poor prediction accuracy of most SDP models is proposed. A SDP model combining minimum absolute value compression and selection method and support vector machine algorithm is proposed. Firstly, the feature selection ability of the minimum absolute value compression and selection method is used to reduce the dimension of the original data set, and the data set not related to SDP is removed. Then, the optimal value of SVM is obtained by using the parameter optimization ability of cross-validation algorithm. Finally, the SDP is completed by the nonlinear computing ability of SVM. The accuracy of simulation results is 93.25% and 66.67%, recall rate is 78.04%, and f-metric is 72.72%. The results show that the proposed defect prediction model has higher prediction accuracy than the traditional defect prediction model, and the prediction speed is faster.},
journal = {Neural Comput. Appl.},
month = jul,
pages = {8249–8259},
numpages = {11},
keywords = {Software defect prediction, Feature selection, Support vector machine, Cross-validation}
}

@article{10.1007/s11063-020-10355-z,
author = {Niu, Liang and Wan, Jianwu and Wang, Hongyuan and Zhou, Kaiwei},
title = {Cost-sensitive Dictionary Learning for Software Defect Prediction},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {3},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-020-10355-z},
doi = {10.1007/s11063-020-10355-z},
abstract = {In recent years, software defect prediction has been recognized as a cost-sensitive learning problem. To deal with the unequal misclassification losses resulted by different classification errors, some cost-sensitive dictionary learning methods have been proposed recently. Generally speaking, these methods usually define the misclassification costs to measure the unequal losses and then propose to minimize the cost-sensitive reconstruction loss by embedding the cost information into the reconstruction function of dictionary learning. Although promising performance has been achieved, their cost-sensitive reconstruction functions are not well-designed. In addition, no sufficient attentions are paid to the coding coefficients which can also be helpful to reduce the reconstruction loss. To address these issues, this paper proposes a new cost-sensitive reconstruction loss function and introduces an additional cost-sensitive discrimination regularization for the coding coefficients. Both the two terms are jointly optimized in a unified cost-sensitive dictionary learning framework. By doing so, we can achieve the minimum reconstruction loss and thus obtain a more cost-sensitive dictionary for feature encoding of test data. In the experimental part, we have conducted extensive experiments on twenty-five software projects from four benchmark datasets of NASA, AEEEM, ReLink and Jureczko. The results, in comparison with ten state-of-the-art software defect prediction methods, demonstrate the effectiveness of learned cost-sensitive dictionary for software defect prediction.},
journal = {Neural Process. Lett.},
month = dec,
pages = {2415–2449},
numpages = {35},
keywords = {Software defect prediction, Cost-sensitive, Dictionary learning, Discrimination}
}

@article{10.1016/j.infsof.2021.106664,
author = {Yao, Jingxiu and Shepperd, Martin},
title = {The impact of using biased performance metrics on software defect prediction research},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106664},
doi = {10.1016/j.infsof.2021.106664},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {14},
keywords = {Software engineering, Machine learning, Software defect prediction, Computational experiment, Classification metrics}
}

@inproceedings{10.1007/978-3-030-58817-5_45,
author = {Balogun, Abdullateef O. and Lafenwa-Balogun, Fatimah B. and Mojeed, Hammed A. and Adeyemo, Victor E. and Akande, Oluwatobi N. and Akintola, Abimbola G. and Bajeh, Amos O. and Usman-Hamza, Fatimah E.},
title = {SMOTE-Based Homogeneous Ensemble Methods for Software Defect Prediction},
year = {2020},
isbn = {978-3-030-58816-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58817-5_45},
doi = {10.1007/978-3-030-58817-5_45},
abstract = {Class imbalance is a prevalent problem in machine learning which affects the prediction performance of classification algorithms. Software Defect Prediction (SDP) is no exception to this latent problem. Solutions such as data sampling and ensemble methods have been proposed to address the class imbalance problem in SDP. This study proposes a combination of Synthetic Minority Oversampling Technique (SMOTE) and homogeneous ensemble (Bagging and Boosting) methods for predicting software defects. The proposed approach was implemented using Decision Tree (DT) and Bayesian Network (BN) as base classifiers on defects datasets acquired from NASA software corpus. The experimental results showed that the proposed approach outperformed other experimental methods. High accuracy of 86.8% and area under operating receiver characteristics curve value of 0.93% achieved by the proposed technique affirmed its ability to differentiate between the defective and non-defective labels without bias.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part VI},
pages = {615–631},
numpages = {17},
keywords = {Software Defect Prediction, Class imbalance, Data sampling, Ensemble methods},
location = {Cagliari, Italy}
}

@article{10.1007/s10515-016-0194-x,
author = {Zhang, Zhi-Wu and Jing, Xiao-Yuan and Wang, Tie-Jian},
title = {Label propagation based semi-supervised learning for software defect prediction},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-016-0194-x},
doi = {10.1007/s10515-016-0194-x},
abstract = {Software defect prediction can automatically predict defect-prone software modules for efficient software test in software engineering. When the previous defect labels of modules are limited, predicting the defect-prone modules becomes a challenging problem. In static software defect prediction, there exist the similarity among software modules, a software module can be approximated by a sparse representation of the other part of the software modules, and class-imbalance problem, the number of defect-free modules is much larger than that of defective ones. In this paper, we propose to use graph based semi-supervised learning technique to predict software defect. By using Laplacian score sampling strategy for the labeled defect-free modules, we construct a class-balance labeled training dataset firstly. And then, we use a nonnegative sparse algorithm to compute the nonnegative sparse weights of a relationship graph which serve as clustering indicators. Lastly, on the nonnegative sparse graph, we use a label propagation algorithm to iteratively predict the labels of unlabeled software modules. We thus propose a nonnegative sparse graph based label propagation approach for software defect classification and prediction, which uses not only few labeled data but also abundant unlabeled ones to improve the generalization capability. We vary the size of labeled software modules from 10 to 30 % of all the datasets in the widely used NASA projects. Experimental results show that the NSGLP outperforms several representative state-of-the-art semi-supervised software defect prediction methods, and it can fully exploit the characteristics of static code metrics and improve the generalization capability of the software defect prediction model.},
journal = {Automated Software Engg.},
month = mar,
pages = {47–69},
numpages = {23},
keywords = {Label propagation, Nonnegative sparse graph, Nonnegative sparse graph based label propagation (NSGLP), Semi-supervised learning, Software defect prediction}
}

@article{10.1007/s11334-021-00399-2,
author = {Suresh Kumar, P. and Behera, H. S. and Nayak, Janmenjoy and Naik, Bighnaraj},
title = {Bootstrap aggregation ensemble learning-based reliable approach for software defect prediction by using characterized code feature},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-021-00399-2},
doi = {10.1007/s11334-021-00399-2},
abstract = {To ensure software quality, software defect prediction plays a prominent role for the software developers and practitioners. Software defect prediction can assist us with distinguishing software defect modules and enhance the software quality. In present days, many supervised machine learning algorithms have proved their efficacy to identify defective modules. However, those are limited to prove their major significance due to the limitations such as the adaptation of parameters with the environment and complexity. So, it is important to develop a key methodology to improve the efficiency of the prediction module. In this paper, an ensemble learning technique called&nbsp;Bootstrap&nbsp;aggregating has been proposed for software defect prediction object-oriented modules. The proposed method's accuracy, recall, precision, F-measure, and AUC-ROC efficiency were compared to those of many qualified machine learning algorithms. Simulation results and performance comparison are evident that the proposed method outperformed well compared to other approaches.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {355–379},
numpages = {25},
keywords = {Ensemble learning, Software defect prediction, Software reliability, Machine learning}
}

@article{10.4018/IJDSST.2020070105,
author = {Kakkar, Misha and Jain, Sarika and Bansal, Abhay and Grover, P. S.},
title = {Nonlinear Geometric Framework for Software Defect Prediction},
year = {2020},
issue_date = {Jul 2020},
publisher = {IGI Global},
address = {USA},
volume = {12},
number = {3},
issn = {1941-6296},
url = {https://doi.org/10.4018/IJDSST.2020070105},
doi = {10.4018/IJDSST.2020070105},
abstract = {Humans use the software in every walk of life thus it is essential to have the best quality software. Software defect prediction models assist in identifying defect prone modules with the help of historical data, which in turn improves software quality. Historical data consists of data related to modules /files/classes which are labeled as buggy or clean. As the number of buggy artifacts as less as compared to clean artifacts, the nature of historical data becomes imbalance. Due to this uneven distribution of the data, it difficult for classification algorithms to build highly effective SDP models. The objective of this study is to propose a new nonlinear geometric framework based on SMOTE and ensemble learning to improve the performance of SDP models. The study combines the traditional SMOTE algorithm and the novel ensemble Support Vector Machine (SVM) is used to develop the proposed framework called SMEnsemble. SMOTE algorithm handles the class imbalance problem by generating synthetic instances of the minority class. Ensemble learning generates multiple classification models to select the best performing SDP model. For experimentation, datasets from three different software repositories that contain both open source as well as proprietary projects are used in the study. The results show that SMEnsemble performs better than traditional methods for identifying the minority class i.e. buggy artifacts. Also, the proposed model performance is better than the latest state of Art SDP model- SMOTUNED. The proposed model is capable of handling imbalance classes when compared with traditional methods. Also, by carefully selecting the number of ensembles high performance can be achieved in less time.},
journal = {Int. J. Decis Support Syst. Technol.},
month = jul,
pages = {85–100},
numpages = {16},
keywords = {Classification, Data Analytics For Software Engineering, Ensemble Learning, Imbalanced Data, Preprocessing, SMOTE, Software Defect Prediction}
}

@article{10.1016/j.neucom.2019.11.067,
author = {Qiao, Lei and Li, Xuesong and Umer, Qasim and Guo, Ping},
title = {Deep learning based software defect prediction},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {385},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.11.067},
doi = {10.1016/j.neucom.2019.11.067},
journal = {Neurocomput.},
month = apr,
pages = {100–110},
numpages = {11},
keywords = {Software defect prediction, Deep learning, Software quality, Software metrics, Robustness evaluation}
}

@article{10.1007/s11219-016-9353-3,
author = {Bowes, David and Hall, Tracy and Petri\'{c}, Jean},
title = {Software defect prediction: do different classifiers find the same defects?},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9353-3},
doi = {10.1007/s11219-016-9353-3},
abstract = {During the last 10 years, hundreds of different defect prediction models have been published. The performance of the classifiers used in these models is reported to be similar with models rarely performing above the predictive performance ceiling of about 80% recall. We investigate the individual defects that four classifiers predict and analyse the level of prediction uncertainty produced by these classifiers. We perform a sensitivity analysis to compare the performance of Random Forest, Na\"{\i}ve Bayes, RPart and SVM classifiers when predicting defects in NASA, open source and commercial datasets. The defect predictions that each classifier makes is captured in a confusion matrix and the prediction uncertainty of each classifier is compared. Despite similar predictive performance values for these four classifiers, each detects different sets of defects. Some classifiers are more consistent in predicting defects than others. Our results confirm that a unique subset of defects can be detected by specific classifiers. However, while some classifiers are consistent in the predictions they make, other classifiers vary in their predictions. Given our results, we conclude that classifier ensembles with decision-making strategies not based on majority voting are likely to perform best in defect prediction.},
journal = {Software Quality Journal},
month = jun,
pages = {525–552},
numpages = {28},
keywords = {Machine learning, Prediction modelling, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-37352-8_13,
author = {Cui, Mengtian and Huang, Yameng and Luo, Jing},
title = {Software Defect Prediction Model Based on GA-BP Algorithm},
year = {2019},
isbn = {978-3-030-37351-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37352-8_13},
doi = {10.1007/978-3-030-37352-8_13},
abstract = {The novel software defect prediction model based on GA-BP algorithm was proposed in the paper considering the disadvantage of traditional BP (abbreviated for Back Propagation) neural network, which has the problem of easy to fall into local optimization when constructing software defect prediction model, and finally affects the prediction accuracy. Firstly, the optimization ability of GA (abbreviated for Genetic Algorithms) is introduced to optimize the weights and thresholds of Back Propagation neural network. Then the prediction model was constructed based on the GA-BP. Meanwhile the public dataset MDP from NASA was selected and the tool WEKA was used to clean the data and format conversion and as the result, four datasets is available. In the end, experimental results show that the proposed method in the paper is effective for software defect prediction.},
booktitle = {Cyberspace Safety and Security: 11th International Symposium, CSS 2019, Guangzhou, China, December 1–3, 2019, Proceedings, Part II},
pages = {151–161},
numpages = {11},
keywords = {Software defect prediction, Machine learning, Genetic Algorithms, BP neural network},
location = {Guangzhou, China}
}

@article{10.1007/s00500-020-05159-1,
author = {Jin, Cong},
title = {Software defect prediction model based on distance metric learning},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {1},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05159-1},
doi = {10.1007/s00500-020-05159-1},
abstract = {Software defect prediction (SDP) is a very important way for analyzing software quality and reducing development costs. The data during software lifecycle can be used to predict software defect. Currently, many SDP models have been proposed; however, their performance was not always ideal. In many existing prediction models based on machine learning, the distance metric between samples has significant impact on the performance of the SDP model. In addition, most samples are usually class imbalanced. To solve these issues, in this paper, a novel distance metric learning based on cost-sensitive learning (CSL) is proposed for reducing the impact of class imbalance of samples, which is then applied to the large margin distribution machine (LDM) to substitute the traditional kernel function. Further, the improvement and optimization of LDM based on CSL are also studied, and the improved LDM is used as the SDP model, called as CS-ILDM. Subsequently, the proposed CS-ILDM is applied to five publicly available data sets from the NASA Metrics Data Program repository and its performance is compared to other existing SDP models. The experimental results confirm that the proposed CS-ILDM not only has good prediction performance, but also can reduce the misprediction cost and avoid the impact of class imbalance of samples.},
journal = {Soft Comput.},
month = jan,
pages = {447–461},
numpages = {15},
keywords = {Software defect prediction, Software attributes, Distance metric learning, Cost-sensitive learning, Misprediction cost, Class imbalance of samples}
}

@article{10.1049/iet-sen.2019.0149,
author = {Deng, Jiehan and Lu, Lu and Qiu, Shaojian},
title = {Software defect prediction via LSTM},
year = {2020},
issue_date = {August 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {4},
url = {https://doi.org/10.1049/iet-sen.2019.0149},
doi = {10.1049/iet-sen.2019.0149},
abstract = {Software quality plays an important role in the software lifecycle. Traditional software defect prediction approaches mainly focused on using hand‐crafted features to detect defects. However, like human languages, programming languages contain rich semantic and structural information, and the cause of defective code is closely related to its context. Failing to catch this significant information, the performance of traditional approaches is far from satisfactory. In this study, the authors leveraged a long short‐term memory (LSTM) network to automatically learn the semantic and contextual features from the source code. Specifically, they first extract the program's Abstract Syntax Trees (ASTs), which is made up of AST nodes, and then evaluate what and how much information they can preserve for several node types. They traverse the AST of each file and fed them into the LSTM network to automatically the semantic and contextual features of the program, which is then used to determine whether the file is defective. Experimental results on several opensource projects showed that the proposed LSTM method is superior to the state‐of‐the‐art methods.},
journal = {IET Software},
month = aug,
pages = {443–450},
numpages = {8},
keywords = {feature extraction, learning (artificial intelligence), public domain software, program diagnostics, program debugging, software quality, recurrent neural nets, trees (mathematics), program abstract syntax trees, AST node sequence, semantic features, contextual features, LSTM, software quality, software lifecycle, software defect prediction approaches, machine learning techniques, programming languages, human languages, structural information, defective code, long short-term memory network, open source projects, numerical vectors, word embedding techniques}
}

@article{10.1002/smr.2362,
author = {Guo, Shikai and Dong, Jian and Li, Hui and Wang, Jiahui},
title = {Software defect prediction with imbalanced distribution by radius‐synthetic minority over‐sampling technique},
year = {2021},
issue_date = {July 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {7},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2362},
doi = {10.1002/smr.2362},
abstract = {Software defect prediction, which can identify the defect‐prone modules, is an effective technology to ensure the quality of software products. Due to the importance in software maintenance, many learning‐based software defect prediction models are presented in recent years. Actually, the defects usually occupy a very small proportions in software source codes; thus, the imbalanced distributions between defect‐prone modules and non‐defect‐prone modules increase the learning difficulty of the classification task. To address this issue, we present a random over‐sampling mechanism used to generate minority‐class samples from high‐dimensional sampling space to deal with the imbalanced distributions in software defect prediction, in which two constraints are applied to provide a robust way to generate new synthetic samples, that is, scaling the random over‐sampling scope to a reasonable area and distinguishing the majority‐class samples in a critical region. Based on nine open datasets of software projects, we experimentally verify that our presented method is effective on predict the defect‐prone modules, and the effect is superior to the traditional imbalanced processing methods.},
journal = {J. Softw. Evol. Process},
month = jul,
numpages = {21},
keywords = {imbalanced learning, software defect prediction, software quality}
}

@inproceedings{10.1145/3352411.3352412,
author = {Li, Ran and Zhou, Lijuan and Zhang, Shudong and Liu, Hui and Huang, Xiangyang and Sun, Zhong},
title = {Software Defect Prediction Based on Ensemble Learning},
year = {2019},
isbn = {9781450371414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352411.3352412},
doi = {10.1145/3352411.3352412},
abstract = {Software defect prediction is one of the important ways to guarantee the quality of software systems. Combining various algorithms in machine learning to predict software defects has become a hot topic in the current study. The paper uses the datasets of MDP as the experimental research objects and takes ensemble learning as research focus to construct software defect prediction model. With experimenting five different types of ensemble algorithms and analyzing the features and procedures, this paper discusses the best ensemble algorithm which is Random Forest through experimental comparison. Then we utilize the SMOTE over-sampling and Resample methods to improve the quality of datasets to build a complete new software defect prediction model. Therefore, the results show that the model can improve defect classification performance effectively.},
booktitle = {Proceedings of the 2019 2nd International Conference on Data Science and Information Technology},
pages = {1–6},
numpages = {6},
keywords = {Ensemble algorithm, Over-sampling, Software defect prediction, Under-sampling},
location = {Seoul, Republic of Korea},
series = {DSIT 2019}
}

@inproceedings{10.1109/ASE.2019.00071,
author = {Gong, Lina and Jiang, Shujuan and Wang, Rongcun and Jiang, Li},
title = {Empirical evaluation of the impact of class overlap on software defect prediction},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00071},
doi = {10.1109/ASE.2019.00071},
abstract = {Software defect prediction (SDP) utilizes the learning models to detect the defective modules in project, and their performance depends on the quality of training data. The previous researches mainly focus on the quality problems of class imbalance and feature redundancy. However, training data often contains some instances that belong to different class but have similar values on features, and this leads to class overlap to affect the quality of training data. Our goal is to investigate the impact of class overlap on software defect prediction. At the same time, we propose an improved K-Means clustering cleaning approach (IKMCCA) to solve both the class overlap and class imbalance problems. Specifically, we check whether K-Means clustering cleaning approach (KMCCA) or neighborhood cleaning learning (NCL) or IKMCCA is feasible to improve defect detection performance for two cases (i) within-project defect prediction (WPDP) (ii) cross-project defect prediction (CPDP). To have an objective estimate of class overlap, we carry out our investigations on 28 open source projects, and compare the performance of state-of-the-art learning models for the above-mentioned cases by using IKMCCA or KMCCA or NCL VS. without cleaning data. The experimental results make clear that learning models obtain significantly better performance in terms of balance, Recall and AUC for both WPDP and CPDP when the overlapping instances are removed. Moreover, it is better to consider both class overlap and class imbalance.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {698–709},
numpages = {12},
keywords = {K-Means clustering, class overlap, machine learning, software defect prediction},
location = {San Diego, California},
series = {ASE '19}
}

@article{10.1016/j.neucom.2019.05.100,
author = {Huo, Xuan and Li, Ming},
title = {On cost-effective software defect prediction: Classification or ranking?},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {363},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.05.100},
doi = {10.1016/j.neucom.2019.05.100},
journal = {Neurocomput.},
month = oct,
pages = {339–350},
numpages = {12},
keywords = {Software mining, Software defect prediction, Ranking model, Classification model}
}

@inproceedings{10.1007/978-3-030-62463-7_33,
author = {Lei, Tianwei and Xue, Jingfeng and Han, Weijie},
title = {Cross-Project Software Defect Prediction Based on Feature Selection and Transfer Learning},
year = {2020},
isbn = {978-3-030-62462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62463-7_33},
doi = {10.1007/978-3-030-62463-7_33},
abstract = {Cross-project software defect prediction solves the problem that traditional defect prediction can’t get enough data, but how to apply the model learned from the data of different mechanisms to the target data set is a new problem. At the same time, there is the problem that information redundancy in the training process leads to low accuracy. Based on the difference of projects, this paper uses MIC to filter features to solve the problem of information redundancy. At the same time, combined with the TrAdaboost algorithm, which is based on the idea of aggravating multiple classification error samples, this paper proposes a cross-project software prediction method based on feature selection and migration learning. Experimental results show that the algorithm proposed in this paper has better experimental results on AUC and F1.},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part III},
pages = {363–371},
numpages = {9},
keywords = {Transfer learning, TrAdaboost, MIC, Cross-project software defect prediction},
location = {Guangzhou, China}
}

@article{10.1007/s11277-017-5117-z,
author = {Zhou, Lijuan and Li, Ran and Zhang, Shudong and Wang, Hua},
title = {Imbalanced Data Processing Model for Software Defect Prediction},
year = {2018},
issue_date = {Sep 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {2},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-5117-z},
doi = {10.1007/s11277-017-5117-z},
abstract = {In the field of software engineering, software defect prediction is the hotspot of the researches which can effectively guarantee the quality during software development. However, the problem of class imbalanced datasets will affect the accuracy of overall classification of software defect prediction, which is the key issue to be solved urgently today. In order to better solve this problem, this paper proposes a model named ASRA which combines attribute selection, sampling technologies and ensemble algorithm. The model adopts the Chi square test of attribute selection and then utilizes the combined sampling technique which includes SMOTE over-sampling and under-sampling to remove the redundant attributes and make the datasets balance. Afterwards, the model ASRA is eventually established by ensemble algorithm named Adaboost with basic classifier J48 decision tree. The data used in the experiments comes from UCI datasets. It can draw the conclusion that the effect of software defect prediction classification which using this model is improved and better than before by comparing the precision P, F-measure and AUC values from the results of the experiments.},
journal = {Wirel. Pers. Commun.},
month = sep,
pages = {937–950},
numpages = {14},
keywords = {Attribute selection, Class imbalance, Ensemble algorithm, Sampling, Software defect prediction}
}

@inproceedings{10.1145/3489849.3489948,
author = {Lebiedz, Jacek and Wiszniewski, Bogdan},
title = {CAVE applications: from craft manufacturing to product line engineering},
year = {2021},
isbn = {9781450390927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489849.3489948},
doi = {10.1145/3489849.3489948},
abstract = {Product line engineering model is suitable for engineering related software products in an efficient manner, taking advantage of their similarities while managing their differences. Our feature driven software product line (SPL) solution based on that model allows for instantiation of different CAVE products based on the set of core assets and driven by a set of common VR features with the minimal budget and time to market.},
booktitle = {Proceedings of the 27th ACM Symposium on Virtual Reality Software and Technology},
articleno = {57},
numpages = {2},
keywords = {VR application features, core assets, production stations},
location = {Osaka, Japan},
series = {VRST '21}
}

@article{10.1007/s10515-021-00289-8,
author = {Ali, Aftab and Khan, Naveed and Abu-Tair, Mamun and Noppen, Joost and McClean, Sally and McChesney, Ian},
title = {Discriminating features-based cost-sensitive approach for software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-021-00289-8},
doi = {10.1007/s10515-021-00289-8},
abstract = {Correlated quality metrics extracted from a source code repository can be utilized to design a model to automatically predict defects in a software system. It is obvious that the extracted metrics will result in a highly unbalanced data, since the number of defects in a good quality software system should be far less than the number of normal instances. It is also a fact that the selection of the best discriminating features significantly improves the robustness and accuracy of a prediction model. Therefore, the contribution of this paper is twofold, first it selects the best discriminating features that help in accurately predicting a defect in a software component. Secondly, a cost-sensitive logistic regression and decision tree ensemble-based prediction models are applied to the best discriminating features for precisely predicting a defect in a software component. The proposed models are compared with the most recent schemes in the literature in terms of accuracy, area under the curve, and recall. The models are evaluated using 11 datasets and it is evident from the results and analysis that the performance of the proposed prediction models outperforms the schemes in the literature.},
journal = {Automated Software Engg.},
month = nov,
numpages = {18},
keywords = {Software bugs/defects, Machine learning models, Discriminating features, Cost-sensitivity, AUC, Recall}
}

@inproceedings{10.1007/978-3-030-79463-7_43,
author = {Lorentz, Joe and Hartmann, Thomas and Moawad, Assaad and Fouquet, Francois and Aouada, Djamila},
title = {Explaining Defect Detection with&nbsp;Saliency Maps},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_43},
doi = {10.1007/978-3-030-79463-7_43},
abstract = {The rising quality and throughput demands of the manufacturing domain require flexible, accurate and explainable computer-vision solutions for defect detection. Deep Neural Networks (DNNs) reach state-of-the-art performance on various computer-vision tasks but wide-spread application in the industrial domain is blocked by the lacking explainability of DNN decisions. A promising, human-readable solution is given by saliency maps, heatmaps highlighting the image areas that influence the classifier’s decision. This work evaluates a selection of saliency methods in the area of industrial quality assurance. To this end we propose the distance pointing game, a new metric to quantify the meaningfulness of saliency maps for defect detection. We provide steps to prepare a publicly available dataset on defective steel plates for the proposed metric. Additionally, the computational complexity is investigated to determine which methods could be integrated on industrial edge devices. Our results show that DeepLift, GradCAM and GradCAM++ outperform the alternatives while the computational cost is feasible for real time applications even on edge devices. This indicates that the respective methods could be used as an additional, autonomous post-classification step to explain decisions taken by intelligent quality assurance systems.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {506–518},
numpages = {13},
keywords = {XAI, Saliency, Defect detection, Edge AI},
location = {Kuala Lumpur, Malaysia}
}

@article{10.1016/j.eswa.2021.114637,
author = {Jin, Cong},
title = {Cross-project software defect prediction based on domain adaptation learning and optimization},
year = {2021},
issue_date = {Jun 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {171},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114637},
doi = {10.1016/j.eswa.2021.114637},
journal = {Expert Syst. Appl.},
month = jun,
numpages = {14},
keywords = {Software defect prediction, Optimization, Domain adaptation, Cross-project defect prediction, Improved quantum particle swarm optimization}
}

@phdthesis{10.5555/AAI28389525,
author = {Rahman, Ashiqur},
advisor = {R, Cordy, James},
title = {Software Defect Prediction Using Rich Contextualized Language Use Vectors},
year = {2020},
isbn = {9798708779250},
publisher = {Queen's University (Canada)},
abstract = {Context. Software defect prediction aims to find defect prone source code, and thus reduce the effort, time and cost involved with ensuring the quality of software systems. Both code and non-code metrics are commonly used in this process to train machine learning algorithms to predict software defects. Studies have shown that such metrics-based approaches are failing to give satisfactory results, and have reached a performance ceiling. This thesis explores the idea of using code profiles as an alternative to traditional metrics to predict software defects. This code profile-based method proves to be more promising than traditional metrics-based approaches.Aims. This thesis aims to improve software defect prediction using code profiles as feature variables in place of traditional metrics. Software code profiles encode the density of language feature use and the context of such use in Rich Contextualized Language Use Vectors (RCLUVs) by analysing the parse tree of the source code. This thesis explores whether code profiles can be used to train machine learning algorithms, and compares the performance of the derived models to traditional metrics-based approaches.Methods. To achieve these aims the learning curves of several machine learning algorithms are analyzed, and the performance of the derived models are evaluated against traditional metrics-based approaches. Two benchmark bug datasets, the Eclipse bug dataset and the Github bug database, are used to train the models.Results. The learning curves of the models show machine learning algorithms can learn from RCLUV-based code profiles. Performance evaluation against existing metrics-based approaches reveals that the code profile-based approach is more promising than traditional metrics-based approaches. However, the predictive performance of both metrics and code profile-based approaches drops in cross-version predictions.Conclusions. Unlike traditional metrics-based approaches, this thesis uses vectors generated by analyzing language feature use from the parse trees of source code as feature variables to train machine learning algorithms. Experimental results using learning algorithms encourages us to use software code profiles as an alternative to traditional metrics to predict software defects.},
note = {AAI28389525}
}

@article{10.1049/iet-sen.2017.0148,
author = {Li, Zhiqiang and Jing, Xiao-Yuan and Zhu, Xiaoke},
title = {Progress on approaches to software defect prediction},
year = {2018},
issue_date = {June 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2017.0148},
doi = {10.1049/iet-sen.2017.0148},
abstract = {Software defect prediction is one of the most popular research topics in software engineering. It aims to predict defect‐prone software modules before defects are discovered, therefore it can be used to better prioritise software quality assurance effort. In recent years, especially for recent 3 years, many new defect prediction studies have been proposed. The goal of this study is to comprehensively review, analyse and discuss the state‐of‐the‐art of defect prediction. The authors survey almost 70 representative defect prediction papers in recent years (January 2014–April 2017), most of which are published in the prominent software engineering journals and top conferences. The selected defect prediction papers are summarised to four aspects: machine learning‐based prediction algorithms, manipulating the data, effort‐aware prediction and empirical studies. The research community is still facing a number of challenges for building methods and many research opportunities exist. The identified challenges can give some practical guidelines for both software engineering researchers and practitioners in future software defect prediction.},
journal = {IET Software},
month = jun,
pages = {161–175},
numpages = {15},
keywords = {software quality, software reliability, quality assurance, research and development, software defect prediction, software engineering journals, defect-prone software modules, software quality assurance, machine learning-based prediction algorithms, data manipulation, effort-aware prediction, empirical studies}
}

@article{10.1016/j.infsof.2021.106662,
author = {Feng, Shuo and Keung, Jacky and Yu, Xiao and Xiao, Yan and Zhang, Miao},
title = {Investigation on the stability of SMOTE-based oversampling techniques in software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106662},
doi = {10.1016/j.infsof.2021.106662},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {14},
keywords = {Software defect prediction, Class imbalance, Oversampling, SMOTE, Empirical Software Engineering}
}

@inproceedings{10.1007/978-3-030-27455-9_1,
author = {Sarro, Federica},
title = {Search-Based Predictive Modelling for Software Engineering: How Far Have We Gone?},
year = {2019},
isbn = {978-3-030-27454-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27455-9_1},
doi = {10.1007/978-3-030-27455-9_1},
abstract = {In this keynote I introduce the use of Predictive Analytics for Software Engineering (SE) and then focus on the use of search-based heuristics to tackle long-standing SE prediction problems including (but not limited to) software development effort estimation and software defect prediction. I review recent research in Search-Based Predictive Modelling for SE in order to assess the maturity of the field and point out promising research directions. I conclude my keynote by discussing best practices for a rigorous and realistic empirical evaluation of search-based predictive models, a condicio sine qua non to facilitate the adoption of prediction models in software industry practices.},
booktitle = {Search-Based Software Engineering: 11th International Symposium, SSBSE 2019, Tallinn, Estonia, August 31 – September 1, 2019, Proceedings},
pages = {3–7},
numpages = {5},
keywords = {Predictive analytics, Predictive modelling, Search-based software engineering, Machine learning, Software analytics},
location = {Tallinn, Estonia}
}

@inproceedings{10.1007/978-3-030-86472-9_28,
author = {Shakhovska, Natalya and Yakovyna, Vitaliy},
title = {Feature Selection and Software Defect Prediction by Different Ensemble Classifiers},
year = {2021},
isbn = {978-3-030-86471-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86472-9_28},
doi = {10.1007/978-3-030-86472-9_28},
abstract = {Software defect prediction can improve its quality and is actively studied during the last decade. This paper focuses on the improvement of software defect prediction accuracy by proper feature selection techniques and using ensemble classifier. The software code metrics were used to predict the defective modules. JM1 public NASA dataset from PROMISE Software Engineering Repository was used in this study. Boruta, ACE, regsubsets and simple correlation are used for feature selection. The results of selection are formed based on hard voting of all features selectors. A new stacking classifier for software defects prediction is presented in this paper. The stacking classifier for defects prediction algorithm is based on combination of 5 weak classifiers. Random forest algorithm is used to combine the predictions. The obtained prediction accuracy was up to 96.26%.},
booktitle = {Database and Expert Systems Applications: 32nd International Conference, DEXA 2021, Virtual Event, September 27–30, 2021, Proceedings, Part I},
pages = {307–313},
numpages = {7},
keywords = {Ensemble of classifiers, Feature selection, Software defect analysis}
}

@article{10.1016/j.jss.2021.111026,
author = {Zhu, Kun and Ying, Shi and Zhang, Nana and Zhu, Dandan},
title = {Software defect prediction based on enhanced metaheuristic feature selection optimization and a hybrid deep neural network},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111026},
doi = {10.1016/j.jss.2021.111026},
journal = {J. Syst. Softw.},
month = oct,
numpages = {25},
keywords = {Software defect prediction, Metaheuristic feature selection, Whale optimization algorithm, Convolutional neural network, Kernel extreme learning machine}
}

@article{10.1155/2021/2323100,
author = {Liu, Wenjian and Wang, Baoping and Wang, Wennan and Ni, Tongguang},
title = {Deep Learning Software Defect Prediction Methods for Cloud Environments Research},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/2323100},
doi = {10.1155/2021/2323100},
abstract = {This paper provides an in-depth study and analysis of software defect prediction methods in a cloud environment and uses a deep learning approach to justify software prediction. A cost penalty term is added to the supervised part of the deep ladder network; that is, the misclassification cost of different classes is added to the model. A cost-sensitive deep ladder network-based software defect prediction model is proposed, which effectively mitigates the negative impact of the class imbalance problem on defect prediction. To address the problem of lack or insufficiency of historical data from the same project, a flow learning-based geodesic cross-project software defect prediction method is proposed. Drawing on data information from other projects, a migration learning approach was used to embed the source and target datasets into a Gaussian manifold. The kernel encapsulates the incremental changes between the differences and commonalities between the two domains. To this point, the subspace is the space of two distributional approximations formed by the source and target data transformations, with traditional in-project software defect classifiers used to predict labels. It is found that real-time defect prediction is more practical because it has a smaller amount of code to review; only individual changes need to be reviewed rather than entire files or packages while making it easier for developers to assign fixes to defects. More importantly, this paper combines deep belief network techniques with real-time defect prediction at a fine-grained level and TCA techniques to deal with data imbalance and proposes an improved deep belief network approach for real-time defect prediction, while trying to change the machine learning classifier underlying DBN for different experimental studies, and the results not only validate the effectiveness of using TCA techniques to solve the data imbalance problem but also show that the defect prediction model learned by the improved method in this paper has better prediction performance.},
journal = {Sci. Program.},
month = jan,
numpages = {11}
}

@inproceedings{10.1007/978-3-030-87986-0_15,
author = {Nagaraj, Deepak and Vadiraja, Pramod and Nalbach, Oliver and Werth, Dirk},
title = {Convolutional Autoencoder Based Textile Defect Detection Under Unconstrained Setting},
year = {2021},
isbn = {978-3-030-87985-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87986-0_15},
doi = {10.1007/978-3-030-87986-0_15},
abstract = {Automated visual defect detection on textile products under unconstrained setting is a much sought-after, and at the same time a challenging problem. In general, textile products are structurally complex and highly varied in design, which makes the development of a generalized approach using conventional image processing methods impossible. Deep supervised machine learning models have been very successful on similar problems but cannot be applied in this use-case due to lack of annotated data. This paper demonstrates a novel automated approach which still leverages on the ability of deep learning models to capture complex features on the textured and colored fabric, but in an unsupervised manner. Specifically, deep autoencoders are applied to capture the complex features, which are further processed by image processing techniques like thresholding and blob detection, subsequently leading to detection of defects in the images.},
booktitle = {Artificial Intelligence and Soft Computing: 20th International Conference, ICAISC 2021, Virtual Event, June 21–23, 2021, Proceedings, Part I},
pages = {168–181},
numpages = {14},
keywords = {Fabric defect detection, Unsupervised learning, Dimensionality reduction, Autoencoder}
}

@inproceedings{10.1007/978-3-031-02375-0_41,
author = {Liu, Zhoufeng and Gao, Chengli and Li, Chunlei and Huang, Ning and Guo, Zijing},
title = {Unsupervised Fabric Defect Detection Based on DCGAN with Component-Encoder},
year = {2021},
isbn = {978-3-031-02374-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-02375-0_41},
doi = {10.1007/978-3-031-02375-0_41},
abstract = {Deep learning technology has been proven applicable in fabric defect detection, but the detection performance relies on the large-scale labeled training sets. However, it is a tedious task to construct these annotated datasets in the industrial production line. To alleviate this issue, an unsupervised fabric defect detection model based on generative adversarial network (GAN) with component-encoder is proposed. Firstly, a component encoder is integrated into the deep convolutional generative adversarial network (DCGAN) for easily training the acquired positive sample image instead of random noise, and it is easier for the model to fit the data distribution of the samples. And to ensure the authenticity of the reconstructed image, two loss functions are adopted for the original DCGAN. In the testing stage, the test image patches are input into the trained model to generate the normal image patches. Finally, the residual image obtained by subtracting the original image from the reconstructed image is segmented to localize the defect region. Experimental results on the fabric dataset demonstrate the proposed model can locate the defect region well.},
booktitle = {Pattern Recognition: 6th Asian Conference, ACPR 2021, Jeju Island, South Korea, November 9–12, 2021, Revised Selected Papers, Part I},
pages = {557–568},
numpages = {12},
keywords = {Fabric defect detection, DCGAN, Unsupervised learning, Encoder, Image processing},
location = {Jeju Island, Korea (Republic of)}
}

@inproceedings{10.1145/3474124.3474127,
author = {Rajnish, Kumar and Bhattacharjee, Vandana and Chandrabanshi, Vishnu},
title = {Applying Cognitive and Neural Network Approach over Control Flow Graph for Software Defect Prediction},
year = {2021},
isbn = {9781450389204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474124.3474127},
doi = {10.1145/3474124.3474127},
booktitle = {Proceedings of the 2021 Thirteenth International Conference on Contemporary Computing},
pages = {13–17},
numpages = {5},
keywords = {CFGs, Cognitive Complexity, Cognitive Measures, Graph Convolutional Network, Neural Network, Software Defect Prediction},
location = {Noida, India},
series = {IC3-2021}
}

@article{10.3103/S1060992X21030024,
author = {Biradar, Maheshwari S. and Shiparamatti, B. G. and Patil, P. M.},
title = {Fabric Defect Detection Using Deep Convolutional Neural Network},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {3},
issn = {1060-992X},
url = {https://doi.org/10.3103/S1060992X21030024},
doi = {10.3103/S1060992X21030024},
journal = {Opt. Mem. Neural Netw.},
month = jul,
pages = {250–256},
numpages = {7},
keywords = {fabric defect detection, Deep Convolutional Neural Network, patterned fabric, non-patterned fabric}
}

@inproceedings{10.1145/3336294.3336321,
author = {Ghofrani, Javad and Kozegar, Ehsan and Fehlhaber, Anna Lena and Soorati, Mohammad Divband},
title = {Applying Product Line Engineering Concepts to Deep Neural Networks},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336321},
doi = {10.1145/3336294.3336321},
abstract = {Deep Neural Networks (DNNs) are increasingly being used as a machine learning solution thanks to the complexity of their architecture and hyperparameters-weights. A drawback is the excessive demand for massive computational power during the training process. Not only as a whole but parts of neural networks can also be in charge of certain functionalities. We present a novel challenge in an intersection between machine learning and variability management communities to reuse modules of DNNs without further training. Let us assume that we are given a DNN for image processing that recognizes cats and dogs. By extracting a part of the network, without additional training a new DNN should be divisible with the functionality of recognizing only cats. Existing research in variability management can offer a foundation for a product line of DNNs composing the reusable functionalities. An ideal solution can be evaluated based on its speed, granularity of determined functionalities, and the support for adding variability to the network. The challenge is decomposed in three subchallenges: feature extraction, feature abstraction, and the implementation of a product line of DNNs.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {72–77},
numpages = {6},
keywords = {deep neural networks, machine learning, software product lines, transfer learning, variability},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.5555/2684939.2684969,
author = {Ma, Ying and Pan, Weiwei and Zhu, Shunzhi and Yin, Huayi and Luo, Jian},
title = {An improved semi-supervised learning method for software defect prediction},
year = {2014},
issue_date = {September 2014},
publisher = {IOS Press},
address = {NLD},
volume = {27},
number = {5},
issn = {1064-1246},
abstract = {This paper presents an improved semi-supervised learning approach for defect prediction involving class imbalanced and limited labeled data problem. This approach employs random under-sampling technique to resample the original training set and updating training set in each round for co-train style algorithm. It makes the defect predictor more practical for real applications, by combating these problems. In comparison with conventional machine learning approaches, our method has significant superior performance. Experimental results also show that with the proposed learning approach, it is possible to design better method to tackle the class imbalanced problem in semi-supervised learning.},
journal = {J. Intell. Fuzzy Syst.},
month = sep,
pages = {2473–2480},
numpages = {8},
keywords = {Class Imbalance, Co-Train, Defect Prediction, Random Sampling, Semi-Supervised Learning}
}

@article{10.1016/j.neucom.2021.05.043,
author = {Harzevili, Nima Shiri and Alizadeh, Sasan H.},
title = {Analysis and modeling conditional mutual dependency of metrics in software defect prediction using latent variables},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {460},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.05.043},
doi = {10.1016/j.neucom.2021.05.043},
journal = {Neurocomput.},
month = oct,
pages = {309–330},
numpages = {22},
keywords = {Software defect prediction Software metrics, Naive Bayes classifier, Latent variable, 00–01, 99–00}
}

@article{10.1007/s10586-018-1730-1,
author = {Jayanthi, R. and Florence, Lilly},
title = {Software defect prediction techniques using metrics based on neural network classifier},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-018-1730-1},
doi = {10.1007/s10586-018-1730-1},
abstract = {Software industries strive for software quality improvement by consistent bug prediction, bug removal and prediction of fault-prone module. This area has attracted researchers due to its significant involvement in software industries. Various techniques have been presented for software defect prediction. Recent researches have recommended data-mining using machine learning as an important paradigm for software bug prediction. state-of-art software defect prediction task suffer from various issues such as classification accuracy. However, software defect datasets are imbalanced in nature and known fault prone due to its huge dimension. To address this issue, here we present a combined approach for software defect prediction and prediction of software bugs. Proposed approach delivers a concept of feature reduction and artificial intelligence where feature reduction is carried out by well-known principle component analysis (PCA) scheme which is further improved by incorporating maximum-likelihood estimation for error reduction in PCA data reconstruction. Finally, neural network based classification technique is applied which shows prediction results. A framework is formulated and implemented on NASA software dataset where four datasets i.e., KC1, PC3, PC4 and JM1 are considered for performance analysis using MATLAB simulation tool. An extensive experimental study is performed where confusion, precision, recall, classification accuracy etc. parameters are computed and compared with existing software defect prediction techniques. Experimental study shows that proposed approach can provide better performance for software defect prediction.},
journal = {Cluster Computing},
month = jan,
pages = {77–88},
numpages = {12},
keywords = {Defect prediction models, Machine learning techniques, Software defect prediction, Software metrics}
}

@inproceedings{10.1007/978-3-030-58802-1_25,
author = {Ronchieri, Elisabetta and Canaparo, Marco and Belgiovine, Mauro},
title = {Software Defect Prediction on Unlabelled Datasets: A Comparative Study},
year = {2020},
isbn = {978-3-030-58801-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58802-1_25},
doi = {10.1007/978-3-030-58802-1_25},
abstract = {Background: Defect prediction on unlabelled datasets is a challenging and widespread problem in software engineering. Machine learning is of great value in this context because it provides techniques - called unsupervised - that are applicable to unlabelled datasets. Objective: This study aims at comparing various approaches employed over the years on unlabelled datasets to predict the defective modules, i.e. the ones which need more attention in the testing phase. Our comparison is based on the measurement of performance metrics and on the real defective information derived from software archives. Our work leverages a new dataset that has been obtained by extracting and preprocessing its metrics from a C++ software. Method: Our empirical study has taken advantage of CLAMI with its improvement CLAMI+ that we have applied on high energy physics software datasets. Furthermore, we have used clustering techniques such as the K-means algorithm to find potentially critical modules. Results: Our experimental analysis have been carried out on 1 open source project with 34 software releases. We have applied 17 ML techniques to the labelled datasets obtained by following the CLAMI and CLAMI+ approaches. The two approaches have been evaluated by using different performance metrics, our results show that CLAMI+ performs better than CLAMI. The predictive average accuracy metric is around 95% for 4 ML techniques (4 out of 17) that show a Kappa statistic greater than 0.80. We applied K-means on the same dataset and obtained 2 clusters labelled according to the output of CLAMI and CLAMI+. Conclusion: Based on the results of the different statistical tests, we conclude that no significant performance differences have been found in the selected classification techniques.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part II},
pages = {333–353},
numpages = {21},
keywords = {Unlabelled dataset, Defect prediction, Unsupervised methods, Machine learning},
location = {Cagliari, Italy}
}

@article{10.1007/s11219-016-9342-6,
author = {Chen, Lin and Fang, Bin and Shang, Zhaowei and Tang, Yuanyan},
title = {Tackling class overlap and imbalance problems in software defect prediction},
year = {2018},
issue_date = {March     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9342-6},
doi = {10.1007/s11219-016-9342-6},
abstract = {Software defect prediction (SDP) is a promising solution to save time and cost in the software testing phase for improving software quality. Numerous machine learning approaches have proven effective in SDP. However, the unbalanced class distribution in SDP datasets could be a problem for some conventional learning methods. In addition, class overlap increases the difficulty for the predictors to learn the defective class accurately. In this study, we propose a new SDP model which combines class overlap reduction and ensemble imbalance learning to improve defect prediction. First, the neighbor cleaning method is applied to remove the overlapping non-defective samples. The whole dataset is then randomly under-sampled several times to generate balanced subsets so that multiple classifiers can be trained on these data. Finally, these individual classifiers are assembled with the AdaBoost mechanism to build the final prediction model. In the experiments, we investigated nine highly unbalanced datasets selected from a public software repository and confirmed that the high rate of overlap between classes existed in SDP data. We assessed the performance of our proposed model by comparing it with other state-of-the-art methods including conventional SDP models, imbalance learning and data cleaning methods. Test results and statistical analysis show that the proposed model provides more reasonable defect prediction results and performs best in terms of G-mean and AUC among all tested models.},
journal = {Software Quality Journal},
month = mar,
pages = {97–125},
numpages = {29},
keywords = {Class imbalance, Class overlap, Machine learning, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-92273-3_53,
author = {Lang, Jiulin and Tang, Chenwei and Gao, Yi and Lv, Jiancheng},
title = {Knowledge Distillation Method for&nbsp;Surface Defect Detection},
year = {2021},
isbn = {978-3-030-92272-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-92273-3_53},
doi = {10.1007/978-3-030-92273-3_53},
abstract = {In this paper, we propose a multi-scale attention mechanism-guided knowledge distillation method for surface defect detection. Enables a lighter student model to mimic the complex teacher model through the use of knowledge distillation techniques, the proposed method improves the defect detection accuracy and maintains high real-time performance, simultaneously. Specifically, we first present a multi-scale fusion-based teacher network. Owing to the fusion of two resolution scales features, the teacher network can keep high compatibility with the low-resolution student network during knowledge distillation, so as to better direct the student model. Then, in the process of knowledge distillation, attentional mechanisms were introduced with the aim of enabling the student network to more effectively mimic the foreground attention map and features of the teacher network. Finally, in order to address the imbalance of foreground and background in defect detection, we introduce a class-weighted cross entropy loss. Experiments conducted on three benchmark datasets proved the validity and efficiency of the proposed method in surface defect detection.},
booktitle = {Neural Information Processing: 28th International Conference, ICONIP 2021, Sanur, Bali, Indonesia, December 8–12, 2021, Proceedings, Part IV},
pages = {644–655},
numpages = {12},
keywords = {Surface defect detection, Knowledge distillation, Multi-scale fusion, Attention mechanism},
location = {Sanur, Bali, Indonesia}
}

@article{10.1007/s00500-021-06096-3,
author = {Pandey, Sushant Kumar and Tripathi, Anil Kumar},
title = {An empirical study toward dealing with noise and class imbalance issues in software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {21},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06096-3},
doi = {10.1007/s00500-021-06096-3},
abstract = {The quality of the defect datasets is a critical issue in the domain of software defect prediction (SDP). These datasets are obtained through the mining of software repositories. Recent studies claim over the quality of the defect dataset. It is because of inconsistency between bug/clean fix keyword in fault reports and the corresponding link in the change management logs. Class Imbalance (CI) problem is also a big challenging issue in SDP models. The defect prediction method trained using noisy and imbalanced data leads to inconsistent and unsatisfactory results. Combined analysis over noisy instances and CI problem needs to be required. To the best of our knowledge, there are insufficient studies that have been done over such aspects. In this paper, we deal with the impact of noise and CI problem on five baseline SDP models; we manually added the various noise level (0–80%) and identified its impact on the performance of those SDP models. Moreover, we further provide guidelines for the possible range of tolerable noise for baseline models. We have also suggested the SDP model, which has the highest noise tolerable ability and outperforms over other classical methods. The True Positive Rate (TPR) and False Positive Rate (FPR) values of the baseline models reduce between 20–30% after adding 10–40% noisy instances. Similarly, the ROC (Receiver Operating Characteristics) values of SDP models reduce to 40–50%. The suggested model leads to avoid noise between 40–60% as compared to other traditional models.},
journal = {Soft Comput.},
month = nov,
pages = {13465–13492},
numpages = {28},
keywords = {Software testing, Software fault prediction, Class imbalance, Noisy instance, Machine learning, Software metrics, Fault proneness}
}

@inproceedings{10.1145/3374549.3374553,
author = {Zong, Liang},
title = {Classification Based Software Defect Prediction Model for Finance Software System - An Industry Study},
year = {2020},
isbn = {9781450376495},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374549.3374553},
doi = {10.1145/3374549.3374553},
abstract = {Automated software defect prediction is an important and fundamental activity in the domain of software development. Successful software defect prediction can save testing effort thus reduce the time and cost for software development. However, software systems for finance company are inherently large and complex with numerous interfaces with other systems. Thus, identifying and selecting a good model and a set of features is important but challenging problem. In our paper, we first define the problem we want to solve. Then we propose a prediction model based on binary classification and a set of novel features, which is more specific for finance software systems. We collected 15 months real production data and labelled it as our dataset. The experiment shows our model and features can give a better prediction accuracy for finance systems. In addition, we demonstrate how our prediction model helps improve our production quality further. Unlike other research papers, our proposal focuses to solve problem in real finance industry.},
booktitle = {Proceedings of the 2019 3rd International Conference on Software and E-Business},
pages = {60–65},
numpages = {6},
keywords = {Faulty change, Finance system, Machine learning, Software defect prediction},
location = {Tokyo, Japan},
series = {ICSEB '19}
}

@article{10.1007/s10515-011-0092-1,
author = {Li, Ming and Zhang, Hongyu and Wu, Rongxin and Zhou, Zhi-Hua},
title = {Sample-based software defect prediction with active and semi-supervised learning},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0092-1},
doi = {10.1007/s10515-011-0092-1},
abstract = {Software defect prediction can help us better understand and control software quality. Current defect prediction techniques are mainly based on a sufficient amount of historical project data. However, historical data is often not available for new projects and for many organizations. In this case, effective defect prediction is difficult to achieve. To address this problem, we propose sample-based methods for software defect prediction. For a large software system, we can select and test a small percentage of modules, and then build a defect prediction model to predict defect-proneness of the rest of the modules. In this paper, we describe three methods for selecting a sample: random sampling with conventional machine learners, random sampling with a semi-supervised learner and active sampling with active semi-supervised learner. To facilitate the active sampling, we propose a novel active semi-supervised learning method ACoForest which is able to sample the modules that are most helpful for learning a good prediction model. Our experiments on PROMISE datasets show that the proposed methods are effective and have potential to be applied to industrial practice.},
journal = {Automated Software Engg.},
month = jun,
pages = {201–230},
numpages = {30},
keywords = {Active semi-supervised learning, Machine learning, Quality assurance, Sampling, Software defect prediction}
}

@book{10.5555/3175829,
author = {Rashid, Ekbal and Rashid, Ekbal},
title = {Enhancing Software Fault Prediction With Machine Learning: Emerging Research and Opportunities},
year = {2017},
isbn = {1522531858},
publisher = {IGI Global},
address = {USA},
edition = {1st},
abstract = {Software development and design is an intricate and complex process that requires a multitude of steps to ultimately create a quality product. One crucial aspect of this process is minimizing potential errors through software fault prediction. Enhancing Software Fault Prediction With Machine Learning: Emerging Research and Opportunities is an innovative source of material on the latest advances and strategies for software quality prediction. Including a range of pivotal topics such as case-based reasoning, rate of improvement, and expert systems, this book is an ideal reference source for engineers, researchers, academics, students, professionals, and practitioners interested in novel developments in software design and analysis.}
}

@article{10.1016/j.jss.2018.06.025,
author = {\"{O}zak\i{}nc\i{}, Rana and Tarhan, Ay\c{c}a},
title = {Early software defect prediction: A systematic map and review},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.06.025},
doi = {10.1016/j.jss.2018.06.025},
journal = {J. Syst. Softw.},
month = oct,
pages = {216–239},
numpages = {24},
keywords = {Early defect prediction, Software defect, Software quality, Prediction model, Systematic mapping, Systematic literature review}
}

@article{10.1016/j.ins.2018.02.027,
author = {Miholca, Diana-Lucia and Czibula, Gabriela and Czibula, Istvan Gergely},
title = {A novel approach for software defect prediction through hybridizing gradual relational association rules with artificial neural networks},
year = {2018},
issue_date = {May 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {441},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2018.02.027},
doi = {10.1016/j.ins.2018.02.027},
abstract = {The growing complexity of software projects requires increasing consideration of their analysis and testing. Identifying defective software entities is essential for software quality assurance and it also improves activities related to software testing. In this study, we developed a novel supervised classification method called HyGRAR for software defect prediction. HyGRAR is a non-linear hybrid model that combines gradual relational association rule mining and artificial neural networks to discriminate between defective and non-defective software entities. Experiments performed based on 10 open-source data sets demonstrated the excellent performance of the HYGRAR classifier. HyGRAR performed better than most of the previously proposed approaches for software defect prediction in performance evaluations using the same data sets.},
journal = {Inf. Sci.},
month = may,
pages = {152–170},
numpages = {19},
keywords = {Artificial neural network, Gradual relational association rule, Machine learning, Software defect prediction}
}

@inproceedings{10.1145/3484274.3484285,
author = {Xu, Qinyan and Zhou, Liang},
title = {Straw Defect Detection Algorithm Based on Pruned YOLOv3},
year = {2021},
isbn = {9781450390477},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3484274.3484285},
doi = {10.1145/3484274.3484285},
abstract = {To solve the problem of defect detection in straw pipeline production, this paper proposes an efficient and fast straw defect detection algorithm (IPOY) based on pruned YOLOv3. Algorithm adopts YOLOv3 model, and then trains the model with channel sparsity regularization, prunes channels with small scaling factors after sparse training, finally fine-tune the pruned network. This process was iterated several times to compress the YOLOv3 model to achieve a lighter model volume, reduce the computational cost of the model, and make the model suitable for industrial production to facilitate application migration to mobile devices. Experimental results show that the proposed algorithm can compress the volume of YOLOv3 model to the maximum extent and maintain the high precision of detection.},
booktitle = {Proceedings of the 4th International Conference on Control and Computer Vision},
pages = {64–69},
numpages = {6},
keywords = {Defect detection, Prune, Straw, YOLOv3},
location = {Macau, China},
series = {ICCCV '21}
}

@inproceedings{10.1109/IRI.2018.00047,
author = {Xu, Ling and Wang, Bei and Liu, Ling and Zhou, Mo and Liao, Shengping and Yan, Meng},
title = {Misclassification Cost-Sensitive Software Defect Prediction},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IRI.2018.00047},
doi = {10.1109/IRI.2018.00047},
abstract = {Software defect prediction helps developers focus on defective modules for efficient software quality assurance. A common goal shared by existing software defect prediction methods is to attain low classification error rates. These proposals suffer from two practical problems: (i) Most of the prediction methods rely on a large number of labeled training data. However, collecting labeled data is a difficult and expensive task. It is hard to obtain classification labels over new software projects or existing projects without historical defect data. (ii) Software defect datasets are highly imbalanced. In many real-world applications, the misclassification cost of defective modules is generally several times higher than that of non-defective ones. In this paper, we present a misclassification Cost-sensitive approach to Software Defect Prediction (CSDP). The CSDP approach is novel in two aspects: First, CSDP addresses the problem of unlabeled software detect datasets by combining an unsupervised sampling method with a domain specific misclassification cost model. This preprocessing step selectively samples a small percentage of modules through estimating their classification labels. Second, CSDP builds a cost-sensitive support vector machine model to predict defect-proneness of the rest of modules with both overall classification error rate and domain specific misclassification cost as quality metrics. CSDP is evaluated on four NASA projects. Experimental results highlight three interesting observations: (1) CSDP achieves higher Normalized Expected Cost of Misclassification (NECM) compared with state-of-art supervised learning models under imbalanced training data with limited labeling. (2) CSDP outperforms state-of-art semi-supervised learning methods, which disregards classification costs, especially in recall rate. (3) CSDP enhanced through unsupervised sampling as a preprocessing step prior to training and prediction outperforms the baseline CSDP without the sampling process.},
booktitle = {2018 IEEE International Conference on Information Reuse and Integration (IRI)},
pages = {256–263},
numpages = {8},
location = {Salt Lake City, UT, USA}
}

@article{10.1007/s10664-020-09861-4,
author = {Morasca, Sandro and Lavazza, Luigi},
title = {On the assessment of software defect prediction models via ROC curves},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09861-4},
doi = {10.1007/s10664-020-09861-4},
abstract = {Software defect prediction models are classifiers often built by setting a threshold t on a defect proneness model, i.e., a scoring function. For instance, they classify a software module non-faulty if its defect proneness is below t and positive otherwise. Different values of t may lead to different defect prediction models, possibly with very different performance levels. Receiver Operating Characteristic (ROC) curves provide an overall assessment of a defect proneness model, by taking into account all possible values of t and thus all defect prediction models that can be built based on it. However, using a defect proneness model with a value of t is sensible only if the resulting defect prediction model has a performance that is at least as good as some minimal performance level that depends on practitioners’ and researchers’ goals and needs. We introduce a new approach and a new performance metric (the Ratio of Relevant Areas) for assessing a defect proneness model by taking into account only the parts of a ROC curve corresponding to values of t for which defect proneness models have higher performance than some reference value. We provide the practical motivations and theoretical underpinnings for our approach, by: 1) showing how it addresses the shortcomings of existing performance metrics like the Area Under the Curve and Gini’s coefficient; 2) deriving reference values based on random defect prediction policies, in addition to deterministic ones; 3) showing how the approach works with several performance metrics (e.g., Precision and Recall) and their combinations; 4) studying misclassification costs and providing a general upper bound for the cost related to the use of any defect proneness model; 5) showing the relationships between misclassification costs and performance metrics. We also carried out a comprehensive empirical study on real-life data from the SEACRAFT repository, to show the differences between our metric and the existing ones and how more reliable and less misleading our metric can be.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3977–4019},
numpages = {43},
keywords = {Software defect prediction model, Software defect proneness, ROC, Thresholds, AUC, Gini}
}

@article{10.1007/s11554-021-01130-x,
author = {Feng, Chuncheng and Zhang, Hua and Li, Yonglong and Wang, Shuang and Wang, Haoran},
title = {Efficient real-time defect detection for spillway tunnel using deep learning},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {6},
issn = {1861-8200},
url = {https://doi.org/10.1007/s11554-021-01130-x},
doi = {10.1007/s11554-021-01130-x},
abstract = {A spillway tunnel eroded by high-speed water for a long time is prone to the rebar-exposed defects. Therefore, regular defect detection is very important for the safety of the hydropower station. The images of spillway tunnel are obtained by erecting scaffolding, and then the defects are manually recognized. This traditional method has some disadvantages such as high risk, inefficiently, time consumption and strong subjectivity. To improve the efficiency of defect detection, a real-time method is proposed for spillway tunnel defect detection (STDD) using deep learning. First, images of a spillway tunnel are collected by an Unmanned Aerial Vehicle (UAV) system and raw images are cropped and labeled to create a dataset of rebar-exposed defects. Then, the lightweight STDD network is developed using separable convolution and asymmetric convolution, and the network is trained and tested on the dataset. To evaluate the performance of STDD network, a comparative experiment is conducted with other networks. The results show that the STDD network has better detection performance. For defect segmentation, the recall, precision, F1 and mean intersection over union (mIoU) are 89.92%, 93.48%, 91.59%, and 91.73%, respectively. The STDD network has 1.7&nbsp;M parameters, and the average inference time is 14.08&nbsp;ms. In summary, the proposed STDD network achieves accurate and real-time defect detection for spillway tunnel, which can provide reliable support for the structure safety evaluation.},
journal = {J. Real-Time Image Process.},
month = dec,
pages = {2377–2387},
numpages = {11},
keywords = {Real-time, Spillway tunnel, Defect detection, Deep learning, UAV, Rebar exposed}
}

@inproceedings{10.1007/978-3-030-29551-6_23,
author = {Miholca, Diana-Lucia and Czibula, Gabriela},
title = {Software Defect Prediction Using a Hybrid Model Based on Semantic Features Learned from the Source Code},
year = {2019},
isbn = {978-3-030-29550-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-29551-6_23},
doi = {10.1007/978-3-030-29551-6_23},
abstract = {Software defect prediction has extensive applicability thus being a very active research area in Search-Based Software Engineering. A high proportion of the software defects are caused by violated couplings. In this paper, we investigate the relevance of semantic coupling in assessing the software proneness to defects. We propose a hybrid classification model combining Gradual Relational Association Rules with Artificial Neural Networks, which detects the defective software entities based on semantic features automatically learned from the source code. The experiments we have performed led to results that confirm the interplay between conceptual coupling and software defects proneness.},
booktitle = {Knowledge Science, Engineering and Management: 12th International Conference, KSEM 2019, Athens, Greece, August 28–30, 2019, Proceedings, Part I},
pages = {262–274},
numpages = {13},
keywords = {Software defect prediction, Machine learning, Conceptual coupling},
location = {Athens, Greece}
}

@article{10.1504/ijcat.2020.110428,
author = {Bai, Xue and Zhou, Hua and Yang, Hongji and Wang, Dong},
title = {Connecting historical changes for cross-version software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {63},
number = {4},
issn = {0952-8091},
url = {https://doi.org/10.1504/ijcat.2020.110428},
doi = {10.1504/ijcat.2020.110428},
abstract = {In the whole software life cycle, software defects are inevitable and increase the cost of software development and evolution. Cross-Version Software Defect Prediction (CVSDP) aims at learning the defect patterns from the historical data of previous software versions to distinguish buggy software modules from clean ones. In CVSDP, metrics are intrinsic properties associated with the external manifestation of defects. However, traditional software defect measures ignore the sequential information of changes during software evolution process which may play a crucial role in CVSDP. Therefore, researchers tried to connect traditional metrics across versions as a new kind of evolution metrics. This study proposes a new way to connect historical sequence of metrics based on change sequence named HCSM and designs a novel deep learning algorithm GDNN as a classifier to process it. Compared to the traditional metrics approaches and other relevant approaches, the proposed approach fits in projects with stable and orderly defect control trend.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {371–383},
numpages = {12},
keywords = {software testing, cross-version defect prediction, software metrics, historical change sequences, deep learning, DNN, deep neural networks, gate recurrent unit}
}

@article{10.1016/j.jss.2021.111038,
author = {Eken, Beyza and Tosun, Ayse},
title = {Investigating the performance of personalized models for software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {181},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111038},
doi = {10.1016/j.jss.2021.111038},
journal = {J. Syst. Softw.},
month = nov,
numpages = {17},
keywords = {Personalized, Change-level, Defect prediction, Software recommendation systems}
}

@book{10.5555/2911053,
author = {Mistrik, Ivan and Soley, Richard M. and Ali, Nour and Grundy, John and Tekinerdogan, Bedir},
title = {Software Quality Assurance: In Large Scale and Complex Software-intensive Systems},
year = {2015},
isbn = {0128023015},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st},
abstract = {Software Quality Assurance in Large Scale and Complex Software-intensive Systems presents novel and high-quality research related approaches that relate the quality of software architecture to system requirements, system architecture and enterprise-architecture, or software testing. Modern software has become complex and adaptable due to the emergence of globalization and new software technologies, devices and networks. These changes challenge both traditional software quality assurance techniques and software engineers to ensure software quality when building today (and tomorrows) adaptive, context-sensitive, and highly diverse applications. This edited volume presents state of the art techniques, methodologies, tools, best practices and guidelines for software quality assurance and offers guidance for future software engineering research and practice. Each contributed chapter considers the practical application of the topic through case studies, experiments, empirical validation, or systematic comparisons with other approaches already in practice. Topics of interest include, but are not limited, to: quality attributes of system/software architectures; aligning enterprise, system, and software architecture from the point of view of total quality; design decisions and their influence on the quality of system/software architecture; methods and processes for evaluating architecture quality; quality assessment of legacy systems and third party applications; lessons learned and empirical validation of theories and frameworks on architectural quality; empirical validation and testing for assessing architecture quality.Focused on quality assurance at all levels of software design and developmentCovers domain-specific software quality assurance issues e.g. for cloud, mobile, security, context-sensitive, mash-up and autonomic systemsExplains likely trade-offs from design decisions in the context of complex software system engineering and quality assuranceIncludes practical case studies of software quality assurance for complex, adaptive and context-critical systems}
}

@article{10.1007/s11227-019-03051-w,
author = {NezhadShokouhi, Mohammad Mahdi and Majidi, Mohammad Ali and Rasoolzadegan, Abbas},
title = {Software defect prediction using over-sampling and feature extraction based on Mahalanobis distance},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {1},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-019-03051-w},
doi = {10.1007/s11227-019-03051-w},
abstract = {As the size of software projects becomes larger, software defect prediction (SDP) will play a key role in allocating testing resources reasonably, reducing testing costs, and speeding up the development process. Most SDP methods have used machine learning techniques based on common software metrics such as Halstead and McCabe’s cyclomatic. Datasets produced by these metrics usually do not follow Gaussian distribution, and also, they have overlaps in defect and non-defect classes. In addition, in many of software defect datasets, the number of defective modules (minority class) is considerably less than non-defective modules (majority class). In this situation, the performance of machine learning methods is reduced dramatically. Therefore, we first need to create a balance between minority and majority classes and then transfer the samples into a new space in which pair samples with same class (must-link set) are near to each other as close as possible and pair samples with different classes (cannot-link) stay as far as possible. To achieve the mentioned objectives, in this paper, Mahalanobis distance in two manners will be used. First, the minority class is oversampled based on the Mahalanobis distance such that generated synthetic data are more diverse from other minority data, and minority class distribution is not changed significantly. Second, a feature extraction method based on Mahalanobis distance metric learning is used which try to minimize distances of sample pairs in must-links and maximize the distance of sample pairs in cannot-links. To demonstrate the effectiveness of the proposed method, we performed some experiments on 12 publicly available datasets which are collected NASA repositories and compared its result by some powerful previous methods. The performance is evaluated in F-measure, G-Mean, and Matthews correlation coefficient. Generally, the proposed method has better performance as compared to the mentioned methods.},
journal = {J. Supercomput.},
month = jan,
pages = {602–635},
numpages = {34},
keywords = {Software defect prediction, Software metrics, Mahalanobis distance, Over-sampling, Feature extraction}
}

@article{10.1007/s10515-015-0179-1,
author = {Wang, Tiejian and Zhang, Zhiwu and Jing, Xiaoyuan and Zhang, Liqiang},
title = {Multiple kernel ensemble learning for software defect prediction},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-015-0179-1},
doi = {10.1007/s10515-015-0179-1},
abstract = {Software defect prediction aims to predict the defect proneness of new software modules with the historical defect data so as to improve the quality of a software system. Software historical defect data has a complicated structure and a marked characteristic of class-imbalance; how to fully analyze and utilize the existing historical defect data and build more precise and effective classifiers has attracted considerable researchers' interest from both academia and industry. Multiple kernel learning and ensemble learning are effective techniques in the field of machine learning. Multiple kernel learning can map the historical defect data to a higher-dimensional feature space and make them express better, and ensemble learning can use a series of weak classifiers to reduce the bias generated by the majority class and obtain better predictive performance. In this paper, we propose to use the multiple kernel learning to predict software defect. By using the characteristics of the metrics mined from the open source software, we get a multiple kernel classifier through ensemble learning method, which has the advantages of both multiple kernel learning and ensemble learning. We thus propose a multiple kernel ensemble learning (MKEL) approach for software defect classification and prediction. Considering the cost of risk in software defect prediction, we design a new sample weight vector updating strategy to reduce the cost of risk caused by misclassifying defective modules as non-defective ones. We employ the widely used NASA MDP datasets as test data to evaluate the performance of all compared methods; experimental results show that MKEL outperforms several representative state-of-the-art defect prediction methods.},
journal = {Automated Software Engg.},
month = dec,
pages = {569–590},
numpages = {22},
keywords = {Ensemble learning, Multiple kernel ensemble learning (MKEL), Multiple kernel learning, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-89370-5_8,
author = {Cao, Huibin and Lai, Yongxuan and Chen, Quan and Yang, Fan},
title = {A Semi-supervised Defect Detection Method Based on Image Inpainting},
year = {2021},
isbn = {978-3-030-89369-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89370-5_8},
doi = {10.1007/978-3-030-89370-5_8},
abstract = {Defect detection plays an important role in the industrial field. Because the defective images are often insufficient and defects can be various, defective image synthesis is commonly used and models always tend to learn the distribution of defects. However, the complexity of defective image synthesis and difficulty of detecting unseen defects are still the main challenges. To solve these problems, this paper proposes a semi-supervised defect detection method based on image inpainting, denoted as SDDII, which combines the training strategies of CycleGAN and Pix2Pix. First, we train a defect generator unsupervisedly to generate defective images. Second, we train the defect inpaintor supervisedly using the generated images. Finally, the defect inpaintor is used to inpainting the defects, and the defective areas can be segmented by comparing images before and after inpainting. Without ground truth for training, SDDII achieves better results than the naive CycleGAN, and comparable results with UNET which is supervised learning. In addition, SDDII learns the distribution of contents in defect-free images so it has good adaptability for defects unseen before.},
booktitle = {PRICAI 2021: Trends in Artificial Intelligence: 18th Pacific Rim International Conference on Artificial Intelligence, PRICAI 2021, Hanoi, Vietnam, November 8–12, 2021, Proceedings, Part III},
pages = {97–108},
numpages = {12},
keywords = {Defect detection, Automated optical inspection, Generative adversarial networks},
location = {Hanoi, Vietnam}
}

@article{10.1016/j.asoc.2016.06.023,
author = {Mesquita, Diego P.P. and Rocha, Lincoln S. and Gomes, Joo Paulo P. and Rocha Neto, Ajalmar R.},
title = {Classification with reject option for software defect prediction},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.06.023},
doi = {10.1016/j.asoc.2016.06.023},
abstract = {Graphical abstractDisplay Omitted HighlightsWe propose the use of classification with reject option for software defect prediction (SDP) as a way to incorporate additional knowledge in the SDP process.We propose two variants of the extreme learning machine with reject option.It is proposed an ELM with reject option for imbalanced datasets.The proposed method is tested on five real world software datasets.An example is shown to illustrate how the rejected software modules can be further analyzed to improve the final SDP accuracy. ContextSoftware defect prediction (SDP) is an important task in software engineering. Along with estimating the number of defects remaining in software systems and discovering defect associations, classifying the defect-proneness of software modules plays an important role in software defect prediction. Several machine-learning methods have been applied to handle the defect-proneness of software modules as a classification problem. This type of yes or no decision is an important drawback in the decision-making process and if not precise may lead to misclassifications. To the best of our knowledge, existing approaches rely on fully automated module classification and do not provide a way to incorporate extra knowledge during the classification process. This knowledge can be helpful in avoiding misclassifications in cases where system modules cannot be classified in a reliable way. ObjectiveWe seek to develop a SDP method that (i) incorporates a reject option in the classifier to improve the reliability in the decision-making process; and (ii) makes it possible postpone the final decision related to rejected modules for an expert analysis or even for another classifier using extra domain knowledge. MethodWe develop a SDP method called rejoELM and its variant, IrejoELM. Both methods were built upon the weighted extreme learning machine (ELM) with reject option that makes it possible postpone the final decision of non-classified modules, the rejected ones, to another moment. While rejoELM aims to maximize the accuracy for a rejection rate, IrejoELM maximizes the F-measure. Hence, IrejoELM becomes an alternative for classification with reject option for imbalanced datasets. ResultsrejoEM and IrejoELM are tested on five datasets of source code metrics extracted from real world open-source software projects. Results indicate that rejoELM has an accuracy for several rejection rates that is comparable to some state-of-the-art classifiers with reject option. Although IrejoELM shows lower accuracies for several rejection rates, it clearly outperforms all other methods when the F-measure is used as a performance metric. ConclusionIt is concluded that rejoELM is a valid alternative for classification with reject option problems when classes are nearly equally represented. On the other hand, IrejoELM is shown to be the best alternative for classification with reject option on imbalanced datasets. Since SDP problems are usually characterized as imbalanced learning problems, the use of IrejoELM is recommended.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1085–1093},
numpages = {9},
keywords = {Classification with reject option, Extreme learning machines, Software defect prediction}
}

@article{10.1016/j.neucom.2019.03.076,
author = {Zhao, Linchang and Shang, Zhaowei and Zhao, Ling and Zhang, Taiping and Tang, Yuan Yan},
title = {Software defect prediction via cost-sensitive Siamese parallel fully-connected neural networks},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {352},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.03.076},
doi = {10.1016/j.neucom.2019.03.076},
journal = {Neurocomput.},
month = aug,
pages = {64–74},
numpages = {11},
keywords = {Siamese parallel fully-connected networks, Cost-sensitive learning, Deep learning, Few-shot learning, Software defect prediction}
}

@inproceedings{10.1145/3404709.3404765,
author = {Shen, Jau-Ji and Lee, Chin-Feng and Chen, Yu-Chuan and Agrawal, Somya},
title = {Unsupervised Defect Detection based on Boundary Equilibrium Generative Adversarial Network},
year = {2020},
isbn = {9781450375337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404709.3404765},
doi = {10.1145/3404709.3404765},
abstract = {In addition to the brand and sales channels that can be found everywhere in the shoe industry, the foundry manufacturing industry is also an important part of the industrial chain. The traditional shoe industry has high manpower requirements but a low ratio of information personnel and high-tech equipment. Many testing procedures can only be performed manually.The complexity of footwear products is high, and the entire inspection process depends on a large amount of manpower. Therefore, problems such as consuming too much manpower, lack of efficiency, difficulty in precise inspection, quality requirements that vary from person to person, and incomplete quality management are extended. Through traditional machine learning methods, most of them are supervised learning methods. Under this method, a large number of negative samples should be always collected. It is very difficult to collect these negative samples in actual industrial production.Therefore, this article proposes a defect detection model based on unsupervised learning. As long as there are enough positive samples to be trained, we use the BEGAN model to modify it and combine another Autoencoder. This model is much easier and faster to be trained than the traditional GAN model, better responding to the footwear industry with more product types.},
booktitle = {Proceedings of the 6th International Conference on Frontiers of Educational Technologies},
pages = {178–182},
numpages = {5},
keywords = {autoencoder, defect detection, generative adversarial networks, image recognition, unsupervised learning},
location = {Tokyo, Japan},
series = {ICFET '20}
}

@phdthesis{10.5555/AAI28973000,
author = {Chakraborty, Samit},
advisor = {Marguerite, Moore, and Lisa, Parrillo-Chapman, and Maureen, Grasso, and Dan, Harris,},
title = {Automatic Printed Fabric Defect Detection Using a Convolutional Neural Network},
year = {2021},
isbn = {9798780649717},
publisher = {North Carolina State University},
abstract = {Defect detection is a crucial step in textile quality control. An efficient defect detection system can ensure the overall quality of the processes and products that are acceptable to consumers. Research into automatic defect detection systems using image processing and machine learning techniques emerged in recent years along with advances in technological capability. Researchers have established various prototypes for real-time defect detection during weaving and knitting (Hanbay et al., 2019; Kopaczka et al., 2018; Weinmann et al., 2013). There are a number of techniques for real-time defect detection and they tend to vary according to each unique manufacturing process, focal defects, and different computational algorithms. Although the need is high, applications or research related to automatic, real-time defect detection processes for printed fabrics are not prevalent in academic literatures There are a number of academic studies that focus on fabric printing defect detection after the fabric is produced, rather than through a real-time perspective (Alam et al., 2020; Junfeng Jing &amp; Ren, 2020; Kang et al., 2015; Kuo et al., 2012; M. Li et al., 2015; Pan et al., 2010). Also, this stream of research does not include work that employs a convolutional neural network (CNN), which is considered to be particularly efficient for image classification compared to rival algorithmic models (Eldessouki, 2018; Ferguson et al., 2018; Hanbay et al., 2019; Indolia et al., 2018; A. Kumar, 2008; Ngan et al., 2011; Wang et al., 2018).The purpose of this research is to develop an automatic defect detection model employing a CNN to facilitate real-time deployment in the textile printing process. Two general objectives are stated to address this purpose including establishing an empirical dataset (RO1) and developing, training and testing the model using a CNN algorithmic approach. This approach potentially provides a number of potential advantages over current defect detection processes in printing by identifying problems more effectively and efficiently in real-time. This research extends current state of the art machine learning techniques into the print production context and provides potential directions for ADD in textile quality control. This research proposes a novel methodology that demonstrates the application of convolutional neural network (CNN) to classify printing defects based on the fabric images collected from industries. The research also integrated cross validation and k-Nearest Neighbor (KNN) algorithm based classification methods to compare model performance. The results show that the CNN model performs better compared to cross validation and k-Nearest Neighbor (KNN) algorithm based classification methods. Then the research included visual geometric group (VGG), DenseNet-121 (DNS12), InceptionV3 and Xception deep learning networks to compare model performance with proposed CNN model. The results exhibit that the VGG-based models perform better compared to a simple CNN model. However the custom CNN model showed higher accuracy compared to DNS12, InceptionV3 and Xception networks.},
note = {AAI28973000}
}

@inproceedings{10.1145/3377811.3380389,
author = {Chen, Jinyin and Hu, Keke and Yu, Yue and Chen, Zhuangzhi and Xuan, Qi and Liu, Yi and Filkov, Vladimir},
title = {Software visualization and deep transfer learning for effective software defect prediction},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380389},
doi = {10.1145/3377811.3380389},
abstract = {Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort. Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules. Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models.To bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools. To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction. Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction. Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {578–589},
numpages = {12},
keywords = {cross-project defect prediction, deep transfer learning, self-attention, software visualization, within-project defect prediction},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1504/ijcse.2020.106871,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {A benchmarking framework using nonlinear manifold detection techniques for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {21},
number = {4},
issn = {1742-7185},
url = {https://doi.org/10.1504/ijcse.2020.106871},
doi = {10.1504/ijcse.2020.106871},
abstract = {Prediction of software defects in time improves quality and helps in locating the defect-prone areas accurately. Although earlier considerable methods were applied, actually none of those measures was found to be fool-proof and accurate. Hence, a newer framework includes nonlinear manifold detection model, and its algorithm originated for defect prediction using different techniques of nonlinear manifold detection (nonlinear MDs) along with 14 different machine learning techniques (MLTs) on eight defective software datasets. A critical analysis cum exhaustive comparative estimation revealed that nonlinear manifold detection model has a more accurate and effective impact on defect prediction as compared to feature selection techniques. The outcome of the experiment was statistically tested by Friedman and post hoc analysis using Nemenyi test, which validates that hidden Markov model (HMM) along with nonlinear manifold detection model outperforms and is significantly different from MLTs.},
journal = {Int. J. Comput. Sci. Eng.},
month = jan,
pages = {593–614},
numpages = {21},
keywords = {dimensionality reduction, feature selection, Friedman test, machine learning, Nemenyi test, nonlinear manifold detection, software defect prediction, post hoc analysis}
}

@inproceedings{10.1007/978-3-030-34885-4_27,
author = {Ali, Aftab and Abu-Tair, Mamun and Noppen, Joost and McClean, Sally and Lin, Zhiwei and McChesney, Ian},
title = {Contributing Features-Based Schemes for Software Defect Prediction},
year = {2019},
isbn = {978-3-030-34884-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-34885-4_27},
doi = {10.1007/978-3-030-34885-4_27},
abstract = {Automated defect prediction of large and complex software systems is a challenging task. However, by utilising correlated quality metrics, a defect prediction model can be devised to automatically predict the defects in a software system. The robustness and accuracy of a prediction model is highly dependent on the selection of contributing and non-contributing features. Hence, in this regard, the contribution of this paper is twofold, first it separates those features which are contributing towards the development of a defect in a software component from those which are non-contributing features. Secondly, a logistic regression and Ensemble Bagged Trees-based prediction model are applied on the contributing features for accurately predicting a defect in a software component. The proposed models are compared with the most recent scheme in the literature in terms of accuracy and area under the curve (AUC). It is evident from the results and analysis that the performance of the proposed prediction models outperforms the schemes in the literature.},
booktitle = {Artificial Intelligence XXXVI: 39th SGAI International Conference on Artificial Intelligence, AI 2019, Cambridge, UK, December 17–19, 2019, Proceedings},
pages = {350–361},
numpages = {12},
keywords = {Machine learning, Intelligent information retrieval, Prediction models},
location = {Cambridge, United Kingdom}
}

@article{10.1016/j.neucom.2021.04.094,
author = {Fuchs, Patrick and Kr\"{o}ger, Thorben and Garbe, Christoph S.},
title = {Defect detection in CT scans of cast aluminum parts: A machine vision perspective},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {453},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.04.094},
doi = {10.1016/j.neucom.2021.04.094},
journal = {Neurocomput.},
month = sep,
pages = {85–96},
numpages = {12},
keywords = {Semantic segmentation, Computed tomography, Deep learning, Defect detection, Self-supervision, Simulated training data}
}

@inproceedings{10.1145/3342999.3343010,
author = {Cui, Mengtian and Sun, Yue and Lu, Yang and Jiang, Yue},
title = {Study on the Influence of the Number of Features on the Performance of Software Defect Prediction Model},
year = {2019},
isbn = {9781450371605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342999.3343010},
doi = {10.1145/3342999.3343010},
abstract = {The software defect prediction model based on machine learning technology is the key to improve the reliability of software. The influence of the number of features on the performance of different software defect prediction models was proposed in this paper. First, a new data sets was built, which is increasing by the number of features based on the NASA public data sets. Then, the eight predictive models are experimented based on these data sets. Next, the influence of the number of features on the performance of different prediction models was analyzed based on the experimental results. Next, the AUC values obtained from the experiment were used to evaluate the performance of different prediction models, and the coefficient of variation C·V values was used to evaluate the performance stability of different prediction models while the number of features changed. In the end, the experiments show that the performance of the predictive model C4.5 is highly susceptible to changes in the number of features, while the performance of the predictive model SMO is relatively stable.},
booktitle = {Proceedings of the 2019 3rd International Conference on Deep Learning Technologies},
pages = {32–37},
numpages = {6},
keywords = {feature selection, machine learning, number of features, software defect prediction},
location = {Xiamen, China},
series = {ICDLT '19}
}

@inproceedings{10.1145/3461001.3475157,
author = {Assun\c{c}\~{a}o, Wesley K. G. and Ayala, Inmaculada and Kr\"{u}ger, Jacob and Mosser, S\'{e}bastien},
title = {International Workshop on Variability Management for Modern Technologies (VM4ModernTech 2021)},
year = {2021},
isbn = {9781450384698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461001.3475157},
doi = {10.1145/3461001.3475157},
abstract = {Variability is an inherent property of software systems that allows developers to deal with the needs of different customers and environments, creating a family of related systems. Variability can be managed in an opportunistic fashion, for example, using clone-and-own, or by employing a systematic approach, for instance, using a software product line (SPL). In the SPL community, variability management has been discussed for systems in various domains, such as defense, avionics, or finance, and for different platforms, such as desktops, web applications, or embedded systems. Unfortunately, other research communities---particularly those working on modern technologies, such as microservice architectures, cyber-physical systems, robotics, cloud computing, autonomous driving, or ML/AI-based systems---are less aware of the state-of-the-art in variability management, which is why they face similar problems and start to redeveloped the same solutions as the SPL community already did. With the International Workshop on Variability Management for Modern Technologies, we aim to foster and strengthen synergies between the communities researching variability management and modern technologies. More precisely, we aim to attract researchers and practitioners to contribute processes, techniques, tools, empirical studies, and problem descriptions or solutions that are related to reuse and variability management for modern technologies. By inviting different communities and establishing collaborations between them, we hope that the workshop can raise the interest of researchers outside the SPL community for variability management, and thus reduce the extent of costly redevelopments in research.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A},
pages = {202},
numpages = {1},
keywords = {software architecture, variability management},
location = {Leicester, United Kingdom},
series = {SPLC '21}
}

@article{10.1155/2019/6230953,
author = {Fan, Guisheng and Diao, Xuyang and Yu, Huiqun and Yang, Kang and Chen, Liqiong and Vitiello, Autilia},
title = {Software Defect Prediction via Attention-Based Recurrent Neural Network},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1058-9244},
url = {https://doi.org/10.1155/2019/6230953},
doi = {10.1155/2019/6230953},
abstract = {In order to improve software reliability, software defect prediction is applied to the process of software maintenance to identify potential bugs. Traditional methods of software defect prediction mainly focus on designing static code metrics, which are input into machine learning classifiers to predict defect probabilities of the code. However, the characteristics of these artificial metrics do not contain the syntactic structures and semantic information of programs. Such information is more significant than manual metrics and can provide a more accurate predictive model. In this paper, we propose a framework called defect prediction via attention-based recurrent neural network (DP-ARNN). More specifically, DP-ARNN first parses abstract syntax trees (ASTs) of programs and extracts them as vectors. Then it encodes vectors which are used as inputs of DP-ARNN by dictionary mapping and word embedding. After that, it can automatically learn syntactic and semantic features. Furthermore, it employs the attention mechanism to further generate significant features for accurate defect prediction. To validate our method, we choose seven open-source Java projects in Apache, using F1-measure and area under the curve (AUC) as evaluation criteria. The experimental results show that, in average, DP-ARNN improves the F1-measure by 14% and AUC by 7% compared with the state-of-the-art methods, respectively.},
journal = {Sci. Program.},
month = jan,
numpages = {14}
}

@article{10.1016/j.patcog.2020.107571,
author = {Zhang, Jiabin and Su, Hu and Zou, Wei and Gong, Xinyi and Zhang, Zhengtao and Shen, Fei},
title = {CADN: A weakly supervised learning-based category-aware object detection network for surface defect detection},
year = {2021},
issue_date = {Jan 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {109},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2020.107571},
doi = {10.1016/j.patcog.2020.107571},
journal = {Pattern Recogn.},
month = jan,
numpages = {10},
keywords = {Weakly supervised learning, Automated surface inspection, Defect detection, Knowledge distillation}
}

@inproceedings{10.1145/2351676.2351734,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {Software defect prediction using semi-supervised learning with dimension reduction},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351734},
doi = {10.1145/2351676.2351734},
abstract = {Accurate detection of fault prone modules offers the path to high quality software products while minimizing non essential assurance expenditures. This type of quality modeling requires the availability of software modules with known fault content developed in similar environment. Establishing whether a module contains a fault or not can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics. Our results show that the semi-supervised learning algorithm with dimension-reduction preforms significantly better than one of the best performing supervised learning algorithms, random forest, in situations when few modules with known fault content are available for training.},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {314–317},
numpages = {4},
keywords = {Software fault prediction, dimension reduction, semi-supervised learning, software metrics},
location = {Essen, Germany},
series = {ASE '12}
}

@inproceedings{10.1007/978-3-030-64243-3_30,
author = {Sun, Yi and Cai, Yuexiao and Li, Yang and Zhao, Yunlong},
title = {Defect Detection of Production Surface Based on CNN},
year = {2020},
isbn = {978-3-030-64242-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64243-3_30},
doi = {10.1007/978-3-030-64243-3_30},
abstract = {With the continuous development of artificial intelligence, great progress has been made in the field of object detection. Defect detection is a branch of the field of object detection, as long as the purpose is to locate and classify defects on the surface of objects to help people further analyze product quality. In large-scale manufacturing, the demand for product surface defect detection has always been strong, and companies hope to reduce costs, while improving detection accuracy. This paper mainly proposes a method that is biased towards the detection of surface defects on smooth products, solving the problems including difficulty on detecting small scratches and imbalance between positive and negative samples. Finally, we achieve good results through the detector.},
booktitle = {Green, Pervasive, and Cloud Computing: 15th International Conference, GPC 2020, Xi'an, China, November 13–15, 2020, Proceedings},
pages = {405–412},
numpages = {8},
keywords = {Object detection, Defect detection, Deep learning},
location = {Xi'an, China}
}

@article{10.4018/IJOSSP.2017100102,
author = {Akour, Mohammed and Melhem, Wasen Yahya},
title = {Software Defect Prediction Using Genetic Programming and Neural Networks},
year = {2017},
issue_date = {October 2017},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {4},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2017100102},
doi = {10.4018/IJOSSP.2017100102},
abstract = {This article describes how classification methods on software defect prediction is widely researched due to the need to increase the software quality and decrease testing efforts. However, findings of past researches done on this issue has not shown any classifier which proves to be superior to the other. Additionally, there is a lack of research that studies the effects and accuracy of genetic programming on software defect prediction. To find solutions for this problem, a comparative software defect prediction experiment between genetic programming and neural networks are performed on four datasets from the NASA Metrics Data repository. Generally, an interesting degree of accuracy is detected, which shows how the metric-based classification is useful. Nevertheless, this article specifies that the application and usage of genetic programming is highly recommended due to the detailed analysis it provides, as well as an important feature in this classification method which allows the viewing of each attributes impact in the dataset.},
journal = {Int. J. Open Source Softw. Process.},
month = oct,
pages = {32–51},
numpages = {20},
keywords = {Classification, Genetic Algorithm, Genetic Programming, Machine learning, Nasa Metrics, Neural Networks, Software Defect Prediction, Testing}
}

@article{10.1016/j.asoc.2021.107913,
author = {Koulali, Imane and Eskil, M. Taner},
title = {Unsupervised textile defect detection using convolutional neural networks},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {113},
number = {PA},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107913},
doi = {10.1016/j.asoc.2021.107913},
journal = {Appl. Soft Comput.},
month = dec,
numpages = {17},
keywords = {Fabric defect, Textile defect, Anomaly detection, Neural network, Cross-patch similarity, Manhattan distance}
}

@inproceedings{10.1145/3239576.3239622,
author = {Yang, Zhao and Qian, Hongbing},
title = {Automated Parameter Tuning of Artificial Neural Networks for Software Defect Prediction},
year = {2018},
isbn = {9781450364607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239576.3239622},
doi = {10.1145/3239576.3239622},
abstract = {Defect prediction can help predict defect-prone software modules and improve the efficiency and accuracy of defect location and repair, which plays an extremely important role in software quality assurance. Artificial Neural Networks (ANNs), a family of powerful machine learning regression or classification models, have been widely applied for defect prediction. However, the performance of these models will be degraded if they use suboptimal default parameter settings (e.g., the number of units in the hidden layer). This paper utilizes an automated parameter tuning technique-Caret to optimize parameter settings. In our study, 30 datasets are downloaded from the Tera-PROMISE Repository. According to the characteristics of the datasets, we select key features (metrics) as predictors to train defect prediction models. The experiment applies feed-forward, single hidden layer artificial neural network as classifier to build different defect prediction models respectively with optimized parameter settings and with default parameter settings. Confusion matrix and ROC curve are used for evaluating the quality of the models above. The results show that the models trained with optimized parameter settings outperform the models trained with default parameter settings. Hence, we suggest that researchers should pay attention to tuning parameter settings by Caret for ANNs instead of using suboptimal default settings if they select ANNs for training models in the future defect prediction studies.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
pages = {203–209},
numpages = {7},
keywords = {Artificial Neural Networks, Automated Parameter Tuning, Metrics, Software defect prediction},
location = {Chengdu, China},
series = {ICAIP '18}
}

@inproceedings{10.1145/3377811.3380403,
author = {Tabassum, Sadia and Minku, Leandro L. and Feng, Danyi and Cabral, George G. and Song, Liyan},
title = {An investigation of cross-project learning in online just-in-time software defect prediction},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380403},
doi = {10.1145/3377811.3380403},
abstract = {Just-In-Time Software Defect Prediction (JIT-SDP) is concerned with predicting whether software changes are defect-inducing or clean based on machine learning classifiers. Building such classifiers requires a sufficient amount of training data that is not available at the beginning of a software project. Cross-Project (CP) JIT-SDP can overcome this issue by using data from other projects to build the classifier, achieving similar (not better) predictive performance to classifiers trained on Within-Project (WP) data. However, such approaches have never been investigated in realistic online learning scenarios, where WP software changes arrive continuously over time and can be used to update the classifiers. It is unknown to what extent CP data can be helpful in such situation. In particular, it is unknown whether CP data are only useful during the very initial phase of the project when there is little WP data, or whether they could be helpful for extended periods of time. This work thus provides the first investigation of when and to what extent CP data are useful for JIT-SDP in a realistic online learning scenario. For that, we develop three different CP JIT-SDP approaches that can operate in online mode and be updated with both incoming CP and WP training examples over time. We also collect 2048 commits from three software repositories being developed by a software company over the course of 9 to 10 months, and use 19,8468 commits from 10 active open source GitHub projects being developed over the course of 6 to 14 years. The study shows that training classifiers with incoming CP+WP data can lead to improvements in G-mean of up to 53.90% compared to classifiers using only WP data at the initial stage of the projects. For the open source projects, which have been running for longer periods of time, using CP data to supplement WP data also helped the classifiers to reduce or prevent large drops in predictive performance that may occur over time, leading to up to around 40% better G-Mean during such periods. Such use of CP data was shown to be beneficial even after a large number of WP data were received, leading to overall G-means up to 18.5% better than those of WP classifiers.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {554–565},
numpages = {12},
keywords = {class imbalance, concept drift, cross-project learning, online learning, software defect prediction, transfer learning, verification latency},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1007/s11219-018-9436-4,
author = {Ji, Haijin and Huang, Song and Wu, Yaning and Hui, Zhanwei and Zheng, Changyou},
title = {A new weighted naive Bayes method based on information diffusion for software defect prediction},
year = {2019},
issue_date = {Sep 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9436-4},
doi = {10.1007/s11219-018-9436-4},
abstract = {Software defect prediction (SDP) plays a significant part in identifying the most defect-prone modules before software testing and allocating limited testing resources. One of the most commonly used classifiers in SDP is naive Bayes (NB). Despite the simplicity of the NB classifier, it can often perform better than more complicated classification models. In NB, the features are assumed to be equally important, and the numeric features are assumed to have a normal distribution. However, the features often do not contribute equivalently to the classification, and they usually do not have a normal distribution after performing a Kolmogorov-Smirnov test; this may harm the performance of the NB classifier. Therefore, this paper proposes a new weighted naive Bayes method based on information diffusion (WNB-ID) for SDP. More specifically, for the equal importance assumption, we investigate six weight assignment methods for setting the feature weights and then choose the most suitable one based on the F-measure. For the normal distribution assumption, we apply the information diffusion model (IDM) to compute the probability density of each feature instead of the acquiescent probability density function of the normal distribution. We carry out experiments on 10 software defect data sets of three types of projects in three different programming languages provided by the PROMISE repository. Several well-known classifiers and ensemble methods are included for comparison. The final experimental results demonstrate the effectiveness and practicability of the proposed method.},
journal = {Software Quality Journal},
month = sep,
pages = {923–968},
numpages = {46},
keywords = {Software defect prediction, Naive Bayes, Feature weighting, Information diffusion}
}

@article{10.1016/j.asoc.2015.04.045,
author = {Arar, \"{O}mer Faruk and Ayan, K\"{u}r\c{s}at},
title = {Software defect prediction using cost-sensitive neural network},
year = {2015},
issue_date = {August 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {33},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.04.045},
doi = {10.1016/j.asoc.2015.04.045},
abstract = {Software defect prediction model was built by Artificial Neural Network (ANN).ANN connection weights were optimized by Artificial Bee Colony (ABC).Parametric cost-sensitivity feature was added to ANN by using a new error function.Model was applied to five publicly available datasets from the NASA repository.Results were compared with other cost-sensitive and non-cost-sensitive studies. The software development life cycle generally includes analysis, design, implementation, test and release phases. The testing phase should be operated effectively in order to release bug-free software to end users. In the last two decades, academicians have taken an increasing interest in the software defect prediction problem, several machine learning techniques have been applied for more robust prediction. A different classification approach for this problem is proposed in this paper. A combination of traditional Artificial Neural Network (ANN) and the novel Artificial Bee Colony (ABC) algorithm are used in this study. Training the neural network is performed by ABC algorithm in order to find optimal weights. The False Positive Rate (FPR) and False Negative Rate (FNR) multiplied by parametric cost coefficients are the optimization task of the ABC algorithm. Software defect data in nature have a class imbalance because of the skewed distribution of defective and non-defective modules, so that conventional error functions of the neural network produce unbalanced FPR and FNR results. The proposed approach was applied to five publicly available datasets from the NASA Metrics Data Program repository. Accuracy, probability of detection, probability of false alarm, balance, Area Under Curve (AUC), and Normalized Expected Cost of Misclassification (NECM) are the main performance indicators of our classification approach. In order to prevent random results, the dataset was shuffled and the algorithm was executed 10 times with the use of n-fold cross-validation in each iteration. Our experimental results showed that a cost-sensitive neural network can be created successfully by using the ABC optimization algorithm for the purpose of software defect prediction.},
journal = {Appl. Soft Comput.},
month = aug,
pages = {263–277},
numpages = {15},
keywords = {Artificial Bee Colony, Artificial Neural Network, Cost-sensitive classification, Machine learning, Software defect prediction, Software quality}
}

@inproceedings{10.1007/978-3-030-88013-2_20,
author = {Liu, Zhoufeng and Huang, Ning and Li, Chunlei and Guo, Zijing and Gao, Chengli},
title = {Fabric Defect Detection via Multi-scale Feature Fusion-Based Saliency},
year = {2021},
isbn = {978-3-030-88012-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-88013-2_20},
doi = {10.1007/978-3-030-88013-2_20},
abstract = {Automatic fabric defect detection plays a key role in controlling product quality. Salient object detection (SOD) based on convolutional neural network has been proven applicable in fabric defect detection, but how to learn powerful features and feature fusion for saliency are still challenging tasks due to the complex texture of fabric image. In this paper, a novel visual saliency based on multi-scale feature fusion is proposed for fabric defect detection. First, a Multi-scale Feature Learning Module (MFLM) by simulating the parallel processing mechanism of multi-receptive is proposed to efficiently characterize the complex fabric texture. In addition, Feedback Attention Refinement Fusion Module (FARFM) is designed to selectively aggregate multi-level features for enhancing the feature fusion. In the end, fabric defect detection is localized by segmenting the generated saliency map. Experimental results demonstrate that the proposed method can localize the defect region with high accuracy, and outperform the 5 state-of-the-art methods.},
booktitle = {Pattern Recognition and Computer Vision: 4th Chinese Conference, PRCV 2021, Beijing, China, October 29 – November 1, 2021, Proceedings, Part IV},
pages = {240–251},
numpages = {12},
keywords = {Fabric defect detection, Salient object detection, Multi-scale feature learning, Feedback attention refinement fusion},
location = {Beijing, China}
}

@article{10.1007/s10845-021-01864-2,
author = {Huang, Feng and Wang, Ben-wu and Li, Qi-peng and Zou, Jun},
title = {Texture surface defect detection of plastic relays with an enhanced feature pyramid network},
year = {2021},
issue_date = {Mar 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01864-2},
doi = {10.1007/s10845-021-01864-2},
abstract = {Deep learning has seen its promising applications in manufacturing processes. In this study, a deep network named Cascade Tri-DFPN based on the two-stage target detection algorithm is proposed for detecting the defects on the texture surface of plastic relays. The network adopts a derivative Resnet-101d as the backbone to obtain a loss-reduced feature extraction. Meanwhile, an enhanced feature pyramid module is put forward to enhance the feature representation of the network by adding a dense connection of feature layers through the self-attentive block. Moreover, the defect region proposals are optimized by introducing a cascade module to obtain high-quality defective proposal boxes. Experimental results on the augmented data set of relays’ surface defect reveal an average accuracy of 88.57% and an average recall rate of 94.58%, much higher than those of traditional RCNN or FPN detectors, demonstrating the remarkable improvement of the proposed network. Robustness of the method is also verified by performing tests with deteriorative image processing, which indicates an eligible defect detection under relatively&nbsp;complex scenarios such as image blurring. The proposed deep network could be used in surface defect detection of plastic relays and other potentially related industrial defect detection fields.},
journal = {J. Intell. Manuf.},
month = nov,
pages = {1409–1425},
numpages = {17},
keywords = {Defect detection, Deep learning, Enhanced FPN, Self-attention, Manufacturing application}
}

@article{10.1049/iet-sen.2017.0198,
author = {Zhang, Zhi-Wu and Jing, Xiao-Yuan and Wu, Fei},
title = {Low‐rank representation for semi‐supervised software defect prediction},
year = {2018},
issue_date = {December 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {6},
url = {https://doi.org/10.1049/iet-sen.2017.0198},
doi = {10.1049/iet-sen.2017.0198},
abstract = {Software defect prediction based on machine learning is an active research topic in the field of software engineering. The historical defect data in software repositories may contain noises because automatic defect collection is based on modified logs and defect reports. When the previous defect labels of modules are limited, predicting the defect‐prone modules becomes a challenging problem. In this study, the authors propose a graph‐based semi‐supervised defect prediction approach to solve the problems of insufficient labelled data and noisy data. Graph‐based semi‐supervised learning methods used the labelled and unlabelled data simultaneously and consider them as the nodes of the graph at the training phase. Therefore, they solve the problem of insufficient labelled samples. To improve the stability of noisy defect data, a powerful clustering method, low‐rank representation (LRR), and neighbourhood distance are used to construct the relationship graph of samples. Therefore, they propose a new semi‐supervised defect prediction approach, named low‐rank representation‐based semi‐supervised software defect prediction (LRRSSDP). The widely used datasets from NASA projects and noisy datasets are employed as test data to evaluate the performance. Experimental results show that (i) LRRSSDP outperforms several representative state‐of‐the‐art semi‐supervised defect prediction methods; and (ii) LRRSSDP can maintain robustness in noisy environments.},
journal = {IET Software},
month = dec,
pages = {527–535},
numpages = {9},
keywords = {software engineering, learning (artificial intelligence), pattern clustering, graph theory, program diagnostics, semisupervised software defect prediction, software engineering, historical defect data, software repositories, automatic defect collection, defect reports, defect-prone modules, semisupervised defect prediction approach, insufficient labelled data, noisy data, unlabelled data, insufficient labelled samples, noisy defect data, low-rank representation, LRRSSDP}
}

@article{10.1504/ijista.2019.102667,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {Statistical assessment of nonlinear manifold detection-based software defect prediction techniques},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {6},
issn = {1740-8865},
url = {https://doi.org/10.1504/ijista.2019.102667},
doi = {10.1504/ijista.2019.102667},
abstract = {Prediction of software defects has immense importance for obtaining desired outcome at minimised cost and so attracted researchers working on this topic applying various techniques, which were not found fully effective. Software datasets comprise of redundant features that hinder effective application of techniques resulting inappropriate defect prediction. Hence, it requires newer application of nonlinear manifold detection techniques (nonlinear MDTs) that has been examined for accurate prediction of defects at lesser time and cost using different classification techniques. In this work, we analysed and tested the effect of nonlinear MDTs to find out accurate and best classification technique for all datasets. Comparison has been made between the results of without or with nonlinear MDTs and paired two-tailed T-test has been performed for statistical testing and verifying the performance of classifiers using nonlinear MDTs on all datasets. Outcome revealed that among all nonlinear MDTs, FastMVU makes most accurate prediction of software defects.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {579–605},
numpages = {26},
keywords = {dimensionality reduction, fast maximum variance unfolding, FastMVU, machine learning, manifold detection, nonlinear, promise repository, software defect prediction}
}

@inproceedings{10.1007/978-3-030-87355-4_39,
author = {Xie, Huosheng and Lin, ShuFeng},
title = {A Weakly Supervised Defect Detection Based on Dual Path Networks and GMA-CAM},
year = {2021},
isbn = {978-3-030-87354-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87355-4_39},
doi = {10.1007/978-3-030-87355-4_39},
abstract = {In recent research, the defect detection algorithm based on the fully-supervised object detection model has become one of the research hotspots and has achieved good results. However, fully-supervised object detection models require image-level and localization-level labels. Obtaining these labels requires a great deal of manpower. Therefore, this paper proposes a dual path defect detection network (DPNET) based on weakly supervised object detection model, which aims to identify the classification label and carry on localization for defects merely by using image-level labels. Firstly, the paper employs the deep convolutional residual network ResNet-50 as a feature classification network for defect classification. Secondly, we designed a localization network based on the global average-max pooling class activation map (GAM-CAM) and the Full Convolutional Channel Attention (FCCA) for defect localization, which can improve the defect localization accuracy. Experimental results on the DAGM dataset confirm that the proposed detection model is able to efficiently detect defects.},
booktitle = {Image and Graphics: 11th International Conference, ICIG 2021, Haikou, China, August 6–8, 2021, Proceedings, Part I},
pages = {467–478},
numpages = {12},
keywords = {Defect detection, Weakly supervised object detection, Dual Path Network, Global average-max pooling class activation map, Full Convolutional Channel Attention},
location = {Haikou, China}
}

@article{10.1002/stvr.1610,
author = {Wang, Tiejian and Zhang, Zhiwu and Jing, Xiaoyuan and Liu, Yanli},
title = {Non-negative sparse-based SemiBoost for software defect prediction},
year = {2016},
issue_date = {November 2016},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {26},
number = {7},
issn = {0960-0833},
url = {https://doi.org/10.1002/stvr.1610},
doi = {10.1002/stvr.1610},
abstract = {Software defect prediction is an important decision support activity in software quality assurance. The limitation of the labelled modules usually makes the prediction difficult, and the class-imbalance characteristic of software defect data leads to negative influence on decision of classifiers. Semi-supervised learning can build high-performance classifiers by using large amount of unlabelled modules together with the labelled modules. Ensemble learning achieves a better prediction capability for class-imbalance data by using a series of weak classifiers to reduce the bias generated by the majority class. In this paper, we propose a new semi-supervised software defect prediction approach, non-negative sparse-based SemiBoost learning. The approach is capable of exploiting both labelled and unlabelled data and is formulated in a boosting framework. In order to enhance the prediction ability, we design a flexible non-negative sparse similarity matrix, which can fully exploit the similarity of historical data by incorporating the non-negativity constraint into sparse learning for better learning the latent clustering relationship among software modules. The widely used datasets from NASA projects are employed as test data to evaluate the performance of all compared methods. Experimental results show that non-negative sparse-based SemiBoost learning outperforms several representative state-of-the-art semi-supervised software defect prediction methods. Copyright © 2016 John Wiley &amp; Sons, Ltd.},
journal = {Softw. Test. Verif. Reliab.},
month = nov,
pages = {498–515},
numpages = {18},
keywords = {ensemble learning, non-negative sparse based SemiBoost NSSB, semi-supervised learning, software defect prediction}
}

@inproceedings{10.1007/978-3-030-88007-1_29,
author = {Liu, Xuefei and Song, Kaitao and Lu, Jianfeng},
title = {MPN: Multi-scale Progressive Restoration Network for Unsupervised Defect Detection},
year = {2021},
isbn = {978-3-030-88006-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-88007-1_29},
doi = {10.1007/978-3-030-88007-1_29},
abstract = {Defect detection is one of the most challenging tasks in the industry, as defects (e.g., flaw or crack) in objects usually own arbitrary shapes and different sizes. Especially in practical applications, defect detection usually is an unsupervised issue, since it is difficult to collect enough labeled defect samples in the industrial scenario. Although a lot of works have achieved remarkable progress with the help of labeled data, how to effectively detect defects with only positive samples (i.e., clean image without any defects) for training is still a troublesome problem. Therefore, in our paper, we adopt the image restoration strategy to address the unsupervised defect detection task. More specifically, we enable model to restore the original image from the defect samples first and then calculate the differences between the restored image and defect image as the final results. To deal with the unsupervised scenario, we first introduce a self-synthesis component to generate pseudo defects for training by Poisson editing, and the generated pseudo defects will be used for training. Targeting at the unsupervised defect detection, we introduce a novel Multi-scale Progressive restoration Network (MPN), which utilizes multi-scale information to detect defects progressively. More specifically, we choose an invariant scale convolution network as the restoration network for image reconstruction. However, it is difficult to detect defects with once restoration. Thus, we adopt the iterative restorations and our model is conditioned on the previous results for progressive defect detection. Our progressive detection is maintained by using a recurrent neural network to memory previous states. Considering that the defects can be arbitrary size, we incorporate the top-down and bottom-up structure into our model to extract multi-scale semantics better. Experimental results on multiple datasets demonstrate that our model achieves better performance than previous methods.},
booktitle = {Pattern Recognition and Computer Vision: 4th Chinese Conference, PRCV 2021, Beijing, China, October 29 – November 1, 2021, Proceedings, Part II},
pages = {349–359},
numpages = {11},
keywords = {Defect detection, Image restoration, Self-synthetic samples, Multi-scale, Recurrent Neural Network},
location = {Beijing, China}
}

@article{10.1016/j.procs.2018.05.115,
author = {Singh, Ajmer and Bhatia, Rajesh and Singhrova, Anita},
title = {Taxonomy of machine learning algorithms in software fault prediction using object oriented metrics},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.115},
doi = {10.1016/j.procs.2018.05.115},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {993–1001},
numpages = {9},
keywords = {Software fault prediction, Object Oriented Testing, Object Oriented Coupling, software faults prediction, machine learning}
}

@article{10.1007/s42979-020-0119-4,
author = {Khuat, Thanh Tung and Le, My Hanh},
title = {Evaluation of Sampling-Based Ensembles of Classifiers on Imbalanced Data for Software Defect Prediction Problems},
year = {2020},
issue_date = {Mar 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {2},
url = {https://doi.org/10.1007/s42979-020-0119-4},
doi = {10.1007/s42979-020-0119-4},
abstract = {Defect prediction in software projects plays a crucial role to reduce quality-based risk and increase the capability of detecting faulty program modules. Hence, classification approaches to anticipate software defect proneness based on static code characteristics have become a hot topic with a great deal of attention in recent years. While several novel studies show that the use of a single classifier causes the performance bottleneck, ensembles of classifiers might effectively enhance classification performance compared to a single classifier. However, the class imbalance property of software defect data severely hinders the classification efficiency of ensemble learning. To cope with this problem, resampling methods are usually combined into ensemble models.
This paper empirically assesses the importance of sampling with regard to ensembles of various classifiers on imbalanced data in software defect prediction problems. Extensive experiments with the combination of seven different kinds of classification algorithms, three sampling methods, and two balanced data learning schemata were conducted over ten datasets. Empirical results indicated the positive effects of combining sampling techniques and the ensemble learning model on the performance of defect prediction regarding datasets with imbalanced class distributions.},
journal = {SN Comput. Sci.},
month = mar,
numpages = {16},
keywords = {Software defect prediction, Random undersampling, Random oversampling, SMOTE, Data balancing, Ensemble learning, Imbalanced data}
}

@article{10.1016/j.asoc.2020.106686,
author = {Haouari, Ahmed Taha and Souici-Meslati, Labiba and Atil, Fadila and Meslati, Djamel},
title = {Empirical comparison and evaluation of Artificial Immune Systems in inter-release software fault prediction},
year = {2020},
issue_date = {Nov 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {96},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.106686},
doi = {10.1016/j.asoc.2020.106686},
journal = {Appl. Soft Comput.},
month = nov,
numpages = {18},
keywords = {Artificial Immune Systems, Software defect prediction, Inter-projects fault prediction, Artificial Immune Recognition System, Neural Network}
}

@article{10.1016/j.engappai.2021.104504,
author = {Vaish, Rachna and Dwivedi, U.D. and Tewari, Saurabh and Tripathi, S.M.},
title = {Machine learning applications in power system fault diagnosis: Research advancements and perspectives},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {106},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2021.104504},
doi = {10.1016/j.engappai.2021.104504},
journal = {Eng. Appl. Artif. Intell.},
month = nov,
numpages = {33},
keywords = {Machine learning (ML), Reinforcement learning, Supervised learning, Transfer learning, Unsupervised learning}
}

@inproceedings{10.1007/978-3-030-89098-8_54,
author = {Lu, Junxu and Zhang, Xu and Li, Chen},
title = {An Surface Defect Detection Framework for Glass Bottle Body Based on the Stripe Light Source},
year = {2021},
isbn = {978-3-030-89097-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89098-8_54},
doi = {10.1007/978-3-030-89098-8_54},
abstract = {Quality inspection is an essential technology in the glass product industry. Machine vision has shown more significant potential than manual inspection at present. However, the visual inspection of the bottle for defects remains a challenging task in a quality-controlled due to the difficulty in detecting some notable defects. To overcome the problem, we propose a surface defect detection framework based on the stripe light source. First, a novel method, DTST, determines the stripe type in the background with traditional image processing methods. Then, according to the result of DTST, the stripe type is divided into vertical stripes and horizontal stripes. For the former, a defect detection method based on DDVS that uses machine learning technology is proposed to detect cold mold defects precisely. A defect detection method named DDHS that uses deep learning technology is proposed to precisely detect wrinkled skin defects for the latter. The proposed framework is tested for data sets obtained by our designed vision system. The experimental results demonstrate that our framework achieves good performance.},
booktitle = {Intelligent Robotics and Applications: 14th International Conference, ICIRA 2021, Yantai, China, October 22–25, 2021, Proceedings, Part II},
pages = {575–585},
numpages = {11},
keywords = {Defect detection, Stripe light source, Machine learning, Deep learning},
location = {Yantai, China}
}

@article{10.1007/s00521-018-03969-x,
author = {Essa, Ehab and Hossain, M. Shamim and Tolba, A. S. and Raafat, Hazem M. and Elmogy, Samir and Muahmmad, Ghulam},
title = {Toward cognitive support for automated defect detection},
year = {2020},
issue_date = {May 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {9},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-018-03969-x},
doi = {10.1007/s00521-018-03969-x},
abstract = {With the development of cognitive computing, machine learning techniques, and big data analytics, cognitive support is crucial for automated industrial production. The real-time automated visual inspection in industrial production is a challenging task. Speed and accuracy are crucial factors for the process of automating the defect detection. Many statistical and spectrum analysis approaches have been introduced; however, they suffer from high computational cost with average performance. This paper proposes a neighborhood-maintaining approach, which is based on the minimum ratio for fast and reliable inspection of industrial products. The minimum ratio between local neighborhood sliding windows is used as a similarity measure for localizing defection. Extreme learning machine is then adapted to classify surfaces to defect or normal. A defect detection accuracy on textile fabrics has achieved 98.07% with 91.29% sensitivity and 99.67% specificity. The minimum ratio shows highly discriminant power to distinguish between normal and abnormal surfaces. A defective region produces a smaller value of minimum ratio than that of a defect-free region. Experimental results show superior speed and accuracy performance over many existing defect detection methods.},
journal = {Neural Comput. Appl.},
month = may,
pages = {4325–4333},
numpages = {9},
keywords = {Minimum ratio, Defect detection, Visual inspection, Cognitive automation}
}

@article{10.1007/s10845-021-01871-3,
author = {Melakhsou, Abdallah Amine and Batton-Hubert, Mireille},
title = {Welding monitoring and defect detection using probability density distribution and functional nonparametric kernel classifier},
year = {2021},
issue_date = {Mar 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01871-3},
doi = {10.1007/s10845-021-01871-3},
abstract = {Welding fault detection in the industry of hot water tanks remains typically conducted visually or with the assistance of None Destructive Examination, such as X-ray, ultrasound, and penetrant testing. However, this leads to high consumption of time and resources. We propose in this paper a two-level method for automatic welding defect detection and localization. The method is based on the classification of the probability density distributions of the voltage signals underlying the generated stochastic process from the welding operation. In the main phase, we apply a passband filter to the raw signals and use the Kernel Density Estimation to measure the distribution of the filtered signal. The probability density distributions are processed as functional data and classified employing a functional non-parametric kernel classifier. In the second phase, the signal of nonconforming welding is split into segments and their probability density distributions are classified in order to extract the precise location of the defect in the whole signal. The proposed method allows to detect and localize welding defects with high accuracy.},
journal = {J. Intell. Manuf.},
month = nov,
pages = {1469–1481},
numpages = {13},
keywords = {Welding defect detection, Functional data classification, Probability density distribution}
}

@article{10.1155/2021/4997459,
author = {Li, Zhen and Li, Tong and Wu, YuMei and Yang, Liu and Miao, Hong and Wang, DongSheng and Precup, Radu-Emil},
title = {Software Defect Prediction Based on Hybrid Swarm Intelligence and Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/4997459},
doi = {10.1155/2021/4997459},
abstract = {In order to improve software quality and testing efficiency, this paper implements the prediction of software defects based on deep learning. According to the respective advantages and disadvantages of the particle swarm algorithm and the wolf swarm algorithm, the two algorithms are mixed to realize the complementary advantages of the algorithms. At the same time, the hybrid algorithm is used in the search of model hyperparameter optimization, the loss function of the model is used as the fitness function, and the collaborative search ability of the swarm intelligence population is used to find the global optimal solution in multiple local solution spaces. Through the analysis of the experimental results of six data sets, compared with the traditional hyperparameter optimization method and a single swarm intelligence algorithm, the model using the hybrid algorithm has higher and better indicators. And, under the processing of the autoencoder, the performance of the model has been further improved.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {17}
}

@article{10.1007/s00607-016-0538-1,
author = {Gupta, Shivani and Gupta, Atul},
title = {A set of measures designed to identify overlapped instances in software defect prediction},
year = {2017},
issue_date = {September 2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {99},
number = {9},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-016-0538-1},
doi = {10.1007/s00607-016-0538-1},
abstract = {The performance of the learning models will intensely rely on the characteristics of the training data. The previous outcomes recommend that the overlapping between classes and the presence of noise have the most grounded impact on the performance of learning algorithm, and software defect datasets are no exceptions. The class overlap problem is concerned with the performance of machine learning classifiers critical problem is class overlap in which data samples appear as valid examples of more than one class which may be responsible for the presence of noise in datasets. We aim to investigate how the presence of overlapped instances in a dataset influences the classifier's performance, and how to deal with class overlapping problem. To have a close estimate of class overlapping, we have proposed four different measures namely, nearest enemy ratio, subconcept ratio, likelihood ratio and soft margin ratio. We performed our investigations using 327 binary defect classification datasets obtained from 54 software projects, where we first identified overlapped datasets using three data complexity measures proposed in the literature. We also include treatment effort into the prediction process. Subsequently, we used our proposed measures to find overlapped instances in the identified overlapped datasets. Our results indicated that by training a classifier on a training data free from overlapped instances led to an improved classifier performance on the test data containing overlapped instances. The classifiers perform significantly better when the evaluation measure takes the effort into account.},
journal = {Computing},
month = sep,
pages = {889–914},
numpages = {26},
keywords = {Class overlapping, Data complexity measures, Data mining, Machine learning, Software defect prediction}
}

@article{10.1016/j.procs.2018.05.012,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {A Nonlinear Manifold Detection based Model for Software Defect Prediction},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.012},
doi = {10.1016/j.procs.2018.05.012},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {581–594},
numpages = {14},
keywords = {Feature Selection techniques, Friedman test, Nonlinear Manifold Detection techniques, Paired two-tailed T-test, Software Defect Prediction}
}

@inproceedings{10.1145/3180374.3181331,
author = {Li, Yuting and Su, Jianmin and Yang, Xiaoxing},
title = {Multi-Objective vs. Single-Objective Approaches for Software Defect Prediction},
year = {2018},
isbn = {9781450354318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180374.3181331},
doi = {10.1145/3180374.3181331},
abstract = {Software defect prediction employs attributes of software modules to identify defect-prone modules and thus improves software reliability by allocating testing resources more efficiently. Realizing that single-objective methods might be insufficient for solving defect prediction problems, some researchers have proposed multi-objective learning approaches, and proved better performance of multi-objective than single-objective methods. However, existing compared single-objective methods optimize a completely different goal from goals of multi-objective approaches, which might lead to bias. In this paper, we compare a multi-objective approach that optimizes two objectives and a single-objective approach that directly optimizes a trade-off of the two objectives, in order to further investigate the comparison of multi-objective and single-objective approaches. The conclusion will help to appropriately choose multi-objective or single-objective learning approaches for defect prediction.},
booktitle = {Proceedings of the 2018 2nd International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {122–127},
numpages = {6},
keywords = {Multi-objective learning, cost, effectiveness, single-objective learning, software defect prediction},
location = {Wuhan, China},
series = {ICMSS 2018}
}

@inproceedings{10.1109/ICSE.2019.00076,
author = {Cabral, George G. and Minku, Leandro L. and Shihab, Emad and Mujahid, Suhaib},
title = {Class imbalance evolution and verification latency in just-in-time software defect prediction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00076},
doi = {10.1109/ICSE.2019.00076},
abstract = {Just-in-Time Software Defect Prediction (JIT-SDP) is an SDP approach that makes defect predictions at the software change level. Most existing JIT-SDP work assumes that the characteristics of the problem remain the same over time. However, JIT-SDP may suffer from class imbalance evolution. Specifically, the imbalance status of the problem (i.e., how much underrepresented the defect-inducing changes are) may be intensified or reduced over time. If occurring, this could render existing JIT-SDP approaches unsuitable, including those that rebuild classifiers over time using only recent data. This work thus provides the first investigation of whether class imbalance evolution poses a threat to JIT-SDP. This investigation is performed in a realistic scenario by taking into account verification latency - the often overlooked fact that labeled training examples arrive with a delay. Based on 10 GitHub projects, we show that JIT-SDP suffers from class imbalance evolution, significantly hindering the predictive performance of existing JIT-SDP approaches. Compared to state-of-the-art class imbalance evolution learning approaches, the predictive performance of JIT-SDP approaches was up to 97.2% lower in terms of g-mean. Hence, it is essential to tackle class imbalance evolution in JIT-SDP. We then propose a novel class imbalance evolution approach for the specific context of JIT-SDP. While maintaining top ranked g-means, this approach managed to produce up to 63.59% more balanced recalls on the defect-inducing and clean classes than state-of-the-art class imbalance evolution approaches. We thus recommend it to avoid overemphasizing one class over the other in JIT-SDP.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {666–676},
numpages = {11},
keywords = {class imbalance, concept drift, ensembles, online learning, software defect prediction, verification latency},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/2896387.2900324,
author = {Rahman, Md. Habibur and Sharmin, Sadia and Sarwar, Sheikh Muhammad and Shoyaib, Mohammad},
title = {Software Defect Prediction Using Feature Space Transformation},
year = {2016},
isbn = {9781450340632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896387.2900324},
doi = {10.1145/2896387.2900324},
abstract = {In software quality estimation research, software defect prediction is a key topic. A defect prediction model is generally constructed using a variety of software attributes and each attribute may have positive, negative or neutral effect on a specific model. Selection of an optimal set of attributes for model development remains a vital yet unexplored issue. In this paper, we have introduced a new feature space transformation process with a normalization technique to improve the defect prediction accuracy. We proposed a feature space transformation technique and classify the instances using Support Vector Machine (SVM) with its histogram intersection kernel. The proposed method is evaluated using the data sets from NASA metric data repository and its application demonstrates acceptable accuracy.},
booktitle = {Proceedings of the International Conference on Internet of Things and Cloud Computing},
articleno = {72},
numpages = {6},
keywords = {Attribute selection, Feature space transformation, Software defect prediction},
location = {Cambridge, United Kingdom},
series = {ICC '16}
}

@inproceedings{10.1145/3028842.3028859,
author = {Gao, Yan and Yang, Chunhui},
title = {Software defect prediction based on manifold learning in subspace selection},
year = {2016},
isbn = {9781450347990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3028842.3028859},
doi = {10.1145/3028842.3028859},
abstract = {Software defects will lead to software running error and system crashes. In order to detect software defect as early as possible at early stage of software development, a series of machine learning approaches have been studied and applied to predict defects in software modules. Unfortunately, the imbalanceof software defect datasets brings great challenge to software defect prediction model training. In this paper, a new manifold learning based subspace learning algorithm, Discriminative Locality Alignment(DLA), is introduced into software defects prediction. Experimental results demonstrate that DLA is consistently superior to LDA (Linear Discriminant Analysis) and PCA (Principal Component Analysis) in terms of discriminate information extraction and prediction performance. In addition, DLA reveals some attractive intrinsic properties for numeric calculation, e.g. it can overcome the matrix singular problem and small sample size problem in software defect prediction.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Information Processing},
articleno = {17},
numpages = {6},
keywords = {discriminative locality alignment, manifold learning, software defect prediction, support vector machine},
location = {Wuhan, China},
series = {ICIIP '16}
}

@article{10.1504/ijwmc.2021.120013,
author = {Li, Gongfa and Liu, Xin and Tao, Bo and Jiang, Du and Zeng, Fei and Xu, Shuang},
title = {Research on ceramic tile defect detection based on YOLOv3},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {21},
number = {2},
issn = {1741-1084},
url = {https://doi.org/10.1504/ijwmc.2021.120013},
doi = {10.1504/ijwmc.2021.120013},
abstract = {Artificial intelligence is a technology that studies, simulates and expands human intelligence theory and related methods, it is the direction of modern and future science and technology development. The teaching methods of artificial intelligence courses are supposed to be different from the traditional teaching methods, but the actual investigation finds that there are still some problems in the artificial intelligence course, such as the single teaching mode, the low enthusiasm of students for studying, and the poor practical ability of students. In order to solve these issues, this paper applies project teaching methods to an artificial intelligence course, through a specific tile defect detection project to analyse. YOLOv3 algorithm is used to detect six kinds of tile defects, and the experimental results are analysed.},
journal = {Int. J. Wire. Mob. Comput.},
month = jan,
pages = {128–133},
numpages = {5},
keywords = {defect detection, artificial intelligence, YOLOv3 algorithm, project-based teaching}
}

@article{10.1504/ijcat.2019.100297,
author = {Jayanthi, R. and Florence, M. Lilly},
title = {Improved Bayesian regularisation using neural networks based on feature selection for software defect prediction},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {60},
number = {3},
issn = {0952-8091},
url = {https://doi.org/10.1504/ijcat.2019.100297},
doi = {10.1504/ijcat.2019.100297},
abstract = {Demand for software-based applications has grown drastically in various real-time applications. However, software testing schemes have been developed which include manual and automatic testing. Manual testing requires human effort and chances of error may still affect the quality of software. To overcome this issue, automatic software testing techniques based on machine learning techniques have been developed. In this work, we focus on the machine learning scheme for early prediction of software defects using Levenberg-Marquardt algorithm (LM), Back Propagation (BP) and Bayesian Regularisation (BR) techniques. Bayesian regularisation achieves better performance in terms of bug prediction. However, this performance can be enhanced further. Hence, we developed a novel approach for attribute selection-based feature selection technique to improve the performance of BR classification. An extensive study is carried out with the PROMISE repository where we considered KC1 and JM1 datasets. Experimental study shows that the proposed approach achieves better performance in predicting the defects in software.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {225–241},
numpages = {16},
keywords = {defect prediction model, machine learning techniques, software defect prediction, software metrics, gradient descent optimisation, gradient-based approach, feature subset selection, cross entropy error function, adaptive computation process}
}

@inproceedings{10.1145/3490725.3490739,
author = {Shi, Linlin and Yu, Pengfei and He, Shilie and Zhou, Zhenwei and Meng, Linghui and Liu, Junbin},
title = {Degradation Characteristics Analysis and Fault Prediction of Switching Power Supply Based on Data Mining},
year = {2022},
isbn = {9781450384247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490725.3490739},
doi = {10.1145/3490725.3490739},
abstract = {Fault prediction and health monitoring of DC-DC switching power supply plays an important role in the safe and reliable operation of power electronic equipment. In this paper, a long-term high temperature degradation test was carried out for DC-DC power supply, and the characteristic parameters related to device health, such as input current, input voltage, output current and output voltage, were collected during the test. Through data mining technology, we carry out data preprocessing, feature analysis, health index modeling and fault prediction analysis on the samples collected in the power supply test, so as to study the degradation and fault predictor of the power supply from the real power supply test degradation data. The research results of this paper have important engineering significance for the monitoring and health prediction of power supply.},
booktitle = {Proceedings of the 2021 4th International Conference on Machine Learning and Machine Intelligence},
pages = {89–98},
numpages = {10},
keywords = {DC-DC power supply, Data Mining, Fault Prediction, feature analysis},
location = {Hangzhou, China},
series = {MLMI '21}
}

@inproceedings{10.1109/CASE49439.2021.9551659,
author = {Melakhsou, Abdallah Amine and Batton-Hubert, Mireille},
title = {On welding defect detection and causalities between welding signals},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CASE49439.2021.9551659},
doi = {10.1109/CASE49439.2021.9551659},
abstract = {In the manufacturing of hot water tanks, welding quality evaluation and fault detection is a critical operation that is still frequently conducted visually or with the help of none destructive tests, which can generate a high consumption of time and resources. To overcome this problem, many methods have been proposed for defect detection based on the classification of the welding signals. However, most of the proposed methods do not consider the problems of defect localization and the generalization from small sample size. Moreover, studies on the interactions between welding signals seem to be absent in the literature despite its importance in the formulation of the defect detection problem. In this paper, we aim to address these gaps by presenting a study on the causalities between welding signals in the circular welding of hot water tanks. Based on the findings from the causality study, we propose a method that detects and localize welding defect with high accuracy and handles the problem of small sample size. Furthermore, we present a study on the defects root cause and show the possibility of early defect prediction.},
booktitle = {2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)},
pages = {401–408},
numpages = {8},
location = {Lyon, France}
}

@article{10.1016/j.neucom.2018.04.090,
author = {Malhotra, Ruchika and Kamal, Shine},
title = {An empirical study to investigate oversampling methods for improving software defect prediction using imbalanced data},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {343},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.04.090},
doi = {10.1016/j.neucom.2018.04.090},
journal = {Neurocomput.},
month = may,
pages = {120–140},
numpages = {21},
keywords = {Defect prediction, Imbalanced data, Oversampling methods, MetaCost learners, Machine learning techniques, Procedural metrics}
}

@inproceedings{10.4108/icst.bict.2014.257871,
author = {Malhotra, Ruchika and Raje, Rajeev},
title = {An empirical comparison of machine learning techniques for software defect prediction},
year = {2014},
isbn = {9781631900532},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.bict.2014.257871},
doi = {10.4108/icst.bict.2014.257871},
abstract = {Software systems are exposed to various types of defects. The timely identification of defective classes is essential in early phases of software development to reduce the cost of testing the software. This will guide the software practitioners and researchers for planning of the proper allocation of testing resources. Software metrics can be used in conjunction with defect data to develop models for predicting defective classes. There have been various machine learning techniques proposed in the literature for analyzing complex relationships and extracting useful information from problems in less time. However, more studies comparing these techniques are needed to provide evidence so that confidence is established on the performance of one technique over the other. In this paper we address four issues (i) comparison of the machine learning techniques over unpopular used data sets (ii) use of inappropriate performance measures for measuring the performance of defect prediction models (iii) less use of statistical tests and (iv) validation of models from the same data set from which they are trained. To resolve these issues, in this paper, we compare 18 machine learning techniques for investigating the effect of Object-Oriented metrics on defective classes. The results are validated on six releases of the 'MMS' application package of recent widely used mobile operating system -- Android. The overall results of the study indicate the predictive capability of the machine learning techniques and an endorsement of one particular ML technique to predict defects.},
booktitle = {Proceedings of the 8th International Conference on Bioinspired Information and Communications Technologies},
pages = {320–327},
numpages = {8},
keywords = {defect prediction, empirical validation, machine learning, object-oriented metrics},
location = {Boston, Massachusetts},
series = {BICT '14}
}

@inproceedings{10.1007/978-3-030-89029-2_16,
author = {Baculo, Maria Jeseca C. and Ruiz, Conrado and Aran, Oya},
title = {Cecid Fly Defect Detection in Mangoes Using Object Detection Frameworks},
year = {2021},
isbn = {978-3-030-89028-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-89029-2_16},
doi = {10.1007/978-3-030-89029-2_16},
abstract = {Mango export has experienced rapid growth in global trade over the past few years, however, they are susceptible to surface defects that can affect their market value. This paper investigates the automated detection of a mango defect caused by cecid flies, which can affect a significant portion of the production yield.

 Object detection frameworks using CNN were used to localize and detect multiple defects present in a single mango image. This paper also proposes modified versions of R-CNN and FR-CNN replacing its region search algorithms with segmentation-based region extraction. A dataset consisting of 1329 cecid fly surface blemishes was used to train the object detection models. The results of the experiments show comparable performance between the modified and existing state-of-the-art object detection frameworks. Results show that Faster R-CNN achieved the highest average precision of 0.901 at aP50 while the Modified FR-CNN has the highest average precision of 0.723 at aP75.},
booktitle = {Advances in Computer Graphics: 38th Computer Graphics International Conference, CGI 2021, Virtual Event, September 6–10, 2021, Proceedings},
pages = {205–216},
numpages = {12},
keywords = {Defect detection, Image processing, Region-based CNN, Convolutional neural networks}
}

@article{10.1155/2021/9948808,
author = {Li, Chao and Li, Jun and Li, Yafei and He, Lingmin and Fu, Xiaokang and Chen, Jingjing and Zhou, Xiaokang},
title = {Fabric Defect Detection in Textile Manufacturing: A Survey of the State of the Art},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/9948808},
doi = {10.1155/2021/9948808},
abstract = {Defects in the textile manufacturing process lead to a great waste of resources and further affect the quality of textile products. Automated quality guarantee of textile fabric materials is one of the most important and demanding computer vision tasks in textile smart manufacturing. This survey presents a thorough overview of algorithms for fabric defect detection. First, this review briefly introduces the importance and inevitability of fabric defect detection towards the era of manufacturing of artificial intelligence. Second, defect detection methods are categorized into traditional algorithms and learning-based algorithms, and traditional algorithms are further categorized into statistical, structural, spectral, and model-based algorithms. The learning-based algorithms are further divided into conventional machine learning algorithms and deep learning algorithms which are very popular recently. A systematic literature review on these methods is present. Thirdly, the deployments of fabric defect detection algorithms are discussed in this study. This paper provides a reference for researchers and engineers on fabric defect detection in textile manufacturing.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {13}
}

@article{10.1155/2019/2384706,
author = {Yang, Xingguang and Yu, Huiqun and Fan, Guisheng and Shi, Kai and Chen, Liqiong and Tramontana, Emiliano},
title = {Local versus Global Models for Just-In-Time Software Defect Prediction},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1058-9244},
url = {https://doi.org/10.1155/2019/2384706},
doi = {10.1155/2019/2384706},
abstract = {Just-in-time software defect prediction (JIT-SDP) is an active topic in software defect prediction, which aims to identify defect-inducing changes. Recently, some studies have found that the variability of defect data sets can affect the performance of defect predictors. By using local models, it can help improve the performance of prediction models. However, previous studies have focused on module-level defect prediction. Whether local models are still valid in the context of JIT-SDP is an important issue. To this end, we compare the performance of local and global models through a large-scale empirical study based on six open-source projects with 227417 changes. The experiment considers three evaluation scenarios of cross-validation, cross-project-validation, and timewise-cross-validation. To build local models, the experiment uses the k-medoids to divide the training set into several homogeneous regions. In addition, logistic regression and effort-aware linear regression (EALR) are used to build classification models and effort-aware prediction models, respectively. The empirical results show that local models perform worse than global models in the classification performance. However, local models have significantly better effort-aware prediction performance than global models in the cross-validation and cross-project-validation scenarios. Particularly, when the number of clusters k is set to 2, local models can obtain optimal effort-aware prediction performance. Therefore, local models are promising for effort-aware JIT-SDP.},
journal = {Sci. Program.},
month = jan,
numpages = {13}
}

@article{10.4018/IJOSSP.2018010101,
author = {Kakkar, Misha and Jain, Sarika and Bansal, Abhay and Grover, P.S.},
title = {Combining Data Preprocessing Methods With Imputation Techniques for Software Defect Prediction},
year = {2018},
issue_date = {January 2018},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {1},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2018010101},
doi = {10.4018/IJOSSP.2018010101},
abstract = {Software Defect Prediction SDP models are used to predict, whether software is clean or buggy using the historical data collected from various software repositories. The data collected from such repositories may contain some missing values. In order to estimate missing values, imputation techniques are used, which utilizes the complete observed values in the dataset. The objective of this study is to identify the best-suited imputation technique for handling missing values in SDP dataset. In addition to identifying the imputation technique, the authors have investigated for the most appropriate combination of imputation technique and data preprocessing method for building SDP model. In this study, four combinations of imputation technique and data preprocessing methods are examined using the improved NASA datasets. These combinations are used along with five different machine-learning algorithms to develop models. The performance of these SDP models are then compared using traditional performance indicators. Experiment results show that among different imputation techniques, linear regression gives the most accurate imputed value. The combination of linear regression with correlation based feature selector outperforms all other combinations. To validate the significance of data preprocessing methods with imputation the findings are applied to open source projects. It was concluded that the result is in consistency with the above conclusion.},
journal = {Int. J. Open Source Softw. Process.},
month = jan,
pages = {1–19},
numpages = {19},
keywords = {Feature Selection, Instance Selection, Missing Value Imputation, Software Defect Prediction}
}

@inproceedings{10.1145/3426826.3426832,
author = {Qi, Shengxiang and Yang, Jiarong and Zhong, Zhenyi},
title = {A Review on Industrial Surface Defect Detection Based on Deep Learning Technology},
year = {2020},
isbn = {9781450388344},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3426826.3426832},
doi = {10.1145/3426826.3426832},
abstract = {In recent years, with the rapid development of deep learning, computer vision technology based on convolutional neural network (CNN) is widely used in industrial fields. At present, surface defect detection by machine vision is one of the most mature applications of CNN in industry. This paper provides a comprehensive overview of deep learning in the field. First of all, we briefly introduce the major tasks of CNN in computer vision researches, including image classification, object detection, edge detection and image segmentation, which are frequently used techniques in surface defect inspection. After that, we describe in detail the applications of computer vision based on CNN models in a variety of industrial scenarios for surface defect detection tasks, which mainly cover the steel surface defect inspection, magnetic tile surface defect inspection, rail surface defect inspection, screen surface detect inspection, solar cell surface defect inspection, and some others. As an emerging representative of artificial intelligence technology, we believe that deep learning will gradually become one of the mainstream technologies for industrial vision in the future. Accordingly, this paper aims to present a reference and guidance for researchers in industry to apply the advanced technology of deep learning.},
booktitle = {Proceedings of the 2020 3rd International Conference on Machine Learning and Machine Intelligence},
pages = {24–30},
numpages = {7},
keywords = {Deep learning, computer vision, industrial application, surface defect detection},
location = {Hangzhou, China},
series = {MLMI '20}
}

@article{10.1016/j.infsof.2017.11.008,
author = {Tong, Haonan and Liu, Bin and Wang, Shihai},
title = {Software defect prediction using stacked denoising autoencoders and two-stage ensemble learning},
year = {2018},
issue_date = {Apr 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {96},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.11.008},
doi = {10.1016/j.infsof.2017.11.008},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {94–111},
numpages = {18},
keywords = {Software defect prediction, Stacked denoising autoencoders, Ensemble learning, Software metrics, Deep learning}
}

@article{10.1016/j.knosys.2015.09.035,
author = {Li, Weiwei and Huang, Zhiqiu and Li, Qing},
title = {Three-way decisions based software defect prediction},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {91},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.09.035},
doi = {10.1016/j.knosys.2015.09.035},
abstract = {Based on a two-stage classification method and a two-stage ranking method on three-way decisions, this paper introduces a three-way decisions framework for cost-sensitive software defect prediction. For the classification problem in software defect prediction, traditional two-way decisions methods usually generate a higher classification error and more decision cost. Here, a two-stage classification method that integrates three-way decisions and ensemble learning to predict software defect is proposed. Experimental results on NASA data sets show that our method can obtain a higher accuracy and a lower decision cost. For the ranking problem in software defect prediction, a two-stage ranking method is introduced. In the first stage, all software modules are classified into three different regions based on three-way decisions. A dominance relation rough set based ranking algorithm is next applied to rank the modules in each region. Comparison experiments with 6 other ranking methods present that our proposed method can obtain a better result on FPA measure.},
journal = {Know.-Based Syst.},
month = jan,
pages = {263–274},
numpages = {12},
keywords = {Software defect classification, Software defect ranking, Three-way decisions}
}

@inproceedings{10.1007/978-3-030-61616-8_2,
author = {Li, Yajie and Chen, Yiqiang and Gu, Yang and Ouyang, Jianquan and Wang, Jiwei and Zeng, Ni},
title = {A Lightweight Fully Convolutional Neural Network of High Accuracy Surface Defect Detection},
year = {2020},
isbn = {978-3-030-61615-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-61616-8_2},
doi = {10.1007/978-3-030-61616-8_2},
abstract = {Surface defect detection is an indispensable step in the production process. Recent researches based on deep learning have paid primarily attention to improving accuracy. However, it is difficult to apply in real situation, because of huge number of parameters and the strict hardware requirements. In this paper, a lightweight fully convolutional neural network, named LFCSDD, is proposed. The parameters of our model are 11x fewer than baselines at least, and obtain the accuracy of 99.72% and 98.74% on benchmark defect datasets, DAGM 2007 and KolektorSDD, respectively, outperforming all the baselines. In addition, our model can process the images with different sizes, which is verified on the RSDDs with the accuracy of 97.00%.},
booktitle = {Artificial Neural Networks and Machine Learning – ICANN 2020: 29th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 15–18, 2020, Proceedings, Part II},
pages = {15–26},
numpages = {12},
keywords = {Surface defect detection, Convolutional neural network, Lightweight},
location = {Bratislava, Slovakia}
}

@inproceedings{10.1007/978-3-030-90439-5_28,
author = {Kobayashi, Hiroki and Miyoshi, Ryo and Hashimoto, Manabu},
title = {Normal Image Generation-Based Defect Detection by Generative Adversarial Network with Chaotic Random Images},
year = {2021},
isbn = {978-3-030-90438-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90439-5_28},
doi = {10.1007/978-3-030-90439-5_28},
abstract = {We propose a defect detection method called ChaosGAN (Generative Adversarial Network with Chaotic Random Images) for image generation that can output a normal image with high reconstruction performance regardless of whether the input image is normal or anomaly. A defect detection method based on image generation should be able to (i) convert from a normal image to the same normal image as input and (ii) convert from an anomaly image to normal image with the defective parts removed. ChaosGAN is a combination of Skip-GANomaly, which performs well at identity mapping of a normal image, and AnoGAN, which reconstructs a normal image by regarding a random image as an input latent space. We conducted an experiment to evaluate ChaosGAN using the area under the curve of receiver operating characteristic (AUROC). The AUROC was 0.76 with ChaosGAN (AnoGAN was 0.49, and Skip-GANomaly was 0.67), indicating that it performs better than other defect detection methods.},
booktitle = {Advances in Visual Computing: 16th International Symposium, ISVC 2021, Virtual Event, October 4-6, 2021, Proceedings, Part I},
pages = {353–365},
numpages = {13},
keywords = {Random image, Image generation, Uniformly distributed random number, Visual inspection, Defect detection}
}

@inproceedings{10.1145/3483207.3483212,
author = {Yao, Yong and Wei, Siwen and Wang, Jing},
title = {Surface Defect Detection of Aircraft Flared Duct Based on Improved YOLOv4 Algorithm},
year = {2021},
isbn = {9781450390170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483207.3483212},
doi = {10.1145/3483207.3483212},
abstract = {In order to solve the problems of low detection accuracy, slow detection speed and low detection efficiency existing in traditional methods, an improved YOLOv4 algorithm for the surface defect detection of aircraft flared duct is proposed. Firstly, convolutional layers are added to improve the ability of network to extract defect features, and the layers change in the backbone feature extraction network output and the spatial pyramid pooling structure in the YOLOv4 network. Secondly, the aircraft flared ducts with surface defects datasets is made, and the K-means++ clustering algorithm is put forward to cluster the defect samples to obtain the priors anchor's parameters of different sizes. Finally, due to the uneven distribution of defects, we add rotation detection and improved loss function to improve defect detection capabilities. Experiments show that the mAP value of the improved YOLOv4 algorithm on the test set reaches 91.11%, which is 7.50% higher than original YOLOv4 model. The average detection time for each image is 0.1573s, and the detection performance is optimized.},
booktitle = {Proceedings of the 2021 4th International Conference on Signal Processing and Machine Learning},
pages = {26–32},
numpages = {7},
location = {Beijing, China},
series = {SPML '21}
}

@article{10.1007/s10462-017-9563-5,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {A study on software fault prediction techniques},
year = {2019},
issue_date = {February  2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {2},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-017-9563-5},
doi = {10.1007/s10462-017-9563-5},
abstract = {Software fault prediction aims to identify fault-prone software modules by using some underlying properties of the software project before the actual testing process begins. It helps in obtaining desired software quality with optimized cost and effort. Initially, this paper provides an overview of the software fault prediction process. Next, different dimensions of software fault prediction process are explored and discussed. This review aims to help with the understanding of various elements associated with fault prediction process and to explore various issues involved in the software fault prediction. We search through various digital libraries and identify all the relevant papers published since 1993. The review of these papers are grouped into three classes: software metrics, fault prediction techniques, and data quality issues. For each of the class, taxonomical classification of different techniques and our observations have also been presented. The review and summarization in the tabular form are also given. At the end of the paper, the statistical analysis, observations, challenges, and future directions of software fault prediction have been discussed.},
journal = {Artif. Intell. Rev.},
month = feb,
pages = {255–327},
numpages = {73},
keywords = {Fault prediction techniques, Software fault datasets, Software fault prediction, Software metrics, Taxonomic classification}
}

@article{10.1016/j.asoc.2017.05.043,
author = {Arar, mer Faruk and Ayan, Krat},
title = {A feature dependent Naive Bayes approach and its application to the software defect prediction problem},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {59},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.05.043},
doi = {10.1016/j.asoc.2017.05.043},
abstract = {Display Omitted In Naive Bayes, features are assumed to be independent and have equal weight. But, In practice, features are interrelated.In this study, features are included for calculation as pairs using the proposed Feature Dependent Naive Bayes (FDNB) method.Eight data sets from the NASA PROMISE repository were used for the software defect prediction problem.Results were compared with other modified NBs. Increased classification performance was found after use of the proposed FDNB. Naive Bayes is one of the most widely used algorithms in classification problems because of its simplicity, effectiveness, and robustness. It is suitable for many learning scenarios, such as image classification, fraud detection, web mining, and text classification. Naive Bayes is a probabilistic approach based on assumptions that features are independent of each other and that their weights are equally important. However, in practice, features may be interrelated. In that case, such assumptions may cause a dramatic decrease in performance. In this study, by following preprocessing steps, a Feature Dependent Naive Bayes (FDNB) classification method is proposed. Features are included for calculation as pairs to create dependence between one another. This method was applied to the software defect prediction problem and experiments were carried out using widely recognized NASA PROMISE data sets. The obtained results show that this new method is more successful than the standard Naive Bayes approach and that it has a competitive performance with other feature-weighting techniques. A further aim of this study is to demonstrate that to be reliable, a learning model must be constructed by using only training data, as otherwise misleading results arise from the use of the entire data set.},
journal = {Appl. Soft Comput.},
month = oct,
pages = {197–209},
numpages = {13},
keywords = {Data mining, Discretization, Feature independence, Naive Bayes, Software defect prediction}
}

@inproceedings{10.1145/3474198.3478149,
author = {Cheng, Zhen and Luo, Xin and Shi, Youqun and Kita, Kenji},
title = {Fabric defect detection algorithm based on YOLOv3 Transfer learning},
year = {2022},
isbn = {9781450390149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474198.3478149},
doi = {10.1145/3474198.3478149},
abstract = {Fabric defect detection is an important part of controlling the quality of fabrics. Aiming at the low accuracy of manual detection methods and the difficulty of manual feature extraction in traditional machine learning methods, a transfer learning method based on YOLOv3 is proposed to achieve fabric defect detection. First, combined with the transfer learning principle, freeze the low layers of the network, and only retrain the parameters of certain layers in the higher layers with the fabric defect dataset. Then use the K-means algorithm to perform dimensional clustering to determine the anchor frame parameters. Finally, a detection layer is added before the third prediction scale in YOLOv3 to fuse the high semantic information of deep network with the high resolution of shallow layer to realize multi-scale fusion detection and improve the accuracy of fabric defect detection task. The experimental results show that the algorithm can effectively detect the surface defects of fabric image, and the accuracy rate is 88.87%. It has practical application value for fabric defect detection.},
booktitle = {International Conference on Frontiers of Electronics, Information and Computation Technologies},
articleno = {69},
numpages = {7},
keywords = {Deep learning, Fabric defect, K-means, Transfer learning, YOLOv3},
location = {Changsha, China},
series = {ICFEICT 2021}
}

@inproceedings{10.1145/2591062.2591151,
author = {Jing, Xiao-Yuan and Zhang, Zhi-Wu and Ying, Shi and Wang, Feng and Zhu, Yang-Ping},
title = {Software defect prediction based on collaborative representation classification},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591151},
doi = {10.1145/2591062.2591151},
abstract = {In recent years, machine learning techniques have been successfully applied into software defect prediction. Although they can yield reasonably good prediction results, there still exists much room for improvement on the aspect of prediction accuracy. Sparse representation is one of the most advanced machine learning techniques. It performs well with respect to signal compression and classification, but suffers from its time-consuming sparse coding. Compared with sparse representation, collaborative representation classification (CRC) can yield significantly lower computational complexity and competitive classification performance in pattern recognition domains. To achieve better defect prediction results, we introduce the CRC technique in this paper and propose a CRC based software defect prediction (CSDP) approach. We first design a CRC based learner to build a prediction model, whose computational burden is low. Then, we design a CRC based predictor to classify whether the query software modules are defective or defective-free. Experimental results on the widely used NASA datasets demonstrate the effectiveness and efficiency of the proposed approach.},
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {632–633},
numpages = {2},
keywords = {Collaborative representation classification, Machine learning, Prediction model, Software defect prediction},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@article{10.1016/j.knosys.2021.107272,
author = {Lin, Dongyun and Li, Yiqun and Prasad, Shitala and Nwe, Tin Lay and Dong, Sheng and Oo, Zaw Min},
title = {CAM-guided Multi-Path Decoding U-Net with Triplet Feature Regularization for Defect Detection and Segmentation},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {228},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107272},
doi = {10.1016/j.knosys.2021.107272},
journal = {Know.-Based Syst.},
month = sep,
numpages = {13},
keywords = {Defect detection and segmentation, Multi-path decoding, Triplet feature regularization, U-Net}
}

@inproceedings{10.1145/3238147.3240469,
author = {Qu, Yu and Liu, Ting and Chi, Jianlei and Jin, Yangxu and Cui, Di and He, Ancheng and Zheng, Qinghua},
title = {node2defect: using network embedding to improve software defect prediction},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240469},
doi = {10.1145/3238147.3240469},
abstract = {Network measures have been proved to be useful in predicting software defects. Leveraging the dependency relationships between software modules, network measures can capture various structural features of software systems. However, existing studies have relied on user-defined network measures (e.g., degree statistics or centrality metrics), which are inflexible and require high computation cost, to describe the structural features. In this paper, we propose a new method called node2defect which uses a newly proposed network embedding technique, node2vec, to automatically learn to encode dependency network structure into low-dimensional vector spaces to improve software defect prediction. Specifically, we firstly construct a program's Class Dependency Network. Then node2vec is used to automatically learn structural features of the network. After that, we combine the learned features with traditional software engineering features, for accurate defect prediction. We evaluate our method on 15 open source programs. The experimental results show that in average, node2defect improves the state-of-the-art approach by 9.15% in terms of F-measure.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {844–849},
numpages = {6},
keywords = {Software defect, defect prediction, network embedding, software metrics},
location = {Montpellier, France},
series = {ASE '18}
}

@article{10.1109/TIP.2019.2959741,
author = {Liu, Juhua and Wang, Chaoyue and Su, Hai and Du, Bo and Tao, Dacheng},
title = {Multistage GAN for Fabric Defect Detection},
year = {2020},
issue_date = {2020},
publisher = {IEEE Press},
volume = {29},
issn = {1057-7149},
url = {https://doi.org/10.1109/TIP.2019.2959741},
doi = {10.1109/TIP.2019.2959741},
abstract = {Fabric defect detection is an intriguing but challenging topic. Many methods have been proposed for fabric defect detection, but these methods are still suboptimal due to the complex diversity of both fabric textures and defects. In this paper, we propose a generative adversarial network (GAN)-based framework for fabric defect detection. Considering existing challenges in real-world applications, the proposed fabric defect detection system is capable of learning existing fabric defect samples and automatically adapting to different fabric textures during different application periods. Specifically, we customize a deep semantic segmentation network for fabric defect detection that can detect different defect types. Furthermore, we attempted to train a multistage GAN to synthesize reasonable defects in new defect-free samples. First, a texture-conditioned GAN is trained to explore the conditional distribution of defects given different texture backgrounds. Given a novel fabric, we aim to generate reasonable defective patches. Then, a GAN-based fusion network fuses the generated defects to specific locations. Finally, the well-trained multistage GAN continuously updates the existing fabric defect datasets and contributes to the fine-tuning of the semantic segmentation network to better detect defects under different conditions. Comprehensive experiments on various representative fabric samples are conducted to verify the detection performance of our proposed method.},
journal = {Trans. Img. Proc.},
month = jan,
pages = {3388–3400},
numpages = {13}
}

@inproceedings{10.1109/SMC52423.2021.9659140,
author = {Kankam Gyimah, Nana and Girma, Abenezer and Nabil Mahmoud, Mahmoud and Nateghi, Shamila and Homaifar, Abdollah and Opoku, Daniel},
title = {A Robust Completed Local Binary Pattern (RCLBP) for Surface Defect Detection},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC52423.2021.9659140},
doi = {10.1109/SMC52423.2021.9659140},
abstract = {In this paper, we present a Robust Completed Local Binary Pattern (RCLBP) framework for a surface defect detection task. Our approach uses a combination of Non-Local (NL) means filter with wavelet thresholding and Completed Local Binary Pattern (CLBP) to extract robust features which are fed into classifiers for surface defects detection. This paper combines three components: A denoising technique based on Non-Local (NL) means filter with wavelet thresholding is established to denoise the noisy image while preserving the textures and edges. Second, discriminative features are extracted using the CLBP technique. Finally, the discriminative features are fed into the classifiers to build the detection model and evaluate the performance of the proposed framework. The performance of the defect detection models are evaluated using a real-world steel surface defect database from Northeastern University (NEU). Experimental results demonstrate that the proposed approach RCLBP is noise robust and can be applied for surface defect detection under varying conditions of intraclass and inter-class changes and with illumination changes.},
booktitle = {2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
pages = {1927–1934},
numpages = {8},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/2931037.2931039,
author = {Bowes, David and Hall, Tracy and Harman, Mark and Jia, Yue and Sarro, Federica and Wu, Fan},
title = {Mutation-aware fault prediction},
year = {2016},
isbn = {9781450343909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2931037.2931039},
doi = {10.1145/2931037.2931039},
abstract = {We introduce mutation-aware fault prediction, which leverages additional guidance from metrics constructed in terms of mutants and the test cases that cover and detect them. We report the results of 12 sets of experiments, applying 4 different predictive modelling techniques to 3 large real-world systems (both open and closed source). The results show that our proposal can significantly (p ≤ 0.05) improve fault prediction performance. Moreover, mutation-based metrics lie in the top 5% most frequently relied upon fault predictors in 10 of the 12 sets of experiments, and provide the majority of the top ten fault predictors in 9 of the 12 sets of experiments.},
booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
pages = {330–341},
numpages = {12},
keywords = {Empirical Study, Mutation Testing, Software Defect Prediction, Software Fault Prediction, Software Metrics},
location = {Saarbr\"{u}cken, Germany},
series = {ISSTA 2016}
}

@article{10.1016/j.jss.2019.03.012,
author = {Ni, Chao and Chen, Xiang and Wu, Fangfang and Shen, Yuxiang and Gu, Qing},
title = {An empirical study on pareto based multi-objective feature selection for software defect prediction},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.03.012},
doi = {10.1016/j.jss.2019.03.012},
journal = {J. Syst. Softw.},
month = jun,
pages = {215–238},
numpages = {24},
keywords = {xx-xx, xx-xx, Software defect prediction, Search based software engineering, Feature selection, Multi-Objective optimization, Empirical study}
}

@inproceedings{10.1145/2568225.2568320,
author = {Jing, Xiao-Yuan and Ying, Shi and Zhang, Zhi-Wu and Wu, Shan-Shan and Liu, Jin},
title = {Dictionary learning based software defect prediction},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568320},
doi = {10.1145/2568225.2568320},
abstract = {In order to improve the quality of a software system, software defect prediction aims to automatically identify defective software modules for efficient software test. To predict software defect, those classification methods with static code attributes have attracted a great deal of attention. In recent years, machine learning techniques have been applied to defect prediction. Due to the fact that there exists the similarity among different software modules, one software module can be approximately represented by a small proportion of other modules. And the representation coefficients over the pre-defined dictionary, which consists of historical software module data, are generally sparse. In this paper, we propose to use the dictionary learning technique to predict software defect. By using the characteristics of the metrics mined from the open source software, we learn multiple dictionaries (including defective module and defective-free module sub-dictionaries and the total dictionary) and sparse representation coefficients. Moreover, we take the misclassification cost issue into account because the misclassification of defective modules generally incurs much higher risk cost than that of defective-free ones. We thus propose a cost-sensitive discriminative dictionary learning (CDDL) approach for software defect classification and prediction. The widely used datasets from NASA projects are employed as test data to evaluate the performance of all compared methods. Experimental results show that CDDL outperforms several representative state-of-the-art defect prediction methods.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {414–423},
numpages = {10},
keywords = {Software defect prediction, cost-sensitive discriminative dictionary learning (CDDL), dictionary learning, sparse representation},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@article{10.1016/j.neucom.2021.06.094,
author = {Posilovi\'{c}, Luka and Medak, Duje and Suba\v{s}i\'{c}, Marko and Budimir, Marko and Lon\v{c}ari\'{c}, Sven},
title = {Generative adversarial network with object detector discriminator for enhanced defect detection on ultrasonic B-scans},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {459},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.06.094},
doi = {10.1016/j.neucom.2021.06.094},
journal = {Neurocomput.},
month = oct,
pages = {361–369},
numpages = {9},
keywords = {Non-destructive testing, Ultrasonic B-scan, Automated defect detection, Image generation, Generative adversarial networks}
}

@article{10.1155/2020/8852705,
author = {Zheng, Shang and Gai, Jinjing and Yu, Hualong and Zou, Haitao and Gao, Shang and Briola, Daniela},
title = {Software Defect Prediction Based on Fuzzy Weighted Extreme Learning Machine with Relative Density Information},
year = {2020},
issue_date = {2020},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2020},
issn = {1058-9244},
url = {https://doi.org/10.1155/2020/8852705},
doi = {10.1155/2020/8852705},
abstract = {To identify software modules that are more likely to be defective, machine learning has been used to construct software defect prediction (SDP) models. However, several previous works have found that the imbalanced nature of software defective data can decrease the model performance. In this paper, we discussed the issue of how to improve imbalanced data distribution in the context of SDP, which can benefit software defect prediction with the aim of finding better methods. Firstly, a relative density was introduced to reflect the significance of each instance within its class, which is irrelevant to the scale of data distribution in feature space; hence, it can be more robust than the absolute distance information. Secondly, a K-nearest-neighbors-based probability density estimation (KNN-PDE) alike strategy was utilised to calculate the relative density of each training instance. Furthermore, the fuzzy memberships of sample were designed based on relative density in order to eliminate classification error coming from noise and outlier samples. Finally, two algorithms were proposed to train software defect prediction models based on the weighted extreme learning machine. This paper compared the proposed algorithms with traditional SDP methods on the benchmark data sets. It was proved that the proposed methods have much better overall performance in terms of the measures including G-mean, AUC, and Balance. The proposed algorithms are more robust and adaptive for SDP data distribution types and can more accurately estimate the significance of each instance and assign the identical total fuzzy coefficients for two different classes without considering the impact of data scale.},
journal = {Sci. Program.},
month = jan,
numpages = {18}
}

@inproceedings{10.1145/3239576.3239607,
author = {Du, Yuntao and Zhang, Lu and Shi, Jiahao and Tang, Jingjuan and Yin, Ying},
title = {Feature-Grouping-Based Two Steps Feature Selection Algorithm in Software Defect Prediction},
year = {2018},
isbn = {9781450364607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239576.3239607},
doi = {10.1145/3239576.3239607},
abstract = {In order to improve the effect of software defect prediction, many algorithms including feature selection, have been proposed. Based on Wrapper and Filter hybrid framework, a feature-grouping-based feature selection algorithm is proposed in this paper. The algorithm is composed of two steps. In the first step, in order to remove the redundant features, we group the features according to the redundancy between the features. The symmetry uncertainty is used as the constant indicator of the correlation and the FCBF-based grouping algorithm is used to group the features. In the second step, a subset of the features are selected from each group to form the final subset of features. Many classical methods select the representative feature from each group. We consider that when the number of intra-group features is large, the representative features are not enough to reflect the information in this group. Therefore, we require that at least one feature be selected within each group, in this step, the PSO algorithm is used for Searching Randomly from each group. We tested on the open source NASA and PROMISE data sets. Using three kinds of classifier. Compared to the other methods tested in this article, our method resulted in 90% improvement in the predictive performance of 30 sets of results on 10 data sets. Compared with the algorithms without feature selection, the AUC values of this method in the Logistic regression, Naive Bayesian, and K-neighbor classifiers are improved by 5.94% and 4.69% And 8.05%. The FCBF algorithm can also be regarded as a kind of first performing feature grouping. Compared with the FCBF algorithm, the AUC values of this method are improved by 4.78%, 6.41% and 4.4% on the basis of Logistic regression, Naive Bayes and K-neighbor. We can also see that for the FCBF-based grouping algorithm, it could be better to choose a characteristic cloud from each group than to choose a representative one.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
pages = {173–178},
numpages = {6},
keywords = {FCBF-based grouping algorithm, Feature grouping, Intra-group feature selection, PSO, Software defect prediction},
location = {Chengdu, China},
series = {ICAIP '18}
}

@article{10.1016/j.asoc.2017.01.050,
author = {Maua, Goran and Galinac Grbac, Tihana},
title = {Co-evolutionary multi-population genetic programming for classification in software defect prediction},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {55},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.01.050},
doi = {10.1016/j.asoc.2017.01.050},
abstract = {Evolving diverse ensembles using genetic programming has recently been proposed for classification problems with unbalanced data. Population diversity is crucial for evolving effective algorithms. Multilevel selection strategies that involve additional colonization and migration operations have shown better performance in some applications. Therefore, in this paper, we are interested in analysing the performance of evolving diverse ensembles using genetic programming for software defect prediction with unbalanced data by using different selection strategies. We use colonization and migration operators along with three ensemble selection strategies for the multi-objective evolutionary algorithm. We compare the performance of the operators for software defect prediction datasets with varying levels of data imbalance. Moreover, to generalize the results, gain a broader view and understand the underlying effects, we replicated the same experiments on UCI datasets, which are often used in the evolutionary computing community. The use of multilevel selection strategies provides reliable results with relatively fast convergence speeds and outperforms the other evolutionary algorithms that are often used in this research area and investigated in this paper. This paper also presented a promising ensemble strategy based on a simple convex hull approach and at the same time it raised the question whether ensemble strategy based on the whole population should also be investigated.},
journal = {Appl. Soft Comput.},
month = jun,
pages = {331–351},
numpages = {21},
keywords = {Classification, Coevolution, Genetic programming, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-85607-6_20,
author = {Ardito, Carmelo and Deldjoo, Yashar and Di Sciascio, Eugenio and Nazary, Fatemeh and Sapienza, Gianluca},
title = {ISCADA: Towards a Framework for&nbsp;Interpretable Fault Prediction in&nbsp;Smart Electrical Grids},
year = {2021},
isbn = {978-3-030-85606-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-85607-6_20},
doi = {10.1007/978-3-030-85607-6_20},
abstract = {This paper reports ongoing research for the definition of a data-driven self-healing system using machine learning (ML) techniques that can perform automatic and timely detection of fault types and locations. Specifically, the proposed method makes use of spectrogram-based CNN modeling of the 3-phase voltage signals. Furthermore, to keep human operators informed about why certain decisions were made, i.e., to facilitate the interpretability of the black-box ML model, we propose a novel explanation approach that highlight regions in the input spectrogram that contributed the most for the prediction task at hand (e.g., fault type or location) - or visual explanation.},
booktitle = {Human-Computer Interaction – INTERACT 2021: 18th IFIP TC 13 International Conference, Bari, Italy, August 30 – September 3, 2021, Proceedings, Part V},
pages = {270–274},
numpages = {5},
keywords = {Self-healing system, Interpretability, Fault prediction},
location = {Bari, Italy}
}

@phdthesis{10.5555/AAI29159899,
author = {Arar, \"{O}mer Faruk and undefinedBrahim, \"{O}Z\c{c}elik, and G\"{u}ltekin, \c{C}agil, and Pakize, Erdogmu\c{s}, and Onay, Durdu, Pinar},
advisor = {K\"{u}r\c{s}at, Ayan,},
title = {Makine \"{o}\u{g}renme algoritmalar\i{} kullan\i{}larak yaz\i{}l\i{}m Hata Kestiriminin iyile\c{s}tirilmesi / Using Machine Learning Algorithms to Improve Software Defect Prediction},
year = {2016},
isbn = {9798835589593},
publisher = {Sakarya Universitesi (Turkey)},
abstract = {Yaz\i{}l\i{}m sistemleri g\"{u}nl\"{u}k ya\c{s}ant\i{}m\i{}zda \c{c}ok \"{o}nemli bir role sahiptir ve her ge\c{c}en g\"{u}n kullan\i{}m\i{} daha da yayg\i{}nla\c{s}maktad\i{}r. Makinelerin ve servislerin b\"{u}y\"{u}k \c{c}o\u{g}unlu\u{g}u kendi i\c{c}lerinde farkl\i{} t\"{u}rde yaz\i{}l\i{}m i\c{c}erirler. Yaz\i{}l\i{}m geli\c{s}tiriciler, g\"{u}nl\"{u}k kullan\i{}m\i{}n\i{} yayg\i{}nla\c{s}t\i{}rmak ve rekabette geri kalmamak i\c{c}in m\"{u}mk\"{u}n oldu\u{g}unca h\i{}zl\i{} bir \c{s}ekilde yaz\i{}l\i{}mlar\i{} geli\c{s}tirmektedirler. Yaz\i{}l\i{}m ya\c{s}am d\"{o}ng\"{u}s\"{u}; genellikle analiz, tasar\i{}m, kodlama, test ve kurulum safhalar\i{}ndan olu\c{s}tur. Son kullan\i{}c\i{}ya hatadan ar\i{}nd\i{}r\i{}lm\i{}\c{s} bir yaz\i{}l\i{}m sunabilmek i\c{c}in test safhas\i{} etkili olarak y\"{u}r\"{u}t\"{u}lmelidir. Yaz\i{}l\i{}m metrikleri, kaynak kodun kalitesini yans\i{}tmay\i{} ama\c{c}larlar ve i\c{c}eri\u{g}i ile ilgili niceliksel bilgi verirler. Her bir metrik kodun farkl\i{} bir y\"{o}n\"{u}n\"{u} de\u{g}erlendirir. Kaynak kodun kalitesi seviyesi ile risk seviyesi aras\i{}nda bir ili\c{s}ki vard\i{}r. Son 20 y\i{}ll\i{}k d\"{o}nemde, akademisyenler, yaz\i{}l\i{}m hata kestirimi problemine giderek artan bir ilgi g\"{o}stermi\c{s}ler, daha g\"{u}rb\"{u}z bir kestirim i\c{c}in \c{c}e\c{s}itli makine \"{o}\u{g}renmesi yakla\c{s}\i{}mlar\i{} uygulanm\i{}\c{s}t\i{}r. Bu \c{c}al\i{}\c{s}mada da bu problem i\c{c}in \c{c}e\c{s}itli makine \"{o}\u{g}renmesi modelleri \"{o}nerilmi\c{s}tir. Yapay Sinir A\u{g}\i{} ve Yapay Ar\i{} Kolonisi kombinasyonu, Lojistik Regresyon-tabanl\i{} Bender Metot ve Naive Bayes bu \c{c}al\i{}\c{s}mada kullan\i{}lan algoritmalard\i{}r. \"{O}nerilen yakla\c{s}\i{}mlar, herkese a\c{c}\i{}k NASA Metrik Veri Program\i{} ve PROMISE havuzunda bulunan veri setlerine uygulanm\i{}\c{s}t\i{}r. undefinedstatistiki olarak g\"{u}venilir sonu\c{c}lar elde etmek ve \"{o}rneklem yanl\i{}l\i{}\u{g}\i{}n\i{} azaltmak i\c{c}in deneyler n-k\"{u}me \c{c}apraz validasyon ile kurgulanm\i{}\c{s}t\i{}r. Performans\i{} artt\i{}rmak i\c{c}in \"{o}nerilen modellere \"{o}zellik se\c{c}imi, normalizasyon ve ayr\i{}kla\c{s}t\i{}rma gibi \c{c}e\c{s}itli veri \"{o}n i\c{s}leme teknikleri uygulanm\i{}\c{s}t\i{}r. Deneylerden elde edilen sonu\c{c}lar di\u{g}er \c{c}al\i{}\c{s}malar ile kar\c{s}\i{}la\c{s}t\i{}r\i{}lm\i{}\c{s}t\i{}r. Bu \c{c}al\i{}\c{s}ma, \"{o}zellikle, yaz\i{}l\i{}m geli\c{s}tiricileri ve test personelinin kullan\i{}m\i{} y\"{o}n\"{u}yle katk\i{} yapmaktad\i{}r. Yaz\i{}l\i{}m geli\c{s}tiricileri, d\"{u}zenlemeye ihtiya\c{c} duyulan s\i{}n\i{}f veya mod\"{u}lleri g\"{o}r\"{u}rler; dolay\i{}s\i{}yla, bu mod\"{u}llerin kalitesinin artt\i{}r\i{}lmas\i{}na ve risk seviyelerinin azalt\i{}lmas\i{}na katk\i{} yapm\i{}\c{s} olurlar. Test personeli, daha \c{c}ok test yo\u{g}unla\c{s}mas\i{} gerektiren mod\"{u}lleri tespit eder ve bunun neticesinde mod\"{u}llerin \"{o}nceliklendirmesinin risk seviyelerine g\"{o}re yap\i{}lmas\i{} sa\u{g}lanm\i{}\c{s} olunur.},
note = {AAI29159899}
}

@article{10.1016/j.neucom.2020.08.094,
author = {Pastor-L\'{o}pez, Iker and Sanz, Borja and Tellaeche, Alberto and Psaila, Giuseppe and de la Puerta, Jos\'{e} Gaviria and Bringas, Pablo G.},
title = {Quality assessment methodology based on machine learning with small datasets: Industrial castings defects},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {456},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2020.08.094},
doi = {10.1016/j.neucom.2020.08.094},
journal = {Neurocomput.},
month = oct,
pages = {622–628},
numpages = {7},
keywords = {Artificial vision, Machine-learning, Surface defect detection, Defect categorization}
}

@inproceedings{10.1145/3028842.3028858,
author = {Gao, Yan and Yang, Chunhui and Liang, Lixin},
title = {Pseudo-samples generation in Gaussian mixture distribution for software defect prediction},
year = {2016},
isbn = {9781450347990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3028842.3028858},
doi = {10.1145/3028842.3028858},
abstract = {In this paper, we present GCRF method based on pseudo-samples generation and conditional random field (CRF) for software defect prediction in Gaussian Mixture Distribution. In the proposed method, firstly, we leverage Gaussian Mixture Distribution (GMM) to generate pseudo-samples, which can increase the samples of minority class for balancing the train dataset. Secondly, we propose to apply CRF model in the balanced train dataset because the CRF model can handle complex features in nonlinear high dimensional subspace. Moreover, in order to avoid explicit modeling of the observed data, the proposed method can incorporate the classification of software defect data with different statistics characteristics into a unified probabilistic framework. Interestingly, the experiments show that the GCRF method achieves much better prediction performance than the other approach as shown in the software defect data classification task.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Information Processing},
articleno = {16},
numpages = {6},
keywords = {conditional random field, gaussian mixture distribution, imbalance distribution, software defect prediction},
location = {Wuhan, China},
series = {ICIIP '16}
}

@article{10.1155/2021/9374465,
author = {Chen, Yongbin and Fu, Qinshen and Wang, Guitang and Tsai, Sang-Bing},
title = {Surface Defect Detection of Nonburr Cylinder Liner Based on Improved YOLOv4},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/9374465},
doi = {10.1155/2021/9374465},
abstract = {Cylinder liner plays an important role in the internal combustion engine. The surface defects of cylinder liner will directly affect the safety and service life of the internal combustion engine. At present, the surface defect detection of cylinder liner mainly relies on manual visual inspection, which is easily affected by subjective factors of inspectors. Aiming at the bottleneck of traditional visual inspection technology in appearance inspection, this paper proposes a surface defect detection algorithm based on deep learning to realize defect location and classification. Based on the characteristics of the research object in this paper, the surface defect detection algorithm based on the improved YOLOv4 model is proposed, the model framework is constructed, and the data enhancement method and verification method are proposed. Experiments show that the proposed method can improve the detection accuracy and speed and can meet the requirements of the nonburr cylinder surface defect detection. At the same time, the method can be extended to other surface defect detection applications.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {13}
}

@article{10.1007/s10664-019-09787-6,
author = {Berger, Thorsten and Stegh\"{o}fer, Jan-Philipp and Ziadi, Tewfik and Robin, Jacques and Martinez, Jabier},
title = {The state of adoption and the challenges of systematic variability management in industry},
year = {2020},
issue_date = {May 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09787-6},
doi = {10.1007/s10664-019-09787-6},
abstract = {Handling large-scale software variability is still a challenge for many organizations. After decades of research on variability management concepts, many industrial organizations have introduced techniques known from research, but still lament that pure textbook approaches are not applicable or efficient. For instance, software product line engineering—an approach to systematically develop portfolios of products—is difficult to adopt given the high upfront investments; and even when adopted, organizations are challenged by evolving their complex product lines. Consequently, the research community now mainly focuses on re-engineering and evolution techniques for product lines; yet, understanding the current state of adoption and the industrial challenges for organizations is necessary to conceive effective techniques. In this multiple-case study, we analyze the current adoption of variability management techniques in twelve medium- to large-scale industrial cases in domains such as automotive, aerospace or railway systems. We identify the current state of variability management, emphasizing the techniques and concepts they adopted. We elicit the needs and challenges expressed for these cases, triangulated with results from a literature review. We believe our results help to understand the current state of adoption and shed light on gaps to address in industrial practice.},
journal = {Empirical Softw. Engg.},
month = may,
pages = {1755–1797},
numpages = {43},
keywords = {Variability management, Software product lines, Multiple-case study, Challenges}
}

@inproceedings{10.1109/AIM46487.2021.9517664,
author = {Liu, Ming-Wei and Lin, Yu-Heng and Lo, Yuan-Chieh and Shih, Chih-Hsuan and Lin, Pei-Chun},
title = {Defect Detection of Grinded and Polished Workpieces Using Faster R-CNN},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AIM46487.2021.9517664},
doi = {10.1109/AIM46487.2021.9517664},
abstract = {Polishing and grinding are crucial in the fabrication processes of industrial and commercial products. While the fabrication process can be automated using robots or specialized machines, experienced workers are still needed for the subsequent quality inspection. Here, we report the development of an automatic defect detection system, which is capable of detecting the defects of grinded and polished faucets due to its Faster Region-based Convolutional Neural Networks (Faster RCNN) architecture. The images of the workpieces were taken using a manipulator with a preset trajectory to cover all the surfaces of the workpieces. After labeling, the data were augmented to the trainable level. Three pretrained CNN-based models were utilized and evaluated. The hyperparameters were analyzed to validate their effect on the performance of the model. The mean average precision, using the tuned hyperparameters, was 80.26%.},
booktitle = {2021 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)},
pages = {1290–1296},
numpages = {7},
location = {Delft, Netherlands}
}

@article{10.1155/2021/5069016,
author = {Balogun, Abdullateef O. and Basri, Shuib and Mahamad, Saipunidzam and Capretz, Luiz Fernando and Imam, Abdullahi Abubakar and Almomani, Malek A. and Adeyemo, Victor E. and Kumar, Ganesh and Dourado, Ant\'{o}nio},
title = {A Novel Rank Aggregation-Based Hybrid Multifilter Wrapper Feature Selection Method in Software Defect Prediction},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/5069016},
doi = {10.1155/2021/5069016},
abstract = {The high dimensionality of software metric features has long been noted as a data quality problem that affects the performance of software defect prediction (SDP) models. This drawback makes it necessary to apply feature selection (FS) algorithm(s) in SDP processes. FS approaches can be categorized into three types, namely, filter FS (FFS), wrapper FS (WFS), and hybrid FS (HFS). HFS has been established as superior because it combines the strength of both FFS and WFS methods. However, selecting the most appropriate FFS (filter rank selection problem) for HFS is a challenge because the performance of FFS methods depends on the choice of datasets and classifiers. In addition, the local optima stagnation and high computational costs of WFS due to large search spaces are inherited by the HFS method. Therefore, as a solution, this study proposes a novel rank aggregation-based hybrid multifilter wrapper feature selection (RAHMFWFS) method for the selection of relevant and irredundant features from software defect datasets. The proposed RAHMFWFS is divided into two stepwise stages. The first stage involves a rank aggregation-based multifilter feature selection (RMFFS) method that addresses the filter rank selection problem by aggregating individual rank lists from multiple filter methods, using a novel rank aggregation method to generate a single, robust, and non-disjoint rank list. In the second stage, the aggregated ranked features are further preprocessed by an enhanced wrapper feature selection (EWFS) method based on a dynamic reranking strategy that is used to guide the feature subset selection process of the HFS method. This, in turn, reduces the number of evaluation cycles while amplifying or maintaining its prediction performance. The feasibility of the proposed RAHMFWFS was demonstrated on benchmarked software defect datasets with Na\"{\i}ve Bayes and Decision Tree classifiers, based on accuracy, the area under the curve (AUC), and F-measure values. The experimental results showed the effectiveness of RAHMFWFS in addressing filter rank selection and local optima stagnation problems in HFS, as well as the ability to select optimal features from SDP datasets while maintaining or enhancing the performance of SDP models. To conclude, the proposed RAHMFWFS achieved good performance by improving the prediction performances of SDP models across the selected datasets, compared to existing state-of-the-arts HFS methods.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {19}
}

@article{10.1016/j.asoc.2021.107306,
author = {Shaul Hameed, Syed and Muralidharan, V. and Ane, Bernadetta Kwintiana},
title = {Comparative analysis of fuzzy classifier and ANN with histogram features for defect detection and classification in planetary gearbox},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {106},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107306},
doi = {10.1016/j.asoc.2021.107306},
journal = {Appl. Soft Comput.},
month = jul,
numpages = {14},
keywords = {Defect detection, Histogram features, Decision tree, Fuzzy classifier, ANN}
}

@article{10.1049/sfw2.12012,
author = {Zou, Quanyi and Lu, Lu and Qiu, Shaojian and Gu, Xiaowei and Cai, Ziyi},
title = {Correlation feature and instance weights transfer learning for cross project software defect prediction},
year = {2021},
issue_date = {February 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {15},
number = {1},
url = {https://doi.org/10.1049/sfw2.12012},
doi = {10.1049/sfw2.12012},
abstract = {Due to the differentiation between training and testing data in the feature space, cross‐project defect prediction (CPDP) remains unaddressed within the field of traditional machine learning. Recently, transfer learning has become a research hot‐spot for building classifiers in the target domain using the data from the related source domains. To implement better CPDP models, recent studies focus on either feature transferring or instance transferring to weaken the impact of irrelevant cross‐project data. Instead, this work proposes a dual weighting mechanism to aid the learning process, considering both feature transferring and instance transferring. In our method, a local data gravitation between source and target domains determines instance weight, while features that are highly correlated with the learning task, uncorrelated with other features and minimizing the difference between the domains are rewarded with a higher feature weight. Experiments on 25 real‐world datasets indicate that the proposed approach outperforms the existing CPDP methods in most cases. By assigning weights based on the different contribution of features and instances to the predictor, the proposed approach is able to build a better CPDP model and demonstrates substantial improvements over the state‐of‐the‐art CPDP models.},
journal = {IET Software},
month = jan,
pages = {55–74},
numpages = {20},
keywords = {learning (artificial intelligence), pattern classification, software reliability}
}

@article{10.1016/j.procs.2015.02.161,
author = {Arora, Ishani and Tetarwal, Vivek and Saha, Anju},
title = {Open Issues in Software Defect Prediction},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.161},
doi = {10.1016/j.procs.2015.02.161},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {906–912},
numpages = {7},
keywords = {data mining, defect prediction, machine learning, software quality, software testing}
}

@inproceedings{10.1007/978-3-030-59003-1_27,
author = {Shakhovska, Natalya and Yakovyna, Vitaliy and Kryvinska, Natalia},
title = {An Improved Software Defect Prediction Algorithm Using Self-organizing Maps Combined with Hierarchical Clustering and Data Preprocessing},
year = {2020},
isbn = {978-3-030-59002-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59003-1_27},
doi = {10.1007/978-3-030-59003-1_27},
abstract = {An improved software defects prediction algorithm based on combination of Kohonen map and hierarchical clustering is presented in this paper. The need for software reliability assessment and analysis growths rapidly due to increasing dependence of our day-to-day life on software-controlled devices and systems. Software reliability prediction is the only tool available at early stage of software development lifecycle when the debugging cost risk of faulty operation is minimal. Artificial intelligence and machine learning in particular are promising techniques to solve this task. Various classification methods have been used previously to build software defect prediction models, ranging from simple, like logistic regression, to advanced methods, e.g. multivariate adaptive regression splicing. However, the available literature still does not allow to make unambiguous conclusion concerning the choice of the best classifier and trying different dimensions to overcome potential bias is suggested. The purpose of the paper is to analyze the software code metrics to find dependences be-tween software module’s defect-proneness and its metrics. JM1 public NASA dataset from PROMISE Software Engineering Repository was used in this study. To increase the classification accuracy, we combine self-organizing maps with hierarchical clustering and data preprocessing.},
booktitle = {Database and Expert Systems Applications: 31st International Conference, DEXA 2020, Bratislava, Slovakia, September 14–17, 2020, Proceedings, Part I},
pages = {414–424},
numpages = {11},
keywords = {Prediction algorithm, Hierarchical clustering, Software defect analysis},
location = {Bratislava, Slovakia}
}

@article{10.1007/s10489-020-01935-6,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {An empirical study of ensemble techniques for software fault prediction},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {6},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-01935-6},
doi = {10.1007/s10489-020-01935-6},
abstract = {Previously, many researchers have performed analysis of various techniques for the software fault prediction (SFP). Oddly, the majority of such studies have shown the limited prediction capability and their performance for given software fault datasets was not persistent. In contrast to this, recently, ensemble techniques based SFP models have shown promising and improved results across different software fault datasets. However, many new as well as improved ensemble techniques have been introduced, which are not explored for SFP. Motivated by this, the paper performs an investigation on ensemble techniques for SFP. We empirically assess the performance of seven ensemble techniques namely, Dagging, Decorate, Grading, MultiBoostAB, RealAdaBoost, Rotation Forest, and Ensemble Selection. We believe that most of these ensemble techniques are not used before for SFP. We conduct a series of experiments on the benchmark fault datasets and use three distinct classification algorithms, namely, naive Bayes, logistic regression, and J48 (decision tree) as base learners to the ensemble techniques. Experimental analysis revealed that rotation forest with J48 as the base learner achieved the highest precision, recall, and G-mean 1 values of 0.995, 0.994, and 0.994, respectively and Decorate achieved the highest AUC value of 0.986. Further, results of statistical tests showed used ensemble techniques demonstrated a statistically significant difference in their performance among the used ones for SFP. Additionally, the cost-benefit analysis showed that SFP models based on used ensemble techniques might be helpful in saving software testing cost and effort for twenty out of twenty-eight used fault datasets.},
journal = {Applied Intelligence},
month = jun,
pages = {3615–3644},
numpages = {30},
keywords = {Software fault prediction, Ensemble techniques, PROMISE data repository, Empirical analysis}
}

@inproceedings{10.1109/ICMA52036.2021.9512731,
author = {Yang, Lei and Song, Shouan and Niu, Yong and Liu, Yanhong},
title = {A Lightweight Defect Detection Algorithm of Insulators for Power Inspection},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICMA52036.2021.9512731},
doi = {10.1109/ICMA52036.2021.9512731},
abstract = {The rapid development of smart grid causes a large increase of power equipments. Power insulator is one of the most important infrastructures in the power transmission lines which is vital to ensure the safe operation of power system. As a common defect, the missing-cap issues will affect the structural strength of power insulators and the safe operation of power lines. Consequently, the monitoring and assessment of abnormal power insulators are of extreme importance for the safe power transmission lines. Due to the good feature expression ability, machine learning algorithms have got much applications on power line inspection, and they could be divided into two categories: shallow learning and deep learning algorithms. Nevertheless, the defect recognition issues on power insulators are always against complex power inspection environment. It will bring a certain effect to the handcrafted feature design of shallow learning algorithms. Meanwhile, the small-scale defect data set will affect the model training of the deep network model. To address the above issues, aimed at the feature of the limited processing power of airborne processor, a novel lightweight defect detection algorithm is proposed for the defects of power insulators which fuses the advantages of shallow learning and deep learning models. Firstly, an insulator location algorithm based on lightweight deep convolutional neural network (DCNN) model is proposed to remove the disturbance of complex backgrounds and serve the high-precision defect detection. On the basis, the high-level image feature based on the improved transfer learning is acquired to effectively distinguish the normal and abnormal power insulators. Finally, a defect recognition method based on Support Vector Machine (SVM) is proposed to solve the small-scale defect detection issue. Experiments show that the proposed method could well meet the precision and speed demands of power system compared with other inspection methods.},
booktitle = {2021 IEEE International Conference on Mechatronics and Automation (ICMA)},
pages = {281–286},
numpages = {6},
location = {Takamatsu, Japan}
}

@article{10.1007/s00500-018-3546-6,
author = {Khuat, Thanh Tung and Le, My Hanh},
title = {Binary teaching–learning-based optimization algorithm with a new update mechanism for sample subset optimization in software defect prediction},
year = {2019},
issue_date = {Oct 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {20},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-018-3546-6},
doi = {10.1007/s00500-018-3546-6},
abstract = {Software defect prediction has gained considerable attention in recent years. A broad range of computational methods has been developed for accurate prediction of faulty modules based on code and design metrics. One of the challenges in training classifiers is the highly imbalanced class distribution in available datasets, leading to an undesirable bias in the prediction performance for the minority class. Data sampling is a widespread technique to tackle this problem. However, traditional sampling methods, which depend mainly on random resampling from a given dataset, do not take advantage of useful information available in training sets, such as sample quality and representative instances. To cope with this limitation, evolutionary undersampling methods are usually used for identifying an optimal sample subset for the training dataset. This paper proposes a binary teaching–learning- based optimization algorithm employing a distribution-based solution update rule, namely BTLBOd, to generate a balanced subset of highly valuable examples. This subset is then applied to train a classifier for reliable prediction of potentially defective modules in a software system. Each individual in BTLBOd includes two vectors: a real-valued vector generated by the distribution-based update mechanism, and a binary vector produced from the corresponding real vector by a proposed mapping function. Empirical results showed that the optimal sample subset produced by BTLBOd might ameliorate the classification accuracy of the predictor on highly imbalanced software defect data. Obtained results also demonstrated the superior performance of the proposed sampling method compared to other popular sampling techniques.},
journal = {Soft Comput.},
month = oct,
pages = {9919–9935},
numpages = {17},
keywords = {Teaching–learning-based optimization, Binary teaching–learning-based optimization, Distribution-based update, Sample subset optimization, Imbalanced learning, Software defect prediction}
}

@inproceedings{10.1145/3469213.3469219,
author = {Ren, Jing and Huang, Xishi},
title = {Rapid Transformation Estimation Using Deep Learning for Defect Detection},
year = {2021},
isbn = {9781450390200},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469213.3469219},
doi = {10.1145/3469213.3469219},
abstract = {Defect detection is a crucial step in the manufacturing of vehicle parts such as the engine. One major method for defect detection is to use image registration and image difference to identify and segment the defects. The key technology of this approach is to extract the accurate transformation information between the template image and the testing images. In this paper, we propose a novel deep neural network (DNN) method to learn the transformations from the training dataset. Wavelet transformation is introduced to denoise the images and reduce the image size for fast image registration. The results show that the trained DNN models are able to effectively predict the transformation between the template image and the actual test image in real time with high accuracy.},
booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
articleno = {6},
numpages = {5},
location = {Chongqing, China},
series = {ICAIIS 2021}
}

@inproceedings{10.1007/978-3-030-27538-9_49,
author = {Qin, Shujia and Guo, Di and Chen, Heping and Xi, Ning},
title = {Non-concentric Circular Texture Removal for Workpiece Defect Detection},
year = {2019},
isbn = {978-3-030-27537-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27538-9_49},
doi = {10.1007/978-3-030-27538-9_49},
abstract = {Since workpiece defect detection is a typical problem in computer vision with small datasets, generally its solutions cannot exploit the advantages of high accuracy, generalization ability, and neural network structures from the deep learning paradigm. Thus, traditional image processing techniques are still widely applied in such requirements. Aiming at three types of defects (crack, pitting and scratch) on a workpiece with non-concentric circular textures that severely interfere in the defect recognition stage, this paper proposes a sliding window filter for the texture detection. Experiments compare the proposed method with the polar coordinate mapping method and the T-smooth texture removal algorithm. Results show that the proposed method reveals the three types of defects better than the other two methods.},
booktitle = {Intelligent Robotics and Applications: 12th International Conference, ICIRA 2019, Shenyang, China, August 8–11, 2019, Proceedings, Part IV},
pages = {576–584},
numpages = {9},
keywords = {Defect detection, Non-concentric circle, Small dataset},
location = {Shenyang, China}
}

@inproceedings{10.1145/2961111.2962610,
author = {Petri\'{c}, Jean and Bowes, David and Hall, Tracy and Christianson, Bruce and Baddoo, Nathan},
title = {Building an Ensemble for Software Defect Prediction Based on Diversity Selection},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962610},
doi = {10.1145/2961111.2962610},
abstract = {Background: Ensemble techniques have gained attention in various scientific fields. Defect prediction researchers have investigated many state-of-the-art ensemble models and concluded that in many cases these outperform standard single classifier techniques. Almost all previous work using ensemble techniques in defect prediction rely on the majority voting scheme for combining prediction outputs, and on the implicit diversity among single classifiers. Aim: Investigate whether defect prediction can be improved using an explicit diversity technique with stacking ensemble, given the fact that different classifiers identify different sets of defects. Method: We used classifiers from four different families and the weighted accuracy diversity (WAD) technique to exploit diversity amongst classifiers. To combine individual predictions, we used the stacking ensemble technique. We used state-of-the-art knowledge in software defect prediction to build our ensemble models, and tested their prediction abilities against 8 publicly available data sets. Conclusion: The results show performance improvement using stacking ensembles compared to other defect prediction models. Diversity amongst classifiers used for building ensembles is essential to achieving these performance improvements.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {46},
numpages = {10},
keywords = {Software defect prediction, diversity, ensembles of learning machines, software faults, stacking},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@inproceedings{10.1145/3318299.3318341,
author = {Lin, Zhongkang and Guo, Zhiqiang and Yang, Jie},
title = {Research on Texture Defect Detection Based on Faster-RCNN and Feature Fusion},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318341},
doi = {10.1145/3318299.3318341},
abstract = {Product texture defect detection is one of the important quality inspection procedures in industrial production. For the traditional defect detection methods, the detection processes are cumbersome, the accuracies are not high, and the generalizations are not strong. This paper proposes a method based on Faster-RCNN and feature fusion. This method uses the ResNet network model to extract the shared convolution feature, and combines the high-level features of the ROI pooling layer output with the low-level features obtained by the direction gradient histogram (HOG) as full connection layer input. Then, optimizing the model by adjusting the training parameters and convolutional neural network structure. Experiments on the German Pattern Recognition Association (GAPR) texture defect dataset show that the proposed model has improved in the mAP index. Through the migration learning strategy, experiments are carried out on several sets of actually collected data sets. The experimental results show that the model has good adaptability and can be applied to the surface defect detection of workpieces under different conditions.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {429–433},
numpages = {5},
keywords = {defect detection, faster-RCNN, feature fusion, target location},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@article{10.1109/TVLSI.2021.3082476,
author = {Erozan, Ahmet Turan and Bosse, Simon and Tahoori, Mehdi B.},
title = {Defect Detection in Transparent Printed Electronics Using Learning-Based Optical Inspection},
year = {2021},
issue_date = {Aug. 2021},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {29},
number = {8},
issn = {1063-8210},
url = {https://doi.org/10.1109/TVLSI.2021.3082476},
doi = {10.1109/TVLSI.2021.3082476},
abstract = {Printed electronics (PE) is an emerging technology that provides attractive and complementary features compared to traditional wafer-scale silicon fabrication, such as flexible substrate and point-of-use ultralow-cost manufacturing. The low-cost manufacturing and larger feature sizes mandate reduced complexity in circuit size and also limited and transparent printing layers. This enables optical inspection for manufacturing defect detection, eliminating the need for electrical testing for gross defect detection. Therefore, the traditional problem of controllability and observability in logic testing can completely be alleviated. In this article, we present a learning-based method for optical inspection to detect defective transistors in transparent PE. The method leverages domain-specific as well as common inspection features extracted from optical images to detect defective transistors using supervised learning algorithms trained with real fabricated transistor images. The results show that the proposed method detects 95% of the defective transistors, which can significantly reduce the cost of the overall test flow.},
journal = {IEEE Trans. Very Large Scale Integr. Syst.},
month = aug,
pages = {1505–1517},
numpages = {13}
}

@article{10.1016/j.eswa.2021.114820,
author = {Bertolini, Massimo and Mezzogori, Davide and Neroni, Mattia and Zammori, Francesco},
title = {Machine Learning for industrial applications: A comprehensive literature review},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {175},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114820},
doi = {10.1016/j.eswa.2021.114820},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {29},
keywords = {Literature review, Industrial applications, Deep Learning, Machine Learning, Operation management}
}

@inproceedings{10.1145/3377024.3380451,
author = {Bencomo, Nelly},
title = {Next steps in variability management due to autonomous behaviour and runtime learning},
year = {2020},
isbn = {9781450375016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377024.3380451},
doi = {10.1145/3377024.3380451},
abstract = {One of the basic principles in product lines is to delay design decisions related to offered functionality and quality to later phases of the life cycle [25]. Instead of deciding on what system to develop in advance, a set of assets and a common reference architecture are specified and implemented during the Domain Engineering process. Later on, during Application Engineering, specific systems are developed to satisfy the requirements reusing the assets and architecture [16]. Traditionally, this is during the Application Engineering when delayed design decisions are solved. The realization of this delay relies heavily on the use of variability in the development of product lines and systems. However, as systems become more interconnected and diverse, software architects cannot easily foresee the software variants and the interconnections between components. Consequently, a generic a priori model is conceived to specify the system's dynamic behaviour and architecture. The corresponding design decisions are left to be solved at runtime [13].Surprisingly, few research initiatives have investigated variability models at runtime [9]. Further, they have been applied only at the level of goals and architecture, which contrasts to the needs claimed by the variability community, i.e., Software Product Lines (SPLC) and Dynamic Software Product Lines (DSPL) [2, 10, 14, 22]. Especially, the vision of DSPL with their ability to support runtime updates with virtually zero downtime for products of a software product line, denotes the obvious need of variability models being used at runtime to adapt the corresponding programs. A main challenge for dealing with runtime variability is that it should support a wide range of product customizations under various scenarios that might be unknown until the execution time, as new product variants can be identified only at runtime [10, 11]. Contemporary variability models face the challenge of representing runtime variability to therefore allow the modification of variation points during the system's execution, and underpin the automation of the system's reconfiguration [15]. The runtime representation of feature models (i.e. the runtime model of features) is required to automate the decision making [9].Software automation and adaptation techniques have traditionally required a priori models for the dynamic behaviour of systems [17]. With the uncertainty present in the scenarios involved, the a priori model is difficult to define [20, 23, 26]. Even if foreseen, its maintenance is labour-intensive and, due to architecture decay, it is also prone to get out-of-date. However, the use of models@runtime does not necessarily require defining the system's behaviour model beforehand. Instead, different techniques such as machine learning, or mining software component interactions from system execution traces can be used to build a model which is in turn used to analyze, plan, and execute adaptations [18], and synthesize emergent software on the fly [7].Another well-known problem posed by the uncertainty that characterize autonomous systems is that different stakeholders (e.g. end users, operators and even developers) may not understand them due to the emergent behaviour. In other words, the running system may surprise its customers and/or developers [4]. The lack of support for explanation in these cases may compromise the trust to stakeholders, who may eventually stop using a system [12, 24]. I speculate that variability models can offer great support for (i) explanation to understand the diversity of the causes and triggers of decisions during execution and their corresponding effects using traceability [5], and (ii) better understand the behaviour of the system and its environment.Further, an extension and potentially reframing of the techniques associated with variability management may be needed to help taming uncertainty and support explanation and understanding of the systems. The use of new techniques such as machine learning exacerbates the current situation. However, at the same time machine learning techniques can also help and be used, for example, to explore the variability space [1]. What can the community do to face the challenges associated?We need to meaningfully incorporate techniques from areas such as artificial intelligence, machine learning, optimization, planning, decision theory, and bio-inspired computing into our variability management techniques to provide explanation and management of the diversity of decisions, their causes and the effects associated. My own previous work has progressed [3, 5, 6, 8, 11, 12, 19, 21] to reflect what was discussed above.},
booktitle = {Proceedings of the 14th International Working Conference on Variability Modelling of Software-Intensive Systems},
articleno = {2},
numpages = {2},
keywords = {autonomous systems, dynamic software product lines, dynamic variability, machine learning, uncertainty, variability management},
location = {Magdeburg, Germany},
series = {VaMoS '20}
}

@article{10.1016/j.jss.2019.110402,
author = {Xu, Zhou and Li, Shuai and Xu, Jun and Liu, Jin and Luo, Xiapu and Zhang, Yifeng and Zhang, Tao and Keung, Jacky and Tang, Yutian},
title = {LDFR: Learning deep feature representation for software defect prediction},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {158},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110402},
doi = {10.1016/j.jss.2019.110402},
journal = {J. Syst. Softw.},
month = dec,
numpages = {20},
keywords = {Software defect prediction, Deep feature representation, Triplet loss, Weighted cross-entropy loss, Deep neural network, 00-01, 99-00}
}

@phdthesis{10.5555/AAI28498637,
author = {Khalil, Kasem Mohamed Ahmed and Ashok, Kumar, and Mohammad, Madani, and Michael, Totaro,},
advisor = {A, Bayoumi, Magdy},
title = {Fault Prediction and Self-Healing Paradigm for Intelligent Hardware Systems},
year = {2021},
isbn = {9798522907303},
publisher = {University of Louisiana at Lafayette},
abstract = {As the complexity of hardware systems grows, the failure rate, or the rate at which such systems produce faults, accelerates. Ideally, future hardware should heal faults before the faults can occur and impact a system adversely. Fault prediction is needed to identify a fault before it occurs, and this helps to heal the fault early to avoid losing data or missing some operation. Such systems, also referred to as intelligent hardware systems, are expected to revolutionize the way circuits and systems are designed, and it is the focus of this dissertation. An intelligent hardware system is expected to have mechanisms for self-healing and fault prediction. A novel mechanism for self-healing methods for Embryonic Hardware (EmHW), Network-on-Chip (NoC), and neural network is proposed. The proposed self-healing method is implemented in VHDL on Altera Arria 10 GX FPGA device. The area overhead of the proposed self-healing method for EmHW and NoC is 34% and 31%, respectively, with high reliability and the mean-time-to-failure that prove extended network age. The hardware fault prediction requires low-cost machine learning techniques. A hardware neural network optimization and reconfiguration is proposed for artificial neural networks, Long Short-Term Memory (LSTM), and Convolutional Neural Network (CNN). An Economic LSTM (ELSTM) is proposed, which saves 34% of the area and 35% of the power consumption compared to LSTM. Next, a novel Absolute Average Deviation (ADD) pooling method with very high accuracy for CNN is also. The AAD pooling achieves an accuracy of more than 98%. and has a modest 4%. It is synthesized using Synopsis in 45 nm technology and found to occupy an area of 244.466 nm2, and consume 0.31 mW of power. Two fault prediction methods are presented, and they are based on the proposed machine learning optimization methods. The proposed fault prediction methods are used for early transistor and architectural fault prediction for NoC and EmHW, using fast Fourier transform, Principal Component Analysis (PCA), Relative PCA (RPCA), ELSTM, and CNN. The proposed approaches are implemented using Tensorflow and FPGA device, and the result shows the proposed approach could predict a fault with the accuracy of more than 98%.},
note = {AAI28498637}
}

@article{10.1016/j.knosys.2015.10.009,
author = {Rana, Zeeshan Ali and Mian, M. Awais and Shamail, Shafay},
title = {Improving Recall of software defect prediction models using association mining},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {90},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.10.009},
doi = {10.1016/j.knosys.2015.10.009},
abstract = {Use of software product metrics in defect prediction studies highlights the utility of these metrics. Public availability of software defect data based on the product metrics has resulted in the development of defect prediction models. These models experience a limitation in learning Defect-prone (D) modules because the available datasets are imbalanced. Most of the datasets are dominated by Not Defect-prone (ND) modules as compared to D modules. This affects the ability of classification models to learn the D modules more accurately. This paper presents an association mining based approach that allows the defect prediction models to learn D modules in imbalanced datasets. The proposed algorithm preprocesses data by setting specific metric values as missing and improves the prediction of D modules. The proposed algorithm has been evaluated using 5 public datasets. A Naive Bayes (NB) classifier has been developed before and after the proposed preprocessing. It has been shown that Recall of the classifier after the proposed preprocessing has improved. Stability of the approach has been tested by experimenting the algorithm with different number of bins. The results show that the algorithm has resulted in up to 40% performance gain.},
journal = {Know.-Based Syst.},
month = dec,
pages = {1–13},
numpages = {13},
keywords = {Association mining, Imbalanced data, Improving Recall, Naive Bayes, PROMISE repository, Software defect prediction}
}

@article{10.5555/3324436.3324448,
title = {A statistical comparison for evaluating the effectiveness of linear and nonlinear manifold detection techniques for software defect prediction},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {3–4},
issn = {1755-0386},
abstract = {Most of the software systems are released without predicting defects and therefore, this paper presents a new effective technique-manifold detection technique MDT is essential and different than earlier applied defect prediction methods like regression, feature selection methods, etc. In this paper, performance of classifiers has been compared with or without MDTs to evaluate the effectiveness of different MDTs linear and nonlinear by reducing the dimensions of software datasets. In this process, eight classifiers were applied to four PROMISE datasets to determine the best performing classifier with respect to prediction performance measuring factors accuracy, precision, recall, F-measure, AUC, misclassification error with or without MDTs. The experimental results statistically tested by paired two-tailed t-test proved that FastMVU is the most accurate result producing technique as compared to all other nonlinear MDTs and Bayesian network BN is the most effective technique for software defect prediction using with or without MDTs.},
journal = {Int. J. Adv. Intell. Paradigms},
month = jan,
pages = {370–391},
numpages = {22}
}

@phdthesis{10.5555/AAI28962495,
author = {Shen, Mingren and Izabela, Szlufarska, and K., Chan, Maria and Victor, Zavala, and Paul, Evans,},
advisor = {Dane, Morgan,},
title = {Machine Learning Applications in Material Science Problems},
year = {2021},
isbn = {9798762108003},
publisher = {The University of Wisconsin - Madison},
abstract = {Machine learning tools have the potential to provide a new solution for problems in material science community. In this thesis, I will present my works about applying machine learning methods to solve two typical material sciences problems, one is the defect detection problem and another one is the X-ray image pattern problem. Chapter 1 is an introduction of the thesis that states the goal of this thesis and key concepts learned in my Ph.D. study. Chapter 2 talks about the important background knowledge about machine learning, deep learning, and computer vision which are frequently used later. In Chapter 3, three deep learning based defect analysis systems are discussed for TEM/STEM images or videos. Those models prove the ability of deep learning models and show the potential of applying them to solve defect detection problems. In Chapter 4, we introduce a deep learning based classifier that can assist the interpretation of X-ray image patterns which paves the way to better understand the patterns. Chapter 5 summarize other published work I completed at UW-Madison which were not closely related to material science but shared the general theme of this thesis. Finally, in Chapter 6, a summary and future of work is present.},
note = {AAI28962495}
}

@inproceedings{10.1007/978-3-030-31726-3_31,
author = {Cheng, Long and Gong, Ping and Qiu, Guanghui and Wang, Jing and Liu, Ziyuan},
title = {Small Defect Detection in Industrial X-Ray Using Convolutional Neural Network},
year = {2019},
isbn = {978-3-030-31725-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31726-3_31},
doi = {10.1007/978-3-030-31726-3_31},
abstract = {It’s crucial to ensure the complete reliability of each metallic component in vehicle industry. In the past few years, X-ray testing has been widely adopted in defect detection field. Due to huge production in industry, it’s absolutely necessary for manufacturers to employ more intelligent and automated inspection scheme to detect defects efficiently. This study develops an accurate and fast detection method combined with X-ray images using computer vision and deep learning techniques to recognize small defects, mark theirs’ area and divide them into different levels according to their sizes. This program modifies the original RetinaNet to adapt to tiny defects. We present a novel data augmentation method aiming to expand the number of defects. Then a multi-scale transform module is designed to generate scale-specific feature map which helps to grade defects better. Experiments show that the proposed method can achieve significant precision improvement over X-ray machine with similarly high recall rate. Both speed and accuracy of this scheme reach practical industrial-service demand.},
booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part III},
pages = {366–377},
numpages = {12},
keywords = {Defect detection, X-ray, Dilated convolution, CNN},
location = {Xi'an, China}
}

@article{10.3233/KES-200029,
author = {Singh, Pradeep and Verma, Shrish},
title = {ACO based comprehensive model for software fault prediction},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {24},
number = {1},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-200029},
doi = {10.3233/KES-200029},
abstract = {The comprehensive models can be used for software quality modelling which involves prediction of low-quality modules using interpretable rules. Such comprehensive model can guide the design and testing team to focus on the poor quality modules, thereby, limited resources allocated for software quality inspection can be targeted only towards modules that are likely to be defective. Ant Colony Optimization (ACO) based learner is one potential way to obtain rules that can classify the software modules faulty and not faulty. This paper investigates ACO based mining approach with ROC based rule quality updation to constructs a rule-based software fault prediction model with useful metrics. We have also investigated the effect of feature selection on ACO based and other benchmark algorithms. We tested the proposed method on several publicly available software fault data sets. We compared the performance of ACO based learning with the results of three benchmark classifiers on the basis of area under the receiver operating characteristic curve. The evaluation of performance measure proves that the ACO based learner outperforms other benchmark techniques.},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {63–71},
numpages = {9},
keywords = {Software metric, fault prediction, ACO}
}

@inproceedings{10.1007/978-3-030-59722-1_72,
author = {Ding, Fei and Yang, Gang and Ding, Dayong and Cheng, Gangwei},
title = {Retinal Nerve Fiber Layer Defect Detection with Position Guidance},
year = {2020},
isbn = {978-3-030-59721-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59722-1_72},
doi = {10.1007/978-3-030-59722-1_72},
abstract = {The retinal nerve fiber layer defect (RNFLD) provides early diagnostic evidence for many irreversible disabling or blinding diseases. This paper aims for automated RNFLD detection based on fundus images. Different from previous works that only consider the local contexts, we are the first to propose to detect RNFLD with position guidance, which senses both the physiological position and global dependencies with ease. Our solution consists of a position-consistent data preprocessing, a Position Guided Network, and a weakly supervised learning strategy. In the position-consistent data preprocessing, the optic disc region is evenly divided into several sectors according to the distribution regularity of RNFL. To detect RNFLD in sectors, the proposed Position Guided Network highlights the significant region with a position-aware attention module and captures the global dependencies with a bidirectional GRU module. The dataset about RNFLD suffers from noise labels, which is verified in our created dataset containing 4,335 fundus images. Thus the weakly supervised learning strategy, which jointly optimizes network parameters and label distributions, is proposed to reduce the impact of noise labels. Tested on a clinical dataset of 750 images, our solution achieves outstanding performance, attaining the F1 score of 81.00% that outperforms the baseline by 13.71%.},
booktitle = {Medical Image Computing and Computer Assisted Intervention – MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part V},
pages = {745–754},
numpages = {10},
keywords = {RNFLD, Fundus image, Cnn, Position, Dependency},
location = {Lima, Peru}
}

@article{10.1007/s10489-021-02346-x,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {Software fault prediction based on the dynamic selection of learning technique: findings from the eclipse project study},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {12},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-021-02346-x},
doi = {10.1007/s10489-021-02346-x},
abstract = {An effective software fault prediction (SFP) model could help developers in the quick and prompt detection of faults and thus help enhance the overall reliability and quality of the software project. Variations in the prediction performance of learning techniques for different software systems make it difficult to select a suitable learning technique for fault prediction modeling. The evaluation of previously presented SFP approaches has shown that single machine learning-based models failed to provide the best accuracy in any context, highlighting the need to use multiple techniques to build the SFP model. To solve this problem, we present and discuss a software fault prediction approach based on selecting the most appropriate learning techniques from a set of competitive and accurate learning techniques for building a fault prediction model. In work, we apply the discussed SFP approach for the five Eclipse project datasets and nine Object-oriented (OO) project datasets and report the findings of the experimental study. We have used different performance measures, i.e., AUC, accuracy, sensitivity, and specificity, to assess the discussed approach’s performance. Further, we have performed a cost-benefit analysis to evaluate the economic viability of the approach. Results showed that the presented approach predicted the software’s faults effectively for the used accuracy, AUC, sensitivity, and specificity measures with the highest achieved values of 0.816, 0.835, 0.98, and 0.903 for AUC, accuracy, sensitivity, and specificity, respectively. The cost-benefit analysis of the approach showed that it could help reduce the overall software testing cost.},
journal = {Applied Intelligence},
month = dec,
pages = {8945–8960},
numpages = {16},
keywords = {Software fault prediction, Eclipse project, Dynamic selection, Cost-benefit analysis, Machine learning techniques}
}

@article{10.1016/j.jss.2016.09.001,
author = {Andreou, Andreas S. and Chatzis, Sotirios P.},
title = {Software defect prediction using doubly stochastic Poisson processes driven by stochastic belief networks},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.09.001},
doi = {10.1016/j.jss.2016.09.001},
abstract = {This research aims at better addressing the challenges related with software defect prediction.We develop a novel Bayesian inference approach driven from appropriate metrics.Formulation of our method is based on a doubly stochastic homogeneous Poisson process.Our model better learns from data with multiple modes in their distributions.We evaluate generalization across software classes, subsequent releases, and projects. Accurate prediction of software defects is of crucial importance in software engineering. Software defect prediction comprises two major procedures: (i) Design of appropriate software metrics to represent characteristic software system properties; and (ii) development of effective regression models for count data, allowing for accurate prediction of the number of software defects. Although significant research effort has been devoted to software metrics design, research in count data regression has been rather limited. More specifically, most used methods have not been explicitly designed to tackle the problem of metrics-driven software defect counts prediction, thus postulating irrelevant assumptions, such as (log-)linearity of the modeled data. In addition, a lack of simple and efficient algorithms for posterior computation has made more elaborate hierarchical Bayesian approaches appear unattractive in the context of software defect prediction. To address these issues, in this paper we introduce a doubly stochastic Poisson process for count data regression, the failure log-rate of which is driven by a novel latent space stochastic feedforward neural network. Our approach yields simple and efficient updates for its complicated conditional distributions by means of sampling importance resampling and error backpropagation. We exhibit the efficacy of our approach using publicly available and benchmark datasets.},
journal = {J. Syst. Softw.},
month = dec,
pages = {72–82},
numpages = {11},
keywords = {Doubly stochastic Poisson process, Sampling importance resampling, Software defect prediction, Stochastic belief network}
}

@article{10.1155/2021/5990020,
author = {Chen, Xieyi and Wang, Dongyun and Shao, Jinjun and Fan, Jun and Pan, Zhaoqing},
title = {Plastic Gasket Defect Detection Based on Transfer Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/5990020},
doi = {10.1155/2021/5990020},
abstract = {To automatically detect plastic gasket defects, a set of plastic gasket defect visual detection devices based on GoogLeNet Inception-V2 transfer learning was designed and established in this study. The GoogLeNet Inception-V2 deep convolutional neural network (DCNN) was adopted to extract and classify the defect features of plastic gaskets to solve the problem of their numerous surface defects and difficulty in extracting and classifying the features. Deep learning applications require a large amount of training data to avoid model overfitting, but there are few datasets of plastic gasket defects. To address this issue, data augmentation was applied to our dataset. Finally, the performance of the three convolutional neural networks was comprehensively compared. The results showed that the GoogLeNet Inception-V2 transfer learning model had a better performance in less time. It means it had higher accuracy, reliability, and efficiency on the dataset used in this paper.},
journal = {Sci. Program.},
month = jan,
numpages = {11}
}

@inproceedings{10.1109/COASE.2019.8842998,
author = {Zhang, Haodong and Chen, Zuzhi and Zhang, Chaoqun and Xi, Juntong and Le, Xinyi},
title = {Weld Defect Detection Based on Deep Learning Method},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8842998},
doi = {10.1109/COASE.2019.8842998},
abstract = {Welding is an important joining technology but the defects in welds wreck the quality of the product evidently. Due to the variety of weld defects’ characteristics, weld defect detection is a complex task in industry. In this paper, we try to explore a possible solution for weld defect detection and a novel image-based approach is proposed using small X-ray image data sets. An image-processing based data augmentation approach and a WGAN based data augmentation approach are applied to deal with imbalanced image sets. Then we train two deep convolutional neural networks (CNNs) on the augmented image sets using feature-extraction based transfer learning techniques. The two trained CNNs are combined to classify defects through a multi-model ensemble framework, aiming at lower false detection rate. Both of the experiments on augmented images and real world defect images achieve satisfying accuracy, which substantiates the possibility that the proposed approach is promising for weld defect detection.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {1574–1579},
numpages = {6},
location = {Vancouver, BC, Canada}
}

@article{10.1016/j.aei.2019.100933,
author = {Mujeeb, Abdul and Dai, Wenting and Erdt, Marius and Sourin, Alexei},
title = {One class based feature learning approach for defect detection using deep autoencoders},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {42},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2019.100933},
doi = {10.1016/j.aei.2019.100933},
journal = {Adv. Eng. Inform.},
month = oct,
numpages = {9},
keywords = {Automatic Optical Inspection, Deep learning, Unsupervised learning, One Class Classification, Autoencoders}
}

@article{10.1016/j.patcog.2019.107057,
author = {Yan, Yaping and Kaneko, Shun’ichi and Asano, Hirokazu},
title = {Accumulated and aggregated shifting of intensity for defect detection on micro 3D textured surfaces},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {98},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2019.107057},
doi = {10.1016/j.patcog.2019.107057},
journal = {Pattern Recogn.},
month = feb,
numpages = {11},
keywords = {Defect detection, Accumulated and aggregated shifting of intensity (AASI) procedure, Saliency description, Illumination invariance}
}

@article{10.1007/s11277-018-5390-5,
author = {Hu, Kun and Zhang, Shuyou and Zhao, Xinyue},
title = {An Energy-Minimizing Level Set Method for Defect Detection},
year = {2018},
issue_date = {Oct 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {4},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-018-5390-5},
doi = {10.1007/s11277-018-5390-5},
abstract = {This paper proposes an energy-minimizing level set method for defect detection in product surface, which consists of image segmentation module, image feature extraction module and product defect detection module. This new method, embedding energy function into the classic level set algorithm, segments internal and external areas of product image with minimized energy consumption, ensuring that the gradient of the level set function is in the direction of the minimum point so that the evolution process is closer to the zero level set. 15-dimentional features including zero-crossing rate and image entropy are used in the process of contour detection. Results show that the method is highly accurate and effective.},
journal = {Wirel. Pers. Commun.},
month = oct,
pages = {3545–3555},
numpages = {11},
keywords = {Defect detection, Energy minimization, Image encryption, Level set}
}

@article{10.1016/j.eswa.2021.115673,
author = {Zhang, Huan and Jiang, Liangxiao and Li, Chaoqun},
title = {CS-ResNet: Cost-sensitive residual convolutional neural network for PCB cosmetic defect detection},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {185},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115673},
doi = {10.1016/j.eswa.2021.115673},
journal = {Expert Syst. Appl.},
month = dec,
numpages = {10},
keywords = {PCB cosmetic defect detection, Residual convolutional neural network, Class imbalance, Cost-sensitive learning}
}

@article{10.1016/j.infsof.2011.09.007,
author = {Ma, Ying and Luo, Guangchun and Zeng, Xue and Chen, Aiguo},
title = {Transfer learning for cross-company software defect prediction},
year = {2012},
issue_date = {March, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2011.09.007},
doi = {10.1016/j.infsof.2011.09.007},
abstract = {Context: Software defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction? Objective: In this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model. Method: Unlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built. Results: This article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods. Conclusion: It is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {248–256},
numpages = {9},
keywords = {Different distribution, Machine learning, Naive Bayes, Software defect prediction, Transfer learning}
}

@inproceedings{10.1007/978-3-031-21517-9_10,
author = {Kunal, Kishore and Upadhyay, Pawan Kumar and Ramasubramaniam, M. and Xavier, M. J.},
title = {Mura Defect Detection in&nbsp;Flat Panel Display Using B-Spline Approximation},
year = {2021},
isbn = {978-3-031-21516-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-21517-9_10},
doi = {10.1007/978-3-031-21517-9_10},
abstract = {Flat panel display (FDP) devices continue to grow at rapid rate and quite popular as a promising technology and evolve various investment opportunity. In this paper, a machine vision approach has been proposed for automatic inspection of mura defects in film or glass of flat panel display device. The proposed method is based on a Mura filter using B-spline global approximation method. Experimental result shows that the detection of mura defect has been performed on images data with high speed computational techniques and obtained robust results.},
booktitle = {Mining Intelligence and Knowledge Exploration: 9th International Conference, MIKE 2021, Hammamet, Tunisia, November 1–3, 2021, Proceedings},
pages = {102–108},
numpages = {7},
keywords = {B-spline, Machine learning, Machine vision, Flat panel display},
location = {Hammamet, Tunisia}
}

@inproceedings{10.1145/3448734.3450927,
author = {Zang, Yangyang and Zhang, Jing and Billah, Mohammad Masum},
title = {Defect detection of flexible circuit board based on convolutional neural network},
year = {2021},
isbn = {9781450389570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448734.3450927},
doi = {10.1145/3448734.3450927},
abstract = {Flexible printed circuit (FPCs) is one of the important links in the manufacture of electronic products. A minor flaw in the FPC can lead to a major flaw in the final product. Therefore, it is critical to detect and locate all defects on a FPC. Although great progress has been made in FPC defect detection, traditional detection methods are still difficult to deal with complex and diverse FPC. Therefore, this paper designs a depth model that can accurately detect FPC defects from non-detection templates and defect detection image input pairs. This method uses the multi-scale pyramid hierarchy structure inherent in deep neural network (DNN) to construct multi-scale characteristics. First of all, k-means clustering is used to design reasonable anchor points. Then, the network strengthens the relationship between the feature mapping at different levels and the advantages of the underlying structure information and is suitable for the detection of minor defects. The experimental results show that the accuracy of defect detection is improved effectively.},
booktitle = {The 2nd International Conference on Computing and Data Science},
articleno = {197},
numpages = {5},
keywords = {DNN, Deep Learning, Multiscale fusion, convolutional Neural Networks},
location = {Stanford, CA, USA},
series = {CONF-CDS 2021}
}

@inproceedings{10.1145/3373509.3373550,
author = {Liu, Zhoufeng and Cui, Jian and Li, Chunlei and Ding, Shumin and Xu, Qingwei},
title = {Real-time Fabric Defect Detection based on Lightweight Convolutional Neural Network},
year = {2020},
isbn = {9781450376570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373509.3373550},
doi = {10.1145/3373509.3373550},
abstract = {Fabric defect detection is an important link for quality control in a textile factory. Deep convolutional neural network (CNN) has made great progress in the field of target detection, and has proven applicable in fabric defect detection. However, the improvement of detection performance of CNN network mainly depends on complex network structure. This comes the drawbacks of significant increase in computational costs and storage services, which seriously hinders the usages of CNN on resource-limited environments, such as smart industrial cameras and other embedded devices. In this paper, a lightweight CNN model is designed for fabric defect detection, and denoted as DefectNet. It is based on a streamlined architecture that uses depthwise separable convolutions instead of standard convolutions to build a lightweight neural network architecture, and significantly reduce the computational complexity of the model. The multi-scale feature extraction method is used to improve the detection ability of the model for fabric defects of various sizes. Experimental results demonstrate that the proposed scheme has higher detection accuracy and faster detection speed on the basis of fewer network parameters, which can provide real-time fabric defects detection on the embedded devices.},
booktitle = {Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition},
pages = {122–127},
numpages = {6},
keywords = {Deep learning, depthwise separable convolution, fabric defect detection, lightweight},
location = {Beijing, China},
series = {ICCPR '19}
}

@inproceedings{10.1007/978-3-031-12700-7_57,
author = {Hassan, Neelofar and Chattopadhyay, Chiranjoy},
title = {Towards Automatic Defect Detection in&nbsp;Sugarcane Billets from&nbsp;Images},
year = {2021},
isbn = {978-3-031-12699-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-12700-7_57},
doi = {10.1007/978-3-031-12700-7_57},
abstract = {Sugarcane billets are shorter segments of cane harvested and used globally for plantations. Due to such a mechanical approach, billets are often damaged and directly impact crop yield. Hence, automatic identification of sugarcane billet quality is a fundamental problem in the context of intelligent farming. Many familiar convolutional neural network (CNN) architectures are used for image classification tasks in the literature. This paper proposes an improved deep neural network architecture, SBDNet (Sugarcane Billet Diagnosis Network), that takes an image of the sugarcane billet as input and labels it healthy or damaged. We have conducted experiments on three different sugarcane billet varieties and obtained an overall accuracy of 73.81%. We have compared our work with recently published works on the same domain and got a 3% overall performance accuracy gain. The proposed SBDNet also shows impressive outcomes relating to the number of parameters and computational cost compared to other state-of-the-art models.},
booktitle = {Pattern Recognition and Machine Intelligence: 9th International Conference, PReMI 2021, Kolkata, India, December 15–18, 2021, Proceedings},
pages = {559–567},
numpages = {9},
keywords = {Convolutional neural networks (CNNs), Sugarcane billets, smart farming, computer vision},
location = {Kolkata, India}
}

@inproceedings{10.1109/ICMLA.2012.226,
author = {Hall, Tracy and Bowes, David},
title = {The State of Machine Learning Methodology in Software Fault Prediction},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.226},
doi = {10.1109/ICMLA.2012.226},
abstract = {The aim of this paper is to investigate the quality of methodology in software fault prediction studies using machine learning. Over two hundred studies of fault prediction have been published in the last 10 years. There is evidence to suggest that the quality of methodology used in some of these studies does not allow us to have confidence in the predictions reported by them. We evaluate the machine learning methodology used in 21 fault prediction studies. All of these studies use NASA data sets. We score each study from 1 to 10 in terms of the quality of their machine learning methodology (e.g. whether or not studies report randomising their cross validation folds). Only 10 out of the 21 studies scored 5 or more out of 10. Furthermore 1 study scored only 1 out of 10. When we plot these scores over time there is no evidence that the quality of machine learning methodology is better in recent studies. Our results suggest that there remains much to be done by both researchers and reviewers to improve the quality of machine learning methodology used in software fault prediction. We conclude that the results reported in some studies need to be treated with caution.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 02},
pages = {308–313},
numpages = {6},
keywords = {experimental techniques, fault prediction, machine learning, methodology, software engineering},
series = {ICMLA '12}
}

@inproceedings{10.1145/3220267.3220286,
author = {El-Shorbagy, Sara Adel and El-Gammal, Wael Mohamed and Abdelmoez, Walid M.},
title = {Using SMOTE and Heterogeneous Stacking in Ensemble learning for Software Defect Prediction},
year = {2018},
isbn = {9781450364690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220267.3220286},
doi = {10.1145/3220267.3220286},
abstract = {Nowadays, there are a lot of classifications models used for predictions in the software engineering field such as effort estimation and defect prediction. One of these models is the ensemble learning machine that improves model performance by combining multiple models in different ways to get a more powerful model.One of the problems facing the prediction model is the misclassification of the minority samples. This problem mainly appears in the case of defect prediction. Our aim is the classification of defects which are considered minority samples during the training phase. This can be improved by implementing the Synthetic Minority Over-Sampling Technique (SMOTE) before the implementation of the ensemble model which leads to over-sample the minority class instances.In this paper, our work propose applying a new ensemble model by combining the SMOTE technique with the heterogeneous stacking ensemble to get the most benefit and performance in training a dataset that focus on the minority subset as in the software prediction study. Our proposed model shows better performance that overcomes other techniques results applied on the minority samples of the defect prediction.},
booktitle = {Proceedings of the 7th International Conference on Software and Information Engineering},
pages = {44–47},
numpages = {4},
keywords = {Classification, Defect Prediction, Ensemble, Heterogeneous, Machine Learning, SMOTE, Software Engineering, Stacking},
location = {Cairo, Egypt},
series = {ICSIE '18}
}

@article{10.1016/j.asoc.2014.11.023,
author = {Malhotra, Ruchika},
title = {A systematic review of machine learning techniques for software fault prediction},
year = {2015},
issue_date = {February 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {27},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2014.11.023},
doi = {10.1016/j.asoc.2014.11.023},
abstract = {Reviews studies from 1991-2013 to assess application of ML techniques for SFP.Identifies seven categories of the ML techniques.Identifies 64 studies to answer the established research questions.Selects primary studies according to the quality assessment of the studies.Systematic literature review performs the following:Summarize ML techniques for SFP models.Assess performance accuracy and capability of ML techniques for constructing SFP models.Provide comparison between the ML and statistical techniques.Provide comparison of performance accuracy of different ML techniques.Summarize the strength and weakness of the ML techniques.Provides future guidelines to software practitioners and researchers. BackgroundSoftware fault prediction is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. There are various machine learning techniques used in the past for predicting faults. MethodIn this study we perform a systematic review of studies from January 1991 to October 2013 in the literature that use the machine learning techniques for software fault prediction. We assess the performance capability of the machine learning techniques in existing research for software fault prediction. We also compare the performance of the machine learning techniques with the statistical techniques and other machine learning techniques. Further the strengths and weaknesses of machine learning techniques are summarized. ResultsIn this paper we have identified 64 primary studies and seven categories of the machine learning techniques. The results prove the prediction capability of the machine learning techniques for classifying module/class as fault prone or not fault prone. The models using the machine learning techniques for estimating software fault proneness outperform the traditional statistical models. ConclusionBased on the results obtained from the systematic review, we conclude that the machine learning techniques have the ability for predicting software fault proneness and can be used by software practitioners and researchers. However, the application of the machine learning techniques in software fault prediction is still limited and more number of studies should be carried out in order to obtain well formed and generalizable results. We provide future guidelines to practitioners and researchers based on the results obtained in this work.},
journal = {Appl. Soft Comput.},
month = feb,
pages = {504–518},
numpages = {15},
keywords = {Machine learning, Software fault proneness, Systematic literature review}
}

@article{10.1504/ijbidm.2021.115475,
author = {Manimozhi, I. and Janakiraman, S.},
title = {An efficient approach for defect detection in pattern texture analysis using an improved support vector machine},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {4},
issn = {1743-8195},
url = {https://doi.org/10.1504/ijbidm.2021.115475},
doi = {10.1504/ijbidm.2021.115475},
abstract = {Texture defect detection can be defined as the process of determining the location and size of the collection pixels in a textured image which deviate in their intensity values or spatial in compression to a background texture. The detection of abnormalities is a very challenging problem in computer vision. In our proposed method we have designed a method for detecting the defect of pattern texture analysis. Initially, features are extracted from the input image using the grey level co-occurrence matrix (GLCM) and grey level run-length matrix (GLRLM). Then the extracted features are fed to the input of classification stage. Here the classification is done by improved support vector machine (ISVM). The proposed pattern analysis showed that the traditional support vector machine is improved by means of kernel methods. In the final stage, the classified features are segmented using the modified fuzzy c means algorithm (MFCM).},
journal = {Int. J. Bus. Intell. Data Min.},
month = jan,
pages = {411–434},
numpages = {23},
keywords = {texture defect detection, preprocessing, grey level co-occurrence matrix, GLCM, grey level run-length matrix, GLRLM, improved support vector machine, ISVM, modified fuzzy c means, MFCM}
}

@inproceedings{10.1109/ISISE.2012.114,
author = {Wang, Pei and Jin, Cong and Jin, Shu-Wei},
title = {Software Defect Prediction Scheme Based on Feature Selection},
year = {2012},
isbn = {9780769549514},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISISE.2012.114},
doi = {10.1109/ISISE.2012.114},
abstract = {Predicting defect-prone software modules accurately and effectively are important ways to control the quality of a software system during software development. Feature selection can highly improve the accuracy and efficiency of the software defect prediction model. The main purpose of this paper is to discuss the best size of feature subset for building a prediction model and prove that feature selection method is useful for establishing software defect prediction model. Mutual information is an outstanding indicator of relevance between variables, and it has been used as a measurement in our feature selection algorithm. We also introduce a nonlinear factor to our evaluation function for feature selection to improve its performance. The results of our feature selection algorithm are validated by different machine learning methods. The experiment results show that all the classifiers achieve higher accuracy by using the feature subset provided by our algorithm.},
booktitle = {Proceedings of the 2012 Fourth International Symposium on Information Science and Engineering},
pages = {477–480},
numpages = {4},
keywords = {feature selection, mutual information, software defect prediction},
series = {ISISE '12}
}

@inproceedings{10.1145/2810146.2810150,
author = {Mahmood, Zaheed and Bowes, David and Lane, Peter C. R. and Hall, Tracy},
title = {What is the Impact of Imbalance on Software Defect Prediction Performance?},
year = {2015},
isbn = {9781450337151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810146.2810150},
doi = {10.1145/2810146.2810150},
abstract = {Software defect prediction performance varies over a large range. Menzies suggested there is a ceiling effect of 80% Recall [8]. Most of the data sets used are highly imbalanced. This paper asks, what is the empirical effect of using different datasets with varying levels of imbalance on predictive performance? We use data synthesised by a previous meta-analysis of 600 fault prediction models and their results. Four model evaluation measures (the Mathews Correlation Coefficient (MCC), F-Measure, Precision and Recall) are compared to the corresponding data imbalance ratio. When the data are imbalanced, the predictive performance of software defect prediction studies is low. As the data become more balanced, the predictive performance of prediction models increases, from an average MCC of 0.15, until the minority class makes up 20% of the instances in the dataset, where the MCC reaches an average value of about 0.34. As the proportion of the minority class increases above 20%, the predictive performance does not significantly increase. Using datasets with more than 20% of the instances being defective has not had a significant impact on the predictive performance when using MCC. We conclude that comparing the results of defect prediction studies should take into account the imbalance of the data.},
booktitle = {Proceedings of the 11th International Conference on Predictive Models and Data Analytics in Software Engineering},
articleno = {4},
numpages = {4},
keywords = {Data Imbalance, Defect Prediction, Machine Learning},
location = {Beijing, China},
series = {PROMISE '15}
}

@inproceedings{10.1109/COMPSAC.2014.65,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {A Semi-supervised Approach to Software Defect Prediction},
year = {2014},
isbn = {9781479935758},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2014.65},
doi = {10.1109/COMPSAC.2014.65},
abstract = {Accurate detection of software components that need to be exposed to additional verification and validation offers the path to high quality products while minimizing non essential software assurance expenditures. In this type of quality modeling we assume that software modules with known fault content developed in similar environment are available. Supervised learning algorithms are the traditional methods of choice for training on existing modules. The models are then used to predict fault content for newly developed software components prior to product release. However, one needs to realize that establishing whether a module contains a fault or not, only to be used for model training, can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available, thus reducing the overall cost of quality assurance. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics used for prediction. Our results show that the dimension-reduction with semi-supervised learning algorithm preforms significantly better than one of the best performing supervised learning algorithm - random forest - in situations when few modules with known fault content are available. We compare our results with the published benchmarks and clearly demonstrate performance benefits.},
booktitle = {Proceedings of the 2014 IEEE 38th Annual Computer Software and Applications Conference},
pages = {416–425},
numpages = {10},
keywords = {software fault prediction, semi-supervised learning, dimension reduction, software metrics},
series = {COMPSAC '14}
}

@inproceedings{10.1145/3383219.3383281,
author = {Khan, Bilal and Iqbal, Danish and Badshah, Sher},
title = {Cross-Project Software Fault Prediction Using Data Leveraging Technique to Improve Software Quality},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383281},
doi = {10.1145/3383219.3383281},
abstract = {Software fault prediction is a process to detect bugs in software projects. Fault prediction in software engineering has attracted much attention from the last decade. The early prognostication of faults in software minimize the cost and effort of errors that come at later stages. Different machine learning techniques have been utilized for fault prediction, that is proven to be utilizable. Despite, the significance of fault prediction most of the companies do not consider fault prediction in practice and do not build useful models due to lack of data or lack of enough data to strengthen the power of fault predictors. However, models trained and tested on less amount of data are difficult to generalize, because they do not consider project size, project differences, and features selection. To overcome these issues, we proposed an instance-based transfer learning through data leveraging using logistic linear regression as a base proposed statistical methodology. In our study, we considered three software projects within the same domain. Finally, we performed a comparative analysis of three different experiments for building models (targeted project). The experimental results of the proposed approach show promising improvements in (SFP).},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {434–438},
numpages = {5},
keywords = {Cross-project, Instance-based learning, Machine learning, Software Quality, Software fault prediction, data leveraging},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1145/3338906.3341462,
author = {Caulo, Maria},
title = {A taxonomy of metrics for software fault prediction},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3341462},
doi = {10.1145/3338906.3341462},
abstract = {In the field of Software Fault Prediction (SFP), researchers exploit software metrics to build predictive models using machine learning and/or statistical techniques. SFP has existed for several decades and the number of metrics used has increased dramatically. Thus, the need for a taxonomy of metrics for SFP arises firstly to standardize the lexicon used in this field so that the communication among researchers is simplified and then to organize and systematically classify the used metrics. In this doctoral symposium paper, I present my ongoing work which aims not only to build such a taxonomy as comprehensive as possible, but also to provide a global understanding of the metrics for SFP in terms of detailed information: acronym(s), extended name, univocal description, granularity of the fault prediction (e.g., method and class), category, and research papers in which they were used.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1144–1147},
numpages = {4},
keywords = {software fault prediction, software metrics, taxonomy},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1007/978-3-030-38961-1_8,
author = {Sun, Yuanyuan and Xu, Lele and Guo, Lili and Li, Ye and Wang, Yongming},
title = {A Comparison Study of VAE and GAN for Software Fault Prediction},
year = {2019},
isbn = {978-3-030-38960-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38961-1_8},
doi = {10.1007/978-3-030-38961-1_8},
abstract = {Software fault is an unavoidable problem in software project. How to predict software fault to enhance safety and reliability of system is worth studying. In recent years, deep learning has been widely used in the fields of image, text and voice. However it is seldom applied in the field of software fault prediction. Considering the ability of deep learning, we select the deep learning techniques of VAE and GAN for software fault prediction and compare the performance of them. There is one salient feature of software fault data. The proportion of non-fault data is well above the proportion of fault data. Because of the imbalanced data, it is difficult to get high accuracy to predict software fault. As we known, VAE and GAN are able to generate synthetic samples that obey the distribution of real data. We try to take advantage of their power to generate new fault samples in order to improve the accuracy of software fault prediction. The architectures of VAE and GAN are designed to fit for the high dimensional software fault data. New software fault samples are generated to balance the software fault datasets in order to get better performance for software fault prediction. The models of VAE and GAN are trained on GPU TITAN X. SMOTE is also adopted in order to compare the performance with VAE and GAN. The results in the experiment show that VAE and GAN are useful techniques for software fault prediction and VAE has better performance than GAN on this issue.},
booktitle = {Algorithms and Architectures for Parallel Processing: 19th International Conference, ICA3PP 2019, Melbourne, VIC, Australia, December 9–11, 2019, Proceedings, Part II},
pages = {82–96},
numpages = {15},
keywords = {Deep learning, VAE, GAN, Software fault prediction},
location = {Melbourne, VIC, Australia}
}

@inproceedings{10.1145/3183399.3183402,
author = {Koch, Patrick and Schekotihin, Konstantin and Jannach, Dietmar and Hofer, Birgit and Wotawa, Franz and Schmitz, Thomas},
title = {Combining spreadsheet smells for improved fault prediction},
year = {2018},
isbn = {9781450356626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183399.3183402},
doi = {10.1145/3183399.3183402},
abstract = {Spreadsheets are commonly used in organizations as a programming tool for business-related calculations and decision making. Since faults in spreadsheets can have severe business impacts, a number of approaches from general software engineering have been applied to spreadsheets in recent years, among them the concept of code smells. Smells can in particular be used for the task of fault prediction. An analysis of existing spreadsheet smells, however, revealed that the predictive power of individual smells can be limited. In this work we therefore propose a machine learning based approach which combines the predictions of individual smells by using an AdaBoost ensemble classifier. Experiments on two public datasets containing real-world spreadsheet faults show significant improvements in terms of fault prediction accuracy.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {25–28},
numpages = {4},
keywords = {fault prediction, spreadsheet QA, spreadsheet smells},
location = {Gothenburg, Sweden},
series = {ICSE-NIER '18}
}

@inproceedings{10.1007/978-3-030-31726-3_41,
author = {Wang, Junpu and Li, Chunlei and Liu, Zhoufeng and Dong, Yan and Huang, Yun},
title = {Combing Deep and Handcrafted Features for NTV-NRPCA Based Fabric Defect Detection},
year = {2019},
isbn = {978-3-030-31725-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31726-3_41},
doi = {10.1007/978-3-030-31726-3_41},
abstract = {Fabric defect detection plays an important role in automated inspection and quality control in textile manufacturing. As the textures and defects in fabric images have complexity and diversity, the traditional detection methods show a poor adaptability and low detection accuracy. Low-rank decomposition model that can be used to separate the image into object and background have proven applicable in fabric defect detection. However, how to represent texture feature of the fabric image more effectively is still problematic in this kind of method. Also, in traditional Low-rank decomposition model, we tend to seek the convex surrogate to resolve this model. However, this results in low accuracy and more noises in sparse part. In this paper, a novel fabric defect detection method based on combination of deep global feature and handcrafted local features and NTV-NRPCA is proposed. In this method, image representation ability is well enhanced through fusing the global deep feature extracted by a convolutional neural network and the handcrafted low-level feature masterly. Then, the non-convex total variation regularized non-convex RPCA (NTV-NRPCA) is proposed in which non-convex solution is more approximate to the real solution and non-convex total variation constraint significantly reduces the noises in sparse part. Finally, the defect region is located by segmenting the saliency map generated by the sparse matrix via a threshold segmentation algorithm. The experimental results show that the proposed method improves the adaptability and detection accuracy comparing to the state-of-the-art.},
booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part III},
pages = {479–490},
numpages = {12},
keywords = {Fabric defect detection, Deep-handcrafted feature, RPCA, Total variation, Non-convex},
location = {Xi'an, China}
}

@article{10.1007/s10664-021-09991-3,
author = {Tahir, Amjed and Bennin, Kwabena E. and Xiao, Xun and MacDonell, Stephen G.},
title = {Does class size matter? An in-depth assessment of the effect of class size in software defect prediction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09991-3},
doi = {10.1007/s10664-021-09991-3},
abstract = {In the past 20 years, defect prediction studies have generally acknowledged the effect of class size on software prediction performance. To quantify the relationship between object-oriented (OO) metrics and defects, modelling has to take into account the direct, and potentially indirect, effects of class size on defects. However, some studies have shown that size cannot be simply controlled or ignored, when building prediction models. As such, there remains a question whether, and when, to control for class size. This study provides a new in-depth examination of the impact of class size on the relationship between OO metrics and software defects or defect-proneness. We assess the impact of class size on the number of defects and defect-proneness in software systems by employing a regression-based mediation (with bootstrapping) and moderation analysis to investigate the direct and indirect effect of class size in count and binary defect prediction. Our results show that the size effect is not always significant for all metrics. Of the seven OO metrics we investigated, size consistently has significant mediation impact only on the relationship between Coupling Between Objects (CBO) and defects/defect-proneness, and a potential moderation impact on the relationship between Fan-out and defects/defect-proneness. Other metrics show mixed results, in that they are significant for some systems but not for others. Based on our results we make three recommendations. One, we encourage researchers and practitioners to examine the impact of class size for the specific data they have in hand and through the use of the proposed statistical mediation/moderation procedures. Two, we encourage empirical studies to investigate the indirect effect of possible additional variables in their models when relevant. Three, the statistical procedures adopted in this study could be used in other empirical software engineering research to investigate the influence of potential mediators/moderators.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {38},
keywords = {Defect prediction, Class size, Metrics, Software quality}
}

@article{10.1007/s10845-020-01563-4,
author = {Stern, Maike Lorena and Schellenberger, Martin},
title = {Fully convolutional networks for chip-wise defect detection employing photoluminescence images: Efficient quality control in LED manufacturing},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01563-4},
doi = {10.1007/s10845-020-01563-4},
abstract = {Efficient quality control is inevitable in the manufacturing of light-emitting diodes (LEDs). Because defective LED chips may be traced back to different causes, a time and cost-intensive electrical and optical contact measurement is employed. Fast photoluminescence measurements, on the other hand, are commonly used to detect wafer separation damages but also hold the potential to enable an efficient detection of all kinds of defective LED chips. On a photoluminescence image, every pixel corresponds to an LED chip’s brightness after photoexcitation, revealing performance information. But due to unevenly distributed brightness values and varying defect patterns, photoluminescence images are not yet employed for a comprehensive defect detection. In this work, we show that fully convolutional networks can be used for chip-wise defect detection, trained on a small data-set of photoluminescence images. Pixel-wise labels allow us to classify each and every chip as defective or not. Being measurement-based, labels are easy to procure and our experiments show that existing discrepancies between training images and labels do not hinder network training. Using weighted loss calculation, we were able to equalize our highly unbalanced class categories. Due to the consistent use of skip connections and residual shortcuts, our network is able to predict a variety of structures, from extensive defect clusters up to single defective LED chips.},
journal = {J. Intell. Manuf.},
month = jan,
pages = {113–126},
numpages = {14},
keywords = {Fully convolutional networks, Deep learning, Photoluminescence images, Chip-wise prediction, Defect cluster detection, LED manufacturing, Quality control, Industrial application}
}

@article{10.1016/j.ins.2013.12.031,
author = {Czibula, Gabriela and Marian, Zsuzsanna and Czibula, Istvan Gergely},
title = {Software defect prediction using relational association rule mining},
year = {2014},
issue_date = {April, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {264},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2013.12.031},
doi = {10.1016/j.ins.2013.12.031},
abstract = {This paper focuses on the problem of defect prediction, a problem of major importance during software maintenance and evolution. It is essential for software developers to identify defective software modules in order to continuously improve the quality of a software system. As the conditions for a software module to have defects are hard to identify, machine learning based classification models are still developed to approach the problem of defect prediction. We propose a novel classification model based on relational association rules mining. Relational association rules are an extension of ordinal association rules, which are a particular type of association rules that describe numerical orderings between attributes that commonly occur over a dataset. Our classifier is based on the discovery of relational association rules for predicting whether a software module is or it is not defective. An experimental evaluation of the proposed model on the open source NASA datasets, as well as a comparison to similar existing approaches is provided. The obtained results show that our classifier overperforms, for most of the considered evaluation measures, the existing machine learning based techniques for defect prediction. This confirms the potential of our proposal.},
journal = {Inf. Sci.},
month = apr,
pages = {260–278},
numpages = {19},
keywords = {Association rule, Data mining, Defect prediction, Software engineering}
}

@article{10.1016/j.aei.2019.101004,
author = {Dai, Wenting and Mujeeb, Abdul and Erdt, Marius and Sourin, Alexei},
title = {Soldering defect detection in automatic optical inspection},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {43},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2019.101004},
doi = {10.1016/j.aei.2019.101004},
journal = {Adv. Eng. Inform.},
month = jan,
numpages = {7},
keywords = {Automatic Optical Inspection (AOI), Localization and classification of solder joint defects, Semi-supervised learning, YOLO, Clustering, Active learning}
}

@inproceedings{10.1109/COASE.2019.8843204,
author = {Niu, Shuanlong and Lin, Hui and Niu, Tongzhi and Li, Bin and Wang, Xinggang},
title = {DefectGAN: Weakly-Supervised Defect Detection using Generative Adversarial Network},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8843204},
doi = {10.1109/COASE.2019.8843204},
abstract = {Traditional methods for defect detection applied in industry are complex, time-consuming, not robust and demanding for professional experience due to hand-crafted features extraction and pipeline design. Besides, current deep learning based methods for general object segmentation demand for a large number of region-level human annotations.Instead, we present DefectGAN for defect detection in a weakly-supervised learning, which requires very a few human annotations. In practical application, images in training dataset are merely labeled with two categories: negative and positive. Despite being trained on image-level rather than region-level labels, DefectGAN has remarkable ability of localizing defect regions.DefectGAN can have comparable and visually even better performance than SegNet, a supervised learning method on dataset CCSD-NL and DAGM 2007. The detected regions are more similar to the original defect regions visually and it has the potential of detecting unseen defects.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {127–132},
numpages = {6},
location = {Vancouver, BC, Canada}
}

@article{10.1016/j.eswa.2019.113156,
author = {Majd, Amirabbas and Vahidi-Asl, Mojtaba and Khalilian, Alireza and Poorsarvi-Tehrani, Pooria and Haghighi, Hassan},
title = {SLDeep: Statement-level software defect prediction using deep-learning model on static code features},
year = {2020},
issue_date = {Jun 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {147},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113156},
doi = {10.1016/j.eswa.2019.113156},
journal = {Expert Syst. Appl.},
month = jun,
numpages = {14},
keywords = {Defect, Software fault proneness, Machine learning, Fault prediction model, Software metric}
}

@article{10.1155/2021/5592878,
author = {Zhao, Weidong and Chen, Feng and Huang, Hancheng and Li, Dan and Cheng, Wei and Versaci, Mario},
title = {A New Steel Defect Detection Algorithm Based on Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/5592878},
doi = {10.1155/2021/5592878},
abstract = {In recent years, more and more scholars devoted themselves to the research of the target detection algorithm due to the continuous development of deep learning. Among them, the detection and recognition of small and complex targets are still a problem to be solved. The authors of this article have understood the shortcomings of the deep learning detection algorithm in detecting small and complex defect targets and would like to share a new improved target detection algorithm in steel surface defect detection. The steel surface defects will affect the quality of steel seriously. We find that most of the current detection algorithms for NEU-DET dataset detection accuracy are low, so we choose to verify a steel surface defect detection algorithm based on machine vision on this dataset for the problem of defect detection in steel production. A series of improvement measures are carried out in the traditional Faster R-CNN algorithm, such as reconstructing the network structure of Faster R-CNN. Based on the small features of the target, we train the network with multiscale fusion. For the complex features of the target, we replace part of the conventional convolution network with a deformable convolution network. The experimental results show that the deep learning network model trained by the proposed method has good detection performance, and the mean average precision is 0.752, which is 0.128 higher than the original algorithm. Among them, the average precision of crazing, inclusion, patches, pitted surface, rolled in scale and scratches is 0.501, 0.791, 0.792, 0.874, 0.649, and 0.905, respectively. The detection method is able to identify small target defects on the steel surface effectively, which can provide a reference for the automatic detection of steel defects.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {13}
}

@article{10.1155/2021/9976209,
author = {Chen, Yuquan and Wang, Hongxing and Shen, Jie and Zhang, Xingwei and Gao, Xiaowei and Nazir, Shah},
title = {Application of Data-Driven Iterative Learning Algorithm in Transmission Line Defect Detection},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/9976209},
doi = {10.1155/2021/9976209},
abstract = {Deep learning technology has received extensive consideration in recent years, and its application value in target detection is also increasing day by day. In order to accelerate the practical process of deep learning technology in electric transmission line defect detection, the current work used the improved Faster R-CNN algorithm to achieve data-driven iterative training and defect detection functions for typical transmission line defect targets. Based on Faster R-CNN, we proposed an improved network that combines deformable convolution and feature pyramid modules and combined it with a data-driven iterative learning algorithm; it achieves extremely automated and intelligent transmission line defect target detection, forming an intelligent closed-loop image processing. The experimental results show that the increase of the recognition of improved Faster R-CNN network combined with data-driven iterative learning algorithm for the pin defect target is 31.7% more than Faster R-CNN. In the future, the proposed method can quickly improve the accuracy of transmission line defect target detection in a small sample and save manpower. It also provides some theoretical guidance for the practical work of transmission line defect target detection.},
journal = {Sci. Program.},
month = jan,
numpages = {9}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00014,
author = {Idowu, Samuel and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Asset management in machine learning: a survey},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00014},
doi = {10.1109/ICSE-SEIP52600.2021.00014},
abstract = {Machine Learning (ML) techniques are becoming essential components of many software systems today, causing an increasing need to adapt traditional software engineering practices and tools to the development of ML-based software systems. This need is especially pronounced due to the challenges associated with the large-scale development and deployment of ML systems. Among the most commonly reported challenges during the development, production, and operation of ML-based systems are experiment management, dependency management, monitoring, and logging of ML assets. In recent years, we have seen several efforts to address these challenges as witnessed by an increasing number of tools for tracking and managing ML experiments and their assets. To facilitate research and practice on engineering intelligent systems, it is essential to understand the nature of the current tool support for managing ML assets. What kind of support is provided? What asset types are tracked? What operations are offered to users for managing those assets? We discuss and position ML asset management as an important discipline that provides methods and tools for ML assets as structures and the ML development activities as their operations. We present a feature-based survey of 17 tools with ML asset management support identified in a systematic search. We overview these tools' features for managing the different types of assets used for engineering ML-based systems and performing experiments. We found that most of the asset management support depends on traditional version control systems, while only a few tools support an asset granularity level that differentiates between important ML assets, such as datasets and models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {51–60},
numpages = {10},
keywords = {SE4AI, asset management, machine learning},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@article{10.1504/IJWMC.2016.076145,
author = {Li, Feixiang and Rong, Xiaotao and Cui, Zhihua},
title = {A hybrid CRBA-SVM model for software defect prediction},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {10},
number = {2},
issn = {1741-1084},
url = {https://doi.org/10.1504/IJWMC.2016.076145},
doi = {10.1504/IJWMC.2016.076145},
abstract = {Support vector machine SVM model is becoming an increasingly popular method in software defects prediction. This model has strong non-linear classifying ability. However, SVM model lacks effective method to determine the best parameters. In this paper, a modified bat algorithm, named changing range bat algorithm, is employed to optimise the parameters of SVM model. To test the performance of this new model, several public datasets of software defect prediction are employed and then the results are compared with other five approaches. Experimental results show that the classification ability of hybrid CRBA-SVM model surpasses all other approaches.},
journal = {Int. J. Wire. Mob. Comput.},
month = apr,
pages = {191–196},
numpages = {6}
}

@article{10.4018/IJOSSP.2017010102,
author = {Alsukhni, Emad and Saifan, Ahmad A. and Alawneh, Hanadi},
title = {A New Data Mining-Based Framework to Test Case Prioritization Using Software Defect Prediction},
year = {2017},
issue_date = {January 2017},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {1},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2017010102},
doi = {10.4018/IJOSSP.2017010102},
abstract = {Test cases do not have the same importance when used to detect faults in software; therefore, it is more efficient to test the system with the test cases that have the ability to detect the faults. This research proposes a new framework that combines data mining techniques to prioritize the test cases. It enhances fault prediction and detection using two different techniques: 1 the data mining regression classifier that depends on software metrics to predict defective modules, and 2 the k-means clustering technique that is used to select and prioritize test cases to identify the fault early. Our approach of test case prioritization yields good results in comparison with other studies. The authors used the Average Percentage of Faults Detection APFD metric to evaluate the proposed framework, which results in 19.9% for all system modules and 25.7% for defective ones. Our results give us an indication that it is effective to start the testing process with the most defective modules instead of testing all modules arbitrary arbitrarily.},
journal = {Int. J. Open Source Softw. Process.},
month = jan,
pages = {21–41},
numpages = {21},
keywords = {Data Mining, Software Defect Prediction, Software Testing, Test Case Prioritization}
}

@article{10.1007/s11042-020-09245-2,
author = {Xu, Jiabin and Zhang, Jindong and Zhang, Kunpeng and Liu, Tong and Wang, Donghui and Wang, Xue},
title = {An APF-ACO algorithm for automatic defect detection on vehicle paint},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {35–36},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-09245-2},
doi = {10.1007/s11042-020-09245-2},
abstract = {As a popular technology in the field of artificial intelligence, computer vision is gradually adapting to the needs of convenience for human beings, improving production efficiency and reducing production costs. Therefore, this study proposes a computer vision algorithm to locate and identify the location of defects. For the traditional edge detection algorithm Sobel, LoG, Canny, the decisive factor for the detection effect of paint defect image is the adjustment of parameters, which can’t achieve an adaptive edge detection algorithm for paint defects, so it is thought that the evolution idea of ant colony algorithm can be used to achieve accurate detection of defects. This paper proposes an automatic detection method for vehicle body paint film defects based on computer vision. An ant colony optimization edge detection algorithm based on automotive paint features (APF-ACO) is proposed. By combining global update and local update, the convergence speed of ant colony algorithm is improved and a new pheromone calculation and update method is proposed to effectively preserve the edge details of the detected image. A reflection area detection algorithm based on HSV color space is designed to detect the reflective area and eliminate interference. Establish defect classification identification rules, identify and mark five types of defects, and determine defect categories. Experiments show that the method can effectively detect the defect area and the recognition accuracy is 97.76%.},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {25315–25333},
numpages = {19},
keywords = {Ant colony algorithm, Defect detection, Image edge detection, Computer vision}
}

@inproceedings{10.1145/3379247.3379278,
author = {Ahmed, Md. Razu and Ali, Md. Asraf and Ahmed, Nasim and Zamal, Md. Fahad Bin and Shamrat, F.M. Javed Mehedi},
title = {The Impact of Software Fault Prediction in Real-World Application: An Automated Approach for Software Engineering},
year = {2020},
isbn = {9781450376730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379247.3379278},
doi = {10.1145/3379247.3379278},
abstract = {Software fault prediction and proneness has long been considered as a critical issue for the tech industry and software professionals. In the traditional techniques, it requires previous experience of faults or a faulty module while detecting the software faults inside an application. An automated software fault recovery models enable the software to significantly predict and recover software faults using machine learning techniques. Such ability of the feature makes the software to run more effectively and reduce the faults, time and cost. In this paper, we proposed a software defect predictive development models using machine learning techniques that can enable the software to continue its projected task. Moreover, we used different prominent evaluation benchmark to evaluate the model's performance such as ten-fold cross-validation techniques, precision, recall, specificity, f 1 measure, and accuracy. This study reports a significant classification performance of 98-100% using SVM on three defect datasets in terms of f1 measure. However, software practitioners and researchers can attain independent understanding from this study while selecting automated task for their intended application.},
booktitle = {Proceedings of 2020 6th International Conference on Computing and Data Engineering},
pages = {247–251},
numpages = {5},
keywords = {Defect prediction, Machine learning, Software engineering, Software fault},
location = {Sanya, China},
series = {ICCDE '20}
}

@inproceedings{10.1145/3336294.3336303,
author = {Varela-Vaca, \'{A}ngel Jes\'{u}s and Galindo, Jos\'{e} A. and Ramos-Guti\'{e}rrez, Bel\'{e}n and G\'{o}mez-L\'{o}pez, Mar\'{\i}a Teresa and Benavides, David},
title = {Process Mining to Unleash Variability Management: Discovering Configuration Workflows Using Logs},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336303},
doi = {10.1145/3336294.3336303},
abstract = {Variability models are used to build configurators. Configurators are programs that guide users through the configuration process to reach a desired configuration that fulfils user requirements. The same variability model can be used to design different configurators employing different techniques. One of the elements that can change in a configurator is the configuration workflow, i.e., the order and sequence in which the different configuration elements are presented to the configuration stakeholders. When developing a configurator, a challenge is to decide the configuration workflow that better suites stakeholders according to previous configurations. For example, when configuring a Linux distribution, the configuration process start by choosing the network or the graphic card, and then other packages with respect to a given sequence. In this paper, we present COnfiguration workfLOw proceSS mIning (COLOSSI), an automated technique that given a set of logs of previous configurations and a variability model can automatically assist to determine the configuration workflow that better fits the configuration logs generated by user activities. The technique is based on process discovery, commonly used in the process mining area, with an adaptation to configuration contexts. Our proposal is validated using existing data from an ERP configuration environment showing its feasibility. Furthermore, we open the door to new applications of process mining techniques in different areas of software product line engineering.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {265–276},
numpages = {12},
keywords = {clustering, configuration workflow, process discovery, process mining, variability},
location = {Paris, France},
series = {SPLC '19}
}

@article{10.1007/s11227-018-2326-5,
author = {Kalsoom, Anum and Maqsood, Muazzam and Ghazanfar, Mustansar Ali and Aadil, Farhan and Rho, Seungmin},
title = {A dimensionality reduction-based efficient software fault prediction using Fisher linear discriminant analysis (FLDA)},
year = {2018},
issue_date = {Sep 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {74},
number = {9},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-018-2326-5},
doi = {10.1007/s11227-018-2326-5},
abstract = {Software quality is an important factor in the success of software companies. Traditional software quality assurance techniques face some serious limitations especially in terms of time and budget. This leads to increase in the use of machine learning classification techniques to predict software faults. Software fault prediction can help developers to uncover software problems in early stages of software life cycle. The extent to which these techniques can be generalized to different sizes of software, class imbalance problem, and identification of discriminative software metrics are the most critical challenges. In this paper, we have analyzed the performance of nine widely used machine learning classifiers--Bayes Net, NB, artificial neural network, support vector machines, K nearest neighbors, AdaBoost, Bagging, Zero R, and Random Forest for software fault prediction. Two standard sampling techniques--SMOTE and Resample with substitution are used to handle the class imbalance problem. We further used FLDA-based feature selection approach in combination with SMOTE and Resample to select most discriminative metrics. Then the top four classifiers based on performance are used for software fault prediction. The experimentation is carried out over 15 publically available datasets (small, medium and large) which are collected from PROMISE repository. The proposed Resample-FLDA method gives better performance as compared to existing methods in terms of precision, recall, f-measure and area under the curve.},
journal = {J. Supercomput.},
month = sep,
pages = {4568–4602},
numpages = {35},
keywords = {Fault-tolerance, Fisher linear discriminant, Reliability, Robustness, Software fault prediction}
}

@article{10.1007/s11042-018-6483-6,
author = {Li, Chunlei and Liu, Chaodie and Gao, Guangshuai and Liu, Zhoufeng and Wang, Yuping},
title = {Robust low-rank decomposition of multi-channel feature matrices for fabric defect detection},
year = {2019},
issue_date = {March     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {78},
number = {6},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-018-6483-6},
doi = {10.1007/s11042-018-6483-6},
abstract = {Fabric defect detection plays an important role in the quality control of textile products. Most existing defect detection techniques adopted traditional pattern recognition methods, which were lacking adaptability and presented the undesirable detection accuracy. In this paper, a fabric defect detection algorithm based on multi-channel feature matrixes extraction and joint low-rank decomposition was proposed by simulating biological visual perception mechanism. Based on the fact that the second-order gradient information is more suitable for characterizing the fabric texture, we developed a novel second-order multi-channel feature extraction method by modeling the response and distribution properties of the P-type ganglion cells in the primate retina. Upon devising a powerful descriptor, a joint low-rank decomposition method is utilized to model biological visual saliency, and decomposes the fabric images into backgrounds and salient defect objects. Experimental results demonstrate that our proposed algorithm has good self-adaptability and detection performance for plain and twill fabrics or complex patterned fabrics, and is superior to the state-of-the-art methods.},
journal = {Multimedia Tools Appl.},
month = mar,
pages = {7321–7339},
numpages = {19},
keywords = {Defect detection, Fabric images, Joint low-rank decomposition, Multi-channel feature, Second-order gradient}
}

@article{10.1155/2021/2036466,
author = {Liu, Bangchao and Chen, Youping and Xie, Jingming and Chen, Bing and Praveenkumar, Padmapriya},
title = {Industrial Printing Image Defect Detection Using Multi-Edge Feature Fusion Algorithm},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/2036466},
doi = {10.1155/2021/2036466},
abstract = {Online defect detection system is a necessary technical measure and important means for large-scale industrial printing production. It is effective to reduce artificial detection fatigue and improve the accuracy and stability of industry printing line. However, the existing defect detection algorithms are mainly developed based on high-quality database and it is difficult to detect the defects on low-quality printing images. In this paper, we propose a new multi-edge feature fusion algorithm which is effective in solving this problem. Firstly, according to the characteristics of sheet-fed printing system, a new printing image database is established; compared with the existing databases, it has larger translation, deformation, and uneven illumination variation. These interferences make defect detection become more challenging. Then, SIFT feature is employed to register the database. In order to reduce the number of false detections which are caused by the position, deformation, and brightness deviation between the detected image and reference image, multi-edge feature fusion algorithm is proposed to overcome the effects of these disturbances. Lastly, the experimental results of mAP (92.65%) and recall (96.29%) verify the effectiveness of the proposed method which can effectively detect defects in low-quality printing database. The proposed research results can improve the adaptability of visual inspection system on a variety of different printing platforms. It is better to control the printing process and further reduce the number of operators.},
journal = {Complex.},
month = jan,
numpages = {10}
}

@article{10.1007/s00500-020-04985-7,
author = {Le, D. Van-Khoa and Chen, Zhiyuan and Wong, Yee Wan and Isa, Dino},
title = {A complete online-SVM pipeline for case-based reasoning system: a study on pipe defect detection system},
year = {2020},
issue_date = {Nov 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {22},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-04985-7},
doi = {10.1007/s00500-020-04985-7},
abstract = {Recent developments in case-based reasoning system (CBR) have led to an interest in favoring machine learning (ML) approaches as a replacement for traditional weighted distance methods. However, valuable information obtained through a training process was relinquished as transferring to other phases. This paper proposed a complete pipeline integration of CBR using kernel method designated with support vector machine (SVM) as the main engine. Since the system requires learning SVM model to be invoked in every phase, the online learning mechanism is nominated to effectively update the model when a new case adjoins. The proposed full SVM-CBR integration has been successfully built into a pipe defect detection. The achieved result indicates a substantial improvement by transferring learning information accurately.},
journal = {Soft Comput.},
month = nov,
pages = {16917–16933},
numpages = {17},
keywords = {Defect detection, Case-based reasoning, Online learning, SVM, Expert system}
}

@inproceedings{10.1145/3381271.3381298,
author = {Chen, Xue and Cao, Jian-Wen and Wang, Yu-Peng},
title = {Defect detection in ID cards with accurately reconstructed reference image},
year = {2020},
isbn = {9781450376648},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3381271.3381298},
doi = {10.1145/3381271.3381298},
abstract = {ID card is made by hot-pressing a standard film with identifiable information onto a fixed baseboard with background of wavy lines. In this paper, we propose a defect detect algorithm by synthesising the film image and baseboard image to accurately reconstruct a reference image for a test card. First, to ensure the content consistency in position and scale, we align the card to a standard film image through perspective transformation(PT) based on AKAZE key-points. Besides, we use contrast limited adaptive histogram equalization(CLAHE) to enhance the background pattern of a baseboard image, and then align it to the rectified card. Second, we apply multiply algorithm to synthesise the aligned film image and baseboard image as a reconstructed reference image. Besides, we align the lightness histogram of the reference image to a test card so as to eliminate the lighting difference. Finally, we apply the difference image method based on canny edge detection to detect difference between a reference image with a card, and further extract the defect information. We experiment on cards with different types of defects and shooting disturbances. Results show high accuracy of our method.},
booktitle = {Proceedings of the 5th International Conference on Multimedia and Image Processing},
pages = {18–22},
numpages = {5},
keywords = {AKAZE, defect detection, difference image, lightness histogram, reference image},
location = {Nanjing, China},
series = {ICMIP '20}
}

@inproceedings{10.1109/COASE.2019.8843235,
author = {Xiao, Ling and Huang, Tao and Wu, Bo and Hu, Youmin and Zhou, Jiehan},
title = {Surface Defect Detection using Hierarchical Features},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8843235},
doi = {10.1109/COASE.2019.8843235},
abstract = {In this paper, we propose an instance level hierarchical features based convolution neural network model (H-CNN) for detecting surface defects. The H-CNN uses different convolutional layers’ extracted features to generate defect masks. The H-CNN first generates proposal regions. Then, it proposes a fully convolutional neural network to extract different level’s convolutional features and detect instance level defects. We applied the H-CNN model in freight train detection system for detecting oil-leaks, and the results demonstrate that the H-CNN can effectively identify and generate defect masks. It achieves 92% accuracy on the large reflective oil-leak stain, 86% on the large non-reflective oil-leak stain, 89% on the small reflective oil-leak stain and 74% on the small non-reflective oil-leak stain. Its image process speed is 0.467 s per frame.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {1592–1596},
numpages = {5},
location = {Vancouver, BC, Canada}
}

@inproceedings{10.1007/978-3-319-97310-4_54,
author = {Zhao, Zhixuan and Li, Bo and Dong, Rong and Zhao, Peng},
title = {A Surface Defect Detection Method Based on Positive Samples},
year = {2018},
isbn = {978-3-319-97309-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-97310-4_54},
doi = {10.1007/978-3-319-97310-4_54},
abstract = {Surface defect detection and classification based on machine vision can greatly improve the efficiency of industrial production. With enough labeled images, defect detection methods based on convolution neural network have achieved the detection effect of state-of-art. However in practical applications, the defect samples or negative samples are usually difficult to be collected beforehand and manual labelling is time-consuming. In this paper, a novel defect detection framework only based on training of positive samples is proposed. The basic detection concept is to establish a reconstruction network which can repair defect areas in the samples if they are existed, and then make a comparison between the input sample and the restored one to indicate the accurate defect areas. We combine GAN and autoencoder for defect image reconstruction and use LBP for image local contrast to detect defects. In the training process of the algorithm, only positive samples is needed, without defect samples and manual label. This paper carries out verification experiments for concentrated fabric images and the dataset of DAGM 2007. Experiments show that the proposed GAN+LBP algorithm and supervised training algorithm with sufficient training samples have fairly high detection accuracy. Because of its unsupervised characteristics, it has higher practical application value.},
booktitle = {PRICAI 2018: Trends in Artificial Intelligence: 15th Pacific Rim International Conference on Artificial Intelligence, Nanjing, China, August 28–31, 2018, Proceedings, Part II},
pages = {473–481},
numpages = {9},
keywords = {Positive samples, Surface defect detection, Autoencoder, GAN},
location = {Nanjing, China}
}

@article{10.1155/2021/3965247,
author = {Li, Xiaoguang and Zhu, Juan and Shi, Haoran and Cong, Zijian and Gupta, Punit},
title = {Surface Defect Detection of Seals Based on K-Means Clustering Algorithm and Particle Swarm Optimization},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/3965247},
doi = {10.1155/2021/3965247},
abstract = {As an important part of automobile, the quality and safety of automobile engine high-pressure oil circuit seal parts are an important indicator of the manufacturer’s production process. In order to improve the detection accuracy and efficiency of seal parts in the traditional production process, the defect detection method on the surface of the seal was studied. A K-Means clustering image segmentation algorithm based on particle swarm optimization was proposed. To detect the surface defects of seals, first, preprocess the seal image. Then, use the SURF algorithm to extract the feature points of the seal image. Finally, according to the particle swarm fitness variance function, select the insertion point calculated by combining particle swarm optimization and K-Means algorithm. Through iteration, optimize the initial clustering center of K-Means algorithm. The efficiency of K-Means algorithm clustering iteration is improved. The test verifies the applicability of the algorithm in the actual process, and it can be used to accurately detect seals. Experimental results show that the detection accuracy rate reaches 98%, which is highly applicable to the actual production.},
journal = {Sci. Program.},
month = jan,
numpages = {12}
}

@article{10.1016/j.eswa.2018.12.033,
author = {Turabieh, Hamza and Mafarja, Majdi and Li, Xiaodong},
title = {Iterated feature selection algorithms with layered recurrent neural network for software fault prediction},
year = {2019},
issue_date = {May 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2018.12.033},
doi = {10.1016/j.eswa.2018.12.033},
journal = {Expert Syst. Appl.},
month = may,
pages = {27–42},
numpages = {16},
keywords = {Software fault prediction, Feature selection, Layered recurrent neural network}
}

@inproceedings{10.1145/3434581.3434672,
author = {Jiang, Anyao and Liu, Jun},
title = {Pipeline Flange Defect Detection based on Deep Learning},
year = {2020},
isbn = {9781450375764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3434581.3434672},
doi = {10.1145/3434581.3434672},
abstract = {Pipe flanges are an indispensable part of industrial piping equipment. Due to the large number of flanges and different installation positions, it will inevitably have a certain negative impact on the quality of manual inspections. Therefore, this paper proposes a pipeline flange visual inspection method based on the improved YOLO v3 algorithm to adjust the network structure: In order to reduce the impact of image shooting scale changes on the detection accuracy, the original network's multi-scale target detection is adjusted to 5 types Scale; At the same time, use the RAdam optimizer to replace the SGD optimizer to improve the training efficiency of the initial stage. Experimental results show that the improved YOLOv3 network can greatly improve the accuracy of flange image recognition and accelerate the convergence speed of the network training phase. It can make full use of the surveillance cameras and intelligent inspection robots in the environment to analyse the flange image, thereby Realize intelligent operation and maintenance.},
booktitle = {Proceedings of the 2020 International Conference on Aviation Safety and Information Technology},
pages = {296–300},
numpages = {5},
keywords = {Deep learning, algorithm, flange, object detection},
location = {Weihai City, China},
series = {ICASIT 2020}
}

@inproceedings{10.1109/CIS.2013.61,
author = {Shuai, Bo and Li, Haifeng and Li, Mengjun and Zhang, Quan and Tang, Chaojing},
title = {Software Defect Prediction Using Dynamic Support Vector Machine},
year = {2013},
isbn = {9781479925490},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CIS.2013.61},
doi = {10.1109/CIS.2013.61},
abstract = {In order to solve the problems of traditional SVM classifier for software defect prediction, this paper proposes a novel dynamic SVM method based on improved cost-sensitive SVM (CSSVM) which is optimized by the Genetic Algorithm (GA). Through selecting the geometric classification accuracy as the fitness function, the GA method could improve the performance of CSSVM by enhancing the accuracy of defective modules and reducing the total cost in the whole decision. Experimental results show that the GA-CSSVM method could achieve higher AUC value which denotes better prediction accuracy both for minority and majority samples in the imbalanced software defect data set.},
booktitle = {Proceedings of the 2013 Ninth International Conference on Computational Intelligence and Security},
pages = {260–263},
numpages = {4},
keywords = {AUC, CSSVM, GA, software defect},
series = {CIS '13}
}

@inproceedings{10.1145/3358528.3358594,
author = {Lu, Guo and Zhongqing, Yu and Jianqi, Yu and Chuang, Liu},
title = {Data Driven Induction Motor Condition Identification and Fault Prediction},
year = {2019},
isbn = {9781450371926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358528.3358594},
doi = {10.1145/3358528.3358594},
abstract = {With the development of technologies such as sensing and the scale of industrial production, the equipment data can be gathered massively. For induction motors, the health data can be collected is sufficient, but the fault data is not easy to obtain. Therefore, the focus of this paper was determined to identify motor operating conditions and predict possible faults based on motor health data. In this case, an induction motor condition model consisting of a state recognizer and adaptive thresholds was proposed. The health data was used for the training of the induction motor condition model, and an improved SOM-FCM Two-Layer clustering method was used to solve the problem of obtaining the motor data without label. Finally, the validity of the model and method was verified by normal motor variable load state identification and rotor broken motor fault prediction, and the accuracy of 97.5% and 90.2% was obtained respectively.},
booktitle = {Proceedings of the 2nd International Conference on Big Data Technologies},
pages = {221–229},
numpages = {9},
keywords = {Condition Identification, Data Driven, Fault Prediction, Induction Motor, Two-Layer clustering},
location = {Jinan, China},
series = {ICBDT '19}
}

@article{10.1016/j.compeleceng.2018.02.043,
author = {Choudhary, Garvit Rajesh and Kumar, Sandeep and Kumar, Kuldeep and Mishra, Alok and Catal, Cagatay},
title = {Empirical analysis of change metrics for software fault prediction},
year = {2018},
issue_date = {Apr 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {67},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2018.02.043},
doi = {10.1016/j.compeleceng.2018.02.043},
journal = {Comput. Electr. Eng.},
month = apr,
pages = {15–24},
numpages = {10},
keywords = {Software fault prediction, Eclipse, Change log, Metrics, Software quality, Defect prediction}
}

@article{10.1007/s11554-020-01023-5,
author = {Wei, Wei and Deng, Dexiang and Zeng, Lin and Zhang, Chen},
title = {Real-time implementation of fabric defect detection based on variational automatic encoder with structure similarity},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {18},
number = {3},
issn = {1861-8200},
url = {https://doi.org/10.1007/s11554-020-01023-5},
doi = {10.1007/s11554-020-01023-5},
abstract = {Automatic detection of fabric defects based on machine vision is an important topic in the quality control of cotton textile factories. There are many kinds of defects in fabric production, it is very difficult to classify the defects automatically. In recent years, deep learning image processing technology based on a convolutional neural network (CNN) can train and extract features of the target image automatically. Since a large number of defect samples cannot be collected completely, we compared unsupervised learning algorithms based on CNN, including auto encoder (AE), variational automatic encoder (VAE), and generative adversarial networks (GAN). Because of the large amount of calculation and the difficulty of training in GAN, we chose AE and VAE codec networks and then introduced mean structural similarity (MSSIM) as network training loss function to improve the performance that only used Lp-distance loss function for image brightness comparison. After training finished, the authors used the trained model to obtain target defects from SSIM residual maps between input and reconstruct images. According to the evaluation results, we finally implemented a fabric defect detection system based on VAE on Jetson TX2 from Nvidia Corporation, USA. The optimized algorithm can meet the real-time requirements of the project and realize its popularization and application.},
journal = {J. Real-Time Image Process.},
month = jun,
pages = {807–823},
numpages = {17},
keywords = {Fabric defects, Variational automatic encoder, Structural similarity, Real-time, Deep learning}
}

@article{10.1007/s10619-021-07331-4,
author = {Srinivasan, R. and Subalalitha, C. N.},
title = {Sentimental analysis from imbalanced code-mixed data using machine learning approaches},
year = {2021},
issue_date = {Jun 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {41},
number = {1},
issn = {0926-8782},
url = {https://doi.org/10.1007/s10619-021-07331-4},
doi = {10.1007/s10619-021-07331-4},
abstract = {Knowledge discovery from various perspectives has become a crucial asset in almost all fields. Sentimental analysis is a classification task used to classify the sentence based on the meaning of their context. This paper addresses class imbalance problem which is one of the important issues in sentimental analysis. Not much works focused on sentimental analysis with imbalanced class label distribution. The paper also focusses on another aspect of the problem which involves a concept called “Code Mixing”. Code mixed data consists of text alternating between two or more languages. Class imbalance distribution is a commonly noted phenomenon in a code-mixed data. The existing works have focused more on analyzing the sentiments in a monolingual data but not in a code-mixed data. This paper addresses all these issues and comes up with a solution to analyze sentiments for a class imbalanced code-mixed data using sampling technique combined with levenshtein distance metrics. Furthermore, this paper compares the performances of various machine learning approaches namely, Random Forest Classifier, Logistic Regression, XGBoost classifier, Support Vector Machine and Na\"{\i}ve Bayes Classifier using F1- Score.},
journal = {Distrib. Parallel Databases},
month = mar,
pages = {37–52},
numpages = {16},
keywords = {Code-mixed data, Sentimental analysis, Imbalanced data, Machine learning, Sampling}
}

@article{10.1111/mice.12533,
author = {Tong, Zheng and Yuan, Dongdong and Gao, Jie and Wang, Zhenjun},
title = {Pavement defect detection with fully convolutional network and an uncertainty framework},
year = {2020},
issue_date = {August 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {35},
number = {8},
issn = {1093-9687},
url = {https://doi.org/10.1111/mice.12533},
doi = {10.1111/mice.12533},
abstract = {Image segmentation has been implemented for pavement defect detection, from which types, locations, and geometric information can be obtained. In this study, an integration of a fully convolutional network with a Gaussian‐conditional random field (G‐CRF), an uncertainty framework, and probability‐based rejection is proposed for detecting pavement defects. First, a fully convolutional network is designed to generate preliminary segmentation results, and a G‐CRF is used to refine the segmentation. Second, epistemic and aleatory uncertainties in the model and database are considered to overcome the disadvantages of traditional deep‐learning methods. Last, probability‐based rejection is conducted to remove unreasonable segmentations. The proposed method is evaluated on a data set of images that were obtained from 16 highways. The proposed integration segments pavement distresses from digital images with desirable performance. It also provides a satisfactory means to improve the accuracy and generalization performance of pavement defect detection without introducing a delay into the segmentation process.},
journal = {Comput.-Aided Civ. Infrastruct. Eng.},
month = jul,
pages = {832–849},
numpages = {18}
}

@inproceedings{10.1109/MSR.2019.00017,
author = {Dam, Hoa Khanh and Pham, Trang and Ng, Shien Wee and Tran, Truyen and Grundy, John and Ghose, Aditya and Kim, Taeksu and Kim, Chul-Joo},
title = {Lessons learned from using a deep tree-based model for software defect prediction in practice},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00017},
doi = {10.1109/MSR.2019.00017},
abstract = {Defects are common in software systems and cause many problems for software users. Different methods have been developed to make early prediction about the most likely defective modules in large codebases. Most focus on designing features (e.g. complexity metrics) that correlate with potentially defective code. Those approaches however do not sufficiently capture the syntax and multiple levels of semantics of source code, a potentially important capability for building accurate prediction models. In this paper, we report on our experience of deploying a new deep learning tree-based defect prediction model in practice. This model is built upon the tree-structured Long Short Term Memory network which directly matches with the Abstract Syntax Tree representation of source code. We discuss a number of lessons learned from developing the model and evaluating it on two datasets, one from open source projects contributed by our industry partner Samsung and the other from the public PROMISE repository.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {46–57},
numpages = {12},
keywords = {deep learning, defect prediction},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@article{10.1007/s11277-021-08347-w,
author = {Zhu, Yanlong},
title = {Edge Defect Detection of Network Image by the Application of Modal Symmetry},
year = {2021},
issue_date = {Nov 2022},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {127},
number = {1},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-021-08347-w},
doi = {10.1007/s11277-021-08347-w},
abstract = {In order to improve the accuracy of detection the image defect, a method to detect the edge defect based on modal symmetry algorithm was put forward. The improved PCNN was used to deal with the salt-pepper noise and Gaussian noise in image. On this basis, the semantic learning and annotation of image features were achieved. At first, the corresponding features were extracted from the original image. And then, the semantics were learned by combining the extracted features and the manually labeled library. Combined with the semantic annotation of image, the modal symmetry algorithm was adopted to linearly subtract the data collected by two centrosymmetric sampling points and thus to get the mean value. The asymmetric modal information of the whole image was obtained. Thus, the asymmetric modal could be extracted from the symmetrical modal. Due to the high amplitude of asymmetrical modal signal in defect location. Finally, the defect identification for various locations in image was completed by judging whether the amplitude of asymmetrical modal at the defect location had a sudden change. Following conclusions can be drawn from experimental results. The proposed method has excellent performance in image processing. Meanwhile, this method has high detection accuracy and practicability.},
journal = {Wirel. Pers. Commun.},
month = mar,
pages = {561–576},
numpages = {16},
keywords = {Modal symmetry algorithm, Image, Edge defect, Detection}
}

@article{10.1155/2021/6687146,
author = {Lv, Zhaomin and Ma, Anqi and Chen, Xingjie and Zheng, Shubin and Wang, Rui},
title = {Defect Detection of Pandrol Track Fastener Based on Local Depth Feature Fusion Network},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/6687146},
doi = {10.1155/2021/6687146},
abstract = {There are three main problems in track fastener defect detection based on image: (1) The number of abnormal fastener pictures is scarce, and supervised learning detection model is difficult to establish. (2) The potential data features obtained by different feature extraction methods are different. Some methods focus on edge features, and some methods focus on texture features. Different features have different detection capabilities, and these features are not effectively fused and utilized. (3) The detection of the track fastener clip will be interfered by the track fastener bolt subimage. Aiming at the above three problems, a method for track fastener defects detection based on Local Deep Feature Fusion Network (LDFFN) is proposed. Firstly, the track fastener image segmentation method is used to obtain the track fastener clip subimage, which can effectively reduce the interference of bolt subimage features on the track fastener clip detection. Secondly, the edge features and texture features of track fastener clip subimages are extracted by Autoencoder (AE) and Restricted Boltzmann Machine (RBM), and the features are fused. Finally, the similarity measurement method Mahalanobis Distance (MD) is used to detect defects in track fasteners. The effectiveness of the proposed method is verified by real Pandrol track fastener images.},
journal = {Complex.},
month = jan,
numpages = {9}
}

@article{10.1016/j.procs.2017.09.040,
author = {Zhang, Mei and Wu, Jinglan and Lin, Huifeng and Yuan, Peng and Song, Yanan},
title = {The Application of One-Class Classifier Based on CNN in Image Defect Detection},
year = {2017},
issue_date = {November 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {114},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2017.09.040},
doi = {10.1016/j.procs.2017.09.040},
abstract = {In the field of defect detection, image processing algorithms and feature extraction algorithms have some limitations, owing to their necessity for extracting a large number of different features of diverse products images. Meanwhile, the images of defective products are less and various. Aiming at these problems, we presented a One-Class classifier based on deep convolution neural network to detect the defect images in this paper. We design a loss function with the penalty term based on Euclidean distance to train the deep convolution neural network model. A hypersphere is used as classification decision surface after setting an appropriate hypersphere radius according to the inspection accuracy. It maps the non-defective products into a hypersphere in a high dimensional feature space, while the defect images are mapped somewhere far from the center of hypersphere. Thus, a One-Class classifier based on convolutional neural network(CNN) model is proposed to detect the defects. Experiments show that the proposed method, with less number of iteration, help build the classifier for image defect detection with high generalization ability and high detection precision.},
journal = {Procedia Comput. Sci.},
month = nov,
pages = {341–348},
numpages = {8},
keywords = {CNN, Hypersphere, Image defect detection, One-Class classifier}
}

@article{10.1007/s10845-021-01774-3,
author = {Meister, Sebastian and Wermes, Mahdieu A. M. and St\"{u}ve, Jan and Groves, Roger M.},
title = {Review of image segmentation techniques for layup defect detection in the Automated Fiber Placement process: A comprehensive study to improve AFP inspection},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {8},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01774-3},
doi = {10.1007/s10845-021-01774-3},
abstract = {The aerospace industry has established the Automated Fiber Placement process as a common technique for manufacturing fibre reinforced components. In this process multiple composite tows are placed simultaneously onto a tool. Currently in such processes manual testing requires often up to 50% of the manufacturing duration. Moreover, the accuracy of quality assurance varies significantly with the inspector in charge. Thus, inspection automation provides an effective way to increase efficiency. However, to achieve a proper inspection performance, the segmentation of layup defects need to be examined. In order to improve such defect detection systems, this paper performs a comprehensive ranking of segmentation techniques. Thus, 29 statistical, spectral and structural algorithms from related work were evaluated based on nine substantial criteria as assessed from literature and process requirements. For reasons of determinism and easy technology transferability without the need of much training data, the development of new Machine Learning algorithms is not part of this paper. Afterwards, seven of the most auspicious algorithms were studied experimentally. Therefore, laser line scan sensor depth maps from fibre placement defects were utilised. Furthermore noisy images were generated and applied for testing algorithm robustness. The test data contained five defect categories with 50 samples per class. It was concluded that Adaptive Thresholding and Cell Wise Standard Deviation Thresholding work best yielding detection accuracies mostly &gt;97%. Noteworthy is that influenced input data can affect the detection results. Feasible algorithms with sensible parameter settings were able to perform reliable defect segmentation for layed material.},
journal = {J. Intell. Manuf.},
month = dec,
pages = {2099–2119},
numpages = {21},
keywords = {Image segmentation, Automated fiber placement, Inline inspection, Adaptive thresholding, Computer vision, Laser line scan sensor}
}

@inproceedings{10.1007/978-3-030-11018-5_35,
author = {Dong, Xinghui and Taylor, Chris J. and Cootes, Tim F.},
title = {Small Defect Detection Using Convolutional Neural Network Features and Random Forests},
year = {2018},
isbn = {978-3-030-11017-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-11018-5_35},
doi = {10.1007/978-3-030-11018-5_35},
abstract = {We address the problem of identifying small abnormalities in an imaged region, important in applications such as industrial inspection. The goal is to label the pixels corresponding to a defect with a minimum of false positives. A common approach is to run a sliding-window classifier over the image. Recent Fully Convolutional Networks (FCNs), such as U-Net, can be trained to identify pixels corresponding to abnormalities given a suitable training set. However in many application domains it is hard to collect large numbers of defect examples (by their nature they are rare). Although U-Net can work in this scenario, we show that better results can be obtained by replacing the final softmax layer of the network with a Random Forest (RF) using features sampled from the earlier network layers. We also demonstrate that rather than just thresholding the resulting probability image to identify defects it is better to compute Maximally Stable Extremal Regions (MSERs). We apply the approach to the challenging problem of identifying defects in radiographs of aerospace&nbsp;welds.},
booktitle = {Computer Vision – ECCV 2018 Workshops: Munich, Germany, September 8-14, 2018, Proceedings, Part IV},
pages = {398–412},
numpages = {15},
keywords = {Defect detection, Non-destructive evaluation, CNN, Local features, Random Forests},
location = {Munich, Germany}
}

@inproceedings{10.1145/2499777.2499779,
author = {Antkiewicz, Micha\l{} and B\k{a}k, Kacper and Murashkin, Alexandr and Olaechea, Rafael and Liang, Jia Hui (Jimmy) and Czarnecki, Krzysztof},
title = {Clafer tools for product line engineering},
year = {2013},
isbn = {9781450323253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499777.2499779},
doi = {10.1145/2499777.2499779},
abstract = {Clafer is a lightweight yet expressive language for structural modeling: feature modeling and configuration, class and object modeling, and metamodeling. Clafer Tools is an integrated set of tools based on Clafer. In this paper, we describe some product-line variability modeling scenarios of Clafer Tools from the viewpoints of product-line owner, product-line engineer, and product engineer.},
booktitle = {Proceedings of the 17th International Software Product Line Conference Co-Located Workshops},
pages = {130–135},
numpages = {6},
keywords = {Clafer, ClaferIG, ClaferMOO, ClaferMOO visualizer, ClaferWiki, clafer configurator},
location = {Tokyo, Japan},
series = {SPLC '13 Workshops}
}

@inproceedings{10.1145/3478905.3478914,
author = {Jia, Beini and Luo, Xin and Tao, Ran and Shi, Youqun},
title = {Surface Defect Detection of Aluminum Material Based on HRNet Feature Extraction},
year = {2021},
isbn = {9781450390248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478905.3478914},
doi = {10.1145/3478905.3478914},
booktitle = {2021 4th International Conference on Data Science and Information Technology},
pages = {44–48},
numpages = {5},
keywords = {Aluminum material defects, Deep learning, Deformable Convolution, HRNet Network},
location = {Shanghai, China},
series = {DSIT 2021}
}

@article{10.1007/s00521-020-04819-5,
author = {Chen, Haiyong and Hu, Qidi and Zhai, Baoshuo and Chen, He and Liu, Kun},
title = {A robust weakly supervised learning of deep Conv-Nets for surface defect inspection},
year = {2020},
issue_date = {Aug 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {15},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04819-5},
doi = {10.1007/s00521-020-04819-5},
abstract = {Automatic defect detection is a challenging task owing to the complex textured background with non-uniform intensity distribution, weak differences between defects and background, diversity of defect types, and high cost of annotated samples. In order to solve these challenges, this paper proposes a novel end-to-end defect classification and segmentation framework based on weakly supervised learning of a convolutional neural network (CNN) with attention architecture. Firstly, a novel end-to-end CNN architecture integrating the robust classifier and spatial attention module is proposed to enhance defect feature representation ability, which significantly improves the classification accuracy. Secondly, a new spatial attention class activation map (SA-CAM) is proposed to improve segmentation adaptability by generating more accurate heatmap. Moreover, for different surface texture, SA-CAM can significantly suppress the background’s inference and highlight defect area. Finally, the proposed weakly supervised learning framework is trained using only global image labels and devoted to two main visual recognition tasks: defect samples classification and area segmentation. At the same time, it is robust to complex backgrounds. Results of the experiments verify the generalization of the proposed method on three distinct datasets with different kinds of textures and backgrounds. In the classification tasks, the proposed method improves accuracy by 0.66–25.50%. In the segmentation tasks, the proposed method improves accuracy by 5.49–7.07%.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {11229–11244},
numpages = {16},
keywords = {Machine vision, Spatial attention, Deep learning, Defect detection, Convolutional neural network}
}

@article{10.1007/s10664-012-9218-8,
author = {Okutan, Ahmet and Y\i{}ld\i{}z, Olcay Taner},
title = {Software defect prediction using Bayesian networks},
year = {2014},
issue_date = {February  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-012-9218-8},
doi = {10.1007/s10664-012-9218-8},
abstract = {There are lots of different software metrics discovered and used for defect prediction in the literature. Instead of dealing with so many metrics, it would be practical and easy if we could determine the set of metrics that are most important and focus on them more to predict defectiveness. We use Bayesian networks to determine the probabilistic influential relationships among software metrics and defect proneness. In addition to the metrics used in Promise data repository, we define two more metrics, i.e. NOD for the number of developers and LOCQ for the source code quality. We extract these metrics by inspecting the source code repositories of the selected Promise data repository data sets. At the end of our modeling, we learn the marginal defect proneness probability of the whole software system, the set of most effective metrics, and the influential relationships among metrics and defectiveness. Our experiments on nine open source Promise data repository data sets show that response for class (RFC), lines of code (LOC), and lack of coding quality (LOCQ) are the most effective metrics whereas coupling between objects (CBO), weighted method per class (WMC), and lack of cohesion of methods (LCOM) are less effective metrics on defect proneness. Furthermore, number of children (NOC) and depth of inheritance tree (DIT) have very limited effect and are untrustworthy. On the other hand, based on the experiments on Poi, Tomcat, and Xalan data sets, we observe that there is a positive correlation between the number of developers (NOD) and the level of defectiveness. However, further investigation involving a greater number of projects is needed to confirm our findings.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {154–181},
numpages = {28},
keywords = {Bayesian networks, Defect prediction}
}

@article{10.1016/j.cosrev.2020.100341,
author = {Kotsiopoulos, Thanasis and Sarigiannidis, Panagiotis and Ioannidis, Dimosthenis and Tzovaras, Dimitrios},
title = {Machine Learning and Deep Learning in smart manufacturing: The Smart Grid paradigm},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2020.100341},
doi = {10.1016/j.cosrev.2020.100341},
journal = {Comput. Sci. Rev.},
month = may,
numpages = {25},
keywords = {Industry 4.0, Machine Learning, Deep Learning, Industrial AI, Smart Grid}
}

@article{10.1007/s13319-019-0215-1,
author = {Deotale, Nilesh Tejram and Sarode, Tanuja K.},
title = {Fabric Defect Detection Adopting Combined GLCM, Gabor Wavelet Features and Random Decision Forest},
year = {2019},
issue_date = {March     2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {10},
number = {1},
issn = {2092-6731},
url = {https://doi.org/10.1007/s13319-019-0215-1},
doi = {10.1007/s13319-019-0215-1},
journal = {3D Res.},
month = mar,
articleno = {215},
numpages = {13},
keywords = {Fabric defect detection, Feature extraction, GLCM, Gabor wavelet, Random decision forest}
}

@article{10.1145/3442181,
author = {Sabir, Bushra and Ullah, Faheem and Babar, M. Ali and Gaire, Raj},
title = {Machine Learning for Detecting Data Exfiltration: A Review},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442181},
doi = {10.1145/3442181},
abstract = {Context: Research at the intersection of cybersecurity, Machine Learning (ML), and Software Engineering (SE) has recently taken significant steps in proposing countermeasures for detecting sophisticated data exfiltration attacks. It is important to systematically review and synthesize the ML-based data exfiltration countermeasures for building a body of knowledge on this important topic. Objective: This article aims at systematically reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches, feature engineering techniques, evaluation datasets, and performance metrics used for these countermeasures. This review also aims at identifying gaps in research on ML-based data exfiltration countermeasures. Method: We used Systematic Literature Review (SLR) method to select and review 92 papers. Results: The review has enabled us to: (a) classify the ML approaches used in the countermeasures into data-driven, and behavior-driven approaches; (b) categorize features into six types: behavioral, content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance measures used by these studies. Conclusion: We conclude that: (i) The integration of data-driven and behavior-driven approaches should be explored; (ii) There is a need of developing high quality and large size evaluation datasets; (iii) Incremental ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial learning should be considered and explored during the development of countermeasures to avoid poisoning attacks; and (v) The use of automated feature engineering should be encouraged for efficiently detecting data exfiltration attacks.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {50},
numpages = {47},
keywords = {Data exfiltration, advanced persistent threat, data breach, data leakage, machine learning}
}

@article{10.1016/j.is.2015.02.006,
author = {Siers, Michael J. and Islam, Md Zahidul},
title = {Software defect prediction using a cost sensitive decision forest and voting, and a potential solution to the class imbalance problem},
year = {2015},
issue_date = {July 2015},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {51},
number = {C},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2015.02.006},
doi = {10.1016/j.is.2015.02.006},
abstract = {Software development projects inevitably accumulate defects throughout the development process. Due to the high cost that defects can incur, careful consideration is crucial when predicting which sections of code are likely to contain defects. Classification algorithms used in machine learning can be used to create classifiers which can be used to predict defects. While traditional classification algorithms optimize for accuracy, cost-sensitive classification methods attempt to make predictions which incur the lowest classification cost. In this paper we propose a cost-sensitive classification technique called CSForest which is an ensemble of decision trees. We also propose a cost-sensitive voting technique called CSVoting in order to take advantage of the set of decision trees in minimizing the classification cost. We then investigate a potential solution to class imbalance within our decision forest algorithm. We empirically evaluate the proposed techniques comparing them with six (6) classifier algorithms on six (6) publicly available clean datasets that are commonly used in the research on software defect prediction. Our initial experimental results indicate a clear superiority of the proposed techniques over the existing ones. Author-HighlightsSDP is short for Software Defect Prediction.We show that there is not a clear winner in the studied existing methods for SDP*.A cost-sensitive decision forest and voting technique are proposed.The superiority of the proposed techniques is shown.A proposed framework for the forest algorithm for handling class imbalance.},
journal = {Inf. Syst.},
month = jul,
pages = {62–71},
numpages = {10},
keywords = {Class imbalance, Cost-sensitive, Decision forest, Forest voting, Software defect prediction}
}

@article{10.1007/s00138-021-01177-7,
author = {Xiao, Maohua and Wang, Weichen and Shen, Xiaojie and Zhu, Yue and Bartos, Petr and Yiliyasi, Yilidaer},
title = {Research on defect detection method of powder metallurgy gear based on machine vision},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {2},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-021-01177-7},
doi = {10.1007/s00138-021-01177-7},
abstract = {Powder metallurgy gears are often accompanied by broken teeth, abrasion, scratches and crack defects. In order to eliminate the defective gears in gear production and improve the yield of gears, this paper presents an improved GA–PSO algorithm, called the SHGA–PSO algorithm. Firstly, the gear images were preprocessed by bilateral filtering, and the images were segmented by the Sobel operator. Then, the geometrical shape, texture feature and color features of the sample were extracted. Next, the BP neural network was reconstructed and SHGA–PSO algorithm was used optimize its structure and weights. Finally, four different gear defect samples were brought into the neural network for calculation, and the performance of the SHGA–PSO algorithm was compared with the GA, PSO and GA–PSO algorithms. Compared with GA–BP algorithm, PSO–BP algorithm, and GA–PSO–BP algorithm, the defect diagnosis of SHGA–PSO–BP algorithm not only enhanced generalization ability, but also improved recognition accuracy.},
journal = {Mach. Vision Appl.},
month = mar,
numpages = {13},
keywords = {Machine vision, Gear defect, Image segmentation, Feature extraction, Detection and recognition}
}

@article{10.5555/3057337.3057441,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {A decision tree logic based recommendation system to select software fault prediction techniques},
year = {2017},
issue_date = {March     2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {99},
number = {3},
issn = {0010-485X},
abstract = {Identifying a reliable fault prediction technique is the key requirement for building effective fault prediction model. It has been found that the performance of fault prediction techniques is highly dependent on the characteristics of the fault dataset. To mitigate this issue, researchers have evaluated and compared a plethora of fault prediction techniques by varying the context in terms of domain information, characteristics of input data, complexity, etc. However, the lack of an accepted benchmark makes it difficult to select fault prediction technique for a particular context of prediction. In this paper, we present a recommendation system that facilitates the selection of appropriate technique(s) to build fault prediction model. First, we have reviewed the literature to elicit the various characteristics of the fault dataset and the appropriateness of the machine learning and statistical techniques for the identified characteristics. Subsequently, we have formalized our findings and built a recommendation system that helps in the selection of fault prediction techniques. We performed an initial appraisal of our presented system and found that proposed recommendation system provides useful hints in the selection of the fault prediction techniques.},
journal = {Computing},
month = mar,
pages = {255–285},
numpages = {31},
keywords = {68N30 Mathematical aspects of software engineering (specification, Decision tree, Recommendation system, Software fault prediction, Software fault prediction techniques, etc.), metrics, requirements, verification}
}

@article{10.1504/ijics.2020.105155,
author = {Pinto, Joey and Jain, Pooja and Kumar, Tapan},
title = {Fault prediction for distributed computing Hadoop clusters using real-time higher order differential inputs to SVM: Zedacross},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {2–3},
issn = {1744-1765},
url = {https://doi.org/10.1504/ijics.2020.105155},
doi = {10.1504/ijics.2020.105155},
abstract = {Hadoop distributed computing clusters are used worldwide for high-performance computations. Often various hardware and software faults occur, leading to both data and computation time losses. This paper proposes the usage of a fault prediction software called 'Zedacross' which uses machine learning principles combined with cluster monitoring tools. Firstly, the paper suggests a model that uses the resource usage statistics of a normally functioning Hadoop cluster to create a machine learning model that can then be used to predict and detect faults in real time. Secondly, the paper explains the novel idea of using higher order differentials as inputs to SVM for highly accurate fault predictions. Predictions of system faults by observing system resource usage statistics in real-time with minimum delay will play a vital role in deciding the need for job rescheduling tasks or even dynamic up-scaling of the cluster. To demonstrate the effectiveness of the design a Java utility was built to perform cluster fault monitoring. The results obtained after running the system on various test cases demonstrate that the proposed method is accurate and effective.},
journal = {Int. J. Inf. Comput. Secur.},
month = jan,
pages = {181–198},
numpages = {17},
keywords = {fault prediction, Ganglia, Hadoop, higher order differential, SVM}
}

@article{10.1504/IJBIC.2018.092808,
title = {An improved twin support vector machine based on multi-objective cuckoo search for software defect prediction},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {11},
number = {4},
issn = {1758-0366},
url = {https://doi.org/10.1504/IJBIC.2018.092808},
doi = {10.1504/IJBIC.2018.092808},
abstract = {Recently, software defect prediction SDP has drawn much attention as software size becomes larger and consumers hold higher reliability expectations. The premise of SDP is to guide the detection of software bugs and to conserve computational resources. However, in prior research, data imbalances among software defect modules were largely ignored to focus instead on how to improve defect prediction accuracy. In this paper, a novel SDP model based on twin support vector machines TSVM and a multi-objective cuckoo search MOCS is proposed, called MOCSTSVM. We set the probability of detection and the probability of false alarm as the SDP objectives. We use TSVM to predict defected modules and employ MOCS to optimise TSVM for this dual-objective optimisation problem. To test our approach, we conduct a series of experiments on a public dataset from the PROMISE repository. The experimental results demonstrate that our approach achieves good performance compared with other SDP models.},
journal = {Int. J. Bio-Inspired Comput.},
month = jan,
pages = {282–291},
numpages = {10}
}

@article{10.5555/3271870.3271878,
title = {Software fault prediction using firefly algorithm},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {6},
number = {3–4},
issn = {1758-8715},
abstract = {The software fault prediction SFP literature has shown an immense growth of the research studies involving the artificial neural network ANN based fault prediction models. However, the default gradient descent back propagation neural networks BPNNs have a high risk of getting stuck in the local minima of the search space. A class of nature inspired computing methods overcomes this disadvantage of BPNNs and has helped ANNs to evolve into a class of adaptive ANN. In this work, we propose a hybrid SFP model built using firefly algorithm FA and artificial neural network ANN, along with an empirical comparison with GA and PSO based evolutionary methods in optimising the connection weights of ANN. Seven different datasets were involved and MSE and the confusion matrix parameters were used for performance evaluation. The results have shown that FA-ANN model has performed better than the genetic and particle swarm optimised ANN fault prediction models.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {356–377},
numpages = {22}
}

@inproceedings{10.1145/3439961.3439979,
author = {Santos, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
title = {Predicting Software Defects with Explainable Machine Learning},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439979},
doi = {10.1145/3439961.3439979},
abstract = {Most software systems must evolve to cope with stakeholders’ requirements and fix existing defects. Hence, software defect prediction represents an area of interest in both academia and the software industry. As a result, predicting software defects can help the development team to maintain substantial levels of software quality. For this reason, machine learning models have increased in popularity for software defect prediction and have demonstrated effectiveness in many scenarios. In this paper, we evaluate a machine learning approach for selecting features to predict software module defects. We use a tree boosting algorithm that receives as input a training set comprising records of software features encoding characteristics of each module and outputs whether the corresponding module is defective prone. For nine projects within the widely known NASA data program, we build prediction models from a set of easy-to-compute module features. We then sample this sizable model space by randomly selecting software features to compose each model. This significant number of models allows us to structure our work along model understandability and predictive accuracy. We argue that explaining model predictions is meaningful to provide information to developers on features related to each module defective-prone. We show that (i) features that contribute most to finding the best models may vary depending on the project, and (ii) effective models are highly understandable based on a survey with 40 developers.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {18},
numpages = {10},
keywords = {NASA datasets, SHAP values, explainable models, software defects},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@article{10.1155/2021/5553470,
author = {Xue, Bin and Wu, Zhisheng and Wu, Wenqing},
title = {Key Technologies of Steel Plate Surface Defect Detection System Based on Artificial Intelligence Machine Vision},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/5553470},
doi = {10.1155/2021/5553470},
abstract = {With the rapid development of visual inspection technology, computer technology, and image processing technology, machine vision technology has become more and more mature, and the role of quality inspection and control in the steel industry is becoming more and more obvious and important. Defects on the surface of the strip are a key factor affecting the quality inspection process. Its inspection plays an extremely important role in improving the final quality. For a long time, traditional manual inspection methods cannot meet actual production needs, so in-depth research on steel surface defect inspection systems has become the consensus of today’s steel companies. The accuracy and low performance of traditional detection methods can no longer meet the needs of people and society. The surface defect detection method based on machine vision has the characteristics of high accuracy, fast processing speed, and intelligent processing, which is the main trend of surface defect detection. We select a steel plate; take the invariant moment features of the cracks, holes, scratches, oil stains, and other images on it; extract the data results; and analyze them. Then, we read the texture features of these defect images again, extract the data results, and analyze them. The experimental results prove that after the mean value filter and Gaussian filter process the image, the mean variance value MSE is relatively large (46.276&gt;31.2271), and as the concentration of salt and pepper noise increases, the rate of increase of MSE increases obviously, and as the peak signal-to-noise ratio and the mean variance value MSE increase continuously (32.2271&lt;33.3695), the image distortion is more serious. The method designed in this paper is extremely effective. Improving the surface quality of steel is of great significance to improving market competitiveness.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {12}
}

@inproceedings{10.1145/2491411.2494581,
author = {Zhang, Hongyu and Cheung, S. C.},
title = {A cost-effectiveness criterion for applying software defect prediction models},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2494581},
doi = {10.1145/2491411.2494581},
abstract = {Ideally, software defect prediction models should help organize software quality assurance (SQA) resources and reduce cost of finding defects by allowing the modules most likely to contain defects to be inspected first. In this paper, we study the cost-effectiveness of applying defect prediction models in SQA and propose a basic cost-effectiveness criterion. The criterion implies that defect prediction models should be applied with caution. We also propose a new metric FN/(FN+TN) to measure the cost-effectiveness of a defect prediction model.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {643–646},
numpages = {4},
keywords = {Defect prediction, cost effectiveness, evaluation metrics},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@article{10.1007/s10044-017-0640-9,
author = {Gaidhane, Vilas H. and Hote, Yogesh V. and Singh, Vijander},
title = {An efficient similarity measure approach for PCB surface defect detection},
year = {2018},
issue_date = {February  2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {1},
issn = {1433-7541},
url = {https://doi.org/10.1007/s10044-017-0640-9},
doi = {10.1007/s10044-017-0640-9},
abstract = {In this paper, an efficient similarity measure method is proposed for printed circuit board (PCB) surface defect detection. The advantage of the presented approach is that the measurement of similarity between the scene image and the reference image of PCB surface is taken without computing image features such as eigenvalues and eigenvectors. In the proposed approach, a symmetric matrix is calculated using the companion matrices of two compared images. Further, the rank of a symmetric matrix is used as similarity measure metric for defect detection. The numerical value of rank is zero for the defectless images and distinctly large for defective images. It is reliable and well tolerated to local variations and misalignment. The various experiments are carried out on the different PCB images. Moreover, the presented approach is tested in the presence of varying illumination and noise effect. Experimental results have shown the effectiveness of the proposed approach for detecting and locating the local defects in a complicated component-mounted PCB images.},
journal = {Pattern Anal. Appl.},
month = feb,
pages = {277–289},
numpages = {13},
keywords = {Companion matrix, Defect detection, Polynomial coefficient, Printed circuit board, Rank, Similarity measure}
}

@article{10.3233/JIFS-179459,
author = {Bashir, Kamal and Li, Tianrui and Yohannese, Chubato Wondaferaw and Yahaya, Mahama and Kahraman, Cengiz},
title = {SMOTEFRIS-INFFC: Handling the challenge of borderline and noisy examples in imbalanced learning for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {38},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-179459},
doi = {10.3233/JIFS-179459},
abstract = {The object of Software Defect Prediction (SDP) is to identify modules that are prone to defect. This is achieved by training prediction models with datasets obtained by mining software historical depositories. When one acquires data through this approach, it often includes class imbalance which has an unequal class representation among their example. We hypothesize that the imbalance learning is not a problem in itself and decrease in performance is also influenced by other factors related to class distribution in the data. One of these is the existence of noisy and borderline examples. Thus, the objective of our research is to propose a novel preprocessing method using Synthetic Minority Over-Sampling Technique (SMOTE), Fuzzy-rough Instance Selection type II (FRIS-II) and Iterative Noise Filter based on the Fusion of Classifiers (INFFC) which can overcome these problems. The experimental results show that the new proposal significantly outperformed all the methods compared in this study.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {917–933},
numpages = {17},
keywords = {Software defect prediction, data sampling, fuzzy rough set, noise filtering}
}

@inproceedings{10.1145/3297280.3297411,
author = {Leotta, Maurizio and Olianas, Dario and Ricca, Filippo and Noceti, Nicoletta},
title = {How do implementation bugs affect the results of machine learning algorithms?},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297411},
doi = {10.1145/3297280.3297411},
abstract = {Applications based on Machine learning (ML) are growing in popularity in a multitude of different contexts such as medicine, bioinformatics, and finance. However, there is a lack of established approaches and strategies able to assure the reliability of this category of software. This has a big impact since nowadays our society relies on (potentially) unreliable applications that could cause, in extreme cases, catastrophic events (e.g., loss of life due to a wrong diagnosis of an ML-based cancer classifier).In this paper, as a preliminary step towards providing a solution to this big problem, we used automatic mutations to mimic realistic bugs in the code of two machine learning algorithms, Multilayer Perceptron and Logistic Regression, with the goal of studying the impact of implementation bugs on their behaviours.Unexpectedly, our experiments show that about 2/3 of the injected bugs are silent since they does not influence the results of the algorithms, while the bugs emerge as runtime errors, exceptions, or modified accuracy of the predictions only in the remaining cases. Moreover, we also discovered that about 1% of the bugs are extremely dangerous since they drastically affect the quality of the prediction only in rare cases and with specific datasets increasing the possibility of going unnoticed.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1304–1313},
numpages = {10},
keywords = {Oracle problem, accuracy, bug, machine learning, software quality assurance, testing},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/2875913.2875944,
author = {Qing, He and Biwen, Li and Beijun, Shen and Xia, Yong},
title = {Cross-Project Software Defect Prediction Using Feature-Based Transfer Learning},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875944},
doi = {10.1145/2875913.2875944},
abstract = {Cross-project defect prediction is taken as an effective means of predicting software defects when the data shortage exists in the early phase of software development. Unfortunately, the precision of cross-project defect prediction is usually poor, largely because of the differences between the reference and the target projects. Having realized the project differences, this paper proposes CPDP, a feature-based transfer learning approach to cross-project defect prediction. The core insight of CPDP is to (1) filter and transfer highly-correlated data based on data samples in the target projects, and (2) evaluate and choose learning schemas for transferring data sets. Models are then built for predicting defects in the target projects. We have also conducted an evaluation of the proposed approach on PROMISE datasets. The evaluation results show that, the proposed approach adapts to cross-project defect prediction in that f-measure of 81.8% of projects can get improved, and AUC of 54.5% projects improved. It also achieves similar f-measure and AUC as some inner-project defect prediction approaches.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {74–82},
numpages = {9},
keywords = {cross-project defect prediction, feature-based transfer, transfer learning},
location = {Wuhan, China},
series = {Internetware '15}
}

@article{10.1007/s10586-021-03282-8,
author = {Mustaqeem, Mohd. and Saqib, Mohd.},
title = {Principal component based support vector machine (PC-SVM): a hybrid technique for software defect detection},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-021-03282-8},
doi = {10.1007/s10586-021-03282-8},
abstract = {Defects are the major problems in the current situation and predicting them is also a difficult task. Researchers and scientists have developed many software defects prediction techniques to overcome this very helpful issue. But to some extend there is a need for an algorithm/method to predict defects with more accuracy, reduce time and space complexities. All the previous research conducted on the data without feature reduction lead to the curse of dimensionality. We brought up a machine learning hybrid approach by combining Principal component Analysis (PCA) and Support vector machines (SVM) to overcome the ongoing problem. We have employed PROMISE (CM1: 344 observations, KC1: 2109 observations) data from the directory of NASA to conduct our research. We split the dataset into training (CM1: 240 observations, KC1: 1476 observations) dataset and testing (CM1: 104 observations, KC1: 633 observations) datasets. Using PCA, we find the principal components for feature optimization which reduce the time complexity. Then, we applied SVM for classification due to very native qualities over traditional and conventional methods. We also employed the GridSearchCV method for hyperparameter tuning. In the proposed hybrid model we have found better accuracy (CM1: 95.2%, KC1: 86.6%) than other methods. The proposed model also presents higher evaluation in the terms of other criteria. As a limitation, the only problem with SVM is there is no probabilistic explanation for classification which may very rigid towards classifications. In the future, some other method may also introduce which can overcome this limitation and keep a soft probabilistic based margin for classification on the optimal hyperplane.},
journal = {Cluster Computing},
month = sep,
pages = {2581–2595},
numpages = {15},
keywords = {Software defects detection, PCA, SVM, Feature optimization, Classification, PROMISE dataset}
}

@inproceedings{10.1109/ICMLA.2014.63,
author = {Coelho, Rodrigo A. and Guimar\~{a}es, Fabr\'{\i}cio dos R. N. and Esmin, Ahmed A. A.},
title = {Applying Swarm Ensemble Clustering Technique for Fault Prediction Using Software Metrics},
year = {2014},
isbn = {9781479974153},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2014.63},
doi = {10.1109/ICMLA.2014.63},
abstract = {Number of defects remaining in a system provides an insight into the quality of the system. Defect detection systems predict defects by using software metrics and data mining techniques. Clustering analysis is adopted to build the software defect prediction models. Cluster ensembles have emerged as a prominent method for improving robustness, stability and accuracy of clustering solutions. The clustering ensembles combine multiple partitions generated by different clustering algorithms into a single clustering solution. In this paper, the clustering ensemble using Particle Swarm Optimization algorithm (PSO) solution is proposed to improve the prediction quality. An empirical study shows that the PSO can be a good choice to build defect prediction software models.},
booktitle = {Proceedings of the 2014 13th International Conference on Machine Learning and Applications},
pages = {356–361},
numpages = {6},
keywords = {Cluster data, Ensemble clustering, Particle swarm optimization, Software defect prediction},
series = {ICMLA '14}
}

@article{10.1016/j.engappai.2019.01.008,
author = {Wei, Xiukun and Yang, Ziming and Liu, Yuxin and Wei, Dehua and Jia, Limin and Li, Yujie},
title = {Railway track fastener defect detection based on image processing and deep learning techniques: A comparative study},
year = {2019},
issue_date = {Apr 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {80},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2019.01.008},
doi = {10.1016/j.engappai.2019.01.008},
journal = {Eng. Appl. Artif. Intell.},
month = apr,
pages = {66–81},
numpages = {16},
keywords = {Track fastener, Detection, Image processing, Deep learning, Feature extraction, DCNN, Faster R-CNN}
}

@article{10.1007/s10796-013-9430-0,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan and Napolitano, Amri and Wald, Randall},
title = {A comparative study of iterative and non-iterative feature selection techniques for software defect prediction},
year = {2014},
issue_date = {November  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {5},
issn = {1387-3326},
url = {https://doi.org/10.1007/s10796-013-9430-0},
doi = {10.1007/s10796-013-9430-0},
abstract = {Two important problems which can affect the performance of classification models are high-dimensionality (an overabundance of independent features in the dataset) and imbalanced data (a skewed class distribution which creates at least one class with many fewer instances than other classes). To resolve these problems concurrently, we propose an iterative feature selection approach, which repeated applies data sampling (in order to address class imbalance) followed by feature selection (in order to address high-dimensionality), and finally we perform an aggregation step which combines the ranked feature lists from the separate iterations of sampling. This approach is designed to find a ranked feature list which is particularly effective on the more balanced dataset resulting from sampling while minimizing the risk of losing data through the sampling step and missing important features. To demonstrate this technique, we employ 18 different feature selection algorithms and Random Undersampling with two post-sampling class distributions. We also investigate the use of sampling and feature selection without the iterative step (e.g., using the ranked list from a single iteration, rather than combining the lists from multiple iterations), and compare these results from the version which uses iteration. Our study is carried out using three groups of datasets with different levels of class balance, all of which were collected from a real-world software system. All of our experiments use four different learners and one feature subset size. We find that our proposed iterative feature selection approach outperforms the non-iterative approach.},
journal = {Information Systems Frontiers},
month = nov,
pages = {801–822},
numpages = {22},
keywords = {Class imbalance, Date sampling, High dimensionality, Iterative feature selection, Software defect prediction}
}

@inproceedings{10.1109/AIM.2018.8452361,
author = {Jung, S. Y. and Tsai, Y.H. and Chiu, W.Y and Hu, J.S. and Sun, C.T.},
title = {Defect Detection on Randomly Textured Surfaces by Convolutional Neural Networks},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AIM.2018.8452361},
doi = {10.1109/AIM.2018.8452361},
abstract = {Automatically detecting the defects on the randomly textured surfaces for industrial purpose is a demanding procedure due to the ambiguity between defects and textures, lack of defect-labeled data and the must-have extreme accuracy. In this paper we proposed a procedure as the beginning of automating the defect detection on woods with randomly textured surfaces by employing 3 different architectures of convolutional neural networks. The deep convolutional neural network resulted in 99.80% accuracy, discriminating among normal wood and the other 4 types of defects images. The models were evaluated and understood by visualizing the saliency maps. The results from our work implies that other industrial images with defects on randomly textured surfaces may apply the similar procedures to accelerate the automating of defect detection and progressing of industry 4.0.},
booktitle = {2018 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)},
pages = {1456–1461},
numpages = {6},
location = {Auckland, New Zealand}
}

@article{10.4018/ijssci.2014040101,
author = {Mishra, Bharavi and Shukla, K.K.},
title = {Software Defect Prediction Based on GUHA Data Mining Procedure and Multi-Objective Pareto Efficient Rule Selection},
year = {2014},
issue_date = {April 2014},
publisher = {IGI Global},
address = {USA},
volume = {6},
number = {2},
issn = {1942-9045},
url = {https://doi.org/10.4018/ijssci.2014040101},
doi = {10.4018/ijssci.2014040101},
abstract = {Software defect prediction, if is effective, enables the developers to distribute their testing efforts efficiently and let them focus on defect prone modules. It would be very resource consuming to test all the modules while the defect lies in fraction of modules. Information about fault-proneness of classes and methods can be used to develop new strategies which can help mitigate the overall development cost and increase the customer satisfaction. Several machine learning strategies have been used in recent past to identify defective modules. These models are built using publicly available historical software defect data sets. Most of the proposed techniques are not able to deal with the class imbalance problem efficiently. Therefore, it is necessary to develop a prediction model which consists of small simple and comprehensible rules. Considering these facts, in this paper, the authors propose a novel defect prediction approach named GUHA based Classification Association Rule Mining algorithm G-CARM where "GUHA" stands for General Unary Hypothesis Automaton. G-CARM approach is primarily based on Classification Association Rule Mining, and deploys a two stage process involving attribute discretization, and rule generation using GUHA. GUHA is oldest yet very powerful method of pattern mining. The basic idea of GUHA procedure is to mine the interesting attribute patterns that indicate defect proneness. The new method has been compared against five other models reported in recent literature viz. Naive Bayes, Support Vector Machine, RIPPER, J48 and Nearest Neighbour classifier by using several measures, including AUC and probability of detection. The experimental results indicate that the prediction performance of G-CARM approach is better than other prediction approaches. The authors' approach achieved 76% mean recall and 83% mean precision for defective modules and 93% mean recall and 83% mean precision for non-defective modules on CM1, KC1, KC2 and Eclipse data sets. Further defect rule generation process often generates a large number of rules which require considerable efforts while using these rules as a defect predictor, hence, a rule sub-set selection process is also proposed to select best set of rules according to the requirements. Evolution criteria for defect prediction like sensitivity, specificity, precision often compete against each other. It is therefore, important to use multi-objective optimization algorithms for selecting prediction rules. In this paper the authors report prediction rules that are Pareto efficient in the sense that no further improvements in the rule set is possible without sacrificing some performance criteria. Non-Dominated Sorting Genetic Algorithm has been used to find Pareto front and defect prediction rules.},
journal = {Int. J. Softw. Sci. Comput. Intell.},
month = apr,
pages = {1–29},
numpages = {29},
keywords = {Data Mining, Defect Patterns, Fault Prediction, General Unary Hypothesis Automaton GUHA, Pareto Optimality}
}

@inproceedings{10.1145/3360322.3360835,
author = {Li, Xiaoxia and Li, Wei and Yang, Qiang and Yan, Wenjun and Zomaya, Albert Y.},
title = {Building an Online Defect Detection System for Large-scale Photovoltaic Plants},
year = {2019},
isbn = {9781450370059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3360322.3360835},
doi = {10.1145/3360322.3360835},
abstract = {The power efficiency of photovoltaic modules is highly correlated with their health status. Under dynamically changing environments, photovoltaic defects could spontaneously form and develop into fatal faults during the daily operation of photovoltaic plants. To facilitate defect detection with less human intervention, a nondestructive and contactless visual inspection system with the help of unmanned aerial vehicles and edge computing is proposed in this work. Limited by the resources of edge devices and the availability of images of photovoltaic defects for training, we developed an online solution combined with deep learning, data argumentation and transfer learning to properly address the issues of running resource hungry applications on edge devices and lack of training samples faced by the deep learning approaches used in the field. With the reduction of the network depth of the deep convolutional neural network model and the transfer of features from the learned defects, the resource consumption of our proposed approach is significantly reduced, and thus can be used on a wide range of edge devices to complete defect detection in a timely manner with high accuracy. To study the performance of our design, a testbed was built from open source hardware and software, and field trials were carried out in three photovoltaic plants. The experimental results clearly demonstrate the practicality and effectiveness of our design for detecting visible defects on photovoltaic modules.},
booktitle = {Proceedings of the 6th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {253–262},
numpages = {10},
keywords = {classification, cyber-physical systems, defects detection, edge computing, transfer learning},
location = {New York, NY, USA},
series = {BuildSys '19}
}

@inproceedings{10.1007/978-3-030-69449-4_14,
author = {J\"{o}chl, Robert and Uhl, Andreas},
title = {A Machine Learning Approach to Approximate the Age of a Digital Image},
year = {2020},
isbn = {978-3-030-69448-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-69449-4_14},
doi = {10.1007/978-3-030-69449-4_14},
abstract = {In-field image sensor defects develop almost continually over a camera’s lifetime. Since these defects accumulate over time, a forensic analyst can approximate the age of an image under investigation based on the defects present. In this context, the temporal accuracy of the approximation is bounded by the different defect onset times. Thus, the approximation of the image age based on in-field sensor defects can be regarded as a multi-class classification problem. In this paper, we propose to utilize two well-known machine learning techniques (i.e. a Naive Bayes Classifier and a Support Vector Machine) to solve this problem. The accuracy of each technique is empirically evaluated by conducting several experiments, and the results are compared to the current state-of-the art in this field. In addition, the prediction results are assessed individually for each class.},
booktitle = {Digital Forensics and Watermarking: 19th International Workshop, IWDW 2020, Melbourne, VIC, Australia, November 25–27, 2020, Revised Selected Papers},
pages = {181–195},
numpages = {15},
keywords = {Digital image forensics, In-field sensor defects, Image age approximation, Machine learning},
location = {Melbourne, VIC, Australia}
}

@inproceedings{10.1145/3358331.3358376,
author = {Easttom, Chuck},
title = {A Methodological Approach to Weaponizing Machine Learning},
year = {2019},
isbn = {9781450372022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358331.3358376},
doi = {10.1145/3358331.3358376},
abstract = {The current literature is replete with studies involving the use of machine learning algorithms for defensive security implementations. For example, machine learning has been utilized to enhance antivirus software and intrusion detection systems. The use of machine learning in defensive cybersecurity operations is well documented. However, there is a substantial gap in the literature on the offensive use of machine learning. Particularly, use of machine learning algorithms to enhance cyber warfare operations. Cyber components to modern conflicts, whether those conflicts are cyber or kinetic warfare, are a fact of the modern international political landscape. It is a natural progression to explore applications of machine learning to cyber warfare, particularly weaponized malware.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Advanced Manufacturing},
articleno = {45},
numpages = {5},
keywords = {Weaponized malware, cyber warfare, machine learning, weaponized malware},
location = {Dublin, Ireland},
series = {AIAM 2019}
}

@article{10.1155/2021/9870129,
author = {Guo, Kehua and Tan, Zhiyuan and Luo, Entao and Zhou, Xiaokang},
title = {Machine Learning: The Cyber-Security, Privacy, and Public Safety Opportunities and Challenges for Emerging Applications},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/9870129},
doi = {10.1155/2021/9870129},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {2}
}

@inproceedings{10.1109/ITSC48978.2021.9564437,
author = {Shi, Xiaojie and Dai, Shenghua},
title = {Fault Prediction of Turnout Equipment Based on Double-layer Gated Recurrent Unit Neural Network},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC48978.2021.9564437},
doi = {10.1109/ITSC48978.2021.9564437},
abstract = {Turnout is an important railway equipment, and the failure of the turnout equipment will have a great impact on the safe operation of the train. In order to predict the failure of the turnout equipment in advance, this paper combines the double-layer gated recurrent unit (DL-GRU) neural network with the failure prediction of the turnout. This paper extracts the features of the current curves generated during multiple actions before the turnout fails, and uses the method of kernel principal component analysis (KPCA) to reduce the dimensions of the extracted features. Finally, the time series data set of turnout action current fault feature is established, which is used as the input of the DL-GRU neural network to realize the fault prediction of the turnout. The simulation results show that the DL-GRU network has a high prediction accuracy, compared with LSTM network and single-layer GRU neural network, the DL-GRU has better prediction performance.},
booktitle = {2021 IEEE International Intelligent Transportation Systems Conference (ITSC)},
pages = {2336–2341},
numpages = {6},
location = {Indianapolis, IN, USA}
}

@inproceedings{10.1145/2851613.2851788,
author = {das D\^{o}res, Silvia N. and Alves, Luciano and Ruiz, Duncan D. and Barros, Rodrigo C.},
title = {A meta-learning framework for algorithm recommendation in software fault prediction},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851788},
doi = {10.1145/2851613.2851788},
abstract = {Software fault prediction is a significant part of software quality assurance and it is commonly used to detect faulty software modules based on software measurement data. Several machine learning based approaches have been proposed for generating predictive models from collected data, although none has become standard given the specificities of each software project. Hence, we believe that recommending the best algorithm for each project is much more important and useful than developing a single algorithm for being used in any project. For achieving that goal, we propose in this paper a novel framework for recommending machine learning algorithms that is capable of automatically identifying the most suitable algorithm according to the software project that is being considered. Our solution, namely SFP-MLF, makes use of the meta-learning paradigm in order to learn the best learner for a particular project. Results show that the SFP-MLF framework provides both the best single algorithm recommendation and also the best ranking recommendation for the software fault prediction problem.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1486–1491},
numpages = {6},
keywords = {algorithm recommendation, machine learning, meta-learning, software fault prediction, software quality},
location = {Pisa, Italy},
series = {SAC '16}
}

@article{10.1016/j.compeleceng.2021.107362,
author = {P, Gouthaman and Sankaranarayanan, Suresh},
title = {Prediction of Risk Percentage in Software Projects by Training Machine Learning Classifiers},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {94},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107362},
doi = {10.1016/j.compeleceng.2021.107362},
journal = {Comput. Electr. Eng.},
month = sep,
numpages = {9},
keywords = {Software model, Agile, Waterfall, Evolutionary, Incremental, Machine learning, Risk prediction}
}

@inproceedings{10.1109/ICMLA.2012.145,
author = {Gao, Kehan and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {A Hybrid Approach to Coping with High Dimensionality and Class Imbalance for Software Defect Prediction},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.145},
doi = {10.1109/ICMLA.2012.145},
abstract = {High dimensionality and class imbalance are the two main problems affecting many software defect prediction. In this paper, we propose a new technique, named SelectRUSBoost, which is a form of ensemble learning that in-corporates data sampling to alleviate class imbalance and feature selection to resolve high dimensionality. To evaluate the effectiveness of the new technique, we apply it to a group of datasets in the context of software defect prediction. We employ two classification learners and six feature selection techniques. We compare the technique to the approach where feature selection and data sampling are used together, as well as the case where feature selection is used alone (no sampling used at all). The experimental results demonstrate that the SelectRUSBoost technique is more effective in improving classification performance compared to the other approaches.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 02},
pages = {281–288},
numpages = {8},
keywords = {class imbalance, high dimensionality, software defect prediction},
series = {ICMLA '12}
}

@article{10.1007/s00521-021-05811-3,
author = {Mehta, Sweta and Patnaik, K. Sridhar},
title = {Improved prediction of software defects using ensemble machine learning techniques},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05811-3},
doi = {10.1007/s00521-021-05811-3},
abstract = {Software testing process is a crucial part in software development. Generally the errors made by developers get fixed at a later stage of the software development process. This increases the impact of the defect. To prevent this, defects need to be predicted during the initial days of the software development, which in turn helps in efficient utilization of the testing resources. Defect prediction process involves classification of software modules into defect prone and non-defect prone. This paper aims to reduce the impact of two major issues faced during defect prediction, i.e., data imbalance and high dimensionality of the defect datasets. In this research work, various software metrics are evaluated using feature selection techniques such as Recursive Feature Elimination (RFE), Correlation-based feature selection, Lasso, Ridge, ElasticNet and Boruta. Logistic Regression, Decision Trees, K-nearest neighbor, Support Vector Machines and Ensemble Learning are some of the algorithms in machine learning that have been used in combination with the feature extraction and feature selection techniques for classifying the modules in software as defect prone and non-defect prone. The proposed model uses combination of Partial Least Square (PLS) Regression and RFE for dimension reduction which is further combined with Synthetic Minority Oversampling Technique due to the imbalanced nature of the used datasets. It has been observed that XGBoost and Stacking Ensemble technique gave best results for all the datasets with defect prediction accuracy more than 0.9 as compared to algorithms used in the research work.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {10551–10562},
numpages = {12},
keywords = {Defect prediction, Dimension reduction, Data imbalance, Machine learning algorithms, XGBoost, Stacking ensemble classifier}
}

@article{10.1002/smr.2330,
author = {Shi, Ke and Lu, Yang and Liu, Guangliang and Wei, Zhenchun and Chang, Jingfei},
title = {MPT‐embedding: An unsupervised representation learning of code for software defect prediction},
year = {2021},
issue_date = {April 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {4},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2330},
doi = {10.1002/smr.2330},
abstract = {Software project defect prediction can help developers allocate debugging resources. Existing software defect prediction models are usually based on machine learning methods, especially deep learning. Deep learning‐based methods tend to build end‐to‐end models that directly use source code‐based abstract syntax trees (ASTs) as input. They do not pay enough attention to the front‐end data representation. In this paper, we propose a new framework to represent source code called multiperspective tree embedding (MPT‐embedding), which is an unsupervised representation learning method. MPT‐embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on both cross‐project defect prediction (CPDP) and within‐project defect prediction (WPDP) show that, on average, MPT‐embedding provides improvements over the state‐of‐the‐art method.Source code‐based automatic representations are more objective and accurate than traditional handcrafted metrics. This article proposed a new framework to represent code called multiperspective tree embedding (MPT‐embedding), which is an unsupervised representation learning method. MPT‐embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on the tasks of defect prediction show the effectiveness of the model.


image
image},
journal = {J. Softw. Evol. Process},
month = apr,
numpages = {20},
keywords = {deep learning, defect prediction, representation learning, tree embedding}
}

@inproceedings{10.1007/978-3-030-04780-1_26,
author = {Pal, Amrit and Kumar, Manish},
title = {Applying Big Data Intelligence for Real Time Machine Fault Prediction},
year = {2018},
isbn = {978-3-030-04779-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-04780-1_26},
doi = {10.1007/978-3-030-04780-1_26},
abstract = {Continuous use of mechanical systems requires precise maintenance. Automatic monitoring of such systems generates a large amount of data which require intelligent mining methods for processing and information extraction. The problem is to predict the faults generated with ball bearing which severely degrade operating conditions of machinery. We develop a distributed fault prediction model based on big data intelligence that extracts nine essential features from ball bearing dataset through distributed random forest. We also perform a rigorous simulation analysis of the proposed approach and the results ensure the accuracy/correctness of the method. Different types of fault classes are considered for prediction purpose and classification is done in a supervised distributed environment.},
booktitle = {Big Data Analytics: 6th International Conference, BDA 2018, Warangal, India, December 18–21, 2018, Proceedings},
pages = {376–391},
numpages = {16},
keywords = {Distributed environment, Random forest, Ball bearing, Fault prediction, Spark, Parallel processing, Decision tree},
location = {Warangal, India}
}

@article{10.1007/s00500-020-05226-7,
author = {Khuat, Thanh Tung and Ruta, Dymitr and Gabrys, Bogdan},
title = {Hyperbox-based machine learning algorithms: a comprehensive survey},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {2},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05226-7},
doi = {10.1007/s00500-020-05226-7},
abstract = {With the rapid development of digital information, the data volume generated by humans and machines is growing exponentially. Along with this trend, machine learning algorithms have been formed and evolved continuously to discover new information and knowledge from different data sources. Learning algorithms using hyperboxes as fundamental representational and building blocks are a branch of machine learning methods. These algorithms have enormous potential for high scalability and online adaptation of predictors built using hyperbox data representations to the dynamically changing environments and streaming data. This paper aims to give a comprehensive survey of the literature on hyperbox-based machine learning models. In general, according to the architecture and characteristic features of the resulting models, the existing hyperbox-based learning algorithms may be grouped into three major categories: fuzzy min–max neural networks, hyperbox-based hybrid models and other algorithms based on hyperbox representations. Within each of these groups, this paper shows a brief description of the structure of models, associated learning algorithms and an analysis of their advantages and drawbacks. Main applications of these hyperbox-based models to the real-world problems are also described in this paper. Finally, we discuss some open problems and identify potential future research directions in this field.},
journal = {Soft Comput.},
month = jan,
pages = {1325–1363},
numpages = {39},
keywords = {Hyperboxes, Membership function, Fuzzy min–max neural network, Hybrid classifiers, Data classification, Clustering, Online learning}
}

@article{10.3233/JIFS-179619,
author = {Lyu, Yi and Jiang, YiJie and Zhang, Weiping},
title = {Examination on avionics system fault prediction technology based on ashy neural network and fuzzy recognition},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {38},
number = {4},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-179619},
doi = {10.3233/JIFS-179619},
abstract = {The purpose of this paper is to accurately locate the fault prediction and diagnosis technology, to have a high degree of automation, and to handle it quickly, for the large aircraft avionics system failure presents the feature of multiple coupling, complex impact and rapid spread. At the same time, the fault prediction diagnosis technology is one of the most important contents of the avionics system equipment prediction, so how to quickly and effectively predict the failure of key system parts of avionics is the core essential to ensure the complete operation of the whole system. This paper through establishing the gray neural network model, combining the advantages of gray model to deal with poor information and the characteristics of artificial neural network processing nonlinear data, to realize the fault prediction of avionics system, At the same time, At the same time, through the fuzzy recognition method based on the deterioration degree, established the bridge between the two, in turn, to achieve the health prediction management of system. The method mainly includes: Firstly, by combining gray theory and artificial neural network algorithm with fuzzy recognition to establish a network model that contains gray neural network models and can reflect the excellent characteristics of fuzzy recognition and conduct experimental analysis; Second, on this basis, improve the weight update strategy of the gray neural network by using additional learning rate method which based on momentum and improve the accuracy of the algorithm. Therefore, it can be concluded that the predictions presented in this paper should not be directly imitated when the system disturbance factor is too large or the system is abnormally caused by a serious disturbance suddenly appearing at a certain point in time, but should properly processed the data firstly according to the actual situation. According to the time series of the actual situation, several models are established, and the data correction is explained from the model prediction effect, and the gray model and description are improved. The improved combination of gray neural network and gray neural network can not only improve the prediction accuracy, but also provide a feasible method for such time series prediction, which provides a practical and effective technical method for avionics system fault prediction.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {3939–3947},
numpages = {9},
keywords = {Ashy neural network, avionics system, fuzzy recognition, fault prediction, combined forecast}
}

@inproceedings{10.1145/1629716.1629720,
author = {Chae, Wonseok and Blume, Matthias},
title = {Language support for feature-oriented product line engineering},
year = {2009},
isbn = {9781605585673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629716.1629720},
doi = {10.1145/1629716.1629720},
abstract = {Product line engineering is an emerging paradigm of developing a family of products. While product line analysis and design mainly focus on reasoning about commonality and variability of family members, product line implementation gives its attention to mechanisms of managing variability. In many cases, however, product line methods do not impose any specific synthesis mechanisms on product line implementation, so implementation details are left to developers. In our previous work, we adopted feature-oriented product line engineering to build a family of compilers and managed variations using the Standard ML module system. We demonstrated the applicability of this module system to product line implementation. Although we have benefited from the product line engineering paradigm, it mostly served us as a design paradigm to change the way we think about a set of closely related compilers, not to change the way we build them. The problem was that Standard ML did not fully realize this paradigm at the code level, which caused some difficulties when we were developing a set of compilers.In this paper, we address such issues with a language-based solution. MLPolyR is our choice of an implementation language. It supports three different programming styles. First, its first-class cases facilitate composable extensions at the expression levels. Second, its module language provides extensible and parameterized modules, which make large-scale extensible programming possible. Third, its macro system simplifies specification and composition of feature related code. We will show how the combination of these language features work together to facilitate the product line engineering paradigm.},
booktitle = {Proceedings of the First International Workshop on Feature-Oriented Software Development},
pages = {3–10},
numpages = {8},
keywords = {feature-oriented programming, product line engineering},
location = {Denver, Colorado, USA},
series = {FOSD '09}
}

@article{10.1145/3408063,
author = {Xama, Nektar and Andraud, Martin and Gomez, Jhon and Esen, Baris and Dobbelaere, Wim and Vanhooren, Ronny and Coyette, Anthony and Gielen, Georges},
title = {Machine Learning-based Defect Coverage Boosting of Analog Circuits under Measurement Variations},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {5},
issn = {1084-4309},
url = {https://doi.org/10.1145/3408063},
doi = {10.1145/3408063},
abstract = {Safety-critical and mission-critical systems, such as airplanes or (semi-)autonomous cars, are relying on an ever-increasing number of embedded integrated circuits. Consequently, there is a need for complete defect coverage during the testing of these circuits to guarantee their functionality in the field. In this context, reducing the escape rate of defects during production testing is crucial, and significant progress has been made to this end. However, production testing using automatic test equipment is subject to various measurement parasitic variations, which may have a negative impact on the testing procedure and therefore limit the final defect coverage. To tackle this issue, this article proposes an improved test flow targeting increased analog defect coverage, both at the system and block levels, by analyzing and improving the coverage of typical functional and structural tests under these measurement variations. To illustrate the flow, the technique of inserting a pseudo-random signal at available circuit nodes and applying machine learning techniques to its response is presented. A DC-DC converter, derived from an industrial product, is used as a case study to validate the flow. In short, results show that system-level tests for the converter suffer strongly from the measurement variations and are limited to just under 80% coverage, even when applying the proposed test flow. Block-level testing, however, can achieve only 70% fault coverage without improvements but is able to consistently achieve 98% of fault coverage at a cost of at most 2% yield loss with the proposed machine learning–based boosting technique.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = aug,
articleno = {47},
numpages = {27},
keywords = {AMS IC test, Machine learning for test, test under measurements variations}
}

@inproceedings{10.5555/3432601.3432605,
author = {Krishnakumar, Sanjena and Abdou, Tamer},
title = {Towards interpretable and maintainable supervised learning using shapley values in arrhythmia},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {This paper investigates the application of a model-agnostic interpretability technique, Shapley Additive Explanations (SHAP), to understand and hence, enhance machine learning classification models using Shapley values in the prediction of arrhythmias1. Using the Arrhythmia dataset2, three different feature selection techniques, Information Gain (IG), Recursive Feature Elimination-Random Forest (RFE-RF), and AutoSpearman, were used to select features for machine learning models to predict the arrhythmia class. Four multi-class classification models, Na\"{\i}ve Bayes (NB), k-Nearest Neighbours (kNN), Random Forest (RF), and stacking heterogeneous ensemble (Ensemble) were built, evaluated, and compared. SHAP interpretation method was applied to find reliable explanations for the predictions of the classification models. Additionally, SHAP values were used to find `bellwether' instances to enhance the training of our models in order to improve their performances in the prediction of arrhythmia. The most stable and top-performing classification model was RF, followed by Ensemble in comparison to NB and kNN. SHAP provided robust and reliable explanations for the classification models. Furthermore, improving the training of our models with `bellwether' instances, found using SHAP values, enhanced the overall model performances in terms of accuracy, AUC, and F1 score. In conclusion, we recommend using SHAP value explanations as a robust and reliable method for local model-agnostic interpretability and to enhance machine learning models for arrhythmia prediction.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {23–32},
numpages = {10},
keywords = {LIME, SHAP, arrhythmia, bellwether, healthcare, local model-agnostic interpretation, machine learning, multi-class classification, shapley value},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@inproceedings{10.5555/3507788.3507798,
author = {Khan, Md Asif and Azim, Akramul and Liscano, Ramiro and Smith, Kevin and Chang, Yee-Kang and Garcon, Sylvain and Tauseef, Qasim},
title = {Failure prediction using machine learning in IBM WebSphere liberty continuous integration environment},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {The growing complexity and dependencies of software have increased the importance of testing to ensure that frequent changes do not adversely affect existing functionality. Moreover, continuous integration comes with unique challenges associated with maintaining a stable build environment. Several studies have shown that the testing environment becomes more efficient with proper test case prioritization techniques. However, an application's dynamic behavior makes it challenging to derive test case prioritization techniques for achieving optimal results. With the advance of machine learning, the context of an application execution can be analyzed to select and prioritize test suites more efficiently.Test suite prioritization techniques aim to reorder test suites' execution to deliver high quality, maintainable software at lower costs to meet specific objectives such as revealing failures earlier. The state-of-the-art techniques on test prioritization in a continuous integration environment focus on relatively small, single-language, unit-tested projects. This paper compares and analyzes Machine learning-based test suite prioritization technique on two large-scale dataset collected from a continuous integration environment Google and IBM respectively. We optimize hyperparameters and report on experiments' findings by using different machine learning algorithms for test suite prioritization. Our optimized algorithms prioritize test suites with 93% accuracy on average and require 20% fewer test suites to detect 80% of the failures than the test suites prioritized randomly.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {63–72},
numpages = {10},
keywords = {CI, continuous integration, machine learning, test prioritization},
location = {Toronto, Canada},
series = {CASCON '21}
}

@inproceedings{10.1007/978-3-031-08421-8_41,
author = {Giorgio, Lazzarinetti and Nicola, Massarenti and Fabio, Sgr\`{o} and Andrea, Salafia},
title = {Continuous Defect Prediction in CI/CD Pipelines: A Machine Learning-Based Framework},
year = {2021},
isbn = {978-3-031-08420-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-08421-8_41},
doi = {10.1007/978-3-031-08421-8_41},
abstract = {Recent advances in information technology has led to an increasing number of applications to be developed and maintained daily by product teams. Ensuring that a software application works as expected and that it is absent of bugs requires a lot of time and resources. Thanks to the recent adoption of DevOps methodologies, it is often the case where code commits and application builds are centralized and standardized. Thanks to this new approach, it is now possible to retrieve log and build data to ease the development and management operations of product teams. However, even if such approaches include code control to detect unit or integration errors, they do not check for the presence of logical bugs that can raise after code builds. For such reasons in this work we propose a framework for continuous defect prediction based on machine learning algorithms trained on a publicly available dataset. The framework is composed of a machine learning model for detecting the presence of logical bugs in code on the basis of the available data generated by DevOps tools and a dashboard to monitor the software projects status. We also describe the serverless architecture we designed for hosting the aforementioned framework.},
booktitle = {AIxIA 2021 – Advances in Artificial Intelligence: 20th International Conference of the Italian Association for Artificial Intelligence, Virtual Event, December 1–3, 2021, Revised Selected Papers},
pages = {591–606},
numpages = {16},
keywords = {Continuous defect prediction, Machine learning, DevOps, Continuous integration}
}

@article{10.1504/IJISTA.2016.076102,
author = {Rong, Xiaotao and Li, Feixiang and Cui, Zhihua},
title = {A model for software defect prediction using support vector machine based on CBA},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {15},
number = {1},
issn = {1740-8865},
url = {https://doi.org/10.1504/IJISTA.2016.076102},
doi = {10.1504/IJISTA.2016.076102},
abstract = {Software defection prediction is not only crucial for improving software quality, but also helpful for software test effort estimation. As is well-known, 80% of the fault happens in 20% of the modules. Therefore, we need to find out the most error prone modules accurately and correct them in time to save time, money, and energy. Support vector machine SVM is an advanced classification method that fits the defection classification. However, studies show that, the value of parameters of SVM model has a remarkable influence on its classification accuracy and the selection process lacks theory guidance that makes the SVM model uncertainty and low efficiency. In this paper, a CBA-SVM software defect prediction model is proposed, which take advantage of the non-linear computing ability of SVM model and optimisation capacity of bat algorithm with centroid strategy CBA. Through the experimental comparison with other models, CBA-SVM is proved to have a higher accuracy.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = apr,
pages = {19–34},
numpages = {16}
}

@article{10.1016/j.neucom.2017.02.021,
author = {Susan, Seba and Sharma, Monika},
title = {Automatic texture defect detection using Gaussian mixture entropy modeling},
year = {2017},
issue_date = {May 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {239},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2017.02.021},
doi = {10.1016/j.neucom.2017.02.021},
abstract = {In this paper we propose a new unsupervised, automated texture defect detection that does not require any user-inputs and yields high accuracies at the same time. To achieve this end we use the non-extensive entropy with Gaussian gain as the regularity index, computed locally from texture patches through a sliding window approach. The optimum window size is determined by modeling the entropy values by a two-mode Gaussian mixture model and checking for the minimum entropy of the mode-probabilities. The outlier entropy values corresponding to defective areas are defined as those that exceed thrice the standard deviation, as is the norm in statistics. The result is automatic defect detection with no manual intervention. Empirical results on defective texture images from the Brodatz database provide accurate localization of the defect as compared to Chetverikov and Hanbury's maximal regularity method, which requires manual setting of threshold parameters for each type of texture despite of being a benchmark for texture defect detection.},
journal = {Neurocomput.},
month = may,
pages = {232–237},
numpages = {6},
keywords = {Gaussian mixture model, Non-extensive entropy with Gaussian gain, Sliding window approach, Texture defects, Texture regularity}
}

@inproceedings{10.1109/RAMS.2019.8768923,
author = {Cui, Can and Liu, Bin and Li, Guoqi},
title = {A Novel Feature Selection Method for Software Fault Prediction Model},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/RAMS.2019.8768923},
doi = {10.1109/RAMS.2019.8768923},
abstract = {Software fault prediction (SFP) is an active issue in software engineering (SE). At present, machine learning (ML) has been successfully applied to SFP classification problems. However, one of the challenges for building software fault prediction models (SFPM) is processing high dimensional datasets, which include many irrelevant and redundant features. To address this issue, feature selection techniques, mainly contain wrapper methods and filter methods, are used. In the paper, we report an empirical study aimed at providing a novel approach to select feature for SFP.},
booktitle = {2019 Annual Reliability and Maintainability Symposium (RAMS)},
pages = {1–6},
numpages = {6},
location = {Orlando, FL, USA}
}

@inproceedings{10.1145/3434581.3434619,
author = {Bao, Yang and Rui, Guosheng and Zhang, Song},
title = {A Unsupervised Learning System of Aeroengine Predictive Maintenance Based on Cluster Analysis},
year = {2020},
isbn = {9781450375764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3434581.3434619},
doi = {10.1145/3434581.3434619},
abstract = {In this paper, a new cluster analysis system of predictive maintenance is proposed. The aim is to perform predictive maintenance on aero-engines under unsupervised conditions and reduce the cost of traditional periodic maintenance. Using this system and the proposed maintenance strategy to verify the subset from C-MAPSS dataset, the results show that the system obtains 40% extra uptime than regular maintenance. Under the theoretical limit, up to 60% of extra uptime can be obtained. The results show that the system can effectively increase uptime and reduce costs, which is a good supplement to the existing predictive maintenance.},
booktitle = {Proceedings of the 2020 International Conference on Aviation Safety and Information Technology},
pages = {187–191},
numpages = {5},
keywords = {Predictive maintenance, cluster analysis, unsupervised learning, warning system},
location = {Weihai City, China},
series = {ICASIT 2020}
}

@article{10.1016/j.infsof.2019.08.005,
author = {Bigonha, Mariza A.S. and Ferreira, Kecia and Souza, Priscila and Sousa, Bruno and Janu\'{a}rio, Marcela and Lima, Daniele},
title = {The usefulness of software metric thresholds for detection of bad smells and fault prediction},
year = {2019},
issue_date = {Nov 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {115},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.08.005},
doi = {10.1016/j.infsof.2019.08.005},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {79–92},
numpages = {14},
keywords = {Software metrics, Software quality, Thresholds, Detection strategies, Bad smell, Fault prediction}
}

@article{10.1016/j.inffus.2018.09.013,
author = {Praveen Kumar, D. and Amgoth, Tarachand and Annavarapu, Chandra Sekhara Rao},
title = {Machine learning algorithms for wireless sensor networks: A survey},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2018.09.013},
doi = {10.1016/j.inffus.2018.09.013},
journal = {Inf. Fusion},
month = sep,
pages = {1–25},
numpages = {25},
keywords = {Wireless sensor networks, Machine learning, Energy efficiency, Network lifetime, Data aggregation}
}

@article{10.1007/s10922-020-09512-5,
author = {Le, Duc C. and Zincir-Heywood, Nur},
title = {A Frontier: Dependable, Reliable and Secure Machine Learning for Network/System Management},
year = {2020},
issue_date = {Oct 2020},
publisher = {Plenum Press},
address = {USA},
volume = {28},
number = {4},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-020-09512-5},
doi = {10.1007/s10922-020-09512-5},
abstract = {Modern networks and systems pose many challenges to traditional management approaches. Not only the number of devices and the volume of network traffic are increasing exponentially, but also new network protocols and technologies require new techniques and strategies for monitoring controlling and managing up and coming networks and systems. Moreover, machine learning has recently found its successful applications in many fields due to its capability to learn from data to automatically infer patterns for network analytics. Thus, the deployment of machine learning in network and system management has become imminent. This work provides a review of the applications of machine learning in network and system management. Based on this review, we aim to present the current opportunities and challenges in and highlight the need for dependable, reliable and secure machine learning for network and system management.},
journal = {J. Netw. Syst. Manage.},
month = oct,
pages = {827–849},
numpages = {23},
keywords = {Network and system management, Reliable and dependable machine learning, Secure machine learning}
}

@article{10.1109/TSE.2017.2731766,
author = {Bennin, Kwabena Ebo and Keung, Jacky and Phannachitta, Passakorn and Monden, Akito and Mensah, Solomon},
title = {MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction},
year = {2018},
issue_date = {June 2018},
publisher = {IEEE Press},
volume = {44},
number = {6},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2017.2731766},
doi = {10.1109/TSE.2017.2731766},
abstract = {Highly imbalanced data typically make accurate predictions difficult. Unfortunately, software defect datasets tend to have fewer defective modules than non-defective modules. Synthetic oversampling approaches address this concern by creating new minority defective modules to balance the class distribution before a model is trained. Notwithstanding the successes achieved by these approaches, they mostly result in over-generalization (high rates of false alarms) and generate near-duplicated data instances (less diverse data). In this study, we introduce MAHAKIL, a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with SMOTE, Borderline-SMOTE, ADASYN, Random Oversampling and the No sampling approach using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant &lt;italic&gt;pf&lt;/italic&gt; values than the other oversampling approaches, based on Brunner's statistical significance test and Cliff's effect sizes. Therefore, MAHAKIL is strongly recommended as an efficient alternative for defect prediction models built on highly imbalanced datasets.},
journal = {IEEE Trans. Softw. Eng.},
month = jun,
pages = {534–550},
numpages = {17}
}

@article{10.1016/j.scico.2021.102713,
author = {Jain, Shivani and Saha, Anju},
title = {Improving performance with hybrid feature selection and ensemble machine learning techniques for code smell detection},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {212},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2021.102713},
doi = {10.1016/j.scico.2021.102713},
journal = {Sci. Comput. Program.},
month = dec,
numpages = {34},
keywords = {Code smell, Machine learning, Ensemble machine learning, Hybrid feature selection, Stacking}
}

@article{10.1007/s11263-016-0953-y,
author = {Sindagi, Vishwanath A. and Srivastava, Sumit},
title = {Domain Adaptation for Automatic OLED Panel Defect Detection Using Adaptive Support Vector Data Description},
year = {2017},
issue_date = {April     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {122},
number = {2},
issn = {0920-5691},
url = {https://doi.org/10.1007/s11263-016-0953-y},
doi = {10.1007/s11263-016-0953-y},
abstract = {Detection of surface defects on organic light emitting diode (OLED) panels pose challenges such as irregular shapes and sizes along with varying textures and patterns on the panels. These challenges can be addressed by designing invariant features and training an anomaly detection algorithm such as support vector data description (SVDD). However, these hand designed features may not be capable of handling test datasets that have undergone distributional shift due to changes in lighting configuration or panel specification. This leads to a degradation of the classifier performance. In this paper, we propose a domain adaptation technique for outlier detection called as adaptive support vector data description (A-SVDD) to tackle distributional change in OLED panel datasets. The proposed method aims to learn an incremental classifier based on the existing classifier using an objective function similar to SVDD. We also investigate the application of features called as local inlier---outlier ratios augmented with modified local binary pattern (LBP) for detection of OLED panel defects in the context of SVDD and A-SVDD. In the experiments, the proposed domain adaptation technique is compared with baseline methods and existing approaches to demonstrate its effectiveness. A detailed evaluation of the features was performed in the context of A-SVDD and SVDD on several defects like scratch, spot, stain and pit to demonstrate that the combination of local inlier---outlier ratios and modified LBP significantly increases the detection accuracy.},
journal = {Int. J. Comput. Vision},
month = apr,
pages = {193–211},
numpages = {19},
keywords = {Adaptive-SVDD, Defect detection, Domain adaptation}
}

@article{10.1016/j.jss.2021.111031,
author = {Giray, G\"{o}rkem},
title = {A software engineering perspective on engineering machine learning systems: State of the art and challenges},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111031},
doi = {10.1016/j.jss.2021.111031},
journal = {J. Syst. Softw.},
month = oct,
numpages = {35},
keywords = {Software engineering, Software development, Software process, Machine learning, Deep learning, Systematic literature review}
}

@article{10.1007/s10766-021-00707-0,
author = {\"{O}z, I\c{s}\i{}l and Arslan, Sanem},
title = {Predicting the Soft Error Vulnerability of Parallel Applications Using Machine Learning},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {3},
issn = {0885-7458},
url = {https://doi.org/10.1007/s10766-021-00707-0},
doi = {10.1007/s10766-021-00707-0},
abstract = {With the widespread use of the multicore systems having smaller transistor sizes, soft errors become an important issue for parallel program execution. Fault injection is a prevalent method to quantify the soft error rates of the applications. However, it is very time consuming to perform detailed fault injection experiments. Therefore, prediction-based techniques have been proposed to evaluate the soft error vulnerability in a faster way. In this work, we present a soft error vulnerability prediction approach for parallel applications using machine learning algorithms. We define a set of features including thread communication, data sharing, parallel programming, and performance characteristics; and train our models based on three ML algorithms. This study uses the parallel programming features, as well as the combination of all features for the first time in vulnerability prediction of parallel programs. We propose two models for the soft error vulnerability prediction: (1) A regression model with rigorous feature selection analysis that estimates correct execution rates, (2) A novel classification model that predicts the vulnerability level of the target programs. We get maximum prediction accuracy rate of 73.2% for the regression-based model, and achieve 89% F-score for our classification model.},
journal = {Int. J. Parallel Program.},
month = jun,
pages = {410–439},
numpages = {30},
keywords = {Soft error analysis, Fault injection, Parallel programming, Machine Learning}
}

@article{10.1007/s11704-020-9441-1,
author = {Sun, Xiaobing and Zhou, Tianchi and Wang, Rongcun and Duan, Yucong and Bo, Lili and Chang, Jianming},
title = {Experience report: investigating bug fixes in machine learning frameworks/libraries},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {6},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-020-9441-1},
doi = {10.1007/s11704-020-9441-1},
abstract = {Machine learning (ML) techniques and algorithms have been successfully and widely used in various areas including software engineering tasks. Like other software projects, bugs are also common in ML projects and libraries. In order to more deeply understand the features related to bug fixing in ML projects, we conduct an empirical study with 939 bugs from five ML projects by manually examining the bug categories, fixing patterns, fixing scale, fixing duration, and types of maintenance. The results show that (1) there are commonly seven types of bugs in ML programs; (2) twelve fixing patterns are typically used to fix the bugs in ML programs; (3) 68.80% of the patches belong to micro-scale-fix and small-scale-fix; (4) 66.77% of the bugs in ML programs can be fixed within one month; (5) 45.90% of the bug fixes belong to corrective activity from the perspective of software maintenance. Moreover, we perform a questionnaire survey and send them to developers or users of ML projects to validate the results in our empirical study. The results of our empirical study are basically consistent with the feedback from developers. The findings from the empirical study provide useful guidance and insights for developers and users to effectively detect and fix bugs in ML projects.},
journal = {Front. Comput. Sci.},
month = dec,
numpages = {16},
keywords = {bug fixing, machine learning project, empirical study, questionnaire survey}
}

@inproceedings{10.1145/3297156.3297187,
author = {Liu, Kun and Luo, Nana and Ren, Yafei},
title = {A Contrast Pre-adjusted Defect Detection of Strip Steel Surface by Total Variation-based Image Decomposition},
year = {2018},
isbn = {9781450366069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297156.3297187},
doi = {10.1145/3297156.3297187},
abstract = {Automatic vision-based defect detection on the strip steel surface is a challenging task due to miscellaneous patterns of defects, low contrast of the image. Traditional methods mainly distinguish the defects from the background by analyzing textural information. In this paper, a novel defect detection method by total variation-based image decomposition is developed to extract abnormal region from repetitive texture. Specially, a contrast-adjusted step is designed for the image decomposition, which can compress the dynamic range of the background brightness and enhance the contrast effectively. Furthermore, the histogram of the enhanced image shows multi-peak characteristics, which greatly contributes to the subsequent image decomposition. Next, the total variation-based image decomposition is developed for the contrast-adjusted image to extract structural map. Finally, the abnormal regions can be located only by an adaptive threshold in the structural map. The proposed method can be extended to detect the defects on other regularly textured surface, even under the low signal-to-noise ratio condition. The experiments show that the performance of the proposed algorithm is better than the state-of-art algorithms.},
booktitle = {Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence},
pages = {327–333},
numpages = {7},
keywords = {Contrast enhancement, Defect detection, Image decomposition, Low SNR},
location = {Shenzhen, China},
series = {CSAI '18}
}

@inproceedings{10.1145/3177457.3191709,
author = {Ren, Yidan and Zhu, Zhengzhou and Chen, Xiangzhou and Ding, Huixia and Zhang, Geng},
title = {Research on Defect Detection Technology of Trusted Behavior Decision Tree Based on Intelligent Data Semantic Analysis of Massive Data},
year = {2018},
isbn = {9781450363396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3177457.3191709},
doi = {10.1145/3177457.3191709},
abstract = {With the rapid development of information technology, software systems' scales and complexity are showing a trend of expansion. The users' needs for the software security, software security reliability and software stability are growing increasingly. At present, the industry has applied machine learning methods to the fields of defect detection to repair and improve software defects through the massive data intelligent semantic analysis or code scanning. The model in machine learning is faced with big difficulty of model building, understanding, and the poor visualization in the field of traditional software defect detection. In view of the above problems, we present a point of view that intelligent semantic analysis technology based on massive data, and using the trusted behavior decision tree model to analyze the soft behavior by layered detection technology. At the same time, it is equipped related test environment to compare the tested software. The result shows that the defect detection technology based on intelligent semantic analysis of massive data is superior to other techniques at the cost of building time and error reported ratio.},
booktitle = {Proceedings of the 10th International Conference on Computer Modeling and Simulation},
pages = {168–175},
numpages = {8},
keywords = {Massive data, decision tree, intelligent semantic analysis, software defect detection},
location = {Sydney, Australia},
series = {ICCMS '18}
}

@inproceedings{10.1145/3379597.3387461,
author = {Chen, Yang and Santosa, Andrew E. and Yi, Ang Ming and Sharma, Abhishek and Sharma, Asankhaya and Lo, David},
title = {A Machine Learning Approach for Vulnerability Curation},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387461},
doi = {10.1145/3379597.3387461},
abstract = {Software composition analysis depends on database of open-source library vulerabilities, curated by security researchers using various sources, such as bug tracking systems, commits, and mailing lists. We report the design and implementation of a machine learning system to help the curation by by automatically predicting the vulnerability-relatedness of each data item. It supports a complete pipeline from data collection, model training and prediction, to the validation of new models before deployment. It is executed iteratively to generate better models as new input data become available. We use self-training to significantly and automatically increase the size of the training dataset, opportunistically maximizing the improvement in the models' quality at each iteration. We devised new deployment stability metric to evaluate the quality of the new models before deployment into production, which helped to discover an error. We experimentally evaluate the improvement in the performance of the models in one iteration, with 27.59% maximum PR AUC improvements. Ours is the first of such study across a variety of data sources. We discover that the addition of the features of the corresponding commits to the features of issues/pull requests improve the precision for the recall values that matter. We demonstrate the effectiveness of self-training alone, with 10.50% PR AUC improvement, and we discover that there is no uniform ordering of word2vec parameters sensitivity across data sources.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {32–42},
numpages = {11},
keywords = {application security, classifiers ensemble, machine learning, open-source software, self-training},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/2648511.2648513,
author = {Harman, M. and Jia, Y. and Krinke, J. and Langdon, W. B. and Petke, J. and Zhang, Y.},
title = {Search based software engineering for software product line engineering: a survey and directions for future work},
year = {2014},
isbn = {9781450327404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2648511.2648513},
doi = {10.1145/2648511.2648513},
abstract = {This paper presents a survey of work on Search Based Software Engineering (SBSE) for Software Product Lines (SPLs). We have attempted to be comprehensive, in the sense that we have sought to include all papers that apply computational search techniques to problems in software product line engineering. Having surveyed the recent explosion in SBSE for SPL research activity, we highlight some directions for future work. We focus on suggestions for the development of recent advances in genetic improvement, showing how these might be exploited by SPL researchers and practitioners: Genetic improvement may grow new products with new functional and non-functional features and graft these into SPLs. It may also merge and parameterise multiple branches to cope with SPL branchmania.},
booktitle = {Proceedings of the 18th International Software Product Line Conference - Volume 1},
pages = {5–18},
numpages = {14},
keywords = {SBSE, SPL, genetic programming, program synthesis},
location = {Florence, Italy},
series = {SPLC '14}
}

@inproceedings{10.1145/3349341.3349460,
author = {Wang, Xiaojuan and Wang, Defu and Zhang, Yong and Jin, Lei and Song, Mei},
title = {Unsupervised Learning for Log Data Analysis Based on Behavior and Attribute Features},
year = {2019},
isbn = {9781450371506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349341.3349460},
doi = {10.1145/3349341.3349460},
abstract = {In some special application environments, network fault can lead to loss of important information or even mission failures, resulting in unpredictable losses. Therefore, it has certain research significance and practical value to evaluate the network status and predict the possible faults before performing the key tasks. Based on the logs collected by the router board in the real network, this paper analyses the behavior type, attribute information and the corresponding status value, and detects the hidden fault or network attack, so as to provide early warning information for operators. We propose a deep neural network model utilizing Long Short-Term Memory (LSTM) to predict the current number of level-1 logs. By comparing the predicted number of level-1 logs, it can detect abnormal behavior such as a surge in the number of logs. What's more, we perform semantic analysis on attribute information to construct attribute syntax forest, which assists maintenance staff to monitor the system through key fingerprint information in the log. In addition, we adopt attribute information and status value to train the unsupervised learning algorithm models such as Isolation Forest, OneClassSVM and LocalOutlierFactor. What's more, this paper analyses the results to find out the causes of log surge, and to assist operators in subsequent maintenance of the system.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science},
pages = {510–518},
numpages = {9},
keywords = {LSTM, Log Analysis, Network Fault, Unsupervised Machine Learning},
location = {Wuhan, Hubei, China},
series = {AICS 2019}
}

@inproceedings{10.1145/2961111.2962620,
author = {Shippey, Thomas and Hall, Tracy and Counsell, Steve and Bowes, David},
title = {So You Need More Method Level Datasets for Your Software Defect Prediction? Voil\`{a}!},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962620},
doi = {10.1145/2961111.2962620},
abstract = {Context: Defect prediction research is based on a small number of defect datasets and most are at class not method level. Consequently our knowledge of defects is limited. Identifying defect datasets for prediction is not easy and extracting quality data from identified datasets is even more difficult. Goal: Identify open source Java systems suitable for defect prediction and extract high quality fault data from these datasets. Method: We used the Boa to identify candidate open source systems. We reduce 50,000 potential candidates down to 23 suitable for defect prediction using a selection criteria based on the system's software repository and its defect tracking system. We use an enhanced SZZ algorithm to extract fault information and calculate metrics using JHawk. Result: We have produced 138 fault and metrics datasets for the 23 identified systems. We make these datasets (the ELFF datasets) and our data extraction tools freely available to future researchers. Conclusions: The data we provide enables future studies to proceed with minimal effort. Our datasets significantly increase the pool of systems currently being used in defect analysis studies.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {12},
numpages = {6},
keywords = {Boa, Data Mining, Defect Prediction, Defect linking, Defects},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@article{10.1016/j.future.2019.09.009,
author = {Lopes, F\'{a}bio and Agnelo, Jo\~{a}o and Teixeira, C\'{e}sar A. and Laranjeiro, Nuno and Bernardino, Jorge},
title = {Automating orthogonal defect classification using machine learning algorithms},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {102},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.09.009},
doi = {10.1016/j.future.2019.09.009},
journal = {Future Gener. Comput. Syst.},
month = jan,
pages = {932–947},
numpages = {16},
keywords = {Software defects, Bug reports, Orthogonal defect classification, Machine learning, Text classification}
}

@inproceedings{10.1109/ICSE43902.2021.00138,
author = {Wang, Song and Shrestha, Nishtha and Subburaman, Abarna Kucheri and Wang, Junjie and Wei, Moshi and Nagappan, Nachiappan},
title = {Automatic Unit Test Generation for Machine Learning Libraries: How Far Are We?},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00138},
doi = {10.1109/ICSE43902.2021.00138},
abstract = {Automatic unit test generation that explores the input space and produces effective test cases for given programs have been studied for decades. Many unit test generation tools that can help generate unit test cases with high structural coverage over a program have been examined. However, the fact that existing test generation tools are mainly evaluated on general software programs calls into question about its practical effectiveness and usefulness for machine learning libraries, which are statistically-orientated and have fundamentally different nature and construction from general software projects.In this paper, we set out to investigate the effectiveness of existing unit test generation techniques on machine learning libraries. To investigate this issue, we conducted an empirical study on five widely-used machine learning libraries with two popular unit test case generation tools, i.e., EVOSUITE and Randoop. We find that (1) most of the machine learning libraries do not maintain a high-quality unit test suite regarding commonly applied quality metrics such as code coverage (on average is 34.1%) and mutation score (on average is 21.3%), (2) unit test case generation tools, i.e., EVOSUITE and Randoop, lead to clear improvements in code coverage and mutation score, however, the improvement is limited, and (3) there exist common patterns in the uncovered code across the five machine learning libraries that can be used to improve unit test case generation tasks.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1548–1560},
numpages = {13},
keywords = {Empirical software engineering, test case generation, testing machine learning libraries},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1504/ijiids.2020.109457,
author = {Anwar, Khalid and Siddiqui, Jamshed and Sohail, Shahab Saquib},
title = {Machine learning-based book recommender system: a survey and new perspectives},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {2–4},
issn = {1751-5858},
url = {https://doi.org/10.1504/ijiids.2020.109457},
doi = {10.1504/ijiids.2020.109457},
abstract = {The exponential growth of recommender systems research has drawn the attention of the scientific community recently. These systems are very useful in reducing information overload and providing users with the items of their need. The major areas where recommender systems have contributed significantly include e-commerce, online auction, and books and conference recommendation for academia and industrialists. Book recommender systems suggest books of interest to users according to their preferences and requirements. In this article, we have surveyed machine learning techniques which have been used in book recommender systems. Moreover, evaluation metrics applied to evaluate recommendation techniques is also studied. Six categories for book recommendation techniques have been identified and discussed which would enable the scientific community to lay a foundation of research in the concerned field. We have also proposed future perspectives to improve recommender system. We hope that researchers exploring recommendation technology in general and book recommendation in particular will be finding this work highly beneficial.},
journal = {Int. J. Intell. Inf. Database Syst.},
month = jan,
pages = {231–248},
numpages = {17},
keywords = {book recommender system, BRS, machine learning, classification, association rule mining, evaluation metrics}
}

@article{10.1155/2021/2565500,
author = {Zheng, Danyang and Li, Liming and Zheng, Shubin and Chai, Xiaodong and Zhao, Shuguang and Tong, Qianqian and Wang, Ji and Guo, Lizheng and Zhang, Nian},
title = {A Defect Detection Method for Rail Surface and Fasteners Based on Deep Convolutional Neural Network},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/2565500},
doi = {10.1155/2021/2565500},
abstract = {As a result of long-term pressure from train operations and direct exposure to the natural environment, rails, fasteners, and other components of railway track lines inevitably produce defects, which have a direct impact on the safety of train operations. In this study, a multiobject detection method based on deep convolutional neural network that can achieve nondestructive detection of rail surface and fastener defects is proposed. First, rails and fasteners on the railway track image are localized by the improved YOLOv5 framework. Then, the defect detection model based on Mask R-CNN is utilized to detect the surface defects of the rail and segment the defect area. Finally, the model based on ResNet framework is used to classify the state of the fasteners. To verify the robustness and effectiveness of our proposed method, we conduct experimental tests using the ballast and ballastless railway track images collected from Shijiazhuang-Taiyuan high-speed railway line. Through a variety of evaluation indexes to compare with other methods using deep learning algorithms, experimental results show that our method outperforms others in all stages and enables effective detection of rail surface and fasteners.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {15}
}

@article{10.1016/j.mejo.2021.105198,
author = {Abazyan, Suren and Melikyan, Vazgen},
title = {Enhanced pin-access prediction and design optimization with machine learning integration},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {116},
number = {C},
issn = {0026-2692},
url = {https://doi.org/10.1016/j.mejo.2021.105198},
doi = {10.1016/j.mejo.2021.105198},
journal = {Microelectron. J.},
month = oct,
numpages = {5},
keywords = {Pin access, Machine learning, Prediction and optimization}
}

@article{10.1504/ijcsm.2021.117600,
author = {Hammad, Mustafa},
title = {Classifying defective software projects based on machine learning and complexity metrics},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {4},
issn = {1752-5055},
url = {https://doi.org/10.1504/ijcsm.2021.117600},
doi = {10.1504/ijcsm.2021.117600},
abstract = {Software defects can lead to software failures or errors at any time. Therefore, software developers and engineers spend a lot of time and effort in order to find possible defects. This paper proposes an automatic approach to predict software defects based on machine learning algorithms. A set of complexity measures values are used to train the classifier. Three public datasets were used to evaluate the ability of mining complexity measures for different software projects to predict possible defects. Experimental results showed that it is possible to min software complexity to build a defect prediction model with a high accuracy rate.},
journal = {Int. J. Comput. Sci. Math.},
month = jan,
pages = {401–412},
numpages = {11},
keywords = {software defects, defect prediction, software metrics, machine learning, complexity, neural networks, na\"{\i}ve Bayes, decision trees, SVM, support vector machine}
}

@inproceedings{10.1007/978-3-642-02481-8_80,
author = {Santos, Igor and Nieves, Javier and Penya, Yoseba K. and Bringas, Pablo G.},
title = {Optimising Machine-Learning-Based Fault Prediction in Foundry Production},
year = {2009},
isbn = {9783642024801},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-02481-8_80},
doi = {10.1007/978-3-642-02481-8_80},
abstract = {Microshrinkages are known as probably the most difficult defects to avoid in high-precision foundry. The presence of this failure renders the casting invalid, with the subsequent cost increment. Modelling the foundry process as an expert knowledge cloud allows properly-trained machine learning algorithms to foresee the value of a certain variable, in this case the probability that a microshrinkage appears within a casting. Extending previous research that presented outstanding results with a Bayesian-network-based approach, we have adapted and tested an artificial neural network and the K-nearest neighbour algorithm for the same objective. Finally, we compare the obtained results and show that Bayesian networks are more suitable than the rest of the counterparts for the prediction of microshrinkages.},
booktitle = {Proceedings of the 10th International Work-Conference on Artificial Neural Networks: Part II: Distributed Computing, Artificial Intelligence, Bioinformatics, Soft Computing, and Ambient Assisted Living},
pages = {554–561},
numpages = {8},
keywords = {fault prediction, data mining, Machine learning},
location = {Salamanca, Spain},
series = {IWANN '09}
}

@inproceedings{10.1145/3127005.3127013,
author = {Valdivia-Garcia, Harold and Nagappan, Meiyappan},
title = {The Characteristics of False-Negatives in File-level Fault Prediction},
year = {2017},
isbn = {9781450353052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127005.3127013},
doi = {10.1145/3127005.3127013},
abstract = {Over the years, a plethora of works has proposed more and more sophisticated machine learning techniques to improve fault prediction models. However, past studies using product metrics from closed-source projects, found a ceiling effect in the performance of fault prediction models. On the other hand, other studies have shown that process metrics are significantly better than product metrics for fault prediction. In our case study therefore we build models that include both product and process metrics taken together. We find that the ceiling effect found in prior studies exists even when we consider process metrics. We then qualitatively investigate the bug reports, source code files, and commit information for the bugs in the files that are false-negative in our fault prediction models trained using product and process metrics. Surprisingly, our qualitative analysis shows that bugs related to false-negative files and true-positive files are similar in terms of root causes, impact and affected components, and consequently such similarities might be exploited to enhance fault prediction models.},
booktitle = {Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {73–82},
numpages = {10},
keywords = {Code Metrics, Post-release Defects, Process Metrics},
location = {Toronto, Canada},
series = {PROMISE}
}

@inproceedings{10.1145/3318299.3318345,
author = {Li, ZhanJun and Shao, Yan},
title = {A Survey of Feature Selection for Vulnerability Prediction Using Feature-based Machine Learning},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318345},
doi = {10.1145/3318299.3318345},
abstract = {This paper summarized the basic process of software vulnerability prediction using feature-based machine learning for the first time. In addition to sorting out the related types and basis of vulnerability features definition, the advantages and disadvantages of different methods are compared. Finally, this paper analyzed the difficulties and challenges in this research field, and put forward some suggestions for future work.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {36–42},
numpages = {7},
keywords = {machine learning, feature, Software vulnerability prediction},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@article{10.3233/JIFS-210229,
author = {Narendiranath Babu, T. and Singh, Prabhu Pal and Somesh, M. and Jha, Harshit Kumar and Rama Prabha, D. and Venkatesan, S. and Ramesh Babu, V.},
title = {Vibration analysis of planetary gearbox using empirical mode decomposition and automatic fault prediction using artificial neural network},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {41},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-210229},
doi = {10.3233/JIFS-210229},
abstract = {The planetary gearbox works on an epicyclic gear train consisting of sun gear meshed with planets gears and ring gear. It got advantages due to its large torque to weight ratio and reduced vibrations. It is mostly employed in analog clocks, automobile automatic gearbox, Lathe machines, and other heavy industries. Therefore, it was imperative to analyze the various faults occurring in a gearbox. Furthermore, come up with a method so that failures can be avoided at the early stage. It was also a reason why it became the field of intensive research. Moreover, the technology of neural networks emerged recently, where machine learning models are trained to detect uneven vibrations on their own. This attracted many researchers to perform the study to devise their own methods of prediction. The central concept of fault prediction by the neural network without human beings’ interference inspired this study. Most industries always wanted to know if their operation line is working fine or not. In this study, an attempt was made to apply the method of deep learning on one of the most critical gearboxes because of its components and functionality. A significant part of the study also involved filtering the vibration data obtained while testing. Comparative analysis of the variation of the peak of acceleration was performed for healthy and faulty conditions.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6407–6427},
numpages = {21},
keywords = {deep learning, neural networks, Planetary gearbox}
}

@article{10.1016/j.asoc.2016.10.030,
author = {Jian, Chuanxia and Gao, Jian and Ao, Yinhui},
title = {Automatic surface defect detection for mobile phone screen glass based on machine vision},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {52},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.10.030},
doi = {10.1016/j.asoc.2016.10.030},
abstract = {Display Omitted A surface defect detection system is proposed for mobile phone screen glass. This system achieves 94% in sensitivity and 97.33% in specificity.The proposed system takes approximate 1.6601s to detect a MPSG. The detection accuracy and speed can meet the needs of online detection for MPSG.Compared with other methods used in the experiment, the proposed improved fuzzy c-means can segment the surface defects in MPSG more accurately. Defect detection using machine vision technology plays an important role in the manufacturing process of mobile phone screen glass (MPSG). This study proposes an improved detection algorithm for MPSG defect recognition and segmentation. Considering the problem of MPSG image misalignment caused by vibrations in the mobile stages, a contour-based registration (CR) method is used to generate the template image used to align the MPSG images. Based on this registration result, the combination of subtraction and projection (CSP) is used to identify defects on the MPSG image, which can eliminate the influence of fluctuation in ambient illumination. To segment the defects with a fuzzy grey boundary from a noisy MPSG image, an improved fuzzy c-means cluster (IFCM) algorithm is developed in this study. A defect detection system is developed, and the proposed algorithms are validated using a number of experimental tests on MPSG images. The testing results demonstrate that the approach proposed in this study can effectively detect various defects on MPSG and that it has better performance than other methods.},
journal = {Appl. Soft Comput.},
month = mar,
pages = {348–358},
numpages = {11},
keywords = {Mobile phone screen glass, Image subtraction, Fuzzy c-means cluster, Defect detection, Contour-based registration}
}

@article{10.1016/j.eswa.2009.12.056,
author = {Zheng, Jun},
title = {Cost-sensitive boosting neural networks for software defect prediction},
year = {2010},
issue_date = {June, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {6},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2009.12.056},
doi = {10.1016/j.eswa.2009.12.056},
abstract = {Software defect predictors which classify the software modules into defect-prone and not-defect-prone classes are effective tools to maintain the high quality of software products. The early prediction of defect-proneness of the modules can allow software developers to allocate the limited resources on those defect-prone modules such that high quality software can be produced on time and within budget. In the process of software defect prediction, the misclassification of defect-prone modules generally incurs much higher cost than the misclassification of not-defect-prone ones. Most of the previously developed predication models do not consider this cost issue. In this paper, three cost-sensitive boosting algorithms are studied to boost neural networks for software defect prediction. The first algorithm based on threshold-moving tries to move the classification threshold towards the not-fault-prone modules such that more fault-prone modules can be classified correctly. The other two weight-updating based algorithms incorporate the misclassification costs into the weight-update rule of boosting procedure such that the algorithms boost more weights on the samples associated with misclassified defect-prone modules. The performances of the three algorithms are evaluated by using four datasets from NASA projects in terms of a singular measure, the Normalized Expected Cost of Misclassification (NECM). The experimental results suggest that threshold-moving is the best choice to build cost-sensitive software defect prediction models with boosted neural networks among the three algorithms studied, especially for the datasets from projects developed by object-oriented language.},
journal = {Expert Syst. Appl.},
month = jun,
pages = {4537–4543},
numpages = {7},
keywords = {Software defect, Neural networks, Cost-sensitive, Adaboost}
}

@article{10.1007/s10515-020-00277-4,
author = {Esteves, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
title = {Understanding machine learning software defect predictions},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3–4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-020-00277-4},
doi = {10.1007/s10515-020-00277-4},
abstract = {Software defects are well-known in software development and might cause several problems for users and developers aside. As a result, researches employed distinct techniques to mitigate the impacts of these defects in the source code. One of the most notable techniques focuses on defect prediction using machine learning methods, which could support developers in handling these defects before they are introduced in the production environment. These studies provide alternative approaches to predict the likelihood of defects. However, most of these works concentrate on predicting defects from a vast set of software features. Another key issue with the current literature is the lack of a satisfactory explanation of the reasons that drive the software to a defective state. Specifically, we use a tree boosting algorithm (XGBoost) that receives as input a training set comprising records of easy-to-compute characteristics of each module and outputs whether the corresponding module is defect-prone. To exploit the link between predictive power and model explainability, we propose a simple model sampling approach that finds accurate models with the minimum set of features. Our principal idea is that features not contributing to increasing the predictive power should not be included in the model. Interestingly, the reduced set of features helps to increase model explainability, which is important to provide information to developers on features related to each module of the code which is more defect-prone. We evaluate our models on diverse projects within Jureczko datasets, and we show that (i) features that contribute most for finding best models may vary depending on the project and (ii) it is possible to find effective models that use few features leading to better understandability. We believe our results are useful to developers as we provide the specific software features that influence the defectiveness of selected projects.},
journal = {Automated Software Engg.},
month = dec,
pages = {369–392},
numpages = {24},
keywords = {SHAP values, Jureczko datasets, Explainable models, Software defects}
}

@article{10.1016/j.cose.2021.102459,
author = {Zhao, Jinxiong and Guo, Sensen and Mu, Dejun},
title = {DouBiGRU-A: Software defect detection algorithm based on attention mechanism and double BiGRU},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {111},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2021.102459},
doi = {10.1016/j.cose.2021.102459},
journal = {Comput. Secur.},
month = dec,
numpages = {10},
keywords = {Flawfinder, RATS, Vulnerability identification, Software defect detection, DouBiGRU-A}
}

@inproceedings{10.5555/1332044.1332090,
author = {Catal, Cagatay and Diri, Banu},
title = {Software defect prediction using artificial immune recognition system},
year = {2007},
publisher = {ACTA Press},
address = {USA},
abstract = {Predicting fault-prone modules for software development projects enables companies to reach high reliable systems and minimizes necessary budget, personnel and resource to be allocated to achieve this goal. Researchers have investigated various statistical techniques and machine learning algorithms until now but most of them applied their models to the different datasets which are not public or used different criteria to decide the best predictor model. Artificial Immune Recognition System is a supervised learning algorithm which has been proposed in 2001 for the classification problems and its performance for UCI datasets (University of California machine learning repository) is remarkable.In this paper, we propose a novel software defect prediction model by applying Artificial Immune Recognition System (AIRS) along with the Correlation-Based Feature Selection (CFS) technique. In order to evaluate the performance of the proposed model, we apply it to the five NASA public defect datasets and compute G-mean 1, G-mean 2 and F-measure values to discuss the effectiveness of the model. Experimental results show that AIRS has a great potential for software defect prediction and AIRS along with CFS technique provides relatively better prediction for large scale projects which consist of many modules.},
booktitle = {Proceedings of the 25th Conference on IASTED International Multi-Conference: Software Engineering},
pages = {285–290},
numpages = {6},
keywords = {artificial immune recognition system (AIRS) and correlation-based feature selection, immune systems, quality prediction, software defect prediction},
location = {Innsbruck, Austria},
series = {SE'07}
}

@article{10.1504/ijica.2021.119339,
author = {Jiang, Xiaoliang and Yang, Xiaojun and Ding, Xiaokang},
title = {An efficient and reliable approach based on adaptive threshold for road defect detection},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {5–6},
issn = {1751-648X},
url = {https://doi.org/10.1504/ijica.2021.119339},
doi = {10.1504/ijica.2021.119339},
abstract = {With the rapid development of economy, automatic detection of road crack becomes a hot research study. However, it still has immense challenges due to the shading, intensity inhomogeneity and divots in the crack image. Traditional detection algorithms use the characteristic of the image such as intensity and texture to segment the crack regions, so they cannot achieve satisfactory performance. In this article, we introduce an automatically image-based method for road crack detection. Firstly, a new mask image is constructed based on the grey-mean of original image. Secondly, calculating the difference between the original image and the mask image and selecting the highest value to extract the targets from the image background. Finally, the redundant interference is removed by morphological operation. Experimental results concentrate on public datasets show that our method is more reliable than previous approaches.},
journal = {Int. J. Innov. Comput. Appl.},
month = jan,
pages = {321–329},
numpages = {8},
keywords = {adaptive threshold, Otsu, image segmentation, road crack detection}
}

@article{10.4018/IJITSA.2021010104,
author = {Shatnawi, Raed and Mishra, Alok},
title = {An Empirical Study on Software Fault Prediction Using Product and Process Metrics},
year = {2021},
issue_date = {Jan 2021},
publisher = {IGI Global},
address = {USA},
volume = {14},
number = {1},
issn = {1935-570X},
url = {https://doi.org/10.4018/IJITSA.2021010104},
doi = {10.4018/IJITSA.2021010104},
abstract = {Product and process metrics are measured from the development and evolution of software. Metrics are indicators of software fault-proneness and advanced models using machine learning can be provided to the development team to select modules for further inspection. Most fault-proneness classifiers were built from product metrics. However, the inclusion of process metrics adds evolution as a factor to software quality. In this work, the authors propose a process metric measured from the evolution of software to predict fault-proneness in software models. The process metrics measures change-proneness of modules (classes and interfaces). Classifiers are trained and tested for five large open-source systems. Classifiers were built using product metrics alone and using a combination of product and the proposed process metric. The classifiers evaluation shows improvements whenever the process metrics were used. Evolution metrics are correlated with quality of software and helps in improving software quality prediction for future releases.},
journal = {Int. J. Inf. Technol. Syst. Appoach},
month = jan,
pages = {62–78},
numpages = {17},
keywords = {Software Fault, Product Metrics, Process Metrics, CK Metrics}
}

@article{10.1016/j.aei.2015.01.014,
author = {Tsai, Du-Ming and Li, Guan-Nan and Li, Wei-Chen and Chiu, Wei-Yao},
title = {Defect detection in multi-crystal solar cells using clustering with uniformity measures},
year = {2015},
issue_date = {August 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {29},
number = {3},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2015.01.014},
doi = {10.1016/j.aei.2015.01.014},
abstract = {Solar cells that convert sunlight into electrical energy are the main component of a solar power system. Quality inspection of solar cells ensures high energy conversion efficiency of the product. The surface of a multi-crystal solar wafer shows multiple crystal grains of random shapes and sizes. It creates an inhomogeneous texture in the surface, and makes the defect inspection task extremely difficult. This paper proposes an automatic defect detection scheme based on Haar-like feature extraction and a new clustering technique. Only defect-free images are used as training samples. In the training process, a binary-tree clustering method is proposed to partition defect-free samples that involve tens of groups. A uniformity measure based on principal component analysis is evaluated for each cluster. In each partition level, the current cluster with the worst uniformity of inter-sample distances is separated into two new clusters using the Fuzzy C-means. In the inspection process, the distance from a test data point to each individual cluster centroid is computed to measure the evidence of a defect. Experimental results have shown that the proposed method is effective and efficient to detect various defects in solar cells. It has shown a very good detection rate, and the computation time is only 0.1s for a 550 550 image.},
journal = {Adv. Eng. Inform.},
month = aug,
pages = {419–430},
numpages = {12},
keywords = {Surface inspection, Solar cells, Fuzzy C-means, Defect detection, Clustering}
}

@inproceedings{10.1109/ICSE-C.2017.72,
author = {Wu, Fei and Jing, Xiao-Yuan and Dong, Xiwei and Cao, Jicheng and Xu, Mingwei and Zhang, Hongyu and Ying, Shi and Xu, Baowen},
title = {Cross-project and within-project semi-supervised software defect prediction problems study using a unified solution},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.72},
doi = {10.1109/ICSE-C.2017.72},
abstract = {When there exists not enough historical defect data for building accurate prediction model, semi-supervised defect prediction (SSDP) and cross-project defect prediction (CPDP) are two feasible solutions. Existing CPDP methods assume that the available source data is well labeled. However, due to expensive human efforts for labeling a large amount of defect data, usually, we can only make use of the suitable unlabeled source data to help build the prediction model. We call CPDP in this scenario as cross-project semi-supervised defect prediction (CSDP). As to within-project semi-supervised defect prediction (WSDP), although some WSDP methods have been developed in recent years, there still exists much room for improvement. In this paper, we aim to provide an effective solution for both CSDP and WSDP problems. We introduce the semi-supervised dictionary learning technique, an effective machine learning technique, into defect prediction and propose a semi-supervised structured dictionary learning (SSDL) approach for CSDP and WSDP. SSDL can make full use of the useful information in limited labeled defect data and a large amount of unlabeled data. Experiments on two public datasets indicate that SSDL can obtain better prediction performance than related SSDP methods in the CSDP scenario.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {195–197},
numpages = {3},
keywords = {within-project semi-supervised defect prediction, semi-supervised structured dictionary learning, cross-project semi-supervised defect prediction},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1109/QSIC.2012.19,
author = {Wang, Jun and Shen, Beijun and Chen, Yuting},
title = {Compressed C4.5 Models for Software Defect Prediction},
year = {2012},
isbn = {9780769548333},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QSIC.2012.19},
doi = {10.1109/QSIC.2012.19},
abstract = {Defects in every software must be handled properly, and the number of defects directly reflects the quality of a software. In recent years, researchers have applied data mining and machine learning methods to predicting software defects. However, in their studies, the method in which the machine learning models are directly adopted may not be precise enough. Optimizing the machine learning models used in defects prediction will improve the prediction accuracy. In this paper, aiming at the characteristics of the metrics mined from the open source software, we proposed three new defect prediction models based on C4.5 model. The new models introduce the Spearman's rank correlation coefficient to the basis of choosing root node of the decision tree which makes the models better on defects prediction. In order to verify the effectiveness of the improved models, an experimental scheme is designed. In the experiment, we compared the prediction accuracies of the existing models and the improved models and the result showed that the improved models reduced the size of the decision tree by 49.91% on average and increased the prediction accuracy by 4.58% and 4.87% on two modules used in the experiment.},
booktitle = {Proceedings of the 2012 12th International Conference on Quality Software},
pages = {13–16},
numpages = {4},
keywords = {Software Repository, Defect Prediction, Decision Tree Learner, Data Mining},
series = {QSIC '12}
}

@article{10.5555/1991856.1991869,
author = {Jiang, Yuan and Li, Ming and Zhou, Zhi-Hua},
title = {Software defect detection with rocus},
year = {2011},
issue_date = {March 2011},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {2},
issn = {1000-9000},
abstract = {Software defect detection aims to automatically identify defective software modules for efficient software test in order to improve the quality of a software system. Although many machine learning methods have been successfully applied to the task, most of them fail to consider two practical yet important issues in software defect detection. First, it is rather difficult to collect a large amount of labeled training data for learning a well-performing model; second, in a software system there are usually much fewer defective modules than defect-free modules, so learning would have to be conducted over an imbalanced data set. In this paper, we address these two practical issues simultaneously by prcposing a novel semi-supervised learning approach named ROCUS. This method exploits the abundant unlabeled examples to improve the detection accuracy, as well as employs under-sampling to tackle the class-imbalance problem in the learning process. Experimental results of real-world software defect detection tasks show that ROCUS is effective for software defect cetection. Its performance is better than a semi-supervised learning method that ignores the class-imbalance nature of the task and a class-imbalance learning method that does not make effective use of unlabeled data.},
journal = {J. Comput. Sci. Technol.},
month = mar,
pages = {328–342},
numpages = {15},
keywords = {software defect detection, semi-supervised learning, machine learning, data mining, class-imbalance}
}

@article{10.1007/s00521-021-05892-0,
author = {Rajakumar, M. P. and Ramya, J. and Maheswari, B. Uma},
title = {Health monitoring and fault prediction using a lightweight deep convolutional neural network optimized by Levy flight optimization algorithm},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {19},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05892-0},
doi = {10.1007/s00521-021-05892-0},
abstract = {Agricultural machines (AMs) refer to equipment usually used in agriculture such as tractors, hand tools, and power tools. It reduces the labor work, increases farms produce, enhances goods quality, and reduces farming time and cost-saving. However, the faults in the fuel system, blades, engine of the AM will often result in degraded vehicle performance, compromising the vehicle’s efficiency and strength. To overcome these problems, fault detection algorithms are developed to identify the faults even before they occur with high classification accuracy. The deep convolutional neural network (DCNN) is a popular deep learning model that offers a high classification recognition rate, and it is widely adopted in similar fields for monitoring the health status of machines. Very few state-of-the-art works are available to identify the health state of agricultural machines using deep learning techniques and extracting the acoustic features from an audio recording. The acoustic signal-based agricultural machine health monitoring and fault prediction model using smartphones is a cost-effective option that is deployed in this proposed work. To optimize the network structure of the DCNN, this paper proposes a Levy flight optimization algorithm (LFOA). The DCNN-LFOA model is implemented on the smartphone’s on-board device (OBD) along with the health monitoring application. The LFOA algorithm minimizes the number of neurons in the DCNN hidden layer and the number of input features from the audio recordings and enhances the classification accuracy. The LFOA algorithm provides the optimal solution which is essential in developing a lightweight DCNN model to implement in the edge processor (smartphone). The experimental results prove that the proposed model gives improved accuracy for the six faults to be classified and serves as a new research model to identify the health condition of the vehicles.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {12513–12534},
numpages = {22},
keywords = {Short-term audio signals, Fault detection, Levy flight optimization algorithm, Convolutional neural network, Agricultural vehicles}
}

@article{10.1155/2021/4795396,
author = {Zhang, Bin and Fang, Shuqi and Li, Zhixi and Wang, Long},
title = {Research on Surface Defect Detection of Rare-Earth Magnetic Materials Based on Improved SSD},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1076-2787},
url = {https://doi.org/10.1155/2021/4795396},
doi = {10.1155/2021/4795396},
abstract = {In order to overcome the limitation of manual visual inspection of surface defects of rare-earth magnetic materials and increase production efficiency of traditional rare-earth enterprises, a detection method based on improved SSD (Single Shot Detector) is proposed. The SSD model is improved from two aspects for better performance in the detection of small defects. First of all, the multiscale receptive field module is embedded into the backbone network of the algorithm to improve the feature extraction ability of the model. Secondly, the interlayer feature fusion strategy of bidirectional feature pyramid in PANet (path aggregation network) is integrated into the model. In order to enhance the detection ability of the model, the high-level semantic information is strengthened by an efficient channel attention mechanism. The detection speed of the improved SSD algorithm is 55FPS, and the mAP (mean Average Precision) is up to 83.65%, which is 3.41% higher than of the original SSD algorithm, and the ability to identify small defects is significantly improved.},
journal = {Complex.},
month = jan,
numpages = {10}
}

@inproceedings{10.1109/CEC48606.2020.9185555,
author = {Brester, Christina and Niska, Harri and Ciszek, Robert and Kolehmainen, Mikko},
title = {Weather-based Fault Prediction in Electricity Networks with Artificial Neural Networks},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC48606.2020.9185555},
doi = {10.1109/CEC48606.2020.9185555},
abstract = {Predicting weather-related outages in electricity networks is an important issue for distribution system operators. In this study, we apply a data-driven approach and train artificial neural networks to predict faults in the electricity network. In our experiments, we utilize the meteorological data and fault records collected for the period of1.1.2011-31.12.2013 in central Finland. Assuming that there might be long-term dependencies between weather conditions and faults in the network, we investigate simple recurrent neural networks, long short-term memory networks, and traditional multilayer perceptrons. Taking into account the meteorological observations preceding faults and varying this period from several hours to several days, we found that 6 hours prior to faults included the sufficient information to make accurate predictions. Also, there was no need in more complicated recurrent neural networks as multilayer perceptron was able to predict events with the large number of faults more accurately. Besides, while forecasting all types of faults and wind-related faults only, oversampling allowed the model to predict rare high peaks.},
booktitle = {2020 IEEE Congress on Evolutionary Computation (CEC)},
pages = {1–8},
numpages = {8},
location = {Glasgow, United Kingdom}
}

@article{10.1016/j.cie.2018.12.043,
author = {He, Di and Xu, Ke and Zhou, Peng},
title = {Defect detection of hot rolled steels with a new object detection framework called classification priority network},
year = {2019},
issue_date = {Feb 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {128},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2018.12.043},
doi = {10.1016/j.cie.2018.12.043},
journal = {Comput. Ind. Eng.},
month = feb,
pages = {290–297},
numpages = {8},
keywords = {Surface inspection, Hot rolled steels, Object detection, Classification priority network}
}

@article{10.1155/2021/2021344,
author = {Luo, Long and Ma, Rukuo and Li, Yuan and Yang, Fangnan and Qiu, Zhanfei and Ding, Bai Yuan},
title = {Image Recognition Technology with Its Application in Defect Detection and Diagnosis Analysis of Substation Equipment},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/2021344},
doi = {10.1155/2021/2021344},
abstract = {Detection of substation equipment can promptly and effectively discover equipment overheating defects and prevent equipment failures. Traditional manual diagnosis methods are difficult to deal with the massive infrared images generated by the autonomous inspection of substation robots and drones. At present, most of the infrared image defect recognition is based on traditional machine learning algorithms, with low recognition accuracy and poor generalization capability. Therefore, this paper develops a method for identifying infrared defects of substation equipment based on the improvement of traditional ones. First, based on the Faster RCNN, target detection is performed on 6 types of substation equipment including bushings, insulators, wires, voltage transformers, lightning rods, and circuit breakers to achieve precise positioning of the equipment. Afterwards, different classes are identified based on the sparse representation-based classification (SRC), so the actual label of the input sample can be obtained. Finally, based on the temperature threshold discriminant algorithm, defects are identified in the equipment area. The measured infrared images are used for experiments. The average detection accuracy achieved by the proposed method for the 6 types of equipment reaches 92.34%. The recognition rate of different types of equipment is 98.57%, and the defect recognition accuracy reaches 88.75%. The experimental results show the effectiveness and accuracy of the proposed method.},
journal = {Sci. Program.},
month = jan,
numpages = {6}
}

@inproceedings{10.1109/COASE.2019.8843313,
author = {Yan, Hao and Yeh, Huai-Ming and Sergin, Nurettin},
title = {Image-based Process Monitoring via Adversarial Autoencoder with Applications to Rolling Defect Detection},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8843313},
doi = {10.1109/COASE.2019.8843313},
abstract = {Image-based process monitoring has recently attracted increasing attention due to the advancement of the sensing technologies. However, existing process monitoring methods fail to fully utilize the spatial information of images due to their complex characteristics including the high-dimensionality and complex spatial structures. Recent advancements in unsupervised deep models such as generative adversarial networks (GAN) and adversarial autoencoders (AAE) has enabled to learn the complex spatial structures automatically. Inspired by this advancement, we propose an anomaly detection framework based on the AAE for unsupervised anomaly detection for images. AAE combines the power of GAN with the variational autoencoder, which serves as a nonlinear dimension reduction technique. Based on this, we propose a monitoring statistic efficiently capturing the change of the data. The performance of the proposed AAE-based anomaly detection algorithm is validated through a simulation study and real case study for rolling defect detection.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {311–316},
numpages = {6},
location = {Vancouver, BC, Canada}
}

@inproceedings{10.1145/3331453.3360965,
author = {Chen, Shouhong and Kang, Huaiqiang and Ma, Jun and Guo, Ling and Hou, Xingna},
title = {Research on TSV Void Defects Based on Machine Learning},
year = {2019},
isbn = {9781450362948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331453.3360965},
doi = {10.1145/3331453.3360965},
abstract = {With the rapid development of 3D TSV (through silicon via) technology, it is particularly important to improve the yield for TSV fault detection. Aiming at TSV void defects, the paper adopts supervised machine learning method to train S parameters in TSV model with void faults, and carries out classification processing, then predicts the size of void faults through stimulus signal and S parameters. The results show that for spherical void defects detection, the classification accuracy of ELM (Extreme Learning Machine) algorithm and KNN (K-Nearest Neighbor) algorithm is above 85%, while for TSV cylindrical void defects detection, the classification accuracy of ELM algorithm is 96%.},
booktitle = {Proceedings of the 3rd International Conference on Computer Science and Application Engineering},
articleno = {75},
numpages = {4},
keywords = {TSV fault detection, Machine learning, Classification algorithm},
location = {Sanya, China},
series = {CSAE '19}
}

@inproceedings{10.1007/978-3-030-33607-3_12,
author = {Shepperd, Martin and Guo, Yuchen and Li, Ning and Arzoky, Mahir and Capiluppi, Andrea and Counsell, Steve and Destefanis, Giuseppe and Swift, Stephen and Tucker, Allan and Yousefi, Leila},
title = {The Prevalence of Errors in Machine Learning Experiments},
year = {2019},
isbn = {978-3-030-33606-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33607-3_12},
doi = {10.1007/978-3-030-33607-3_12},
abstract = {Context: Conducting experiments is central to research machine learning research to benchmark, evaluate and compare learning algorithms. Consequently it is important we conduct reliable, trustworthy experiments.Objective: We investigate the incidence of errors in a sample of machine learning experiments in the domain of software defect prediction. Our focus is simple arithmetical and statistical errors.Method: We analyse 49 papers describing 2456 individual experimental results from a previously undertaken systematic review comparing supervised and unsupervised defect prediction classifiers. We extract the confusion matrices and test for relevant constraints, e.g., the marginal probabilities must sum to one. We also check for multiple statistical significance testing errors.Results: We find that a total of 22 out of 49 papers contain demonstrable errors. Of these 7 were statistical and 16 related to confusion matrix inconsistency (one paper contained both classes of error).Conclusions: Whilst some errors may be of a relatively trivial nature, e.g., transcription errors their presence does not engender confidence. We strongly urge researchers to follow open science principles so errors can be more easily be detected and corrected, thus as a community reduce this worryingly high error rate with our computational experiments.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2019: 20th International Conference, Manchester, UK, November 14–16, 2019, Proceedings, Part I},
pages = {102–109},
numpages = {8},
keywords = {Classifier, Computational experiment, Reliability, Error},
location = {Manchester, United Kingdom}
}

@article{10.1007/s11042-020-09727-3,
author = {Jawahar, Malathy and Babu, N. K. Chandra and Vani, K. and Anbarasi, L. Jani and Geetha, S.},
title = {Vision based inspection system for leather surface defect detection using fast convergence particle swarm optimization ensemble classifier approach},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {3},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-09727-3},
doi = {10.1007/s11042-020-09727-3},
abstract = {Surface defect inspection plays a vital role in leather manufacturing. Current practice involves an expert to inspect each piece of leather individually and detect defects manually. However, such a manual inspection is highly subjective and varies quite considerably from one assorter to another. Computer vision system for natural material like leather is a challenging research problem. This study describes the application of computer vision system to capture leather surface images and use of a novel Fast Convergence Particle Swarm Optimization (FCPSO) algorithm on a set of handcrafted texture features viz., GLCM and classified using supervised classifiers viz., Multi Layer Perceptron (MLP), Decision Tree (DT), SVM, Na\"{\i}ve Bayes, K-Nearest Neighbors (KNN) and Random Forest (RF). FCPSO using modified fitness function by selective band Shannon entropy is implemented to segment industrial leather images. Segmentation efficiency of the proposed FCPSO algorithm is evaluated and its performance is compared with other optimization algorithms. Efficiency of the segmentation algorithms is evaluated using performance measures such as average difference (AD), Area Error Rate (AER), Edge-based structural similarity index (ESSIM), F-Score, Normalized correlation coefficient (NK), Overlap Error (OE), structural content (SC), Structural similarity index (SSIM) and Zijdenbos similarity index (ZSI). Correlation of the segmented area using FCPSO with the experts’ ground truth is found to be high with R value of 0.84. Feature extraction is carried out using GLCM texture features and the most prominent features were selected using statistical t-test and correlation coefficient. Experimental results showed encouraging results for random forest classifier confirming the potential of the proposed system for automatic leather defect classification.},
journal = {Multimedia Tools Appl.},
month = jan,
pages = {4203–4235},
numpages = {33},
keywords = {Ensemble classifier, Fast convergence particle swarm optimization, Leather surface defect detection, segmentation, Image analysis}
}

@article{10.1007/s10462-020-09876-9,
author = {Goh, G. D. and Sing, S. L. and Yeong, W. Y.},
title = {A review on machine learning in 3D printing: applications, potential, and challenges},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {1},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09876-9},
doi = {10.1007/s10462-020-09876-9},
abstract = {Additive manufacturing (AM) or 3D printing is growing rapidly in the manufacturing industry and has gained a lot of attention from various fields owing to its ability to fabricate parts with complex features. The reliability of the 3D printed parts has been the focus of the researchers to realize AM as an end-part production tool. Machine learning (ML) has been applied in various aspects of AM to improve the whole design and manufacturing workflow especially in the era of industry 4.0. In this review article, various types of ML techniques are first introduced. It is then followed by the discussion on their use in various aspects of AM such as design for 3D printing, material tuning, process optimization, in situ monitoring, cloud service, and cybersecurity. Potential applications in the biomedical, tissue engineering and building and construction will be highlighted. The challenges faced by ML in AM such as computational cost, standards for qualification and data acquisition techniques will also be discussed. In the authors’ perspective, in situ monitoring of AM processes will significantly benefit from the object detection ability of ML. As a large data set is crucial for ML, data sharing of AM would enable faster adoption of ML in AM. Standards for the shared data are needed to facilitate easy sharing of data. The use of ML in AM will become more mature and widely adopted as better data acquisition techniques and more powerful computer chips for ML are developed.},
journal = {Artif. Intell. Rev.},
month = jan,
pages = {63–94},
numpages = {32},
keywords = {Process optimization, Additive manufacturing, In-situ monitoring, 3D printing, Artificial intelligence, Machine learning}
}

@inproceedings{10.1145/3396743.3396778,
author = {Natsupakpong, Suriya and Nithisopa, Nahpat},
title = {Lens Quality Inspection using Image Processing and Machine Learning},
year = {2020},
isbn = {9781450377065},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3396743.3396778},
doi = {10.1145/3396743.3396778},
abstract = {This research proposes a system to inspect defective lenses with a polarization technique by using image processing and machine learning. Currently, a skilled operator checks the lens quality with the polarization method by eye and decides whether or not a lens is good (OK) or not good (NG). A 'not good' lens has a circle or a line appearing in the stress pattern of the lens. This research designs and develops a lens quality checking system with machine learning by simulating and prototyping a machine to experiment and collect persistent data, using the camera to capture and analyze images with image processing and machine learning techniques to decide on the lens quality in the computer. The experimental results show that the proposed system with a trained model with data augmentation and image preprocessing can achieve performance testing with 97.75% accuracy.},
booktitle = {Proceedings of the 2020 2nd International Conference on Management Science and Industrial Engineering},
pages = {184–188},
numpages = {5},
keywords = {polarization, machine learning, lens quality inspection, image processing},
location = {Osaka, Japan},
series = {MSIE '20}
}

@inproceedings{10.1109/WORDS.2005.32,
author = {Challagulla, Venkata U. B. and Bastani, Farokh B. and Yen, I-Ling and Paul, Raymond A.},
title = {Empirical Assessment of Machine Learning based Software Defect Prediction Techniques},
year = {2005},
isbn = {0769523471},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WORDS.2005.32},
doi = {10.1109/WORDS.2005.32},
abstract = {The wide-variety of real-time software systems, including telecontrol/telepresence systems, robotic systems, and mission planning systems, can entail dynamic code synthesis based on runtime mission-specific requirements and operating conditions. This necessitates the need for dynamic dependability assessment to ensure that these systems will perform as specified and will not fail in catastrophic ways. One approach in achieving this is to dynamically assess the modules in the synthesized code using software defect prediction techniques. Statistical models, such as Stepwise Multi-linear Regression models and multivariate models, and machine learning approaches, such as Artificial Neural Networks, Instance-based Reasoning, Bayesian-Belief Networks, Decision Trees, and Rule Inductions, have been investigated for predicting software quality. However, there is still no consensus about the best predictor model for software defects. In this paper, we evaluate different predictor models on four different real-time software defect data sets. The results show that a combination of 1R and Instance-based Learning along with the Consistencybased Subset Evaluation technique provides relatively better consistency in accuracy prediction compared to other models. The results also show that "size" and "complexity" metrics are not sufficient for accurately predicting real-time software defects.},
booktitle = {Proceedings of the 10th IEEE International Workshop on Object-Oriented Real-Time Dependable Systems},
pages = {263–270},
numpages = {8},
series = {WORDS '05}
}

@inproceedings{10.1145/3390557.3394322,
author = {Qin, Yang and Xing, Yongkang and Du, Jinglong},
title = {LSDDN: A Lightweight End-to-End Network for Surface Defect Detection},
year = {2020},
isbn = {9781450376587},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3390557.3394322},
doi = {10.1145/3390557.3394322},
abstract = {Surface defect detection is a key method to control product quality in industry. Deep learning based surface defect detection algorithm plays a crucial role in improving industrial production efficiency. A large number of existing CNN models aim at building deeper and larger structures, thus deep network models are difficult to be applied in the industrial field because of the requirement of speed in industry. This paper proposes a lightweight end-to-end surface defect detection network (LSDDN) to overcome this problem. LSDDN significantly reduces the number of parameters and improves the detection speed while maintaining a high accuracy. We validate our model on the DAGM2007 dataset with an average classification accuracy of 97.23%.},
booktitle = {Proceedings of the 2020 the 4th International Conference on Innovation in Artificial Intelligence},
pages = {79–83},
numpages = {5},
keywords = {Lightweight network, Defect detection, Deep learning},
location = {Xiamen, China},
series = {ICIAI '20}
}

@article{10.1007/s42979-021-00872-6,
author = {Sakhrawi, Zaineb and Sellami, Asma and Bouassida, Nadia},
title = {Software Enhancement Effort Prediction Using Machine-Learning Techniques: A Systematic Mapping Study},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {6},
url = {https://doi.org/10.1007/s42979-021-00872-6},
doi = {10.1007/s42979-021-00872-6},
abstract = {Accurate prediction of software enhancement effort is a key success in software project management. To increase the accuracy of estimates, several proposals used machine-learning (ML) techniques for predicting the software project effort. However, there is no clear evidence for determining which techniques to select for predicting more accurate effort within the context of enhancement projects. This paper aims to present a systematic mapping study (SMS) related to the use of ML techniques for predicting software enhancement effort (SEME). A SMS was performed by reviewing relevant papers from 1995 through 2020. We followed well-known guidelines. We selected 30 relevant studies; 19 from journals and 11 conferences proceedings through 4 search engines. Some of the key findings indicate that (1) there is relatively little activity in the area of SEME, (2) most of the successful studies cited focused on regression problems for enhancement maintenance effort prediction, (3) SEME is the dependent variable the most commonly used in software enhancement project planning, and the enhancement size (or the functional change size) is the most used independent variables, (4) several private datasets were used in the selected studies, and there is a growing demand for the use of commonly published datasets, and (5) only single models were employed for SEME prediction. Results indicate that much more work is needed to develop repositories in all prediction models. Based on the findings obtained in this SMS, estimators should be aware that SEME using ML techniques as part of non-algorithmic models demonstrated increased accuracy prediction over the algorithmic models. The use of ML techniques generally provides a reasonable accuracy when using the enhancement functional size as independent variables.},
journal = {SN Comput. Sci.},
month = sep,
numpages = {15},
keywords = {Machine learning (ML), Software enhancement effort (SEME) prediction, Functional change (FC), Systematic mapping study (SMS)}
}

@article{10.1007/s00521-020-05051-x,
author = {Yin, Xiangbao},
title = {Driven by machine learning to intelligent damage recognition of terminal optical components},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {2},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05051-x},
doi = {10.1007/s00521-020-05051-x},
abstract = {In order to realize the terminal optical element online detection system in the Shenguang III system, each optical element in each terminal optical component in the target room is detected. The research on the optical damage of terminal optical components focuses on the search for damage points, the extraction of damage information, and the classification of damage types. In addition, damage classification and identification of terminal optical components are performed through machine learning, and infrared nondestructive testing is used as technical support to improve the identification model and reduce the complexity of the spectral model. After studying the preprocessing and dimensionality reduction methods of near-infrared spectroscopy, this paper compares the effects of different preprocessing methods and screening feature methods and combines different modeling methods to conduct experiments. The research results show that the method proposed in this paper has certain effects.},
journal = {Neural Comput. Appl.},
month = jan,
pages = {789–804},
numpages = {16},
keywords = {Infrared nondestructive testing, Damage identification, Terminal optics, Machine learning}
}

@article{10.1016/j.asoc.2016.08.025,
author = {Erturk, Ezgi and Akcapinar Sezer, Ebru},
title = {Iterative software fault prediction with a hybrid approach},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.08.025},
doi = {10.1016/j.asoc.2016.08.025},
abstract = {Display Omitted To make software fault prediction (SFP) more beneficial, it should be into service at the beginning of the project.A novel prediction methodology based on existing methods (i.e. FIS, ANN) are proposed here.Version based development of software projects are considered to design an iterative prediction approach.Proposed methodology is developed as Eclipse plugin.Experiments show that proposed methodology gives promising results to use SFP in daily routine of software development phases. In this study, we consider a software fault prediction task that can assist a developer during the lifetime of a project. We aim to improve the performance of software fault prediction task while keeping it as applicable. Initial predictions are constructed by Fuzzy Inference Systems (FISs), whereas subsequent predictions are performed by data-driven methods. In this paper, an Artificial Neural Network and Adaptive Neuro Fuzzy Inference System are employed. We propose an iterative prediction model that begins with a FIS when no data are available for the software project and continues with a data-driven method when adequate data become available. To prove the usability of this iterative prediction approach, software fault prediction experiments are performed using expert knowledge for the initial version and information about previous versions for subsequent versions. The datasets employed in this paper comprise different versions of Ant, jEdit, Camel, Xalan, Log4j and Lucene projects from the PROMISE repository. The metrics of the models are common object-oriented metrics, such as coupling between objects, weighted methods per class and response for a class. The results of the models are evaluated according to the receiver operating characteristics with the area under the curve approach. The results indicate that the iterative software fault prediction is successful and can be transformed into a tool that can automatically locate fault-prone modules due to its well-organized information flow. We also implement the proposed methodology as a plugin for the Eclipse environment.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1020–1033},
numpages = {14},
keywords = {Software fault prediction, Iterative prediction, Fuzzy inference systems, Artificial neural network, Adaptive neuro fuzzy inference system}
}

@article{10.1016/j.jss.2019.110486,
author = {Barbez, Antoine and Khomh, Foutse and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l},
title = {A machine-learning based ensemble method for anti-patterns detection},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {161},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110486},
doi = {10.1016/j.jss.2019.110486},
journal = {J. Syst. Softw.},
month = mar,
numpages = {11},
keywords = {Ensemble methods, Machine learning, Anti-patterns, Software quality}
}

@article{10.1155/2021/6627588,
author = {Xie, Yuan and Zhao, Jisheng and Qiang, Baohua and Mi, Luzhong and Tang, Chenghua and Li, Longge and Xue, Xingsi},
title = {Attention Mechanism-Based CNN-LSTM Model for Wind Turbine Fault Prediction Using SSN Ontology Annotation},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/6627588},
doi = {10.1155/2021/6627588},
abstract = {The traditional model for wind turbine fault prediction is not sensitive to the time sequence data and cannot mine the deep connection between the time series data, resulting in poor generalization ability of the model. To solve this problem, this paper proposes an attention mechanism-based CNN-LSTM model. The semantic sensor data annotated by SSN ontology is used as input data. Firstly, CNN extracts features to get high-level feature representation from input data. Then, the latent time sequence connection of features in different time periods is learned by LSTM. Finally, the output of LSTM is input into the attention mechanism module to obtain more fault-related target information, which improves the efficiency, accuracy, and generalization ability of the model. In addition, in the data preprocessing stage, the random forest algorithm analyzes the feature correlation degree of the data to get the features of high correlation degree with the wind turbine fault, which further improves the efficiency, accuracy, and generalization ability of the model. The model is validated on the icing fault dataset of No. 21 wind turbine and the yaw dataset of No. 4 wind turbine. The experimental results show that the proposed model has better efficiency, accuracy, and generalization ability than RNN, LSTM, and XGBoost.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {12}
}

@inproceedings{10.1007/978-3-030-86475-0_15,
author = {Azimi, Shelernaz and Pahl, Claus},
title = {The Effect of IoT Data Completeness and Correctness on Explainable Machine Learning Models},
year = {2021},
isbn = {978-3-030-86474-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86475-0_15},
doi = {10.1007/978-3-030-86475-0_15},
abstract = {Many systems in the Edge Cloud, the Internet-of-Things or Cyber-Physical Systems are built for processing data, which is delivered from sensors and devices, transported, processed and consumed locally by actuators. This, given the regularly high volume of data, permits Artificial Intelligence (AI) strategies like Machine Learning (ML) to be used to generate the application and management functions needed. The quality of both source data and machine learning model is here unavoidably of high significance, yet has not been explored sufficiently as an explicit connection of the ML model quality that are created through ML procedures to the quality of data that the model functions consume in their construction. Here, we investigated the link between input data quality for ML function construction and the quality of these functions in data-driven software systems towards explainable model construction through an experimental approach with IoT Data using decision trees. We have 3 objectives in this research: 1. Search for indicators that influence data quality such as correctness and completeness and model construction factors on accuracy, precision and recall. 2. Estimate the impact of variations in model construction and data quality. 3. Identify change patterns that can be attributed to specific input changes.},
booktitle = {Database and Expert Systems Applications: 32nd International Conference, DEXA 2021, Virtual Event, September 27–30, 2021, Proceedings, Part II},
pages = {151–160},
numpages = {10},
keywords = {Explainable AI, Data quality, IoT systems, Machine learning, Data correctness, Data completeness, Decision trees}
}

@article{10.1016/j.sysarc.2021.102298,
author = {Fern\'{a}ndez, Javier and Perez, Jon and Agirre, Irune and Allende, Imanol and Abella, Jaume and Cazorla, Francisco J.},
title = {Towards functional safety compliance of matrix–matrix multiplication for machine learning-based autonomous systems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {121},
number = {C},
issn = {1383-7621},
url = {https://doi.org/10.1016/j.sysarc.2021.102298},
doi = {10.1016/j.sysarc.2021.102298},
journal = {J. Syst. Archit.},
month = dec,
numpages = {14},
keywords = {Error detection, Functional safety, Machine learning}
}

@inproceedings{10.1145/3425174.3425226,
author = {Santos, Sebasti\~{a}o H. N. and da Silveira, Beatriz Nogueira Carvalho and Andrade, Stev\~{a}o A. and Delamaro, M\'{a}rcio and Souza, Simone R. S.},
title = {An Experimental Study on Applying Metamorphic Testing in Machine Learning Applications},
year = {2020},
isbn = {9781450387552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425174.3425226},
doi = {10.1145/3425174.3425226},
abstract = {Machine learning techniques have been successfully employed in various areas and, in particular, for the development of healthcare applications, aiming to support in more effective and faster diagnostics (such as cancer diagnosis). However, machine learning models may present uncertainties and errors. Errors in the training process, classification, and evaluation can generate incorrect results and, consequently, to wrong clinical decisions, reducing the professionals' confidence in the use of such techniques. Similar to other application domains, the quality should be guaranteed to produce more reliable models capable of assisting health professionals in their daily activities. Metamorphic testing can be an interesting option to validate machine learning applications. Using this testing approach is possible to define relationships that define changes to be made in the application's input data to identify faults. This paper presents an experimental study to evaluate the effectiveness of metamorphic testing to validate machine learning applications. A Machine learning application to verify breast cancer diagnostic was developed, using an available dataset composed of 569 samples whose data were taken from breast cancer images, and used as the software under test, in which the metamorphic testing was applied. The results indicate that metamorphic testing can be an alternative to support the validation of machine learning applications.},
booktitle = {Proceedings of the 5th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {98–106},
numpages = {9},
keywords = {Metamorphic Test, Machine Learning, Experimental Study},
location = {Natal, Brazil},
series = {SAST '20}
}

@article{10.1016/j.eswa.2014.10.025,
author = {Erturk, Ezgi and Sezer, Ebru Akcapinar},
title = {A comparison of some soft computing methods for software fault prediction},
year = {2015},
issue_date = {March 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2014.10.025},
doi = {10.1016/j.eswa.2014.10.025},
abstract = {Software fault prediction is implemented with ANN, SVM and ANFIS.First ANFIS implementation is applied to solve fault prediction problem.Parameters are discussed in neuro fuzzy approach.Experiments show that the application of ANFIS to the software fault prediction problem is highly reasonable. The main expectation from reliable software is the minimization of the number of failures that occur when the program runs. Determining whether software modules are prone to fault is important because doing so assists in identifying modules that require refactoring or detailed testing. Software fault prediction is a discipline that predicts the fault proneness of future modules by using essential prediction metrics and historical fault data. This study presents the first application of the Adaptive Neuro Fuzzy Inference System (ANFIS) for the software fault prediction problem. Moreover, Artificial Neural Network (ANN) and Support Vector Machine (SVM) methods, which were experienced previously, are built to discuss the performance of ANFIS. Data used in this study are collected from the PROMISE Software Engineering Repository, and McCabe metrics are selected because they comprehensively address the programming effort. ROC-AUC is used as a performance measure. The results achieved were 0.7795, 0.8685, and 0.8573 for the SVM, ANN and ANFIS methods, respectively.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {1872–1879},
numpages = {8},
keywords = {Support Vector Machines, Software fault prediction, McCabe metrics, Artificial Neural Networks, Adaptive neuro fuzzy systems}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00049,
author = {Zhu, Junjie and Long, Teng and Memon, Atif},
title = {Automatically authoring regression tests for machine-learning based systems},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00049},
doi = {10.1109/ICSE-SEIP52600.2021.00049},
abstract = {Two key design characteristics of machine learning (ML) systems---their ever-improving nature, and learning-based emergent functional behavior---create a moving target, posing new challenges for authoring/maintaining functional regression tests. We identify four specific challenges and address them by developing a new general methodology to automatically author and maintain tests. In particular, we use the volume of production data to periodically refresh our large corpus of test inputs and expected outputs; we use perturbation of the data to obtain coverage-adequate tests; and we use clustering to help identify patterns of failures that are indicative of software bugs. We demonstrate our methodology on an ML-based context-aware Speller. Our coverage-adequate, approx. 1 million regression test cases, automatically authored and maintained for Speller (1) are virtually maintenance free, (2) detect a higher number of Speller failures than previous manually-curated tests, (3) have better coverage of previously unknown functional boundaries of the ML component, and (4) lend themselves to automatic failure triaging by clustering and prioritizing subcategories of tests with over-represented failures. We identify several systematic failure patterns which were due to previously undetected bugs in the Speller, e.g., (1) when the user misses the first letter in a short word, and (2) when the user mistakenly inserts a character in the last token of an address; these have since been fixed.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {374–383},
numpages = {10},
keywords = {spelling correction, ML-based testing, ML testing},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@inproceedings{10.1109/ICMLA.2009.18,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan},
title = {Feature Selection with Imbalanced Data for Software Defect Prediction},
year = {2009},
isbn = {9780769539263},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2009.18},
doi = {10.1109/ICMLA.2009.18},
abstract = {In this paper, we study the learning impact of data sampling followed by attribute selection on the classification models built with binary class imbalanced data within the scenario of software quality engineering. We use a wrapper-based attribute ranking technique to select a subset of attributes, and the random undersampling technique (RUS) on the majority class to alleviate the negative effects of imbalanced data on the prediction models. The datasets used in the empirical study were collected from numerous software projects. Five data preprocessing scenarios were explored in these experiments, including: (1) training on the original, unaltered fit dataset, (2) training on a sampled version of the fit dataset, (3) training on an unsampled version of the fit dataset using only the attributes chosen by feature selection based on the unsampled fit dataset, (4) training on an unsampled version of the fit dataset using only the attributes chosen by feature selection based on a sampled version of the fit dataset, and (5) training on a sampled version of the fit dataset using only the attributes chosen by feature selection based on the sampled version of the fit dataset. We compared the performances of the classification models constructed over these five different scenarios. The results demonstrate that the classification models constructed on the sampled fit data with or without feature selection (case 2 and case 5) significantly outperformed the classification models built with the other cases (unsampled fit data). Moreover, the two scenarios using sampled data (case 2 and case 5) showed very similar performances, but the subset of attributes (case 5) is only around 15% or 30% of the complete set of attributes (case 2).},
booktitle = {Proceedings of the 2009 International Conference on Machine Learning and Applications},
pages = {235–240},
numpages = {6},
keywords = {wrapper-based attribute ranking, software defect prediction, imbalanced data, feature selection},
series = {ICMLA '09}
}

@article{10.1016/j.infsof.2013.02.009,
author = {Radjenovi\'{c}, Danijel and Heri\v{c}ko, Marjan and Torkar, Richard and \v{Z}ivkovi\v{c}, Ale\v{s}},
title = {Software fault prediction metrics},
year = {2013},
issue_date = {August 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.02.009},
doi = {10.1016/j.infsof.2013.02.009},
abstract = {ContextSoftware metrics may be used in fault prediction models to improve software quality by predicting fault location. ObjectiveThis paper aims to identify software metrics and to assess their applicability in software fault prediction. We investigated the influence of context on metrics' selection and performance. MethodThis systematic literature review includes 106 papers published between 1991 and 2011. The selected papers are classified according to metrics and context properties. ResultsObject-oriented metrics (49%) were used nearly twice as often compared to traditional source code metrics (27%) or process metrics (24%). Chidamber and Kemerer's (CK) object-oriented metrics were most frequently used. According to the selected studies there are significant differences between the metrics used in fault prediction performance. Object-oriented and process metrics have been reported to be more successful in finding faults compared to traditional size and complexity metrics. Process metrics seem to be better at predicting post-release faults compared to any static code metrics. ConclusionMore studies should be performed on large industrial software systems to find metrics more relevant for the industry and to answer the question as to which metrics should be used in a given context.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {1397–1418},
numpages = {22},
keywords = {Systematic literature review, Software metric, Software fault prediction}
}

@inproceedings{10.1007/978-3-030-54407-2_17,
author = {Djavadifar, Abtin and Graham-Knight, John Brandon and Gupta, Kashish and K\"{o}rber, Marian and Lasserre, Patricia and Najjaran, Homayoun},
title = {Robot-Assisted Composite Manufacturing Based on Machine Learning Applied to Multi-view Computer Vision},
year = {2019},
isbn = {978-3-030-54406-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-54407-2_17},
doi = {10.1007/978-3-030-54407-2_17},
abstract = {This paper introduces an automated wrinkle detection method on semi-finished fiber products in the aerospace manufacturing industry. Machine learning, computer vision techniques, and evidential reasoning are combined to detect wrinkles during the draping process of fibre-reinforced materials with an industrial robot. A well-performing Deep Convolutional Neural Network (DCNN) was developed based on a preliminary, hand-labelled dataset captured on a functioning robotic system used in a composite manufacturing facility. Generalization of this model to different, unlearned wrinkle features naturally compromises detection accuracy. To alleviate this problem, the proposed method employs computer vision techniques and belief functions to enhance defect detection accuracy. Co-temporal views of the same fabric are extracted, and individual detection results obtained from the DCNN are fused using the Dempster-Shafer Theory (DST). By the application of the DST rule of combination, the overall wrinkle detection accuracy for the generalized case is greatly improved in this composite manufacturing facility.},
booktitle = {Smart Multimedia: Second International Conference, ICSM 2019, San Diego, CA, USA, December 16–18, 2019, Revised Selected Papers},
pages = {199–211},
numpages = {13},
keywords = {Classification, Data fusion, Belief functions, Deep neural network, Machine learning, Process automation, Wrinkle detection, Composite manufacturing, Computer vision},
location = {San Diego, CA, USA}
}

@inproceedings{10.1109/IECON.2019.8927370,
author = {Gao, Kai and Lyu, Lijun and Huang, Hua and Fu, ChenZhao and Chen, Fuchun and Jin, Lijun},
title = {Insulation Defect Detection of Electrical Equipment Based on Infrared and Ultraviolet Photoelectric Sensing Technology},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON.2019.8927370},
doi = {10.1109/IECON.2019.8927370},
abstract = {Insulation faults account for a high proportion in the faults of electrical equipment. Insulation defects or faults of electrical equipment may cause excessive temperature rise or partial discharge, which can be used as the criteria of insulation state of electrical equipment. However, the existing detection methods can't meet the requirements of safe and stable operation of modern substations. The exploration of new methods for temperature rise and partial discharge detection has become important for online detection of electrical equipment. Photoelectric sensor is a device that converts optical signal into electrical signal. It can be used to detect the optical signal generated by the running electrical equipment. The infrared photoelectric sensor can detect the temperature of electrical equipment, and the ultraviolet photoelectric sensor can detect the ultraviolet pulse signal generated by partial discharge of electrical equipment. In this paper, the characteristics of infrared photoelectric sensor's temperature changing with the detection distance are studied, and then the optimum detection distance is obtained. The relationship between the output pulse signal of ultraviolet photoelectric sensor and discharge intensity is analyzed, and the attenuation characteristics of pulse signal with the increase of propagation distance are also analyzed. The optimum placement position is selected. An insulation defect detection system for electrical equipment based on infrared and ultraviolet photoelectric sensing technology is constructed. Based on the adaptive fuzzy neural network, the insulation state of electrical equipment is synthetically judged by the signals of the infrared and ultraviolet photoelectric sensors. Experimental results show that through the combined detection of infrared and ultraviolet photoelectric sensors, and then information fusion diagnosis, it can effectively reduce the single sensor's misjudgment caused by one-sided information, and the accuracy of fault diagnosis is significantly improved.},
booktitle = {IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society},
pages = {2184–2189},
numpages = {6},
location = {Lisbon, Portugal}
}

@article{10.1007/s11042-017-4419-1,
author = {Singh, Sandip Kumar and Kumar, Sandeep and Dwivedi, J. P.},
title = {Compound fault prediction of rolling bearing using multimedia data},
year = {2017},
issue_date = {Sep 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {18},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-017-4419-1},
doi = {10.1007/s11042-017-4419-1},
abstract = {Catastrophic failure of mechanical systems due to faults occurring on rolling bearing is still a great challenge. These faults, which are of multiple type, are compounded in nature. Vibration analysis of multimedia signals is one of the most effective techniques for the health monitoring of these bearings. A compound fault signal usually consists of multiple characteristic signals and strong confusion noise, which makes it a tough task to separate weak fault signals from them. To resolve the compound fault diagnosis problem of rolling bearings byseparation of multimedia signals' (obtained from acoustic or acceleration sensors), ensemble empirical mode decomposition (EEMD) method along with some classifier (like independent component analysis (ICA) technique) has been used to some degree of success. But, they are not found capable of detecting difficult faults existing on small balls of the bearing. In order to solve this problem, we are going to propose a new method based on use of Combined Mode Functions (CMF) for selecting the intrinsic mode functions(IMFs) instead of the maximum cross correlation coefficient based EEMD technique, sandwiched with, Convolution Neural Networks (CNN), which are deep neural nets, used as fault classifiers. This composite CNN-CMF-EEMD methodovercomes the deficiencies of other approaches, such as the inability to learn the complex non-linear relationships in fault diagnosis issues and fine compound faults like those occurring on small balls of the bearing. The difficult compound faults can be separated effectively by executing CNN-CMF-EEMD method, which makes the fault features more easily extracted and more clearly identified. Experimental results reinforce the effectiveness of using CNN-CMF--EEMD technique for fine compound faults. A comparison of CNN-CMF-EEMD with Artificial Neural Networks (ANN) based ANN-CMF-EEMD shows the capability of CNN as a powerful classifier in the domain of compound fault features of rolling bearing.},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {18771–18788},
numpages = {18},
keywords = {Multimedia signals, Intrinsic mode functions, Independent component analysis, Ensemble empirical mode distribution, Convolution neural network, Compound faults, Combined mode functions, Artificial neural networks}
}

@article{10.1007/s00521-013-1442-7,
author = {Xie, Liangjun and Huang, Rui and Gu, Nong and Cao, Zhiqiang},
title = {A novel defect detection and identification method in optical inspection},
year = {2014},
issue_date = {June      2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {7–8},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-013-1442-7},
doi = {10.1007/s00521-013-1442-7},
abstract = {Optical inspection techniques have been widely used in industry as they are non-destructive. Since defect patterns are rooted from the manufacturing processes in semiconductor industry, efficient and effective defect detection and pattern recognition algorithms are in great demand to find out closely related causes. Modifying the manufacturing processes can eliminate defects, and thus to improve the yield. Defect patterns such as rings, semicircles, scratches, and clusters are the most common defects in the semiconductor industry. Conventional methods cannot identify two scale-variant or shift-variant or rotation-variant defect patterns, which in fact belong to the same failure causes. To address these problems, a new approach is proposed in this paper to detect these defect patterns in noisy images. First, a novel scheme is developed to simulate datasets of these 4 patterns for classifiers' training and testing. Second, for real optical images, a series of image processing operations have been applied in the detection stage of our method. In the identification stage, defects are resized and then identified by the trained support vector machine. Adaptive resonance theory network 1 is also implemented for comparisons. Classification results of both simulated data and real noisy raw data show the effectiveness of our method.},
journal = {Neural Comput. Appl.},
month = jun,
pages = {1953–1962},
numpages = {10},
keywords = {Support vector machine, Optical inspection, Defect detection, Classification, Adaptive resonance theory network}
}

@article{10.1155/2020/6688075,
author = {Naseem, Rashid and Khan, Bilal and Ahmad, Arshad and Almogren, Ahmad and Jabeen, Saima and Hayat, Bashir and Shah, Muhammad Arif and Uddin, M. Irfan},
title = {Investigating Tree Family Machine Learning Techniques for a Predictive System to Unveil Software Defects},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1076-2787},
url = {https://doi.org/10.1155/2020/6688075},
doi = {10.1155/2020/6688075},
abstract = {Software defects prediction at the initial period of the software development life cycle remains a critical and important assignment. Defect prediction and correctness leads to the assurance of the quality of software systems and has remained integral to study in the previous years. The quick forecast of imperfect or defective modules in software development can serve the development squad to use the existing assets competently and effectively to provide remarkable software products in a given short timeline. Hitherto, several researchers have industrialized defect prediction models by utilizing statistical and machine learning techniques that are operative and effective approaches to pinpoint the defective modules. Tree family machine learning techniques are well-thought-out to be one of the finest and ordinarily used supervised learning methods. In this study, different tree family machine learning techniques are employed for software defect prediction using ten benchmark datasets. These techniques include Credal Decision Tree (CDT), Cost-Sensitive Decision Forest (CS-Forest), Decision Stump (DS), Forest by Penalizing Attributes (Forest-PA), Hoeffding Tree (HT), Decision Tree (J48), Logistic Model Tree (LMT), Random Forest (RF), Random Tree (RT), and REP-Tree (REP-T). Performance of each technique is evaluated using different measures, i.e., mean absolute error (MAE), relative absolute error (RAE), root mean squared error (RMSE), root relative squared error (RRSE), specificity, precision, recall, F-measure (FM), G-measure (GM), Matthew’s correlation coefficient (MCC), and accuracy. The overall outcomes of this paper suggested RF technique by producing best results in terms of reducing error rates as well as increasing accuracy on five datasets, i.e., AR3, PC1, PC2, PC3, and PC4. The average accuracy achieved by RF is 90.2238%. The comprehensive outcomes of this study can be used as a reference point for other researchers. Any assertion concerning the enhancement in prediction through any new model, technique, or framework can be benchmarked and verified.},
journal = {Complex.},
month = jan,
numpages = {21}
}

@inproceedings{10.1145/2020390.2020405,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {An iterative semi-supervised approach to software fault prediction},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020405},
doi = {10.1145/2020390.2020405},
abstract = {Background: Many statistical and machine learning techniques have been implemented to build predictive fault models. Traditional methods are based on supervised learning. Software metrics for a module and corresponding fault information, available from previous projects, are used to train a fault prediction model. This approach calls for a large size of training data set and enables the development of effective fault prediction models. In practice, data collection costs, the lack of data from earlier projects or product versions may make large fault prediction training data set unattainable. Small size of the training set that may be available from the current project is known to deteriorate the performance of the fault predictive model. In semi-supervised learning approaches, software modules with known or unknown fault content can be used for training.Aims: To implement and evaluate a semi-supervised learning approach in software fault prediction.Methods: We investigate an iterative semi-supervised approach to software quality prediction in which a base supervised learner is used within a semi-supervised application.Results: We varied the size of labeled software modules from 2% to 50% of all the modules in the project. After tracking the performance of each iteration in the semi-supervised algorithm, we observe that semi-supervised learning improves fault prediction if the number of initially labeled software modules exceeds 5%.Conclusion: The semi-supervised approach outperforms the corresponding supervised learning approach when both use random forest as base classification algorithm.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {15},
numpages = {10},
keywords = {fault prediction, semi-supervised learning},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@article{10.1504/ijwmc.2020.109275,
author = {Dai, Xiaohong and Zhao, Yingji and Zhu, Chaoping},
title = {A study of an improved RCNN network model for surface defect detection algorithm of precision workpiece and its realisation},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {19},
number = {1},
issn = {1741-1084},
url = {https://doi.org/10.1504/ijwmc.2020.109275},
doi = {10.1504/ijwmc.2020.109275},
abstract = {In this paper, an improved RCNN algorithm for surface defect detection of precision workpiece is proposed. During model training, the original image is processed by data amplification, which overcomes the phenomenon of model overfitting caused by too small data set. The fuzzy image is processed by the conditional generation antagonism network, which guarantees the authenticity of the image and eliminates the fuzziness of the image. On the basis of network selection, through network training and comparative analysis, ResNet101 was selected as the basic network for feature extraction. By combining the network performance, the number of convolutional layers (model depth), system efficiency and other factors, and taking advantage of the spatial characteristics of images, the irregular cross convolution kernel idea and the differentiated convolution kernel design method are adopted to realise the feature fusion of different convolutional layers. Embedded in the target Network Squeeze and Excitation (SE) module channel features fusion module, the Feature Pyramid Network (FPN) module, ROI Network module. The experimental results show that the improved network model is used to realise the location and classification of defects on the workpiece surface. The detection accuracy was 91% and the recall rate was 93%.},
journal = {Int. J. Wire. Mob. Comput.},
month = jan,
pages = {95–105},
numpages = {10},
keywords = {target detection, deep learning, convolution neural network, defect identification, precision workpiece}
}

@article{10.1007/s10044-012-0305-7,
author = {Kim, Hye Won and Yoo, Suk I.},
title = {Defect detection using feature point matching for non-repetitive patterned images},
year = {2014},
issue_date = {May       2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {2},
issn = {1433-7541},
url = {https://doi.org/10.1007/s10044-012-0305-7},
doi = {10.1007/s10044-012-0305-7},
abstract = {Defect detection is an important technology for the quality control in the production process of wafer, TFT-LCD and PCB. Inspection is performed using the finished product's image. The images are classified into two different groups--images with a repetitive pattern on a regular cycle and images without a repetitive pattern. A standard object for comparison is required, because manual defect detection is not possible for areas without repetitive patterns. In such areas, defect detection occurs through contrasting a reference pattern to the pattern being inspected. Methods of inspection using reference image have been researched but have limitations due to their requirement of precise alignment of the images. This paper proposes a method of defect detection to overcome such limitation using feature point matching. Feature points are extracted using a corner detector and detects defect by finding a correspondence between two feature point sets. Performance of the proposed method is evaluated by using Wafer SEM images and compared with conventional methods. Experiment results demonstrate the proposed method achieves higher detection accuracy than conventional methods and is less sensitive to alignment error and noise.},
journal = {Pattern Anal. Appl.},
month = may,
pages = {415–429},
numpages = {15},
keywords = {Inspection, Feature point matching, Defect detection, Computer vision}
}

@article{10.1016/j.jss.2016.02.015,
author = {Rana, Rakesh and Staron, Miroslaw and Berger, Christian and Hansson, J\"{o}rgen and Nilsson, Martin and Meding, Wilhelm},
title = {Analyzing defect inflow distribution and applying Bayesian inference method for software defect prediction in large software projects},
year = {2016},
issue_date = {July 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {117},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.02.015},
doi = {10.1016/j.jss.2016.02.015},
abstract = {Defect inflow distribution of 14 large projects from industry &amp; OSS is analyzed.6 standard distributions are evaluated for their ability to fit the defect inflow.12 out of 14 projects defect inflow data was described best by beta distribution.Historical projects information is useful for early defect prediction using Bayesian inference method. Tracking and predicting quality and reliability is a major challenge in large and distributed software development projects. A number of standard distributions have been successfully used in reliability engineering theory and practice, common among these for modeling software defect inflow being exponential, Weibull, beta and Non-Homogeneous Poisson Process (NHPP). Although standard distribution models have been recognized in reliability engineering practice, their ability to fit defect data from proprietary and OSS software projects is not well understood. Lack of knowledge about underlying defect inflow distribution also leads to difficulty in applying Bayesian based inference methods for software defect prediction. In this paper we explore the defect inflow distribution of total of fourteen large software projects/release from two industrial domain and open source community. We evaluate six standard distributions for their ability to fit the defect inflow data and also assess which information criterion is practical for selecting the distribution with best fit. Our results show that beta distribution provides the best fit to the defect inflow data for all industrial projects as well as majority of OSS projects studied. In the paper we also evaluate how information about defect inflow distribution from historical projects is applied for modeling the prior beliefs/experience in Bayesian analysis which is useful for making software defect predictions early during the software project lifecycle.},
journal = {J. Syst. Softw.},
month = jul,
pages = {229–244},
numpages = {16},
keywords = {Software, SRGM, Defect Inflow}
}

@inproceedings{10.1145/3376067.3376113,
author = {Qian, Kun},
title = {Automated Detection of Steel Defects via Machine Learning based on Real-Time Semantic Segmentation},
year = {2020},
isbn = {9781450376822},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3376067.3376113},
doi = {10.1145/3376067.3376113},
abstract = {To improve automation, increase efficiency, and maintain high quality in the production of steel, applying modern machine learning techniques to help detect steel defects has been the research focus in the steel industry, since an unprecedented revolution in image semantic segmentation has been witnessed in the past few years. In the traditional production process of steel materials, localizing and classifying surface defects manually on a steel sheet is inefficient and error-prone. Therefore, it's a key challenge to achieve automated detection of steel surface defects in image pixel level, leaving an urgent and critical issue to be addressed. In this paper, to accomplish this crucial task, we apply a series of machine learning algorithms of real-time semantic segmentation, utilizing neural networks with encoder-decoder architectures based on Unet and feature pyramid network (FPN). The image dataset of steel defects is provided by Severstal, the largest steel company in Russia, through a featured code competition in the Kaggle community. The results show that the ensemble algorithm of several neural networks with encoder-decoder architectures has a decent performance regarding both time cost and segmentation accuracy. Our machine learning algorithms achieve dice coefficients over 0.915 and 0.905 at a speed of over 1.5 images per second on the public test set and private test set on the Kaggle platform, respectively, which locates at the top 2% among all teams in the competition.},
booktitle = {Proceedings of the 3rd International Conference on Video and Image Processing},
pages = {42–46},
numpages = {5},
keywords = {Steel Defect Detection, Semantic Segmentation, Machine Learning, Encoder-Decoder Neural Network},
location = {Shanghai, China},
series = {ICVIP '19}
}

@inproceedings{10.1109/ICMA.2018.8484328,
author = {Ge, Qingcai and Fang, Ming and Xu, Jing},
title = {Defect Detection of Industrial Products based on Improved Hough Transform},
year = {2018},
isbn = {978-1-5386-6074-4},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICMA.2018.8484328},
doi = {10.1109/ICMA.2018.8484328},
abstract = {In the industrial manufacturing process, defects of industrial products may inevitably occur. In order to detect the defects of industrial products with central symmetry distribution rules, this paper analyzes the limitations of traditional detection methods and proposes an improved detection method based on Hough transform. The method starts from the central area of the industrial product and performs directional clustering towards the direction in which the detection target is located: Firstly, obtain contour of the region of interest and the center point. Secondly, use Hough transform on the points on the contour of the Region Of Interest(ROI). Voting is performed according to the constraint rule that only passes through the direction of central area. The peak corresponding to the detected object is obtained in the voting space, and the defect of the industrial product component is obtained by estimating the peak position. Experimental results show that our algorithm has strong anti-interference ability and can solve the undetectable problems caused by the similarity between the detection target and the background. It can meet the requirements of certain types of industrial production and has significant robustness compared with the traditional Hough method.},
booktitle = {2018 IEEE International Conference on Mechatronics and Automation (ICMA)},
pages = {832–836},
numpages = {5},
location = {Changchun, Jilin, China}
}

@inproceedings{10.1145/3314493.3314508,
author = {Cai, Wang and Wang, Jianzhuang and Zhou, Qi and Yang, Yang and Jiang, Ping},
title = {Equipment and Machine Learning in Welding Monitoring: A Short Review},
year = {2019},
isbn = {9781450360951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314493.3314508},
doi = {10.1145/3314493.3314508},
abstract = {Laser welding has been widely applied to various industries, effective real time monitoring can help to improve the welding efficiency and production quality. This paper makes a short review on the signal detection equipment and machine learning algorithms. It starts with a detailed introduction to some basic monitoring sensors and methods, some special monitoring methods like ICI, MOI and multiple sensor fusion technology are also talked over. The commonly used machine learning algorithms like BPNN and SVM used in welding data mining, weld defects classification and weld seam features forecasting are summarized in the end section. This fundamental work aims to provide a guideline for the selection of monitoring equipment, chose suitable machine learning algorithms for effectively classifying weld defects and realizing welding process intelligent real time monitoring.},
booktitle = {Proceedings of the 5th International Conference on Mechatronics and Robotics Engineering},
pages = {9–15},
numpages = {7},
keywords = {Sensor, Real time monitoring, Machine learning algorithms, Laser welding},
location = {Rome, Italy},
series = {ICMRE'19}
}

@article{10.1016/j.inffus.2018.10.005,
author = {Diez-Olivan, Alberto and Del Ser, Javier and Galar, Diego and Sierra, Basilio},
title = {Data fusion and machine learning for industrial prognosis: Trends and perspectives towards Industry 4.0},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {50},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2018.10.005},
doi = {10.1016/j.inffus.2018.10.005},
journal = {Inf. Fusion},
month = oct,
pages = {92–111},
numpages = {20},
keywords = {VCM, SVMs, SOM-MQE, SBM, SARMA, RNN, RBM, PoF, PCA, LOF, LAD, KDE, kNN, HMM, GRNN, GRBMs, GMM, FPCA, FFT, EWMA, EM, DWT, DBN, BPNN, ANNs, ANFIS, Industry 4.0, Machine learning, Data fusion, Data-driven prognosis}
}

@article{10.1016/j.infsof.2019.106214,
author = {Alsolai, Hadeel and Roper, Marc},
title = {A systematic literature review of machine learning techniques for software maintainability prediction},
year = {2020},
issue_date = {Mar 2020},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {119},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.106214},
doi = {10.1016/j.infsof.2019.106214},
journal = {Inf. Softw. Technol.},
month = mar,
numpages = {25},
keywords = {Dataset, Metric, Machine learning, Software maintainability prediction, Systematic literature review}
}

@article{10.1007/s10515-019-00266-2,
author = {Safdar, Safdar Aqeel and Yue, Tao and Ali, Shaukat and Lu, Hong},
title = {Using multi-objective search and machine learning to infer rules constraining product configurations},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {1–2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-019-00266-2},
doi = {10.1007/s10515-019-00266-2},
abstract = {Modern systems are being developed by integrating multiple products within/across product lines that communicate with each other through information networks. Runtime behaviors of such systems are related to product configurations and information networks. Cost-effectively supporting Product Line Engineering (PLE) of such systems is challenging mainly because of lacking the support of automation of the configuration process. Capturing rules is the key for automating the configuration process in PLE. However, there does not exist explicitly-specified rules constraining configurable parameter values of such products and product lines. Manually specifying such rules is tedious and time-consuming. To address this challenge, in this paper, we present an improved version (named as SBRM+) of our previously proposed Search-based Rule Mining (SBRM) approach. SBRM+ incorporates two machine learning algorithms (i.e., C4.5 and PART) and two multi-objective search algorithms (i.e., NSGA-II and NSGA-III), employs a clustering algorithm (i.e., k means) for classifying rules as high or low confidence rules, which are used for defining three objectives to guide the search. To evaluate SBRM+ (i.e., SBRMNSGA-II+-C45, SBRMNSGA-III+-C45, SBRMNSGA-II+-PART, and SBRMNSGA-III+-PART), we performed two case studies (Cisco and Jitsi) and conducted three types of analyses of results: difference analysis, correlation analysis, and trend analysis. Results of the analyses show that all the SBRM+ approaches performed significantly better than two Random Search-based approaches (RBRM+-C45 and RBRM+-PART) in terms of fitness values, six quality indicators, and 17 machine learning quality measurements (MLQMs). As compared to RBRM+ approaches, SBRM+ approaches have improved the quality of rules based on MLQMs up to 27% for the Cisco case study and 28% for the Jitsi case study.},
journal = {Automated Software Engg.},
month = jun,
pages = {1–62},
numpages = {62},
keywords = {Interacting products, Machine learning, Multi-objective search, Rule mining, Configuration, Product line}
}

@article{10.1016/j.csi.2017.02.003,
title = {An empirical analysis of the effectiveness of software metrics and fault prediction model for identifying faulty classes},
year = {2017},
issue_date = {August 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {53},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2017.02.003},
doi = {10.1016/j.csi.2017.02.003},
abstract = {Software fault prediction models are used to predict faulty modules at the very early stage of software development life cycle. Predicting fault proneness using source code metrics is an area that has attracted several researchers' attention. The performance of a model to assess fault proneness depends on the source code metrics which are considered as the input for the model. In this work, we have proposed a framework to validate the source code metrics and identify a suitable set of source code metrics with the aim to reduce irrelevant features and improve the performance of the fault prediction model. Initially, we applied a t-test analysis and univariate logistic regression analysis to each source code metric to evaluate their potential for predicting fault proneness. Next, we performed a correlation analysis and multivariate linear regression stepwise forward selection to find the right set of source code metrics for fault prediction. The obtained set of source code metrics are considered as the input to develop a fault prediction model using a neural network with five different training algorithms and three different ensemble methods. The effectiveness of the developed fault prediction models are evaluated using a proposed cost evaluation framework. We performed experiments on fifty six Open Source Java projects. The experimental results reveal that the model developed by considering the selected set of source code metrics using the suggested source code metrics validation framework as the input achieves better results compared to all other metrics. The experimental results also demonstrate that the fault prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low 48.89%, median- 39.26%, and high 27.86%). HighlightsFault prediction improve the effectiveness of software quality assurance activities.This paper focus on building an effective fault prediction tool.Fault prediction model using ANN and ensemble methods.We perform experiments on 56 Open Source Java projects.Fault prediction model is best suitable for projects with faulty classes less than the threshold value.},
journal = {Comput. Stand. Interfaces},
month = aug,
pages = {1–32},
numpages = {32}
}

@inproceedings{10.1145/3183440.3194992,
author = {Guo, Yuchen and Shepperd, Martin and Li, Ning},
title = {Bridging effort-aware prediction and strong classification: a just-in-time software defect prediction study},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3194992},
doi = {10.1145/3183440.3194992},
abstract = {Context: Most research into software defect prediction ignores the differing amount of effort entailed in searching for defects between software components. The result is sub-optimal solutions in terms of allocating testing resources. Recently effort-aware (EA) defect prediction has sought to redress this deficiency. However, there is a gap between previous classification research and EA prediction.Objective: We seek to transfer strong defect classification capability to efficient effort-aware software defect prediction.Method: We study the relationship between classification performance and the cost-effectiveness curve experimentally (using six open-source software data sets).Results: We observe extremely skewed distributions of change size which contributes to the lack of relationship between classification performance and the ability to find efficient test orderings for defect detection. Trimming allows all effort-aware approaches bridging high classification capability to efficient effort-aware performance.Conclusion: Effort distributions dominate effort-aware models. Trimming is a practical method to handle this problem.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {325–326},
numpages = {2},
keywords = {defect prediction, effort-aware, just-in-time, software},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3106237.3106257,
author = {Fu, Wei and Menzies, Tim},
title = {Revisiting unsupervised learning for defect prediction},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106257},
doi = {10.1145/3106237.3106257},
abstract = {Collecting quality data from software projects can be time-consuming and expensive. Hence, some researchers explore "unsupervised" approaches to quality prediction that does not require labelled data. An alternate technique is to use "supervised" approaches that learn models from project data labelled with, say, "defective" or "not-defective". Most researchers use these supervised models since, it is argued, they can exploit more knowledge of the projects. At FSE-16, Yang et al. reported startling results where unsupervised defect predictors outperformed supervised predictors for effort-aware just-in-time defect prediction. If confirmed, these results would lead to a dramatic simplification of a seemingly complex task (data mining) that is widely explored in the software engineering literature. This paper repeats and refutes those results as follows. (1) There is much variability in the efficacy of the Yang et al. predictors so even with their approach, some supervised data is required to prune weaker predictors away. (2) Their findings were grouped across N projects. When we repeat their analysis on a project-by-project basis, supervised predictors are seen to work better. Even though this paper rejects the specific conclusions of Yang et al., we still endorse their general goal. In our our experiments, supervised predictors did not perform outstandingly better than unsupervised ones for effort-aware just-in-time defect prediction. Hence, they may indeed be some combination of unsupervised learners to achieve comparable performance to supervised ones. We therefore encourage others to work in this promising area.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {72–83},
numpages = {12},
keywords = {software repository mining, empirical studies, defect prediction, data analytics for software engineering},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@article{10.1016/j.eswa.2011.04.012,
author = {Tolba, A.S.},
title = {Fast defect detection in homogeneous flat surface products},
year = {2011},
issue_date = {Sep 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {10},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2011.04.012},
doi = {10.1016/j.eswa.2011.04.012},
journal = {Expert Syst. Appl.},
month = sep,
pages = {12339–12347},
numpages = {9},
keywords = {Probabilistic neural network (PNN), Homogeneity measures, Log-Gabor filter bank, Feature extraction, Defect detection, Automated visual inspection}
}

@article{10.1016/j.compag.2020.105332,
author = {Nguyen, Van-Tho and Constant, Thi\'{e}ry and Kerautret, Bertrand and Debled-Rennesson, Isabelle and Colin, Francis},
title = {A machine-learning approach for classifying defects on tree trunks using terrestrial LiDAR},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {171},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2020.105332},
doi = {10.1016/j.compag.2020.105332},
journal = {Comput. Electron. Agric.},
month = apr,
numpages = {12},
keywords = {Standing tree grading, Random forests, Roundwood quality}
}

@article{10.1007/s10586-019-02917-1,
author = {Mohammed, Bashir and Awan, Irfan and Ugail, Hassan and Younas, Muhammad},
title = {Failure prediction using machine learning in a virtualised HPC system and application},
year = {2019},
issue_date = {Mar 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-019-02917-1},
doi = {10.1007/s10586-019-02917-1},
abstract = {Failure is an increasingly important issue in high performance computing and cloud systems. As large-scale systems continue to grow in scale and complexity, mitigating the impact of failure and providing accurate predictions with sufficient lead time remains a challenging research problem. Traditional existing fault-tolerance strategies such as regular check-pointing and replication are not adequate because of the emerging complexities of high performance computing systems. This necessitates the importance of having an effective as well as proactive failure management approach in place aimed at minimizing the effect of failure within the system. With the advent of machine learning techniques, the ability to learn from past information to predict future pattern of behaviours makes it possible to predict potential system failure more accurately. Thus, in this paper, we explore the predictive abilities of machine learning by applying a number of algorithms to improve the accuracy of failure prediction. We have developed a failure prediction model using time series and machine learning, and performed comparison based tests on the prediction accuracy. The primary algorithms we considered are the support vector machine (SVM), random forest (RF), k-nearest neighbors (KNN), classification and regression trees (CART) and linear discriminant analysis (LDA). Experimental results indicates that the average prediction accuracy of our model using SVM when predicting failure is 90% accurate and effective compared to other algorithms. This finding implies that our method can effectively predict all possible future system and application failures within the system.},
journal = {Cluster Computing},
month = jun,
pages = {471–485},
numpages = {15},
keywords = {Machine learning, High performance computing, Failure, Cloud computing}
}

@inproceedings{10.1007/978-3-319-07626-3_41,
author = {He, Ning and Zhang, Lulu and Lu, Ke},
title = {Aluminum CT Image Defect Detection Based on Segmentation and Feature Extraction},
year = {2014},
isbn = {9783319076256},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-07626-3_41},
doi = {10.1007/978-3-319-07626-3_41},
abstract = {Industrial computed tomography (CT) scanning has been used in many areas of industry for internal inspection of components. Some of the key uses for CT scanning have been flaw detection, failure analysis, metrology, assembly analysis and reverse engineering applications. In this paper we present the approach to detecting defects follows a general image processing scheme based on three steps: segmentation, feature extractions, and classification. In the first step (segmentation), potential defects are segmented using the region method. In the step of feature extraction, two main features of the potential defects are considered: geometric and intensity features. The third step, design a proper classifier. The classifier assigns a feature vector  Z  to one of the two classes: regular structure or defects, that are assigned "0" and "1", respectively. A good metric defining the similarity must be established. Experiments demonstrate that proposed method is fast and accurate to defects detection in CT image, and the method has high robustness for illumination.},
booktitle = {Proceedings of the Third International Conference on Design, User Experience, and Usability. User Experience Design for Diverse Interaction Platforms and Environments - Volume 8518},
pages = {446–454},
numpages = {9},
keywords = {Histograms of gradients, Feature extraction, Defect detection, CT image}
}

@article{10.1145/3450288,
author = {Lo, Sin Kit and Lu, Qinghua and Wang, Chen and Paik, Hye-Young and Zhu, Liming},
title = {A Systematic Literature Review on Federated Machine Learning: From a Software Engineering Perspective},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3450288},
doi = {10.1145/3450288},
abstract = {Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results and identify future trends to encourage researchers to advance their current work.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {95},
numpages = {39},
keywords = {systematic literature review, software engineering, privacy, edge learning, distributed learning, Federated learning}
}

@inproceedings{10.1145/3409501.3409543,
author = {Yan, Ziyue and Zong, Lu},
title = {Spatial Prediction of Housing Prices in Beijing Using Machine Learning Algorithms},
year = {2020},
isbn = {9781450375603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3409501.3409543},
doi = {10.1145/3409501.3409543},
abstract = {The real estate industry places key influence on almost every aspect of social economy given its great financing capacity and prolonged upstream and downstream industry chain. Therefore, predicting housing prices is regarded as an emerging topic in the recent decades. Hedonic Regression and Machine Learning Algorithms are two main methods in this field. This study aims to explore the important explanatory features and determine an accurate mechanism to implement spatial prediction of housing prices in Beijing by incorporating a list of machine learning techniques, including XGBoost, linear regression, Random Forest Regression, Ridge and Lasso Model, bagging and boosting, based on the housing price and features data in Beijing, China. Our result shows that compared to traditional hedonic method, machine learning methods demonstrate significant improvements on the accuracy of estimation despite that they are more time-costly. Moreover, it is found that XGBoost is the most accurate model in explaining and prediciting the spatial dynamics of housing prices in Beijing.},
booktitle = {Proceedings of the 2020 4th High Performance Computing and Cluster Technologies Conference &amp; 2020 3rd International Conference on Big Data and Artificial Intelligence},
pages = {64–71},
numpages = {8},
keywords = {Spatial Modeling, Prediction, Machine Learning Algorithms, Housing Price},
location = {Qingdao, China},
series = {HPCCT &amp; BDAI '20}
}

@inproceedings{10.1145/2601248.2601294,
author = {Rodriguez, Daniel and Herraiz, Israel and Harrison, Rachel and Dolado, Javier and Riquelme, Jos\'{e} C.},
title = {Preliminary comparison of techniques for dealing with imbalance in software defect prediction},
year = {2014},
isbn = {9781450324762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2601248.2601294},
doi = {10.1145/2601248.2601294},
abstract = {Imbalanced data is a common problem in data mining when dealing with classification problems, where samples of a class vastly outnumber other classes. In this situation, many data mining algorithms generate poor models as they try to optimize the overall accuracy and perform badly in classes with very few samples. Software Engineering data in general and defect prediction datasets are not an exception and in this paper, we compare different approaches, namely sampling, cost-sensitive, ensemble and hybrid approaches to the problem of defect prediction with different datasets preprocessed differently. We have used the well-known NASA datasets curated by Shepperd et al. There are differences in the results depending on the characteristics of the dataset and the evaluation metrics, especially if duplicates and inconsistencies are removed as a preprocessing step.Further Results and replication package: http://www.cc.uah.es/drg/ease14},
booktitle = {Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {43},
numpages = {10},
keywords = {imbalanced data, defect prediction, data quality},
location = {London, England, United Kingdom},
series = {EASE '14}
}

@article{10.4018/IJSSCI.2016070102,
author = {Rashid, Ekbal},
title = {R4 Model for Case-Based Reasoning and Its Application for Software Fault Prediction},
year = {2016},
issue_date = {July 2016},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {3},
issn = {1942-9045},
url = {https://doi.org/10.4018/IJSSCI.2016070102},
doi = {10.4018/IJSSCI.2016070102},
abstract = {Making R4 model effective and efficient I have introduced some new features, i.e., renovation of knowledgebase KBS and reducing the maintenance cost by removing the duplicate record from the KBS. Renovation of knowledgebase is the process of removing duplicate record stored in knowledgebase and adding world new problems along with world new solutions. This paper explores case-based reasoning and its applications for software quality improvement through early prediction of error patterns. It summarizes a variety of techniques for software quality prediction in the domain of software engineering. The system predicts the error level with respect to LOC and with respect to development time, and both affects the quality level. This paper also reviews four existing models of case-based reasoning CBR. The paper presents a work in which I have expanded our previous work Rashid et al., 2012. I have used different similarity measures to find the best method that increases reliability. The present work is also credited through introduction of some new terms like coefficient of efficiency, i.e., developer's ability.},
journal = {Int. J. Softw. Sci. Comput. Intell.},
month = jul,
pages = {19–38},
numpages = {20},
keywords = {Software Fault Prediction, Similarity Function, Reliability, Machine Learning, LOC, Development Time}
}

@inproceedings{10.1109/ICMLA.2012.13,
author = {Zhou, Jian and Semenovich, Dimitri and Sowmya, Arcot and Wang, Jun},
title = {Sparse Dictionary Reconstruction for Textile Defect Detection},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.13},
doi = {10.1109/ICMLA.2012.13},
abstract = {Inspired by the image de-noising techniques using learned dictionaries and sparse representation, we present a fabric defect detection scheme via sparse dictionary reconstruction. Fabric defects can be regarded as local anomalies against the relatively homogeneous texture background. Following from the flexibility of sparse representation, normal fabric samples can be efficiently represented using a linear combination of a few elements of a learned dictionary. When modeling new samples with a learned dictionary, tuned to the input data containing normal fabric structural features, abnormal or defective samples are likely to have larger dissimilarity than normal samples. We evaluate the proposed methods using ten different fabric types. Experimental results show that our method has many advantages in defect detection, especially in adapting variation of fabric textures.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 01},
pages = {21–26},
numpages = {6},
keywords = {Sparse representation, Novelty detection, Image reconstruction, Fabric defect detection, Dictionary learning},
series = {ICMLA '12}
}

@article{10.1016/j.asoc.2019.02.008,
author = {Juneja, Kapil},
title = {A fuzzy-filtered neuro-fuzzy framework for software fault prediction for inter-version and inter-project evaluation},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {77},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2019.02.008},
doi = {10.1016/j.asoc.2019.02.008},
journal = {Appl. Soft Comput.},
month = apr,
pages = {696–713},
numpages = {18},
keywords = {Fuzzy, Classification, Intra project, Inter project, Defect Prediction}
}

@article{10.1111/mice.12351,
author = {Li, Ruoxing and Yuan, Yachao and Zhang, Wei and Yuan, Yali},
title = {Unified Vision‐Based Methodology for Simultaneous Concrete Defect Detection and Geolocalization},
year = {2018},
issue_date = {July 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {7},
issn = {1093-9687},
url = {https://doi.org/10.1111/mice.12351},
doi = {10.1111/mice.12351},
abstract = {Vision‐based autonomous inspection of concrete surface defects is crucial for efficient maintenance and rehabilitation of infrastructures and has become a research hot spot. However, most existing vision‐based inspection methods mainly focus on detecting one kind of defect in nearly uniform testing background where defects are relatively large and easily recognizable. But in the real‐world scenarios, multiple types of defects often occur simultaneously. And most of them occupy only small fractions of inspection images and are swamped in cluttered background, which easily leads to missed and false detections. In addition, the majority of the previous researches only focus on detecting defects but few of them pay attention to the geolocalization problem, which is indispensable for timely performing repair, protection, or reinforcement works. And most of them rely heavily on GPS for tracking the locations of the defects. However, this method is sometimes unreliable within infrastructures where the GPS signals are easily blocked, which causes a dramatic increase in searching costs. To address these limitations, we present a unified and purely vision‐based method denoted as defects detection and localization network, which can detect and classify various typical types of defects under challenging conditions while simultaneously geolocating the defects without requiring external localization sensors. We design a supervised deep convolutional neural network and propose novel training methods to optimize its performance on specific tasks. Extensive experiments show that the proposed method is effective with a detection accuracy of 80.7% and a localization accuracy of 86% at 0.41 s per image (at a scale of 1,200 pixels in the field test experiment), which is ideal for integration within intelligent autonomous inspection systems to provide support for practical applications.},
journal = {Comput.-Aided Civ. Infrastruct. Eng.},
month = jun,
pages = {527–544},
numpages = {18}
}

@article{10.3233/IDT-170323,
author = {Nguyen, T.H. and Nguyen, T.L. and Sidorov, D.N. and Dreglea, A.I. and Vasant, Pandian and Kose, Utku},
title = {Machine learning algorithms application to road defects classification},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {12},
number = {1},
issn = {1872-4981},
url = {https://doi.org/10.3233/IDT-170323},
doi = {10.3233/IDT-170323},
abstract = {The novel approach for automatic detection and classification of road defects is proposed based on shape and texture features analysis. The system includes three main steps: defects position detection, feature contour extraction followed by classification of defects. The proposed approach is implemented in Matlab for automatic detection and classification of defects based on digital images analysis combined with machine learning algorithms such as the random forest algorithm and boosting. Segmentation is implemented using graph-cuts method and Markov random fields. The efficiency of proposed approach is demonstrated on the real data set.},
journal = {Int. Dec. Tech.},
month = jan,
pages = {59–66},
numpages = {8},
keywords = {boosting algorithm, a random forest algorithm, graph-cuts method, Markov random fields, pavement condition, Road defects}
}

@article{10.1016/j.ins.2010.04.019,
author = {Peng, Yi and Wang, Guoxun and Wang, Honggang},
title = {User preferences based software defect detection algorithms selection using MCDM},
year = {2012},
issue_date = {May, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {191},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2010.04.019},
doi = {10.1016/j.ins.2010.04.019},
abstract = {A variety of classification algorithms for software defect detection have been developed over the years. How to select an appropriate classifier for a given task is an important issue in Data mining and knowledge discovery (DMKD). Many studies have compared different types of classification algorithms and the performances of these algorithms may vary using different performance measures and under different circumstances. Since the algorithm selection task needs to examine several criteria, such as accuracy, computational time, and misclassification rate, it can be modeled as a multiple criteria decision making (MCDM) problem. The goal of this paper is to use a set of MCDM methods to rank classification algorithms, with empirical results based on the software defect detection datasets. Since the preferences of the decision maker (DM) play an important role in algorithm evaluation and selection, this paper involved the DM during the ranking procedure by assigning user weights to the performance measures. Four MCDM methods are examined using 38 classification algorithms and 13 evaluation criteria over 10 public-domain software defect datasets. The results indicate that the boosting of CART and the boosting of C4.5 decision tree are ranked as the most appropriate algorithms for software defect datasets. Though the MCDM methods provide some conflicting results for the selected software defect datasets, they agree on most top-ranked classification algorithms.},
journal = {Inf. Sci.},
month = may,
pages = {3–13},
numpages = {11},
keywords = {Software defect detection, Multi-criteria decision making (MCDM), Knowledge-driven data mining, Classification algorithm, Algorithm selection}
}

@article{10.1007/s00607-019-00781-w,
author = {Renga, Daniela and Apiletti, Daniele and Giordano, Danilo and Nisi, Matteo and Huang, Tao and Zhang, Yang and Mellia, Marco and Baralis, Elena},
title = {Data-driven exploratory models of an electric distribution network for fault prediction and diagnosis},
year = {2020},
issue_date = {May 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {102},
number = {5},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-019-00781-w},
doi = {10.1007/s00607-019-00781-w},
abstract = {Data-driven models are becoming of fundamental importance in electric distribution networks to enable predictive maintenance, to perform effective diagnosis and to reduce related expenditures, with the final goal of improving the electric service efficiency and reliability to the benefit of both the citizens and the grid operators themselves. This paper considers a dataset collected over 6 years in a real-world medium-voltage distribution network by the Supervisory Control And Data Acquisition (SCADA) system. A transparent, exploratory, and exhaustive data-mining workflow, based on data characterisation, time-windowing, association rule mining, and associative classification is proposed and experimentally evaluated to automatically identify correlations and build a prognostic–diagnostic model from the SCADA events occurring before and after specific service interruptions, i.e., network faults. Our results, evaluated by both data-driven quality metrics and domain expert interpretations, highlight the capability to assess the limited predictive capability of the SCADA events for medium-voltage distribution networks, while their effective exploitation for diagnostic purposes is promising.},
journal = {Computing},
month = may,
pages = {1199–1211},
numpages = {13},
keywords = {68T04, Associative classification, Data mining, Medium Voltage distribution networks, Fault diagnosis, Predictive maintenance, Smart grid}
}

@article{10.1007/s10845-020-01570-5,
author = {Xu, Chengjun and Zhu, Guobin},
title = {Intelligent manufacturing Lie Group Machine Learning: real-time and efficient inspection system based on fog computing},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01570-5},
doi = {10.1007/s10845-020-01570-5},
abstract = {Due to the improvement of network infrastructure and the application of Internet of Things equipment, a large number of sensors are deployed in the industrial pipeline production, and the large size of data is generated. The most typical case in the production line is product inspection, that is, defect inspection. To implement an efficient and robust detection system, in this study, we propose a classification computing model based on Lie Group Machine Learning, which can find the possible defective products in production. Usually, a workshop has a lot of assembly lines. How to process large data on so many production lines in real-time and accurately is a difficult problem. To solve this problem, we use the concept of fog computing to design the system. By offloading the computation burden from the cloud server center to the fog nodes, the system obtains the ability to deal with extremely data. Our system has two obvious advantages. The first one is to apply Lie Group Machine Learning to fog computing environment to improve the computational efficiency and robustness of the system. The other is that without increasing any production costs, it can quickly detect products, reduce network latency, and reduce the load on bandwidth. The simulations prove that, compared with the existing methods, the proposed method has an average running efficiency increase of 52.57%, an average delay reduction of 42.13%, and an average accuracy increase of 27.86%.},
journal = {J. Intell. Manuf.},
month = jan,
pages = {237–249},
numpages = {13},
keywords = {Inspection system, Fog computing, Lie group intrinsic mean, Lie Group Machine Learning}
}

@article{10.1016/j.micpro.2021.103953,
author = {Pandiaraj, K. and Sivakumar, P. and Prakash, K. Jeya},
title = {Machine learning based effective linear regression model for TSV layer assignment in 3DIC},
year = {2021},
issue_date = {Jun 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {83},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2021.103953},
doi = {10.1016/j.micpro.2021.103953},
journal = {Microprocess. Microsyst.},
month = jun,
numpages = {10},
keywords = {Tsv, through silicon via, Ic- integrated circuit, Elrm- efficient linear regression model. ml- machine learning}
}

@article{10.1016/j.engappai.2009.10.001,
author = {Pendharkar, Parag C.},
title = {Exhaustive and heuristic search approaches for learning a software defect prediction model},
year = {2010},
issue_date = {February, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {23},
number = {1},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2009.10.001},
doi = {10.1016/j.engappai.2009.10.001},
abstract = {In this paper, we propose a software defect prediction model learning problem (SDPMLP) where a classification model selects appropriate relevant inputs, from a set of all available inputs, and learns the classification function. We show that the SDPMLP is a combinatorial optimization problem with factorial complexity, and propose two hybrid exhaustive search and probabilistic neural network (PNN), and simulated annealing (SA) and PNN procedures to solve it. For small size SDPMLP, exhaustive search PNN works well and provides an (all) optimal solution(s). However, for large size SDPMLP, the use of exhaustive search PNN approach is not pragmatic and only the SA-PNN allows us to solve the SDPMLP in a practical time limit. We compare the performance of our hybrid approaches with traditional classification algorithms and find that our hybrid approaches perform better than traditional classification algorithms.},
journal = {Eng. Appl. Artif. Intell.},
month = feb,
pages = {34–40},
numpages = {7},
keywords = {Software engineering, Simulated annealing, Probabilistic neural networks, Heuristics, Exhaustive search}
}

@article{10.1134/S1054661821030068,
author = {Dementev, V. E. and Suetin, M. N. and Gaponova, M. A.},
title = {Using Machine Learning Techniques to Detect Defects in Images of Metal Structures},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {31},
number = {3},
issn = {1054-6618},
url = {https://doi.org/10.1134/S1054661821030068},
doi = {10.1134/S1054661821030068},
journal = {Pattern Recognit. Image Anal.},
month = jul,
pages = {506–512},
numpages = {7},
keywords = {signal processing systems, neural networks, deep learning, unmanned aerial vehicles}
}

@inproceedings{10.1007/978-3-030-30949-7_28,
author = {Farooq, Basit and Bao, Jinsong},
title = {Machine Learning Method for Spinning Cyber-Physical Production System Subject to Condition Monitoring},
year = {2019},
isbn = {978-3-030-30948-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30949-7_28},
doi = {10.1007/978-3-030-30949-7_28},
abstract = {Digitalization encapsulates the importance of machine condition monitoring which is subjected to predictive analytics for realizing significant improvements in the performance and reliability of rotating equipment i.e., spinning. This paper presents a machine learning approach for condition monitoring, based on a regularized deep neural network using automated diagnostics for spinning manufacturing. This article contributes a solution to find disturbances in a running system through real-time data sensing and signal to process via industrial internet of things. Because this controlled sensor network may comprise on different critical components of the same type of machines, therefore back propagation neural network based multi-sensor performance assessment and prediction strategy were developed for our system which worked as intelligent maintenance and diagnostic system. It is completely automatic requiring no manual extraction of handcrafted features.},
booktitle = {Cooperative Design, Visualization, and Engineering: 16th International Conference, CDVE 2019, Mallorca, Spain, October 6–9, 2019, Proceedings},
pages = {244–253},
numpages = {10},
keywords = {Spinning, Prognostics and health management, Machine learning, Condition monitoring, Cyber-physical production system},
location = {Mallorca, Spain}
}

@inproceedings{10.5555/1881763.1881787,
author = {Liu, Guang-Jie and Wang, Wen-Yong},
title = {Research an educational software defect prediction model based on SVM},
year = {2010},
isbn = {3642145329},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We must pay attention and find defects, defects through the prediction to quantify the quality management and quality in order to achieve this goal, requires an estimate of the various defect detection process. Software defects are the departure of software are products' anticipative function. This paper collecting the data of the software defects, then, using the SVM model the predictive values are gained analyzing the predictive results, software are organizations can improve software control measure software process and allocate testing resources effectively.},
booktitle = {Proceedings of the Entertainment for Education, and 5th International Conference on E-Learning and Games},
pages = {215–222},
numpages = {8},
keywords = {software lifecycle, software defect, educational software, SVM},
location = {Changchun, China},
series = {Edutainment'10}
}

@article{10.1007/s00500-021-06086-5,
author = {Cao, Minh-Tu and Chang, Kuan-Tsung and Nguyen, Ngoc-Mai and Tran, Van-Duc and Tran, Xuan-Linh and Hoang, Nhat-Duc},
title = {Image processing-based automatic detection of asphalt pavement rutting using a novel metaheuristic optimized machine learning approach},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {20},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06086-5},
doi = {10.1007/s00500-021-06086-5},
abstract = {Pavement rutting refers to surface depression in the wheel-path along an asphalt road which causes loss of steering control and consequently leads to serious traffic accidents. Hence, it is necessary to develop powerful methods to accurately recognize pavement rutting during road condition survey. This study presents a novel computer vision-based model to automatically identify rutting on asphalt pavement road. The model is established based on a hybridization of image processing techniques (ITPs), least squares support vector classification (LSSVC), dynamic feature selection (FS) method, and forensic-based investigation (FBI). The ITPs, including Gabor filter and discrete cosine transform were employed to implement texture computation for image data. These techniques are used to generate an initial set of extracted features describing rutting and non-rutting states. The extracted features were then refined by a wrapper-based feature selection (FS) method to determine set of highly relevant features. LSSVC models were used to learn the categorization of rutting and non-rutting based on the refined features and hyper-parameters optimized by the FBI metaheuristic. The final LSSVC prediction model with the most desired prediction accuracy can be obtained once the process of the FBI’s optimization terminates. A dataset of 2000 image samples has been collected during field trip of pavement survey in Da Nang city (Vietnam) to construct and evaluate the newly developed model. The statistical results obtained from a k-fold cross-validation have demonstrated that the hybrid FBI-LSSVC-FS model can achieve the most desired rutting recognition performance with accuracy rate, precision, recall, and F1 score of 98.9%, 0.994, 0.984 and 0.989, respectively. Therefore, this paper contributes to the body of knowledge by proposing a novel AI-based prediction model to assist transportation agencies in the task of periodic asphalt pavement survey.},
journal = {Soft Comput.},
month = oct,
pages = {12839–12855},
numpages = {17},
keywords = {Image processing, Feature selection, Forensic-based investigation, Least squares support vector machine, Rutting detection}
}

@inproceedings{10.1007/978-3-319-25945-1_9,
author = {Altinger, Harald and Herbold, Steffen and Grabowski, Jens and Wotawa, Franz},
title = {Novel Insights on Cross Project Fault Prediction Applied to Automotive Software},
year = {2015},
isbn = {9783319259444},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-25945-1_9},
doi = {10.1007/978-3-319-25945-1_9},
abstract = {Defect prediction is a powerful tool that greatly helps focusing quality assurance efforts during development. In the case of the availability of fault data from a particular context, there are different ways of using such fault predictions in practice. Companies like Google, Bell Labs and Cisco make use of fault prediction, whereas its use within automotive industry has not yet gained a lot of attraction, although, modern cars require a huge amount of software to operate. In this paper, we want to contribute the adoption of fault prediction techniques for automotive software projects. Hereby we rely on a publicly available data set comprising fault data from three automotive software projects. When learning a fault prediction model from the data of one particular project, we achieve a remarkably high and nearly perfect prediction performance for the same project. However, when applying a cross-project prediction we obtain rather poor results. These results are rather surprising, because of the fact that the underlying projects are as similar as two distinct projects can possibly be within a certain application context. Therefore we investigate the reasons behind this observation through correlation and factor analyses techniques. We further report the obtained findings and discuss the consequences for future applications of Cross-Project Fault Prediction CPFP in the domain of automotive software.},
booktitle = {Proceedings of the 27th IFIP WG 6.1 International Conference on Testing Software and Systems - Volume 9447},
pages = {141–157},
numpages = {17},
keywords = {Project fault prediction, Principal component analysis, Cross project fault prediction, Automotive},
location = {Sharjah and Dubai, United Arab Emirates},
series = {ICTSS 2015}
}

@article{10.1016/j.engappai.2017.09.008,
author = {Wang, Hong-Qiao and Cai, Yan-Ning and Fu, Guang-Yuan and Wu, Ming and Wei, Zhen-Hua},
title = {Data-driven fault prediction and anomaly measurement for complex systems using support vector probability density estimation},
year = {2018},
issue_date = {January 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {67},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2017.09.008},
doi = {10.1016/j.engappai.2017.09.008},
abstract = {To quantitatively monitor the state of complex system, a data-driven fault prediction and anomaly degree measurement method based on probability density estimation is studied in this paper. First, an anomaly index is introduced and defined to measure the anomaly degree of samples. Then By improving the form of constraint condition, a single slack factor multiple kernel support vector machine probability density estimation model is presented. As a result, the scale of object function and the solution number are all reduced, and the computational efficiency of the presented model is greatly enhanced. On the other hand, as the introduction of multiple kernel functions, a multiple kernel matrix with better data mapping performance is obtained, which can well solve the composite probability density estimation for uncoupled data. The simulation test shows that the presented model has higher estimation precision and speed. The experiments on complex system fault prediction also show that the systems anomaly degree can be quantitatively and accurately measured by the anomaly index gained from the prediction results, which can effectively improve the fault prediction precision and increase the prediction advances.},
journal = {Eng. Appl. Artif. Intell.},
month = jan,
pages = {1–13},
numpages = {13},
keywords = {Support vector machine, Probability density estimation, Fault prediction, Data-driven, Anomaly degree measurement}
}

@article{10.1007/s10462-019-09760-1,
author = {Hassanien, Aboul Ella and Darwish, Ashraf and Abdelghafar, Sara},
title = {Machine learning in telemetry data mining of space mission: basics, challenging and future directions},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {5},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-019-09760-1},
doi = {10.1007/s10462-019-09760-1},
abstract = {The development of an intelligent artificial satellite health monitoring system is a key issue in aerospace engineering that determines satellite health status and failure using telemetry data. The modern design of data mining and machine learning technologies allows the use of satellite telemetry data and the mining of integrated information to produce an advanced health monitoring system. This paper reviews the current status and presents a framework of necessary processes on data mining to solving various problems in telemetry data such as error detection, prediction, summarization, and visualization of large quantities, and help them understand the health status of the satellite and detect the symptoms of anomalies. Machine learning technologies that include neural networks, fuzzy sets, rough sets, support vector machines, Naive Bayesian, swarm optimization, and deep learning are also presented. Also, this paper reviews a wide range of existing satellite health monitoring solutions and discusses them in the framework of remote data mining techniques. In addition, we are discussing the analysis of space debris flow analysis and the prediction of low earth orbit collision based on our orbital Petri nets model. Challenges to be addressed and future directions of research are identified and an extensive bibliography is also included.},
journal = {Artif. Intell. Rev.},
month = jun,
pages = {3201–3230},
numpages = {30},
keywords = {Aerospace engineering, Debris, Deep learning, Machine learning, Satellite ground control operations, Satellite health monitoring, Satellite telemetry data mining}
}

@inproceedings{10.1007/978-3-030-68787-8_33,
author = {Kajatin, Roland and Nalpantidis, Lazaros},
title = {Image Segmentation of Bricks in Masonry Wall Using a Fusion of Machine Learning Algorithms},
year = {2021},
isbn = {978-3-030-68786-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68787-8_33},
doi = {10.1007/978-3-030-68787-8_33},
abstract = {Autonomous mortar raking requires a computer vision system which is able to provide accurate segmentation masks of close-range images of brick walls. The goal is to detect and ultimately remove the mortar, leaving the bricks intact, thus automating this construction-related task. This paper proposes such a vision system based on the combination of machine learning algorithms. The proposed system fuses the individual segmentation outputs of eight classifiers by means of a weighted voting scheme and then performing a threshold operation to generate the final binary segmentation. A novel feature of this approach is the fusion of several segmentations using a low-cost commercial off-the-shelf hardware setup. The close-range brick wall segmentation capabilities of the system are demonstrated on a total of about 9 million data points.},
booktitle = {Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10-15, 2021, Proceedings, Part VII},
pages = {446–461},
numpages = {16},
keywords = {Deep learning, Machine learning, Construction robotics, Image segmentation}
}

@inproceedings{10.1109/COASE.2017.8256161,
author = {Luan, Riwei and Wen, Guangrui and Zhang, Ruxin and Chen, Zheng and Zhang, Zhifen},
title = {Porosity defect detection based on FastICA-RBF during pulsed TIG welding process},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2017.8256161},
doi = {10.1109/COASE.2017.8256161},
abstract = {Porosity is a common defect of the aluminum alloy pulsed alternating current (AC) argon tungsten-arc welding (TIG) welding, which can cause huge damage to weld quality. The spectral information which is directly derived from the optical radiation of the arc is intrinsically related to the welding defects. Aiming at the redundancy of arc spectral, this paper proposed a method of porosity defect detection based on fast independent component analysis (fastICA) and radial basis function (RBF) network. The spectral data is collected by spectrometer, and continuous spectra are removed by calculating lower envelope twice. Then fastICA is applied to extract features from selected line spectra. Finally, the porosity defect is detected by RBF network according to the mean value in period of extracted features. Experimental results show that the proposed method can be used to detect the porosity defects during aluminum alloy pulsed TIG welding process.},
booktitle = {2017 13th IEEE Conference on Automation Science and Engineering (CASE)},
pages = {548–553},
numpages = {6},
location = {Xi'an, China}
}

@article{10.1016/j.infsof.2019.01.008,
author = {Meqdadi, Omar and Alhindawi, Nouh and Alsakran, Jamal and Saifan, Ahmad and Migdadi, Hatim},
title = {Mining software repositories for adaptive change commits using machine learning techniques},
year = {2019},
issue_date = {May 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {109},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.01.008},
doi = {10.1016/j.infsof.2019.01.008},
journal = {Inf. Softw. Technol.},
month = may,
pages = {80–91},
numpages = {12},
keywords = {Machine learning, Maintenance classification, Commit types, Adaptive maintenance, Code change metrics}
}

@inproceedings{10.1109/ASP-DAC47756.2020.9045391,
author = {Yang, Chaofei and Li, Hai and Chen, Yiran and Hu, Jiang},
title = {Enhancing Generalization of Wafer Defect Detection by Data Discrepancy-Aware Preprocessing and Contrast-Varied Augmentation},
year = {2020},
isbn = {9781728141237},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASP-DAC47756.2020.9045391},
doi = {10.1109/ASP-DAC47756.2020.9045391},
abstract = {Wafer inspection locates defects at early fabrication stages and traditionally focuses on pixel-level defects. However, there are very few solutions that can effectively detect large-scale defects. In this work, we leverage Convolutional Neural Networks (CNNs) to automate the wafer inspection process and propose several techniques to preprocess and augment wafer images for enhancing our model's generalization on unseen wafers (e.g., from other fabs). Cross-fab experimental results of both wafer-level and pixel-level detections show that the F1 score increases from 0.09 to 0.77 and the Precision-Recall area under curve (PR AUC) increases from 0.03 to 0.62 using our proposed method.},
booktitle = {Proceedings of the 25th Asia and South Pacific Design Automation Conference},
pages = {145–150},
numpages = {6},
location = {Beijing, China},
series = {ASPDAC '20}
}

@article{10.1504/IJDATS.2016.075971,
author = {Erturk, Ezgi and Sezer, Ebru Akcapinar},
title = {Software fault prediction using Mamdani type fuzzy inference system},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {8},
number = {1},
issn = {1755-8050},
url = {https://doi.org/10.1504/IJDATS.2016.075971},
doi = {10.1504/IJDATS.2016.075971},
abstract = {High quality software requires the occurrence of minimum number of failures while software runs. Software fault prediction is the determining whether software modules are prone to fault or not. Identification of the modules or code segments which need detailed testing, editing or, reorganising can be possible with the help of software fault prediction systems. In literature, many studies present models for software fault prediction using some soft computing methods which use training/testing phases. As a result, they require historical data to build models. In this study, to eliminate this drawback, Mamdani type fuzzy inference system FIS is applied for the software fault prediction problem. Several FIS models are produced and assessed with ROC-AUC as performance measure. The results achieved are ranging between 0.7138 and 0.7304; they are encouraging us to try FIS with the different software metrics and data to demonstrate general FIS performance on this problem.},
journal = {Int. J. Data Anal. Tech. Strateg.},
month = apr,
pages = {14–28},
numpages = {15}
}

@inproceedings{10.1109/COASE.2018.8560341,
author = {Jalalian, A. and Lu, W. F. and Wong, F. S. and Ahmed, S. M. and Chew, C.-M.},
title = {An Automatic Visual Inspection Method based on Statistical Approach for Defect Detection of Ship Hull Surfaces},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2018.8560341},
doi = {10.1109/COASE.2018.8560341},
abstract = {Robotized blasting of ship hull surfaces requires an accurate identification of defective regions of the hull to maximize the blasting efficiency. Accurate surface defect detection may not be achieved by current manual procedures, as its success is highly vulnerable to the human operators' experience and their subjective judgements. Therefore, there is a need for a more accurate and non-subjective method for defect detection. This paper proposes a computer vision based method for detection of ship hull defects. The method utilizes the histogram of hue and entropy data of the hue to identify the defects in two steps. Step 1 is an automatic circular thresholding based on the histogram of hue to distinguish the defects whose hue is different from the defect-free regions. A wrapped Gaussian mixture model is utilized to estimate the circular hue histograms, and maximum likelihood criterion is adopted to set the thresholds. Step 2 uses the probability distribution of the entropy for each segment identified in the first step to decide whether the segments are either defective, defect-free or a mixture of both. For the mixed regions, a Gaussian mixture model is fitted to the probability distribution of the entropy. The maximum likelihood criterion is utilized to segment these regions so as to discriminate their defective and defect-free parts. The high accuracy (F-measure=0.89) and short execution time (&lt;inf&gt;~&lt;/inf&gt;3.5 s) of the proposed method show that it is a good starting point for an automatic defect detection for a fully autonomous ship hull blasting.},
booktitle = {2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)},
pages = {445–450},
numpages = {6},
location = {Munich, Germany}
}

@article{10.1007/s10845-017-1315-5,
author = {Wu, Mingtao and Song, Zhengyi and Moon, Young B.},
title = {Detecting cyber-physical attacks in CyberManufacturing systems with machine learning methods},
year = {2019},
issue_date = {Mar 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-017-1315-5},
doi = {10.1007/s10845-017-1315-5},
abstract = {CyberManufacturing system (CMS) is a vision for future manufacturing systems. The concept delineates a vision of advanced manufacturing system integrated with technologies such as Internet of Things, Cloud Computing, Sensors Network and Machine Learning. As a result, cyber-attacks such as Stuxnet attack will increase along with growing simultaneous connectivity. Now, cyber-physical attacks are new and unique risks to CMSs and modern cyber security countermeasure is not enough. To learn this new vulnerability, the cyber-physical attacks is defined via a taxonomy under the vision of CMS. Machine learning on physical data is studied for detecting cyber-physical attacks. Two examples were developed with simulation and experiments: 3D printing malicious attack and CNC milling machine malicious attack. By implementing machine learning methods in physical data, the anomaly detection algorithm reached 96.1% accuracy in detecting cyber-physical attacks in 3D printing process; random forest algorithm reached on average 91.1% accuracy in detecting cyber-physical attacks in CNC milling process.},
journal = {J. Intell. Manuf.},
month = mar,
pages = {1111–1123},
numpages = {13},
keywords = {Security, Machine learning, CyberManufacturing systems, Additive manufacturing}
}

@article{10.1007/s00500-016-2284-x,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {An empirical study of some software fault prediction techniques for the number of faults prediction},
year = {2017},
issue_date = {December  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {24},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-016-2284-x},
doi = {10.1007/s00500-016-2284-x},
abstract = {During the software development process, prediction of the number of faults in software modules can be more helpful instead of predicting the modules being faulty or non-faulty. Such an approach may help in more focused software testing process and may enhance the reliability of the software system. Most of the earlier works on software fault prediction have used classification techniques for classifying software modules into faulty or non-faulty categories. The techniques such as Poisson regression, negative binomial regression, genetic programming, decision tree regression, and multilayer perceptron can be used for the prediction of the number of faults. In this paper, we present an experimental study to evaluate and compare the capability of six fault prediction techniques such as genetic programming, multilayer perceptron, linear regression, decision tree regression, zero-inflated Poisson regression, and negative binomial regression for the prediction of number of faults. The experimental investigation is carried out for eighteen software project datasets collected from the PROMISE data repository. The results of the investigation are evaluated using average absolute error, average relative error, measure of completeness, and prediction at level l measures. We also perform Kruskal---Wallis test and Dunn's multiple comparison test to compare the relative performance of the considered fault prediction techniques.},
journal = {Soft Comput.},
month = dec,
pages = {7417–7434},
numpages = {18},
keywords = {Zero-inflated Poisson regression, Software fault prediction, Multilayer perceptron, Kruskal---Wallis test, Genetic programming, Dunn's multiple comparison test}
}

@article{10.1016/j.cosrev.2021.100376,
author = {Amutha, J. and Sharma, Sandeep and Sharma, Sanjay Kumar},
title = {Strategies based on various aspects of clustering in wireless sensor networks using classical, optimization and machine learning techniques: Review, taxonomy, research findings, challenges and future directions},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2021.100376},
doi = {10.1016/j.cosrev.2021.100376},
journal = {Comput. Sci. Rev.},
month = may,
numpages = {43},
keywords = {Reliability, Security, Routing, Machine learning, Optimization, Wireless Sensor Networks}
}

@article{10.1007/s00138-014-0600-y,
author = {Schneider, Dorian and Holtermann, Timm and Merhof, Dorit},
title = {A traverse inspection system for high precision visual on-loom fabric defect detection},
year = {2014},
issue_date = {August    2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {6},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-014-0600-y},
doi = {10.1007/s00138-014-0600-y},
abstract = {A self-contained inspection system for vision-based on-loom fabric defect detection is presented in this paper. Design and loom integration of a traversing camera sled, a camera vibration damper and a complementary back-light illumination are presented and discussed. Image acquisition strategies and traverse control are described to complete the discussion on hardware and mechanics. The main part of the paper focuses on a novel algorithmic framework for woven fabric defect detection in highly resolved (1,000+ ppi) image data. Within this scope, single yarns are tracked and measured in terms of position, size, and appearance in real time. An inspection prototype has been mounted onto an industrial loom. Extensive on-line and off-line evaluations for various fabric materials gave precise and stable detection results with few false alarms. A brief cost analysis for the prototype system is provided and completes the presentation of the system.},
journal = {Mach. Vision Appl.},
month = aug,
pages = {1585–1599},
numpages = {15},
keywords = {Textile flaws, Real-time, On-loom, Fabric defect detection, Automated visual inspection}
}

@article{10.1145/3343440,
author = {Kaur, Harsurinder and Pannu, Husanbir Singh and Malhi, Avleen Kaur},
title = {A Systematic Review on Imbalanced Data Challenges in Machine Learning: Applications and Solutions},
year = {2019},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3343440},
doi = {10.1145/3343440},
abstract = {In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {79},
numpages = {36},
keywords = {sampling, machine learning, data analysis, Data imbalance}
}

@article{10.1155/2021/6612342,
author = {Li, Yao and Dourado, Ant\'{o}nio},
title = {A Fault Prediction and Cause Identification Approach in Complex Industrial Processes Based on Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/6612342},
doi = {10.1155/2021/6612342},
abstract = {Faults occurring in the production line can cause many losses. Predicting the fault events before they occur or identifying the causes can effectively reduce such losses. A modern production line can provide enough data to solve the problem. However, in the face of complex industrial processes, this problem will become very difficult depending on traditional methods. In this paper, we propose a new approach based on a deep learning (DL) algorithm to solve the problem. First, we regard these process data as a spatial sequence according to the production process, which is different from traditional time series data. Second, we improve the long short-term memory (LSTM) neural network in an encoder-decoder model to adapt to the branch structure, corresponding to the spatial sequence. Meanwhile, an attention mechanism (AM) algorithm is used in fault detection and cause identification. Third, instead of traditional biclassification, the output is defined as a sequence of fault types. The approach proposed in this article has two advantages. On the one hand, treating data as a spatial sequence rather than a time sequence can overcome multidimensional problems and improve prediction accuracy. On the other hand, in the trained neural network, the weight vectors generated by the AM algorithm can represent the correlation between faults and the input data. This correlation can help engineers identify the cause of faults. The proposed approach is compared with some well-developed fault diagnosing methods in the Tennessee Eastman process. Experimental results show that the approach has higher prediction accuracy, and the weight vector can accurately label the factors that cause faults.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {13}
}

@article{10.1109/TSE.2012.20,
author = {Dejaeger, Karel and Verbraken, Thomas and Baesens, Bart},
title = {Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers},
year = {2013},
issue_date = {February 2013},
publisher = {IEEE Press},
volume = {39},
number = {2},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2012.20},
doi = {10.1109/TSE.2012.20},
abstract = {Software testing is a crucial activity during software development and fault prediction models assist practitioners herein by providing an upfront identification of faulty software code by drawing upon the machine learning literature. While especially the Naive Bayes classifier is often applied in this regard, citing predictive performance and comprehensibility as its major strengths, a number of alternative Bayesian algorithms that boost the possibility of constructing simpler networks with fewer nodes and arcs remain unexplored. This study contributes to the literature by considering 15 different Bayesian Network (BN) classifiers and comparing them to other popular machine learning techniques. Furthermore, the applicability of the Markov blanket principle for feature selection, which is a natural extension to BN theory, is investigated. The results, both in terms of the AUC and the recently introduced H-measure, are rigorously tested using the statistical framework of Dem\v{s}ar. It is concluded that simple and comprehensible networks with less nodes can be constructed using BN classifiers other than the Naive Bayes classifier. Furthermore, it is found that the aspects of comprehensibility and predictive performance need to be balanced out, and also the development context is an item which should be taken into account during model selection.},
journal = {IEEE Trans. Softw. Eng.},
month = feb,
pages = {237–257},
numpages = {21},
keywords = {comprehensibility, classification, Software fault prediction, Software, Probability distribution, Predictive models, Measurement, Machine learning, Capability maturity model, Bayesian networks, Bayesian methods}
}

@article{10.1007/s11334-015-0258-2,
author = {Abdi, Yousef and Parsa, Saeed and Seyfari, Yousef},
title = {A hybrid one-class rule learning approach based on swarm intelligence for software fault prediction},
year = {2015},
issue_date = {December  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {11},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-015-0258-2},
doi = {10.1007/s11334-015-0258-2},
abstract = {Software testing is a fundamental activity in the software development process aimed to determine the quality of software. To reduce the effort and cost of this process, defect prediction methods can be used to determine fault-prone software modules through software metrics to focus testing activities on them. Because of model interpretation and easily used by programmers and testers some recent studies presented classification rules to make prediction models. This study presents a rule-based prediction approach based on kernel k-means clustering algorithm and Distance based Multi-objective Particle Swarm Optimization (DSMOPSO). Because of discrete search space, we modified this algorithm and named it DSMOPSO-D. We prevent best global rules to dominate local rules by dividing the search space with kernel k-means algorithm and by taking different approaches for imbalanced and balanced clusters, we solved imbalanced data set problem. The presented model performance was evaluated by four publicly available data sets from the PROMISE repository and compared with other machine learning and rule learning algorithms. The obtained results demonstrate that our model presents very good performance, especially in large data sets.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {289–301},
numpages = {13},
keywords = {Multi-objective particle swarm optimization, Kernel k-means, Imbalanced data sets, Fault prediction, DSMOPSO-D, Classification rules}
}

@article{10.1007/s11042-010-0472-8,
author = {Shi, Meihong and Fu, Rong and Guo, Yong and Bai, Shixian and Xu, Bugao},
title = {Fabric defect detection using local contrast deviations},
year = {2011},
issue_date = {March     2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {1},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-010-0472-8},
doi = {10.1007/s11042-010-0472-8},
abstract = {Defect inspection is a vital step for quality assurance in fabric production. The development of a fully automated fabric defect detection system requires robust and efficient fabric defect detection algorithms. The inspection of real fabric defects is particularly challenging due to delicate features of defects complicated by variations in weave textures and changes in environmental factors (e.g., illumination, noise, etc.). Based on characteristics of fabric structure, an approach of using  local contrast deviation  (LCD) is proposed for fabric defect detection in this paper. LCD is a parameter used to describe features of the contrast difference in four directions between the analyzed image and a defect-free image of the same fabric, and is used with a bilevel threshold function for defect segmentation. The validation tests on the developed algorithms were performed with fabric images from TILDA's Textile Texture Database and captured by a line-scan camera on an inspection machine. The experimental results show that the proposed method has robustness and simplicity as opposed to the approach of using modified local binary patterns (LBP).},
journal = {Multimedia Tools Appl.},
month = mar,
pages = {147–157},
numpages = {11},
keywords = {Local contrast deviation (LCD), Image segmentation, Fabric defect detection}
}

@article{10.1016/j.imavis.2009.03.007,
author = {Mak, K. L. and Peng, P. and Yiu, K. F. C.},
title = {Fabric defect detection using morphological filters},
year = {2009},
issue_date = {September, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {27},
number = {10},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2009.03.007},
doi = {10.1016/j.imavis.2009.03.007},
abstract = {In this paper, a novel defect detection scheme based on morphological filters is proposed to tackle the problem of automated defect detection for woven fabrics. In the proposed scheme, important texture features of the textile fabric are extracted using a pre-trained Gabor wavelet network. These texture features are then used to facilitate the construction of structuring elements in subsequent morphological processing to remove the fabric background and isolate the defects. Since the proposed defect detection scheme requires a few morphological filters only, the amount of computational load involved is not significant. The performance of the proposed scheme is evaluated by using a wide variety of homogeneous textile images with different types of common fabric defects. The test results obtained exhibit accurate defect detection with low false alarms, thus showing the effectiveness and robustness of the proposed detection scheme. In addition, the proposed detection scheme is further evaluated in real time by using a prototyped automated inspection system.},
journal = {Image Vision Comput.},
month = sep,
pages = {1585–1592},
numpages = {8},
keywords = {Textile fabrics, Quality control, Morphological filter, Gabor wavelet network, Defect detection}
}

@inproceedings{10.1007/978-3-030-30244-3_10,
author = {Khoza, Sibusiso C. and Grobler, Jacomine},
title = {Comparing Machine Learning and Statistical Process Control for Predicting Manufacturing Performance},
year = {2019},
isbn = {978-3-030-30243-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30244-3_10},
doi = {10.1007/978-3-030-30244-3_10},
abstract = {Quality has become one of the most important factors in the success of manufacturing companies. In this paper, the use of machine learning algorithms in quality control is compared to the use of statistical process monitoring, a classical quality management technique. The test dataset has a large number of features, which requires the use of principal component analysis and clustering to isolate the data into potential process groups. A Random Forest, Support Vector Machine and Naive Bayes algorithms were used to predict when the manufacturing process is out of control. The Random Forest algorithm performed significantly better than both the Naive Bayes and SVM algorithms in all 3 clusters of the dataset. The results were benchmarked against Hotelling’s  control charts which were trained using 80% of each cluster dataset and tested on the remaining 20%. In comparison with Hotelling’s  multivariate statistical process monitoring charts, the Random Forest algorithm still emerges as the better quality control method.},
booktitle = {Progress in Artificial Intelligence: 19th EPIA Conference on Artificial Intelligence, EPIA 2019, Vila Real, Portugal, September 3–6, 2019, Proceedings, Part II},
pages = {108–119},
numpages = {12},
location = {Vila Real, Portugal}
}

@article{10.5555/3292849.3292858,
title = {A hybrid approach to improve the quality of software fault prediction using Na\"{\i}ve Bayes and k-NN classification algorithm with ensemble method},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {17},
number = {4},
issn = {1740-8865},
abstract = {This paper considers an improvisation in software fault prediction research area using supervised classification algorithms and it mainly focuses to increase the performance of fault prediction. In this paper, we propose a hybrid prediction model using Na\"{\i}ve Bayes and k-nearest neighbour classification algorithm with vote ensemble method; in short it called as hNK. The goal of this model is to predict the best classification algorithm for software fault prediction based on the metrics and attributes of datasets. In the work, we have applied training sets and testing sets in hNK model with ensemble vote and we proposed the model to identify a suitable classification algorithm for fault prediction based on the accuracy and precision. We have achieved better results using hNK model for classifying supervised algorithms with different dataset.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {483–496},
numpages = {14}
}

@inproceedings{10.1109/COMPSAC.2014.66,
author = {Liu, Shulong and Chen, Xiang and Liu, Wangshu and Chen, Jiaqiang and Gu, Qing and Chen, Daoxu},
title = {FECAR: A Feature Selection Framework for Software Defect Prediction},
year = {2014},
isbn = {9781479935758},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2014.66},
doi = {10.1109/COMPSAC.2014.66},
abstract = {Software defect prediction can classify new software entities into either buggy or clean. However the effectiveness of existing methods is influenced by irrelevant and redundant features. In this paper, we propose a new feature selection framework FECAR using Feature Clustering And feature Ranking. This framework firstly partitions original features into k clusters based on FF-Correlation measure. Then it selects relevant features from each cluster based on FC-Relevance measure. In empirical study, we choose Symmetric Uncertainty as FF-Correlation measure, and choose Information Gain, Chi-Square, and Relief as three different FC-Relevance measures. Based on some real projects Eclipse and NASA, we implemented our framework and performed empirical studies to investigate the redundancy rate and the performance of the trained defect predictors. Final results verify the effectiveness of our proposed framework and further provide a guideline for achieving cost-effective feature selection when using our framework.},
booktitle = {Proceedings of the 2014 IEEE 38th Annual Computer Software and Applications Conference},
pages = {426–435},
numpages = {10},
keywords = {Software Defect Prediction, Feature Selection, Feature Clustering, Feature Ranking},
series = {COMPSAC '14}
}

@inproceedings{10.1145/2590748.2590755,
author = {Rathore, Santosh Singh and Gupta, Atul},
title = {A comparative study of feature-ranking and feature-subset selection techniques for improved fault prediction},
year = {2014},
isbn = {9781450327763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2590748.2590755},
doi = {10.1145/2590748.2590755},
abstract = {The quality of a fault prediction model depends on the software metrics that are used to build the prediction model. Feature selection represents a process of selecting a subset of relevant features that may lead to build improved prediction models. Feature selection techniques can be broadly categorized into two subcategories: feature-ranking and feature-subset selection. In this paper, we present a comparative investigation of seven feature-ranking techniques and eight feature-subset selection techniques for improved fault prediction. The performance of these feature selection techniques is evaluated using two popular machine-learning classifiers: Naive Bayes and Random Forest, over fourteen software project's fault-datasets obtained from the PROMISE data repository. The performances were measured using F-measure and AUC values. Our results demonstrated that feature-ranking techniques produced better results compared to feature-subset selection techniques. Among, the feature-ranking techniques used in the study, InfoGain and PCA techniques provided the best performance over all the datasets, while for feature-subset selection techniques ClassifierSubsetEval and Logistic Regression produced better results against their peers.},
booktitle = {Proceedings of the 7th India Software Engineering Conference},
articleno = {7},
numpages = {10},
keywords = {wrappers, software metrics, filters, feature-ranking, feature selection, fault prediction},
location = {Chennai, India},
series = {ISEC '14}
}

@article{10.1007/s40595-014-0028-3,
author = {Pham, Van Huy and Lee, Byung Ryong},
title = {An image segmentation approach for fruit defect detection using k-means clustering and graph-based algorithm},
year = {2015},
issue_date = {February  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {1},
issn = {2196-8888},
url = {https://doi.org/10.1007/s40595-014-0028-3},
doi = {10.1007/s40595-014-0028-3},
abstract = {Machine vision has been introduced in variety of industrial applications for fruit processing, allowing the automation of tasks performed so far by human operators. Such an important task is the detection of defects present on fruit peel which helps to grade or to classify fruit quality. Image segmentation is usually the first step in detecting flaws in fruits and its result mainly affects the accuracy of the system. A diversity of methods of automatic segmentation for fruit images has been developed. In this paper, a hybrid algorithm, which is based on split and merge approach, is proposed for an image segmentation that can be used in fruit defect detection. The algorithm firstly uses k-means algorithm to split the original image into regions based on Euclidean color distance in $$L^*a^*b^*$$ L a b space to produce an over-segmentation result. Then, based on a graph representation, a merge procedure using minimum spanning tree is then taken into account to iteratively merge similar regions into new homogenous ones. This combination is an efficient approach to employ the local and global characteristic of intensities in the image. The experiment showed good results in the terms of human observation and in processing time.},
journal = {Vietnam J. of Computer Science},
month = feb,
pages = {25–33},
numpages = {9},
keywords = {K-means and graph, Image segmentation, Defect detection}
}

@article{10.1016/j.aei.2017.09.007,
author = {Kamal, K. and Qayyum, R. and Mathavan, S. and Zafar, T.},
title = {Wood defects classification using laws texture energy measures and supervised learning approach},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {34},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2017.09.007},
doi = {10.1016/j.aei.2017.09.007},
abstract = {Machine vision based inspection systems are in great focus nowadays for quality control applications. The proposed work presents a novel approach for classification of wood knot defects for an automated inspection. The proposed technique utilizes gray level co-occurrence matrix and laws texture energy measures as texture feature extractors and feed-forward back-propagation neural network as classifier. The proposed work involves the comparison of gray level co-occurrence matrix based features with laws texture energy measures based features. Firstly it takes contrast, correlation, energy and homogeneity as input parameters to a feed-forward back propagation neural network to predict wood defects and then it take energy calculated from laws texture energy measures based energy maps as input feature to a feed-forward back propagation neural network. Mean Square Error (MSE) for training data is found to be 0.0718 and 90.5% overall average classification accuracy is achieved when laws texture energy measures based features are used as input to the neural network as compared to gray level co-occurrence matrix based input features where MSE for training data is found to be 0.10728 and 84.3% overall average classification accuracy is achieved. The proposed technique shows promising results to classify wood defects using a feed forward back-propagation neural network.},
journal = {Adv. Eng. Inform.},
month = oct,
pages = {125–135},
numpages = {11},
keywords = {Laws texture energy measures, Image processing, Gray level co-occurrence matrix, Back-propagation neural network}
}

@article{10.1016/j.infsof.2008.04.008,
author = {Chang, Ching-Pao and Chu, Chih-Ping and Yeh, Yu-Fang},
title = {Integrating in-process software defect prediction with association mining to discover defect pattern},
year = {2009},
issue_date = {February, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {51},
number = {2},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2008.04.008},
doi = {10.1016/j.infsof.2008.04.008},
abstract = {Rather than detecting defects at an early stage to reduce their impact, defect prevention means that defects are prevented from occurring in advance. Causal analysis is a common approach to discover the causes of defects and take corrective actions. However, selecting defects to analyze among large amounts of reported defects is time consuming, and requires significant effort. To address this problem, this study proposes a defect prediction approach where the reported defects and performed actions are utilized to discover the patterns of actions which are likely to cause defects. The approach proposed in this study is adapted from the Action-Based Defect Prediction (ABDP), an approach uses the classification with decision tree technique to build a prediction model, and performs association rule mining on the records of actions and defects. An action is defined as a basic operation used to perform a software project, while a defect is defined as software flaws and can arise at any stage of the software process. The association rule mining finds the maximum rule set with specific minimum support and confidence and thus the discovered knowledge can be utilized to interpret the prediction models and software process behaviors. The discovered patterns then can be applied to predict the defects generated by the subsequent actions and take necessary corrective actions to avoid defects. The proposed defect prediction approach applies association rule mining to discover defect patterns, and multi-interval discretization to handle the continuous attributes of actions. The proposed approach is applied to a business project, giving excellent prediction results and revealing the efficiency of the proposed approach. The main benefit of using this approach is that the discovered defect patterns can be used to evaluate subsequent actions for in-process projects, and reduce variance of the reported data resulting from different projects. Additionally, the discovered patterns can be used in causal analysis to identify the causes of defects for software process improvement.},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {375–384},
numpages = {10},
keywords = {Software defect prediction, Multi-interval discretization, Association rule}
}

@inproceedings{10.1109/BWCCA.2010.126,
author = {Chang, Chuan-Yu and Li, Shang-Cheng and Chung, Pau-Choo and Kuo, Jui-Yi and Tu, Yung-Chin},
title = {Automatic Facial Skin Defect Detection System},
year = {2010},
isbn = {9780769542362},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/BWCCA.2010.126},
doi = {10.1109/BWCCA.2010.126},
abstract = {Skin analysis is one of the most important procedures before medical cosmetology. Most conventional skin analysis systems are semi-automatic. They often require human intervention. In this study, an automatic facial skin defect detection approach is proposed. The system first detects human face in the facial image. Based on the detected face, facial features are extracted to locate regions of interest. Then, a pattern recognition approach is applied to detect facial skin defects, such as spots and wrinkles, in the regions of interest. For a specific kind of defect, a classifier is designed to provide higher performance for recognition. Using few features extracted from the region of interest, the proposed approach can successfully detect the skin defects. Experimental results demonstrate effectiveness of the proposed approach.},
booktitle = {Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications},
pages = {527–532},
numpages = {6},
keywords = {facial skin defect detection, wrinkle, spot},
series = {BWCCA '10}
}

@article{10.1007/s00521-016-2437-y,
author = {Chatterjee, S. and Nigam, S. and Roy, A.},
title = {Software fault prediction using neuro-fuzzy network and evolutionary learning approach},
year = {2017},
issue_date = {January   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {28},
number = {1},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-016-2437-y},
doi = {10.1007/s00521-016-2437-y},
abstract = {In the real world, a great deal of information is provided by human experts that normally do not conform to the rules of physics, but describe the complicated systems by a set of incomplete or vague statements. The need of conducting uncertainty analysis in software reliability for the large and complex system is demanding. For large complex systems made up of many components, the uncertainty of each individual parameter amplifies the uncertainty of the total system reliability. In this paper, to overcome with the problem of uncertainty in software development process and environment, a neuro-fuzzy modeling has been proposed for software fault prediction. The training of the proposed neuro-fuzzy model has been done with genetic algorithm and back-propagation learning algorithm. The proposed model has been validated using some real software failure data. The efficiency of the two learning algorithms has been compared with various fuzzy and statistical time series-based forecasting algorithms on the basis of their prediction ability.},
journal = {Neural Comput. Appl.},
month = jan,
pages = {1221–1231},
numpages = {11},
keywords = {Software reliability, Genetic algorithm, Fuzzy neural network, Faults}
}

@inproceedings{10.1109/ICMLA.2010.27,
author = {Wang, Huanjing and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {A Comparative Study of Ensemble Feature Selection Techniques for Software Defect Prediction},
year = {2010},
isbn = {9780769543000},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2010.27},
doi = {10.1109/ICMLA.2010.27},
abstract = {Feature selection has become the essential step in many data mining applications. Using a single feature subset selection method may generate local optima. Ensembles of feature selection methods attempt to combine multiple feature selection methods instead of using a single one. We present a comprehensive empirical study examining 17 different ensembles of feature ranking techniques (rankers) including six commonly-used feature ranking techniques, the signal-to-noise filter technique, and 11 threshold-based feature ranking techniques. This study utilized 16 real-world software measurement data sets of different sizes and built 13,600 classification models. Experimental results indicate that ensembles of very few rankers are very effective and even better than ensembles of many or all rankers.},
booktitle = {Proceedings of the 2010 Ninth International Conference on Machine Learning and Applications},
pages = {135–140},
numpages = {6},
keywords = {feature ranking, ensembles, defect prediction},
series = {ICMLA '10}
}

@article{10.1007/s10664-019-09769-8,
author = {Ochodek, Miroslaw and Hebig, Regina and Meding, Wilhelm and Frost, Gert and Staron, Miroslaw},
title = {Recognizing lines of code violating company-specific coding guidelines using machine learning: A Method and Its Evaluation},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09769-8},
doi = {10.1007/s10664-019-09769-8},
abstract = {Software developers in big and medium-size companies are working with millions of lines of code in their codebases. Assuring the quality of this code has shifted from simple defect management to proactive assurance of internal code quality. Although static code analysis and code reviews have been at the forefront of research and practice in this area, code reviews are still an effort-intensive and interpretation-prone activity. The aim of this research is to support code reviews by automatically recognizing company-specific code guidelines violations in large-scale, industrial source code. In our action research project, we constructed a machine-learning-based tool for code analysis where software developers and architects in big and medium-sized companies can use a few examples of source code lines violating code/design guidelines (up to 700 lines of code) to train decision-tree classifiers to find similar violations in their codebases (up to 3 million lines of code). Our action research project consisted of (i) understanding the challenges of two large software development companies, (ii) applying the machine-learning-based tool to detect violations of Sun’s and Google’s coding conventions in the code of three large open source projects implemented in Java, (iii) evaluating the tool on evolving industrial codebase, and (iv) finding the best learning strategies to reduce the cost of training the classifiers. We were able to achieve the average accuracy of over 99% and the average F-score of 0.80 for open source projects when using ca. 40K lines for training the tool. We obtained a similar average F-score of 0.78 for the industrial code but this time using only up to 700 lines of code as a training dataset. Finally, we observed the tool performed visibly better for the rules requiring to understand a single line of code or the context of a few lines (often allowing to reach the F-score of 0.90 or higher). Based on these results, we could observe that this approach can provide modern software development companies with the ability to use examples to teach an algorithm to recognize violations of code/design guidelines and thus increase the number of reviews conducted before the product release. This, in turn, leads to the increased quality of the final software.},
journal = {Empirical Softw. Engg.},
month = jan,
pages = {220–265},
numpages = {46},
keywords = {Code reviews, Action research, Machine learning, Measurement}
}

@inproceedings{10.5555/2404411.2404426,
author = {Gao, Jian and Wang, Zhiliang and Liu, Yanyun and Jian, Chuanxia and Chen, Xin},
title = {Development of OLED panel defect detection system through improved otsu algorithm},
year = {2012},
isbn = {9783642335143},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {OLED (Organic light-emitting) displays have been called the next generation of display devices for their unique properties: colorful images, large viewing angle, light weight and power efficiency. Complex manufacture processing makes the screen have some defects. Detecting the defects will help to improve the quality. In this paper we concentrate on detecting these defects and proposed a corner-points based method, where the corner-points are extracted from the skeleton image and used as the control points for the subtract operation. We proposed an improved Otsu method to determine the image segmentation threshold by recursive process. Based on the algorithm proposed, a system for OLED screen defect detection was developed. The test result shows that the developed system can detect most of the defects on the panel.},
booktitle = {Proceedings of the 5th International Conference on Intelligent Robotics and Applications - Volume Part II},
pages = {127–134},
numpages = {8},
keywords = {subtraction operation, image segmentation, defect detection, Otsu method, OLED panel},
location = {Montreal, QC, Canada},
series = {ICIRA'12}
}

@article{10.1145/3212695,
author = {Allamanis, Miltiadis and Barr, Earl T. and Devanbu, Premkumar and Sutton, Charles},
title = {A Survey of Machine Learning for Big Code and Naturalness},
year = {2018},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3212695},
doi = {10.1145/3212695},
abstract = {Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {81},
numpages = {37},
keywords = {software engineering tools, machine learning, code naturalness, Big code}
}

@article{10.1016/j.ins.2019.03.045,
author = {Li, Jin and Palmieri, Francesco and Xiang, Yang},
title = {Special Issue on Security and Privacy in Machine Learning},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {487},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.03.045},
doi = {10.1016/j.ins.2019.03.045},
journal = {Inf. Sci.},
month = jun,
pages = {208–209},
numpages = {2}
}

@inproceedings{10.1145/3036290.3036323,
author = {Badri, Mourad and Badri, Linda and Flageol, William and Toure, Fadel},
title = {Investigating the Accuracy of Test Code Size Prediction using Use Case Metrics and Machine Learning Algorithms: An Empirical Study},
year = {2017},
isbn = {9781450348287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3036290.3036323},
doi = {10.1145/3036290.3036323},
abstract = {Software testing plays a crucial role in software quality assurance. It is, however, a time and resource consuming process. It is, therefore, important to predict as soon as possible the effort required to test software, so that activities can be planned and resources can be optimally allocated. Test code size, in terms of Test Lines Of Code (TLOC), is an important testing effort indicator used in many empirical studies. In this paper, we investigate empirically the early prediction of TLOC for object-oriented software using use case metrics. We used different machine learning algorithms (linear regression, k-NN, Na\"{\i}ve Bayes, C4.5, Random Forest, and Multilayer Perceptron) to build the prediction models. We performed an empirical study using data collected from five Java projects. The use case metrics have been compared to the well-known Use Case Points (UCP) method. Results show that the use case metrics-based approach gives a more accurate prediction of TLOC than the UCP method.},
booktitle = {Proceedings of the 2017 International Conference on Machine Learning and Soft Computing},
pages = {25–33},
numpages = {9},
keywords = {Use Cases, Use Case Points, Testing Effort, Test Code Size, Software Testing, Prediction, Metrics, Machine Learning Algorithms, Cross Validation},
location = {Ho Chi Minh City, Vietnam},
series = {ICMLSC '17}
}

@inproceedings{10.1145/2811681.2811699,
author = {Hussain, Shahid and Keung, Jacky and Khan, Arif Ali and Bennin, Kwabena Ebo},
title = {Performance Evaluation of Ensemble Methods For Software Fault Prediction: An Experiment},
year = {2015},
isbn = {9781450337960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811681.2811699},
doi = {10.1145/2811681.2811699},
abstract = {In object-oriented software development, a plethora of studies have been carried out to present the application of machine learning algorithms for fault prediction. Furthermore, it has been empirically validated that an ensemble method can improve classification performance as compared to a single classifier. But, due to the inherent differences among machine learning and data mining approaches, the classification performance of ensemble methods will be varied. In this study, we investigated and evaluated the performance of different ensemble methods with itself and base-level classifiers, in predicting the faults proneness classes. Subsequently, we used three ensemble methods AdaboostM1, Vote and StackingC with five base-level classifiers namely Naivebayes, Logistic, J48, VotedPerceptron and SMO in Weka tool. In order to evaluate the performance of ensemble methods, we retrieved twelve datasets of open source projects from PROMISE repository. In this experiment, we used k-fold (k=10) cross-validation and ROC analysis for validation. Besides, we used recall, precision, accuracy, F-value measures to evaluate the performance of ensemble methods and base-level Classifiers. Finally, we observed significant performance improvement of applying ensemble methods as compared to its base-level classifier, and among ensemble methods we observed StackingC outperformed other selected ensemble methods for software fault prediction.},
booktitle = {Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference},
pages = {91–95},
numpages = {5},
keywords = {Weka, Performance, Measures, Ensemble Methods, Classifiers, Chidamber and Kemerer (CK) Metrics},
location = {Adelaide, SA, Australia},
series = {ASWEC ' 15 Vol. II}
}

@article{10.1504/IJIIDS.2015.070825,
author = {Abaei, Golnoush and Mashinchi, M. Reza and Selamat, Ali},
title = {Software fault prediction using BP-based crisp artificial neural networks},
year = {2015},
issue_date = {July 2015},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {1},
issn = {1751-5858},
url = {https://doi.org/10.1504/IJIIDS.2015.070825},
doi = {10.1504/IJIIDS.2015.070825},
abstract = {Early fault detection for software reduces the cost of developments. Fault level can be predicted through learning mechanisms. Conventionally, precise metrics measure the fault level and crisp artificial neural networks CANNs perform the learning. However, the performance of CANNs depends on complexities of data and learning algorithm. This paper considers these two complexities to predict the fault level of software. We apply the principle component analysis PCA to reduce the dimensionality of data, and employ the correlation-based feature selection CFS to select the best features. CANNs, then, predict the fault level of software using back propagation BP algorithm as a learning mechanism. To investigate the performance of BP-based CANNs, we analyse varieties of dimensionality reduction. The results reveal the superiority of PCA to CFS in terms of accuracy.},
journal = {Int. J. Intell. Inf. Database Syst.},
month = jul,
pages = {15–31},
numpages = {17}
}

@inproceedings{10.1109/GCIS.2013.36,
author = {Li, Min and Deng, Zhong-Min and Wang, Lijing},
title = {Defect Detection of Patterned Fabric by Spectral Estimation Technique and Rough Set Classifier},
year = {2013},
isbn = {9781479928866},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/GCIS.2013.36},
doi = {10.1109/GCIS.2013.36},
abstract = {A novel method for patterned fabric defect detection and classification using spectral estimation technique and rough set theory is presented in this paper. Estimating Signal Parameter via Rotational Invariance Technique (ESPRIT) is firstly used to extract the pattern from the image of the patterned fabric. Then, the shape and location of the flawed areas are detected by comparing the pattern image and the source image. A rough set classifier is trained and tested to detect the types of defects in the patterned fabric image. Experimental results show that this method can successfully analyze and recognize oil warp and weft defects in patterned fabrics with nearly 96% success rate.},
booktitle = {Proceedings of the 2013 Fourth Global Congress on Intelligent Systems},
pages = {190–194},
numpages = {5},
keywords = {spectral estimation, rough set theory, patterned fabric, defect detection, Rotational Invariance Technique},
series = {GCIS '13}
}

@inproceedings{10.1109/DCABES.2011.42,
author = {Zhang, Xingye and Xu, Wenbo and Pan, Ruru and Liu, Jihong and Gao, Weidong},
title = {Fabric Defect Detection Based on Projected Transform for Feature Extraction},
year = {2011},
isbn = {9780769544151},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/DCABES.2011.42},
doi = {10.1109/DCABES.2011.42},
abstract = {In order to resolve the key technology problem of automated fabric defect detection, projected transform is proposed to extract features of the fabric image making use of fabric characteristic in this paper. Automated fabric defect detection scheme is divided into two phases, which are the study phase and the detection phase. During the study phase, features of normal fabric image are extracted to get the feature data set of normal fabric. During the detection phase, the method of anomaly detection is developed using features of fabric image to detect defect. Testing on general fabric by this method, experimental results demonstrate that each of feature values is in the normal range for normal fabric image, and one feature value at least is abnormal for defective fabric image. Defects can be located according to the location of abnormal value.},
booktitle = {Proceedings of the 2011 10th International Symposium on Distributed Computing and Applications to Business, Engineering and Science},
pages = {192–196},
numpages = {5},
keywords = {projected transform, feature extraction, fabric, defect detection, anomaly detection},
series = {DCABES '11}
}

@article{10.1016/j.aei.2015.01.008,
author = {Koch, Christian and Georgieva, Kristina and Kasireddy, Varun and Akinci, Burcu and Fieguth, Paul},
title = {A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure},
year = {2015},
issue_date = {April 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {29},
number = {2},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2015.01.008},
doi = {10.1016/j.aei.2015.01.008},
abstract = {Visual inspection of civil infrastructure is essential for condition assessment.We focus on concrete bridges, tunnels, underground pipes, and asphalt pavements.Accordingly, we review the latest computer vision based defect detection methods.Using computer vision most relevant types of defects can be automatically detected.Automatic defect properties retrieval and assessment has not been achieved yet. To ensure the safety and the serviceability of civil infrastructure it is essential to visually inspect and assess its physical and functional condition. This review paper presents the current state of practice of assessing the visual condition of vertical and horizontal civil infrastructure; in particular of reinforced concrete bridges, precast concrete tunnels, underground concrete pipes, and asphalt pavements. Since the rate of creation and deployment of computer vision methods for civil engineering applications has been exponentially increasing, the main part of the paper presents a comprehensive synthesis of the state of the art in computer vision based defect detection and condition assessment related to concrete and asphalt civil infrastructure. Finally, the current achievements and limitations of existing methods as well as open research challenges are outlined to assist both the civil engineering and the computer science research community in setting an agenda for future research.},
journal = {Adv. Eng. Inform.},
month = apr,
pages = {196–210},
numpages = {15},
keywords = {Infrastructure monitoring, Infrastructure, Defect detection, Condition assessment, Computer vision}
}

@inproceedings{10.1109/ARSO.2016.7736285,
author = {Tao, Yong and Zheng, Jiaqi and Wang, Tianmiao and Hu, Yaoguang},
title = {A state and fault prediction method based on RBF neural networks},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ARSO.2016.7736285},
doi = {10.1109/ARSO.2016.7736285},
abstract = {A state and fault prediction method based on RBF neural networks is proposed. The agricultural machinery is chosen as the experimental object of the method. There are 4 health level, such as failure, hazardous, sub-healthy and healthy. Some data of different provinces have been obtained, the health level can be acquired by RBF neural networks. The mathematical model of agricultural machinery is difficult to be proposed in this paper, so the traditional control algorithm can't be used in agricultural machinery. However, the RBF neural networks can solve this problem. At the same time, some vital factors should be considered, such as mileages, rotational speed, stubble height, water temperature, oil pressure of agricultural machinery. The rotational speed and stubble height have a big effect on fault prediction of agriculture. The experimental results verify the effectiveness of the proposed method.},
booktitle = {2016 IEEE Workshop on Advanced Robotics and Its Social Impacts (ARSO)},
pages = {221–225},
numpages = {5},
location = {Shanghai, China}
}

@article{10.1016/j.procs.2015.02.154,
author = {Mahajan, Rohit and Gupta, Sunil Kumar and Bedi, Rajeev Kumar},
title = {Design of Software Fault Prediction Model Using BR Technique},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.154},
doi = {10.1016/j.procs.2015.02.154},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {849–858},
numpages = {10},
keywords = {public dataset ;, Neural network, Levenberg-Marquardt (LM)algorithm, Back Propagation (BPA) algorithm ;Bayesian Regularization(BR)algorithml}
}

@article{10.1145/3464959,
author = {Botero, Ulbert J. and Wilson, Ronald and Lu, Hangwei and Rahman, Mir Tanjidur and Mallaiyan, Mukhil A. and Ganji, Fatemeh and Asadizanjani, Navid and Tehranipoor, Mark M. and Woodard, Damon L. and Forte, Domenic},
title = {Hardware Trust and Assurance through Reverse Engineering: A Tutorial and Outlook from Image Analysis and Machine Learning Perspectives},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/3464959},
doi = {10.1145/3464959},
abstract = {In the context of hardware trust and assurance, reverse engineering has been often considered as an illegal action. Generally speaking, reverse engineering aims to retrieve information from a product, i.e., integrated circuits (ICs) and printed circuit boards (PCBs) in hardware security-related scenarios, in the hope of understanding the functionality of the device and determining its constituent components. Hence, it can raise serious issues concerning Intellectual Property (IP) infringement, the (in)effectiveness of security-related measures, and even new opportunities for injecting hardware Trojans. Ironically, reverse engineering can enable IP owners to verify and validate the design. Nevertheless, this cannot be achieved without overcoming numerous obstacles that limit successful outcomes of the reverse engineering process. This article surveys these challenges from two complementary perspectives: image processing and machine learning. These two fields of study form a firm basis for the enhancement of efficiency and accuracy of reverse engineering processes for both PCBs and ICs. In summary, therefore, this article presents a roadmap indicating clearly the actions to be taken to fulfill hardware trust and assurance objectives.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jun,
articleno = {62},
numpages = {53},
keywords = {trust and assurances, reverse engineering, printed circuit boards, machine learning, integrated circuits, image processing, imaging, hardware trojan, Hardware counterfeiting}
}

@article{10.1016/j.patrec.2006.03.009,
author = {Ng, Hui-Fuang},
title = {Automatic thresholding for defect detection},
year = {2006},
issue_date = {15 October 2006},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {27},
number = {14},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2006.03.009},
doi = {10.1016/j.patrec.2006.03.009},
abstract = {Automatic thresholding has been widely used in the machine vision industry for automated visual inspection of defects. A commonly used thresholding technique, the Otsu method, provides satisfactory results for thresholding an image with a histogram of bimodal distribution. This method, however, fails if the histogram is unimodal or close to unimodal. For defect detection applications, defects can range from no defect to small or large defects, which means that the gray-level distributions range from unimodal to bimodal. For this paper, we revised the Otsu method for selecting optimal threshold values for both unimodal and bimodal distributions, and tested the performance of the revised method, the valley-emphasis method, on common defect detection applications.},
journal = {Pattern Recogn. Lett.},
month = oct,
pages = {1644–1649},
numpages = {6},
keywords = {Defect detection, Automatic thresholding}
}

@article{10.1109/TIP.2012.2194505,
author = {Wang, Xiaosong and Mirmehdi, Majid},
title = {Archive Film Defect Detection and Removal: An Automatic Restoration Framework},
year = {2012},
issue_date = {August 2012},
publisher = {IEEE Press},
volume = {21},
number = {8},
issn = {1057-7149},
url = {https://doi.org/10.1109/TIP.2012.2194505},
doi = {10.1109/TIP.2012.2194505},
abstract = {In this paper, we present an automatic restoration system targeting on dirt and blotches in digitized archive films. The system is composed of mainly two modules: defect detection and defect removal. In defect detection, we locate the defects by combining temporal and spatial information across a number of frames. A hidden Markov model is trained for normal observation sequences and then applied within a framework to detect defective pixels. The resulting defect maps are refined in a two-stage false alarm elimination process and then passed over to the defect removal procedure. A labeled (degraded) pixel is restored in a multiscale framework by first searching the optimal replacement in its dynamically generated random-walk-based region of candidate pixel-exemplars and then updating all its features (intensity, motion, and texture). Finally, the proposed system is compared against the state-of-the-art methods to demonstrate improved accuracy in both detection and restoration using synthetic and real degraded image sequences.},
journal = {Trans. Img. Proc.},
month = aug,
pages = {3757–3769},
numpages = {13}
}

@article{10.4018/ijsi.2014100105,
author = {Abaei, Golnoush and Selamat, Ali},
title = {Increasing the Accuracy of Software Fault Prediction using Majority Ranking Fuzzy Clustering},
year = {2014},
issue_date = {October 2014},
publisher = {IGI Global},
address = {USA},
volume = {2},
number = {4},
issn = {2166-7160},
url = {https://doi.org/10.4018/ijsi.2014100105},
doi = {10.4018/ijsi.2014100105},
abstract = {Despite proposing many software fault prediction models, this area has yet to be explored as still there is a room for stable and consistent model with better performance. In this paper, a new method is proposed to increase the accuracy of fault prediction based on the notion of fuzzy clustering and majority ranking. The authors investigated the effect of irrelevant and inconsistent modules on software fault prediction and tried to decrease it by designing a new framework, in which the entire project modules are clustered. The obtained results showed that fuzzy clustering could decrease the negative effect of irrelevant modules on prediction performance. Eight data sets from NASA and Turkish white-goods software is employed to evaluate our model. Performance evaluation in terms of false positive rate, false negative rate, and overall error showed the superiority of our model compared to other predicting models. The authors proposed majority ranking fuzzy clustering approach showed between 3% to 18% and 1% to 4% improvement in false negative rate and overall error, respectively, compared with other available proposed models (ACF and ACN) in more than half of the testing cases. According to the results, our systems can be used to guide testing effort by identifying fault prone modules to improve the quality of software development and software testing in a limited time and budget.},
journal = {Int. J. Softw. Innov.},
month = oct,
pages = {60–71},
numpages = {12},
keywords = {Software Fault Prediction, NASA, Majority Ranking, Fuzzy Clustering, Available Proposed Models}
}

@inproceedings{10.5555/2045921.2045933,
author = {Sun, Jing and Zhou, Zhiyu},
title = {Fabric defect detection based on computer vision},
year = {2011},
isbn = {9783642238956},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Broken ends, missing picks, oil stain and holes are the most common fabric defects. To deal with the situation that manual fabric detection will affected by the subjective factors of inspectors, an automatic computer vision based fabric defect detection method is introduced in this paper. The system uses threshold segmentation method to identify if there are any defects existed in the fabric, adopts image feature based approach to recognize oil stain and holes, and uses training based technique to detect broken ends and missing picks. Experimental results show that the proposed approach has the advantage of easy implementation, high inspection speed, good noise immunity, greatly meeting the needs for automatic fabric defect inspection.},
booktitle = {Proceedings of the Third International Conference on Artificial Intelligence and Computational Intelligence - Volume Part III},
pages = {86–91},
numpages = {6},
keywords = {fabric detect, computer vision, automatic detection},
location = {Taiyuan, China},
series = {AICI'11}
}

@article{10.1016/j.patcog.2011.07.025,
author = {Li, Wei-Chen and Tsai, Du-Ming},
title = {Wavelet-based defect detection in solar wafer images with inhomogeneous texture},
year = {2012},
issue_date = {February, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {45},
number = {2},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2011.07.025},
doi = {10.1016/j.patcog.2011.07.025},
abstract = {Solar power is an attractive alternative source of electricity. Multicrystalline solar cells dominate the market share owing to their lower manufacturing costs. The surface quality of a solar wafer determines the conversion efficiency of the solar cell. A multicrystalline solar wafer surface contains numerous crystal grains of random shapes and sizes in random positions and directions with different illumination reflections, therefore resulting in an inhomogeneous texture in the sensed image. This texture makes the defect detection task extremely difficult. This paper proposes a wavelet-based discriminant measure for defect inspection in multicrystalline solar wafer images. The traditional wavelet transform techniques for texture analysis and surface inspection rely mainly on the discriminant features extracted in individual decomposition levels. However, these techniques cannot be directly applied to solar wafers with inhomogeneous grain patterns. The defects found in a solar wafer surface generally involve scattering and blurred edges with respect to clear and sharp edges of crystal grains in the background. The proposed method uses the wavelet coefficients in individual decomposition levels as features and the difference of the coefficient values between two consecutive resolution levels as the weights to distinguish local defects from the crystal grain background, and generates a better discriminant measure for identifying various defects in the multicrystalline solar wafers. Experimental results have shown the proposed method performs effectively for detecting fingerprint, contaminant, and saw-mark defects in solar wafer surfaces.},
journal = {Pattern Recogn.},
month = feb,
pages = {742–756},
numpages = {15},
keywords = {inhomogeneous texture, Wavelet transform, Surface inspection, Solar wafer, Defect detection}
}

@inproceedings{10.1145/2245276.2231975,
author = {Banthia, Deepak and Gupta, Atul},
title = {Investigating fault prediction capabilities of five prediction models for software quality},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2231975},
doi = {10.1145/2245276.2231975},
abstract = {Predicting faults in software modules can lead to a high quality and more effective software development process to follow. However, the results of a fault prediction model have to be properly interpreted before incorporating them into any decision making. Most of the earlier studies have used the prediction accuracy as the main criteria to compare amongst competing fault prediction models. However, we show that besides accuracy, other criteria like number of false positives and false negatives can equally be important to choose a candidate model for fault prediction. We have used five NASA software data sets in our experiment. Our results suggest that the performance of Simple Logistic is better than the others on raw data sets whereas the performance of Neural Network was found to be better when we applied dimensionality reduction method on raw data sets. When we used data pre-processing techniques, the prediction accuracy of Random Forest was found to be better in both cases i.e. with and without dimensionality reduction but reliability of Simple Logistic was better than Random Forest because it had less number of fault negatives.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {1259–1261},
numpages = {3},
keywords = {quality assurance, fault prediction models, fault prediction, effort estimation, attribute selection},
location = {Trento, Italy},
series = {SAC '12}
}

@article{10.1007/s00500-016-2316-6,
author = {Chinna Gounder Dhanajayan, Rajaganapathy and Appavu Pillai, Subramani},
title = {SLMBC: spiral life cycle model-based Bayesian classification technique for efficient software fault prediction and classification},
year = {2017},
issue_date = {January   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {2},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-016-2316-6},
doi = {10.1007/s00500-016-2316-6},
abstract = {Software fault prediction and classification plays a vital role in the software development process for assuring high quality and reliability of the software product. Earlier prediction of the fault-prone software modules enables timely correction of the faults and delivery of reliable product. Generally, the fuzzy logic, decision tree and neural networks are deployed for fault prediction. But these techniques suffer due to low accuracy and inconsistency. To overcome these issues, this paper proposes a spiral life cycle model-based Bayesian classification technique for efficient software fault prediction and classification. In this process, initially the dependent and independent software modules are identified. The spiral life cycle model is used for testing the software modules in each life cycle of the software development process. Bayesian classification is applied to classify the software modules as faulty module and non-faulty module, by using the probability distribution models. Robust similarity-aware clustering algorithm performs clustering of the faulty and non-faulty software modules based on the similarity measure of the features in the dataset. From the experimental results, it is observed that the proposed method enables accurate prediction and classification of the faulty modules. The proposed technique achieves higher accuracy, precision, recall, probability of detection, F-measure and lower error rate than the existing techniques. The misclassification rate of the proposed technique is found to be lower than the existing techniques. Hence, the reliability of the software development process can be improved.},
journal = {Soft Comput.},
month = jan,
pages = {403–415},
numpages = {13},
keywords = {Spiral life cycle model-based Bayesian classification technique (SLMBC), Spiral life cycle model, Software development, Segregate fault prediction algorithm, Robust similarity-aware clustering (RSC) algorithm, Bayesian classification}
}

@inproceedings{10.1145/2365324.2365335,
author = {Lu, Huihua and Cukic, Bojan},
title = {An adaptive approach with active learning in software fault prediction},
year = {2012},
isbn = {9781450312417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2365324.2365335},
doi = {10.1145/2365324.2365335},
abstract = {Background: Software quality prediction plays an important role in improving the quality of software systems. By mining software metrics, predictive models can be induced that provide software managers with insights into quality problems they need to tackle as effectively as possible.Objective: Traditional, supervised learning approaches dominate software quality prediction. Resulting models tend to be project specific. On the other hand, in situations where there are no previous releases, supervised learning approaches are not very useful because large training data sets are needed to develop accurate predictive models.Method: This paper eases the limitations of supervised learning approaches and offers good prediction performance. We propose an adaptive approach in which supervised learning and active learning are coupled together. NaiveBayes classifier is used as the base learner.Results: We track the performance at each iteration of the adaptive learning algorithm and compare it with the performance of supervised learning. Our results show that proposed scheme provides good fault prediction performance over time, i.e., it eventually outperforms the corresponding supervised learning approach. On the other hand, adaptive learning classification approach reduces the variance in prediction performance in comparison with the corresponding supervised learning algorithm.Conclusion: The adaptive approach outperforms the corresponding supervised learning approach when both use Naive-Bayes as base learner. Additional research is needed to investigate whether this observation remains valid with other base classifiers.},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering},
pages = {79–88},
numpages = {10},
keywords = {active learning, adaptive learning, software fault prediction},
location = {Lund, Sweden},
series = {PROMISE '12}
}

@inproceedings{10.1145/1540438.1540466,
author = {Jiang, Yue and Cukic, Bojan},
title = {Misclassification cost-sensitive fault prediction models},
year = {2009},
isbn = {9781605586342},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1540438.1540466},
doi = {10.1145/1540438.1540466},
abstract = {Traditionally, software fault prediction models are built by assuming a uniform misclassification cost. In other words, cost implications of misclassifying a faulty module as fault free are assumed to be the same as the cost implications of misclassifying a fault free module as faulty. In reality, these two types of misclassification costs are rarely equal. They are project-specific, reflecting the characteristics of the domain in which the program operates. In this paper, using project information from a public repository, we analyze the benefits of techniques which incorporate misclassification costs in the development of software fault prediction models. We find that cost-sensitive learning does not provide operational points which outperform cost-insensitive classifiers. However, an advantage of cost-sensitive modeling is the explicit choice of the operational threshold appropriate for the cost differential.},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
articleno = {20},
numpages = {10},
keywords = {cost-sensitive, fault prediction, machine learning, misclassification cost},
location = {Vancouver, British Columbia, Canada},
series = {PROMISE '09}
}

@inproceedings{10.1145/3371158.3371233,
author = {Mannarswamy, Sandya and Roy, Shourya and Chidambaram, Saravanan},
title = {Tutorial on Software Testing &amp; Quality Assurance for Machine Learning Applications from research bench to real world},
year = {2020},
isbn = {9781450377386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3371158.3371233},
doi = {10.1145/3371158.3371233},
abstract = {Rapid progress in Machine Learning (ML) has seen a swift translation to real world commercial deployment. While research and development of ML applications have progressed at an exponential pace, the required software engineering process for ML applications and the corresponding eco-system of testing and quality assurance tools which enable software reliable, trustworthy and safe and easy to deploy, have sadly lagged behind. Specifically, the challenges and gaps in quality assurance (QA) and testing of AI applications have largely remained unaddressed contributing to a poor translation rate of ML applications from research to real world. Unlike traditional software, which has a well-defined software testing methodology, ML applications have largely taken an ad-hoc approach to testing. ML researchers and practitioners either fall back to traditional software testing approaches, which are inadequate for this domain, due to its inherent probabilistic and data dependent nature, or rely largely on non-rigorous self-defined QA methodologies. These issues have driven the ML and Software Engineering research communities to develop of newer tools and techniques designed specifically for ML. These research advances need to be publicized and practiced in real world in ML development and deployment for enabling successful translation of ML from research prototypes to real world. This tutorial intends to address this need.This tutorial aims to:[1] Provide a comprehensive overview of testing of ML applications[2] Provide practical insights and share community best practices for testing ML softwareBesides scientific literature, we derive our insights from our conversations with industry experts in ML.},
booktitle = {Proceedings of the 7th ACM IKDD CoDS and 25th COMAD},
pages = {373–374},
numpages = {2},
keywords = {Software Testing, Quality Assurance, Machine Learning},
location = {Hyderabad, India},
series = {CoDS COMAD 2020}
}

@inproceedings{10.1109/FIT.2012.33,
author = {Hassan, J. and Awan, A. Majid and Jalil, A.},
title = {Welding Defect Detection and Classification Using Geometric Features},
year = {2012},
isbn = {9780769549279},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/FIT.2012.33},
doi = {10.1109/FIT.2012.33},
abstract = {In this paper we present a welding defect detection system using radiographic images. Main goal is to craft a dependable system because a human evaluator is not a stable evaluator besides other humanoid constraints. We present a novel technique for the detection and classification of weld defects by means of geometric features. Firstly noise reduction is done as radiographic images contain noise due to several effects. After this we tend to localize defects with maximum interclass variance and minimum intra class variance. Further we move towards extracting features describing the shape of localized objects in segmented images. Using these shape descriptors (geometric features) we classify the defects by Artificial Neural Network.},
booktitle = {Proceedings of the 2012 10th International Conference on Frontiers of Information Technology},
pages = {139–144},
numpages = {6},
keywords = {welding, radiography, features extraction},
series = {FIT '12}
}

@article{10.1080/08839514.2017.1378012,
author = {Fekri-Ershad, Shervan and Tajeripour, Farshad},
title = {Multi-Resolution and Noise-Resistant Surface Defect Detection Approach Using New Version of Local Binary Patterns},
year = {2017},
issue_date = {2017},
publisher = {Taylor &amp; Francis, Inc.},
address = {USA},
volume = {31},
number = {5–6},
issn = {0883-9514},
url = {https://doi.org/10.1080/08839514.2017.1378012},
doi = {10.1080/08839514.2017.1378012},
abstract = {Visual quality inspection systems play an important role in many industrial applications. In this respect, surface defect detection is one of the problems that have received much attention by image processing scientists. Until now, different methods have been proposed based on texture analysis. An operation that provides discriminate features for texture analysis is local binary patterns LBP. LBP was first introduced for gray-level images that makes it useless for colorful samples. Sensitivity to noise is another limitation of LBP. In this article, a new noise-resistant and multi-resolution version of LBP is used that extracts color and texture features jointly. Then, a robust algorithm is proposed for detecting abnormalities in surfaces. It includes two steps. First, new version of LBP is applied on full defect-less surface images, and the basic feature vector is calculated. Then, by image windowing and computing the non-similarity amount between windows and basic vector, a threshold is computed. In test phase, defect parts are detected on test samples using the tuned threshold. High detection rate, low computational complexity, low noise sensitivity, and rotation invariant are some advantages of our proposed approach.},
journal = {Appl. Artif. Intell.},
month = jul,
pages = {395–410},
numpages = {16}
}

@article{10.1007/s00138-011-0403-3,
author = {Tsai, Du-Ming and Chen, Ming-Chun and Li, Wei-Chen and Chiu, Wei-Yao},
title = {A fast regularity measure for surface defect detection},
year = {2012},
issue_date = {September 2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {5},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-011-0403-3},
doi = {10.1007/s00138-011-0403-3},
abstract = {In this paper, we propose a fast regularity measure for defect detection in non-textured and homogeneously textured surfaces, with specific emphasis on ill-defined subtle defects. A small neighborhood window of proper size is first chosen and they slide over the entire inspection image in a pixel-by-pixel basis. The regularity measure for each image patch enclosed in the window is then derived from the eigenvalues of the covariance matrix formed by the variance–covariance of the x- and y-coordinates with the pixel gray levels as the weights for all pixel points in the window. The two eigenvalues of the weighted covariance matrix will be approximately the same when the image patch contains only a homogeneous region, whereas the two eigenvalues will be relatively different if the image patch in the window contains a defect. The smaller eigenvalue of the covariance matrix is then used as the regularity measure. The integral image technique is introduced to the computation of the regularity measure so that it is invariant to the neighborhood window size. The proposed method uses only one single discrimination feature for defect detection. It avoids the use of complicated classifiers in a high-dimensional feature space, and requires no learning process from a set of defective and defect-free training samples. Experimental results on a variety of material surfaces found in industry, including textured images of plastic surfaces and leather and non-textured images of backside solar wafers and LCD backlight panels, have shown the effectiveness of the proposed regularity measure for surface defect detection. It is computationally very fast, and takes only 0.032 s for a 400 \texttimes{} 400 image on a Pentium 3.00&nbsp;GHz personal computer. In a test set of 73 backside solar wafer images involving 53 defect-free and 20 defective samples, the proposed regularity measure can correctly identify all the test images.},
journal = {Mach. Vision Appl.},
month = sep,
pages = {869–886},
numpages = {18},
keywords = {Texture analysis, Surface inspection, Integral image, Computer vision}
}

@inproceedings{10.5555/1802408.1802423,
author = {Jiang, Yue and Lin, Jie and Cukic, Bojan and Menzies, Tim},
title = {Variance analysis in software fault prediction models},
year = {2009},
isbn = {9781424453757},
publisher = {IEEE Press},
abstract = {Software fault prediction models play an important role in software quality assurance. They identify software subsystems (modules, components, classes, or files) which are likely to contain faults. These subsystems, in turn, receive additional resources for verification and validation activities. Fault prediction models are binary classifiers typically developed using one of the supervised learning techniques from either a subset of the fault data from the current project or from a similar past project. In practice, it is critical that such models provide a reliable prediction performance on the data not used in training. Variance is an important reliability indicator of software fault prediction models. However, variance is often ignored or barely mentioned in many published studies. In this paper, through the analysis of twelve data sets from a public software engineering repository from the perspective of variance, we explore the following five questions regarding fault prediction models: (1) Do different types of classification performance measures exhibit different variance? (2) Does the size of the data set imply a more (or less) accurate prediction performance? (3) Does the size of training subset impact model's stability? (4) Do different classifiers consistently exhibit different performance in terms of model's variance? (5) Are there differences between variance from 1000 runs and 10 runs of 10-fold cross validation experiments? Our results indicate that variance is a very important factor in understanding fault prediction models and we recommend the best practice for reporting variance in empirical software engineering studies.},
booktitle = {Proceedings of the 20th IEEE International Conference on Software Reliability Engineering},
pages = {99–108},
numpages = {10},
location = {Bengaluru-Mysuru, India},
series = {ISSRE'09}
}

@article{10.5555/1859570.1859573,
author = {Tolba, A. S. and Atwan, Ahmad and Amanneddine, N. and Mutawa, A. M. and Khan, H. A.},
title = {Defect detection in flat surface products using log-Gabor filters},
year = {2010},
issue_date = {August 2010},
publisher = {IOS Press},
address = {NLD},
volume = {7},
number = {3},
issn = {1448-5869},
abstract = {This paper introduces a novel method for defect detection in homogeneous flat surface products. The coefficient of variation is used as a homogeneity measure for approximate defect localization and features extracted from the Log - Gabor filter bank response are used to accurately localize and detect the defect while reducing the complexity of Gabor based inspection approaches. The scanning window size and threshold parameter are the two major factors that affect the system performance. An adaptive technique is proposed for selecting the size of the scanning window and automating the selection of the threshold level. Compared to the Log-Gabor filters, the proposed combination resulted in speeding up the defect detection process by about ten times. The experimental results show that the proposed system gives promising results and is applicable for defect detection in homogeneous surfaces like paper, steel plates, ceramic tiles and foils.},
journal = {Int. J. Hybrid Intell. Syst.},
month = aug,
pages = {187–201},
numpages = {15},
keywords = {log-gabor filter bank, homogeneity measures, feature extraction, defect detection, Automated visual inspection}
}

@article{10.1016/j.eswa.2008.10.027,
author = {Catal, Cagatay and Diri, Banu},
title = {A systematic review of software fault prediction studies},
year = {2009},
issue_date = {May, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2008.10.027},
doi = {10.1016/j.eswa.2008.10.027},
abstract = {This paper provides a systematic review of previous software fault prediction studies with a specific focus on metrics, methods, and datasets. The review uses 74 software fault prediction papers in 11 journals and several conference proceedings. According to the review results, the usage percentage of public datasets increased significantly and the usage percentage of machine learning algorithms increased slightly since 2005. In addition, method-level metrics are still the most dominant metrics in fault prediction research area and machine learning algorithms are still the most popular methods for fault prediction. Researchers working on software fault prediction area should continue to use public datasets and machine learning algorithms to build better fault predictors. The usage percentage of class-level is beyond acceptable levels and they should be used much more than they are now in order to predict the faults earlier in design phase of software life cycle.},
journal = {Expert Syst. Appl.},
month = may,
pages = {7346–7354},
numpages = {9},
keywords = {Public datasets, Method-level metrics, Machine learning, Expert systems, Automated fault prediction models}
}

@article{10.1007/s00138-011-0335-y,
author = {Tolba, Ahmad Said},
title = {A novel multiscale-multidirectional autocorrelation approach for defect detection in homogeneous flat surfaces},
year = {2012},
issue_date = {July 2012},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {4},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-011-0335-y},
doi = {10.1007/s00138-011-0335-y},
abstract = {Defect detection in flat web surface products is a challenging task. Reliable vision-based systems for detection of defects require the suitable selection of a huge set of parameters which highly impact the performance of these systems such as image resolution/scale, size of the scanning window, feature extraction, direction of scanning, classifier type and parameters and system performance evaluation measures. This paper addresses these issues and introduces a novel multi-scale and multi-directional (MSMD) autocorrelation function (ACF)-based approach for reliable defect detection and localization in homogeneous web surfaces. The proposed approach has been experimentally tested on samples from the well-known TILDA textiles database and wallboards. Performance evaluation using the system Precision, Recall (Sensitivity), Specificity, Accuracy, Youden’s index, F-measure and Matthews correlation coefficient has shown that the MSMD ACF approach outperforms the state-of-the-art approaches like MSMD Log-Gabor filters. The MSMD ACFs approach results in better performance indicators for defect detection than the Log-Gabor based approach in addition to being about 2–6 times faster in defect detection.},
journal = {Mach. Vision Appl.},
month = jul,
pages = {739–750},
numpages = {12},
keywords = {Performance evaluation, MSMD ACF, Log-Gabor filter banks, Defect detection}
}

@article{10.1016/j.jss.2009.12.023,
author = {de Carvalho, Andr\'{e} B. and Pozo, Aurora and Vergilio, Silvia Regina},
title = {A symbolic fault-prediction model based on multiobjective particle swarm optimization},
year = {2010},
issue_date = {May, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {83},
number = {5},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.12.023},
doi = {10.1016/j.jss.2009.12.023},
abstract = {In the literature the fault-proneness of classes or methods has been used to devise strategies for reducing testing costs and efforts. In general, fault-proneness is predicted through a set of design metrics and, most recently, by using Machine Learning (ML) techniques. However, some ML techniques cannot deal with unbalanced data, characteristic very common of the fault datasets and, their produced results are not easily interpreted by most programmers and testers. Considering these facts, this paper introduces a novel fault-prediction approach based on Multiobjective Particle Swarm Optimization (MOPSO). Exploring Pareto dominance concepts, the approach generates a model composed by rules with specific properties. These rules can be used as an unordered classifier, and because of this, they are more intuitive and comprehensible. Two experiments were accomplished, considering, respectively, fault-proneness of classes and methods. The results show interesting relationships between the studied metrics and fault prediction. In addition to this, the performance of the introduced MOPSO approach is compared with other ML algorithms by using several measures including the area under the ROC curve, which is a relevant criterion to deal with unbalanced data.},
journal = {J. Syst. Softw.},
month = may,
pages = {868–882},
numpages = {15},
keywords = {Rule learning algorithm, Particle swarm optimization, Multiobjective, Fault prediction}
}

@inproceedings{10.1109/ICRA.2016.7487573,
author = {Fujii, Hiromitsu and Yamashita, Atsushi and Asama, Hajime},
title = {Defect detection with estimation of material condition using ensemble learning for hammering test},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICRA.2016.7487573},
doi = {10.1109/ICRA.2016.7487573},
abstract = {This paper introduces a new methodology of robotic hammering inspection for the maintenance of social infrastructures. In particular, the estimation of material defect conditions, such as delamination depth of concrete, is focused upon. Development of an automated diagnosis methodology is necessary for the maintenance of superannuated social infrastructures. The hammering test, which is an efficient inspection method, has attracted considerable attention in the context of automated inspection using robots. In this study, to apply the hammering test to robotic inspection, in which material conditions of infrastructures must be diagnosed in detail, an estimation method of the defect conditions is proposed, and an integration technique of plural classifiers for improving the inspection accuracy is introduced. Furthermore, an inspection system that can decrease the influence of the mechanical running-noise is implemented. Our experimental results using concrete test pieces demonstrate the effectiveness of the proposed method; the accuracy of the defect detection and defect condition estimation was validated.},
booktitle = {2016 IEEE International Conference on Robotics and Automation (ICRA)},
pages = {3847–3854},
numpages = {8},
location = {Stockholm, Sweden}
}

@article{10.1016/j.jvcir.2013.05.011,
author = {Bissi, Lucia and Baruffa, Giuseppe and Placidi, Pisana and Ricci, Elisa and Scorzoni, Andrea and Valigi, Paolo},
title = {Automated defect detection in uniform and structured fabrics using Gabor filters and PCA},
year = {2013},
issue_date = {October, 2013},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {24},
number = {7},
issn = {1047-3203},
url = {https://doi.org/10.1016/j.jvcir.2013.05.011},
doi = {10.1016/j.jvcir.2013.05.011},
abstract = {This paper describes an algorithm for texture defect detection in uniform and structured fabrics, which has been tested on the TILDA image database. The proposed approach is structured in a feature extraction phase, which relies on a complex symmetric Gabor filter bank and Principal Component Analysis (PCA), and on a defect identification phase, which is based on the Euclidean norm of features and on the comparison with fabric type specific parameters. Our analysis is performed on a patch basis, instead of considering single pixels. The performance has been evaluated with uniformly textured fabrics and fabrics with visible texture and grid-like structures, using as reference defect locations identified by human observers. The results show that our algorithm outperforms previous approaches in most cases, achieving a detection rate of 98.8% and a false alarm rate as low as 0.20-0.37%, whereas for heavily structured yarns misdetection rate can be as low as 5%.},
journal = {J. Vis. Comun. Image Represent.},
month = oct,
pages = {838–845},
numpages = {8},
keywords = {TILDA, Principa Component Analysis, Manual defect annotation, Gabor filters, False alarm rate, Fabric defect detection, Detection rate, Automated textile inspection}
}

@article{10.1016/j.compind.2020.103232,
author = {Ge, Ce and Wang, Jing and Wang, Jingyu and Qi, Qi and Sun, Haifeng and Liao, Jianxin},
title = {Towards automatic visual inspection: A weakly supervised learning method for industrial applicable object detection},
year = {2020},
issue_date = {Oct 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {121},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2020.103232},
doi = {10.1016/j.compind.2020.103232},
journal = {Comput. Ind.},
month = oct,
numpages = {11},
keywords = {Deep learning, Weakly supervised learning, Object detection, Insulator detection, Industrial automation}
}

@inproceedings{10.1145/2532443.2532461,
author = {Chen, Jiaqiang and Liu, Shulong and Chen, Xiang and Gu, Qing and Chen, Daoxu},
title = {Empirical studies on feature selection for software fault prediction},
year = {2013},
isbn = {9781450323697},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2532443.2532461},
doi = {10.1145/2532443.2532461},
abstract = {Classification based software fault prediction methods aim to classify the modules into either fault-prone or non-fault-prone. Feature selection is a preprocess step used to improve the data quality. However most of previous research mainly focus on feature relevance analysis, there is little work focusing on feature redundancy analysis. Therefore we propose a two-stage framework for feature selection to solve this issue. In particular, during the feature relevance phase, we adopt three different relevance measures to obtain the relevant feature subset. Then during the feature redundancy analysis phase, we use a cluster-based method to eliminate redundant features. To verify the effectiveness of our proposed framework, we choose typical real-world software projects, including Eclipse projects and NASA software project KC1. Final empirical result shows the effectiveness of our proposed framework.},
booktitle = {Proceedings of the 5th Asia-Pacific Symposium on Internetware},
articleno = {26},
numpages = {4},
keywords = {software fault prediction, relevance analysis, redundancy analysis, feature selection},
location = {Changsha, China},
series = {Internetware '13}
}

@article{10.1504/IJCAT.2016.080493,
author = {Kayarvizhy, N. and Kanmani, S. and Uthariaraj, V. Rhymend},
title = {Enhancing the fault prediction accuracy of CK metrics using high precision cohesion metric},
year = {2016},
issue_date = {January 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {54},
number = {4},
issn = {0952-8091},
url = {https://doi.org/10.1504/IJCAT.2016.080493},
doi = {10.1504/IJCAT.2016.080493},
abstract = {Object-oriented programs can be viewed as a collection of objects communicating with each other to perform a unique task. Many complex commercial applications have taken the object-oriented approach because of the benefits that it offers. The need for a reliable software resulted in the study and analysis of object-oriented metrics. The Chidamber and Kemerer CK metric suite has been considered as a pioneering work on object-oriented metrics and is the default standard for any new metric to be compared against. In this paper we evaluate the fault prediction capability of CK metric suite and validate it empirically. To further improve the accuracy of fault prediction we explore replacing the cohesion metric LCOM in CK suite with the proposed cohesion metric high precision cohesion metric. We have considered data from 500 classes spread across 12 projects for the study. The results show that there is a considerable improvement in the prediction accuracy.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {290–296},
numpages = {7},
keywords = {software reliability, object-oriented programming, object-oriented metrics, high precision cohesion metric, fault prediction accuracy, OOP, HPCM, Chidamber and Kemerer, CK metrics}
}

@inproceedings{10.1109/PACIIA.2008.179,
author = {Guan, Shengqi and Shi, Xiuhua and Cui, Haiying and Song, Yuqin},
title = {Fabric Defect Detection Based on Wavelet Characteristics},
year = {2008},
isbn = {9780769534909},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/PACIIA.2008.179},
doi = {10.1109/PACIIA.2008.179},
abstract = {On the basis of wavelet and singular signal characteristic analysis, a new defect detection method based on wavelet characteristics is presented. Firstly, to select wavelet filters of compact support and high vanishing moment properties are regarded as finite biorthogonal filters. Secondly, the new wavelet with concussive and filters coefficients of centralized distribution is constructed by lifting scheme, which is matching with test fabric texture properties. Lastly, the detail signal feature after wavelet decomposition of fabric image is extracted, and it is compared with the detail signal feature of normal fabric image decomposition to determine whether there exists defect. The experimental result confirms that the proposed method is validity and the detection accuracy is over 92.5%.},
booktitle = {Proceedings of the 2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application - Volume 01},
pages = {366–370},
numpages = {5},
keywords = {Wavelet characteristics, Lifting Sheme, Feature extraction, Defect Detection},
series = {PACIIA '08}
}

@inproceedings{10.1109/ICMA.2017.8015822,
author = {Gao, Qiang and Liu, Wenjie and Zhao, Xuewen and Li, Junfang and Yu, Xiao},
title = {Research and application of the distillation column process fault prediction based on the improved KPCA},
year = {2017},
isbn = {978-1-5090-6758-9},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICMA.2017.8015822},
doi = {10.1109/ICMA.2017.8015822},
abstract = {With the development of modern intelligent, automation and integration of the increasingly complex industrial process control system, the traditional prediction methods of faults perform not well, so it has faced a huge challenge. In this paper, a new improved kernel principal component analysis method is presented which uses the concept of indiscernibility and eigenvector applied to distillation column process fault prediction. Compared with traditional statistical techniques, improved KPCA not only can remove variables with little or no correlation with the fault, but also can reduce the amount of datas calculated by K. Applying this new method to distillation column process fault prediction, the simulation results show that the proposed methods have great advantages. Compared with the traditional KPCA, the improved KPCA improves the ability to predict the process failure caused by small disturbance and becomes more effective.},
booktitle = {2017 IEEE International Conference on Mechatronics and Automation (ICMA)},
pages = {247–251},
numpages = {5},
location = {Takamatsu, Japan}
}

@inproceedings{10.1145/3071178.3071261,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat},
title = {Mining cross product line rules with multi-objective search and machine learning},
year = {2017},
isbn = {9781450349208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3071178.3071261},
doi = {10.1145/3071178.3071261},
abstract = {Nowadays, an increasing number of systems are being developed by integrating products (belonging to different product lines) that communicate with each other through information networks. Cost-effectively supporting Product Line Engineering (PLE) and in particular enabling automation of configuration in PLE is a challenge. Capturing rules is the key for enabling automation of configuration. Product configuration has a direct impact on runtime interactions of communicating products. Such products might be within or across product lines and there usually don't exist explicitly specified rules constraining configurable parameter values of such products. Manually specifying such rules is tedious, time-consuming, and requires expert's knowledge of the domain and the product lines. To address this challenge, we propose an approach named as SBRM that combines multi-objective search with machine learning to mine rules. To evaluate the proposed approach, we performed a real case study of two communicating Video Conferencing Systems belonging to two different product lines. Results show that SBRM performed significantly better than Random Search in terms of fitness values, Hyper-Volume, and machine learning quality measurements. When comparing with rules mined with real data, SBRM performed significantly better in terms of Failed Precision (18%), Failed Recall (72%), and Failed F-measure (59%).},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1319–1326},
numpages = {8},
keywords = {rule mining, product line, multi-objective search, machine learning, configuration},
location = {Berlin, Germany},
series = {GECCO '17}
}

@article{10.1109/TKDE.2011.163,
author = {Bishnu, Partha S. and Bhattacherjee, Vandana},
title = {Software Fault Prediction Using Quad Tree-Based K-Means Clustering Algorithm},
year = {2012},
issue_date = {June 2012},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {24},
number = {6},
issn = {1041-4347},
url = {https://doi.org/10.1109/TKDE.2011.163},
doi = {10.1109/TKDE.2011.163},
abstract = {Unsupervised techniques like clustering may be used for fault prediction in software modules, more so in those cases where fault labels are not available. In this paper a Quad Tree-based K-Means algorithm has been applied for predicting faults in program modules. The aims of this paper are twofold. First, Quad Trees are applied for finding the initial cluster centers to be input to the K-Means Algorithm. An input threshold parameter delta governs the number of initial cluster centers and by varying delta the user can generate desired initial cluster centers. The concept of clustering gain has been used to determine the quality of clusters for evaluation of the Quad Tree-based initialization algorithm as compared to other initialization techniques. The clusters obtained by Quad Tree-based algorithm were found to have maximum gain values. Second, the Quad Tree-based algorithm is applied for predicting faults in program modules. The overall error rates of this prediction approach are compared to other existing algorithms and are found to be better in most of the cases.},
journal = {IEEE Trans. on Knowl. and Data Eng.},
month = jun,
pages = {1146–1150},
numpages = {5},
keywords = {software fault prediction., Quad Tree, K-Means clustering}
}

@article{10.1145/3092566,
author = {Ghaffarian, Seyed Mohammad and Shahriari, Hamid Reza},
title = {Software Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey},
year = {2017},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3092566},
doi = {10.1145/3092566},
abstract = {Software security vulnerabilities are one of the critical issues in the realm of computer security. Due to their potential high severity impacts, many different approaches have been proposed in the past decades to mitigate the damages of software vulnerabilities. Machine-learning and data-mining techniques are also among the many approaches to address this issue. In this article, we provide an extensive review of the many different works in the field of software vulnerability analysis and discovery that utilize machine-learning and data-mining techniques. We review different categories of works in this domain, discuss both advantages and shortcomings, and point out challenges and some uncharted territories in the field.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {56},
numpages = {36},
keywords = {survey, software vulnerability discovery, software security, review, machine-learning, data-mining, Software vulnerability analysis}
}

@inproceedings{10.5555/1671248.1671311,
author = {Tosun, Ayse and Bener, Ayse},
title = {Reducing false alarms in software defect prediction by decision threshold optimization},
year = {2009},
isbn = {9781424448425},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Software defect data has an imbalanced and highly skewed class distribution. The misclassification costs of two classes are not equal nor are known. It is critical to find the optimum bound, i.e. threshold, which would best separate defective and defect-free classes in software data. We have applied decision threshold optimization on Na\"{\i}ve Bayes classifier in order to find the optimum threshold for software defect data. ROC analyses show that decision threshold optimization significantly decreases false alarms (on the average by 11%) without changing probability of detection rates.},
booktitle = {Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
pages = {477–480},
numpages = {4},
series = {ESEM '09}
}

@inbook{10.1007/978-3-540-89778-1_4,
author = {Feather, Martin S.},
title = {Defect Detection and Prevention (DDP)},
year = {2008},
isbn = {9783540897774},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-89778-1_4},
abstract = {The Defect Detection and Prevention (DDP) decision support process, developed at JPL, has over the last 8 years been applied to assist in making a variety of spacecraft decisions. It was originally conceived of as a means to help select and plan hardware assurance activities (inspections, tests, etc) [1], generally late in the development lifecycle. However, since then it has been used predominantly in early phase of system design, when information is scarce, yet many critical decisions are made. Its range of application has extended to encompass a wide variety of kinds of systems and technologies. Its predominant role has been to assist in planning the maturation of promising new technologies to help guide the next steps in their development as they emerge from the laboratory and seek to mature sufficiently to become acceptable to spacecraft missions [2]. Although this may at first glance seem far removed from terrestrial considerations, the factors that come into play in this kind of decision-making are universal - unclear and inconsistent perceptions about requirements and capabilities, uncertainty of what are the driving concerns that should be addressed and how best to address them, challenges of gathering and combining information from experts of multiple difference disciplines, and inevitably the lack of sufficient resources (money, time, CPU, power, ...) to do everything one would wish. Other significant applications of DDP have been as the risk management tool for entire spacecraft projects in their early phases of development, as an aid to planning portfolios of mission activities (e.g., [3]), and as a means to help guide R&amp;D decisions (e.g., [4], [5]).},
booktitle = {Innovations for Requirement Analysis. From Stakeholders' Needs to Formal Designs: 14th Monterey Workshop 2007, Monterey, CA, USA, September 10-13, 2007. Revised Selected Papers},
pages = {13–14},
numpages = {2}
}

@article{10.1111/exsy.12078,
author = {Malhotra, Ruchika and Bansal, Ankita Jain},
title = {Fault prediction considering threshold effects of object-oriented metrics},
year = {2015},
issue_date = {April 2015},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {32},
number = {2},
issn = {0266-4720},
url = {https://doi.org/10.1111/exsy.12078},
doi = {10.1111/exsy.12078},
abstract = {Software product quality can be enhanced significantly if we have a good knowledge and understanding of the potential faults therein. This paper describes a study to build predictive models to identify parts of the software that have high probability of occurrence of fault. We have considered the effect of thresholds of object-oriented metrics on fault proneness and built predictive models based on the threshold values of the metrics used. Prediction of fault prone classes in earlier phases of software development life cycle will help software developers in allocating the resources efficiently. In this paper, we have used a statistical model derived from logistic regression to calculate the threshold values of object oriented, Chidamber and Kemerer metrics. Thresholds help developers to alarm the classes that fall outside a specified risk level. In this way, using the threshold values, we can divide the classes into two levels of risk - low risk and high risk. We have shown threshold effects at various risk levels and validated the use of these thresholds on a public domain, proprietary dataset, KC1 obtained from NASA and two open source, Promise datasets, IVY and JEdit using various machine learning methods and data mining classifiers. Interproject validation has also been carried out on three different open source datasets, Ant and Tomcat and Sakura. This will provide practitioners and researchers with well formed theories and generalised results. The results concluded that the proposed threshold methodology works well for the projects of similar nature or having similar characteristics.},
journal = {Expert Sys: J. Knowl. Eng.},
month = apr,
pages = {203–219},
numpages = {17},
keywords = {software quality, receiver operating characteristics, object-oriented metrics, machine learning, logistic regression, empirical validation}
}

@article{10.5555/1718109.1718125,
author = {Lin, Chun-Cheng and Yeh, Cheng-Yu},
title = {Texture defect detection system with image deflection compensation},
year = {2009},
issue_date = {September 2009},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
volume = {8},
number = {9},
issn = {1109-2750},
abstract = {Image textural analysis technology has been widely used in the design of automated defect detection systems. Because the presence of defects may change the textural features of an image, a reference image without defects can be compared with the test image to detect whether there are any defects. However, besides defects, the deflection of the input test image could also change its textural features. When there is any angular difference between the reference and test images, their textural features would also be different, even if there is no defect in the test image. As a result, misjudgment of the defect detection system may occur. Most of the previous studies have focused on the development of textural analysis technology which could decrease the effect of test image deflection. This study aimed to estimate the deflection angle of test images through polar Fourier transform and phase correlation analysis, and rotate the reference image by the same angle to compensate for the deflection of the test image. After the angles of the reference and test images were brought into line, the textural analysis based on the gray level co-occurrence matrix was applied to analyze and compare the textural features of the two images. The results of actual texture defect detection demonstrated that the angular differences between the reference and test images could be estimated correctly, with an estimation error of only 0° to 0.5°. By compensating for the deflection of the test image, the accuracy of the texture defect detection could be effectively enhanced.},
journal = {W. Trans. on Comp.},
month = sep,
pages = {1575–1586},
numpages = {12},
keywords = {texture defect detection, polar fourier transform, phase correlation analysis, image deflection compensation, gray level co-occurrence matrix}
}

@article{10.1007/s00138-008-0146-y,
author = {Zontak, Maria and Cohen, Israel},
title = {Defect detection in patterned wafers using anisotropic kernels},
year = {2010},
issue_date = {February 2010},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {2},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-008-0146-y},
doi = {10.1007/s00138-008-0146-y},
abstract = {Wafer defect detection often relies on accurate image registration of source and reference images obtained from neighboring dies. Unfortunately, perfect registration is generally impossible, due to pattern variations between the source and reference images. In this paper, we propose a defect detection procedure, which avoids image registration and is robust to pattern variations. The proposed method is based on anisotropic kernel reconstruction of the source image using the reference image. The source and reference images are mapped into a feature space, where every feature with origin in the source image is estimated by a weighted sum of neighboring features from the reference image. The set of neighboring features is determined according to the spatial neighborhood in the original image space, and the weights are calculated from exponential distance similarity function. We show that features originating from defect regions are not reconstructible from the reference image, and hence can be identified. The performance of the proposed algorithm is evaluated and its advantage is demonstrated compared to using an anomaly detection algorithm.},
journal = {Mach. Vision Appl.},
month = feb,
pages = {129–141},
numpages = {13},
keywords = {Similarity measure, Semiconductor defect detection, NL-means, Image reconstruction, Anomaly detection, Anisotropic kernels}
}

@inproceedings{10.1145/1370750.1370759,
author = {Ratzinger, Jacek and Sigmund, Thomas and Gall, Harald C.},
title = {On the relation of refactorings and software defect prediction},
year = {2008},
isbn = {9781605580241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370750.1370759},
doi = {10.1145/1370750.1370759},
abstract = {This paper analyzes the influence of evolution activities such as refactoring on software defects. In a case study of five open source projects we used attributes of software evolution to predict defects in time periods of six months. We use versioning and issue tracking systems to extract 110 data mining features, which are separated into refactoring and non-refactoring related features. These features are used as input into classification algorithms that create prediction models for software defects. We found out that refactoring related features as well as non-refactoring related features lead to high quality prediction models. Additionally, we discovered that refactorings and defects have an inverse correlation: The number of software defects decreases, if the number of refactorings increased in the preceding time period. As a result, refactoring should be a significant part of both bug fixes and other evolutionary changes to reduce software defects.},
booktitle = {Proceedings of the 2008 International Working Conference on Mining Software Repositories},
pages = {35–38},
numpages = {4},
keywords = {software evolution, software analysis, mining},
location = {Leipzig, Germany},
series = {MSR '08}
}

@inproceedings{10.1007/978-3-030-05499-1_8,
author = {Kopaczka, Marcin and Saggiomo, Marco and G\"{u}ttler, Moritz and Kielholz, Kevin and Merhof, Dorit},
title = {Detection and Classification of Faulty Weft Threads Using Both Feature-Based and Deep Convolutional Machine Learning Methods},
year = {2018},
isbn = {978-3-030-05498-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-05499-1_8},
doi = {10.1007/978-3-030-05499-1_8},
abstract = {In our work, we analyze how faulty weft threads in air-jet weaving machines can be detected using image processing methods. To this end, we design and construct a multi-camera array for automated acquisition of images of relevant machine areas. These images are subsequently fed into a multi-stage image processing pipeline that allows defect detection using a set of different preprocessing and classification methods. Classification is performed using both image descriptors combined with feature-based machine learning algorithms and deep learning techniques implementing fully convolutional neural networks. To analyze the capabilities of our solution, system performance is thoroughly evaluated under realistic production settings. We show that both approaches show excellent detection rates and that by utilizing semantic segmentation acquired from a fully convolutional network we are not only able to detect defects reliably but also classify defects into different subtypes, allowing more refined strategies for defect removal.},
booktitle = {Pattern Recognition Applications and Methods: 7th International Conference, ICPRAM 2018, Funchal, Madeira, Portugal, January 16-18, 2018, Revised Selected Papers},
pages = {141–163},
numpages = {23},
location = {Funchal, Portugal}
}

@article{10.5555/1294141.1294145,
author = {Cucchiara, R. and Mello, P. and Piccardi, M. and Riguzzi, F.},
title = {An application of machine learning and statistics to defect detection},
year = {2001},
issue_date = {April 2001},
publisher = {IOS Press},
address = {NLD},
volume = {5},
number = {2},
issn = {1088-467X},
abstract = {We present an application of machine learning and statistics to the problem of distinguishing between defective and non-defective industrial workpieces, where the defect takes the form of a long and thin crack on the surface of the piece. From the images of pieces a number of features are extracted by using the Hough transform and the Correlated Hough transform. Two datasets are considered, one containing only features related to the Hough transform and the other containing also features related to the Correlated Hough transform. On these datasets we have compared six different learning algorithms: an attribute-value learner, C4.5, a backpropagation neural network, NeuralWorks Predict, a k-nearest neighbour algorithm, and three statistical techniques, linear, logistic and quadratic discriminant. The experiments show that C4.5 performs best for both feature sets and gives an average accuracy of 93.3% for the first dataset and 95.9% for the second dataset.},
journal = {Intell. Data Anal.},
month = apr,
pages = {151–164},
numpages = {14}
}

@inproceedings{10.1109/ISSRE.2009.13,
author = {Jiang, Yue and Lin, Jie and Cukic, Bojan and Menzies, Tim},
title = {Variance Analysis in Software Fault Prediction Models},
year = {2009},
isbn = {9780769538785},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2009.13},
doi = {10.1109/ISSRE.2009.13},
abstract = {Software fault prediction models play an important role in softwarequality assurance. They identify software subsystems (modules,components, classes, or files) which are likely to contain faults.These subsystems, in turn, receive additional resources forverification and validation activities.Fault prediction models arebinary classifiers typically developed using one of the supervisedlearning techniques from either a subset of the fault data from thecurrent project or from a similar past project.In practice, itis critical that such models provide a reliable predictionperformance on the data not used in training.Variance is animportant reliability indicator of software fault prediction models.However, variance is often ignored or barely mentioned in manypublished studies. In this paper, through the analysis of twelvedata sets from a public software engineering repository from theperspective of variance, we explore the following five questionsregarding fault prediction models:(1) Do different types ofclassification performance measures exhibit different variance? (2)Does the size of the data set imply a more (or less) accurateprediction performance? (3) Does the size of training subset impactmodel's stability? (4) Do different classifiers consistently exhibitdifferent performance in terms of model's variance? (5) Are theredifferences between variance from 1000 runs and 10 runs of 10-fold crossvalidation experiments?Our results indicate that variance is avery important factor in understanding fault prediction models andwe recommend the best practice for reporting variance in empiricalsoftware engineering studies.},
booktitle = {Proceedings of the 2009 20th International Symposium on Software Reliability Engineering},
pages = {99–108},
numpages = {10},
keywords = {variance, machine learning, fault prediction models},
series = {ISSRE '09}
}

@inproceedings{10.5555/2394970.2395098,
author = {Castilho, Hugo Peres and Gon\c{c}alves, Paulo Jorge Sequeira and Pinto, Jo\~{a}o Rog\'{e}rio Caldas and Serafim3, Ant\'{o}nio Limas},
title = {Intelligent real-time fabric defect detection},
year = {2007},
isbn = {3540742581},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper presents real-time fabric defect detection based in intelligent techniques. Neural networks (NN), fuzzy modeling (FM) based on productspace fuzzy clustering and adaptive network based fuzzy inference system (ANFIS) were used to obtain a clearly classification for defect detection. Their implementation requires thresholding its output, and based in previous studies a confusion matrix based optimization is used to obtain the threshold. Experimental results for real fabric defect detection were obtained from the experimental apparatus presented in the paper, that showed the usefulness of the three intelligent techniques, although the NN has a faster performance. Online implementation of the algorithms showed they can be easily implemented with commonly available resources and may be adapted to industrial applications without great effort.},
booktitle = {Proceedings of the 4th International Conference on Image Analysis and Recognition},
pages = {1297–1307},
numpages = {11},
location = {Montreal, Canada},
series = {ICIAR'07}
}

@article{10.1155/2018/7913952,
author = {Hoang, Nhat-Duc and Peric, Zoran},
title = {Image Processing-Based Recognition of Wall Defects Using Machine Learning Approaches and Steerable Filters},
year = {2018},
issue_date = {2018},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2018},
issn = {1687-5265},
url = {https://doi.org/10.1155/2018/7913952},
doi = {10.1155/2018/7913952},
abstract = {Detection of defects including cracks and spalls on wall surface in high-rise buildings is a crucial task of buildings’ maintenance. If left undetected and untreated, these defects can significantly affect the structural integrity and the aesthetic aspect of buildings. Timely and cost-effective methods of building condition survey are of practicing need for the building owners and maintenance agencies to replace the time- and labor-consuming approach of manual survey. This study constructs an image processing approach for periodically evaluating the condition of wall structures. Image processing algorithms of steerable filters and projection integrals are employed to extract useful features from digital images. The newly developed model relies on the Support vector machine and least squares support vector machine to generalize the classification boundaries that categorize conditions of wall into five labels: longitudinal crack, transverse crack, diagonal crack, spall damage, and intact wall. A data set consisting of 500 image samples has been collected to train and test the machine learning based classifiers. Experimental results point out that the proposed model that combines the image processing and machine learning algorithms can achieve a good classification performance with a classification accuracy rate = 85.33%. Therefore, the newly developed method can be a promising alternative to assist maintenance agencies in periodic building surveys.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {18}
}

@inproceedings{10.1109/UKSim.2013.95,
author = {Mirmahdavi, Seyyed Abdollah and Ahmadyfard, Alireza and Shahraki, Abdollah Amirkhani and Khojasteh, Parham},
title = {A Novel Modeling of Random Textures Using Fourier Transform for Defect Detection},
year = {2013},
isbn = {9780769549941},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/UKSim.2013.95},
doi = {10.1109/UKSim.2013.95},
abstract = {In this paper we are concerned with the problem of detecting defects on random texture surfaces. We propose a novel method for the addressed problem. Due to the nature of random textures, characterizing normal patterns from defects is difficult. In this method we use the approach so called Phase Only Transform from Fourier transform family to extract frequency features from the texture patches in training and test stages. In training stage we use the extracted features from the training image patches to learn the probability density function of patches in the feature space. The training is performed on non-defective training sample using Gaussian mixture model. In the test stage, we divide the test image into small patches and from each patch we extract frequency features similar to training images. We use weighted normalized Euclidean distance measure derived from the model parameters to set a proper threshold. In order to obtain a defect map, distance of feature vectors extracted from image under inspection at each pixel position is calculated against our learned model and compare with threshold. The result of experiments for detecting defects on random texture tiles is very promising},
booktitle = {Proceedings of the 2013 UKSim 15th International Conference on Computer Modelling and Simulation},
pages = {470–475},
numpages = {6},
keywords = {random texture, defect detection, Gaussian Mixture Model, Fourier Transform},
series = {UKSIM '13}
}

@inproceedings{10.1109/ETFA.2016.7733668,
author = {Bonnin-Pascual, Francisco and Ortiz, Alberto},
title = {A generic framework for defect detection on vessel structures based on image saliency},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ETFA.2016.7733668},
doi = {10.1109/ETFA.2016.7733668},
abstract = {Seagoing vessels have to undergo regular visual inspections in order to detect defects such as cracks and corrosion before they result into catastrophic consequences. These inspections are currently performed manually by ship surveyors at a great cost, so that any level of assistance during the inspection process would significatively decrease the inspection cost. In this paper, we describe a novel framework for visually detecting the aforementioned defects. This framework is generic and flexible in the sense that it can be easily configured to compute the features that perform better for the inspection at hand. In this regard, inspired by the idea of conspicuity, this work considers contrast and symmetry as features for detecting defects on vessel structures. A combination operator is additionally tested in order to merge the information provided by these features and improve the detection performance. Experimental results for the different configurations of the detection framework show better classification results than state of the art methods.},
booktitle = {2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)},
pages = {1–4},
numpages = {4},
location = {Berlin, Germany}
}

@inproceedings{10.1145/1868328.1868350,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
title = {On the value of learning from defect dense components for software defect prediction},
year = {2010},
isbn = {9781450304047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868328.1868350},
doi = {10.1145/1868328.1868350},
abstract = {BACKGROUND: Defect predictors learned from static code measures can isolate code modules with a higher than usual probability of defects.AIMS: To improve those learners by focusing on the defect-rich portions of the training sets.METHOD: Defect data CM1, KC1, MC1, PC1, PC3 was separated into components. A subset of the projects (selected at random) were set aside for testing. Training sets were generated for a NaiveBayes classifier in two ways. In sample the dense treatment, the components with higher than the median number of defective modules were used for training. In the standard treatment, modules from any component were used for training. Both samples were run against the test set and evaluated using recall, probability of false alarm, and precision. In addition, under sampling and over sampling was performed on the defect data. Each method was repeated in a 10-by-10 cross-validation experiment.RESULTS: Prediction models learned from defect dense components out-performed standard method, under sampling, as well as over sampling. In statistical rankings based on recall, probability of false alarm, and precision, models learned from dense components won 4--5 times more often than any other method, and also lost the least amount of times.CONCLUSIONS: Given training data where most of the defects exist in small numbers of components, better defect predictors can be trained from the defect dense components.},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
articleno = {14},
numpages = {9},
keywords = {ceiling effect, defect dense components, defect prediction, sampling},
location = {Timi\c{s}oara, Romania},
series = {PROMISE '10}
}

@inproceedings{10.1145/3377713.3377753,
author = {Lu, Qiwei and Cheng, Jinpei and Guo, Dianlin and Su, Mengmeng and Wu, Xuewei and Ru, Tao},
title = {Binary Classification Model Based on Machine Learning Algorithm for the Short-Circuit Detection in Power System},
year = {2020},
isbn = {9781450372619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377713.3377753},
doi = {10.1145/3377713.3377753},
abstract = {Short circuit faults usually occur in the damaged insulation lines or line connections, which will cause serious accidents such as fires and explosions. As the power supply distance increases, accuracy of short-circuit fault detection is insufficient and the process is tedious with the traditional analysis method. In order to solve the problems above, the short-circuit fault detection is classified into the two classification problems while the machine learning method is used. The data of the normal state and short circuit fault state are obtained by the short-circuit simulation experiment. Extract four features from time domain, including the average current and so on. By training support vector machine (SVM) using the different combinations of extraction features above, the model is obtained. The accuracy of classification of the test data set by the model is high. The results show that the short-circuit fault detection method based on machine learning is more accurate and robust than traditional analysis methods.},
booktitle = {Proceedings of the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence},
pages = {271–275},
numpages = {5},
keywords = {normalization, feature extraction, feature analysis, Short-circuit detection},
location = {Sanya, China},
series = {ACAI '19}
}

@inproceedings{10.5555/2487085.2487122,
author = {Amoui, Mehdi and Kaushik, Nilam and Al-Dabbagh, Abraham and Tahvildari, Ladan and Li, Shimin and Liu, Weining},
title = {Search-based duplicate defect detection: an industrial experience},
year = {2013},
isbn = {9781467329361},
publisher = {IEEE Press},
abstract = {Duplicate defects put extra overheads on software organizations, as the cost and effort of managing duplicate defects are mainly redundant. Due to the use of natural language and various ways to describe a defect, it is usually hard to investigate duplicate defects automatically. This problem is more severe in large software organizations with huge defect repositories and massive number of defect reporters. Ideally, an efficient tool should prevent duplicate reports from reaching developers by automatically detecting and/or filtering duplicates. It also should be able to offer defect triagers a list of top-N similar bug reports and allow them to compare the similarity of incoming bug reports with the suggested duplicates. This demand has motivated us to design and develop a search-based duplicate bug detection framework at BlackBerry. The approach follows a generalized process model to evaluate and tune the performance of the system in a systematic way. We have applied the framework on software projects at BlackBerry, in addition to the Mozilla defect repository. The experimental results exhibit the performance of the developed framework and highlight the high impact of parameter tuning on its performance.},
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
pages = {173–182},
numpages = {10},
location = {San Francisco, CA, USA},
series = {MSR '13}
}

@inproceedings{10.1145/2979779.2979811,
author = {Kaur, Ishleen and Bajpai, Neha},
title = {An Empirical Study on Fault Prediction using Token-Based Approach},
year = {2016},
isbn = {9781450342131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2979779.2979811},
doi = {10.1145/2979779.2979811},
abstract = {Since exhaustive testing is not possible, prediction of fault prone modules can be used for prioritizing the components of a software system. Various approaches have been proposed for the prediction of fault prone modules. Most of them uses module metrics as quality estimators. In this study, we proposed a tokenbased approach and combine the metric evaluated from our approach with the module metrics to further improve the prediction results. We conducted the experiment on an open source project for evaluating the approach. The proposed approach is further compared with the existing fault prone filtering technique. The results show that the proposed approach is an improvement over fault prone filtering technique.},
booktitle = {Proceedings of the International Conference on Advances in Information Communication Technology &amp; Computing},
articleno = {32},
numpages = {7},
keywords = {software testing, software metrics, logistic regression, fault prone modules, fault, Classification},
location = {Bikaner, India},
series = {AICTC '16}
}

@inproceedings{10.1109/GCIS.2009.356,
author = {Han, Runping and Zhang, Lingmin},
title = {Fabric Defect Detection Method Based on Gabor Filter Mask},
year = {2009},
isbn = {9780769535715},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/GCIS.2009.356},
doi = {10.1109/GCIS.2009.356},
abstract = {In this paper, a fabric defect detection method based on Gabor filter masks is proposed. In this method, one even symmetric Gabor filter mask and one odd symmetric Gabor filter mask derived from the impulse response of the optimal Gabor filter are used. The optimal Gabor filter is designed to match with the texture features of defect-free fabric image, whose parameters are obtained by using the genetic algorithm. The performance of the proposed method is evaluated off-line by using a group of fabric sample images containing many kinds of fabric defects. The experimental results exhibit its accurate defect detection with low false alarms. And the effectiveness and robustness of the proposed method are confirmed.},
booktitle = {Proceedings of the 2009 WRI Global Congress on Intelligent Systems - Volume 03},
pages = {184–188},
numpages = {5},
keywords = {fabric defect detection, convolution mask, Gabor filter, GA},
series = {GCIS '09}
}

@inproceedings{10.1145/2463676.2465338,
author = {Condie, Tyson and Mineiro, Paul and Polyzotis, Neoklis and Weimer, Markus},
title = {Machine learning for big data},
year = {2013},
isbn = {9781450320375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2463676.2465338},
doi = {10.1145/2463676.2465338},
abstract = {Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities.The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research.},
booktitle = {Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data},
pages = {939–942},
numpages = {4},
keywords = {machine learning, databases, big data},
location = {New York, New York, USA},
series = {SIGMOD '13}
}

@inproceedings{10.1007/978-3-030-68821-9_12,
author = {Dementev, Vitalii E. and Gaponova, Maria A. and Suetin, Marat R. and Streltzova, Anastasia S.},
title = {The Use of Machine Learning Methods to Detect Defects in Images of Metal Structures},
year = {2021},
isbn = {978-3-030-68820-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68821-9_12},
doi = {10.1007/978-3-030-68821-9_12},
abstract = {The work is devoted to the study of the possibilities provided by modern neural networks in image processing for solving the problem of monitoring the state of steel and reinforced concrete structures. The paper presents a method for solving problems of such monitoring based on the use of a combination of several neural networks focused on recognizing a fragment of a structure and parts of a structure. Methods for training neural networks on small training samples are proposed. The results of algorithms on real images that show the consistency and efficiency of the proposed solution are presented.},
booktitle = {Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10–15, 2021, Proceedings, Part V},
pages = {120–128},
numpages = {9},
keywords = {Deep learning, Neural networks, Adaptive algorithm, Recognition, Anomaly detection, Prediction}
}

@inproceedings{10.1109/IS.2016.7737471,
author = {Marani, Roberto and Palumbo, Davide and Galietti, Umberto and Stella, Ettore and D'Orazio, Tiziana},
title = {Automatic detection of subsurface defects in composite materials using thermography and unsupervised machine learning},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IS.2016.7737471},
doi = {10.1109/IS.2016.7737471},
abstract = {This paper presents a complete framework aimed to nondestructive inspection of composite materials. Starting from the acquisition, performed with lock-in thermography, the method flows through a set of consecutive blocks of data processing: input enhancement, feature extraction, classification and defect detection. Experimental results prove the capability of the presented methodology to detect the presence of defects underneath the surface of a calibrated specimen made of Glass Fiber Reinforced Polymer (GFRP). Results are also compared with those obtained by other techniques, based on different features and unsupervised learning methods. The comparison further proves that the proposed methodology is able to reduce the number of false positives, while ensuring the exact detection of subsurface defects.},
booktitle = {2016 IEEE 8th International Conference on Intelligent Systems (IS)},
pages = {516–521},
numpages = {6},
location = {Sofia, Bulgaria}
}

@article{10.1016/j.eswa.2010.09.144,
author = {Si, Xiao-Sheng and Hu, Chang-Hua and Yang, Jian-Bo and Zhang, Qi},
title = {On the dynamic evidential reasoning algorithm for fault prediction},
year = {2011},
issue_date = {May, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {5},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.09.144},
doi = {10.1016/j.eswa.2010.09.144},
abstract = {Research highlights A dynamic evidential reasoning algorithm is presented for dynamic fusion. A fault prognosis model is established based on the dynamic evidential reasoning algorithm. The optimization models are presented for estimating the parameters of the prognosis model. The developed model has been validated by case studies. In this paper, a new fault prediction model is presented to deal with the fault prediction problems in the presence of both quantitative and qualitative data based on the dynamic evidential reasoning (DER) approach. In engineering practice, system performance is constantly changed with time. As such, there is a need to develop a supporting mechanism that can be used to conduct dynamic fusion with time, and establish a prediction model to trace and predict system performance. In this paper, a DER approach is first developed to realize dynamic fusion. The new approach takes account of time effect by introducing belief decaying factor, which reflects the nature that evidence credibility is decreasing over time. Theoretically, it is show that the new DER aggregation schemes also satisfy the synthesis theorems. Then a fault prediction model based on the DER approach is established and several optimization models are developed for locally training the DER prediction model. The main feature of these optimization models is that only partial input and output information is required, which can be either incomplete or vague, either numerical or judgmental, or mixed. The models can be used to fine tune the DER prediction model whose initial parameters are decided by expert's knowledge or common sense. Finally, two numerical examples are provided to illustrate the detailed implementation procedures of the proposed approach and demonstrate its potential applications in fault prediction.},
journal = {Expert Syst. Appl.},
month = may,
pages = {5061–5080},
numpages = {20},
keywords = {Utility, Nonlinear programming, Fault prediction, Dynamic evidential reasoning approach, Artificial intelligence}
}

@article{10.1016/j.infsof.2019.07.003,
author = {Zhou, Tianchi and Sun, Xiaobing and Xia, Xin and Li, Bin and Chen, Xiang},
title = {Improving defect prediction with deep forest},
year = {2019},
issue_date = {Oct 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {114},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.07.003},
doi = {10.1016/j.infsof.2019.07.003},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {204–216},
numpages = {13},
keywords = {Empirical evaluation, Cascade strategy, Deep forest, Software defect prediction}
}

@inproceedings{10.1109/COMPSAC.2015.66,
author = {Liu, Wangshu and Liu, Shulong and Gu, Qing and Chen, Xiang and Chen, Daoxu},
title = {FECS: A Cluster Based Feature Selection Method for Software Fault Prediction with Noises},
year = {2015},
isbn = {9781467365642},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2015.66},
doi = {10.1109/COMPSAC.2015.66},
abstract = {Noises are inevitable when mining software archives for software fault prediction. Although some researchers have investigated the noise tolerance of existing feature selection methods, few studies focus on proposing new feature selection methods with a certain noise tolerance. To solve this issue, we propose a novel method FECS (FEature Clustering with Selection strategies). This method includes two phases: a feature clustering phase and a feature selection phase with three different heuristic search strategies. During empirical studies, we choose real-world software projects, such as Eclipse and NASA and inject class level and feature level noises simultaneously to imitate noisy datasets. After using classical feature selection methods as the baseline, we confirm the effectiveness of FECS and provide a guideline of using FECS after analyzing the effects of varying either the percentage of selected features or the noise rate.},
booktitle = {Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 02},
pages = {276–281},
numpages = {6},
keywords = {Software Quality Assurance, Software Fault Prediction, Noise Tolerance, Feature Selection, Classification Model},
series = {COMPSAC '15}
}

@inproceedings{10.1109/iCECE.2010.253,
author = {Luhui, Lin and Jie, Ma},
title = {Fault Prediction Based on Data-Driven Technique},
year = {2010},
isbn = {9780769540313},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/iCECE.2010.253},
doi = {10.1109/iCECE.2010.253},
abstract = {This paper presents principal component analysis (PCA), some improvement of PCA and the development of PCA. PCA does not depend on the accurate mathematical model, is able to implement the feature extraction of the complex process data, and establishes a principal component model of the corresponding process. It can achieve the extraction of the system information and eliminate the interference the system. So there is the existence of a good applications prospect in the complex process of fault diagnosis and prediction maintain.},
booktitle = {Proceedings of the 2010 International Conference on Electrical and Control Engineering},
pages = {997–1001},
numpages = {5},
keywords = {principal component analysis (PCA), improvement, fault prediction, data-driven},
series = {ICECE '10}
}

@article{10.1016/j.eswa.2010.08.022,
author = {Catal, Cagatay and Sevim, Ugur and Diri, Banu},
title = {Practical development of an Eclipse-based software fault prediction tool using Naive Bayes algorithm},
year = {2011},
issue_date = {March, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {3},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.08.022},
doi = {10.1016/j.eswa.2010.08.022},
abstract = {Despite the amount of effort software engineers have been putting into developing fault prediction models, software fault prediction still poses great challenges. This research using machine learning and statistical techniques has been ongoing for 15years, and yet we still have not had a breakthrough. Unfortunately, none of these prediction models have achieved widespread applicability in the software industry due to a lack of software tools to automate this prediction process. Historical project data, including software faults and a robust software fault prediction tool, can enable quality managers to focus on fault-prone modules. Thus, they can improve the testing process. We developed an Eclipse-based software fault prediction tool for Java programs to simplify the fault prediction process. We also integrated a machine learning algorithm called Naive Bayes into the plug-in because of its proven high-performance for this problem. This article presents a practical view to software fault prediction problem, and it shows how we managed to combine software metrics with software fault data to apply Naive Bayes technique inside an open source platform.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {2347–2353},
numpages = {7},
keywords = {Software fault prediction, Naive Bayes, Machine learning, Eclipse technology}
}

@article{10.1016/j.patcog.2007.11.014,
author = {Ngan, Henry Y. T. and Pang, Grantham K. H. and Yung, Nelson H. C.},
title = {Motif-based defect detection for patterned fabric},
year = {2008},
issue_date = {June, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {41},
number = {6},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2007.11.014},
doi = {10.1016/j.patcog.2007.11.014},
abstract = {This paper proposes a generalized motif-based method for detecting defects in 16 out of 17 wallpaper groups in 2D patterned texture. It assumes that most patterned texture can be decomposed into lattices and their constituents-motifs. It then utilizes the symmetry property of motifs to calculate the energy of moving subtraction and its variance among different motifs. By learning the distribution of these values over a number of defect-free patterns, boundary conditions for discerning defective and defect-free patterns can be determined. This paper presents the theoretical foundation of the method, and defines the relations between motifs and lattice, from which a new concept called energy of moving subtraction is derived using norm metric measurement between a collection of circular shift matrices of motif and itself. It has been shown in this paper that the energy of moving subtraction amplifies the defect information of the defective motif. Together with its variance, an energy-variance space is further defined where decision boundaries are drawn for classifying defective and defect-free motifs. As the 16 wallpaper groups of patterned fabric can be transformed into three major groups, the proposed method is evaluated over these three major groups, from which 160 defect-free lattices samples are used for defining the decision boundaries, with 140 defect-free and 113 defective samples used for testing. An overall detection success rate of 93.32% is achieved for the proposed method. No other generalized approach can achieve this success rate has been reported before, and hence this result outperforms all other previously published approaches.},
journal = {Pattern Recogn.},
month = jun,
pages = {1878–1894},
numpages = {17},
keywords = {Wallpaper group, Texture analysis, Patterned fabric, Motif, Lattice, Defect detection}
}

@inproceedings{10.1007/978-3-030-79463-7_36,
author = {Kawalerowicz, Marcin and Madeyski, Lech},
title = {Jaskier: A Supporting Software Tool for&nbsp;Continuous Build Outcome Prediction Practice},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_36},
doi = {10.1007/978-3-030-79463-7_36},
abstract = {Continuous Defect Prediction (CDP) is an assisting software development practice that combines Software Defect Prediction (SDP) with machine learning aided modelling and continuous developer feedback. Jaskier is a set of software tools developed under the supervision and with the participation of the authors of the article that implements a lightweight version of CDP called Continuous Build Outcome Prediction (CBOP). CBOP uses classification to label the possible build results based on historical data and metrics derived from the software repository. This paper contains a detailed description of the tool that was already started to be used in the production environment of a real software project where the CBOP practice is being evaluated.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {426–438},
numpages = {13},
keywords = {Continuous integration, Software defect prediction},
location = {Kuala Lumpur, Malaysia}
}

@article{10.1155/2019/8097213,
author = {Hoang, Nhat-Duc and Tran, Van-Duc and G\'{o}mez-Pulido, Juan A.},
title = {Image Processing-Based Detection of Pipe Corrosion Using Texture Analysis and Metaheuristic-Optimized Machine Learning Approach},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1687-5265},
url = {https://doi.org/10.1155/2019/8097213},
doi = {10.1155/2019/8097213},
abstract = {To maintain the serviceability of buildings, the owners need to be informed about the current condition of the water supply and waste disposal systems. Therefore, timely and accurate detection of corrosion on pipe surface is a crucial task. The conventional manual surveying process performed by human inspectors is notoriously time consuming and labor intensive. Hence, this study proposes an image processing-based method for automating the task of pipe corrosion detection. Image texture including statistical measurement of image colors, gray-level co-occurrence matrix, and gray-level run length is employed to extract features of pipe surface. Support vector machine optimized by differential flower pollination is then used to construct a decision boundary that can recognize corroded and intact pipe surfaces. A dataset consisting of 2000 image samples has been collected and utilized to train and test the proposed hybrid model. Experimental results supported by the Wilcoxon signed-rank test confirm that the proposed method is highly suitable for the task of interest with an accuracy rate of 92.81%. Thus, the model proposed in this study can be a promising tool to assist building maintenance agents during the phase of pipe system survey.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {13}
}

@article{10.1007/s11334-017-0295-0,
author = {Shatnawi, Raed},
title = {The application of ROC analysis in threshold identification, data imbalance and metrics selection for software fault prediction},
year = {2017},
issue_date = {September 2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {2–3},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-017-0295-0},
doi = {10.1007/s11334-017-0295-0},
abstract = {Software engineers have limited resources and need metrics analysis tools to investigate software quality such as fault-proneness of modules. There are a large number of software metrics available to investigate quality. However, not all metrics are strongly correlated with faults. In addition, software fault data are imbalanced and affect quality assessment tools such as fault prediction or threshold values that are used to identify risky modules. Software quality is investigated for three purposes. First, the receiver operating characteristics (ROC) analysis is used to identify threshold values to identify risky modules. Second, the ROC analysis is investigated for imbalanced data. Third, the ROC analysis is considered for feature selection. This work validated the use of ROC to identify thresholds for four metrics (WMC, CBO, RFC and LCOM). The ROC results after sampling the data are not significantly different from before sampling. The ROC analysis selects the same metrics (WMC, CBO and RFC) in most datasets, while other techniques have a large variation in selecting metrics.},
journal = {Innov. Syst. Softw. Eng.},
month = sep,
pages = {201–217},
numpages = {17},
keywords = {Software metrics, ROC analysis, Imbalanced data, Feature selection, Fault-proneness models}
}

@article{10.1016/j.eswa.2021.114810,
author = {Demirci, Mustafa Yusuf and Be\c{s}li, Nurettin and G\"{u}m\"{u}\c{s}\c{c}\"{u}, Abd\"{u}lkadir},
title = {Efficient deep feature extraction and classification for identifying defective photovoltaic module cells in Electroluminescence images},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {175},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114810},
doi = {10.1016/j.eswa.2021.114810},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {15},
keywords = {Deep learning, Deep features, Feature selection, Feature extraction, Defect detection, Electroluminescence imaging}
}

@article{10.1016/j.asoc.2016.04.032,
author = {Malhotra, Ruchika},
title = {An empirical framework for defect prediction using machine learning techniques with Android software},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.04.032},
doi = {10.1016/j.asoc.2016.04.032},
abstract = {Display Omitted Use of appropriate and large number data sets for comparing 18 ML techniques for defect prediction using object-oriented metrics.Effective performance of the predicted models assessed using appropriate performance measures.Reliability of the results evaluated using statistical test and post-hoc analysis.Validating the predicted models using inter-release validation on various releases of seven application packages of Android software. ContextSoftware defect prediction is important for identification of defect-prone parts of a software. Defect prediction models can be developed using software metrics in combination with defect data for predicting defective classes. Various studies have been conducted to find the relationship between software metrics and defect proneness, but there are few studies that statistically determine the effectiveness of the results. ObjectiveThe main objectives of the study are (i) comparison of the machine-learning techniques using data sets obtained from popular open source software (ii) use of appropriate performance measures for measuring the performance of defect prediction models (iii) use of statistical tests for effective comparison of machine-learning techniques and (iv) validation of models over different releases of data sets. MethodIn this study we use object-oriented metrics for predicting defective classes using 18 machine-learning techniques. The proposed framework has been applied to seven application packages of well known, widely used Android operating system viz. Contact, MMS, Bluetooth, Email, Calendar, Gallery2 and Telephony. The results are validated using 10-fold and inter-release validation methods. The reliability and significance of the results are evaluated using statistical test and post-hoc analysis. ResultsThe results show that the area under the curve measure for Nave Bayes, LogitBoost and Multilayer Perceptron is above 0.7 in most of the cases. The results also depict that the difference between the ML techniques is statistically significant. However, it is also proved that the Support Vector Machines based techniques such as Support Vector Machines and voted perceptron do not possess the predictive capability for predicting defects. ConclusionThe results confirm the predictive capability of various ML techniques for developing defect prediction models. The results also confirm the superiority of one ML technique over the other ML techniques. Thus, the software engineers can use the results obtained from this study in the early phases of the software development for identifying defect-prone classes of given software.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1034–1050},
numpages = {17},
keywords = {Statistical tests, Software defect proneness, Object-oriented metrics, Machine-learning, Inter-release validation}
}

@inproceedings{10.1007/978-3-642-38577-3_68,
author = {D\'{\i}ez-Pastor, Jos\'{e} Francisco and Garc\'{\i}a-Osorio, C\'{e}sar and Barbero-Garc\'{\i}a, V\'{\i}ctor and Blanco-\'{A}lamo, Alan},
title = {Imbalanced learning ensembles for defect detection in X-ray images},
year = {2013},
isbn = {9783642385766},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-38577-3_68},
doi = {10.1007/978-3-642-38577-3_68},
abstract = {This paper describes the process of detection of defects in metallic pieces through the analysis of X-ray images. The images used in this work are highly variable (several different pieces, different views, variability introduced by the inspection process such as positioning the piece). Because of this variability, the sliding window technique has been used, an approach based on data mining. Experiments have been carried out with various window sizes, several feature selection algorithms and different classification algorithms, with a special focus on learning unbalanced data sets. The results show that Bagging achieved significantly better results than decision trees by themselves or combined with SMOTE or Undersampling.},
booktitle = {Proceedings of the 26th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems},
pages = {654–663},
numpages = {10},
keywords = {x-ray, undersampling, non destructive testing, ensemble learning, bagging, SMOTE},
location = {Amsterdam, The Netherlands},
series = {IEA/AIE'13}
}

@inproceedings{10.1145/2837060.2837066,
author = {Han, Ji-Hyeong and Kim, Rockwon and Chi, Su-Young},
title = {Applications of Machine Learning Algorithms to Predictive Manufacturing: Trends and Application of Tool Wear Compensation Parameter Recommendation},
year = {2015},
isbn = {9781450338462},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2837060.2837066},
doi = {10.1145/2837060.2837066},
abstract = {The manufacturing industry has become more competitive because of globalization and fast change in the industry. To survive from the global market, manufacturing enterprises should reduce the product cost and increase the productivity. The most promising way is applying the information communication technology especially machine learning algorithms to the traditional manufacturing system. This paper presents recent trends of applying machine learning techniques to manufacturing system and briefly explains each kind of applications. As a representative application of machine learning algorithms to manufacturing system, a generalized tool wear compensation parameter recommendation framework using regression algorithms and preliminary results using real data gathered from local and small manufacturing are also presented.},
booktitle = {Proceedings of the 2015 International Conference on Big Data Applications and Services},
pages = {51–57},
numpages = {7},
keywords = {tool wear compensation parameter recommendation, machine learning, Predictive manufacturing},
location = {Jeju Island, Republic of Korea},
series = {BigDAS '15}
}

@inproceedings{10.1007/978-3-642-39068-5_56,
author = {Nawaz, Javeria Muhammad and Arshad, Muhammad Zeeshan and Hong, Sang Jeen},
title = {Time series fault prediction in semiconductor equipment using recurrent neural network},
year = {2013},
isbn = {9783642390678},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-39068-5_56},
doi = {10.1007/978-3-642-39068-5_56},
abstract = {This paper presents a model of Elman recurrent neural network (ERNN) for time series fault prediction in semiconductor etch equipment. ERNN maintains a copy of previous state of the input in its context units, as well as the current state of the input. Derivative dynamic time warping (DDTW) method is also discussed for the synchronization of time series data set acquired from plasma etcher. For each parameter of the data, the best ERNN structure was selected and trained using Levenberg Marquardt to generate one-step-ahead prediction for 10 experimental runs. The faulty experimental runs were successfully distinguished from healthy experimental runs with one missed alarm out of ten experimental runs.},
booktitle = {Proceedings of the 10th International Conference on Advances in Neural Networks - Volume Part II},
pages = {463–472},
numpages = {10},
keywords = {time series prediction, recurrent neural network, derivative dynamic time warping},
location = {Dalian, China},
series = {ISNN'13}
}

@article{10.1007/s00500-019-04047-7,
author = {Sudharson, D. and Prabha, D.},
title = {RETRACTED ARTICLE: A novel machine learning
approach for software reliability growth modelling with pareto distribution
function},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {18},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-019-04047-7},
doi = {10.1007/s00500-019-04047-7},
abstract = {Software reliability is the important quantifiable attribute in gaining
reliability by assessing faults at the time of testing in the software products.
Time-based software reliability models used to identify the defects in the product,
and it is not suitable for dynamic situations. Instead of time, test effect is used
in few explorations through effort function and it is not realistic for infinite
testing time. Identifying number of defects is essential in software reliability
models, and this research work presents a Pareto distribution (PD) to predict the
fault distribution of software under homogenous and nonhomogeneous conditions along
with artificial neural network (ANN). This methodology enables the parallel
evolution of a product through NN models which exhibit estimated Pareto optimality
with respect to multiple error measures. The proposed PD-ANN-based SRGM describes
types of failure data and also improves the accuracy of parameter estimation more
than existing growth models such as homogeneous poison process and two fuzzy time
series-based software reliability models. Experimental evidence is presented for
general application and the proposed framework by generating solutions for different
product and developer indexes.},
journal = {Soft Comput.},
month = sep,
pages = {8379–8387},
numpages = {9},
keywords = {Software reliability, Artificial neural networks, Pareto distribution, Distribution parameter estimation}
}

@article{10.1155/2019/8391425,
author = {Ren, Jiadong and Zheng, Zhangqi and Liu, Qian and Wei, Zhiyao and Yan, Huaizhi and Chen, Jiageng},
title = {A Buffer Overflow Prediction Approach Based on Software Metrics and Machine Learning},
year = {2019},
issue_date = {2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2019},
issn = {1939-0114},
url = {https://doi.org/10.1155/2019/8391425},
doi = {10.1155/2019/8391425},
abstract = {Buffer overflow vulnerability is the most common and serious type of vulnerability in software today, as network security issues have become increasingly critical. To alleviate the security threat, many vulnerability mining methods based on static and dynamic analysis have been developed. However, the current analysis methods have problems regarding high computational time, low test efficiency, low accuracy, and low versatility. This paper proposed a software buffer overflow vulnerability prediction method by using software metrics and a decision tree algorithm. First, the software metrics were extracted from the software source code, and data from the dynamic data stream at the functional level was extracted by a data mining method. Second, a model based on a decision tree algorithm was constructed to measure multiple types of buffer overflow vulnerabilities at the functional level. Finally, the experimental results showed that our method ran in less time than SVM, Bayes, adaboost, and random forest algorithms and achieved 82.53% and 87.51% accuracy in two different data sets. The method presented in this paper achieved the effect of accurately predicting software buffer overflow vulnerabilities in C/C++ and Java programs.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {13}
}

@article{10.1016/j.patcog.2009.09.006,
author = {Tsneg, Yan-Hsin and Tsai, Du-Ming},
title = {Defect detection of uneven brightness in low-contrast images using basis image representation},
year = {2010},
issue_date = {March, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {43},
number = {3},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2009.09.006},
doi = {10.1016/j.patcog.2009.09.006},
abstract = {In this paper, we propose a machine vision approach for detecting local irregular brightness in low-contrast surface images and, especially, focus on mura (brightness non-uniformity) defects in liquid crystal display (LCD) panels. A mura defect embedded in a low-contrast surface image shows no distinct intensity from its surrounding region, and even worse, the sensed image may also present uneven illumination on the surface. All these make the mura defect detection in low-contrast surface images extremely difficult. A set of basis images derived from defect-free surface images are used to represent the general appearance of a clear surface. An image to be inspected is then constructed as a linear combination of the basis images, and the coefficients of the combination form the feature vector for discriminating mura defects from clear surfaces. In order to find minimum number of basis images for efficient and effective representation, the basis images are designed such that they are both statistically independent and spatially exclusive. An independent component analysis-based model that finds both the maximum negentropy for statistical independency and minimum spatial correlation for spatial redundancy is proposed to extract the representative basis images. Experimental results have shown that the proposed method can effectively detect various mura defects in low-contrast LCD panel images.},
journal = {Pattern Recogn.},
month = mar,
pages = {1129–1141},
numpages = {13},
keywords = {Surface inspection, Particle swarm optimization, Independent component analysis, Defect detection, Basis image representation}
}

@article{10.1155/2021/2668761,
author = {Zhang, Xiangquan and Ma, Zhili and Wang, Anmin and Mi, Haifeng and Hang, Junjun and Xiong, Jinbo},
title = {LstFcFedLear: A LSTM-FC with Vertical Federated Learning Network for Fault Prediction},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/2668761},
doi = {10.1155/2021/2668761},
abstract = {The firefighting IoT platform links multiple firefighting subsystems. The data of each subsystem belongs to the sensitive data of the profession. Failure prediction is a crucial topic for firefighting IoT platforms, because failures may cause equipment injuries. Currently, in the maintenance of fire IoT terminal equipment, fault prediction based on equipment time series has not been included. The use of intelligent technology to continuously predict the failure of firefighting IoT equipment can not only eliminate the intervention of regular maintenance but also provide early warning of upcoming failures. In order to solve this problem, we propose a vertical federated learning framework based on LSTM fault classification network (LstFcFedLear). The advantage of this framework is that it can encrypt and integrate the data on the entire firefighting IoT platform to form a new dataset. After the synthesized data is trained through each model, the optimal model parameters can be finally updated. At the same time, it can ensure that the data of each business system is not leaked. The framework can predict when IoT equipment will fail in the future and then provide what measures should be used. The experimental results show that the LstFcFedLear model provides an effective method for fault prediction, and its results are comparable to the baseline.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {10}
}

@article{10.1007/s10664-008-9079-3,
author = {Jiang, Yue and Cukic, Bojan and Ma, Yan},
title = {Techniques for evaluating fault prediction models},
year = {2008},
issue_date = {October   2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {13},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-008-9079-3},
doi = {10.1007/s10664-008-9079-3},
abstract = {Many statistical techniques have been proposed to predict fault-proneness of program modules in software engineering. Choosing the "best" candidate among many available models involves performance assessment and detailed comparison, but these comparisons are not simple due to the applicability of varying performance measures. Classifying a software module as fault-prone implies the application of some verification activities, thus adding to the development cost. Misclassifying a module as fault free carries the risk of system failure, also associated with cost implications. Methodologies for precise evaluation of fault prediction models should be at the core of empirical software engineering research, but have attracted sporadic attention. In this paper, we overview model evaluation techniques. In addition to many techniques that have been used in software engineering studies before, we introduce and discuss the merits of cost curves. Using the data from a public repository, our study demonstrates the strengths and weaknesses of performance evaluation techniques and points to a conclusion that the selection of the "best" model cannot be made without considering project cost characteristics, which are specific in each development environment.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {561–595},
numpages = {35},
keywords = {Predictive models in software engineering, Model evaluation, Fault-prediction models, Empirical studies}
}

@article{10.1007/s10664-014-9316-x,
author = {Yang, Jiachen and Hotta, Keisuke and Higo, Yoshiki and Igaki, Hiroshi and Kusumoto, Shinji},
title = {Classification model for code clones based on machine learning},
year = {2015},
issue_date = {August    2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9316-x},
doi = {10.1007/s10664-014-9316-x},
abstract = {Results from code clone detectors may contain plentiful useless code clones, but judging whether each code clone is useful varies from user to user based on a user's purpose for the clone. In this research, we propose a classification model that applies machine learning to the judgments of each individual user regarding the code clones. To evaluate the proposed model, 32 participants completed an online survey to test its usability and accuracy. The result showed several important observations on the characteristics of the true positives of code clones for the users. Our classification model showed more than 70 % accuracy on average and more than 90 % accuracy for some particular users and projects.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1095–1125},
numpages = {31},
keywords = {Machine learning, Filtering, Code clone detector, Classify}
}

@inproceedings{10.1007/978-3-642-12304-7_60,
author = {Zhang, Yu and Lu, Zhaoyang and Li, Jing},
title = {Fabric defect detection and classification using gabor filters and gaussian mixture model},
year = {2009},
isbn = {3642123031},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-12304-7_60},
doi = {10.1007/978-3-642-12304-7_60},
abstract = {This work investigates the problem of automatic and robust fabric defect detection and classification which are more essential and important in assuring the fabric quality. Two characteristics of this work are: first, a new scheme combining Gabor filters and Gaussian mixture model (GMM) is proposed for fabric defect detection and classification. In detection, the foreground mask and texture features are extracted using Gabor filters. In classification, a GMM based classifier is trained and assigns each foreground pixel to known classes. The second characteristic of this work is the test data is actually collected from Qinfeng textile factory, China, including nine different fabric defects with more than 1000 samples. All the evaluation of our method is based on these actual fabric images and the experimental results show the proposed algorithm achieved satisfied performance.},
booktitle = {Proceedings of the 9th Asian Conference on Computer Vision - Volume Part II},
pages = {635–644},
numpages = {10},
location = {Xi'an, China},
series = {ACCV'09}
}

@article{10.1145/1943371.1943381,
author = {Bishnu, P. S. and Bhattacherjee, V.},
title = {Application of K-Medoids with Kd-Tree for Software Fault Prediction},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/1943371.1943381},
doi = {10.1145/1943371.1943381},
abstract = {Software fault prediction area is subject to problems like non availability of fault data which makes the application of supervised techniques difficult. In such cases unsupervised approaches like clustering are helpful. In this paper, K-Medoids clustering approach has been applied for software fault prediction. To overcome the inherent computational complexity of KMedoids algorithm a data structure called Kd-Tree has been used to identify data agents in the datasets. Partitioning Around Medoids is applied on these data agents and this results in a set of medoids. All the remaining data points are assigned to the nearest medoids thus obtained to get the final clusters. Software fault prediction error analysis results show that our approach outperforms all unsupervised approaches in the case of one given real dataset and gives best values for the evaluation parameters. For other real datasets, our results are comparable to other techniques. Performance evaluation of our technique with other techniques has been done. Results show that our technique reduces the total number of distance calculations drastically since the number of data agents is much less than the number of data points.},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
pages = {1–6},
numpages = {6},
keywords = {Software fault prediction, Kd-Tree, K-Medoids}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00032,
author = {Parthy, Abhaya and Silberstein, Leo and Kowalczyk, Emily and High, John-Paul and Nagarajan, Adithya and Memon, Atif},
title = {Using machine learning to recommend correctness checks for geographic map data},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00032},
doi = {10.1109/ICSE-SEIP.2019.00032},
abstract = {Developing an industry application that serves geographic map data to users across the world presents the significant challenge of checking the data using "data correctness checks." The size of data that needs to be checked---the entire world---and data churn rate---thousands per day---makes executing the full set of candidate checks cost prohibitive. Current techniques rely on hand-curated static subsets of checks to be run at different stages of the data production pipeline, These hard-coded subsets are uninformed of data changes, and cause bug detection to be delayed to downstream quality assurance activities. To address these problems, we have developed new representations of map data changes and checks, formally defined "check safety," and built a recommender system that dynamically and automatically selects and ranks a relevant subset of checks using signals from latest data changes. Empirical evaluation shows that it improves (1) efficiency by eliminating 65% of checks unrelated to changes, (2) coverage by recommending and ranking change-related checks from the full set of candidate checks, previously excluded by the manual process, and (3) overall visibility into the data editing process by quickly and automatically identifying latest fault prone parts of the data.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {223–232},
numpages = {10},
keywords = {safe test/check selection, data check recommender, automated data validation},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@inproceedings{10.1109/ISISE.2008.139,
author = {Guan, Shengqi and Shi, Xiuhua},
title = {Fabric Defect Detection Based on Wavelet Decomposition with One Resolution Level},
year = {2008},
isbn = {9780769534947},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISISE.2008.139},
doi = {10.1109/ISISE.2008.139},
abstract = {According to the property of wavelet transform and fabric texture's Fourier spectrum, a new method for defect detection was presented. The proposed method is based on wavelet lifting transform with one resolution level. By using restoration scheme of the Fourier transform, the normal fabric textures of smooth sub-image in the spatial domain are removed by detecting the high-energy frequency components of sub-image in the Fourier domain, setting them to zero using frequency-domain filter, and back-transforming to a spatial domain sub-image. Then, the smooth and detail sub-images are segmented into many sub-windows, in which standard deviation are calculated as extracted features. The extracted features are compared with normal sub-window's features to determine whether there exists defect. Experimental results show that this method is validity and feasibility.},
booktitle = {Proceedings of the 2008 International Symposium on Information Science and Engieering - Volume 01},
pages = {281–285},
numpages = {5},
keywords = {wavelet transform, lifting scheme, frequency-domain filter, fourier transform, Defect detection},
series = {ISISE '08}
}

@inproceedings{10.1145/2365324.2365338,
author = {Bowes, David and Hall, Tracy and Gray, David},
title = {Comparing the performance of fault prediction models which report multiple performance measures: recomputing the confusion matrix},
year = {2012},
isbn = {9781450312417},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2365324.2365338},
doi = {10.1145/2365324.2365338},
abstract = {There are many hundreds of fault prediction models published in the literature. The predictive performance of these models is often reported using a variety of different measures. Most performance measures are not directly comparable. This lack of comparability means that it is often difficult to evaluate the performance of one model against another. Our aim is to present an approach that allows other researchers and practitioners to transform many performance measures of categorical studies back into a confusion matrix. Once performance is expressed in a confusion matrix alternative preferred performance measures can then be derived. Our approach has enabled us to compare the performance of 600 models published in 42 studies. We demonstrate the application of our approach on several case studies, and discuss the advantages and implications of doing this.},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering},
pages = {109–118},
numpages = {10},
keywords = {confusion matrix, fault, machine learning},
location = {Lund, Sweden},
series = {PROMISE '12}
}

@article{10.1016/j.imavis.2006.07.028,
author = {Han, Yanfang and Shi, Pengfei},
title = {An adaptive level-selecting wavelet transform for texture defect detection},
year = {2007},
issue_date = {August, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {25},
number = {8},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2006.07.028},
doi = {10.1016/j.imavis.2006.07.028},
abstract = {We present an effective approach based on wavelet transform (WT) to detect defects on images with high frequency texture background. The original image is decomposed at various levels by WT. Then, by selecting an appropriate level at which the approximation sub-image is reconstructed, textures on the background are effectively removed. Thus, the difficult texture defect detection problem can be settled by non-texture techniques. An adaptive level-selecting scheme is presented by analyzing the co-occurrence matrices (COM) of the approximation sub-images. Experiments are done to detect the stains and broken points on texture surfaces. Comparisons with frequency domain low and high pass filters show that our method is much more effective.},
journal = {Image Vision Comput.},
month = aug,
pages = {1239–1248},
numpages = {10},
keywords = {Wavelet transform, Texture image processing, Defect detection, Co-occurrence matrix}
}

@article{10.1016/j.patrec.2005.02.002,
author = {Tsai, Du-Ming and Yang, Cheng-Hsiang},
title = {A quantile-quantile plot based pattern matching for defect detection},
year = {2005},
issue_date = {1 October 2005},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {26},
number = {13},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2005.02.002},
doi = {10.1016/j.patrec.2005.02.002},
abstract = {Pattern matching has been used extensively for many machine vision applications such as optical character recognition, face detection, object detection, and defect detection. The normalized cross correlation (NCC) is the most commonly used technique in pattern matching. However, it is computationally intensive, sensitive to environmental changes such as lighting and shifting, and suffers from false alarms for a complicated image that contains partial uniform regions. In this paper, a pattern-matching scheme based on the quantile-quantile plot (Q-Q plot) is proposed for defect detection applications. In a Q-Q plot, the quantiles of an inspection image are plotted against the corresponding quantiles of the template image. The p-value of Chi-square test from the resulting Q-Q plot is then used as the quantitative measure of similarity between two compared images. The quantile representation transforms the 2D gray-level information into the 1D quantile one. It can therefore efficiently reduce the dimensionality of the data, and accelerate the computation. Experimental results have shown that the proposed pattern-matching scheme is computationally fast and is tolerable to minor displacement and process variation. The proposed similarity measure of p-value has excellent discrimination capability to detect subtle defects, compared with the traditional measure of NCC. With a proper normalization of the Q-Q plot, the p-value measure can be tolerable to moderate light changes. Experimental results from assembled PCB (printed circuit board) samples, IC wafers, and liquid crystal display (LCD) panels have shown the efficacy of the proposed pattern-matching scheme for defect detection.},
journal = {Pattern Recogn. Lett.},
month = oct,
pages = {1948–1962},
numpages = {15},
keywords = {Similarity measure, Quantile-quantile plot, Pattern matching, Defect detection}
}

@inproceedings{10.1109/ICPR.2006.419,
author = {Amano, Toshiyuki},
title = {Correlation Based Image Defect Detection},
year = {2006},
isbn = {0769525210},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICPR.2006.419},
doi = {10.1109/ICPR.2006.419},
abstract = {The defect inspection that used image sensing such as automated pattern inspection is a useful solution to automatize the visual check, not limit to factory automation field. Mostly such defect inspection is using the models of defect that described by primitive features. This paper proposes a new defect detection method that is the non-model based approach. In this approach, the method extracts the image description rule from local regions.It is useful for the defect inspection problems that cannot prepare a defect model such as scratch or superimpose detection, texture image analysis, etc. In the experiment, I tried the defect detection to the landscape picture which several types of superimpose were added. From these results, it was confirmed that the proposed method has high ability to detect the defected regions independently with the texture type.Furthermore, I attempted the application to a scene image.Therefrom, the possibility to apply the figure-ground separation of the image understanding basic problem was confirmed.},
booktitle = {Proceedings of the 18th International Conference on Pattern Recognition - Volume 01},
pages = {163–166},
numpages = {4},
series = {ICPR '06}
}

@inproceedings{10.1007/978-3-642-02397-2_5,
author = {Cottrell, Marie and Gaubert, Patrice and Eloy, C\'{e}dric and Fran\c{c}ois, Damien and Hallaux, Geoffroy and Lacaille, J\'{e}r\^{o}me and Verleysen, Michel},
title = {Fault Prediction in Aircraft Engines Using Self-Organizing Maps},
year = {2009},
isbn = {9783642023965},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-02397-2_5},
doi = {10.1007/978-3-642-02397-2_5},
abstract = {Aircraft engines are designed to be used during several tens of years. Their maintenance is a challenging and costly task, for obvious security reasons. The goal is to ensure a proper operation of the engines, in all conditions, with a zero probability of failure, while taking into account aging. The fact that the same engine is sometimes used on several aircrafts has to be taken into account too.The maintenance can be improved if an efficient procedure for the prediction of failures is implemented. The primary source of information on the health of the engines comes from measurement during flights. Several variables such as the core speed, the oil pressure and quantity, the fan speed, etc. are measured, together with environmental variables such as the outside temperature, altitude, aircraft speed, etc.In this paper, we describe the design of a procedure aiming at visualizing successive data measured on aircraft engines. The data are multi-dimensional measurements on the engines, which are projected on a self-organizing map in order to allow us to follow the trajectories of these data over time. The trajectories consist in a succession of points on the map, each of them corresponding to the two-dimensional projection of the multi-dimensional vector of engine measurements. Analyzing the trajectories aims at visualizing any deviation from a normal behavior, making it possible to anticipate an operation failure.However rough engine measurements are inappropriate for such an analysis; they are indeed influenced by external conditions, and may in addition vary between engines. In this work, we first process the data by a General Linear Model (GLM), to eliminate the effect of engines and of measured environmental conditions. The residuals are then used as inputs to a Self-Organizing Map for the easy visualization of trajectories.},
booktitle = {Proceedings of the 7th International Workshop on Advances in Self-Organizing Maps},
pages = {37–44},
numpages = {8},
keywords = {self-organizing maps, general linear models, fault detection, aircraft engine maintenance},
location = {St. Augustine, FL, USA},
series = {WSOM '09}
}

@inproceedings{10.5555/1819998.1820267,
author = {Fu, Rong and Shi, Meihong and Wei, Hongli and Chen, Huijuan},
title = {Fabric defect detection based on adaptive local binary patterns},
year = {2009},
isbn = {9781424447749},
publisher = {IEEE Press},
abstract = {Adaptive local binary patterns method is proposed in this paper, on which an effective fabric defect detection algorithm is designed. ALBP method selects the frequently occurred patterns to construct the main pattern set, which avoids using the same pattern set to describe different texture structures in uniform local binary patterns method. The features of free defect image are extracted according to the set and the threshold is confirmed. The image to be tested is divided into same size detection windows from which ALBP features are also extracted. Defective window is found through comparing ALBP features with threshold. The experiment exhibited the detection effect of the proposed method is comparatively better than traditional LBP method from human visual aspect and detection accuracy.},
booktitle = {Proceedings of the 2009 International Conference on Robotics and Biomimetics},
pages = {1336–1340},
numpages = {5},
location = {Guilin, China},
series = {ROBIO'09}
}

@inproceedings{10.1109/ITNG.2009.12,
author = {Catal, Cagatay and Sevim, Ugur and Diri, Banu},
title = {Clustering and Metrics Thresholds Based Software Fault Prediction of Unlabeled Program Modules},
year = {2009},
isbn = {9780769535968},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ITNG.2009.12},
doi = {10.1109/ITNG.2009.12},
abstract = {Predicting the fault-proneness of program modules when the fault labels for modules are unavailable is a practical problem frequently encountered in the software industry. Because fault data belonging to previous software version is not available, supervised learning approaches can not be applied, leading to the need for new methods, tools, or techniques. In this study, we propose a clustering and metrics thresholds based software fault prediction approach for this challenging problem and explore it on three datasets, collected from a Turkish white-goods manufacturer developing embedded controller software. Experiments reveal that unsupervised software fault prediction can be automated and reasonable results can be produced with techniques based on metrics thresholds and clustering. The results of this study demonstrate the effectiveness of metrics thresholds and show that the standalone application of metrics thresholds (one-stage) is currently easier than the clustering and metrics thresholds based (two-stage) approach because the selection of cluster number is performed heuristically in this clustering based method.},
booktitle = {Proceedings of the 2009 Sixth International Conference on Information Technology: New Generations},
pages = {199–204},
numpages = {6},
keywords = {unsupervised learning, unlabeled program modules, software fault prediction, metrics thresholds, clustering},
series = {ITNG '09}
}

@inproceedings{10.1007/978-3-642-10684-2_2,
author = {Lopez, Jose J. and Aguilera, Emanuel and Cobos, Maximo},
title = {Defect Detection and Classification in Citrus Using Computer Vision},
year = {2009},
isbn = {9783642106828},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-10684-2_2},
doi = {10.1007/978-3-642-10684-2_2},
abstract = {In this paper, a system for quality control in citrus is presented. In current citrus manufacturing industries, calliper and color are successfully used for the automatic classification of fruits using vision systems. However, fault detection in the citrus surface is carried out by means of human inspection. In this work, a computer vision system capable of detecting defects in the citrus peel and also classifying the type of flaw is presented. First, a review of citrus illnesses has been carried out in order to build a database of digitalized oranges classified by the kind of fault, which is used as a training set. The segmentation of faulty zones is performed by applying the Sobel gradient to the image. Afterwards, color and texture features of the flaw are extracted, some of them related with high order statistics. Several techniques have been employed for classification purposes: Euler distance to a prototype, to the nearest neighbor and k-nearest neighbors. Additionally, a three layer neural network has been tested and compared, obtaining promising results.},
booktitle = {Proceedings of the 16th International Conference on Neural Information Processing: Part II},
pages = {11–18},
numpages = {8},
keywords = {Texture analysis segmentation, Quality control, Computer vision, Automatic inspection system},
location = {Bangkok, Thailand},
series = {ICONIP '09}
}

@inproceedings{10.1145/2593833.2593842,
author = {Malhotra, Ruchika},
title = {Search based techniques for software fault prediction: current trends and future directions},
year = {2014},
isbn = {9781450328524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2593833.2593842},
doi = {10.1145/2593833.2593842},
abstract = {The effective allocation of the resources is crucial and essential in the testing phase of the software development life cycle so that the weak areas in the software can be verified and validated efficiently. The prediction of fault prone classes in the early phases of software development can help software developers to focus the limited available resources on those portions of software, which are more prone to fault. Recently, the search based techniques have been successfully applied in the software engineering domain. In this study, we analyze the position of search based techniques for use in software fault prediction by collecting relevant studies from the literature which were conducted during the period January 1991 to October 2013. We further summarize current trends by assessing the performance capability of the search based techniques in the existing research and suggest future directions.},
booktitle = {Proceedings of the 7th International Workshop on Search-Based Software Testing},
pages = {35–36},
numpages = {2},
keywords = {Software Quality, Software Fault proneness, Search Based Techniques},
location = {Hyderabad, India},
series = {SBST 2014}
}

@article{10.1155/2008/783898,
author = {Tajeripour, F. and Kabir, E. and Sheikhi, A.},
title = {Fabric defect detection using modified local binary patterns},
year = {2008},
issue_date = {January 2008},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2008},
issn = {1110-8657},
url = {https://doi.org/10.1155/2008/783898},
doi = {10.1155/2008/783898},
abstract = {Local binary patterns (LBPs) are one of the features which have been used for texture classification. In this paper, a method based on using these features is proposed for fabric defect detection. In the training stage, at first step, LBP operator is applied to an image of defect free fabric, pixel by pixel, and the reference feature vector is computed. Then this image is divided into windows and LBP operator is applied to each of these windows. Based on comparison with the reference feature vector, a suitable threshold for defect free windows is found. In the detection stage, a test image is divided into windows and using the threshold, defective windows can be detected. The proposed method is multiresolution and gray scale invariant and can be used for defect detection in patterned and unpatterned fabrics. Because of its simplicity, online implementation is possible as well.},
journal = {EURASIP J. Adv. Signal Process},
month = jan,
articleno = {60},
numpages = {12}
}

@inproceedings{10.1109/SERA.2007.41,
author = {Lee, Soon-Bok and Kim, Jin-Woo and Song, Chee-Yang and Baik, Doo-Kwon},
title = {An Approach to Analyzing Commonality and Variability of Features using Ontology in a Software Product Line Engineering},
year = {2007},
isbn = {0769528678},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SERA.2007.41},
doi = {10.1109/SERA.2007.41},
abstract = {In a product line engineering, several studies have been made on analysis of feature which determines commonality and variability of product. Fundamentally, because the studies are based on developer's intuition and domain expert's experience, stakeholders lack common understanding of feature and a feature analysis is informal and subjective. Moreover, the reusability of software products, which were developed, is insufficient. This paper proposes an approach to analyzing commonality and variability of features using semantic-based analysis criteria which is able to change feature model of specific domain to featureontology. For the purpose, first feature attributes were made, create a feature model following the Meta model, transform it into feature-ontology, and save it to Meta feature-ontology repository. Henceforth, when we construct a feature model of the same product line, commonality and variability of the features can be extracted, comparing it with Meta feature ontology through a semantic similarity analysis method, which is proposed. Furthermore, a tool for a semantic similarity-comparing algorithm was implemented and an experiment with an electronic approval system domain in order to show the efficiency of the approach Was conducted. A Meta feature model can definitely be created through this approach, to construct a high-quality feature model based on common understanding of a feature. The main contributions are a formulating a method of extracting commonality and variability from features using ontology based on semantic similarity mapping and a enhancement of reusability of feature model.},
booktitle = {Proceedings of the 5th ACIS International Conference on Software Engineering Research, Management &amp; Applications},
pages = {727–734},
numpages = {8},
series = {SERA '07}
}

@article{10.1016/j.cie.2011.12.023,
author = {Alzghoul, Ahmad and L\"{o}fstrand, Magnus and Backe, Bj\"{o}rn},
title = {Data stream forecasting for system fault prediction},
year = {2012},
issue_date = {May, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {62},
number = {4},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2011.12.023},
doi = {10.1016/j.cie.2011.12.023},
abstract = {Competition among today's industrial companies is very high. Therefore, system availability plays an important role and is a critical point for most companies. Detecting failures at an early stage or foreseeing them before they occur is crucial for machinery availability. Data analysis is the most common method for machine health condition monitoring. In this paper we propose a fault-detection system based on data stream prediction, data stream mining, and data stream management system (DSMS). Companies that are able to predict and avoid the occurrence of failures have an advantage over their competitors. The literature has shown that data prediction can also reduce the consumption of communication resources in distributed data stream processing. In this paper different data-stream-based linear regression prediction methods have been tested and compared within a newly developed fault detection system. Based on the fault detection system, three DSM algorithms outputs are compared to each other and to real data. The three applied and evaluated data stream mining algorithms were: Grid-based classifier, polygon-based method, and one-class support vector machines (OCSVM). The results showed that the linear regression method generally achieved good performance in predicting short-term data. (The best achieved performance was with a Mean Absolute Error (MAE) around 0.4, representing prediction accuracy of 87.5%). Not surprisingly, results showed that the classification accuracy was reduced when using the predicted data. However, the fault-detection system was able to attain an acceptable performance of around 89% classification accuracy when using predicted data.},
journal = {Comput. Ind. Eng.},
month = may,
pages = {972–978},
numpages = {7},
keywords = {Fault detection system, Fault detection forecasting, Data stream prediction, Data stream mining, Data stream management system, Availability}
}

@inproceedings{10.1145/2245276.2231967,
author = {Sarro, F. and Di Martino, S. and Ferrucci, F. and Gravino, C.},
title = {A further analysis on the use of Genetic Algorithm to configure Support Vector Machines for inter-release fault prediction},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2231967},
doi = {10.1145/2245276.2231967},
abstract = {Some studies have reported promising results on the use of Support Vector Machines (SVMs) for predicting fault-prone software components. Nevertheless, the performance of the method heavily depends on the setting of some parameters. To address this issue, we investigated the use of a Genetic Algorithm (GA) to search for a suitable configuration of SVMs to be used for inter-release fault prediction. In particular, we report on an assessment of the method on five software systems. As benchmarks we exploited SVMs with random and Grid-search configuration strategies and several other machine learning techniques. The results show that the combined use of GA and SVMs is effective for inter-release fault prediction.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {1215–1220},
numpages = {6},
keywords = {support vector machines, genetic algorithm, fault prediction},
location = {Trento, Italy},
series = {SAC '12}
}

@article{10.1016/j.future.2021.06.009,
author = {Li, Ying and Fan, Binbin and Zhang, Weiping and Jiang, Zhiqiang},
title = {TireNet: A high recall rate method for practical application of tire defect type classification},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {125},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2021.06.009},
doi = {10.1016/j.future.2021.06.009},
journal = {Future Gener. Comput. Syst.},
month = dec,
pages = {1–9},
numpages = {9},
keywords = {Siamese network, Object detection, Defect detection, Tire X-ray image}
}

@article{10.1145/2020976.2020991,
author = {Malhotra, Ruchika and Jain, Ankita},
title = {Software fault prediction for object oriented systems: a literature review},
year = {2011},
issue_date = {September 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2020976.2020991},
doi = {10.1145/2020976.2020991},
abstract = {There always has been a demand to produce efficient and high quality software. There are various object oriented metrics that measure various properties of the software like coupling, cohesion, inheritance etc. which affect the software to a large extent. These metrics can be used in predicting important quality attributes such as fault proneness, maintainability, effort, productivity and reliability. Early prediction of fault proneness will help us to focus on testing resources and use them only on the classes which are predicted to be fault-prone. Thus, this will help in early phases of software development to give a measurement of quality assessment.This paper provides the review of the previous studies which are related to software metrics and the fault proneness. In other words, it reviews several journals and conference papers on software fault prediction. There is large number of software metrics proposed in the literature. Each study uses a different subset of these metrics and performs the analysis using different datasets. Also, the researchers have used different approaches such as Support vector machines, naive bayes network, random forest, artificial neural network, decision tree, logistic regression etc. Thus, this study focuses on the metrics used, dataset used and the evaluation or analysis method used by various authors. This review will be beneficial for the future studies as various researchers and practitioners can use it for comparative analysis.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–6},
numpages = {6},
keywords = {software quality, object oriented, metrics, fault proneness, empirical validation}
}

@article{10.1016/j.patcog.2008.02.011,
author = {Tsai, Du-Ming and Lai, Shia-Chih},
title = {Defect detection in periodically patterned surfaces using independent component analysis},
year = {2008},
issue_date = {September, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {41},
number = {9},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2008.02.011},
doi = {10.1016/j.patcog.2008.02.011},
abstract = {In this paper, we propose a fast self-comparison scheme for defect detection in structural surfaces containing periodic complicated patterns. It works directly on a one-dimensional line image, instead of a two-dimensional array image, that contains a periodic pattern in the line. The proposed self-comparison scheme is simply carried out by dividing a sensed line image into two segments of equal length. Since the line image contains a periodic pattern, the two divided segments are only translated versions to each other. In this study, an independent component analysis (ICA) model is proposed to obtain the de-mixing matrix that can recover the translation between the two divided segments. The proposed ICA model directly measures the independency of signals by minimizing the difference between the joint probability density function (PDF) and the product of marginal PDFs, in which the PDFs are estimated by relative frequency distributions. The particle swarm optimization (PSO) algorithm is used to search for the de-mixing matrix. The proposed ICA model can effectively separate highly correlated signals, and is well suited for translation recovery between two signals with the same periodic pattern. In the detection stage, each line image is first divided into two segments, and the de-mixing matrix learned off-line from a defect-free line image is used to recover the signals with well aligned translation. The normalized cross-correlation is adopted to measure the similarity between two compared segments. Since the de-mixing matrix is only of a small size of 2x2, the proposed method in the detection stage is very computationally efficient. The performance of the proposed method is demonstrated with test samples of TFT-LCD panels and color filters found in LCD manufacturing. Experimental results have shown that the proposed self-comparison scheme can effectively and efficiently detect the presence of defects in periodically patterned surfaces.},
journal = {Pattern Recogn.},
month = sep,
pages = {2812–2832},
numpages = {21},
keywords = {Patterned surface, Particle swarm optimization, Liquid crystal display, Independent component analysis, Defect detection}
}

@article{10.1016/j.engappai.2008.05.006,
author = {Bu, Hong-gang and Wang, Jun and Huang, Xiu-bao},
title = {Fabric defect detection based on multiple fractal features and support vector data description},
year = {2009},
issue_date = {March, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {22},
number = {2},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2008.05.006},
doi = {10.1016/j.engappai.2008.05.006},
abstract = {Computer-vision-based automatic detection of fabric defects is one of the difficult one-class classification tasks in the real world. To overcome the incapacity of a single fractal feature in dealing with this task, multiple fractal features have been extracted in the light of the theory of and problems present in the box-counting method as well as the inherent characteristics of woven fabrics. Based on statistical learning theory, the up-to-date support vector data description (SVDD) is an excellent approach to the problem of one-class classification. A robust new scheme is presented in this paper for optimally selecting values of the parameters especially that of the scale parameter of the Gaussian kernel function involved in the training of the SVDD model. Satisfactory experimental results are finally achieved by jointly applying the extracted multiple fractal features and SVDD to the detection of defects from several datasets of fabric samples with different texture backgrounds.},
journal = {Eng. Appl. Artif. Intell.},
month = mar,
pages = {224–235},
numpages = {12},
keywords = {Support vector data description, Optimum seeking of parameters, One-class classification, Multiple fractal features, Fabric defect detection}
}

@article{10.1007/s10836-005-2783-7,
author = {Patel, Chintan and Singh, Abhishek and Plusquellic, Jim},
title = {Defect Detection Using Quiescent Signal Analysis},
year = {2005},
issue_date = {October   2005},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {5},
issn = {0923-8174},
url = {https://doi.org/10.1007/s10836-005-2783-7},
doi = {10.1007/s10836-005-2783-7},
abstract = {I   DDQ  or steady state current testing has been extensively used in the industry as a mainstream defect detection and reliability screen. The background leakage current has increased significantly with the advent of ultra deep submicron technologies. This increased background leakage noise makes it difficult to differentiate defect-free devices from those with defects that draw significantly small amount of currents. Therefore it is impossible to use single threshold  I   DDQ  testing for today's technologies. Several techniques that improve the resolution of  I   DDQ  testing have been proposed to replace the single threshold detection scheme. However, even these techniques are suffering from loss of resolution that is required for detection of subtle defects in the presence of leakage currents in excess of a few mA. All these techniques use a single  I   DDQ  measurement for detection and thus the scalability of these techniques is limited. Quiescent Signal Analysis (QSA) is a novel  I   DDQ  defect detection and diagnosis technique that uses  I   DDQ  measurements at multiple chip supply pads. Implicit in our methodology is a leakage calibration technique that scales the total leakage current over multiple simultaneous measurements. This helps in decreasing the background leakage component in individual measurements and thus increases the resolution of this technique to subtle defects. Defect detection is accomplished by applying linear regression analysis to the multiple supply port measurements and using outlier analysis to identify defective devices. The effectiveness of this technique is demonstrated in this paper using simulation experiments on portion of a production power grid. Predicted chip size and leakage values from the International Technology Roadmap for semiconductors (ITRS) are used in these experiments. One of the other major concerns expressed in ITRS is that of significant increase in intra-die process variations. The performance of the proposed technique in presence of such variations is evaluated using three different intra-die process variation distribution models.},
journal = {J. Electron. Test.},
month = oct,
pages = {463–483},
numpages = {21},
keywords = {parametric testing, multiple current measurements, defect-based testing, current testing, Quiescent Signal Analysis, IDDQ}
}

@article{10.1016/j.eswa.2010.10.024,
author = {Catal, Cagatay},
title = {Review: Software fault prediction: A literature review and current trends},
year = {2011},
issue_date = {April, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.10.024},
doi = {10.1016/j.eswa.2010.10.024},
abstract = {Software engineering discipline contains several prediction approaches such as test effort prediction, correction cost prediction, fault prediction, reusability prediction, security prediction, effort prediction, and quality prediction. However, most of these prediction approaches are still in preliminary phase and more research should be conducted to reach robust models. Software fault prediction is the most popular research area in these prediction approaches and recently several research centers started new projects on this area. In this study, we investigated 90 software fault prediction papers published between year 1990 and year 2009 and then we categorized these papers according to the publication year. This paper surveys the software engineering literature on software fault prediction and both machine learning based and statistical based approaches are included in this survey. Papers explained in this article reflect the outline of what was published so far, but naturally this is not a complete review of all the papers published so far. This paper will help researchers to investigate the previous studies from metrics, methods, datasets, performance evaluation metrics, and experimental results perspectives in an easy and effective manner. Furthermore, current trends are introduced and discussed.},
journal = {Expert Syst. Appl.},
month = apr,
pages = {4626–4636},
numpages = {11},
keywords = {Statistical methods, Software quality engineering, Software engineering, Machine learning, Expert systems, Automated fault prediction models}
}

@inproceedings{10.1007/978-3-540-69566-0_21,
author = {Catal, Cagatay and Diri, Banu},
title = {A Fault Prediction Model with Limited Fault Data to Improve Test Process},
year = {2008},
isbn = {9783540695646},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-69566-0_21},
doi = {10.1007/978-3-540-69566-0_21},
abstract = {Software fault prediction models are used to identify the fault-prone software modules and produce reliable software. Performance of a software fault prediction model is correlated with available software metrics and fault data. In some occasions, there may be few software modules having fault data and therefore, prediction models using only labeled data can not provide accurate results. Semi-supervised learning approaches which benefit from unlabeled and labeled data may be applied in this case. In this paper, we propose an artificial immune system based semi-supervised learning approach. Proposed approach uses a recent semi-supervised algorithm called YATSI (Yet Another Two Stage Idea) and in the first stage of YATSI, AIRS (Artificial Immune Recognition Systems) is applied. In addition, AIRS, RF (Random Forests) classifier, AIRS based YATSI, and RF based YATSI are benchmarked. Experimental results showed that while YATSI algorithm improved the performance of AIRS, it diminished the performance of RF for unbalanced datasets. Furthermore, performance of AIRS based YATSI is comparable with RF which is the best machine learning classifier according to some researches.},
booktitle = {Proceedings of the 9th International Conference on Product-Focused Software Process Improvement},
pages = {244–257},
numpages = {14},
keywords = {software fault prediction, artificial immune systems, YATSI, Semi-supervised learning, AIRS},
location = {Monte Porzio Catone, Italy},
series = {PROFES '08}
}

@article{10.1016/j.future.2018.09.053,
author = {Cecchinel, Cyril and Fouquet, Fran\c{c}ois and Mosser, S\'{e}bastien and Collet, Philippe},
title = {Leveraging live machine learning and deep sleep to support a self-adaptive efficient configuration of battery powered sensors},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {92},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2018.09.053},
doi = {10.1016/j.future.2018.09.053},
journal = {Future Gener. Comput. Syst.},
month = mar,
pages = {225–240},
numpages = {16}
}

@article{10.1007/s11219-015-9287-1,
author = {Ryu, Duksan and Jang, Jong-In and Baik, Jongmoon},
title = {A transfer cost-sensitive boosting approach for cross-project defect prediction},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-015-9287-1},
doi = {10.1007/s11219-015-9287-1},
abstract = {Software defect prediction has been regarded as one of the crucial tasks to improve software quality by effectively allocating valuable resources to fault-prone modules. It is necessary to have a sufficient set of historical data for building a predictor. Without a set of sufficient historical data within a company, cross-project defect prediction (CPDP) can be employed where data from other companies are used to build predictors. In such cases, a transfer learning technique, which extracts common knowledge from source projects and transfers it to a target project, can be used to enhance the prediction performance. There exists the class imbalance problem, which causes difficulties for the learner to predict defects. The main impacts of imbalanced data under cross-project settings have not been investigated in depth. We propose a transfer cost-sensitive boosting method that considers both knowledge transfer and class imbalance for CPDP when given a small amount of labeled target data. The proposed approach performs boosting that assigns weights to the training instances with consideration of both distributional characteristics and the class imbalance. Through comparative experiments with the transfer learning and the class imbalance learning techniques, we show that the proposed model provides significantly higher defect detection accuracy while retaining better overall performance. As a result, a combination of transfer learning and class imbalance learning is highly effective for improving the prediction performance under cross-project settings. The proposed approach will help to design an effective prediction model for CPDP. The improved defect prediction performance could help to direct software quality assurance activities and reduce costs. Consequently, the quality of software can be managed effectively.},
journal = {Software Quality Journal},
month = mar,
pages = {235–272},
numpages = {38},
keywords = {Transfer learning, Software defect prediction, Cross-project defect prediction, Cost-sensitive learning, Class imbalance, Boosting}
}

@inproceedings{10.5555/1627368.1627435,
author = {Podgorelec, Vili},
title = {On software fault prediction by mining software complexity data with dynamically filtered training sets},
year = {2009},
isbn = {9789604741137},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {Software fault prediction methods are very appropriate for improving the software reliability. With the creation of large empirical databases of software projects, as a result of stimulated research on estimation models, metrics and methods for measuring and improving processes and products, intelligent mining of these datasets can largely add to the improvement of software reliability. In the paper we present a study on using decision tree classifiers for predicting software faults. A new training set filtering method is presented that should improve the classification performance when mining the software complexity measures data. The classification improvement should be achieved by removing the identified outliers from a training set. We argue that a classifier trained by a filtered dataset captures a more general knowledge model and should therefore perform better also on unseen cases. The proposed method is applied on a real-world software reliability analysis dataset and the obtained results are discussed.},
booktitle = {Proceedings of the 9th WSEAS International Conference on Simulation, Modelling and Optimization},
pages = {332–337},
numpages = {6},
keywords = {software fault prediction, search-based software engineering, filtering training set, complexity metrics, classification},
location = {Budapest, Hungary},
series = {SMO'09}
}

@article{10.1016/j.ins.2013.04.025,
author = {Yan, Aijun and Wang, Weixian and Zhang, Chunxiao and Zhao, Hui},
title = {A fault prediction method that uses improved case-based reasoning to continuously predict the status of a shaft furnace},
year = {2014},
issue_date = {February, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {259},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2013.04.025},
doi = {10.1016/j.ins.2013.04.025},
abstract = {For the problem of predicting faults in the status of a shaft furnace, the missed alarm rate and false alarm rate have not been improved significantly by the traditional case-based reasoning (CBR) method. To predict faults more accurately, an improved CBR-based fault prediction method (ICBRP) is proposed in this paper. This ICBRP is composed of a water-filling theory-based weight allocation (WFA) model and a group decision-making-based revision (GDMR) model. According to the optimal allocation mechanism of channel power, a Lagrange function is designed to calculate the weights. Moreover, the credibility of historical results is used to revise the predicted results via the definition of a group utility function. Then, the proposed reasoning strategy can obtain more reasonable weights and take full advantage of comprehensive information from the retrieval results. Finally, the application results indicate that the proposed method is superior to traditional CBR and other methods. This proposed ICBRP significantly reduces the missed alarm rate and the false alarm rate of failure in the furnace status.},
journal = {Inf. Sci.},
month = feb,
pages = {269–281},
numpages = {13},
keywords = {Shaft furnace status, Group decision-making, Fault prediction, Case-based reasoning}
}

@article{10.1049/iet-sen.2013.0008,
author = {Shatnawi, Raed},
title = {Empirical study of fault prediction for open‐source systems using the Chidamber and Kemerer metrics},
year = {2014},
issue_date = {June 2014},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2013.0008},
doi = {10.1049/iet-sen.2013.0008},
abstract = {Software testers are usually provoked with projects that have faults. Predicting a class's fault‐proneness is vital for minimising cost and improving the effectiveness of the software testing. Previous research on software metrics has shown strong relationships between software metrics and faults in object‐oriented systems using a binary variable. However, these models do not consider the history of faults in classes. In this work, a dependent variable is proposed that uses fault history to rate classes into four categories (none, low risk, medium risk and high risk) and to improve the predictive capability of fault models. The study is conducted on many releases of four open‐source systems. The study tests the statistical differences in seven machine learning algorithms to find whether the proposed variable can be used to build better prediction models. The performance of the classifiers using the four categories is significantly better than the binary variable. In addition, the results show improvements on the reliability of the prediction models as the software matures. Therefore the fault history improves the prediction of fault‐proneness of classes in open‐source systems.},
journal = {IET Software},
month = jun,
pages = {113–119},
numpages = {7},
keywords = {machine learning algorithms, statistical differences, binary variable, object-oriented systems, software metrics, software testing, software testers, Chidamber metrics, Kemerer metrics, open-source systems, fault prediction, software metrics, public domain software, program testing, object-oriented methods, learning (artificial intelligence)}
}

@inproceedings{10.1109/ICTAI.2010.27,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan and Seliya, Naeem},
title = {Attribute Selection and Imbalanced Data: Problems in Software Defect Prediction},
year = {2010},
isbn = {9780769542638},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICTAI.2010.27},
doi = {10.1109/ICTAI.2010.27},
abstract = {The data mining and machine learning community is often faced with two key problems: working with imbalanced data and selecting the best features for machine learning. This paper presents a process involving a feature selection technique for selecting the important attributes and a data sampling technique for addressing class imbalance. The application domain of this study is software engineering, more specifically, software quality prediction using classification models. When using feature selection and data sampling together, different scenarios should be considered. The four possible scenarios are: (1) feature selection based on original data, and modeling (defect prediction) based on original data; (2) feature selection based on original data, and modeling based on sampled data; (3) feature selection based on sampled data, and modeling based on original data; and (4) feature selection based on sampled data, and modeling based on sampled data. The research objective is to compare the software defect prediction performances of models based on the four scenarios. The case study consists of nine software measurement data sets obtained from the PROMISE software project repository. Empirical results suggest that feature selection based on sampled data performs significantly better than feature selection based on original data, and that defect prediction models perform similarly regardless of whether the training data was formed using sampled or original data.},
booktitle = {Proceedings of the 2010 22nd IEEE International Conference on Tools with Artificial Intelligence - Volume 01},
pages = {137–144},
numpages = {8},
keywords = {software measurements, feature selection, defect prediction, data sampling},
series = {ICTAI '10}
}

@article{10.1016/j.eswa.2010.11.046,
author = {Liu, Yi-Hung and Liu, Yan-Chen and Chen, Yen-Zen},
title = {High-speed inline defect detection for TFT-LCD array process using a novel support vector data description},
year = {2011},
issue_date = {May, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {5},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.11.046},
doi = {10.1016/j.eswa.2010.11.046},
abstract = {Research highlights Traditional defect inspection for TFT-LCD is based on sampling inspection, mainly due to the fact that the throughput of TFT-LCD panels is huge, while the inspection speed is slow. In this paper, an automatic inspection scheme which can achieve the goal of full inspection is proposed. To achieve the goal of full inspection, a variant of the well-known one-class classifier SVDD (support vector data description) is proposed. This variant greatly improves the classification speed of SVDD, thus called fast SVDD (F-SVDD). The proposed F-SVDD is a general one-class classifier. Therefore, although the F-SVDD is tested on the TFT-LCD inspection in this paper, it can be implemented in other applications related to novelty detection. In the proposed F-SVDD, a novel preimage-finding method is also presented. This method can be applied to reduce the computational complexities of other classifiers such as support vector machines (SVMs). TFT array process is a critical fabrication process for thin film transistor liquid crystal display (TFT-LCD) manufacturing, and defect detection plays an important role in yield improvement for this process. Due to the diversity of defect modes and their occurrence frequencies, the true distribution of the defective patterns is difficult to obtain. On the contrary, normal patterns are easy to collect and they involve only small variations in uniformity. Hence, one-class classification is an appropriate strategy for the LCD inline defect inspection. Accordingly, as a defect detector, the one-class classifier, support vector data description (SVDD), is a good candidate due to its satisfactory results in many one-class classification problems. However, SVDD has the drawback that its testing complexity is linear in the number of training patterns, which makes SVDD unable to provide a fast-enough classification speed. This is problematic because, although SVDD is accurate in defect detection task, it is difficult to implement for real-time tasks, especially when a full inspection (every LCD panel will be inspected) is required. To address this critical issue, in this paper we propose a novel SVDD, called fast SVDD (F-SVDD). The proposed F-SVDD not only inherits the merit of the traditional SVDD, which can obtain a compact description for a target set, but also can provide a much faster classification speed because its testing complexity is independent of the number of training patterns. Experimental results, carried out on real surface images of LCD panels, indicate that the F-SVDD is able to obtain a high defect detection rate of over 95%. More importantly, compared with the traditional SVDD, the proposed F-SVDD is able to accomplish the inline defect detection task with a relatively faster speed: SVDD needs to spend 30.17min inspecting each LCD panel, while the same task can be done within 0.13min (only 7.8s) by F-SVDD.},
journal = {Expert Syst. Appl.},
month = may,
pages = {6222–6231},
numpages = {10},
keywords = {Thin film transistor liquid crystal display (TFT-LCD), TFT array process, Support vector data description (SVDD), Full inspection, Defect inspection}
}

@inproceedings{10.1007/11867661_71,
author = {Castilho, Hugo Peres and Pinto, Jo\~{a}o Rog\'{e}rio Caldas and Serafim, Ant\'{o}nio Limas},
title = {NN automated defect detection based on optimized thresholding},
year = {2006},
isbn = {3540448942},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11867661_71},
doi = {10.1007/11867661_71},
abstract = {This paper presents a new contribution for the problem of automatic visual inspection. New methods for determining threshold values for fabric defect detection using feedforward neural networks are proposed. Neural networks are one of the fastest most flexible classification systems in use. Their implementation in defect detection, where a clear classification is needed, requires thresholding the output. Two methods are proposed for threshold selection, statistical analysis of the NN output and confusion matrix based optimization. Experimental results obtained from the real fabric defects, for the two approaches proposed in this paper, have confirmed their usefulness.},
booktitle = {Proceedings of the Third International Conference on Image Analysis and Recognition - Volume Part II},
pages = {790–801},
numpages = {12},
location = {P\'{o}voa de Varzim, Portugal},
series = {ICIAR'06}
}

@article{10.1016/j.ins.2008.12.001,
author = {Catal, Cagatay and Diri, Banu},
title = {Investigating the effect of dataset size, metrics sets, and feature selection techniques on software fault prediction problem},
year = {2009},
issue_date = {March, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {179},
number = {8},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2008.12.001},
doi = {10.1016/j.ins.2008.12.001},
abstract = {Software quality engineering comprises of several quality assurance activities such as testing, formal verification, inspection, fault tolerance, and software fault prediction. Until now, many researchers developed and validated several fault prediction models by using machine learning and statistical techniques. There have been used different kinds of software metrics and diverse feature reduction techniques in order to improve the models' performance. However, these studies did not investigate the effect of dataset size, metrics set, and feature selection techniques for software fault prediction. This study is focused on the high-performance fault predictors based on machine learning such as Random Forests and the algorithms based on a new computational intelligence approach called Artificial Immune Systems. We used public NASA datasets from the PROMISE repository to make our predictive models repeatable, refutable, and verifiable. The research questions were based on the effects of dataset size, metrics set, and feature selection techniques. In order to answer these questions, there were defined seven test groups. Additionally, nine classifiers were examined for each of the five public NASA datasets. According to this study, Random Forests provides the best prediction performance for large datasets and Naive Bayes is the best prediction algorithm for small datasets in terms of the Area Under Receiver Operating Characteristics Curve (AUC) evaluation parameter. The parallel implementation of Artificial Immune Recognition Systems (AIRS2Parallel) algorithm is the best Artificial Immune Systems paradigm-based algorithm when the method-level metrics are used.},
journal = {Inf. Sci.},
month = mar,
pages = {1040–1058},
numpages = {19},
keywords = {Software fault prediction, Random Forests, Naive Bayes, Machine learning, J48, Artificial Immune Systems}
}

@article{10.1016/j.imavis.2007.10.007,
author = {Lu, Chi-Jie and Tsai, Du-Ming},
title = {Independent component analysis-based defect detection in patterned liquid crystal display surfaces},
year = {2008},
issue_date = {July, 2008},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {26},
number = {7},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2007.10.007},
doi = {10.1016/j.imavis.2007.10.007},
abstract = {In this paper, we propose a machine vision approach for automatic detection of micro defects in periodically patterned surfaces and, especially, aim at thin film transistor liquid crystal display (TFT-LCD) panels. The proposed method is based on an image reconstruction scheme using independent component analysis (ICA). ICA is first applied to a faultless training image to determine the de-mixing matrix and the corresponding independent components (ICs). The ICs representing the global structure of the training image are then identified and the associated row vectors of those ICs in the de-mixing matrix are replaced with a de-mixing row representing the least structured region of the training image. The reformed de-mixing matrix is then used to reconstruct the TFT-LCD image under inspection. The resulting image can effectively remove the global structural pattern and preserve only local anomalies. A number of micro defects in different TFT-LCD panel surfaces are evaluated with the proposed method. The experiments show that the proposed method can well detect various ill-defined defects in periodically patterned surfaces.},
journal = {Image Vision Comput.},
month = jul,
pages = {955–970},
numpages = {16},
keywords = {TFT-LCD panels, Surface inspection, Independent component analysis, Defect detection}
}

@article{10.1016/j.jss.2009.06.055,
author = {Arisholm, Erik and Briand, Lionel C. and Johannessen, Eivind B.},
title = {A systematic and comprehensive investigation of methods to build and evaluate fault prediction models},
year = {2010},
issue_date = {January, 2010},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {83},
number = {1},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.06.055},
doi = {10.1016/j.jss.2009.06.055},
abstract = {This paper describes a study performed in an industrial setting that attempts to build predictive models to identify parts of a Java system with a high fault probability. The system under consideration is constantly evolving as several releases a year are shipped to customers. Developers usually have limited resources for their testing and would like to devote extra resources to faulty system parts. The main research focus of this paper is to systematically assess three aspects on how to build and evaluate fault-proneness models in the context of this large Java legacy system development project: (1) compare many data mining and machine learning techniques to build fault-proneness models, (2) assess the impact of using different metric sets such as source code structural measures and change/fault history (process measures), and (3) compare several alternative ways of assessing the performance of the models, in terms of (i) confusion matrix criteria such as accuracy and precision/recall, (ii) ranking ability, using the receiver operating characteristic area (ROC), and (iii) our proposed cost-effectiveness measure (CE). The results of the study indicate that the choice of fault-proneness modeling technique has limited impact on the resulting classification accuracy or cost-effectiveness. There is however large differences between the individual metric sets in terms of cost-effectiveness, and although the process measures are among the most expensive ones to collect, including them as candidate measures significantly improves the prediction models compared with models that only include structural measures and/or their deltas between releases - both in terms of ROC area and in terms of CE. Further, we observe that what is considered the best model is highly dependent on the criteria that are used to evaluate and compare the models. And the regular confusion matrix criteria, although popular, are not clearly related to the problem at hand, namely the cost-effectiveness of using fault-proneness prediction models to focus verification efforts to deliver software with less faults at less cost.},
journal = {J. Syst. Softw.},
month = jan,
pages = {2–17},
numpages = {16},
keywords = {Verification, Fault prediction models, Cost-effectiveness}
}

@inproceedings{10.5555/2666527.2666533,
author = {Morgado, In\^{e}s Coimbra and Paiva, Ana C. R. and Faria, Jo\~{a}o Pascoal and Camacho, Rui},
title = {GUI reverse engineering with machine learning},
year = {2012},
isbn = {9781467317535},
publisher = {IEEE Press},
abstract = {This paper proposes a new approach to reduce the effort of building formal models representative of the structure and behaviour of Graphical User Interfaces (GUI). The main goal is to automatically extract the GUI model with a dynamic reverse engineering process, consisting in an exploration phase, that extracts information by interacting with the GUI, and in a model generation phase that, making use of machine learning techniques, uses the extracted information of the first step to generate a state-machine model of the GUI, including guard conditions to remove ambiguity in transitions.},
booktitle = {Proceedings of the First International Workshop on Realizing AI Synergies in Software Engineering},
pages = {27–31},
numpages = {5},
keywords = {reverse engineering, model-based testing, machine learning, inductive logic programming},
location = {Zurich, Switzerland},
series = {RAISE '12}
}

@article{10.1016/S0167-8655(03)00106-5,
author = {Tsai, Du-Ming and Lin, Chien-Ta},
title = {Fast normalized cross correlation for defect detection},
year = {2003},
issue_date = {November 2003},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {24},
number = {15},
issn = {0167-8655},
url = {https://doi.org/10.1016/S0167-8655(03)00106-5},
doi = {10.1016/S0167-8655(03)00106-5},
abstract = {Normalized cross correlation (NCC) has been used extensively for many machine vision applications, but the traditional normalized correlation operation does not meet speed requirements for time-critical applications. In this paper, we propose a fast NCC computation for defect detection. A sum-table scheme is utilized, which allows the calculations of image mean, image variance and cross-correlation between images to be invariant to the size of template window. For an image of size M \texttimes{} N and a template window of size m \texttimes{} n, the computational complexity of the traditional NCC involves 3 undefined m undefined n undefined M undefined N additions/subtractions and 2 undefined m undefined n undefined M undefined N multiplications. The required numbers of computations of the proposed sum-table scheme can be significantly reduced to only 18 undefined M undefined N additions/subtractions and 2 undefined M undefined N multiplications.},
journal = {Pattern Recogn. Lett.},
month = nov,
pages = {2625–2631},
numpages = {7},
keywords = {sum tables, normalized cross correlation, defect detection}
}

@article{10.1016/j.eswa.2010.04.082,
author = {Valavanis, Ioannis and Kosmopoulos, Dimitrios},
title = {Multiclass defect detection and classification in weld radiographic images using geometric and texture features},
year = {2010},
issue_date = {December, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {12},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.04.082},
doi = {10.1016/j.eswa.2010.04.082},
abstract = {In this paper, a method for the detection and classification of defects in weld radiographs is presented. The method has been applied for detecting and discriminating discontinuities in the weld images that may correspond to false alarms or defects such as worm holes, porosity, linear slag inclusion, gas pores, lack of fusion or crack. A set of 43 descriptors corresponding to texture measurements and geometrical features is extracted for each segmented object and given as input to a classifier. The classifier is trained to classify each of the objects it into one of the defect classes or characterize it as non-defect. Three fold cross validation was utilized and experimental results are reported for three different classifiers (Support Vector Machine, Neural Network, k-NN).},
journal = {Expert Syst. Appl.},
month = dec,
pages = {7606–7614},
numpages = {9},
keywords = {Welds, Texture, Segmentation, Radiography, Geometrical features, Defects, Classification}
}

@inproceedings{10.1109/SMC.2013.282,
author = {Chandrashekar, Girish and Sahin, Ferat and Cinar, Eyup and Radomski, Aaron and Sarosky, Dan},
title = {In-Vivo Fault Analysis and Real-Time Fault Prediction for RF Generators Using State-of-the-Art Classifiers},
year = {2013},
isbn = {9781479906529},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SMC.2013.282},
doi = {10.1109/SMC.2013.282},
abstract = {In this paper we apply various machine learning techniques for fault detection of RF (Radio Frequency) Power Generators. Fast Fourier Transform features are used in our analysis for all experiments. Radial Basis Function Networks (RBF) is used to build a two class classifier to differentiate between normal and one fault condition. We apply three one class classifiers to model the normal operating conditions. The data is obtained from five different generators of the same model type.},
booktitle = {Proceedings of the 2013 IEEE International Conference on Systems, Man, and Cybernetics},
pages = {1634–1639},
numpages = {6},
keywords = {Radial Basis Functions, RF generators, One class classification, Novelty detection, Fault analysis},
series = {SMC '13}
}

@article{10.1016/j.engappai.2013.01.008,
author = {Rafael Lenz, Alexandre and Pozo, Aurora and Regina Vergilio, Silvia},
title = {Linking software testing results with a machine learning approach},
year = {2013},
issue_date = {May, 2013},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {26},
number = {5–6},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2013.01.008},
doi = {10.1016/j.engappai.2013.01.008},
abstract = {Software testing techniques and criteria are considered complementary since they can reveal different kinds of faults and test distinct aspects of the program. The functional criteria, such as Category Partition, are difficult to be automated and are usually manually applied. Structural and fault-based criteria generally provide measures to evaluate test sets. The existing supporting tools produce a lot of information including: input and produced output, structural coverage, mutation score, faults revealed, etc. However, such information is not linked to functional aspects of the software. In this work, we present an approach based on machine learning techniques to link test results from the application of different testing techniques. The approach groups test data into similar functional clusters. After this, according to the tester's goals, it generates classifiers (rules) that have different uses, including selection and prioritization of test cases. The paper also presents results from experimental evaluations and illustrates such uses.},
journal = {Eng. Appl. Artif. Intell.},
month = may,
pages = {1631–1640},
numpages = {10},
keywords = {Test coverage criteria, Software testing, Machine learning}
}

@article{10.1145/2556777,
author = {Zhou, Yuming and Xu, Baowen and Leung, Hareton and Chen, Lin},
title = {An in-depth study of the potentially confounding effect of class size in fault prediction},
year = {2014},
issue_date = {February 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/2556777},
doi = {10.1145/2556777},
abstract = {Background. The extent of the potentially confounding effect of class size in the fault prediction context is not clear, nor is the method to remove the potentially confounding effect, or the influence of this removal on the performance of fault-proneness prediction models. Objective. We aim to provide an in-depth understanding of the effect of class size on the true associations between object-oriented metrics and fault-proneness. Method. We first employ statistical methods to examine the extent of the potentially confounding effect of class size in the fault prediction context. After that, we propose a linear regression-based method to remove the potentially confounding effect. Finally, we empirically investigate whether this removal could improve the prediction performance of fault-proneness prediction models. Results. Based on open-source software systems, we found: (a) the confounding effect of class size on the associations between object-oriented metrics and fault-proneness in general exists; (b) the proposed linear regression-based method can effectively remove the confounding effect; and (c) after removing the confounding effect, the prediction performance of fault prediction models with respect to both ranking and classification can in general be significantly improved. Conclusion. We should remove the confounding effect of class size when building fault prediction models.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {10},
numpages = {51},
keywords = {prediction, fault, confounding effect, class size, Metrics}
}

@article{10.1504/ijict.2021.117532,
author = {Wang, Hui and Gao, Chunhua and Ling, Yongfa},
title = {A deep learning-based method for aluminium foil-surface defect recognition},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {19},
number = {3},
issn = {1466-6642},
url = {https://doi.org/10.1504/ijict.2021.117532},
doi = {10.1504/ijict.2021.117532},
abstract = {In order to effectively detect and classify various defects on the surface of aluminium foil products, including contaminants, coining, shine marks and scratches, etc., the method of convolution neural network (CNN) is used and the detection of surface defects of aluminium product is realised by machine learning. Firstly, aluminium foil images are collected by CCD camera, and edge detection is performed on these images to obtain a complete picture area. Then, the robust principal component analysis (RPCA) method was used to perform underlying low-rank and sparse decomposition on the data matrix to obtain the defect areas in these images; Finally, using TensorFlow platform to build a CNN model, loading aluminium foil images and training to get the CNN model parameters, according to this CNN network model, the surface defects of aluminium foil images can be detected and classified in real-time. Numerical experiments verified that the proposed algorithm has the following advantages such as high accuracy, favourable expansibility and so on. It can also be easily applied into surface defect detection for other objects.},
journal = {Int. J. Inf. Commun. Techol.},
month = jan,
pages = {231–241},
numpages = {10},
keywords = {aluminium foil image, TensorFlow, deep learning, CNN, convolution neural network, defect detection}
}

@article{10.34768/amcs-2021-0035,
author = {Oz, Muhammed Ali Nur and Kaymakci, Ozgur Turay and Mercimek, Muharrem},
title = {A Nested Autoencoder Approach to Automated Defect Inspection on Textured Surfaces},
year = {2021},
issue_date = {Sep 2021},
publisher = {Walter de Gruyter &amp; Co.},
address = {USA},
volume = {31},
number = {3},
issn = {1641-876X},
url = {https://doi.org/10.34768/amcs-2021-0035},
doi = {10.34768/amcs-2021-0035},
abstract = {In recent years, there has been a highly competitive pressure on industrial production. To keep ahead of the competition, emerging technologies must be developed and incorporated. Automated visual inspection systems, which improve the overall mass production quantity and quality in lines, are crucial. The modifications of the inspection system involve excessive time and money costs. Therefore, these systems should be flexible in terms of fulfilling the changing requirements of high capacity production support. A coherent defect detection model as a primary application to be used in a real-time intelligent visual surface inspection system is proposed in this paper. The method utilizes a new approach consisting of nested autoencoders trained with defect-free and defect injected samples to detect defects. Making use of two nested autoencoders, the proposed approach shows great performance in eliminating defects. The first autoencoder is used essentially for feature extraction and reconstructing the image from these features. The second one is employed to identify and fix defects in the feature code. Defects are detected by thresholding the difference between decoded feature code outputs of the first and the second autoencoder. The proposed model has a 96% detection rate and a relatively good segmentation performance while being able to inspect fabrics driven at high speeds.},
journal = {Int. J. Appl. Math. Comput. Sci.},
month = sep,
pages = {515–523},
numpages = {9},
keywords = {deep learning, automatic visual inspection, defect detection, autoencoders}
}

@inproceedings{10.1145/1370788.1370792,
author = {Weyuker, Elaine J. and Ostrand, Thomas J. and Bell, Robert M.},
title = {Comparing negative binomial and recursive partitioning models for fault prediction},
year = {2008},
isbn = {9781605580364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370788.1370792},
doi = {10.1145/1370788.1370792},
abstract = {Two different software fault prediction models have been used to predict the N% of the files of a large software system that are likely to contain the largest numbers of faults. We used the same predictor variables in a negative binomial regression model and a recursive partitioning model, and compared their effectiveness on three large industrial software systems. The negative binomial model identified files that contain 76 to 93 percent of the faults, and recursive partitioning identified files that contain 68 to 85 percent.},
booktitle = {Proceedings of the 4th International Workshop on Predictor Models in Software Engineering},
pages = {3–10},
numpages = {8},
keywords = {empirical study, fault prediction, negative binomial, recursive partition, software testing},
location = {Leipzig, Germany},
series = {PROMISE '08}
}

@article{10.1007/s10664-011-9165-9,
author = {Shin, Yonghee and Bell, Robert M. and Ostrand, Thomas J. and Weyuker, Elaine J.},
title = {On the use of calling structure information to improve fault prediction},
year = {2012},
issue_date = {August    2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4–5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-011-9165-9},
doi = {10.1007/s10664-011-9165-9},
abstract = {Previous studies have shown that software code attributes, such as lines of source code, and history information, such as the number of code changes and the number of faults in prior releases of software, are useful for predicting where faults will occur. In this study of two large industrial software systems, we investigate the effectiveness of adding information about calling structure to fault prediction models. Adding calling structure information to a model based solely on non-calling structure code attributes modestly improved prediction accuracy. However, the addition of calling structure information to a model that included both history and non-calling structure code attributes produced no improvement.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {390–423},
numpages = {34},
keywords = {Software faults, Negative binomial model, Empirical study, Calling structure attributes}
}

@inproceedings{10.1109/ISSRE.2008.54,
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
title = {Cost Curve Evaluation of Fault Prediction Models},
year = {2008},
isbn = {9780769534053},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2008.54},
doi = {10.1109/ISSRE.2008.54},
abstract = {Prediction of fault prone software components is one of the most researched problems in software engineering. Many statistical techniques have been proposed but there is no consensus on the methodology to select the "best model" for the specific project. In this paper, we introduce and discuss the merits of cost curve analysis of fault prediction models. Cost curves allow software quality engineers to introduce project-specific cost of module misclassification into model evaluation. Classifying a software module as fault-prone implies the application of some verification activities, thus adding to the development cost. Misclassifying a module as fault free carries the risk of system failure, also associated with cost implications. Through the analysis of sixteen projects from public repositories, we observe that software quality does not necessarily benefit from the prediction of fault prone components. The inclusion of misclassification cost in model evaluation may indicate that even the "best" models achieve performance no better than trivial classification. Our results support a recommendation to adopt cost curves as one of the standard methods for software quality model performance evaluation.},
booktitle = {Proceedings of the 2008 19th International Symposium on Software Reliability Engineering},
pages = {197–206},
numpages = {10},
keywords = {software quality, verification and validation, machine learning, classification},
series = {ISSRE '08}
}

@article{10.1007/s10489-011-0316-x,
author = {Chatterjee, S. and Nigam, S. and Singh, J. B. and Upadhyaya, L. N.},
title = {Software fault prediction using Nonlinear Autoregressive with eXogenous Inputs (NARX) network},
year = {2012},
issue_date = {July      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {37},
number = {1},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-011-0316-x},
doi = {10.1007/s10489-011-0316-x},
abstract = {This paper explores a new approach for predicting software faults by means of NARX neural network. Also, a careful analysis has been carried out to determine the applicability of NARX network in software reliability. The validation of the proposed approach has been performed using two real software failure data sets. Comparison has been made with some existing parametric software reliability models as well as some neural network (Elman net and TDNN) based SRGM. The results computed shows that the proposed approach outperformed the other existing parametric and neural network based software reliability models with a reasonably good predictive accuracy.},
journal = {Applied Intelligence},
month = jul,
pages = {121–129},
numpages = {9},
keywords = {Time between failures, Software reliability, NARX neural network, Faults}
}

@article{10.1007/s10664-009-9111-2,
author = {Weyuker, Elaine J. and Ostrand, Thomas J. and Bell, Robert M.},
title = {Comparing the effectiveness of several modeling methods for fault prediction},
year = {2010},
issue_date = {June      2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-009-9111-2},
doi = {10.1007/s10664-009-9111-2},
abstract = {We compare the effectiveness of four modeling methods--negative binomial regression, recursive partitioning, random forests and Bayesian additive regression trees--for predicting the files likely to contain the most faults for 28 to 35 releases of three large industrial software systems. Predictor variables included lines of code, file age, faults in the previous release, changes in the previous two releases, and programming language. To compare the effectiveness of the different models, we use two metrics--the percent of faults contained in the top 20% of files identified by the model, and a new, more general metric, the fault-percentile-average. The negative binomial regression and random forests models performed significantly better than recursive partitioning and Bayesian additive regression trees, as assessed by either of the metrics. For each of the three systems, the negative binomial and random forests models identified 20% of the files in each release that contained an average of 76% to 94% of the faults.},
journal = {Empirical Softw. Engg.},
month = jun,
pages = {277–295},
numpages = {19},
keywords = {Recursive partitioning, Random forests, Negative binomial, Fault-percentile-average, Fault prediction, Empirical study, Bayesian trees}
}

@article{10.1504/IJCAT.2014.060527,
author = {Priya, R. and Aruna, P.},
title = {Automated diagnosis of age-related macular degeneration using machine learning techniques},
year = {2014},
issue_date = {April 2014},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {49},
number = {2},
issn = {0952-8091},
url = {https://doi.org/10.1504/IJCAT.2014.060527},
doi = {10.1504/IJCAT.2014.060527},
abstract = {Age-related macular ARM degeneration is an eye disease, that gradually degrades the macula, a part of the retina, which is responsible for central vision. It occurs in one of the two types, dry and wet age-related macular degeneration. The purpose of this paper is to diagnose the retinal disease age-related macular degeneration. An automated approach is proposed to help in the early detection of age-related macular degeneration using three models and their performances are compared. The amount of the disease spread in the retina can be identified by extracting the features of the retina. Detection of age-related macular degeneration disease has been done using probabilistic neural network PNN, Bayesian classification and support vector machine SVM and the two types of age-related macular degeneration are classified and diagnosed successfully. The results show that SVM achieves a higher performance measure than probabilistic neural network and Bayes classification.},
journal = {Int. J. Comput. Appl. Technol.},
month = apr,
pages = {157–165},
numpages = {9}
}

@article{10.1016/j.patcog.2005.02.004,
author = {Rohrmus, D. R.},
title = {Invariant and adaptive geometrical texture features for defect detection and classification},
year = {2005},
issue_date = {October, 2005},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {38},
number = {10},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2005.02.004},
doi = {10.1016/j.patcog.2005.02.004},
abstract = {Automatic texture defect detection is highly important for many fields of visual inspection. We introduce novel, geometrical texture features for this task, which are Euclidean motion invariant and texture adaptive: An algebraic function (rational, Pade, or polynomial) is integrated over intensities in local, circular neighborhoods on the image including an anisotropical texture analysis. Adaptiveness is achieved through the optimization of this feature kernel and further coefficients based on a simplex energy minimization, constrained by a measure of texture discrimination (Fisher criterion). A backpropagation trained, multilayer perceptron network classifies the textures locally. Our approach contains new properties, usually not common in feature theories: Theoretically implicit, multiple invariances and an automatic and specific adaptation of the features to the texture images. Experiments with a fabric data set and Brodatz textures reveal up to 98.6% recognition accuracy.},
journal = {Pattern Recogn.},
month = oct,
pages = {1546–1559},
numpages = {14},
keywords = {Texture defect detection, Texture adaptive features, Surface inspection, Simplex feature optimization, Rotation/translation invariance, Rational- and Pad\'{e}-based features, Multilayer perceptron network, Multi-texture classification, Geometrical texture features, Fisher criterion discrimination}
}

@article{10.1016/j.jss.2007.07.034,
author = {Vandecruys, Olivier and Martens, David and Baesens, Bart and Mues, Christophe and De Backer, Manu and Haesen, Raf},
title = {Mining software repositories for comprehensible software fault prediction models},
year = {2008},
issue_date = {May, 2008},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {81},
number = {5},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2007.07.034},
doi = {10.1016/j.jss.2007.07.034},
abstract = {Software managers are routinely confronted with software projects that contain errors or inconsistencies and exceed budget and time limits. By mining software repositories with comprehensible data mining techniques, predictive models can be induced that offer software managers the insights they need to tackle these quality and budgeting problems in an efficient way. This paper deals with the role that the Ant Colony Optimization (ACO)-based classification technique AntMiner+ can play as a comprehensible data mining technique to predict erroneous software modules. In an empirical comparison on three real-world public datasets, the rule-based models produced by AntMiner+ are shown to achieve a predictive accuracy that is competitive to that of the models induced by several other included classification techniques, such as C4.5, logistic regression and support vector machines. In addition, we will argue that the intuitiveness and comprehensibility of the AntMiner+ models can be considered superior to the latter models.},
journal = {J. Syst. Softw.},
month = may,
pages = {823–839},
numpages = {17},
keywords = {Software mining, Fault prediction, Comprehensibility, Classification, Ant Colony Optimization}
}

@article{10.1016/j.eswa.2006.07.011,
author = {Huang, Chenn-Jung},
title = {Clustered defect detection of high quality chips using self-supervised multilayer perceptron},
year = {2007},
issue_date = {Nov 2007},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {33},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2006.07.011},
doi = {10.1016/j.eswa.2006.07.011},
journal = {Expert Syst. Appl.},
month = nov,
pages = {996–1003},
numpages = {8},
keywords = {Defect detection, Median filter, Nearest neighbor, Clustering, Neural networks, Probing, Multilayer perceptron}
}

@article{10.1016/j.eswa.2011.03.041,
author = {Afzal, Wasif and Torkar, Richard},
title = {Review: On the application of genetic programming for software engineering predictive modeling: A systematic review},
year = {2011},
issue_date = {September, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {9},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2011.03.041},
doi = {10.1016/j.eswa.2011.03.041},
abstract = {The objective of this paper is to investigate the evidence for symbolic regression using genetic programming (GP) being an effective method for prediction and estimation in software engineering, when compared with regression/machine learning models and other comparison groups (including comparisons with different improvements over the standard GP algorithm). We performed a systematic review of literature that compared genetic programming models with comparative techniques based on different independent project variables. A total of 23 primary studies were obtained after searching different information sources in the time span 1995-2008. The results of the review show that symbolic regression using genetic programming has been applied in three domains within software engineering predictive modeling: (i) Software quality classification (eight primary studies). (ii) Software cost/effort/size estimation (seven primary studies). (iii) Software fault prediction/software reliability growth modeling (eight primary studies). While there is evidence in support of using genetic programming for software quality classification, software fault prediction and software reliability growth modeling; the results are inconclusive for software cost/effort/size estimation.},
journal = {Expert Syst. Appl.},
month = sep,
pages = {11984–11997},
numpages = {14},
keywords = {Systematic review, Symbolic regression, Modeling, Genetic programming}
}

@article{10.1016/j.imavis.2011.02.002,
author = {Ngan, Henry Y. T. and Pang, Grantham K. H. and Yung, Nelson H. C.},
title = {Review article: Automated fabric defect detection-A review},
year = {2011},
issue_date = {June, 2011},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {29},
number = {7},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2011.02.002},
doi = {10.1016/j.imavis.2011.02.002},
abstract = {This paper provides a review of automated fabric defect detection methods developed in recent years. Fabric defect detection, as a popular topic in automation, is a necessary and essential step of quality control in the textile manufacturing industry. In categorizing these methods broadly, a major group is regarded as non-motif-based while a minor group is treated as motif-based. Non-motif-based approaches are conventional, whereas the motif-based approach is novel in utilizing motif as a basic manipulation unit. Compared with previously published review papers on fabric inspection, this paper firstly offers an up-to-date survey of different defect detection methods and describes their characteristics, strengths and weaknesses. Secondly, it employs a wider classification of methods and divides them into seven approaches (statistical, spectral, model-based, learning, structural, hybrid, and motif-based) and performs a comparative study across these methods. Thirdly, it also presents a qualitative analysis accompanied by results, including detection success rate for every method it has reviewed. Lastly, insights, synergy and future research directions are discussed. This paper shall benefit researchers and practitioners alike in image processing and computer vision fields in understanding the characteristics of the different defect detection approaches.},
journal = {Image Vision Comput.},
month = jun,
pages = {442–458},
numpages = {17},
keywords = {Textile, Quality control, Motif-based, Manufacturing, Fabric defect detection, Automation}
}

@article{10.1016/S0167-8655(03)00098-9,
author = {Tsai, Du-Ming and Lin, Chien-Ta and Chen, Jeng-Fung},
title = {The evaluation of normalized cross correlations for defect detection},
year = {2003},
issue_date = {November 2003},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {24},
number = {15},
issn = {0167-8655},
url = {https://doi.org/10.1016/S0167-8655(03)00098-9},
doi = {10.1016/S0167-8655(03)00098-9},
abstract = {The normalized cross correlation (NCC) has been used extensively in machine vision for industrial inspection, but the traditional NCC suffers from false alarms for a complicated image that contains partial uniform regions. In this paper, we study the use of NCCs for defect detection in complicated images. The performance of NCCs in monochrome and color images, and the effect of image smoothing are empirically evaluated. The proposed NCC in a smoothed color image can effectively alleviate false alarms in defect detection applications.},
journal = {Pattern Recogn. Lett.},
month = nov,
pages = {2525–2535},
numpages = {11},
keywords = {smoothing, normalized cross correlation, defect detection, color images}
}

@article{10.1016/j.asoc.2016.10.040,
author = {Layouni, Mohamed and Hamdi, Mohamed Salah and Tahar, Sofine},
title = {Detection and sizing of metal-loss defects in oil and gas pipelines using pattern-adapted wavelets and machine learning},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {52},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.10.040},
doi = {10.1016/j.asoc.2016.10.040},
abstract = {Graphical abstractDisplay Omitted HighlightsOil and gas pipelines are subject to many types of metal-loss defects.Those defects can pose a high risk to the operational safety of the pipeline.This paper proposes a solution to detect, locate, and estimate the size of defects.The proposed solution uses pattern-adapted wavelets and artificial neural networks.The proposed solution is general and applies to a wide range of defect shapes. Signals collected from the magnetic scans of metal-loss defects have distinct patterns. Experienced pipeline engineers are able to recognize those patterns in magnetic flux leakage (MFL) scans of pipelines, and use them to characterize defect types (e.g., corrosion, cracks, dents, etc.) and estimate their lengths and depths. This task, however, can be highly cumbersome to a human operator, because of the large amount of data to be analyzed. This paper proposes a solution to automate the analysis of MFL signals. The proposed solution uses pattern-adapted wavelets to detect and estimate the length of metal-loss defects. Once the parts of MFL signals corresponding to metal-loss defects are isolated, artificial neural networks are used to predict their depth. The proposed technique is computationally efficient, achieves high levels of accuracy, and works for a wide range of defect shapes.},
journal = {Appl. Soft Comput.},
month = mar,
pages = {247–261},
numpages = {15},
keywords = {Safety assessment, Pattern-adapted wavelets, Pattern recognition, Oil and gas pipelines, Neural networks, Magnetic flux leakage, Machine learning, Defect sizing, Defect location}
}

@article{10.3233/JIFS-169571,
author = {Kostopoulos, G. and Livieris, I.E. and Kotsiantis, S. and Tampakas, V. and Patnaik, Srikanta},
title = {CST-Voting: A semi-supervised ensemble method for classification problems},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {35},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-169571},
doi = {10.3233/JIFS-169571},
abstract = {Semi-supervised learning is an emerging subfield of machine learning, with a view to building efficient classifiers exploiting a limited pool of labeled data together with a large pool of unlabeled ones. Most of the studies regarding semi-supervised learning deal with classification problems, whose goal is to learn a function that maps an unlabeled instance into a finite number of classes. In this paper, a new semi-supervised classification algorithm, which is based on a voting methodology, is proposed. The term attributed to this ensemble method is called CST-Voting. Ensemble methods have been effectively applied in various scientific fields and often perform better than the individual classifiers from which they are originated. The efficiency of the proposed algorithm is compared to three familiar semi-supervised learning methods on a plethora of benchmark datasets using three representative supervised classifiers as base learners. Experimental results demonstrate the predominance of the proposed method, outperforming classical semi-supervised classification algorithms as illustrated from the accuracy measurements and confirmed by the Friedman Aligned Ranks nonparametric test.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {99–109},
numpages = {11},
keywords = {accuracy, ensemble methods, voting, classification, Semi-supervised learning}
}

@inproceedings{10.1109/MICAI.2008.38,
author = {Virk, Shafqat M. and Muhammad, Aslam and Martinez-Enriquez, A. M.},
title = {Fault Prediction Using Artificial Neural Network and Fuzzy Logic},
year = {2008},
isbn = {9780769534411},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MICAI.2008.38},
doi = {10.1109/MICAI.2008.38},
abstract = {This paper studies different vehicle fault prediction techniques, using artificial neural network and fuzzy logic based model. With increasing demands for efficiency and product quality as well as progressing integration of automatic control systems in high-cost mechatronics and safety-critical processes, monitoring is necessary to detect and diagnose faults using symptoms and related data. However, beyond protective maintenance services, it is viable to integrate fault prediction services. Thus, we studied different parameters to model a fault prediction service. This service not only helps to predict faults but is also useful to take precautionary measures to avoid tangible and intangible losses.},
booktitle = {Proceedings of the 2008 Seventh Mexican International Conference on Artificial Intelligence},
pages = {149–154},
numpages = {6},
keywords = {Faults, Artificial Neural Network, Fuzzy Logic, Neuro-Fuzzy, Neuro-Neuro, Recurrent Neural Network, Back-propagation},
series = {MICAI '08}
}

@article{10.1016/j.eswa.2008.02.066,
author = {Wong, W. K. and Yuen, C. W. M. and Fan, D. D. and Chan, L. K. and Fung, E. H. K.},
title = {Stitching defect detection and classification using wavelet transform and BP neural network},
year = {2009},
issue_date = {March, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {2},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2008.02.066},
doi = {10.1016/j.eswa.2008.02.066},
abstract = {In the textile and clothing industry, much research has been conducted on fabric defect automatic detection and classification. However, little research has been done to evaluate specifically the stitching defects of a garment. In this study, a stitching detection and classification technique is presented, which combines the improved thresholding method based on the wavelet transform with the back propagation (BP) neural network. The smooth subimage at a certain resolution level using the pyramid wavelet transform was obtained. The study uses the direct thresholding method, which is based on wavelet transform smooth subimages from the use of a quadrant mean filtering method, to attenuate the texture background and preserve the anomalies. The images are then segmented by thresholding processing and noise filtering. Nine characteristic variables based on the spectral measure of the binary images were collected and input into a BP neural network to classify the sample images. The classification results demonstrate that the proposed method can identify five classes of stitching defects effectively. Comparisons of the proposed new direct thresholding method with the direct thresholding method based on the wavelet transform detailed subimages and the automatic band selection for wavelet reconstruction method were made and the experimental results show that the proposed method outperforms the other two approaches.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {3845–3856},
numpages = {12},
keywords = {Wavelet transform, Stitching defect, Quadrant mean filter, Neural network, Image segmentation, Defect classification}
}

@inproceedings{10.1109/ICICIC.2007.308,
author = {Li, Bin and Zhang, Wei-guo and Ning, Dong-fang and Yin, Wei},
title = {Fault Prediction System Based on Neural Network Model},
year = {2007},
isbn = {0769528821},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICICIC.2007.308},
doi = {10.1109/ICICIC.2007.308},
abstract = {In the fault diagnosis of the plane steering surface, exact fault prediction is very important for the security of the aircraft. According to design requirement of the plane steering surface fault prediction system, the application of neural network technique is plane fault prediction is presented, and the algorithm based on the neural network model in the prediction system is given. Considering the advantage of neural network technique, the neural network and the fault prediction technique with expert are combined to form a fault prediction system. Finally, taking the steering surface of plane as an example to realize fault prediction, the result proves that the forecast model and algorithm based on the neural network are feasible.},
booktitle = {Proceedings of the Second International Conference on Innovative Computing, Informatio and Control},
pages = {496},
series = {ICICIC '07}
}

@article{10.1016/j.compeleceng.2014.05.013,
author = {Verma, Alok and Sarangi, Somnath and Kolekar, M.H.},
title = {Stator winding fault prediction of induction motors using multiscale entropy and grey fuzzy optimization methods},
year = {2014},
issue_date = {October 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {40},
number = {7},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2014.05.013},
doi = {10.1016/j.compeleceng.2014.05.013},
abstract = {The prediction of stator winding faults using multiscale entropy is performed for the first time.Real-time vibration and current are used as diagnostics to identify faults.The system complexity associated with motors is investigated using multiscale entropy.GFRG is used to predict fault and also to suggest optimal settings for motor operation.The motor condition has a maximum contribution of 54.21%, as determined from the ANOVA analysis. In the present work, stator winding fault prediction is studied using a multiscale entropy (MSE) algorithm combined with a grey-based fuzzy algorithm. Experiments were performed with a normal motor and a motor with faulty stator winding. Real time, motor current and vibration signals were acquired at different operating speeds and were used for the diagnosis of faults. The obtained signals were denoised by wavelet transform. Grey relational analysis (GRA) coupled with fuzzy logic was used to model the stator winding fault and to predict the optimal setting for running the induction motor within its parameters range. Analysis of variance (ANOVA) was performed to determine the effect of each individual parameter on the response. The results indicate that the proposed novel approach is very effective in predicting the stator winding fault. Furthermore, the best running parameters for the induction motor are also reported.},
journal = {Comput. Electr. Eng.},
month = oct,
pages = {2246–2258},
numpages = {13}
}

@inproceedings{10.1145/3172871.3172872,
author = {Kumar, Lov and Sureka, Ashish},
title = {Feature Selection Techniques to Counter Class Imbalance Problem for Aging Related Bug Prediction: Aging Related Bug Prediction},
year = {2018},
isbn = {9781450363983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3172871.3172872},
doi = {10.1145/3172871.3172872},
abstract = {Aging-Related Bugs (ARBs) occur in long running systems due to error conditions caused because of accumulation of problems such as memory leakage or unreleased files and locks. Aging-Related Bugs are hard to discover during software testing and also challenging to replicate. Automatic identification and prediction of aging related fault-prone files and classes in an object oriented system can help the software quality assurance team to optimize their testing efforts. In this paper, we present a study on the application of static source code metrics and machine learning techniques to predict aging related bugs. We conduct a series of experiments on publicly available dataset from two large open-source software systems: Linux and MySQL. Class imbalance and high dimensionality are the two main technical challenges in building effective predictors for aging related bugs.We investigate the application of five different feature selection techniques (OneR, Information Gain, Gain Ratio, RELEIF and Symmetric Uncertainty) for dimensionality reduction and five different strategies (Random Under-sampling, Random Oversampling, SMOTE, SMOTEBoost and RUSBoost) to counter the effect of class imbalance in our proposed machine learning based solution approach. Experimental results reveal that the random under-sampling approach performs best followed by RUSBoost in-terms of the mean AUC metric. Statistical significance test demonstrates that there is a significant difference between the performance of the various feature selection techniques. Experimental results shows that Gain Ratio and RELEIF performs best in comparison to other strategies to address the class imbalance problem. We infer from the statistical significance test that there is no difference between the performances of the five different learning algorithms.},
booktitle = {Proceedings of the 11th Innovations in Software Engineering Conference},
articleno = {2},
numpages = {11},
keywords = {Source Code Metrics, Software Maintenance, Predictive Modeling, Machine Learning, Imbalance Learning, Feature Selection Techniques, Empirical Software Engineering, Aging Related Bugs},
location = {Hyderabad, India},
series = {ISEC '18}
}

@phdthesis{10.5555/1144653,
author = {Xiao, Xiangyu and Conners, Richard W. and Kline, D. Earl},
title = {A multiple sensors approach to wood defect detection},
year = {2004},
isbn = {0542363771},
publisher = {Virginia Polytechnic Institute &amp; State University},
address = {USA},
abstract = {This research work reported in this dissertation is the first aimed at creating a vision system utilizes three imaging modalities: a color imaging system, a laser range profiling system and an X-ray imaging system. The objective of in designing this vision system is to detect and identify: (1)&nbsp;surface features such as knots, splits, stains; (2)&nbsp;geometry features such as wane, thin board; and (3)&nbsp;internal features such as voids, knots. The laser range profiling system is used to locate and identify geometry features. The X-ray imaging system is primarily used to detect features such as knots, splits and interior voids. The color imaging system is mainly employed to identify surface features. In this vision system a number of methodologies are used to improve processing speed and identification accuracy. The images from different sensing modalities are analyzed in a special order to offset the larger amount of image data that comes from the multiple sensors and that must be analyzed. The analysis of laser image is performed first. It is used to find defects that have insufficient thickness. These defects are then removed from consideration in the subsequent analysis of the X-ray image. Removing these defects from consideration in the analysis of the X-ray image not only improves the accuracy of detecting and identifying defects but also reduces the amount of time needed to analyze the X-ray image. Similarly, defect areas such as knot and mineral streak that are found in the analysis of the X-ray image are removed from consideration in the analysis of the color image. A fuzzy logic algorithm---the approaching degree method---is used to assign defect labels. The fuzzy logic approach is used to mimic human behavior in identifying defects in hardwood lumber. The initial results obtained from this vision system demonstrate the feasibility of locating and identifying all the major defects that occur in hardwood lumber. This was even true during the initial hardware development phase when only images of unsatisfactory quality from a limited lumber of samples were available. The vision system is capable of locating and identifying defects at the production speed of two linear feet per second that is typical in most hardwood secondary manufacturing plants. This vision system software was designed to run on a relative slow computer (200 MHz Pentium processor) with aid of special image processing hardware, i.e., the MORRPH board that was also designed at Virginia Tech. (Abstract shortened by UMI.)},
note = {AAI3193651}
}

@article{10.1007/s11277-017-5069-3,
author = {Dong, Feng and Wang, Junfeng and Li, Qi and Xu, Guoai and Zhang, Shaodong},
title = {Defect Prediction in Android Binary Executables Using Deep Neural Network},
year = {2018},
issue_date = {October   2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {3},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-5069-3},
doi = {10.1007/s11277-017-5069-3},
abstract = {Software defect prediction locates defective code to help developers improve the security of software. However, existing studies on software defect prediction are mostly limited to the source code. Defect prediction for Android binary executables (called apks) has never been explored in previous studies. In this paper, we propose an explorative study of defect prediction in Android apks. We first propose smali2vec, a new approach to generate features that capture the characteristics of smali (decompiled files of apks) files in apks. Smali2vec extracts both token and semantic features of the defective files in apks and such comprehensive features are needed for building accurate prediction models. Then we leverage deep neural network (DNN), which is one of the most common architecture of deep learning networks, to train and build the defect prediction model in order to achieve accuracy. We apply our defect prediction model to more than 90,000 smali files from 50 Android apks and the results show that our model could achieve an AUC (the area under the receiver operating characteristic curve) of 85.98% and it is capable of predicting defects in apks. Furthermore, the DNN is proved to have a better performance than the traditional shallow machine learning algorithms (e.g., support vector machine and naive bayes) used in previous studies. The model has been used in our practical work and helped locate many defective files in apks.},
journal = {Wirel. Pers. Commun.},
month = oct,
pages = {2261–2285},
numpages = {25},
keywords = {Software defect prediction, Mobile security, Machine learning, Deep neural network, Android binary executables}
}

@article{10.1016/j.infsof.2006.07.005,
author = {Kanmani, S. and Uthariaraj, V. Rhymend and Sankaranarayanan, V. and Thambidurai, P.},
title = {Object-oriented software fault prediction using neural networks},
year = {2007},
issue_date = {May, 2007},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {49},
number = {5},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2006.07.005},
doi = {10.1016/j.infsof.2006.07.005},
abstract = {This paper introduces two neural network based software fault prediction models using Object-Oriented metrics. They are empirically validated using a data set collected from the software modules developed by the graduate students of our academic institution. The results are compared with two statistical models using five quality attributes and found that neural networks do better. Among the two neural networks, Probabilistic Neural Networks outperform in predicting the fault proneness of the Object-Oriented modules developed.},
journal = {Inf. Softw. Technol.},
month = may,
pages = {483–492},
numpages = {10},
keywords = {Probabilistic neural network, Object-Oriented metrics, Logistic regression, Fault proneness, Discriminant analysis, Back propagation neural network}
}

@inproceedings{10.1109/ICCIMA.2007.152,
author = {Tajeripour, F. and Kabir, E.},
title = {Defect Detection in Patterned Fabrics Using Modified Local Binary Patterns},
year = {2007},
isbn = {0769530508},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICCIMA.2007.152},
doi = {10.1109/ICCIMA.2007.152},
abstract = {Local Binary Patterns, LBP, is one of the features which has been used for texture classification. In this paper, a method based on using these features is proposed for detecting defects in patterned fabrics. In the training stage, at first step LBP operator is applied to all rows (columns) of a defect free fabric sample, pixel by pixel, and the reference feature vector is computed. Then this image is divided into windows and LBP operator is applied to each row (column) of these windows. Based on comparison with the reference feature vector a suitable threshold for defect free windows is found. In the detection stage, a test image is divided into windows and using the threshold, defective windows can be detected. The proposed method is simple and gray scale invariant. Because of its simplicity, online implementation is possible as well. Key words: Defect Detection, Texture, Local Binary Patterns, Fabric, Machine Vision.},
booktitle = {Proceedings of the International Conference on Computational Intelligence and Multimedia Applications (ICCIMA 2007) - Volume 02},
pages = {261–267},
numpages = {7},
series = {ICCIMA '07}
}

@inproceedings{10.1007/978-3-540-72393-6_94,
author = {Lin, Hong-Dar and Chung, Chung-Yu},
title = {A Wavelet-Based Neural Network Applied to Surface Defect Detection of LED Chips},
year = {2007},
isbn = {9783540723929},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-540-72393-6_94},
doi = {10.1007/978-3-540-72393-6_94},
abstract = {This research explores the automated detection of surface defects that fall across two different background textures in a light-emitting diode (LED) chip. Water-drop defects, commonly found on chip surface, impair the appearance of LEDs as well as their functionality and security. Automated inspection of a water-drop defect is difficult because the defect has a semi-opaque appearance and a low intensity contrast with the rough exterior of the LED chip. Moreover, the blemish may fall across two different background textures, which further increases the difficulties of defect detection. We first use the one-level Haar wavelet transform to decompose a chip image and extract four wavelet characteristics. Then, the Multi-Layer Perceptron (MLP) neural network with back-propagation (BPN) algorithm is applied to integrate the multiple wavelet characteristics. Finally, the wavelet-based neural network approach judges the existence of water-drop defects. Experimental results show that the proposed method achieves an above 96.8% detection rate and a below 4.8% false alarm rate.},
booktitle = {Proceedings of the 4th International Symposium on Neural Networks: Part II--Advances in Neural Networks},
pages = {785–792},
numpages = {8},
keywords = {surface defect detection, Wavelet decomposition, Multi-layer perceptron neural network with backpropagation algorithm, LED chip, Computer vision system},
location = {Nanjing, China},
series = {ISNN '07}
}

@inproceedings{10.1145/3372806.3372816,
author = {Chen, Yuhan and Zhong, Shangping and Chen, Kaizhi and Chen, Shoulong and Zheng, Song},
title = {Automated Detection of Sewer Pipe Defects Based on Cost-Sensitive Convolutional Neural Network},
year = {2020},
isbn = {9781450372213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372806.3372816},
doi = {10.1145/3372806.3372816},
abstract = {Regular inspection and repair of drainage pipes is an important part of urban construction. Currently, many classification methods have been used for defect diagnosis using images inside pipelines. However, most of these classification models train the classifier with the goal of maximizing accuracy without considering the unequal error classification cost in defect diagnosis. In this study, the authors analyze the characteristics of sewer pipeline defect detection and design an automated detection framework based on the cost-sensitive deep convolutional neural network (CNN). The method makes the CNN network cost sensitive by introducing learning theories at the structural and loss levels of the network. To minimize misclassification costs, the authors propose a new auxiliary loss function Cost-Mean Loss, which allows the model to obtain the original parameters of the network to maximize the accuracy and improve the performance of the model by minimizing total misclassification costs in the learning process. Theoretical analysis shows that the new auxiliary loss function can be applied to the classification task to optimize the expected value of misclassification costs. The inspection images collected from multiple drainage pipes were used to train and test the network. Results show that after the cost-sensitive strategy was added, the defect detection rate decreased from 2.1% to 0.45%. Moreover, the model with Cost-Mean Loss has better performance than the original model.},
booktitle = {Proceedings of the 2019 2nd International Conference on Signal Processing and Machine Learning},
pages = {8–17},
numpages = {10},
keywords = {Sewer pipe inspection, Defect detection, Deep learning, Cost-sensitive learning, Cost-Mean Loss},
location = {Hangzhou, China},
series = {SPML '19}
}

@article{10.1016/j.eswa.2009.04.047,
author = {Hou, Shumin and Li, Yourong},
title = {Short-term fault prediction based on support vector machines with parameter optimization by evolution strategy},
year = {2009},
issue_date = {December, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {10},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2009.04.047},
doi = {10.1016/j.eswa.2009.04.047},
abstract = {Support vector machines (SVMs) are the effective machine-learning methods based on the structural risk minimization (SRM) principle, which is an approach to minimize the upper bound risk functional related to the generalization performance. The parameter selection is an important factor that impacts the performance of SVMs. Evolution Strategy with Covariance Matrix Adaptation (CMA-ES) is an evolutionary optimization strategy, which is used to optimize the parameters of SVMs in this paper. Compared with the traditional SVMs, the optimal SVMs using CMA-ES have more accuracy in predicting the Lorenz signal. The industry case illustrates that the proposed method is very successfully in forecasting the short-term fault of large machinery.},
journal = {Expert Syst. Appl.},
month = dec,
pages = {12383–12391},
numpages = {9},
keywords = {Support vector machines, Fault prediction, Evolutionary algorithms}
}

@article{10.1145/2347696.2347709,
author = {Rashid, Ekbal and Patnayak, Srikanta and Bhattacherjee, Vandana},
title = {A survey in the area of machine learning and its application for software quality prediction},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2347696.2347709},
doi = {10.1145/2347696.2347709},
abstract = {This paper explores software quality improvement through early prediction of error patterns. It summarizes a variety of techniques for software quality prediction in the domain of software engineering. The objective of this research is to apply the various machine learning approaches, such as Case-Based Reasoning and Fuzzy logic, to predict software quality. The system predicts the error after accepting the values of certain parameters of the software. This paper advocates the use of case-based reasoning (i.e., CBR) to build a software quality prediction system with the help of human experts. The prediction is based on analogy. We have used different similarity measures to find the best method that increases reliability. This software is compiled using Turbo C++ 3.0 and hence it is very compact and standalone. It can be readily deployed on any configuration without affecting its performance.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–7},
numpages = {7},
keywords = {software quality, similarity, machine learning, function, erffort estimation, analogy, CBR}
}

@inproceedings{10.5555/1768409.1768496,
author = {Salazar, Addisson and Uni\'{o}, Juan M. and Serrano, Arturo and Gosalbez, Jorge},
title = {Neural networks for defect detection in non-destructive evaluation by sonic signals},
year = {2007},
isbn = {9783540730064},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper presents an application of neural networks in pattern recognition of defects in sonic signals from non-destructive evaluation by multichannel impact-echo. The problem approached consists in allocating parallelepiped-shape materials in four levels of classifications defining material condition (homogeneous or defective), kind of defects (holes and cracks), defect orientation, and defect dimension. Various signal features as centroid frequency, attenuation and amplitude of the principal frequency are estimated per channel and processed by PCA and feature selection methods to reduce dimensionality. Results for simulations and experiments applying Radial Basis Function, Multilayer Perceptron and Linear Vector Quantization neural networks are presented. Neural networks obtain good performance in classifying several 3D finite element models and specimens of aluminum alloy.},
booktitle = {Proceedings of the 9th International Work Conference on Artificial Neural Networks},
pages = {638–645},
numpages = {8},
location = {San Sebasti\'{a}n, Spain},
series = {IWANN'07}
}

@article{10.1016/j.ins.2018.05.035,
author = {Siers, Michael J. and Islam, Md Zahidul},
title = {Novel algorithms for cost-sensitive classification and knowledge discovery in class imbalanced datasets with an application to NASA software defects},
year = {2018},
issue_date = {Aug 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {459},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2018.05.035},
doi = {10.1016/j.ins.2018.05.035},
journal = {Inf. Sci.},
month = aug,
pages = {53–70},
numpages = {18},
keywords = {Knowledge discovery, Decision forest, Cost-sensitive, Class imbalance, Software defect prediction}
}

@article{10.1016/j.asoc.2014.03.030,
author = {Chatterjee, Subhashish and Roy, Arunava},
title = {Web software fault prediction under fuzzy environment using MODULO-M multivariate overlapping fuzzy clustering algorithm and newly proposed revised prediction algorithm},
year = {2014},
issue_date = {September, 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {22},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2014.03.030},
doi = {10.1016/j.asoc.2014.03.030},
abstract = {In recent years some research works have been carried out on web software error analysis and reliability predictions. In all these works the web environment has been considered as crisp one, which is not a very realistic assumption. Moreover, web error forecasting remains unworthy for the researchers for quite a long time. Furthermore, among various well known forecasting techniques, fuzzy time series based methods are extensively used, though they are suffering from some serious drawbacks, viz., fixed sized intervals, using some fixed membership values (0, 0.5, and 1) and moreover, the defuzzification process only deals with the factor that is to be predicted. Prompted by these facts, the present authors have proposed a novel multivariate fuzzy forecasting algorithm that is able to remove all the aforementioned drawbacks as also can predict the future occurrences of different web failures (considering the web environment as fuzzy) with better predictive accuracy. Also, the complexity analysis of the proposed algorithm is done to unveil its better run time complexity. Moreover, the comparisons with the other existing frequently used forecasting algorithms were performed to demonstrate its better efficiency and predictive accuracy. Additionally, at the very end, the developed algorithm was applied on the real web failure data of http://www.ismdhanbad.ac.in/, the official website of ISM Dhanbad, India, collected from the corresponding HTTP log files.},
journal = {Appl. Soft Comput.},
month = sep,
pages = {372–396},
numpages = {25},
keywords = {Web software reliability, Web errors, Server logs, Fuzzy time series, Fuzzy clustering, Algorithm}
}

@article{10.1007/s10515-011-0086-z,
author = {Thummalapenta, Suresh and Xie, Tao},
title = {Alattin: mining alternative patterns for defect detection},
year = {2011},
issue_date = {December  2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {18},
number = {3–4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0086-z},
doi = {10.1007/s10515-011-0086-z},
abstract = {To improve software quality, static or dynamic defect-detection tools accept programming rules as input and detect their violations in software as defects. As these programming rules are often not well documented in practice, previous work developed various approaches that mine programming rules as frequent patterns from program source code. Then these approaches use static or dynamic defect-detection techniques to detect pattern violations in source code under analysis. However, these existing approaches often produce many false positives due to various factors. To reduce false positives produced by these mining approaches, we develop a novel approach, called Alattin, that includes new mining algorithms and a technique for detecting neglected conditions based on our mining algorithm. Our new mining algorithms mine patterns in four pattern formats: conjunctive, disjunctive, exclusive-disjunctive, and combinations of these patterns. We show the benefits and limitations of these four pattern formats with respect to false positives and false negatives among detected violations by applying those patterns to the problem of detecting neglected conditions.},
journal = {Automated Software Engg.},
month = dec,
pages = {293–323},
numpages = {31},
keywords = {Static defect detection, Mining software engineering data, Code search engine, Alternative patterns}
}

@inproceedings{10.5555/1777292.1777378,
author = {D'Orazio, T. and Leo, M. and Guaragnella, C. and Distante, A.},
title = {Analysis of image sequences for defect detection in composite materials},
year = {2007},
isbn = {3540746064},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {The problem of inspecting composite materials to detect internal defects is felt in many industrial contexts both for quality controls through production lines and for maintenance operations during in-service inspections. The analysis of the internal defects (not detectable by a visual inspection) is a difficult task unless invasive techniques are applied. For this reason in the last years there has been an increasing interest for the development of low cost non-destructive inspection techniques that can be applied during normal routine tests without damaging materials but also with automatic analysis tools. In this paper we have addressed the problem of developing an automatic signal processing system that analyzes the time/space variations in a sequence of thermographic images and allows the identification of internal defects in composite materials that otherwise could not be detected. First of all a preprocessing technique was applied to the time /space signals to extract significant information, then an unsupervised classifier was used to extract uniform classes that characterize a range of internal defects. The experimental results demonstrate the ability of the method to recognize different regions containing several types defects.},
booktitle = {Proceedings of the 9th International Conference on Advanced Concepts for Intelligent Vision Systems},
pages = {855–864},
numpages = {10},
location = {Delft, The Netherlands},
series = {ACIVS'07}
}

@article{10.1007/s10489-020-01877-z,
author = {Zheng, Xiaoqing and Chen, Jie and Wang, Hongcheng and Zheng, Song and Kong, Yaguang},
title = {A deep learning-based approach for the automated surface inspection of copper clad laminate images},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {3},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-01877-z},
doi = {10.1007/s10489-020-01877-z},
abstract = {Surface quality inspection and control are extremely important for electronic manufacturing. The use of machine vision technology to automatically detect the defects of products has become an indispensable means for better quality control. A machine vision-based surface quality inspection system is usually composed of two processes: image acquisition and automatic defect detection. In this paper, we propose a deep learning-based approach for the defect detection of Copper Clad Laminate (CCL) images acquired from an industrial CCL production line. In the proposed approach, a new convolutional neural network (CNN) that realizes fast defect detection while maintaining high accuracy is designed. Our proposed approach makes four contributions. First, we introduce the depthwise separable convolution to reduce the calculation time. Second, we improve the squeeze-and-excitation block to improve network performance. Third, we introduce the squeeze-and-expand mechanism to reduce the computation cost. Fourth, we employ a smoother activation function (Mish) to allow improved information flow. The proposed network is compared with the benchmark CNNs (including Inception, ResNet and MobileNet). The experimental results show that compared with the benchmark networks, our proposed network has achieved the best results regarding the accuracy and suboptimal results in terms of the speed compared with the benchmark networks. Therefore, our proposed method has been integrated into an industrial CCL production line as a guideline for online defective product rejection.},
journal = {Applied Intelligence},
month = mar,
pages = {1262–1279},
numpages = {18},
keywords = {Efficient network, Convolutional neural network, Deep learning, Defect detection, Machine vision}
}

@inproceedings{10.1109/ISDEA.2010.90,
author = {Zhoufeng, Liu and Erjin, Gao and Chunlei, Li},
title = {A Novel Fabric Defect Detection Scheme Based on Improved Local Binary Pattern Operator},
year = {2010},
isbn = {9780769542126},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISDEA.2010.90},
doi = {10.1109/ISDEA.2010.90},
abstract = {Local binary pattern (LBP) is one of the features which have been used for texture classification. In this paper, we propose a novel fabric detect detection scheme based on an improve LBP operator. In the training stage, LBP operator is applied on the training sets, and a model is generated according to training using support vector machine (SVM). In the test stage, a test image is divided into the image blocks with size. LBP features are extracted from the image blocks, the SVM model is used to classify the fabric defects. Experimental results demonstrate the efficiency of our proposed algorithm. Because of its simplicity, online implementation is possible as well.},
booktitle = {Proceedings of the 2010 International Conference on Intelligent System Design and Engineering Application - Volume 01},
pages = {116–119},
numpages = {4},
keywords = {training sets, fabric defect, SVM, LBP},
series = {ISDEA '10}
}

@article{10.5555/1028839.1028841,
author = {Mandriota, C. and Nitti, M. and Ancona, N. and Stella, E. and Distante, A.},
title = {Filter-based feature selection for rail defect detection},
year = {2004},
issue_date = {October 2004},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {4},
issn = {0932-8092},
abstract = {Over the last few years research has been oriented toward developing a machine vision system for locating and identifying, automatically, defects on rails. Rail defects exhibit different properties and are divided into various categories related to the type and position of flaws on the rail. Several kinds of interrelated factors cause rail defects such as type of rail, construction conditions, and speed and/or frequency of trains using the rail. The aim of this paper is to present an experimental comparison among three filtering approaches, based on texture analysis of rail surfaces, to detect the presence/absence of a particular class of surface detects: corrugation.},
journal = {Mach. Vision Appl.},
month = oct,
pages = {179–185},
numpages = {7},
keywords = {texture feature, rail detection, filter bank, K-nearest neighbor classifier}
}

@inproceedings{10.1007/11552499_46,
author = {Xie, Xianghua and Mirmehdi, Majid},
title = {Texture exemplars for defect detection on random textures},
year = {2005},
isbn = {3540288333},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11552499_46},
doi = {10.1007/11552499_46},
abstract = {We present a new approach to detecting defects in random textures which requires only very few defect free samples for unsupervised training. Each product image is divided into overlapping patches of various sizes. Then, density mixture models are applied to reduce groupings of patches to a number of textural exemplars, referred to here as texems, characterising the means and covariances of whole sets of image patches. The texems can be viewed as implicit representations of textural primitives. A multiscale approach is used to save computational costs. Finally, we perform novelty detection by applying the lower bound of normal samples likelihoods on the multiscale defect map of an image to localise defects.},
booktitle = {Proceedings of the Third International Conference on Pattern Recognition and Image Analysis - Volume Part II},
pages = {404–413},
numpages = {10},
location = {Bath, UK},
series = {ICAPR'05}
}

@article{10.1145/3465381,
author = {Ngo, Vuong M. and Duong, Thuy-Van T. and Nguyen, Tat-Bao-Thien and Nguyen, Phuong T. and Conlan, Owen},
title = {An Efficient Classification Algorithm&nbsp;for Traditional Textile Patterns from Different Cultures Based on Structures},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {1556-4673},
url = {https://doi.org/10.1145/3465381},
doi = {10.1145/3465381},
abstract = {Textiles have an important role in many cultures and have been digitised. They are three-dimensional objects and have complex structures, especially archaeological fabric specimens and artifact textiles created manually by traditional craftsmen. In this article, we propose a novel algorithm for textile classification based on their structures. First, a hypergraph is used to represent the textile structure. Second, multisets of k-neighbourhoods are extracted from the hypergraph and converted to one feature vector for representation of each textile. Then, the k-neighbourhood vectors are classified using seven most popular supervised learning methods. Finally, we evaluate experimentally the different variants of our approach on a data set of 1,600 textile samples with the 4-fold cross-validation technique. The experimental results indicate that comparing the variants, the best classification accuracies are 0.999 with LR, 0.994 with LDA, 0.996 with KNN, 0.994 with CART, 0.998 with NB, 0.974 with SVM, and 0.999 with NNM.},
journal = {J. Comput. Cult. Herit.},
month = jul,
articleno = {53},
numpages = {22},
keywords = {textile classification, supervised learning, hypergraph representation, Fabric pattern}
}

@article{10.1016/j.engappai.2012.09.017,
author = {Galitsky, Boris},
title = {Machine learning of syntactic parse trees for search and classification of text},
year = {2013},
issue_date = {March, 2013},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {26},
number = {3},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2012.09.017},
doi = {10.1016/j.engappai.2012.09.017},
abstract = {We build an open-source toolkit which implements deterministic learning to support search and text classification tasks. We extend the mechanism of logical generalization towards syntactic parse trees and attempt to detect weak semantic signals from them. Generalization of syntactic parse tree as a syntactic similarity measure is defined as the set of maximum common sub-trees and performed at a level of paragraphs, sentences, phrases and individual words. We analyze semantic features of such similarity measure and compare it with semantics of traditional anti-unification of terms. Nearest-neighbor machine learning is then applied to relate a sentence to a semantic class. Using syntactic parse tree-based similarity measure instead of bag-of-words and keyword frequency approach, we expect to detect a weak semantic signal otherwise unobservable. The proposed approach is evaluated in a four distinct domains where a lack of semantic information makes classification of sentences rather difficult. We describe a toolkit which is a part of Apache Software Foun-dation project OpenNLP, designed to aid search engineers in tasks requiring text relevance assessment.},
journal = {Eng. Appl. Artif. Intell.},
month = mar,
pages = {1072–1091},
numpages = {20},
keywords = {Text search, Text classification, Parse trees, Machine learning}
}

@article{10.4018/jaec.2010070104,
author = {Mohanty, Ramakanta and Ravi, V. and Patra, M. R.},
title = {Application of Machine Learning Techniques to Predict Software Reliability},
year = {2010},
issue_date = {July 2010},
publisher = {IGI Global},
address = {USA},
volume = {1},
number = {3},
issn = {1942-3594},
url = {https://doi.org/10.4018/jaec.2010070104},
doi = {10.4018/jaec.2010070104},
abstract = {In this paper, the authors employed machine learning techniques, specifically, Back propagation trained neural network (BPNN), Group method of data handling (GMDH), Counter propagation neural network (CPNN), Dynamic evolving neuro-fuzzy inference system (DENFIS), Genetic Programming (GP), TreeNet, statistical multiple linear regression (MLR), and multivariate adaptive regression splines (MARS), to accurately forecast software reliability. Their effectiveness is demonstrated on three datasets taken from literature, where performance is compared in terms of normalized root mean square error (NRMSE) obtained in the test set. From rigorous experiments conducted, it was observed that GP outperformed all techniques in all datasets, with GMDH coming a close second.},
journal = {Int. J. Appl. Evol. Comput.},
month = jul,
pages = {70–86},
numpages = {17},
keywords = {Software Reliability, Machine Learning Techniques, Group Method of Data Handling, Genetic Programming, Dynamic Evolving Neuro-Fuzzy Inference System, Counter Propagation Neural Network, Back Propagation Trained Neural Network}
}

@article{10.1016/j.compag.2021.106267,
author = {Ghazal, Sumaira and Qureshi, Waqar S. and Khan, Umar S. and Iqbal, Javaid and Rashid, Nasir and Tiwana, Mohsin I.},
title = {Analysis of visual features and classifiers for Fruit classification problem},
year = {2021},
issue_date = {Aug 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {187},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2021.106267},
doi = {10.1016/j.compag.2021.106267},
journal = {Comput. Electron. Agric.},
month = aug,
numpages = {9},
keywords = {Agricultural automation, K nearest neighbors classifier, Fruit classification, Supervised learning, Neural networks}
}

@inproceedings{10.1145/3194718.3194730,
author = {Sarro, Federica},
title = {Predictive analytics for software testing: keynote paper},
year = {2018},
isbn = {9781450357418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194718.3194730},
doi = {10.1145/3194718.3194730},
abstract = {This keynote discusses the use of Predictive Analytics for Software Engineering, and in particular for Software Defect Prediction and Software Testing, by presenting the latest results achieved in these fields leveraging Artificial Intelligence, Search-based and Machine Learning methods, and by giving some directions for future work.},
booktitle = {Proceedings of the 11th International Workshop on Search-Based Software Testing},
pages = {1},
numpages = {1},
keywords = {search-based predictive modelling, predictive analytics},
location = {Gothenburg, Sweden},
series = {SBST '18}
}

@article{10.1023/A:1024424811345,
author = {Khoshgoftaar, Taghi M. and Seliya, Naeem},
title = {Fault Prediction Modeling for Software Quality Estimation: Comparing Commonly Used Techniques},
year = {2003},
issue_date = {September 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1023/A:1024424811345},
doi = {10.1023/A:1024424811345},
abstract = {High-assurance and complex mission-critical software systems are heavily dependent on reliability of their underlying software applications. An early software fault prediction is a proven technique in achieving high software reliability. Prediction models based on software metrics can predict number of faults in software modules. Timely predictions of such models can be used to direct cost-effective quality enhancement efforts to modules that are likely to have a high number of faults. We evaluate the predictive performance of six commonly used fault prediction techniques: CART-LS (least squares), CART-LAD (least absolute deviation), S-PLUS, multiple linear regression, artificial neural networks, and case-based reasoning. The case study consists of software metrics collected over four releases of a very large telecommunications system. Performance metrics, average absolute and average relative errors, are utilized to gauge the accuracy of different prediction models. Models were built using both, original software metrics (RAW) and their principle components (PCA). Two-way ANOVA randomized-complete block design models with two blocking variables are designed with average absolute and average relative errors as response variables. System release and the model type (RAW or PCA) form the blocking variables and the prediction technique is treated as a factor. Using multiple-pairwise comparisons, the performance order of prediction models is determined. We observe that for both average absolute and average relative errors, the CART-LAD model performs the best while the S-PLUS model is ranked sixth.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {255–283},
numpages = {29},
keywords = {software metrics, neural networks, multiple linear regression, fault prediction, case-based reasoning, Software quality prediction, S-PLUS, CART}
}

@inproceedings{10.1109/ICMV.2009.54,
author = {Kaur, Arashdeep and Sandhu, Parvinder S. and Bra, Amanpreet Singh},
title = {Early Software Fault Prediction Using Real Time Defect Data},
year = {2010},
isbn = {9780769539447},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMV.2009.54},
doi = {10.1109/ICMV.2009.54},
abstract = {Quality of a software component can be measured in terms of fault proneness of data. Quality estimations are made using fault proneness data available from previously developed similar type of projects and the training data consisting of software measurements. To predict faulty modules in software data different techniques have been proposed which includes statistical method, machine learning methods, neural network techniques and clustering techniques. The aim of proposed approach is to investigate that whether metrics available in the early lifecycle (i.e. requirement metrics), metrics available in the late lifecycle (i.e. code metrics) and metrics available in the early lifecycle (i.e. requirement metrics) combined with metrics available in the late lifecycle (i.e. code metrics) can be used to identify fault prone modules by using clustering techniques. This approach has been tested with three real time defect datasets of NASA software projects, JM1, PC1 and CM1. Predicting faults early in the software life cycle can be used to improve software process control and achieve high software reliability. The results show that when all the prediction techniques are evaluated, the best prediction model is found to be the fusion of requirement and code metric model.},
booktitle = {Proceedings of the 2009 Second International Conference on Machine Vision},
pages = {242–245},
numpages = {4},
series = {ICMV '09}
}

@inproceedings{10.5555/2394450.2394484,
author = {Catal, Cagatay and Diri, Banu},
title = {Software fault prediction with object-oriented metrics based artificial immune recognition system},
year = {2007},
isbn = {3540734597},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software testing is a time-consuming and expensive process. Software fault prediction models are used to identify fault-prone classes automatically before system testing. These models can reduce the testing duration, project risks, resource and infrastructure costs. In this study, we propose a novel fault prediction model to improve the testing process. Chidamber-Kemerer Object-Oriented metrics and method-level metrics such as Halstead and McCabe are used as independent metrics in our Artificial Immune Recognition System based model. According to this study, class-level metrics based model which applies AIRS algorithm can be used successfully for fault prediction and its performance is higher than J48 based approach. A fault prediction tool which uses this model can be easily integrated into the testing process.},
booktitle = {Proceedings of the 8th International Conference on Product-Focused Software Process Improvement},
pages = {300–314},
numpages = {15},
location = {Riga, Latvia},
series = {PROFES'07}
}

@article{10.3233/IDA-205143,
author = {Mao, Yulin and Wang, Shuangxin and Yu, Dingli and Zhao, Juchao},
title = {Automatic image detection of multi-type surface defects on wind turbine blades based on cascade deep learning network},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {25},
number = {2},
issn = {1088-467X},
url = {https://doi.org/10.3233/IDA-205143},
doi = {10.3233/IDA-205143},
abstract = {A safe operation protocol of the wind blades is a critical factor to ensure the stability of a wind turbine. Sensors are most commonly applied for defect detection on wind turbine blades (WTBs). However, due to the high cost and the sensitivity to stochastic noise, computer vision-guided automatic detection remains a challenge for surface defect detection on WTBs in particularly, its accuracy in locating defects is yet to be optimized. In this paper, we developed a visual inspection model that can automatically and precisely classify and locate the surface defects, through the utilization of a deep learning framework based on the Cascade R-CNN. In order to obtain high mean average precision (mAP) according to the characteristics of the dataset, a model named Contextual Aligned-Deformable Cascade R-CNN (CAD Cascade R-CNN) using improved strategies of transfer learning, Deformable Convolution and Deformable RoI Align, as well as context information fusion is proposed and a dataset with surface defects categorized and labeled as crack, breakage and oil pollution is generated. Moreover to alleviate the problem of false detection under a complex background, an improved bisecting k-means is presented during the test process. The adaptability and generalization of the proposed CAD Cascade R-CNN model were validated by each type of defects in dataset and different IoU thresholds, whereas, each of the above improved strategies was verified by gradual ablation experiments. Finally experiments that compared with the baseline Cascade R-CNN, Faster R-CNN and YOLO-v3 demonstrate its superiority over these existing approaches with a maximum of 92.1% mAP.},
journal = {Intell. Data Anal.},
month = jan,
pages = {463–482},
numpages = {20},
keywords = {accuracy, surface defect detection wind turbine blades, Cascade R-CNN, Deep learning}
}

@inproceedings{10.1145/3501409.3501612,
author = {Qu, Rui and Yuan, Guowu and Liu, Jianchen and Zhou, Hao},
title = {Detection of cigarette appearance defects based on improved SSD model},
year = {2022},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501409.3501612},
doi = {10.1145/3501409.3501612},
abstract = {The automatic detection of product defects has been applied to the assembly line production of various industries. With the automation of the production of cigarettes, the detection of appearance defects of cigarettes can no longer be completed manually. Aiming at the current low efficiency of cigarette appearance defect detection, this paper proposes a model based on improved SSD network and pyramid convolution for cigarette appearance defect detection. First, replace the original VGG16 feature extraction network with the ResNet50 network, which has better feature expression capabilities, to improve the performance of small target detection while retaining more shallow semantics; Secondly, replace the original 3\texttimes{}3 convolution in the network and use pyramid convolution to expand the receptive field and extract multi-scale information; At the same time, the original loss function is optimized to solve the problem of unbalanced cigarette appearance defect categories in the data set. The experimental results show that the average accuracy of the algorithm in this paper is 90.26%, which is much higher than the accuracy of the original SSD model and other target detection algorithms.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1148–1153},
numpages = {6},
keywords = {Convolutional Neural Network, Defect Detection, Pyramid Convolution, SSD Network, Target Detection},
location = {Xiamen, China},
series = {EITCE '21}
}

@article{10.1016/j.patcog.2006.03.005,
author = {Tsai, Du-Ming and Lin, Ping-Chieh and Lu, Chi-Jie},
title = {An independent component analysis-based filter design for defect detection in low-contrast surface images},
year = {2006},
issue_date = {September, 2006},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {39},
number = {9},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2006.03.005},
doi = {10.1016/j.patcog.2006.03.005},
abstract = {In this paper, we propose a convolution filtering scheme for detecting small defects in low-contrast uniform surface images and, especially, focus on the applications for backlight panels and glass substrates found in liquid crystal display (LCD) manufacturing. A defect embedded in a low-contrast surface image shows no distinct intensity from its surrounding region, and even worse, the sensed image may present uneven brightness on the surface. All these make the defect detection in low-contrast surface images extremely difficult. In this study, a constrained independent component analysis (ICA) model is proposed to design an optimal filter with the objective that the convolution filter will generate the most representative source intensity of the background surface without noise. The prior constraint incorporated in the ICA model confines the source values of all training image patches of a defect-free image within a small interval of control limits. In the inspection process, the same control parameter used in the constraint is also applied to set up the thresholds that make impulse responses of all pixels in faultless regions within the control limits, and those in defective regions outside the control limits. A stochastic evolutionary computation algorithm, particle swarm optimization (PSO), is applied to solve for the constrained ICA model. Experimental results have shown that the proposed method can effectively detect small defects in low-contrast backlight panels and LCD glass substrate images.},
journal = {Pattern Recogn.},
month = sep,
pages = {1679–1694},
numpages = {16},
keywords = {Surface inspection, Particle swarm optimization, Independent component analysis, Defect detection, Convolution filter}
}

@article{10.1016/j.patcog.2006.05.023,
author = {Sezer, O. G. and Ercil, A. and Ertuzun, A.},
title = {Using perceptual relation of regularity and anisotropy in the texture with independent component model for defect detection},
year = {2007},
issue_date = {January, 2007},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {40},
number = {1},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2006.05.023},
doi = {10.1016/j.patcog.2006.05.023},
abstract = {This paper addresses the raw textile defect detection problem using independent components approach with insights from human vision system. Human vision system is known to have specialized receptive fields that respond to certain type of input signals. Orientation-selective bar cells and grating cells are examples of receptive fields in the primary visual cortex that are selective to periodic- and aperiodic-patterns, respectively. Regularity and anisotropy are two high-level features of texture perception, and we can say that disruption in regularity and/or orientation field of the texture pattern causes structural defects. In our research, we observed that independent components extracted from texture images give bar or grating cell like results depending on the structure of the texture. For those textures having lower regularity and dominant local anisotropy (orientation or directionality), independent components look similar to bar cells whereas textures with high regularity and lower anisotropy have independent components acting like grating cells. Thus, we will expect different bar or grating cell like independent components to respond to defective and defect-free regions. With this motivation, statistical analysis of the structure of the texture by means of independent components and then extraction of the disturbance in the structure can be a promising approach to understand perception of local disorder of texture in human vision system. In this paper, we will show how to detect regions of structural defects in raw textile data that have certain regularity and local orientation characteristics with the application of independent component analysis (ICA), and we will present results on real textile images with detailed discussions.},
journal = {Pattern Recogn.},
month = jan,
pages = {121–133},
numpages = {13},
keywords = {Texture defect detection, Receptive fields, Independent component analysis, Human vision}
}

@article{10.1504/ijaip.2019.101983,
author = {Kumar, Reddi Kiran and Rao, S.V. Achuta},
title = {Severity of defect: an optimised prediction},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {3–4},
issn = {1755-0386},
url = {https://doi.org/10.1504/ijaip.2019.101983},
doi = {10.1504/ijaip.2019.101983},
abstract = {To assure the quality of software an important activity is performed namely software defect prediction (SDP). Historical databases are used to detect software defects using different machine learning techniques. Conversely, there are disadvantages like testing becomes expensive, poor quality and so the product is unreliable for use. This paper classifies the severity of defects by using a method based on optimised neural network (NN). In full search space, a solution is found by many meta-heuristic optimisations and global search ability has been used. Hence, high-quality solutions are finding within a reasonable period of time. SDP performance is improved by the combination of meta-heuristic optimisation methods. For class imbalance problem, meta-heuristic optimisation methods such as genetic algorithm (GA) and shuffled frog leaping algorithm (SFLA) are applied. The above method is based on SFLA and the experimental outputs show that it can do better than Leven berg Marquardt based NN system (LM-NN).},
journal = {Int. J. Adv. Intell. Paradigms},
month = jan,
pages = {334–345},
numpages = {11},
keywords = {shuffled frog and fuzzy classifier, LM, Levenberg Marquardt, neural network, severity, SDP, software defect prediction}
}

@inproceedings{10.1007/978-3-030-79463-7_35,
author = {Kawalerowicz, Marcin and Madeyski, Lech},
title = {Continuous Build Outcome Prediction: A Small-N Experiment in Settings of a Real Software Project},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_35},
doi = {10.1007/978-3-030-79463-7_35},
abstract = {We explain the idea of Continuous Build Outcome Prediction (CBOP) practice that uses classification to label the possible build results (success or failure) based on historical data and metrics (features) derived from the software repository. Additionally, we present a preliminary empirical evaluation of CBOP in a real live software project. In a small-n repeated-measure with two conditions and replicates experiment, we study whether CBOP will reduce the Failed Build Ratio (FBR). Surprisingly, the result of the study indicates a slight increase in FBR while using the CBOP, although the effect size is very small. A plausible explanation of the revealed phenomenon may come from the authority principle, which is rarely discussed in the software engineering context in general, and AI-supported software development practices in particular.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {412–425},
numpages = {14},
keywords = {Machine learning, Continuous integration, Agile experimentation, Software defect prediction},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00061,
author = {Liu, Changlin and Xiao, Xusheng},
title = {ProMal: precise window transition graphs for Android via synergy of program analysis and machine learning},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00061},
doi = {10.1109/ICSE-Companion52605.2021.00061},
abstract = {Mobile apps have been an integral part in our daily life. As these apps become more complex, it is critical to provide automated analysis techniques to ensure the correctness, security, and performance of these apps. A key component for these automated analysis techniques is to create a graphical user interface (GUI) model of an app, i.e., a window transition graph (WTG), that models windows and transitions among the windows. While existing work has provided both static and dynamic analysis to build the WTG for an app, the constructed WTG misses many transitions or contains many infeasible transitions due to the coverage issues of dynamic analysis and over-approximation of the static analysis. We propose ProMal, a "tribrid" analysis that synergistically combines static analysis, dynamic analysis, and machine learning to construct a precise WTG. Specifically, ProMal first applies static analysis to build a static WTG, and then applies dynamic analysis to verify the transitions in the static WTG. For the unverified transitions, ProMal further provides machine learning techniques that leverage runtime information (i.e., screenshots, UI layouts, and text information) to predict whether they are feasible transitions. Our evaluations on 40 real-world apps demonstrate the superiority of ProMal in building WTGs over static analysis, dynamic analysis, and machine learning techniques when they are applied separately.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {144–146},
numpages = {3},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@article{10.5555/1639385.1639388,
author = {Cheng, Yaoyu and Hu, Yan and Wang, Yu},
title = {Defect detection and characteristics description of auto hub radiographic image based on SUSAN operation},
year = {2009},
issue_date = {July 2009},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
volume = {8},
number = {7},
issn = {1109-2769},
abstract = {The collected images' target object is faint in the auto hub real-time X-ray detection, so it is easily making the miscarriage of justice in the auto hub detection. Most of the current method of detection of defects is by manual detection, so it is very difficult to improve detection efficiency and detection accuracy. Aiming at these issues and combining with the characteristics that auto hub's image have so much noise source, it is adopted SUSAN operator for defect images' edge detection, which is based on the image second partition, and it is achieved good results in edge detection by this method. And then it carried through defect detected for the image, such as, the number, level, center of gravity, area, and circle degree of defects. This can effectively improve the detection efficiency and the accuracy of detection. The experimental results show that the method is feasible in practical applications, and it has strong anti-interference ability, good real-time detection and high efficiency compared with traditional methods.},
journal = {WSEAS Trans. Math.},
month = jul,
pages = {289–298},
numpages = {10},
keywords = {shape features, mask, geometrical features, feature description, edge detection, auto hub, SUSAN operation}
}

@inproceedings{10.1109/ACVMOT.2005.115,
author = {Hou, Zhen and Parker, Johne M.},
title = {Texture Defect Detection Using Support Vector Machines with Adaptive Gabor Wavelet Features},
year = {2005},
isbn = {07695227181},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ACVMOT.2005.115},
doi = {10.1109/ACVMOT.2005.115},
abstract = {This paper aims at investigating a method for detecting defects on textured surfaces using a Support Vector Machines (SVM) classification approach with Gabor wavelet features. Instead of using all the filters in the Gabor wavelets, an adaptive filter selection scheme is applied to reduce the computational cost on feature extraction while keeping a reasonable detection rate. One-Against-All strategy is adopted to prepare the training data for a binary SVM classifier that is learnt to classify pixels as defective or non-defective. Experimental results on comparison with other multiresolution features and the Learning Vector Quantization (LVQ) classifier demonstrate the effectiveness of the proposed method on defect detection on textured surfaces.},
booktitle = {Proceedings of the Seventh IEEE Workshops on Application of Computer Vision (WACV/MOTION'05) - Volume 1 - Volume 01},
pages = {275–280},
numpages = {6},
series = {WACV-MOTION '05}
}

@article{10.1016/j.compind.2016.09.002,
author = {Mera, Carlos and Orozco-Alzate, Mauricio and Branch, John and Mery, Domingo},
title = {Automatic visual inspection},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {83},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2016.09.002},
doi = {10.1016/j.compind.2016.09.002},
abstract = {HighlightsAn approach for quality inspection with multi-instance learning is proposed.Using weakly labeled images reduces the labeling effort in quality inspection.Experiments show that the approach can be effectively used in real-world applications. One of the industrial applications of computer vision is automatic visual inspection. In the last decade, standard supervised learning methods have been used to detect defects in different kind of products. These methods are trained with a set of images where every image has to be manually segmented and labeled by experts in the application domain. These manual segmentations require a large amount of high quality delineations (on pixels), which can be time consuming and often a difficult task. Multi-instance learning (MIL), in contrast to standard supervised classifiers, avoids this task and can, therefore, be trained with weakly labeled images. In this paper, we propose an approach for the automatic visual inspection that uses MIL for defect detection. The approach has been tested with data from three artificial benchmark datasets and three real-world industrial scenarios: inspection of artificial teeth, weld defect detection and fishbone detection. Results show that the proposed approach can be used with weakly labeled images for defect detection on automatic visual inspection systems. This approach is able to increase the area under the receiver-operating characteristic curve (AUC) up to 6.3% compared with the nave MIL approach of propagating the bag labels.},
journal = {Comput. Ind.},
month = dec,
pages = {46–54},
numpages = {9},
keywords = {Weak labels, Pattern recognition, Multi-instance learning, Defect detection, Automatic visual inspection}
}

@phdthesis{10.5555/2519464,
author = {Pelayo Ramirez, Lourdes},
advisor = {Dick, Scott},
title = {Developing and evaluating methods for mitigating sample selection bias in machine learning},
year = {2011},
isbn = {9780494892763},
publisher = {University of Alberta},
address = {CAN},
abstract = {The imbalanced learning problem occurs in a large number of economic and health domains of great importance; consequently, it has drawn a significant amount of interest from academia, industry, and government funding agencies. Several researchers have used stratification to alleviate this problem; however, it is not clear what stratification strategy is in general more effective: under-sampling, over-sampling or the combination of both. Our first topic evaluates the contribution of stratification strategies in the software defect prediction area. We study the statistical contribution of stratification in the new Mozilla dataset, a new large-scale software defect prediction dataset which includes both object-oriented metrics and a count of defects per module. Our second topic responds to the debate about the contribution of over-sampling, under-sampling and the combination of both with the employment of a full-factorial design experiment using the Analysis of Variance (ANOVA) over six software defect prediction datasets. We extend our research to develop a stratification method to mitigate sample selection bias in function approximation problems. The sample selection bias is present when the training and test instances are drawn from a different distribution, with the imbalance dataset problem considered a particular case of sample selection bias. We extend the well-known SMOTE over-sampling technique to continuous-valued response variables. Our new algorithm proves to be a valuable algorithm helping to increase the performance on function approximation problems and effectively reducing the impact of sample selection bias.},
note = {AAINR89276}
}

@inproceedings{10.5555/646079.676215,
author = {Karras, D. A. and Mertzios, B. G.},
title = {Improved Defect Detection Using Novel Wavelet Feature Extraction Involving Principal Component Analysis and Neural Network Techniques},
year = {2002},
isbn = {3540001972},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This paper aims at investigating a novel solution to the problem of defect detection from images, that can find applications in the design of robust quality control systems for the production of furniture, textile, integrated circuits, etc. The suggested solution focuses on detecting defects from their wavelet transformation and vector quantization related properties of the associated wavelet coefficients. More specifically, a novel methodology is investigated for discriminating defects by applying a supervised neural classification technique, employing a Multilayer Perceptron (MLP) trained with the conjugate gradients algorithm, to innovative multidimensional wavelet based feature vectors. These vectors are extracted from the K-Level 2-D DWT (Discrete Wavelet Transform) transformed original image using Vector Quantization techniques and a Principal Component Analysis (PCA) applied to these wavelet domain quantization vectors. The results of the proposed methodology are illustrated in defective textile images where the defective areas are recognized with higher accuracy than the one obtained by applying two rival feature extraction methodologies. The first one of them uses all the wavelet coefficients derived from the k-Level 2-D DWT, while the second one uses only image intensities characteristics. Both rival methods involve the same classification stage as the proposed feature extraction approach. The promising results herein obtained outline the importance of judicious selection and processing of 2-D DWT wavelet coefficients for industrial pattern recognition applications.},
booktitle = {Proceedings of the 15th Australian Joint Conference on Artificial Intelligence: Advances in Artificial Intelligence},
pages = {638–647},
numpages = {10},
keywords = {wavelets, neural networks, defect detection},
series = {AI '02}
}

@inproceedings{10.1109/ICPR.2006.427,
author = {Chao, Shin-Min and Tsai, Du-Ming and Tseng, Yan-Hsin and Jhang, Yuan-Ruei},
title = {Defect detection in low-contrast glass substrates using anisotropic diffusion},
year = {2006},
isbn = {0769525210},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICPR.2006.427},
doi = {10.1109/ICPR.2006.427},
abstract = {In this research, we propose an anisotropic diffusion scheme to detect defects in low-contrast surface images and, especially, aim at glass substrates used in TFT-LCDs (Thin Film Transistor-Liquid Crystal Displays). In a sensed glass substrate, the gray levels of defects and background are hardly distinguishable and result in a low-contrast image. Therefore, thresholding and edge detection techniques cannot be applied to detect subtle defects in the glass substrates surface. The proposed diffusion method in this paper can simultaneously carry out the smoothing and sharpening operations. It adaptively triggers the smoothing process in faultless areas to make the background uniform, and performs the sharpening process in defective areas to enhance anomalies. Experimental results from a number of glass substrate samples including backlight panels and LCD glass substrates have shown the efficacy of the proposed diffusion scheme in low-contrast surface inspection.},
booktitle = {Proceedings of the 18th International Conference on Pattern Recognition - Volume 01},
pages = {654–657},
numpages = {4},
series = {ICPR '06}
}

@inproceedings{10.1007/11867661_68,
author = {L\'{o}pez, Fernando and Prats, Jos\'{e} Manuel and Ferrer, Alberto and Valiente, Jos\'{e} Miguel},
title = {Defect detection in random colour textures using the MIA t2 defect maps},
year = {2006},
isbn = {3540448942},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11867661_68},
doi = {10.1007/11867661_68},
abstract = {In this paper we present a new approach for the detection of defects in random colour textures. This approach is based on the use of the T2 statistic and it is derived from the MIA strategy (Multivariate Image Analysis) developed in recent years in the field of applied statistics. PCA analysis is used to extract a reference eigenspace from a matrix built by unfolding the RGB raw data of defect-free images. The unfolding is performed compiling colour and spatial information of pixels. New testing images are also unfolded and projected onto the reference eigenspace obtaining a score matrix used to compute the T2 images. These images are converted into defect maps which allow the location of defective pixels. Only very few samples are needed to perform unsupervised training. With regard to literature, the method uses one of the simplest approaches providing low computational costs.},
booktitle = {Proceedings of the Third International Conference on Image Analysis and Recognition - Volume Part II},
pages = {752–763},
numpages = {12},
location = {P\'{o}voa de Varzim, Portugal},
series = {ICIAR'06}
}

@article{10.1007/s00500-021-06048-x,
author = {Rathore, Santosh S.},
title = {An exploratory analysis of regression methods for predicting faults in software systems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {23},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06048-x},
doi = {10.1007/s00500-021-06048-x},
abstract = {The use of regression methods, for instance, linear regression, decision tree regression, etc., has been used earlier to build software fault prediction (SFP) models. However, these methods showed limited SFP performance with higher misclassification errors. In previous works, issues such as multicollinearity, feature scaling, and imbalance distribution of faulty and non-faulty modules in the dataset have not been considered reasonably, which might be a potential cause behind the poor prediction performance of these regression methods. Motivated from it, in this paper, we investigate the impact of 15 different regression methods for the faults count prediction in the software system and report their interpretation for fault models. We consider different fault data quality issues, and a comprehensive assessment of the regression methods is presented to handle these issues. We believe that many used regression methods have not been explored before for the SFP by considering different data quality issues. In the presented study, 44 fault datasets and their versions are used that are collected from the PROMISE software data repository are used to validate the performance of the regression methods, and absolute relative error (ARE), root mean square error (RSME), and fault-percentile-average (FPA) are used as the performance measures. For the model building, five different scenarios are considered, (1) original dataset without preprocessing; (2) standardized processed dataset; (3) balanced dataset; (4) non-multicollinearity processed dataset; (5) balanced+non-multicollinearity processed dataset. Experimental results showed that overall kernel-based regression methods, KernelRidge and SVR (Support vector regression, both linear and nonlinear kernels), yielded the best performance for predicting the fault counts compared to other methods. Other regression methods, in particular NNR (Nearest neighbor regression), RFR (Random forest regression), and GBR (Gradient boosting regression), are performed significantly accurately. Further, results showed that applying standardization and handling multicollinearity in the fault dataset helped improve regression methods’ performance. It is concluded that regression methods are promising for building software fault prediction models.},
journal = {Soft Comput.},
month = dec,
pages = {14841–14872},
numpages = {32},
keywords = {Empirical study, PROMISE data repository, Regression methods, Software fault prediction}
}

@inproceedings{10.5555/839286.841747,
author = {Lambert, G. and Bock, F.},
title = {Wavelet methods for texture defect detection},
year = {1997},
isbn = {0818681837},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {In this article we introduce our approach to exploit multiscale wavelet methods for texture defect detection. Several wavelet bases and decomposition algorithms are examined in regard of applicability, parameterization and computational costs. The article points out specific problems in localizing texture defects in multiscale wavelet representations. Besides the fast dyadic wavelet transform we demonstrate the application of the translation invariant a trous algorithm on texture samples. Feature extraction methods are proposed and examples of successful defect classification results are shown.},
booktitle = {Proceedings of the 1997 International Conference on Image Processing (ICIP '97) 3-Volume Set-Volume 3 - Volume 3},
pages = {201},
keywords = {wavelet bases, translation invariant a trous algorithm, texture defects localisation, texture defect detection, multiscale wavelet representations, multiscale wavelet methods, image texture analysis, image texture, feature extraction, fast dyadic wavelet transform, defect classification, decomposition algorithms, computational costs},
series = {ICIP '97}
}

@article{10.1016/j.aei.2016.03.002,
author = {Koch, Christian and Doycheva, Kristina and Kasireddy, Varun and Akinci, Burcu and Fieguth, Paul},
title = {Corrigendum to "A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure" Advanced Engineering Informatics 29(2) (2015) 196-210},
year = {2016},
issue_date = {April 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {30},
number = {2},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2016.03.002},
doi = {10.1016/j.aei.2016.03.002},
abstract = {In the article Advanced Engineering Informatics 29(2) (2015) 196-210 in Section 3.2, there is unattributed use of materials from a prior publication, namely Chaiyasarn (2011). This material has been improperly cited and the authors sincerely apologize for this. This corrigendum contains a revised version of Section 3.2 with corrected attributions and citations.},
journal = {Adv. Eng. Inform.},
month = apr,
pages = {208–210},
numpages = {3},
keywords = {Corrigendum, Advanced Engineering Informatics 29(2) (2015) 196-210}
}

@inproceedings{10.1145/1370788.1370794,
author = {Watanabe, Shinya and Kaiya, Haruhiko and Kaijiri, Kenji},
title = {Adapting a fault prediction model to allow inter languagereuse},
year = {2008},
isbn = {9781605580364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370788.1370794},
doi = {10.1145/1370788.1370794},
abstract = {An important step in predicting error prone modules in a project is to construct the prediction model by using training data of that project, but the resulting prediction model depends on the training data. Therefore it is difficult to apply the model to other projects. The training data consists of metrics data and bug data, and these data should be prepared for each project. Metrics data can be computed by using metric tools, but it is not so easy to collect bug data. In this paper, we try to reuse the generated prediction model. By using the metrics and bug data which are computed from C++ and Java projects, we have evaluated the possibility of applying the prediction model, which is generated based on one project, to other projects, and have proposed compensation techniques for applying to other projects. We showed the evaluation result based on open source projects.},
booktitle = {Proceedings of the 4th International Workshop on Predictor Models in Software Engineering},
pages = {19–24},
numpages = {6},
keywords = {error prone, inter language prediction, metrics, open source},
location = {Leipzig, Germany},
series = {PROMISE '08}
}

@inproceedings{10.1007/978-3-030-55789-8_25,
author = {Saeed, Faisal and Paul, Anand and Rho, Seungmin},
title = {Faster R-CNN Based Fault Detection in Industrial Images},
year = {2020},
isbn = {978-3-030-55788-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-55789-8_25},
doi = {10.1007/978-3-030-55789-8_25},
abstract = {Industry 4.0 requires smart environment to find defects or faults in their products. A defective product in the market can impact negatively on the overall image of the industry. Thus, there is continuous struggle for industrial environment to reduce impulsive downtime, concert deprivation and safety risks. Defect detection in industrial products using the images is very hot topic in era of current research. Machine learning provides various solution but most of the time such solutions are not suitable for environment where product is on conveyor belt and traveling from one point to another. To detect fault using industrial images, we proposed a method which is based on Faster R-CNN which is suitable for smart environment as it can the product efficiently. We simulated our environment using python language and proposed model has almost 99% accuracy. To make our proposed scheme adaptable for the industry 4.0, we also developed an android application which make it easy to interact with the model and industry can train this model according to their needs. Android application is able to take pictures of defective product and feed it to model which improve accuracy and eventually reduces time identify defective product.},
booktitle = {Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices: 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020, Kitakyushu, Japan, September 22-25, 2020, Proceedings},
pages = {280–287},
numpages = {8},
keywords = {RPN, Fast R-CNN, Convolution neural networks, Fault identification, Defect detection, Industrial images},
location = {Kitakyushu, Japan}
}

@inproceedings{10.1145/2915970.2915979,
author = {Petri\'{c}, Jean},
title = {Using different characteristics of machine learners to identify different defect families},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2915979},
doi = {10.1145/2915970.2915979},
abstract = {Background: Software defect prediction has been an active area of research for the last few decades. Many models have been developed with aim to find locations in code likely to contain defects. As of yet, these prediction models are of limited use and rarely used in the software industry.Problem: Current modelling techniques are too coarse grained and fail in finding some defects. Most of the prediction models do not look for targeted defect characteristics, but rather treat them as a black box and homogeneous. No study has investigated in greater detail how well certain defect characteristics work with different prediction modelling techniques.Methodology: This PhD will address three major tasks. First, the relation among software defects, prediction models and static code metrics will be analysed. Second, the possibility of a mapping function between prediction models and defect characteristics shall be investigated. Third, an optimised ensemble model that searches for targeted defects will be developed.Contribution: A few contributions will yield from this work. Characteristics of defects will be identified, allowing other researchers to build on this work to produce more efficient prediction models in future. New modelling techniques that better suit state-of-the-art knowledge in defect prediction shall be designed. Such prediction models should be transformed in a tool that can be used by our industrial collaborator in the real industry environment.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {5},
numpages = {4},
keywords = {software defect prediction, prediction modeling, machine learning},
location = {Limerick, Ireland},
series = {EASE '16}
}

@article{10.5555/1375858.1375890,
author = {Nacereddine, N. and Hamami, L. and Ziou, D.},
title = {Thresholding techniques and their performance evaluation for weld defect detection in radiographic testing},
year = {2006},
issue_date = {February 2006},
publisher = {Polish Academy of Sciences},
address = {POL},
volume = {15},
number = {3},
issn = {1230-0535},
abstract = {In non-destructive testing with radiography, a perfect knowledge of the weld defect shape is an essential step to appreciate the quality of the weld and make decision on its acceptance or rejection. Because of the complex nature of the considered images, and in order that the detected defect region represent the real defect as accurately as possible, the choice of the thresholding methods must be made judiciously. In this paper, performance criteria are used to conduct a comparative study of the thresholding methods based on the gray level histogram, the 2D histogram and the locally adaptive approach to weld defect detection in radiographic images.},
journal = {MG&amp;V},
month = jan,
pages = {557–566},
numpages = {10},
keywords = {weld defect, thresholding, radiographic image, performance criteria, locally adaptive approach, 1D and 2D histogram}
}

@article{10.5555/1283100.1283173,
author = {Qu, Gongyuan and Wood, Sally L. and Teh, Cho},
title = {Wafer defect detection using directional morphological gradient techniques},
year = {2002},
issue_date = {January 2002},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2002},
number = {1},
issn = {1110-8657},
abstract = {Accurate detection and classification of wafer defects constitute an important component of the IC production process because together they can immediately improve the yield and also provide information needed for future process improvements. One class of inspection procedures involves analyzing surface images. Because of the characteristics of the design patterns and the irregular size and shape of the defects, linear processing methods, such as Fourier transform domain filtering or Sobel edge detection, are not as well suited as morphological methods for detecting these defects. In this paper, a newly developed morphological gradient technique using directional components is applied to the detection and isolation of wafer defects. The new methods are computationally efficient and do not rely on a priori knowledge of the specific design pattern to detect particles, scratches, stains, or missing pattern areas. The directional components of the morphological gradient technique allow direction specific edge suppression and reduce the noise sensitivity. Theoretical analysis and several examples are used to demonstrate the performance of the directional morphological gradient methods.},
journal = {EURASIP J. Adv. Signal Process},
month = jan,
pages = {686–703},
numpages = {18},
keywords = {wafer inspection, morphological gradient, edge orientation, edge detection}
}

@article{10.1007/s11219-020-09525-y,
author = {Malhotra, Ruchika and Lata, Kusum},
title = {An empirical study on predictability of software maintainability using imbalanced data},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09525-y},
doi = {10.1007/s11219-020-09525-y},
abstract = {In software engineering predictive modeling, early prediction of software modules or classes that possess high maintainability effort is a challenging task. Many prediction models are constructed to predict the maintainability of software classes or modules by applying various machine learning (ML) techniques. If the software modules or classes need&nbsp;high maintainability, effort would be reduced&nbsp;in a dataset, and&nbsp;there would be imbalanced data to train the model. The imbalanced datasets make&nbsp;ML techniques bias their predictions towards low maintainability effort or majority classes, and minority class instances get discarded as noise by the machine learning (ML) techniques. In this direction, this paper presents empirical work to improve the performance of software maintainability prediction (SMP) models developed with ML techniques using imbalanced data. For developing the models, the imbalanced data is pre-processed by applying data resampling methods. Fourteen data resampling methods, including oversampling, undersampling, and hybrid resampling, are used in the study. The study results recommend that the safe-level synthetic minority oversampling technique (Safe-Level-SMOTE) is a useful method to deal with the imbalanced datasets and to develop competent prediction models to forecast software maintainability.},
journal = {Software Quality Journal},
month = dec,
pages = {1581–1614},
numpages = {34},
keywords = {Imbalanced learning, Data resampling, Machine learning, Software maintainability prediction}
}

@inproceedings{10.1145/3368089.3417062,
author = {Suh, Alexander},
title = {Adapting bug prediction models to predict reverted commits at Wayfair},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3417062},
doi = {10.1145/3368089.3417062},
abstract = {Researchers have proposed many algorithms to predict software bugs. Given a software entity (e.g., a file or method), these algorithms predict whether the entity is bug-prone. However, since these algorithms cannot identify specific bugs, this does not tend to be particularly useful in practice. In this work, we adapt this prior work to the related problem of predicting whether a commit is likely to be reverted. Given the batch nature of continuous integration deployment at scale, this allows developers to find time-sensitive bugs in production more quickly. The models in this paper are based on features extracted from the revision history of a codebase that are typically used in bug prediction. Our experiments, performed on the three main repositories for the Wayfair website, show that our models can rank reverted commits above 80% of non-reverted commits on average. Moreover, when given to Wayfair developers, our models reduce the amount of time needed to find certain kinds of bugs by 55%. Wayfair continues to use our findings and models today to help find bugs during software deployments.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1251–1262},
numpages = {12},
keywords = {software deployment, software defect prediction, reverted commits},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/1188895.1188911,
author = {Baah, George K. and Gray, Alexander and Harrold, Mary Jean},
title = {On-line anomaly detection of deployed software: a statistical machine learning approach},
year = {2006},
isbn = {1595935843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1188895.1188911},
doi = {10.1145/1188895.1188911},
abstract = {This paper presents a new machine-learning technique that performs anomaly detection as software is executing in the field. The technique uses a fully observable Markov model where each state in the model emits a number of distinct observations according to a probability distribution, and estimates the model parameters using the Baum-Welch algorithm. The trained model is then deployed with the software to perform anomaly detection. By performing the anomaly detection as the software is executing, faults associated with anomalies can be located and fixed before they cause critical failures in the system, and developers time to debug deployed software can be reduced. This paper also presents a prototype implementation of our technique, along with a case study that shows, for the subjects we studied, the effectiveness of the technique.},
booktitle = {Proceedings of the 3rd International Workshop on Software Quality Assurance},
pages = {70–77},
numpages = {8},
keywords = {machine learning, fault localization, anomaly diagnosis, anomaly detection, Markov models},
location = {Portland, Oregon},
series = {SOQUA '06}
}

@article{10.1016/j.jss.2009.06.036,
author = {Binkley, David and Feild, Henry and Lawrie, Dawn and Pighin, Maurizio},
title = {Increasing diversity: Natural language measures for software fault prediction},
year = {2009},
issue_date = {November, 2009},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {82},
number = {11},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2009.06.036},
doi = {10.1016/j.jss.2009.06.036},
abstract = {While challenging, the ability to predict faulty modules of a program is valuable to a software project because it can reduce the cost of software development, as well as software maintenance and evolution. Three language-processing based measures are introduced and applied to the problem of fault prediction. The first measure is based on the usage of natural language in a program's identifiers. The second measure concerns the conciseness and consistency of identifiers. The third measure, referred to as the QALP score, makes use of techniques from information retrieval to judge software quality. The QALP score has been shown to correlate with human judgments of software quality. Two case studies consider the language processing measures applicability to fault prediction using two programs (one open source, one proprietary). Linear mixed-effects regression models are used to identify relationships between defects and the measures. Results, while complex, show that language processing measures improve fault prediction, especially when used in combination. Overall, the models explain one-third and two-thirds of the faults in the two case studies. Consistent with other uses of language processing, the value of the three measures increases with the size of the program module considered.},
journal = {J. Syst. Softw.},
month = nov,
pages = {1793–1803},
numpages = {11},
keywords = {Linear regression models, Information retrieval, Fault prediction, Empirical software engineering, Code comprehension}
}

@inproceedings{10.5555/1890580.1890595,
author = {Zhong, Shi and Khoshgoftaar, Taghi M. and Seliya, Naeem},
title = {Unsupervised learning for expert-based software quality estimation},
year = {2004},
isbn = {0769520944},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Current software quality estimation models often involve using supervised learning methods to train a software quality classifier or a software fault prediction model. In such models, the dependent variable is a software quality measurement indicating the quality of a software module by either a risk-based class membership (e.g., whether it is fault-prone or not fault-prone) or the number of faults. In reality, such a measurement may be inaccurate, or even unavailable. In such situations, this paper advocates the use of unsupervised learning (i.e., clustering) techniques to build a software quality estimation system, with the help of a software engineering human expert. The system first clusters hundreds of software modules into a small number of coherent groups and presents the representative of each group to a software quality expert, who labels each cluster as either fault-prone or not fault-prone based on his domain knowledge as well as some data statistics (without any knowledge of the dependent variable, i.e., the software quality measurement). Our preliminary empirical results show promising potentials of this methodology in both predicting software quality and detecting potential noise in a software measurement and quality dataset.},
booktitle = {Proceedings of the Eighth IEEE International Conference on High Assurance Systems Engineering},
pages = {149–155},
numpages = {7},
location = {Tampa, Florida},
series = {HASE'04}
}

@article{10.1016/j.vlsi.2021.08.004,
author = {Saidi, Afef and Ben Othman, Slim and Dhouibi, Meriam and Ben Saoud, Slim},
title = {FPGA-based implementation of classification techniques: A survey},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {81},
number = {C},
issn = {0167-9260},
url = {https://doi.org/10.1016/j.vlsi.2021.08.004},
doi = {10.1016/j.vlsi.2021.08.004},
journal = {Integr. VLSI J.},
month = nov,
pages = {280–299},
numpages = {20},
keywords = {Challenges, Optimizations, Implementation, Classification, Deep learning, Machine learning}
}

@inproceedings{10.1109/ICPR.2006.709,
author = {Tsai, Du-Ming and Tseng, Yan-Hsin and Chao, Shin-Min and Yen, Chao-Hsuan},
title = {Independent component analysis based filter design for defect detection in low-contrast textured images},
year = {2006},
isbn = {0769525210},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICPR.2006.709},
doi = {10.1109/ICPR.2006.709},
abstract = {In this paper, we propose a convolution filtering scheme for detecting defects in low-contrast textured surface images and, especially, focus on the application for glass substrates in Liquid Crystal Display (LCD) manufacturing. A defect embedded in a low-contrast surface image shows no distinct intensity from its surrounding region, and even worse, the sensed image may present uneven brightness on the surface. All these make the defect detection in lowcontrast surface images extremely difficult. In this study, a constrained ICA (independent component analysis) model is proposed to design an optimal filter with the objective that the convolution filter will generate the most representative source intensity of the background surface without noise. The prior constraint incorporated in the ICA model confines the source values of all training image patches of a defect-free image within a small interval of control limits. In the inspection process, the same control parameter used in the constraint is also applied to set up the thresholds that make impulse responses of all pixels in faultless regions within the control limits, and those in defective regions outside the control limits. A stochastic evolutionary computation algorithm, particle swarm optimization (PSO), is applied to solve for the constrained ICA model. Experimental results have shown that the proposed method can effectively detect defects in textured LCD glass substrate images.},
booktitle = {Proceedings of the 18th International Conference on Pattern Recognition - Volume 02},
pages = {231–234},
numpages = {4},
series = {ICPR '06}
}

@inproceedings{10.1007/978-3-030-63830-6_12,
author = {Lopes, Vasco and Alexandre, Lu\'{\i}s A.},
title = {Auto-Classifier: A Robust Defect Detector Based on an AutoML Head},
year = {2020},
isbn = {978-3-030-63829-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-63830-6_12},
doi = {10.1007/978-3-030-63830-6_12},
abstract = {The dominant approach for surface defect detection is the use of hand-crafted feature-based methods. However, this falls short when conditions vary that affect extracted images. So, in this paper, we sought to determine how well several state-of-the-art Convolutional Neural Networks perform in the task of surface defect detection. Moreover, we propose two methods: CNN-Fusion, that fuses the prediction of all the networks into a final one, and Auto-Classifier, which is a novel proposal that improves a Convolutional Neural Network by modifying its classification component using AutoML. We carried out experiments to evaluate the proposed methods in the task of surface defect detection using different datasets from DAGM2007. We show that the use of Convolutional Neural Networks achieves better results than traditional methods, and also, that Auto-Classifier out-performs all other methods, by achieving 100% accuracy and 100% AUC results throughout all the datasets.},
booktitle = {Neural Information Processing: 27th International Conference, ICONIP 2020, Bangkok, Thailand, November 23–27, 2020, Proceedings, Part I},
pages = {137–149},
numpages = {13},
keywords = {Defect detection, CNNs, Deep learning, AutoML},
location = {Bangkok, Thailand}
}

@inproceedings{10.1145/3460945.3464954,
author = {Hasabnis, Niranjan and Gottschlich, Justin},
title = {ControlFlag: a self-supervised idiosyncratic pattern detection system for software control structures},
year = {2021},
isbn = {9781450384674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460945.3464954},
doi = {10.1145/3460945.3464954},
abstract = {Software debugging has been shown to utilize upwards of half of developers’ time. Yet, machine programming (MP), the field concerned with the automation of software (and hardware) development, has recently made strides in both research and production-quality automated debugging systems. In this paper we present ControlFlag, a self-supervised MP system that aims to improve debugging by attempting to detect idiosyncratic pattern violations in software control structures. ControlFlag also suggests possible corrections in the event an anomalous pattern is detected. We present ControlFlag’s design and provide an experimental evaluation and analysis of its efficacy in identifying potential programming errors in production-quality software. As a first concrete evidence towards improving software quality, ControlFlag has already found an anomaly in CURL that has been acknowledged and fixed by its developers. We also discuss future extensions of ControlFlag.},
booktitle = {Proceedings of the 5th ACM SIGPLAN International Symposium on Machine Programming},
pages = {32–42},
numpages = {11},
keywords = {self-supervised learning, Source-code mining},
location = {Virtual, Canada},
series = {MAPS 2021}
}

@article{10.1007/s11042-021-11084-8,
author = {Wang, Jin and Yu, Zhiyong and Duan, Zhizhao and Lu, Guodong},
title = {A sub-region one-to-one mapping (SOM) detection algorithm for glass passivation parts wafer surface low-contrast texture defects},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {19},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-021-11084-8},
doi = {10.1007/s11042-021-11084-8},
abstract = {Glass Passivation Parts (GPP) wafer texture defects are one of the most important factors affecting the accuracy of wafer defect detection. Template matching has local errors and low efficiency, and deep learning requires many training samples. In the early stage, defect training sample sets cannot be provided. This paper discusses the design of an effective GPP wafer grain region texture defect detection algorithm using a sub-region one-to-one mapping. A set of standard wafer datum is selected as the reference of grain region segmentation detection, and then the standard wafer images and test GPP wafer images are automatically calibrated and segmented, respectively. Then, a series of pre-processes were performed to equalize the sizes of the two grain-region images. Then the grain region was divided into an equal number of rectangular sub-regions of the same size according to the measurement precision requirement. The correlation degree of each test sub-region is judged by the designed three-channel RGB gray-scale similarity decision functions. Experiments show that the algorithm successfully achieved the necessary calibration and segmentation for the grain region. Compared with the template and histogram matching algorithms, the proposed method does not require a training set, the detection accuracy is significantly improved and the detection efficiency is up to 29.74 times better on average using the proposed algorithm.},
journal = {Multimedia Tools Appl.},
month = aug,
pages = {28879–28896},
numpages = {18},
keywords = {Defect detection, Feature extraction, Sub-region mapping, Image matching, Texture features, GPP wafer detection}
}

@article{10.1016/j.eswa.2017.04.014,
author = {Rathore, Santosh Singh and Kumar, Sandeep},
title = {Towards an ensemble based system for predicting the number of software faults},
year = {2017},
issue_date = {October 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {82},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2017.04.014},
doi = {10.1016/j.eswa.2017.04.014},
abstract = {Paper presents ensemble based system for the prediction of number of software faults.System is based on the heterogeneous ensemble method.System uses three fault prediction techniques as base learners for the ensemble.Results are verified on Eclipse datasets. Software fault prediction using different techniques has been done by various researchers previously. It is observed that the performance of these techniques varied from dataset to dataset, which make them inconsistent for fault prediction in the unknown software project. On the other hand, use of ensemble method for software fault prediction can be very effective, as it takes the advantage of different techniques for the given dataset to come up with better prediction results compared to individual technique. Many works are available on binary class software fault prediction (faulty or non-faulty prediction) using ensemble methods, but the use of ensemble methods for the prediction of number of faults has not been explored so far. The objective of this work is to present a system using the ensemble of various learning techniques for predicting the number of faults in given software modules. We present a heterogeneous ensemble method for the prediction of number of faults and use a linear combination rule and a non-linear combination rule based approaches for the ensemble. The study is designed and conducted for different software fault datasets accumulated from the publicly available data repositories. The results indicate that the presented system predicted number of faults with higher accuracy. The results are consistent across all the datasets. We also use prediction at level l (Pred(l)), and measure of completeness to evaluate the results. Pred(l) shows the number of modules in a dataset for which average relative error value is less than or equal to a threshold value l. The results of prediction at level l analysis and measure of completeness analysis have also confirmed the effectiveness of the presented system for the prediction of number of faults. Compared to the single fault prediction technique, ensemble methods produced improved performance for the prediction of number of software faults. Main impact of this work is to allow better utilization of testing resources helping in early and quick identification of most of the faults in the software system.},
journal = {Expert Syst. Appl.},
month = oct,
pages = {357–382},
numpages = {26},
keywords = {Software fault prediction techniques, Promise repository, Linear regression, Gradient boosting, Genetic programming, Empirical study}
}

@inproceedings{10.1145/3468264.3477221,
author = {Winkler, Jordan and Agarwal, Abhimanyu and Tung, Caleb and Ugalde, Dario Rios and Jung, Young Jin and Davis, James C.},
title = {A replication of ‘DeepBugs: a learning approach to name-based bug detection’},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3477221},
doi = {10.1145/3468264.3477221},
abstract = {We replicated the main result of DeepBugs, a bug detection algorithm for name-based bugs. The original authors evaluated it in three contexts: swapped-argument bugs, wrong binary operator,and wrong binary operator operands. We followed the algorithm and replicated the results for swapped-argument bugs. Our replication used independent implementations of the major components: training set generation, token vectorization, and neural network data pipeline, model, and loss function. Using the same dataset and the same testing process, we report comparable performance: within 2% of the accuracy reported by Pradel and Sen.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1604},
numpages = {1},
keywords = {replication, machine learning, deep learning, Defect detection},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@article{10.1007/s10515-013-0129-8,
author = {Bowes, David and Hall, Tracy and Gray, David},
title = {DConfusion: a technique to allow cross study performance evaluation of fault prediction studies},
year = {2014},
issue_date = {April     2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-013-0129-8},
doi = {10.1007/s10515-013-0129-8},
abstract = {There are many hundreds of fault prediction models published in the literature. The predictive performance of these models is often reported using a variety of different measures. Most performance measures are not directly comparable. This lack of comparability means that it is often difficult to evaluate the performance of one model against another. Our aim is to present an approach that allows other researchers and practitioners to transform many performance measures back into a confusion matrix. Once performance is expressed in a confusion matrix alternative preferred performance measures can then be derived. Our approach has enabled us to compare the performance of 600 models published in 42 studies. We demonstrate the application of our approach on 8 case studies, and discuss the advantages and implications of doing this.},
journal = {Automated Software Engg.},
month = apr,
pages = {287–313},
numpages = {27},
keywords = {Machine learning, Fault, Confusion matrix}
}

@article{10.1016/j.procs.2021.08.013,
author = {Tomescu, Vlad-Ioan and Czibula, Gabriela and Ni\c{t}ic\u{a}, \c{S}tefan},
title = {A study on using deep autoencoders for imbalanced binary classification},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {192},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.08.013},
doi = {10.1016/j.procs.2021.08.013},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {119–128},
numpages = {10},
keywords = {68T10, 2000 MSC: 68T07, Breast cancer detection, Autoencoders, Deep learning, Imbalanced classification}
}

@article{10.1016/j.patcog.2016.11.021,
author = {Hanzaei, Saeed Hosseinzadeh and Afshar, Ahmad and Barazandeh, Farshad},
title = {Automatic detection and classification of the ceramic tiles surface defects},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {66},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2016.11.021},
doi = {10.1016/j.patcog.2016.11.021},
abstract = {Defect detection and classification of ceramic tile surface defects occurred in firing units are usually performed by human observations in most factories. In this paper, an automatic image processing system with high accuracy and time efficient approaches is presented. To this end, first, for defect detection, Rotation Invariant Measure of Local Variance (RIMLV) operator from statistical methods is employed for defect edges detection, and cooperatively a Close morphological operator from structural methods is used to fill and smooth detected regions. Then, all the detected defects of one ceramic tile are labeled, and the corresponding geometric features are extracted. Finally, a multi-class support vector machine classifier with winner-takes-all strategy based on statistical pattern recognition theories is employed to identify the defect type. The production process of Ceramic Tiles (CTs) includes various stages such as forming body of CTs, glazing and decorating, and firing.The main CTs defects occur in firing unit because of the many effective variables especially the temperature of kiln. For instance, these defects are combination of glaze and decorative pattern because of the exceeded air pressure in kiln, or are dimensional faults because of the improper velocity rate of roller conveyers in kiln. A sample of these defects and their reasons has been attached.It is very clear that the main specification of a CT is its surface quality; and in firing unit, the glaze is baked on CTs body to create the glassed surface. Hence, the unsuitable temperature circumstance along the roller kilns effects on surfaces of CTs and causes the surface defects.},
journal = {Pattern Recogn.},
month = jun,
pages = {174–189},
numpages = {16},
keywords = {Surface defects, Feature extraction, Defect labeling, Defect detection, Classification, Ceramic tile}
}

@inproceedings{10.5555/648287.756369,
author = {Eisele, Heiko and Hamprecht, Fred A.},
title = {A New Approach for Defect Detection in X-ray CT Images},
year = {2002},
isbn = {354044209X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We introduce a novel method to automatically evaluate X-ray computed tomography (CT) images for the purpose of detecting material defects by evaluating the significance of features extracted by first order derivative filters. We estimate the noise of the original image and compute the noise of the filtered image via error propagation. The significance of these features can then be evaluated based on the signal-to-noise ratio in the filtered image. The major benefit of that procedure is, that a sample-independent threshold on the signal-to-noise ratio can be chosen. The results are demonstrated on parts drawn from an industrial manufacturing line.},
booktitle = {Proceedings of the 24th DAGM Symposium on Pattern Recognition},
pages = {345–352},
numpages = {8}
}

@article{10.1007/s11277-019-06238-9,
author = {Padmakumari, P. and Umamakeswari, A.},
title = {Task Failure Prediction using Combine Bagging Ensemble (CBE) Classification in Cloud Workflow},
year = {2019},
issue_date = {Jul 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {107},
number = {1},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-019-06238-9},
doi = {10.1007/s11277-019-06238-9},
abstract = {Scientific applications adopt cloud environment for executing its workflows as tasks. When a task fails, dependency nature of the workflows affects the overall performance of the execution. An efficient failure prediction mechanism is needed to execute the workflow efficiently. This paper proposes a failure prediction method which is implemented using various machine learning classifiers. Among different classifiers, Na\"{\i}ve Bayes predicts the failure with the highest accuracy of 94.4%. Further, to improve the accuracy of prediction, a novel ensemble method called combine bagging ensemble is introduced and acquires overall accuracy as 95.8%. The validation of proposed method is carried out by comparing simulation and real-time cloud testbed.},
journal = {Wirel. Pers. Commun.},
month = jul,
pages = {23–40},
numpages = {18},
keywords = {Task failure, Scientific workflow, Machine learning, Fault prediction, Ensemble, Cloud computing}
}

@article{10.1007/s10115-021-01560-w,
author = {Brzezinski, Dariusz and Minku, Leandro L. and Pewinski, Tomasz and Stefanowski, Jerzy and Szumaczuk, Artur},
title = {The impact of data difficulty factors on classification of imbalanced and concept drifting data streams},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {63},
number = {6},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-021-01560-w},
doi = {10.1007/s10115-021-01560-w},
abstract = {Class imbalance introduces additional challenges when learning classifiers from concept drifting data streams. Most existing work focuses on designing new algorithms for dealing with the global imbalance ratio and does not consider other data complexities. Independent research on static imbalanced data has highlighted the influential role of local data difficulty factors such as minority class decomposition and presence of unsafe types of examples. Despite often being present in real-world data, the interactions between concept drifts and local data difficulty factors have not been investigated in concept drifting data streams yet. We thoroughly study the impact of such interactions on drifting imbalanced streams. For this purpose, we put forward a new categorization of concept drifts for class imbalanced problems. Through comprehensive experiments with synthetic and real data streams, we study the influence of concept drifts, global class imbalance, local data difficulty factors, and their combinations, on predictions of representative online classifiers. Experimental results reveal the high influence of new considered factors and their local drifts, as well as differences in existing classifiers’ reactions to such factors. Combinations of multiple factors are the most challenging for classifiers. Although existing classifiers are partially capable of coping with global class imbalance, new approaches are needed to address challenges posed by imbalanced data streams.},
journal = {Knowl. Inf. Syst.},
month = jun,
pages = {1429–1469},
numpages = {41},
keywords = {Stream classification, Drift categorization, Data difficulty factors, Concept drift, Class imbalance}
}

@inproceedings{10.1145/2184751.2184798,
author = {Rao, G. Subrahmanya Vrk and Diwanji, Vivek and Parthasarathi, Jinka},
title = {Application case study of machine learning techniques towards a fault diagnosis system for a manufacturing plant environment},
year = {2012},
isbn = {9781450311724},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2184751.2184798},
doi = {10.1145/2184751.2184798},
abstract = {Fault diagnosis is a vital problem in process engineering. It is the fundamental component of anomalous event management (AEM) which has attracted a lot of attention over recent years. AEM deals with the timely detection, diagnosis and correction of abnormal conditions of faults in a process. Early detection and diagnosis of process faults while the plant is still operating in a controllable region can help avoid anomalous event evolution, improve uptime and reduce efficiency loss. There is a great quantity of literature on process fault diagnosis ranging from analytical methods to artificial intelligence and statistical approaches. From a modeling perspective, there are methods that require accurate process models, semi-quantitative models, or qualitative models. At the other end of the gamut, there are methods that do not assume any form of model information and rely only on historical process data. In this paper we present the performance of few approaches of data driven modeling/machine learning techniques on the simulated data from a distillation column.},
booktitle = {Proceedings of the 6th International Conference on Ubiquitous Information Management and Communication},
articleno = {38},
numpages = {4},
keywords = {support vector machine, process industries, pattern discovery, na\"{\i}ve Bayesian, fault diagnosis, data mining, artificial intelligence},
location = {Kuala Lumpur, Malaysia},
series = {ICUIMC '12}
}

@article{10.1016/j.asoc.2021.107870,
author = {Kabir, Md Alamgir and Keung, Jacky and Turhan, Burak and Bennin, Kwabena Ebo},
title = {Inter-release defect prediction with feature selection using temporal chunk-based learning: An empirical study},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {113},
number = {PA},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107870},
doi = {10.1016/j.asoc.2021.107870},
journal = {Appl. Soft Comput.},
month = dec,
numpages = {17},
keywords = {Feature selection, Inter-release defect prediction, Software defect prediction}
}

@article{10.1007/s10845-018-1412-0,
author = {Aminzadeh, Masoumeh and Kurfess, Thomas R.},
title = {Online quality inspection using Bayesian classification in powder-bed additive manufacturing from high-resolution visual camera images},
year = {2019},
issue_date = {August    2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {6},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-018-1412-0},
doi = {10.1007/s10845-018-1412-0},
abstract = {Despite their advances and numerous benefits, metal powder-bed additive manufacturing (AM) processes still suffer from the high chances of defect formation and a need for improved quality. This work develops an online monitoring system for quality of fusion and defect formation in every layer of the laser powder-bed fusion process using computer vision and Bayesian inference. An imaging setup is developed that for the first time allows capturing in-situ (during the build) images from every layer that visualize detailed layer defects and porosity. A database of camera images from every layer of AM parts made with various part quality was created that is the first visual labeled dataset from in-situ visual images of the powder-bed AM (also visualizing detailed layer features). The dataset is used in training-based classification to detect layers or sub-regions of the layer with low quality of fusion or defects. Features are carefully selected based on physical intuition into the process and extracted from the images of the various types of builds. A Bayesian classifier is developed and trained to classify the quality of the build that signifies the defective and unacceptable build layers or regions. The results can be used for quasi-real-time (layer-wise) process control, further process decisions, or corrective actions.},
journal = {J. Intell. Manuf.},
month = aug,
pages = {2505–2523},
numpages = {19},
keywords = {Supervised learning, Online quality inspection, Metal powder-bed additive manufacturing, Laser powder-bed fusion, In-situ defect detection, Feature-based classification, Computer vision, Bayesian inference, Additive manufacturing, 3D printing}
}

@inproceedings{10.5555/3507788.3507833,
author = {M\"{u}ller, Hausi A. and Rivera, Luis F. and Jim\'{e}nez, Miguel and Villegas, Norha M. and Tamura, Gabriel and Akkiraju, Rama and Watts, Ian and Erpenbach, Eric},
title = {Proactive AIOps through digital twins},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {The rise of advanced IT environments (IT ·Envs) that meet ever increasing user expectations on software quality necessitates innovative practices in the development and operation of software-intensive systems. DevOps teams find themselves searching for ways to deliver value by attacking operational challenges that tend to overwhelm human capabilities. Most of these challenges relate to the structural and behavioural complexities of modern IT·Envs. While the former concerns the orchestration of multiple technologies, the latter involves the exploitation of the huge data streams produced that are integral to DevOps activities. As automation, autonomy, and artificial intelligence technologies are maturing and permeating various activities in the software development lifecycle, opportunities arise from their integration with DevOps practices to improve risk mitigation, root cause analysis, problem resolution, and operational optimization in IT·Envs. This CASCON x EVOKE 2021 workshop discussed challenges and opportunities in developing proactive AIOps through digital twin technologies.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {275–276},
numpages = {2},
keywords = {machine learning, fault prediction, digital twins, cloud, IT operations, DevOps, AIOps, AI},
location = {Toronto, Canada},
series = {CASCON '21}
}

@article{10.1016/j.procs.2019.09.156,
author = {Czibula, Gabriela and Mihai, Andrei and Crivei, Liana Maria},
title = {S PRAR: A novel relational association rule mining classification model applied for academic performance prediction},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {159},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.09.156},
doi = {10.1016/j.procs.2019.09.156},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {20–29},
numpages = {10},
keywords = {68P15, Relational association rules 2000 MSC: 68T05, Supervised learning, Students’ performance prediction, Educational data mining}
}

@phdthesis{10.5555/AAI29116300,
author = {Coates, Eyler Robert},
advisor = {Warren, Liao, T.},
title = {Internal Defect Detection in Hardwood Logs with Fast Magnetic Resonance Imaging},
year = {1998},
isbn = {9798438712053},
publisher = {Louisiana State University and Agricultural &amp; Mechanical College},
abstract = {Identification of defects such as knots in logs before the cutting operation would allow lumber mills to maximize the value of lumber from each log. This dissertation presented images obtained from scanning an oak log with magnetic resonance imaging (MRI). The unique characteristics of MRI images of hardwood logs were noted and were used to derive a quick algorithm to isolate defects. Defect regions had some pixels that varied considerably in intensity from their neighborhood, providing a seed for initiating the defect region. There was an overlap between the pixel gray level of the defects and clear wood. Therefore, traditional thresholding techniques did not cleanly separate these regions. In this study, region-growing methods were used to extract the defects. The algorithm grew the defect region seed until the border-pixel gray levels approached the average level of the neighborhood. The region-growing methods obtained more accurate defect regions than thresholding methods because of the simultaneous consideration of gray level and adjacency information.Two methods of MRI imaging were considered: spin-echo and echo-planar. Spin-echo imaging provided clear, detailed images but required about 20 seconds of acquisition time, which was too slow to be used in a production environment. Echo-planar images could be acquired in about 1/2 second, which was fast enough for production, but the images were fuzzy and noisy.The dissertation presented an algorithm that found the defect regions in spin-echo images. Region-growing methods use a number of parameters and the best parameters were unique for each image. However, common image statistics could be used to predict the proper parameters.The dissertation also presented an algorithm that found most of the defect regions in echo-planar images. Enhancing the echo-planar images using common general-purpose image-enhancement techniques failed because the lack of discrimination allowed the process to smooth image structures as well as noise. By taking advantage of the structure of a tree, smoothing between MRI frames accomplished the goal of smoothing along homogeneous areas and not across image structures. This "z-axis" smoothing enhanced the echo-planar image visually and reduced the number of false alarm defect regions.},
note = {AAI29116300}
}

@article{10.1007/s10515-021-00285-y,
author = {Goyal, Somya},
title = {Predicting the Defects using Stacked Ensemble Learner with Filtered Dataset},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-021-00285-y},
doi = {10.1007/s10515-021-00285-y},
abstract = {Software defect prediction is a crucial software project management activity to enhance the software quality. It aids the development team to forecast about which modules need extra attention for testing; which part of software is more prone to errors and faults; before the commencement of testing phase. It helps to reduce the testing cost and hence the overall development cost of the software. Though, it ensures in-time delivery of good quality end-product, but there is one major hinderance in making this prediction. This is the class imbalance issue in the training data. Data imbalance in class distribution adversely affects the performance of classifiers. This paper proposes a K-nearest neighbour (KNN) filtering-based data pre-processing technique for stacked ensemble classifier to handle class imbalance issue. First, nearest neighbour-based filtering is applied to filter out the overlapped data-points to reduce Imbalanced Ratio, then, the processed data with static code metrics is supplied to stacked ensemble for prediction. The stacking is achieved with five base classifiers namely Artificial Neural Network, Decision Tree, Na\"{\i}ve Bayes, K-nearest neighbour (KNN) and Support Vector Machine. A comparative analysis among 30 classifiers (5 data pre-processing techniques * 6 prediction techniques) is made. In the experiments, five public datasets from NASA repository namely CM1, JM1, KC1, KC2 and PC1 are used. In total 150 prediction models (5 data pre-processing techniques * 6 classification techniques * 5 datasets) are proposed and their performances are assessed in terms of measures namely Receiver Operator Curve, Area under the Curve and accuracy. The statistical analysis shows that proposed stacked ensemble classifier with KNN filtering performs best among all the predictors independent of datasets.},
journal = {Automated Software Engg.},
month = nov,
numpages = {81},
keywords = {ROC and AUC, Support vector machine, Nearest neighbour, Decision trees, Stacked ensembles, Artificial neural networks (ANN), Class imbalance, Data pre-processing, Defect prediction, Software quality}
}

@article{10.3233/JIFS-202614,
author = {Liu, Hui and He, Boxia and He, Yong and Tao, Xiaotian},
title = {Lightweight detection algorithm for fine-grained surface defects of aerospace seal rings},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-202614},
doi = {10.3233/JIFS-202614},
abstract = {The existing seal ring surface defect detection methods for aerospace applications have the problems of low detection efficiency, strong specificity, large fine-grained classification errors, and unstable detection results. Considering these problems, a fine-grained seal ring surface defect detection algorithm for aerospace applications is proposed. Based on analysis of the stacking process of standard convolution, heat maps of original pixels in the receptive field participating in the convolution operation are quantified and generated. According to the generated heat map, the feature extraction optimization method of convolution combinations with different dilation rates is proposed, and an efficient convolution feature extraction network containing three kinds of dilated convolutions is designed. Combined with the O-ring surface defect features, a multiscale defect detection network is designed. Before the head of multiscale classification and position regression, feature fusion tree modules are added to ensure the reuse and compression of the responsive features of different receptive fields on the same scale feature maps. Experimental results show that on the O-rings-3000 testing dataset, the mean condition accuracy of the proposed algorithm reaches 95.10% for 5 types of surface defects of aerospace O-rings. Compared with RefineDet, the mean condition accuracy of the proposed algorithm is only reduced by 1.79%, while the parameters and FLOPs are reduced by 35.29% and 64.90%, respectively. Moreover, the proposed algorithm has good adaptability to image blur and light changes caused by the cutting of imaging hardware, thus saving the cost.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {11423–11440},
numpages = {18},
keywords = {O-rings, surface defect detection, multiscale classification, lightweight algorithm, feature extraction network, Deep learning}
}

@inproceedings{10.5555/1973598.1973711,
author = {Furferi, Rocco and Governi, Lapo},
title = {Machine vision tool for real-time defect detection and classification on circular knitting machines by using statistical parameters and radon transform},
year = {2006},
isbn = {9608457432},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
abstract = {This work presents a new highly automated artificial vision inspection (AVI) tool for real-time defect detection and classification on circular knitting machines based on the combination of statistical analysis, Image Processing and Radon Transform. The tool (software + hardware) is directly attached to a circular knitting machine and the inspection is performed on-line. The automatic inspection allows the detection and classification of the most frequently occurring types of defects on knitted fabrics, which are significant for purposes of quality control and fabric grading. The reliability of the detection tool is about 93% (defect detected vs. effectively existing defects).},
booktitle = {Proceedings of the 5th WSEAS International Conference on Applied Computer Science},
pages = {590–595},
numpages = {6},
keywords = {skewness, real time, radon transform, kurtosis, knitting machines, image processing},
location = {Hangzhou, China},
series = {ACOS'06}
}

@article{10.1016/j.knosys.2016.12.017,
author = {Rathore, Santosh Singh and Kumar, Sandeep},
title = {Linear and non-linear heterogeneous ensemble methods to predict the number of faults in software systems},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {119},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2016.12.017},
doi = {10.1016/j.knosys.2016.12.017},
abstract = {This paper expands the use of ensemble methods for the prediction of number of faults unlikely the earlier works on ensemble methods that focused on predicting software modules as faulty or non-faulty.This paper investigates the usage of both heterogeneous ensemble methods as well as homogeneous ensemble methods for the prediction of number of faults.We present two linear combination rules and two non-linear combination rules for combining the outputs of the base learners in the ensemble.In addition, we assess the performance of ensemble methods under two different scenarios, intra-release prediction and inter-releases prediction.The experiments are performed over five open-source software systems with their fifteen releases, collected from the PROMISE data repository. Several classification techniques have been investigated and evaluated earlier for the software fault prediction. These techniques have produced different prediction accuracy for the different software systems and none of the technique has always performed consistently better across different domains. On the other hand, software fault prediction using ensemble methods can be very effective, as they take the advantage of each participating technique for the given dataset and try to come up with better prediction results compared to the individual techniques. Many works are available for classifying software modules being faulty or non-faulty using the ensemble methods. These works are only specifying that whether a given software module is faulty or not, but number of faults in that module are not predicted by them. The use of ensemble methods for the prediction of number of faults has not been explored so far. To fulfill this gap, this paper presents ensemble methods for the prediction of number of faults in the given software modules. The experimental study is designed and conducted for five open-source software projects with their fifteen releases, collected from the PROMISE data repository. The results are evaluated under two different scenarios, intra-release prediction and inter-releases prediction. The prediction accuracy of ensemble methods is evaluated using absolute error, relative error, prediction at level l, and measure of completeness performance measures. Results show that the presented ensemble methods yield improved prediction accuracy over the individual fault prediction techniques under consideration. Further, the results are consistent for all the used datasets. The evidences obtained from the prediction at level l and measure of completeness analysis have also confirmed the effectiveness of the proposed ensemble methods for predicting the number of faults.},
journal = {Know.-Based Syst.},
month = mar,
pages = {232–256},
numpages = {25},
keywords = {Software fault prediction, Prediction of number of faults, Heterogeneous ensemble, Ensemble methods}
}

@inproceedings{10.1145/3461002.3473947,
author = {Pinnecke, Marcus},
title = {Product-lining the elinvar wealthtech microservice platform},
year = {2021},
isbn = {9781450384704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461002.3473947},
doi = {10.1145/3461002.3473947},
abstract = {Software product lining is the act of providing different but related software products under the same brand, known as a software product line (SPL). As engineering, management and validation of SPLs is far from trivial, special solutions for software product line engineering (SPLE) have a continuous momentum in both academic and industry. In general, it is hard to judge when to reasonably favor SPLE over alternative solutions that are more common in the industry. In this paper, we illustrate how we as Elinvar manage variability within our WealthTech Platform as a Service (PaaS) at different granularity levels, and discuss methods for SPLE in this context. More in detail, we share our techniques and concepts to address configuration management, and show how we manage a single microservice SPL including inter-service communication. Finally, we provide insights into platform solutions by means of packages for our clients. We end with a discussion on SPLE techniques in context of service SPLs and our packaging strategy. We conclude that while we are good to go with industry-standard approaches for microservice SPLs, the variability modeling and analysis advantages within SPLE is promising for our packaging strategy.},
booktitle = {Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B},
pages = {60–68},
numpages = {9},
keywords = {variability management, technologies and concepts, product families, microservice platforms, configuration management},
location = {Leicester, United Kindom},
series = {SPLC '21}
}

@article{10.1016/j.asoc.2021.107706,
author = {Aydin, Ilhan and Akin, Erhan and Karakose, Mehmet},
title = {Defect classification based on deep features for railway tracks in sustainable transportation},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {111},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107706},
doi = {10.1016/j.asoc.2021.107706},
journal = {Appl. Soft Comput.},
month = nov,
numpages = {14},
keywords = {Railway maintenance, Image processing, Deep learning, Visual inspection, Railway surface defect}
}

@article{10.1145/3381028,
author = {Boukerche, Azzedine and Zheng, Lining and Alfandi, Omar},
title = {Outlier Detection: Methods, Models, and Classification},
year = {2020},
issue_date = {May 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3381028},
doi = {10.1145/3381028},
abstract = {Over the past decade, we have witnessed an enormous amount of research effort dedicated to the design of efficient outlier detection techniques while taking into consideration efficiency, accuracy, high-dimensional data, and distributed environments, among other factors. In this article, we present and examine these characteristics, current solutions, as well as open challenges and future research directions in identifying new outlier detection strategies. We propose a taxonomy of the recently designed outlier detection strategies while underlying their fundamental characteristics and properties. We also introduce several newly trending outlier detection methods designed for high-dimensional data, data streams, big data, and minimally labeled data. Last, we review their advantages and limitations and then discuss future and new challenging issues.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {55},
numpages = {37},
keywords = {unsupervised learning, semi-supervised learning, anomaly detection, Outlier detection}
}

@article{10.1155/2020/8847651,
author = {Yang, Rui and Zhang, Yonglin and Deng, Zhenrong and Huang, Wenming and Lan, Rushi and Luo, Xiaonan and Zhou, Zhili},
title = {SK-FMYOLOV3: A Novel Detection Method for Urine Test Strips},
year = {2020},
issue_date = {2020},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2020},
issn = {1530-8669},
url = {https://doi.org/10.1155/2020/8847651},
doi = {10.1155/2020/8847651},
abstract = {To accurately detect small defects in urine test strips, the SK-FMYOLOV3 defect detection algorithm is proposed. First, the prediction box clustering algorithm of YOLOV3 is improved. The fuzzy C-means clustering algorithm is used to generate the initial clustering centers, and then, the clustering center is passed to the K-means algorithm to cluster the prediction boxes. To better detect smaller defects, the YOLOV3 feature map fusion is increased from the original three-scale prediction to a four-scale prediction. At the same time, 23 convolutional layers of size 3\texttimes{}3 in the YOLOV3 network are replaced with SkNet structures, so that different feature maps can independently select different convolution kernels for training, improving the accuracy of defect classification. We collected and enhanced urine test strip images in industrial production and labeled the small defects in the images. A total of 11634 image sets were used for training and testing. The experimental results show that the algorithm can obtain an anchor frame with an average cross ratio of 86.57, while the accuracy rate and recall rate of nonconforming products are 96.8 and 94.5, respectively. The algorithm can also accurately identify the category of defects in nonconforming products.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {14}
}

@article{10.1007/s10664-021-09984-2,
author = {Ulan, Maria and L\"{o}we, Welf and Ericsson, Morgan and Wingkvist, Anna},
title = {Weighted software metrics aggregation and its application to defect prediction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09984-2},
doi = {10.1007/s10664-021-09984-2},
abstract = {It is a well-known practice in software engineering to aggregate software metrics to assess software artifacts for various purposes, such as their maintainability or their proneness to contain bugs. For different purposes, different metrics might be relevant. However, weighting these software metrics according to their contribution to the respective purpose is a challenging task. Manual approaches based on experts do not scale with the number of metrics. Also, experts get confused if the metrics are not independent, which is rarely the case. Automated approaches based on supervised learning require reliable and generalizable training data, a ground truth, which is rarely available. We propose an automated approach to weighted metrics aggregation that is based on unsupervised learning. It sets metrics scores and their weights based on probability theory and aggregates them. To evaluate the effectiveness, we conducted two empirical studies on defect prediction, one on ca. 200 000 code changes, and another ca. 5 000 software classes. The results show that our approach can be used as an agnostic unsupervised predictor in the absence of a ground truth.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {34},
keywords = {Weighting, Aggregation, Software metrics, Defect prediction, Quantitative methods, Software assessment}
}

@article{10.1007/s00521-021-05995-8,
author = {Tyralis, Hristos and Papacharalampous, Georgia},
title = {Boosting algorithms in energy research: a systematic review},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {21},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05995-8},
doi = {10.1007/s00521-021-05995-8},
abstract = {Machine learning algorithms have been extensively exploited in energy research, due to their flexibility, automation and ability to handle big data. Among the most prominent machine learning algorithms are the boosting ones, which are known to be “garnering wisdom from a council of fools”, thereby transforming weak learners to strong learners. Boosting algorithms are characterized by both high flexibility and high interpretability. The latter property is the result of recent developments by the statistical community. In this work, we provide understanding on the properties of boosting algorithms to facilitate a better exploitation of their strengths in energy research. In this respect, (a) we summarize recent advances on boosting algorithms, (b) we review relevant applications in energy research with those focusing on renewable energy (in particular those focusing on wind energy and solar energy) consisting a significant portion of the total ones, and (c) we describe how boosting algorithms are implemented and how their use is related to their properties. We show that boosting has been underexploited so far, while great advances in the energy field are possible both in terms of explanation and interpretation, and in terms of predictive performance.},
journal = {Neural Comput. Appl.},
month = nov,
pages = {14101–14117},
numpages = {17},
keywords = {Renewable energy, Machine learning, Energy forecasting, Artificial intelligence}
}

@article{10.1016/j.knosys.2019.03.013,
author = {Xu, Peng and Du, Rui and Zhang, Zhongbao},
title = {Predicting pipeline leakage in petrochemical system through GAN and LSTM},
year = {2019},
issue_date = {Jul 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {175},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2019.03.013},
doi = {10.1016/j.knosys.2019.03.013},
journal = {Know.-Based Syst.},
month = jul,
pages = {50–61},
numpages = {12},
keywords = {LSTM, GAN, Pipeline leakage, Fault prediction}
}

@article{10.1007/s10845-020-01571-4,
author = {Park, Seyoung and Jang, Jaeyeon and Kim, Chang Ouk},
title = {Discriminative feature learning and cluster-based defect label reconstruction for reducing uncertainty in wafer bin map labels},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01571-4},
doi = {10.1007/s10845-020-01571-4},
abstract = {Many studies have been conducted to improve wafer bin map (WBM) defect classification performance because accurate WBM classification can provide information about abnormal processes causing a decrease in yield. However, in the actual manufacturing field, the manual labeling performed by engineers leads to a high level of uncertainty. Label uncertainty has been a major cause of the reduction in WBM classification system performance. In this paper, we propose a class label reconstruction method for subdividing a defect class with various patterns into several groups, creating a new class for defect samples that cannot be categorized into known classes and detecting unknown defects. The proposed method performs discriminative feature learning of the Siamese network and repeated cross-learning of the class label reconstruction based on Gaussian means clustering in a learned feature space. We verified the proposed method using a real-world WBM dataset. In a situation where there the class labels of the training dataset were corrupted, the proposed method could increase the classification accuracy of the test dataset by enabling the corrupted sample to find its original class label. As a result, the accuracy of the proposed method was up to 7.8% higher than that of the convolutional neural network (CNN). Furthermore, through the proposed class label reconstruction, we found a new mixed-type defect class that had not been found until now, and we detected new types of unknown defects that were not used for learning with an average accuracy of over 73%.},
journal = {J. Intell. Manuf.},
month = jan,
pages = {251–263},
numpages = {13},
keywords = {G-means clustering, Siamese network, Unknown defect detection, Class label reconstruction, Label uncertainty, Wafer bin map}
}

@inproceedings{10.1145/3416505.3423563,
author = {Palma, Stefano Dalla and Mohammadi, Majid and Di Nucci, Dario and Tamburri, Damian A.},
title = {Singling the odd ones out: a novelty detection approach to find defects in infrastructure-as-code},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423563},
doi = {10.1145/3416505.3423563},
abstract = {Infrastructure-as-Code (IaC) is increasingly adopted. However, little is known about how to best maintain and evolve it. Previous studies focused on defining Machine-Learning models to predict defect-prone blueprints using supervised binary classification. This class of techniques uses both defective and non-defective instances in the training phase. Furthermore, the high imbalance between defective and non-defective samples makes the training more difficult and leads to unreliable classifiers. In this work, we tackle the defect-prediction problem from a different perspective using novelty detection and evaluate the performance of three techniques, namely OneClassSVM, LocalOutlierFactor, and IsolationForest, and compare their performance with a baseline RandomForest binary classifier. Such models are trained using only non-defective samples: defective data points are treated as novelty because the number of defective samples is too little compared to defective ones. We conduct an empirical study on an extremely-imbalanced dataset consisting of 85 real-world Ansible projects containing only small amounts of defective instances. We found that novelty detection techniques can recognize defects with a high level of precision and recall, an AUC-PR up to 0.86, and an MCC up to 0.31. We deem our results can influence the current trends in defect detection and put forward a new research path toward dealing with this problem.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {31–36},
numpages = {6},
keywords = {Novelty Detection, Infrastructure-as-Code, Defect Prediction},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@article{10.1016/j.compag.2010.07.008,
author = {Ariana, Diwan P. and Lu, Renfu},
title = {Original paper: Hyperspectral waveband selection for internal defect detection of pickling cucumbers and whole pickles},
year = {2010},
issue_date = {October, 2010},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {74},
number = {1},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2010.07.008},
doi = {10.1016/j.compag.2010.07.008},
abstract = {Hyperspectral imaging under transmittance mode has shown potential for detecting internal defect, however, the technique still cannot meet the online speed requirement because of the need to acquire and analyze a large amount of image data. This study was carried out to select important wavebands for further development of an online inspection system to detect internal defect in pickling cucumbers and whole pickles. Hyperspectral transmittance/reflectance images were acquired from normal and defective cucumbers and whole pickles using a prototype hyperspectral reflectance (400-740nm)/transmittance (740-1000nm) imaging system. Up to four-waveband subsets were determined by a branch and bound algorithm combined with the k-nearest neighbor classifier. Different waveband binning operations were also compared to determine the bandwidth requirement for each waveband combination. The highest classification accuracies of 94.7 and 82.9% were achieved using the optimal four-waveband sets of 745, 805, 965, and 985nm at 20nm spectral resolution for cucumbers and of 745, 765, 885, and 965nm at 40nm spectral resolution for whole pickles, respectively. The selected waveband sets will be useful for online quality detection of pickling cucumbers and pickles.},
journal = {Comput. Electron. Agric.},
month = oct,
pages = {137–144},
numpages = {8},
keywords = {Waveband selection, Transmittance, Reflectance, Quality, Pickles, Nondestructive, Near-infrared, Internal defect, Hyperspectral imaging, Cucumbers}
}

@inproceedings{10.1145/3318299.3318337,
author = {Zhang, Zongtang and Chen, Zhe and Dai, Weiguo and Cheng, Yusheng},
title = {An Over-sampling Method Based on Margin Theory},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318337},
doi = {10.1145/3318299.3318337},
abstract = {Imbalanced data widely exists in real life, while the traditional classification method usually takes accuracy as the classification criterion, which is not suitable for the classification of imbalanced data. Resampling is an important method to deal with imbalanced data classification. In this paper, a margin based random over-sampling (MRO) method is proposed, and then MROBoost algorithm is proposed by combining the AdaBoost algorithm. Experimental results on the UCI dataset show that the MROBoost algorithm is superior to AdaBoost for imbalanced data classification problem.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {506–510},
numpages = {5},
keywords = {over-sampling, imbalanced data, Machine learning, AdaBoost},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@article{10.1145/3384517,
author = {Kapur, Ritu and Sodhi, Balwinder},
title = {A Defect Estimator for Source Code: Linking Defect Reports with Programming Constructs Usage Metrics},
year = {2020},
issue_date = {April 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3384517},
doi = {10.1145/3384517},
abstract = {An important issue faced during software development is to identify defects and the properties of those defects, if found, in a given source file. Determining defectiveness of source code assumes significance due to its implications on software development and maintenance cost.We present a novel system to estimate the presence of defects in source code and detect attributes of the possible defects, such as the severity of defects. The salient elements of our system are: (i) a dataset of newly introduced source code metrics, called PROgramming CONstruct (PROCON) metrics, and (ii) a novel Machine-Learning (ML)-based system, called Defect Estimator for Source Code (DESCo), that makes use of PROCON dataset for predicting defectiveness in a given scenario. The dataset was created by processing 30,400+ source files written in four popular programming languages, viz., C, C++, Java, and Python.The results of our experiments show that DESCo system outperforms one of the state-of-the-art methods with an improvement of 44.9%. To verify the correctness of our system, we compared the performance of 12 different ML algorithms with 50+ different combinations of their key parameters. Our system achieves the best results with SVM technique with a mean accuracy measure of 80.8%.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {12},
numpages = {35},
keywords = {source code mining, software metrics, software faults and failures, software defect prediction, automated software engineering, Maintaining software, AI in software engineering}
}

@inproceedings{10.1007/978-3-030-95398-0_8,
author = {J\"{o}chl, Robert and Uhl, Andreas},
title = {Effects of&nbsp;Image Compression on&nbsp;Image Age Approximation},
year = {2021},
isbn = {978-3-030-95397-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-95398-0_8},
doi = {10.1007/978-3-030-95398-0_8},
abstract = {In-field sensor defects are at the core of temporal image forensics, as a temporal order among pieces of evidence can be established by knowing their onset time. A characteristic of these single pixel defects is that they appear as point-like image noise. Since sensor defects exhibit noise-like properties, they are vulnerable to image compression. For this reason, it is important to evaluate the effect of image compression on the defect based image age approximation techniques available. In this paper, we assess the robustness of these age approximation methods with respect to four different compression techniques (i.e., ‘JPEG’, ‘JPEG 2000’, ‘JPEG XR’ and ‘Better Portable Graphics’) and different compression strengths. Since the approximation techniques considered require the defect locations to be known in advance, we assess the effect of image compression on the defect detection methods proposed in the context of image age approximation.},
booktitle = {Digital Forensics and Watermarking: 20th International Workshop, IWDW 2021, Beijing, China, November 20–22, 2021, Revised Selected Papers},
pages = {102–116},
numpages = {15},
keywords = {Image forensics, Defect detection, In-field sensor defects, Image age approximation, Image compression},
location = {Beijing, China}
}

@article{10.1007/s11042-018-6786-7,
author = {Liu, Li and Zhang, Jianhong and Fu, Xiaodong and Liu, Lijun and Huang, Qingsong},
title = {Unsupervised segmentation and elm for fabric defect image classification},
year = {2019},
issue_date = {May       2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {78},
number = {9},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-018-6786-7},
doi = {10.1007/s11042-018-6786-7},
abstract = {In order to solve the problem of low accuracy and efficiency for surface defects in common woven fabrics, a novel fabric defect classification method is proposed based on unsupervised segmentation and ELM. The classification method is divided into four steps including defect segmentation, feature extraction, ELM classifier training, and Bayesian probability fusion. Firstly, an unsupervised segmentation is presented for the Grayscale fabric defect image after preprocessing. Secondly, geometric and texture features were extracted by using the segmented image and the undivided Grayscale image. Then, features and labels in fabric defect images are considered as training sets to train the ELM classifier. Finally, the input fabric defect image is classified by the trained ELM classifier and the Bayesian probability fusion method. Experimental results show that the proposed method can classify the fabric defect image with high accuracy and efficiency that can better meet the requirements for practical applications.},
journal = {Multimedia Tools Appl.},
month = may,
pages = {12421–12449},
numpages = {29},
keywords = {Unsupervised segmentation, Image classification, Fabric defect detection, ELM classifier, Bayesian probability fusion}
}

@article{10.1016/j.cie.2021.107630,
author = {Dang, L. Minh and Kyeong, SeonJae and Li, Yanfen and Wang, Hanxiang and Nguyen, Tan N. and Moon, Hyeonjoon},
title = {Deep learning-based sewer defect classification for highly imbalanced dataset},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {161},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2021.107630},
doi = {10.1016/j.cie.2021.107630},
journal = {Comput. Ind. Eng.},
month = nov,
numpages = {16},
keywords = {Sewer network, Crack classification, Deep learning, CCTV, Text recognition, Imbalanced data}
}

@inproceedings{10.1007/978-3-030-78609-0_23,
author = {Peng, Yu and Li, Xiaoyu and Lu, Chao and Tang, Xiaolan and Lin, Bin},
title = {A Light-Weight Prediction Model for Aero-Engine Surge Based on Seq2Seq},
year = {2021},
isbn = {978-3-030-78608-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78609-0_23},
doi = {10.1007/978-3-030-78609-0_23},
abstract = {Surge is an abnormal fault caused by compressor in the process of aero-engine flight, which will reduce the performance of aero-engines. When the surge gets serious, it will even cause engine damage, endanger flight safety, and cause a huge loss of personnel and property. Therefore, it is of great significance to predict the aero-engine surge timely and accurately. At present, little research have been done on the prediction task of aero-engine surge, and there are problems of low prediction accuracy and long calculation time. In order to solve these problems, a light-weight prediction model for aero-engine surge based on Seq2Seq (sequence to sequence) is proposed, which is called Ligh4S. Ligh4S uses the one-dimensional convolution neural network instead of the LSTM (long short-term memory network) structure in tradition-al Seq2Seq, which allows the model to compute in parallel, thus greatly improving computational efficiency and reducing prediction time. Experiments on the experimental data of an aero-engine show that the model achieves the performances of 94.3%, 92.1%, 93.2% respectively on precision rate, recall rate and F1 score under the condition of significantly reducing the size of model and the amount of calculation. What’s more, the model takes only 2ms to make a single prediction, which increases the prediction speed by about 98% compared with the LSTM-based Seq2Seq model.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part I},
pages = {265–277},
numpages = {13},
keywords = {seq2seq, Light-weight, Fault prediction, Aero-engine surge},
location = {Dublin, Ireland}
}

@article{10.1002/smr.2172,
author = {Gong, Lina and Jiang, Shujuan and Jiang, Li},
title = {An improved transfer adaptive boosting approach for mixed‐project defect prediction},
year = {2019},
issue_date = {October 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {10},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2172},
doi = {10.1002/smr.2172},
abstract = {Software defect prediction (SDP) has been a very important research topic in software engineering, since it can provide high‐quality results when given sufficient historical data of the project. Unfortunately, there are not abundant data to bulid the defect prediction model at the beginning of a project. For this scenario, one possible solution is to use data from other projects in the same company. However, using these data practically would get poor performance because of different distributional characteristics among projects. Also, software has more non‐defective instances than defective instances that may cause a significant bias towards defective instances. Considering these two problems, we propose an improved transfer adaptive boosting (ITrAdaBoost) approach for being given a small number of labeled data in the testing project. In our approach, ITrAdaBoost can not only employ the Matthews correlation coefficient (MCC) as the measure instead of accuracy rate but also use the asymmetric misclassification costs for non‐defective and defective instances. Extensive experiments on 18 public projects from four datasets indicate that: (a) our approach significantly outperforms state‐of‐the‐art cross‐project defect prediction (CPDP) approaches, and (b) our approach can obtain comparable prediction performances in contrast with within project prediction results. Consequently, the proposed approach can build an effective prediction model with a small number of labeled instances for mixed‐project defect prediction (MPDP).For mixed‐project defect prediction, improved transfer adaptive boosting approach (ITrAdaBoost) can not only employ the Matthews correlation coefficient (MCC) as the measure instead of accuracy rate, but also use the asymmetric misclassification costs for nondefective and defective instances. Extensive experiments on 18 public projects from four datasets indicate that (a) our approach significantly outperforms state‐of‐the‐art cross‐project defect prediction (CPDP) approaches, and (b) our approach can obtain comparable prediction performances in contrast with within project prediction results.


image
image},
journal = {J. Softw. Evol. Process},
month = oct,
numpages = {23},
keywords = {transfer learning, software defect prediction, mixed‐project, cross‐project, class imbalance}
}

@article{10.1016/j.compeleceng.2019.04.011,
author = {G., Geetharamani and J., Arun Pandian},
title = {Identification of plant leaf diseases using a nine-layer deep convolutional neural network},
year = {2019},
issue_date = {Jun 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {76},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.04.011},
doi = {10.1016/j.compeleceng.2019.04.011},
journal = {Comput. Electr. Eng.},
month = jun,
pages = {323–338},
numpages = {16},
keywords = {Transfer learning, Training epoch, Mini batch, Machine learning, Leaf diseases identification, Image augmentation, Dropout, Deep learning, Deep convolutional neural networks, Artificial intelligence}
}

@inproceedings{10.1007/978-3-030-29551-6_57,
author = {Lahsoumi, Abir and Elouedi, Zied},
title = {Evidential Artificial Immune Recognition System},
year = {2019},
isbn = {978-3-030-29550-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-29551-6_57},
doi = {10.1007/978-3-030-29551-6_57},
abstract = {Uncertainty is one of the main classification issues that must be handled carefully and not rejected in order to make better decisions. Artificial immune recognition system (AIRS) is an immune-inspired supervised learning classifier that has shown good and competitive classification results. It works perfectly in a certain context, however it is quite the opposite in an environment pervaded with uncertainty. To overcome this limitation, we propose a new approach combining the AIRS and belief function theory one of the well-know theories managing uncertainty. Experimentations on real data sets from the U.C.I machine learning repository show good performances of the proposed approach.},
booktitle = {Knowledge Science, Engineering and Management: 12th International Conference, KSEM 2019, Athens, Greece, August 28–30, 2019, Proceedings, Part I},
pages = {643–654},
numpages = {12},
keywords = {Belief function theory, Uncertainty, Classification, Artificial immune recognition system (AIRS)},
location = {Athens, Greece}
}

@inproceedings{10.1007/978-3-030-41299-9_14,
author = {Ji, Xiaotong and Zheng, Yuchen and Suehiro, Daiki and Uchida, Seiichi},
title = {Optimal Rejection Function Meets Character Recognition Tasks},
year = {2019},
isbn = {978-3-030-41298-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-41299-9_14},
doi = {10.1007/978-3-030-41299-9_14},
abstract = {In this paper, we propose an optimal rejection method for rejecting ambiguous samples by a rejection function. This rejection function is trained together with a classification function under the framework of Learning-with-Rejection (LwR). The highlights of LwR are: (1) the rejection strategy is not heuristic but has a strong background from a machine learning theory, and (2) the rejection function can be trained on an arbitrary feature space which is different from the feature space for classification. The latter suggests we can choose a feature space which is more suitable for rejection. Although the past research on LwR focused only its theoretical aspect, we propose to utilize LwR for practical pattern classification tasks. Moreover, we propose to use features from different CNN layers for classification and rejection. Our extensive experiments of notMNIST classification and character/non-character classification demonstrate that the proposed method achieves better performance than traditional rejection strategies.},
booktitle = {Pattern Recognition: 5th Asian Conference, ACPR 2019, Auckland, New Zealand, November 26–29, 2019, Revised Selected Papers, Part II},
pages = {169–183},
numpages = {15},
keywords = {Theoretical machine learning, Optimal rejection function, Learning with Rejection},
location = {Auckland, New Zealand}
}

@article{10.1007/s10515-011-0091-2,
author = {Liparas, Dimitris and Angelis, Lefteris and Feldt, Robert},
title = {Applying the Mahalanobis-Taguchi strategy for software defect diagnosis},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0091-2},
doi = {10.1007/s10515-011-0091-2},
abstract = {The Mahalanobis-Taguchi (MT) strategy combines mathematical and statistical concepts like Mahalanobis distance, Gram-Schmidt orthogonalization and experimental designs to support diagnosis and decision-making based on multivariate data. The primary purpose is to develop a scale to measure the degree of abnormality of cases, compared to "normal" or "healthy" cases, i.e. a continuous scale from a set of binary classified cases. An optimal subset of variables for measuring abnormality is then selected and rules for future diagnosis are defined based on them and the measurement scale. This maps well to problems in software defect prediction based on a multivariate set of software metrics and attributes. In this paper, the MT strategy combined with a cluster analysis technique for determining the most appropriate training set, is described and applied to well-known datasets in order to evaluate the fault-proneness of software modules. The measurement scale resulting from the MT strategy is evaluated using ROC curves and shows that it is a promising technique for software defect diagnosis. It compares favorably to previously evaluated methods on a number of publically available data sets. The special characteristic of the MT strategy that it quantifies the level of abnormality can also stimulate and inform discussions with engineers and managers in different defect prediction situations.},
journal = {Automated Software Engg.},
month = jun,
pages = {141–165},
numpages = {25},
keywords = {Software testing, Software defect prediction, Mahalanobis-Taguchi strategy, Fault-proneness}
}

@phdthesis{10.5555/1369140,
author = {Challagulla, Venkata Udaya Bhaskar},
advisor = {Bastani, Farokh B.},
title = {A machine learning-based approach for dynamic reliability assessment of mission critical software systems},
year = {2007},
isbn = {9780549270720},
publisher = {University of Texas at Dallas},
address = {USA},
abstract = {Software continues to become more complex and difficult to certify to a high degree of confidence due to the increasing scope and sophistication of the requirements. Consequently, traditional development techniques face growing challenges in satisfying these requirements. Future distributed real-time systems, such as robotic swarm systems, telecontrol systems, and industrial automation systems, may need to dynamically adapt themselves based on the run-time mission-specific requirements and operating conditions. This further compounds the problems of developing highly dependable systems. This is also the case with emerging Service Oriented Architecture (SOA) based systems that perform dynamic discovery of services and reconfiguration and composition of services at run-time. These dynamic features combined with the abstractions provided by the services necessitate the need for high-confidence run-time software reliability assessment techniques. This Dissertation investigates machine learning-based software defect prediction techniques to monitor and assess the services in the synthesized code. Experimental assessment of various prediction algorithms using real-world data shows that memory-based reasoning (MBR) techniques perform relatively better than other methods. Based on these results, a framework is developed to automatically derive the optimal configuration of an MBR classifier for software defect data by logical variations of its configuration parameters. This adaptive MBR technique provides a flexible and effective environment for accurate prediction of mission-critical software defect data. In practice, since these systems are dynamically assembled from existing services, a dearth of sufficient sample data regarding the actual operational environment can reduce the level of confidence in the reliability estimate. The Dissertation investigates the combination of Bayesian Belief Network (BBN) and MBR methodologies to integrate multiple evidences from all the services to obtain high-confidence estimates in the reliability of dynamically assembled mission-critical SOA-based systems. Latent defects in more frequently executed domains affect the reliability of the component much more than the domains tested using random testing strategies. A dynamic monitoring and diagnosis framework is developed to accurately estimate the reliability of the system as it executes. The framework incorporates a Markov model to determine the service reliability from its component reliabilities. This systematic assessment method is evaluated using a simulated system and a real-world case study involving an Enterprise Content Management System. An Intelligent Software Defect Analysis Tool (ISDAT) that implements the above framework is developed, to realize the framework objectives of providing a unified framework for dynamically assessing the reliability of mission-critical SOA-based systems to a high-degree of confidence by using AI-based prediction analysis on the defect metrics data collected from real-time system monitoring.},
note = {AAI3285271}
}

@inproceedings{10.1007/978-3-030-27538-9_44,
author = {Yu, Wenyong and Zhang, Yang and Shi, Hui},
title = {Surface Defect Inspection Under a Small Training Set Condition},
year = {2019},
isbn = {978-3-030-27537-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27538-9_44},
doi = {10.1007/978-3-030-27538-9_44},
abstract = {The detection of surface defects in industrial production is an important technology for controlling product quality. Many researchers have applied deep learning methods to the field of surface defect detection. However, obtaining defect sample data in industrial production is difficult, and the number of samples available to train detection networks is not sufficient. Based on the you only look once (YOLO) detection system, we propose a lightweight small sample detection network (SSDN) to overcome the problem of fewer samples in surface defect detection. The SSDN is demonstrated to be a suitable network to represent defect image features as it is better at feature extraction and easier to train. We used only 10/type images to train the SSDN model without data enhancement techniques and achieved excellent results (average accuracy 99.72%) on defect detection benchmark data. Experimental results verify the robustness of the model.},
booktitle = {Intelligent Robotics and Applications: 12th International Conference, ICIRA 2019, Shenyang, China, August 8–11, 2019, Proceedings, Part IV},
pages = {517–528},
numpages = {12},
keywords = {Machine vision, Small training set, YOLO, Surface detection},
location = {Shenyang, China}
}

@article{10.1109/TSE.2005.112,
author = {Gyimothy, Tibor and Ferenc, Rudolf and Siket, Istvan},
title = {Empirical Validation of Object-Oriented Metrics on Open Source Software for Fault Prediction},
year = {2005},
issue_date = {October 2005},
publisher = {IEEE Press},
volume = {31},
number = {10},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2005.112},
doi = {10.1109/TSE.2005.112},
abstract = {Open source software systems are becoming increasingly important these days. Many companies are investing in open source projects and lots of them are also using such software in their own work. But, because open source software is often developed with a different management style than the industrial ones, the quality and reliability of the code needs to be studied. Hence, the characteristics of the source code of these projects need to be measured to obtain more information about it. This paper describes how we calculated the object-oriented metrics given by Chidamber and Kemerer to illustrate how fault-proneness detection of the source code of the open source Web and e-mail suite called Mozilla can be carried out. We checked the values obtained against the number of bugs found in its bug database called Bugzilla using regression and machine learning methods to validate the usefulness of these metrics for fault-proneness prediction. We also compared the metrics of several versions of Mozilla to see how the predicted fault-proneness of the software system changed during its development cycle.},
journal = {IEEE Trans. Softw. Eng.},
month = oct,
pages = {897–910},
numpages = {14},
keywords = {reverse engineering, open source software, metrics validation, fault-proneness detection, compiler wrapping, Mozilla, Index Terms- Fact extraction, Columbus., C++, Bugzilla}
}

@article{10.1504/ijiei.2021.120322,
author = {Lakra, Kirti and Chug, Anuradha},
title = {Application of metaheuristic techniques in software quality prediction: a systematic mapping study},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {4},
issn = {1758-8715},
url = {https://doi.org/10.1504/ijiei.2021.120322},
doi = {10.1504/ijiei.2021.120322},
abstract = {This paper focuses on the systematic review of various metaheuristic techniques employed for analysing different software quality aspects, including fault proneness, defect anticipation, change proneness, maintainability prediction, and software reliability prediction. It is observed that machine learning algorithms are still popular models, but metaheuristic algorithms are also gaining popularity in the field of software quality measurement. This is due to the fact that metaheuristic algorithms are more efficient in solving real-world, search-based, and optimisation problems. Initially, 90 papers were considered and analysed for conducting this study from 2010 to 2020, and 55 studies were shortlisted based on predesigned quality evaluation standards. Resultantly, particle swarm optimisation (PSO), and genetic algorithms came out as the most prominently used metaheuristic techniques for developing software quality models in 36.3% and 27.2% of the shortlisted studies, respectively. The current review will benefit other researchers by providing an insight into the current trends in software quality domain.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {355–399},
numpages = {44},
keywords = {software quality improvement, software maintainability prediction, software reliability prediction, software change prediction, software defect prediction, software fault proneness, software quality, object-oriented metrics, metaheuristic techniques}
}

@article{10.1016/j.future.2019.05.080,
author = {Zhao, Linchang and Shang, Zhaowei and Qin, Anyong and Zhang, Taiping and Zhao, Ling and Wei, Yu and Tang, Yuan Yan},
title = {A cost-sensitive meta-learning classifier: SPFCNN-Miner},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {100},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.05.080},
doi = {10.1016/j.future.2019.05.080},
journal = {Future Gener. Comput. Syst.},
month = nov,
pages = {1031–1043},
numpages = {13},
keywords = {Data mining, Siamese parallel fully-connected networks, Machine learning, Cost-sensitive learning, Few-shot learning, Meta learning}
}

@inproceedings{10.1145/3416505.3423564,
author = {Borovits, Nemania and Kumara, Indika and Krishnan, Parvathy and Palma, Stefano Dalla and Di Nucci, Dario and Palomba, Fabio and Tamburri, Damian A. and van den Heuvel, Willem-Jan},
title = {DeepIaC: deep learning-based linguistic anti-pattern detection in IaC},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423564},
doi = {10.1145/3416505.3423564},
abstract = {Linguistic anti-patterns are recurring poor practices concerning inconsistencies among the naming, documentation, and implementation of an entity. They impede readability, understandability, and maintainability of source code. This paper attempts to detect linguistic anti-patterns in infrastructure as code (IaC) scripts used to provision and manage computing environments. In particular, we consider inconsistencies between the logic/body of IaC code units and their names. To this end, we propose a novel automated approach that employs word embeddings and deep learning techniques. We build and use the abstract syntax tree of IaC code units to create their code embedments. Our experiments with a dataset systematically extracted from open source repositories show that our approach yields an accuracy between 0.785 and 0.915 in detecting inconsistencies.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {7–12},
numpages = {6},
keywords = {Word2Vec, Linguistic Anti-patterns, Infrastructure Code, IaC, Defects, Deep Learning, Code Embedding},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@inproceedings{10.1007/978-3-030-77004-4_20,
author = {Molefe, Mohale and Tapamo, Jules-Raymond},
title = {Classification of Rail Welding Defects Based on the Bag of Visual Words Approach},
year = {2021},
isbn = {978-3-030-77003-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77004-4_20},
doi = {10.1007/978-3-030-77004-4_20},
abstract = {Railway transportation is one of the safest modes of transportation commonly used to transport heavy freight. Rails are the most critical and maintenance demanding component of the railway infrastructure. Rails are usually welded together during the installation process to form a continuous railway line using the thermite welding process. However, thermite welding is prone to the formation of defects on the welded rails, thus the weld joint is usually inspected. Radiography is the widely used Non-Destructive Testing method to inspect the weld joint for possible defects which could have occurred during the welding process. However, the detection and classification of defects from the generated radiography images is done manually by a trained radiography expert. Furthermore, the process is lengthy, costly and subjective even if conducted by a trained expert. This work presents an automated defect detection and classification method based on the Bag of Visual Words approach where the Speeded Up Robust Feature is used as the low-level feature descriptor. A Support Vector Machine is used as the classifier. The proposed method achieved the average classification accuracy of 94.60%.},
booktitle = {Pattern Recognition: 13th Mexican Conference, MCPR 2021, Mexico City, Mexico, June 23–26, 2021, Proceedings},
pages = {207–218},
numpages = {12},
keywords = {Support vector machine, Bag of visual words, Thermite welding, Railway transportation},
location = {Mexico City, Mexico}
}

@article{10.1007/s00354-021-00124-4,
author = {Karadeniz, Talha and Tokdemir, G\"{u}l and Mara\c{s}, Hadi Hakan},
title = {Ensemble Methods for Heart Disease Prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Ohmsha},
address = {JPN},
volume = {39},
number = {3–4},
issn = {0288-3635},
url = {https://doi.org/10.1007/s00354-021-00124-4},
doi = {10.1007/s00354-021-00124-4},
abstract = {Heart disease prediction is a critical task regarding human health. It is based on deriving an Machine Learning model from medical parameters to predict risk levels. In this work, we propose and test novel ensemble methods for heart disease prediction. Randomness analysis of distance sequences is utilized to derive a classifier, which is served as a base estimator of a bagging scheme. Method is successfully tested on medical Spectf dataset. Additionally, a Graph Lasso and Ledoit–Wolf shrinkage-based classifier is developed for Statlog dataset which is a UCI data. These two algorithms yield comparatively good accuracy results: 88.7 and 88.8 for Spectf and Statlog, respectively. These proposed algorithms provide promising results and novel classification methods that can be utilized in various domains to improve performance of ensemble methods.},
journal = {New Gen. Comput.},
month = nov,
pages = {569–581},
numpages = {13},
keywords = {Weak classifier, Bagging classifier, Mahalanobis distance, Covariance estimator, Heart disease prediction, Ensemble methods, Randomness test}
}

@article{10.1007/s40595-013-0008-z,
author = {Abaei, Golnoush and Selamat, Ali},
title = {A survey on software fault detection based on different prediction approaches},
year = {2014},
issue_date = {May       2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {2},
issn = {2196-8888},
url = {https://doi.org/10.1007/s40595-013-0008-z},
doi = {10.1007/s40595-013-0008-z},
abstract = {One of the software engineering interests is quality assurance activities such as testing, verification and validation, fault tolerance and fault prediction. When any company does not have sufficient budget and time for testing the entire application, a project manager can use some fault prediction algorithms to identify the parts of the system that are more defect prone. There are so many prediction approaches in the field of software engineering such as test effort, security and cost prediction. Since most of them do not have a stable model, software fault prediction has been studied in this paper based on different machine learning techniques such as decision trees, decision tables, random forest, neural network, Na\"{\i}ve Bayes and distinctive classifiers of artificial immune systems (AISs) such as artificial immune recognition system, CLONALG and Immunos. We use four public NASA datasets to perform our experiment. These datasets are different in size and number of defective data. Distinct parameters such as method-level metrics and two feature selection approaches which are principal component analysis and correlation based feature selection are used to evaluate the finest performance among the others. According to this study, random forest provides the best prediction performance for large data sets and Na\"{\i}ve Bayes is a trustable algorithm for small data sets even when one of the feature selection techniques is applied. Immunos99 performs well among AIS classifiers when feature selection technique is applied, and AIRSParallel performs better without any feature selection techniques. The performance evaluation has been done based on three different metrics such as area under receiver operating characteristic curve, probability of detection and probability of false alarm. These three evaluation metrics could give the reliable prediction criteria together.},
journal = {Vietnam J. of Computer Science},
month = may,
pages = {79–95},
numpages = {17},
keywords = {Software fault prediction, Random forest, Machine learning, CSCA, Artificial immune system, AISParallel}
}

@inproceedings{10.1145/3460319.3464819,
author = {Zeng, Zhengran and Zhang, Yuqun and Zhang, Haotian and Zhang, Lingming},
title = {Deep just-in-time defect prediction: how far are we?},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464819},
doi = {10.1145/3460319.3464819},
abstract = {Defect prediction aims to automatically identify potential defective code with minimal human intervention and has been widely studied in the literature. Just-in-Time (JIT) defect prediction focuses on program changes rather than whole programs, and has been widely adopted in continuous testing. CC2Vec, state-of-the-art JIT defect prediction tool, first constructs a hierarchical attention network (HAN) to learn distributed vector representations of both code additions and deletions, and then concatenates them with two other embedding vectors representing commit messages and overall code changes extracted by the existing DeepJIT approach to train a model for predicting whether a given commit is defective. Although CC2Vec has been shown to be the state of the art for JIT defect prediction, it was only evaluated on a limited dataset and not compared with all representative baselines. Therefore, to further investigate the efficacy and limitations of CC2Vec, this paper performs an extensive study of CC2Vec on a large-scale dataset with over 310,370 changes (8.3 X larger than the original CC2Vec dataset). More specifically, we also empirically compare CC2Vec against DeepJIT and representative traditional JIT defect prediction techniques. The experimental results show that CC2Vec cannot consistently outperform DeepJIT, and neither of them can consistently outperform traditional JIT defect prediction. We also investigate the impact of individual traditional defect prediction features and find that the added-line-number feature outperforms other traditional features. Inspired by this finding, we construct a simplistic JIT defect prediction approach which simply adopts the added-line-number feature with the logistic regression classifier. Surprisingly, such a simplistic approach can outperform CC2Vec and DeepJIT in defect prediction, and can be 81k X/120k X faster in training/testing. Furthermore, the paper also provides various practical guidelines for advancing JIT defect prediction in the near future.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {427–438},
numpages = {12},
keywords = {Software Defect Prediction, Just-In-Time Prediction, Deep Learning},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@article{10.3233/JIFS-169937,
author = {Singh, Namrata and Singh, Pradeep and Thampi, Sabu M. and El-Alfy, El-Sayed M.},
title = {A novel Bagged Na\"{\i}ve Bayes-Decision Tree approach for multi-class classification problems},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {36},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-169937},
doi = {10.3233/JIFS-169937},
abstract = {Breakthrough classification performances have been achieved by utilizing ensemble techniques in machine learning and data mining. Bagging is one such ensemble technique that has outperformed single models in obtaining higher predictive performances. This paper proposes an ensemble technique by utilizing the basic bootstrap aggregating technique on hybridization of two base learners namely Na\"{\i}ve Bayes (NB) and Decision Tree (DT). Before induction of the DT, NB algorithm is employed for eliminating mislabeled or contradictory instances from the training set. Consequently, bagging approach is applied on hybrid NBDT as the base learner. The resultant Bagged Na\"{\i}ve Bayes-Decision Tree (BNBDT) algorithm is then used for improving the classification accuracy of various multi-class problems. This algorithm iteratively trains the base learner from random samples of the training set, and then performs majority voting of their predictions. The proposed algorithm is compared with both ensemble and single classification techniques such as Random Forest, Bagged NB, Bagged DT, NB, and DT. Experimental results over 52 UCI data sets with bag size 100 demonstrate that the proposed algorithm significantly outperforms the existing algorithms.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {2261–2271},
numpages = {11},
keywords = {hybrid learner, machine learning, multi-class problems, classification, decision tree, na\"{\i}ve bayes, Bagging}
}

@article{10.1504/ijcvr.2021.115162,
author = {Liang, Qiaokang and Xiang, Shao and Long, Jianyong and Zhang, Dan and Coppola, Gianmarc and Sun, Wei and Wang, Yaonan},
title = {Automatic defect inspection system for beer bottles based on deep residual learning},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {11},
number = {3},
issn = {1752-9131},
url = {https://doi.org/10.1504/ijcvr.2021.115162},
doi = {10.1504/ijcvr.2021.115162},
abstract = {Automatic detection of defects in recyclable beer bottles would reduce both the cost of the production process and the time spent in the quality inspection. A novel approach is proposed for automatic detection of defects occurring on the beer bottles by deep residual learning. This method extracts the characteristic information of beer bottle defects through the deep learning network and realises the classification of defect characters. In this work, the recognition of three kinds of common defects (defective body, defective mouth, and defective bottom) is realised, and the promising result demonstrated that the proposed method is capable of inspecting defects of beer bottles with outstanding accuracy. Particularly, a state-of-the-art convolutional neural network (CNN) was applied to the detection of beer bottle defects, which improved the accuracy of beer bottle detection comparing with traditional methods. Experimental results show that the new approach satisfies the requirement of defect detection and is able to improve the production efficiency.},
journal = {Int. J. Comput. Vision Robot.},
month = jan,
pages = {299–314},
numpages = {15},
keywords = {quality inspection, CNN, convolutional neural network, deep learning, detection of defects}
}

@article{10.3233/JIFS-18473,
author = {Malhotra, Ruchika and Sharma, Anjali},
title = {Empirical assessment of feature selection techniques in defect prediction models using web applications},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {36},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-18473},
doi = {10.3233/JIFS-18473},
abstract = {&nbsp;In order to minimize the over-fitting and related factors that are caused by the high dimensionality of the input data in software defect prediction, the attributes are often optimized using various feature selection techniques. However, the comparative performance of these selection techniques in combination with machine learning algorithms remains largely unexplored using web applications. In this work, we investigate the best possible combination of feature selection technique with machine learning algorithms, with the sample space chosen from open source Apache Click and Rave data sets. Our results are based on 945 defect prediction models derived from parametric, non-parametric and ensemble-based machine learning algorithms, for which the metrics are derived from the various filter and threshold-based ranking techniques. Friedman and Nemenyi post-hoc statistical tests are adopted to identify the performance difference of these models. We find that filter-based feature selection in combination with ensemble-based machine learning algorithms not only poise as the best strategy but also yields a maximum feature set redundancy by 94%, with little or no comprise on the performance index.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6567–6578},
numpages = {12},
keywords = {web application quality, machine learning, feature ranking, Feature selection}
}

@inproceedings{10.1145/3483207.3483208,
author = {Yao, Yong and Yang, Yue and Wang, Jing},
title = {Scratch Detection of Aircraft Bell Tube Based on Improved YOLOv4 Framework},
year = {2021},
isbn = {9781450390170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483207.3483208},
doi = {10.1145/3483207.3483208},
abstract = {To solve the problems of low accuracy, false detection, and high rate of missed detection, a surface scratch detection framework for aircraft bell tubes based on an improved YOLOv4 algorithm is proposed. First, we construct a scratch dataset on the surface of the aircraft bell tubes, which marks scratches with angled boxes. Secondly, convolutional layers are added to improve the ability of network to extract defect features, and the layers change in the backbone feature extraction network output and the spatial pyramid pooling structure in the YOLOv4 network. Finally, due to the uneven distribution of scratches, rotation detection is used to predict the scratches with rotate boxes. Experimental results show that the mAP value of the improved model based on YOLOv4 in scratch detection task is 96.21%, the MR value is 0.07, and the average detection time of a single image is 0.2270s, which proves that our model is better than Faster R-CNN, YOLOv4 and variants of our proposed model.},
booktitle = {Proceedings of the 2021 4th International Conference on Signal Processing and Machine Learning},
pages = {1–6},
numpages = {6},
keywords = {rotation detection, deep learning, YOLOv4, Scratch detection},
location = {Beijing, China},
series = {SPML '21}
}

@article{10.1007/s10664-020-09853-4,
author = {Hajri, Ines and Goknil, Arda and Pastore, Fabrizio and Briand, Lionel C.},
title = {Automating system test case classification and prioritization for use case-driven testing in product lines},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09853-4},
doi = {10.1007/s10664-020-09853-4},
abstract = {Product Line Engineering (PLE) is a crucial practice in many software development environments where software systems are complex and developed for multiple customers with varying needs. At the same time, many development processes are use case-driven and this strongly influences their requirements engineering and system testing practices. In this paper, we propose, apply, and assess an automated system test case classification and prioritization approach specifically targeting system testing in the context of use case-driven development of product families. Our approach provides: (i) automated support to classify, for a new product in a product family, relevant and valid system test cases associated with previous products, and (ii) automated prioritization of system test cases using multiple risk factors such as fault-proneness of requirements and requirements volatility in a product family. Our evaluation was performed in the context of an industrial product family in the automotive domain. Results provide empirical evidence that we propose a practical and beneficial way to classify and prioritize system test cases for industrial product lines.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3711–3769},
numpages = {59},
keywords = {Requirements engineering, Automotive, Test case selection and prioritization, Regression testing, Use case driven development, Product Line Engineering}
}

@inproceedings{10.1109/SMC52423.2021.9659221,
author = {Faula, Yannick and Eglin, V\'{e}ronique and Bres, St\'{e}phane},
title = {One-Class Detection and Classification of Defects on Concrete Surfaces},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC52423.2021.9659221},
doi = {10.1109/SMC52423.2021.9659221},
abstract = {Today, railway infrastructure is subject to regular inspections carried out by image acquisition. Experts need automatic tools to process these images and extract defects. These defects can be classified in two categories : linear defects, like cracks, and surface defects, like spall, humidity, graffiti… Cracks detection has been presented in a previous work, and is based on Local Binary Patterns (LBP) extraction and our FLASH algorithm [1]. In this paper, we propose a new method, using the same LBP descriptors, already extracted, to detect surface defects using generative adversarial networks (GAN). The detection is followed by a classification with a potentially scalable system. Experiments show that our detector achieves better performance than the state-of-the art in application to defect detection.},
booktitle = {2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
pages = {826–831},
numpages = {6},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/2915970.2916007,
author = {Petri\'{c}, Jean and Bowes, David and Hall, Tracy and Christianson, Bruce and Baddoo, Nathan},
title = {The jinx on the NASA software defect data sets},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2916007},
doi = {10.1145/2915970.2916007},
abstract = {Background: The NASA datasets have previously been used extensively in studies of software defects. In 2013 Shepperd et al. presented an essential set of rules for removing erroneous data from the NASA datasets making this data more reliable to use.Objective: We have now found additional rules necessary for removing problematic data which were not identified by Shepperd et al.Results: In this paper, we demonstrate the level of erroneous data still present even after cleaning using Shepperd et al.'s rules and apply our new rules to remove this erroneous data.Conclusion: Even after systematic data cleaning of the NASA MDP datasets, we found new erroneous data. Data quality should always be explicitly considered by researchers before use.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {13},
numpages = {5},
keywords = {software defect prediction, machine learning, data quality},
location = {Limerick, Ireland},
series = {EASE '16}
}

@inproceedings{10.1145/3340482.3342747,
author = {Lenarduzzi, Valentina and Martini, Antonio and Taibi, Davide and Tamburri, Damian Andrew},
title = {Towards surgically-precise technical debt estimation: early results and research roadmap},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340482.3342747},
doi = {10.1145/3340482.3342747},
abstract = {The concept of technical debt has been explored from many perspectives but its precise estimation is still under heavy empirical and experimental inquiry. We aim to understand whether, by harnessing approximate, data-driven, machine-learning approaches it is possible to improve the current techniques for technical debt estimation, as represented by a top industry quality analysis tool such as SonarQube. For the sake of simplicity, we focus on relatively simple regression modelling techniques and apply them to modelling the additional project cost connected to the sub-optimal conditions existing in the projects under study. Our results shows that current techniques can be improved towards a more precise estimation of technical debt and the case study shows promising results towards the identification of more accurate estimation of technical debt.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
pages = {37–42},
numpages = {6},
keywords = {Technical Debt, Machine Learning, Empirical Study},
location = {Tallinn, Estonia},
series = {MaLTeSQuE 2019}
}

@inproceedings{10.1145/3277103.3277131,
author = {Castro, Alberto and Richart, Mat\'{\i}as and Baliosian, Javier and Gramp\'{\i}n, Eduardo},
title = {Opportunities for AI/ML in Telecommunications Networks},
year = {2018},
isbn = {9781450359221},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277103.3277131},
doi = {10.1145/3277103.3277131},
abstract = {While it is true that we are in the middle of one of the Artificial Intelligence hypes, it is also true that the combination of unprecedented computation-power and data availability with new variations of well seasoned Machine Learning algorithms is dramatically changing the optimization strategies for large ICT industries. Especially, the telecommunications industry has always had to deal with complex systems, stochastic contexts, combinatorial problems, and hard to predict users; Machine Learning-aided optimization was just waiting there to be used by telecoms. In this paper, we introduce some basic Machine Learning concepts, and discuss how it can be used in the context of telecommunications networks, particularly in optical and wireless networks.},
booktitle = {Proceedings of the 10th Latin America Networking Conference},
pages = {89–95},
numpages = {7},
keywords = {Wireless Networks, Optical Networks, Machine Learning},
location = {S\~{a}o Paulo, Brazil},
series = {LANC '18}
}

@article{10.1145/3464423,
author = {Fernando, Tharindu and Gammulle, Harshala and Denman, Simon and Sridharan, Sridha and Fookes, Clinton},
title = {Deep Learning for Medical Anomaly Detection – A Survey},
year = {2021},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3464423},
doi = {10.1145/3464423},
abstract = {Machine learning–based medical anomaly detection is an important problem that has been extensively studied. Numerous approaches have been proposed across various medical application domains and we observe several similarities across these distinct applications. Despite this comparability, we observe a lack of structured organisation of these diverse research applications such that their advantages and limitations can be studied. The principal aim of this survey is to provide a thorough theoretical analysis of popular deep learning techniques in medical anomaly detection. In particular, we contribute a coherent and systematic review of state-of-the-art techniques, comparing and contrasting their architectural differences as well as training algorithms. Furthermore, we provide a comprehensive overview of deep model interpretation strategies that can be used to interpret model decisions. In addition, we outline the key limitations of existing deep medical anomaly detection techniques and propose key research directions for further investigation.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {141},
numpages = {37},
keywords = {temporal analysis, machine learning, anomaly detection, Deep learning}
}

@article{10.1016/j.eswa.2016.12.035,
author = {Haixiang, Guo and Yijing, Li and Shang, Jennifer and Mingyun, Gu and Yuanyue, Huang and Bing, Gong},
title = {Learning from class-imbalanced data},
year = {2017},
issue_date = {May 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {73},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.12.035},
doi = {10.1016/j.eswa.2016.12.035},
abstract = {527 articles related to imbalanced data and rare events are reviewed.Viewing reviewed papers from both technical and practical perspectives.Summarizing existing methods and corresponding statistics by a new taxonomy idea.Categorizing 162 application papers into 13 domains and giving introduction.Some opening questions are discussed at the end of this manuscript. Rare events, especially those that could potentially negatively impact society, often require humans decision-making responses. Detecting rare events can be viewed as a prediction task in data mining and machine learning communities. As these events are rarely observed in daily life, the prediction task suffers from a lack of balanced data. In this paper, we provide an in depth review of rare event detection from an imbalanced learning perspective. Five hundred and seventeen related papers that have been published in the past decade were collected for the study. The initial statistics suggested that rare events detection and imbalanced learning are concerned across a wide range of research areas from management science to engineering. We reviewed all collected papers from both a technical and a practical point of view. Modeling methods discussed include techniques such as data preprocessing, classification algorithms and model evaluation. For applications, we first provide a comprehensive taxonomy of the existing application domains of imbalanced learning, and then we detail the applications for each category. Finally, some suggestions from the reviewed papers are incorporated with our experiences and judgments to offer further research directions for the imbalanced learning and rare event detection fields.},
journal = {Expert Syst. Appl.},
month = may,
pages = {220–239},
numpages = {20},
keywords = {Rare events, Machine learning, Imbalanced data, Data mining}
}

@article{10.1016/j.jss.2017.06.070,
author = {Yu, Qiao and Jiang, Shujuan and Zhang, Yanmei},
title = {A feature matching and transfer approach for cross-company defect prediction},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {132},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.06.070},
doi = {10.1016/j.jss.2017.06.070},
abstract = {A feature matching algorithm is designed to address the heterogeneous features.A feature matching and transfer (FMT) approach for cross-company defect prediction.An empirical study is conducted on 16 datasets from NASA and PROMISE.The results show that FMT is effective for cross-company defect prediction. Software defect prediction has drawn much attention of researchers in software engineering. Traditional defect prediction methods aim to build the prediction model based on historical data. For a new project or a project with limited historical data, we cannot build a good prediction model. Therefore, researchers have proposed the cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) methods to share the historical data among different projects. However, the features of cross-company datasets are often heterogeneous, which may affect the feasibility of CCDP. To address the heterogeneous features of CCDP, this paper presents a feature matching and transfer (FMT) approach. First, we conduct feature selection for the source project and get the distribution curves of selected features. Similarly, we also get the distribution curves of all features in the target project. Second, according to the distance of different distribution curves, we design a feature matching algorithm to convert the heterogeneous features into the matched features. Finally, we can achieve feature transfer from the source project to the target project. All experiments are conducted on 16 datasets from NASA and PROMISE, and the results show that FMT is effective for CCDP.},
journal = {J. Syst. Softw.},
month = oct,
pages = {366–378},
numpages = {13},
keywords = {Software defect prediction, Heterogeneous features, Feature transfer, Feature matching}
}

@article{10.1007/s10489-014-0610-5,
author = {Zhang, Xueying and Song, Qinbao and Wang, Guangtao and Zhang, Kaiyuan and He, Liang and Jia, Xiaolin},
title = {A dissimilarity-based imbalance data classification algorithm},
year = {2015},
issue_date = {April     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {42},
number = {3},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-014-0610-5},
doi = {10.1007/s10489-014-0610-5},
abstract = {Class imbalances have been reported to compromise the performance of most standard classifiers, such as Naive Bayes, Decision Trees and Neural Networks. Aiming to solve this problem, various solutions have been explored mainly via balancing the skewed class distribution or improving the existing classification algorithms. However, these methods pay more attention on the imbalance distribution, ignoring the discriminative ability of features in the context of class imbalance data. In this perspective, a dissimilarity-based method is proposed to deal with the classification of imbalanced data. Our proposed method first removes the useless and redundant features by feature selection from the given data set; and then, extracts representative instances from the reduced data as prototypes; finally, projects the reduced data into a dissimilarity space by constructing new features, and builds the classification model with data in the dissimilarity space. Extensive experiments over 24 benchmark class imbalance data sets show that, compared with seven other imbalance data tackling solutions, our proposed method greatly improves the performance of imbalance learning, and outperforms the other solutions with all given classification algorithms.},
journal = {Applied Intelligence},
month = apr,
pages = {544–565},
numpages = {22},
keywords = {Software defect prediction, Prototype selection, Feature selection, Dissimilarity-based classification, Class imbalance}
}

@article{10.1007/s10115-013-0721-z,
author = {Czibula, Gabriela and Marian, Zsuzsanna and Czibula, Istvan Gergely},
title = {Detecting software design defects using relational association rule mining},
year = {2015},
issue_date = {March     2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {42},
number = {3},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-013-0721-z},
doi = {10.1007/s10115-013-0721-z},
abstract = {In this paper, we are approaching, from a machine learning perspective, the problem of automatically detecting defective software entities (classes and methods) in existing software systems, a problem of major importance during software maintenance and evolution. In order to improve the internal quality of a software system, identifying faulty entities such as classes, modules, methods is essential for software developers. As defective software entities are hard to identify, machine learning-based classification models are still developed to approach the problem of detecting software design defects. We are proposing a novel method based on relational association rule mining for detecting faulty entities in existing software systems. Relational association rules are a particular type of association rules and describe numerical orderings between attributes that commonly occur over a dataset. Our method is based on the discovery of relational association rules for identifying design defects in software. Experiments on open source software are conducted in order to detect defective classes in object-oriented software systems, and a comparison of our approach with similar existing approaches is provided. The obtained results show that our method is effective for software design defect detection and confirms the potential of our proposal.},
journal = {Knowl. Inf. Syst.},
month = mar,
pages = {545–577},
numpages = {33},
keywords = {Software design, Machine learning, Defect detection, Data mining, Association rule mining}
}

@article{10.1016/j.advengsoft.2021.103031,
author = {Cao, Minh-Tu and Nguyen, Ngoc-Mai and Chang, Kuan-Tsung and Tran, Xuan-Linh and Hoang, Nhat-Duc},
title = {Automatic recognition of concrete spall using image processing and metaheuristic optimized LogitBoost classification tree},
year = {2021},
issue_date = {Sep 2021},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {159},
number = {C},
issn = {0965-9978},
url = {https://doi.org/10.1016/j.advengsoft.2021.103031},
doi = {10.1016/j.advengsoft.2021.103031},
journal = {Adv. Eng. Softw.},
month = sep,
numpages = {14},
keywords = {Ensemble learning, Classification tree, Forensic-based investigation, Image processing, Building maintenance, Concrete spall detection}
}

@inproceedings{10.1145/3325917.3325930,
author = {Zhang, Zhong and Zhang, Borui and Akiduki, Takuma},
title = {Specular reflection Surface Defects Detection by using Deep Learning},
year = {2019},
isbn = {9781450366359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325917.3325930},
doi = {10.1145/3325917.3325930},
abstract = {As you know that defects inspection of specular surface is very difficult because its specular reflection is very strong and defects' reflection is weaker. And the existing computer vision-based industrial parts surface defect detection methods are limited by environmental factors, and the image preprocessing process is complex. On the other hand, with the rapid development of Convolutional Neural Networks (CNN) that is one type of deep learning and has excellent performance for image processing, has led to the rapid development of computer vision research based on deep learning. In this paper, we proposed an ensemble CNN in which integrated two convolutional neural network models for surface defect detection, and obtained better results.},
booktitle = {Proceedings of the 2019 3rd International Conference on Information System and Data Mining},
pages = {6–10},
numpages = {5},
keywords = {Specular surface, Networks, Machine vision, Defect detection, Convolutional neural network},
location = {Houston, TX, USA},
series = {ICISDM '19}
}

@inproceedings{10.1145/3379177.3388892,
author = {John, Meenu Mary and Olsson, Helena Holmstr\"{o}m and Bosch, Jan},
title = {Developing ML/DL Models: A Design Framework},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388892},
doi = {10.1145/3379177.3388892},
abstract = {Artificial Intelligence is becoming increasingly popular with organizations due to the success of Machine Learning and Deep Learning techniques. Using these techniques, data scientists learn from vast amounts of data to enhance behaviour in software-intensive systems. Despite the attractiveness of these techniques, however, there is a lack of systematic and structured design process for developing ML/DL models. The study uses a multiple-case study approach to explore the different activities and challenges data scientists face when developing ML/DL models in software-intensive embedded systems. In addition, we have identified seven different phases in the proposed design process leading to effective model development based on the case study. Iterations identified between phases and events which trigger these iterations optimize the design process for ML/DL models. Lessons learned from this study allow data scientists and engineers to develop high-performance ML/DL models and also bridge the gap between high demand and low supply of data scientists.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {1–10},
numpages = {10},
keywords = {Software Engineering, Machine Learning, Design, Deep Learning, Artificial Intelligence},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@article{10.1007/s10845-021-01845-5,
author = {Le-Hong, Thai and Lin, Pai Chen and Chen, Jian-Zhong and Pham, Thinh Duc Quy and Van Tran, Xuan},
title = {Data-driven models for predictions of geometric characteristics of bead fabricated by selective laser melting},
year = {2021},
issue_date = {Mar 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01845-5},
doi = {10.1007/s10845-021-01845-5},
abstract = {In this paper, the effects of two key process parameters of the selective laser melting process, namely laser power and scanning speed, on the single-track morphologies and the bead characteristics, especially the depth-to-width D/W and height-to-width H/W ratios, were investigated using both experimental and Machine Learning (ML) approaches. A total of 840 single tracks were fabricated with several combinations of laser power and scanning speed levels. Surface morphologies of the single tracks and bead profiles were thoroughly investigated, providing a track-type map and the evolutions of the bead characteristics as a function of laser power and scanning speed. The results indicate neither severe balling nor keyholing effect for all combinations of laser power and scanning speed. Besides, simple relationships cannot accurately describe the evolutions of the D/W and H/W ratios as a function of laser power and scanning speed. Two Machine Learning-based regression models, Random Forest and Artificial Neural Network, were chosen to estimate the D/W and H/W ratios using laser power and scanning speed. The Bayesian optimization algorithm was employed to optimize the model hyperparameter selection. Both Machine Learning-based models appear to be able to predict reasonably well the two aspect ratios, D/W and H/W, with an overall R2 value reaching about 90%, evaluated on the cross-validation dataset after a few seconds of training time, respectively.},
journal = {J. Intell. Manuf.},
month = sep,
pages = {1241–1257},
numpages = {17},
keywords = {Bayesian optimization, Artificial neural network, Machine learning, Single-track morphology, Bead geometry, Selective melting laser}
}

@article{10.1016/j.artmed.2021.102162,
author = {Naranjo, Lizbeth and P\'{e}rez, Carlos J. and Campos-Roca, Yolanda and Madruga, Mario},
title = {Replication-based regularization approaches to diagnose Reinke's edema by using voice recordings},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {120},
number = {C},
issn = {0933-3657},
url = {https://doi.org/10.1016/j.artmed.2021.102162},
doi = {10.1016/j.artmed.2021.102162},
journal = {Artif. Intell. Med.},
month = oct,
numpages = {10},
keywords = {Variable selection, Replicated measurements, Regularization, Reinke's edema, Classification, Acoustic features}
}

@article{10.1016/j.asoc.2017.05.027,
author = {Tuar, Tea and Gantar, Klemen and Koblar, Valentin and enko, Bernard and Filipi, Bogdan},
title = {A study of overfitting in optimization of a manufacturing quality control procedure},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {59},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.05.027},
doi = {10.1016/j.asoc.2017.05.027},
abstract = {Display Omitted Practical solution developed for quality control in a manufacturing process.Analysis detects overfitting of the optimization objective.Detailed investigation confirms optimization is beneficial despite overfitting. Quality control of the commutator manufacturing process can be automated by means of a machine learning model that can predict the quality of commutators as they are being manufactured. Such a model can be constructed by combining machine vision, machine learning and evolutionary optimization techniques. In this procedure, optimization is used to minimize the model error, which is estimated using single cross-validation. This work exposes the overfitting that emerges in such optimization. Overfitting is shown for three machine learning methods with different sensitivity to it (trees, additionally pruned trees and random forests) and assessed in two ways (repeated cross-validation and validation on a set of unseen instances). Results on two distinct quality control problems show that optimization amplifies overfitting, i.e., the single cross-validation error estimate for the optimized models is overly optimistic. Nevertheless, minimization of the error estimate by single cross-validation in general results in minimization of the other error estimates as well, showing that optimization is indeed beneficial in this context.},
journal = {Appl. Soft Comput.},
month = oct,
pages = {77–87},
numpages = {11},
keywords = {Quality control, Overfitting, Optimization, Machine vision, Machine learning}
}

@article{10.1007/s13748-021-00236-4,
author = {Raghuwanshi, Bhagat Singh and Shukla, Sanyam},
title = {Classifying multiclass imbalanced data using generalized class-specific extreme learning machine},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {10},
number = {3},
url = {https://doi.org/10.1007/s13748-021-00236-4},
doi = {10.1007/s13748-021-00236-4},
abstract = {Learning from the imbalanced problem is among the most attractive issues in the contemporary machine learning community. However, the extensive majority of attention in this domain is given to the two-class imbalanced problems, while their much more complex multiclass counterparts are comparatively unexplored. It has been shown (Huang et al. in IEEE Trans Syst Man Cybern B (Cybern) 42(2):513–529, 2012) that extreme learning machine (ELM) achieves much better generalization performance compared to support vector machine (SVM) and least-squares support vector machine (LS-SVM) for multiclass classification problems. On this account, this work proposes a novel generalized class-specific extreme learning machine (GCS-ELM), the extension of our recently proposed, class-specific extreme learning machine (CS-ELM) to address the multiclass imbalanced problems more effectively. The proposed GCS-ELM can be applied directly to the multiclass imbalance problems. The proposed method also has reduced computational cost compared to the weighted extreme learning machine (WELM) for multiclass imbalance problems. The proposed method uses class-specific regularization coefficients, which are computed by employing class distribution. The proposed method has lower computational overhead compared to the class-specific cost regulation extreme learning machine (CCR-ELM). The proposed work is assessed by using benchmark real-world imbalanced datasets downloaded from the well-known KEEL dataset repository and synthetic datasets. The experimental results, supported by the extensive statistical analysis, demonstrate that GCS-ELM is capable to improve the generalization performance for multiclass imbalanced classification problems.},
journal = {Prog. in Artif. Intell.},
month = sep,
pages = {259–281},
numpages = {23},
keywords = {Classification, Multiclass imbalance problem, Generalized class-specific extreme learning machine, Extreme learning machine}
}

@article{10.1007/s10845-020-01566-1,
author = {Du, Wangzhe and Shen, Hongyao and Fu, Jianzhong and Zhang, Ge and Shi, Xuanke and He, Quan},
title = {Automated detection of defects with low semantic information in X-ray images based on deep learning},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01566-1},
doi = {10.1007/s10845-020-01566-1},
abstract = {Nondestructive testing using X-ray imaging has been widely adopted in the defect detection of casting parts for quality management. Deep learning has been proved to be an effective way to detect defects in X-ray images. In this work, Feature Pyramid Network (FPN) which has been utilized broadly in many applications is adopted as our baseline. In FPN, there mainly exits two issues: firstly, down sampling operation in Convolutional Neural Network is often utilized to enhance the perception field, causing the loss of location information in feature maps, and secondly, there exists feature imbalance in feature maps and proposals. DetNet and Path Aggregation Network are adopted to solve the two shortages. To further improve the recall rate, soft Non-Maximum Suppression (soft-NMS) is adopted to remain more proposals that have high classification confidence. Defects in X-ray images of casting parts are provided with low semantic information, causing the different instances between detection results and annotations in the same area. We propose soft Intersection Over Union (soft-IOU) criterion which could evaluate several results or ground truths in the near area, making it more accurate to evaluate detection results. The experimental results demonstrate that the three proposed strategies have better performance than the baseline for our dataset.},
journal = {J. Intell. Manuf.},
month = jan,
pages = {141–156},
numpages = {16},
keywords = {Computer vision, X-ray image, Deep learning, Casting parts, Defect detection}
}

@article{10.1016/j.jss.2021.111044,
author = {Pereira, Juliana Alves and Acher, Mathieu and Martin, Hugo and J\'{e}z\'{e}quel, Jean-Marc and Botterweck, Goetz and Ventresque, Anthony},
title = {Learning software configuration spaces: A systematic literature review},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111044},
doi = {10.1016/j.jss.2021.111044},
journal = {J. Syst. Softw.},
month = dec,
numpages = {29},
keywords = {Configurable systems, Machine learning, Software product lines, Systematic literature review}
}

@article{10.1016/j.aei.2021.101318,
author = {Lv, Yaqiong and Zhou, Qianwen and Li, Yifan and Li, Weidong},
title = {A predictive maintenance system for multi-granularity faults based on AdaBelief-BP neural network and fuzzy decision making},
year = {2021},
issue_date = {Aug 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2021.101318},
doi = {10.1016/j.aei.2021.101318},
journal = {Adv. Eng. Inform.},
month = aug,
numpages = {12},
keywords = {Fuzzy decision making, AdaBelief-BP NN, Predictive maintenance, Multi-granularity faults, Fault prediction}
}

@article{10.1016/j.peva.2012.09.004,
author = {Cotroneo, Domenico and Natella, Roberto and Pietrantuono, Roberto},
title = {Predicting aging-related bugs using software complexity metrics},
year = {2013},
issue_date = {March, 2013},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {70},
number = {3},
issn = {0166-5316},
url = {https://doi.org/10.1016/j.peva.2012.09.004},
doi = {10.1016/j.peva.2012.09.004},
abstract = {Long-running software systems tend to show degraded performance and an increased failure occurrence rate. This problem, known as Software Aging, which is typically related to the runtime accumulation of error conditions, is caused by the activation of the so-called Aging-Related Bugs (ARBs). This paper aims to predict the location of Aging-Related Bugs in complex software systems, so as to aid their identification during testing. First, we carried out a bug data analysis on three large software projects in order to collect data about ARBs. Then, a set of software complexity metrics were selected and extracted from the three projects. Finally, by using such metrics as predictor variables and machine learning algorithms, we built fault prediction models that can be used to predict which source code files are more prone to Aging-Related Bugs.},
journal = {Perform. Eval.},
month = mar,
pages = {163–178},
numpages = {16},
keywords = {Software complexity metrics, Software aging, Fault prediction, Aging-related bugs}
}

@article{10.1016/j.dsp.2021.103150,
author = {Xu, Hongling and Ma, Ruizhe and Yan, Li and Ma, Zongmin},
title = {Two-stage prediction of machinery fault trend based on deep learning for time series analysis},
year = {2021},
issue_date = {Oct 2021},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {117},
number = {C},
issn = {1051-2004},
url = {https://doi.org/10.1016/j.dsp.2021.103150},
doi = {10.1016/j.dsp.2021.103150},
journal = {Digit. Signal Process.},
month = oct,
numpages = {12},
keywords = {Extra-tree, Random forest, LSTM, Time series, Fault trend}
}

@inproceedings{10.1109/ITSC48978.2021.9565036,
author = {Anwar, Noreen and Shen, Zhen and Wei, Qinglai and Xiong, Gang and Ye, Peijun and Li, Zhishuai and Lv, Yisheng and Zhao, Hongxia},
title = {YOLOv4 Based Deep Learning Algorithm for Defects Detection and Classification of Rail Surfaces},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC48978.2021.9565036},
doi = {10.1109/ITSC48978.2021.9565036},
abstract = {To investigate the safety of railway operations, it is significant to measure the technical defects of the rail transit. Traditional machine vision technology does not show better detection results due to the complicated and distinct features of the rail surface. This paper presents a deep learning algorithm based on YOLOv4 which better realise the rail surface's defect detection. Our proposed approach uses modified version of CSPDarkent-53 as the backbone, consequently achieve faster and more accurate detection outcomes. We use six types of datasets of different images of the rail surface for investigation of the defects and compare the outcomes with a different network. This technique is used to evaluate our proposed method's efficiency to detect and classify the defects by comparing them with other techniques. Moreover, the experimental outcomes depict the promising capability of our proposed method. The results represent that accuracy of this algorithm can reach up to 96.5% on the mAP metric. This approach has significant importance for the surface detection of defects in rail transit.},
booktitle = {2021 IEEE International Intelligent Transportation Systems Conference (ITSC)},
pages = {1616–1620},
numpages = {5},
location = {Indianapolis, IN, USA}
}

@inproceedings{10.1145/3475716.3475790,
author = {Wang, Song and Wang, Junjie and Nam, Jaechang and Nagappan, Nachiappan},
title = {Continuous Software Bug Prediction},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475790},
doi = {10.1145/3475716.3475790},
abstract = {Background: Many software bug prediction models have been proposed and evaluated on a set of well-known benchmark datasets. We conducted pilot studies on the widely used benchmark datasets and observed common issues among them. Specifically, most of existing benchmark datasets consist of randomly selected historical versions of software projects, which poses non-trivial threats to the validity of existing bug prediction studies since the real-world software projects often evolve continuously. Yet how to conduct software bug prediction in the real-world continuous software development scenarios is not well studied.Aims: In this paper, to bridge the gap between current software bug prediction practice and real-world continuous software development, we propose new approaches to conduct bug prediction in real-world continuous software development regarding model building, updating, and evaluation.Method: For model building, we propose ConBuild, which leverages distributional characteristics of bug prediction data to guide the training version selection. For model updating, we propose ConUpdate, which leverages the evolution of distributional characteristics of bug prediction data between versions to guide the reuse or update of bug prediction models in continuous software development. For model evaluation, we propose ConEA, which leverages the evolution of buggy probability of files between versions to conduct effort-aware evaluation.Results: Experiments on 120 continuously release versions that span across six large-scale open-source software systems show the practical value of our approaches.Conclusions: This paper provides new insights and guidelines for conducting software bug prediction in the context of continuous software development.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {14},
numpages = {12},
keywords = {software quality, software defect prediction, continuous software development, Empirical software engineering},
location = {Bari, Italy},
series = {ESEM '21}
}

@inproceedings{10.1145/3348445.3348453,
author = {Cynthia, Shamse Tasnim and Ripon, Shamim H.},
title = {Predicting and Classifying Software Faults: A Data Mining Approach},
year = {2019},
isbn = {9781450371957},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3348445.3348453},
doi = {10.1145/3348445.3348453},
abstract = {In the field of software engineering, the detection of fault in the software has become a major topic to explore. With the help of data mining and machine learning approaches, this paper aims to denote whether a software is fault prone or not. In order to accomplish that this paper gives importance to compare between different machine learning approaches and by observing their performances we can conclude which models perform better to detect fault in the selected software modules. The dataset we have chosen to work on has imbalanced data. This paper research also worked with the imbalanced dataset and what results the imbalanced dataset gave when examined. The accuracy comparison, the performance of the different metrics can broadly help in software defect detection mechanism.},
booktitle = {Proceedings of the 7th International Conference on Computer and Communications Management},
pages = {143–147},
numpages = {5},
keywords = {prediction, data mining, association rules, Software faults, SVM, Adaboost},
location = {Bangkok, Thailand},
series = {ICCCM '19}
}

@inproceedings{10.5555/645526.657125,
author = {Cohen, William W. and Devanbu, Premkumar T.},
title = {A Comparative Study of Inductive Logic Programming Methods for Software Fault Prediction},
year = {1997},
isbn = {1558604863},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Fourteenth International Conference on Machine Learning},
pages = {66–74},
numpages = {9},
series = {ICML '97}
}

@article{10.1007/s10878-019-00494-y,
author = {He, Cheng and Liu, Changchun and Wu, Tao and Xu, Ying and Wu, Yang and Chen, Tong},
title = {Medical rolling bearing fault prognostics based on improved extreme learning machine},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {42},
number = {4},
issn = {1382-6905},
url = {https://doi.org/10.1007/s10878-019-00494-y},
doi = {10.1007/s10878-019-00494-y},
abstract = {The problem studied in this article:the random selection of the input weight and the implicit layer bias of the extreme learning machine leads to the instability of the medical rolling bearing fault prediction result of the algorithm. It requires more hidden layer nodes to ensure the accuracy of the algorithm, duing to this, Ensemble Error Minimized Extreme Learning Machine (EEM-ELM) is proposed. The EEM-ELM uses various error limit learning machines (EM-ELM) trained on different training sets as member classifiers. Member classifier factors are also used, including predictive entropy, which verifies the set’s accuracy and average and output weights as weights. All of these form a composite classifier by weighted linear combination. This method skillfully solves the problem of optimal hidden layer neurons number selection. The normalized energy and permutation entropy of each IMF component obtained by VMD decomposition fault signal are established as feature vectors, and the improved EEM-ELM algorithm is used as the fault diagnosis model for bearing fault classification algorithm. The fault diagnosis model is applied to the classification of bearing fault signals. The analysis of experimental data proves that the classification result of the proposed EEM-ELM algorithm is better than the ELM algorithm. At the same time, the accuracy rate is higher than each member classifier because of proper weighting processing. Apart from this, since the EEM-ELM algorithm integrates the error minimization limit learning machine, the EEM-ELM algorithm does not need to select the optimal hidden layer node number. The EEM-ELM algorithm only needs to specify the maximum number of training set samples that each EM-ELM-based classifier can tolerate misclassification to achieve high stability and high accuracy classification.},
journal = {J. Comb. Optim.},
month = nov,
pages = {700–721},
numpages = {22},
keywords = {Accuracy rate, VMD, Ensemble error minimized extreme learning machine, Fault prognostics, Medical rolling bearing}
}

@article{10.1007/s10270-020-00803-8,
author = {Safdar, Safdar Aqeel and Lu, Hong and Yue, Tao and Ali, Shaukat and Nie, Kunming},
title = {A framework for automated multi-stage and multi-step product configuration of cyber-physical systems},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {1},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00803-8},
doi = {10.1007/s10270-020-00803-8},
abstract = {Product line engineering (PLE) has been employed to large-scale cyber-physical systems (CPSs) to provide customization based on users’ needs. A PLE methodology can be characterized by its support for capturing and managing the abstractions as commonalities and variabilities and the automation of the configuration process for effective selection and customization of reusable artifacts. The automation of a configuration process heavily relies on the captured abstractions and formally specified constraints using a well-defined modeling methodology. Based on the results of our previous work and a thorough literature review, in this paper, we propose a conceptual framework to support multi-stage and multi-step automated product configuration of CPSs, including a comprehensive classification of constraints and a list of automated functionalities of a CPS configuration solution. Such a framework can serve as a guide for researchers and practitioners to evaluate an existing CPS PLE solution or devise a novel CPS PLE solution. To validate the framework, we conducted three real-world case studies. Results show that the framework fulfills all the requirements of the case studies in terms of capturing and managing variabilities and constraints. Results of the literature review indicate that the framework covers all the functionalities concerned by the literature, suggesting that the framework is complete for enabling the maximum automation of configuration in CPS PLE.},
journal = {Softw. Syst. Model.},
month = feb,
pages = {211–265},
numpages = {55},
keywords = {Real-world case studies, Variability modeling, Constraint classification, Multi-stage and multi-step configuration process, Automated configuration, Product line engineering, Cyber-physical systems}
}

@inproceedings{10.1007/978-3-030-86960-1_34,
author = {Ribeiro, Diogo and Matos, Lu\'{\i}s Miguel and Cortez, Paulo and Moreira, Guilherme and Pilastri, Andr\'{e}},
title = {A Comparison of Anomaly Detection Methods for Industrial Screw Tightening},
year = {2021},
isbn = {978-3-030-86959-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86960-1_34},
doi = {10.1007/978-3-030-86960-1_34},
abstract = {Within the context of Industry 4.0, quality assessment procedures using data-driven techniques are becoming more critical due to the generation of massive amounts of production data. In this paper, we address the detection of abnormal screw tightening processes, which is a relevant industrial task. Since labeling is costly, requiring a manual effort, we focus on unsupervised approaches. In particular, we assume a low-dimensional input screw fastening approach that is based only on angle-torque pairs. Using such pairs, we explore three main unsupervised Machine Learning (ML) algorithms: Local Outlier Factor (LOF), Isolation Forest (iForest) and a deep learning Autoencoder (AE). For benchmarking purposes, we also explore a supervised Random Forest (RF) algorithm. Several computational experiments were held by using recent industrial data with 2.8 million angle-torque pair records and a realistic and robust rolling window evaluation. Overall, high quality anomaly discrimination results were achieved by the iForest (99%) and AE (95% and 96%) unsupervised methods, which compared well against the supervised RF (99% and 91%). When compared with iForest, the AE requires less computation effort and provides faster anomaly detection response times.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part II},
pages = {485–500},
numpages = {16},
keywords = {Unsupervised learning, Random Forest, One-class classification, Isolation Forest, Industry 4.0, Deep learning, Autoencoder},
location = {Cagliari, Italy}
}

@inproceedings{10.1109/CASE49439.2021.9551414,
author = {Litvintseva, Anna and Evstafev, Oleg and Shavetov, Sergey},
title = {Real-time Steel Surface Defect Recognition Based on CNN},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CASE49439.2021.9551414},
doi = {10.1109/CASE49439.2021.9551414},
abstract = {Steel is one of the most important building materials of our time, and the process of producing flat plates is complex. Before steel is shipped or delivered, the sheets must undergo a thorough inspection procedure to avoid defects. Identification and classification of rolled metal surface defects are one of the main tasks for the correct evaluation of product quality. This work aims to develop a method for recognizing and classifying defects of metal surfaces by their images in real-time. The algorithm is aimed at improving production standards and process efficiency. In this paper, Deep Learning (DL) and Computer Vision (CV) techniques are used to solve the problem of defect detection on the steel surface sheets. Convolutional Neural Network (CNN) architectures are compared, and various steel defects are detected and recognized. The result of this work is a comparative analysis of DL models and the choice of an algorithm designed to search and classify defects in real-time. The use of one CNN model can make it possible to create a tool that greatly facilitates the work of a person.},
booktitle = {2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)},
pages = {1118–1123},
numpages = {6},
location = {Lyon, France}
}

@article{10.1007/s11334-015-0256-4,
author = {Valles-Barajas, Fernando},
title = {A comparative analysis between two techniques for the prediction of software defects: fuzzy and statistical linear regression},
year = {2015},
issue_date = {December  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {11},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-015-0256-4},
doi = {10.1007/s11334-015-0256-4},
abstract = {Software engineers should estimate the necessary resources (time, people, software tools among others) to satisfy software project requirements; this activity is carried out in the planning phase. The estimated time for developing software projects is a necessary element to establish the cost of software projects and to assign human resources to every phase of software projects. Most companies fail to finish software projects on time because of a poor estimation technique or the lack of the same. The estimated time must consider the time spent eliminating software defects injected during each of the software phases. A comparative analysis between two techniques (fuzzy linear regression and statistical linear regression) to perform software defect estimation is presented. These two techniques model uncertainty in a different way; statistical linear regression models uncertainty as randomness, whereas fuzzy linear regression models uncertainty as fuzziness. The main objective of this paper was to establish the kind of uncertainty associated with software defect prediction and to contrast these two prediction techniques. The KC1 NASA data set was used to do this analysis. Only six of the metrics included in KC1 data set and lines of code metric were used in this comparative analysis. Descriptive statistics was first used to have an overview of the main characteristics of the data set used in this research. Linearity property between predictor variables and the variable of interest number of defects was checked using scatter plots and Pearson's correlation coefficient. Then the problem of multicollinearity was verified using inter-correlations among metrics and the variance inflation factor. Best subset regression was applied to detect the most influencing subset of predictor variables; this subset was later used to build fuzzy and statistical regression models. Linearity property between metrics and number of defects was confirmed. The problem of multicollinearity was not detected in the predictor variables. Best subset regression found that the subset composed of 5 variables was the most influencing subset. The analysis showed that the statistical regression model in general outperformed the fuzzy regression model. Techniques for making software defect prediction should be carefully employed in order to have quality plans. Software engineers should consider and understand a set of prediction techniques and know their weaknesses and strengths. At least, in the KC1 data set, the uncertainty in the software defect prediction model is due to randomness so it is reasonable to use statistical linear regression instead of fuzzy linear regression to build a prediction model.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {277–287},
numpages = {11},
keywords = {Statistical linear regression, Software defect prediction, Fuzzy linear regression}
}

@article{10.1016/j.compeleceng.2019.08.001,
author = {Prates, Ricardo M. and Cruz, Ricardo and Marotta, Andr\'{e} P. and Ramos, Rodrigo P. and Simas Filho, Eduardo F. and Cardoso, Jaime S.},
title = {Insulator visual non-conformity detection in overhead power distribution lines using deep learning},
year = {2019},
issue_date = {Sep 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {78},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.08.001},
doi = {10.1016/j.compeleceng.2019.08.001},
journal = {Comput. Electr. Eng.},
month = sep,
pages = {343–355},
numpages = {13},
keywords = {Multi-task learning (MTL), Convolutional Neural Networks (CNNs), Data augmentation, Automated inspection, Insulators, Overhead Distribution Power Lines (ODPLs)}
}

@article{10.1016/j.patcog.2021.108069,
author = {Raghuwanshi, Bhagat Singh and Shukla, Sanyam},
title = {Minimum variance-embedded kernelized extension of extreme learning machine for imbalance learning},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {119},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2021.108069},
doi = {10.1016/j.patcog.2021.108069},
journal = {Pattern Recogn.},
month = nov,
numpages = {23},
keywords = {Classification, Class imbalance problem, Minimum variance-embedded class-specific kernelized extreme learning machine, Extreme learning machine}
}

@inproceedings{10.1145/3368089.3409754,
author = {Harel-Canada, Fabrice and Wang, Lingxiao and Gulzar, Muhammad Ali and Gu, Quanquan and Kim, Miryung},
title = {Is neuron coverage a meaningful measure for testing deep neural networks?},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409754},
doi = {10.1145/3368089.3409754},
abstract = {Recent effort to test deep learning systems has produced an intuitive and compelling test criterion called neuron coverage (NC), which resembles the notion of traditional code coverage. NC measures the proportion of neurons activated in a neural network and it is implicitly assumed that increasing NC improves the quality of a test suite. In an attempt to automatically generate a test suite that increases NC, we design a novel diversity promoting regularizer that can be plugged into existing adversarial attack algorithms. We then assess whether such attempts to increase NC could generate a test suite that (1) detects adversarial attacks successfully, (2) produces natural inputs, and (3) is unbiased to particular class predictions. Contrary to expectation, our extensive evaluation finds that increasing NC actually makes it harder to generate an effective test suite: higher neuron coverage leads to fewer defects detected, less natural inputs, and more biased prediction preferences. Our results invoke skepticism that increasing neuron coverage may not be a meaningful objective for generating tests for deep neural networks and call for a new test generation technique that considers defect detection, naturalness, and output impartiality in tandem.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {851–862},
numpages = {12},
keywords = {Testing, Software Engineering, Neuron Coverage, Machine Learning, Adversarial Attack},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1007/978-3-030-76423-4_6,
author = {Delconte, Florian and Ngo, Phuc and Debled-Rennesson, Isabelle and Kerautret, Bertrand and Nguyen, Van-Tho and Constant, Thiery},
title = {Tree Defect Segmentation Using Geometric Features and CNN},
year = {2021},
isbn = {978-3-030-76422-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-76423-4_6},
doi = {10.1007/978-3-030-76423-4_6},
abstract = {Estimating the quality of standing trees or roundwood after felling is a crucial step in forest production trading. The on-going revolution in the forest sector resulting from the use of 3D sensors can also contribute to this step. Among them the terrestrial lidar scanning is a reference descriptive method offering the possibility to segment defects. In this paper, we propose a new reproducible method allowing to automatically segment the defects. It is based on the construction of a relief map inspired from a previous strategy and combining with a convolutional neural network to improve the resulting segmentation quality. The proposed method outperforms the previous results and the source code is publicly available with an online demonstration allowing to test the defect detection without any software installation.},
booktitle = {Reproducible Research in Pattern Recognition: Third International Workshop, RRPR 2021, Virtual Event, January 11, 2021, Revised Selected Papers},
pages = {80–100},
numpages = {21},
keywords = {U-Net, Centerline, LIDAR, Relief map, Defect segmentation, Wood surface defects}
}

@article{10.1016/j.neucom.2015.09.011,
author = {Tong, Le and Wong, W.K. and Kwong, C.K.},
title = {Differential evolution-based optimal Gabor filter model for fabric inspection},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {173},
number = {P3},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2015.09.011},
doi = {10.1016/j.neucom.2015.09.011},
abstract = {In this paper, a defect detection model using optimized Gabor filters, which is suitable for real-time operation, is proposed to tackle the woven fabric inspection problem in fashion industry. Based on the analysis of the particular characteristics of fabric defects, the proposed model utilizes composite differential evolution (CoDE) to optimize the parameters of Gabor filters, which can achieve the optimal feature extraction of fabric defects. Together with thresholding and fusion operations, the optimal Gabor filters can successfully segment the defects from the original image background. By using optimal Gabor filters instead of a Gabor filter bank, the computational cost of the detection model can be significantly reduced. The performance of the proposed defect detection model is evaluated off-line through extensive experiments based on various types of fabric. Experimental results reveal that the proposed detection model is effective and robust, and is superior than four existing models in terms of the high detection rate and low false alarm rate.},
journal = {Neurocomput.},
month = jan,
pages = {1386–1401},
numpages = {16},
keywords = {Optimal Gabor filters, Fabric quality inspection, Differential evolution, Defect detection}
}

@article{10.1155/2021/5558561,
author = {Shao, Yanli and Zhao, Jingru and Wang, Xingqi and Wu, Weiwei and Fang, Jinglong and Gao, Honghao},
title = {Research on Cross-Company Defect Prediction Method to Improve Software Security},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/5558561},
doi = {10.1155/2021/5558561},
abstract = {As the scale and complexity of software increase, software security issues have become the focus of society. Software defect prediction (SDP) is an important means to assist developers in discovering and repairing potential defects that may endanger software security in advance and improving software security and reliability. Currently, cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) are widely studied to improve the defect prediction performance, but there are still problems such as inconsistent metrics and large differences in data distribution between source and target projects. Therefore, a new CCDP method based on metric matching and sample weight setting is proposed in this study. First, a clustering-based metric matching method is proposed. The multigranularity metric feature vector is extracted to unify the metric dimension while maximally retaining the information contained in the metrics. Then use metric clustering to eliminate metric redundancy and extract representative metrics through principal component analysis (PCA) to support one-to-one metric matching. This strategy not only solves the metric inconsistent and redundancy problem but also transforms the cross-company heterogeneous defect prediction problem into a homogeneous problem. Second, a sample weight setting method is proposed to transform the source data distribution. Wherein the statistical source sample frequency information is set as an impact factor to increase the weight of source samples that are more similar to the target samples, which improves the data distribution similarity between the source and target projects, thereby building a more accurate prediction model. Finally, after the above two-step processing, some classical machine learning methods are applied to build the prediction model, and 12 project datasets in NASA and PROMISE are used for performance comparison. Experimental results prove that the proposed method has superior prediction performance over other mainstream CCDP methods.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {19}
}

@article{10.1016/j.jnca.2021.103213,
author = {Bochie, Kaylani and Gilbert, Mateus S. and Gantert, Luana and Barbosa, Mariana S.M. and Medeiros, Dianne S.V. and Campista, Miguel Elias M.},
title = {A survey on deep learning for challenged networks: Applications and trends},
year = {2021},
issue_date = {Nov 2021},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {194},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2021.103213},
doi = {10.1016/j.jnca.2021.103213},
journal = {J. Netw. Comput. Appl.},
month = nov,
numpages = {30},
keywords = {Machine learning, Deep learning, Vehicular networks, Wireless mobile networks, Industrial networks, Sensor networks, Internet of Things, Challenged networks}
}

@article{10.1016/j.eswa.2017.05.039,
author = {Affonso, Carlos and Rossi, Andr Luis Debiaso and Vieira, Fbio Henrique Antunes and de Carvalho, Andr Carlos Ponce de Leon Ferreira},
title = {Deep learning for biological image classification},
year = {2017},
issue_date = {November 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {85},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2017.05.039},
doi = {10.1016/j.eswa.2017.05.039},
abstract = {Compare Deep Learning archtecture with machine learning techniques.Classify the quality of wood board.Extract texture descriptor from wood images. A number of industries use human inspection to visually classify the quality of their products and the raw materials used in the production process, this process could be done automatically through digital image processing. The industries are not always interested in the most accurate technique for a given problem, but most appropriate for the expected results, there must be a balance between accuracy and computational cost. This paper investigates the classification of the quality of wood boards based on their images. For such, it compares the use of deep learning, particularly Convolutional Neural Networks, with the combination of texture-based feature extraction techniques and traditional techniques: Decision tree induction algorithms, Neural Networks, Nearest neighbors and Support vector machines. Reported studies show that Deep Learning techniques applied to image processing tasks have achieved predictive performance superior to traditional classification techniques, mainly in high complex scenarios. One of the reasons pointed out is their embedded feature extraction mechanism. Deep Learning techniques directly identify and extract features, considered by them to be relevant, in a given image dataset. However, empirical results for the image data set have shown that the texture descriptor method proposed, regardless of the strategy employed is very competitive when compared with Convolutional Neural Network for all the performed experiments. The best performance of the texture descriptor method could be caused by the nature of the image dataset. Finally are pointed out some perspectives of futures developments with the application of Active learning and Semi supervised methods.},
journal = {Expert Syst. Appl.},
month = nov,
pages = {114–122},
numpages = {9},
keywords = {Wood classification, Machine learning, Image classification, Deep learning}
}

@inproceedings{10.1145/3474624.3477070,
author = {Martins, Luana and Bezerra, Carla and Costa, Heitor and Machado, Ivan},
title = {Smart prediction for refactorings in the software test code},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3477070},
doi = {10.1145/3474624.3477070},
abstract = {Test smells are bad practices to either design or implement a test code. Their presence may reduce the test code quality, harming the software testing activities, primarily from a maintenance perspective. Therefore, defining strategies and tools to handle test smells and improve the test code quality is necessary. State-of-the-art strategies encompass automated support mainly based on hard thresholds of rules, static and dynamic metrics to identify the test smells. Such thresholds are subjective to interpretation and may not consider the complexity of the software projects. Moreover, they are limited as they do not automate test refactoring but only count on developers’ expertise and intuition. In this context, a technique that uses historical implicit or tacit data to generate knowledge could assist the identification and refactoring of test smells. This study aims to establish a novel approach based on machine learning techniques to suggest developers refactoring strategies for test smells. As an expected result, we could understand the applicability of the machine learning techniques to handle test smells and a framework proposal that helps developers in decision-making regarding the refactoring of test smells.},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {115–120},
numpages = {6},
keywords = {Test Smells, Software Quality, Machine Learning},
location = {Joinville, Brazil},
series = {SBES '21}
}

@article{10.1049/sfw2.12053,
author = {Huang, Qingan and Ma, Le and Jiang, Siyu and Wu, Guobin and Song, Hengjie and Jiang, Libiao and Zheng, Chunyun},
title = {A cross‐project defect prediction method based on multi‐adaptation and nuclear norm},
year = {2021},
issue_date = {April 2022},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {16},
number = {2},
url = {https://doi.org/10.1049/sfw2.12053},
doi = {10.1049/sfw2.12053},
abstract = {Cross‐project defect prediction (CPDP) is an important research direction in software defect prediction. Traditional CPDP methods based on hand‐crafted features ignore the semantic information in the source code. Existing CPDP methods based on the&nbsp;deep learning model may not fully consider the differences among projects. Additionally, these methods may not accurately classify the samples near the classification boundary. To solve these problems, the authors propose a model based on multi‐adaptation and nuclear norm (MANN) to deal with samples in projects. The feature of samples were embedded into the multi‐core Hilbert space for distribution and the multi‐kernel maximum mean discrepancy method was utilised to reduce differences among projects. More importantly, the nuclear norm module was constructed, which improved the discriminability and diversity of the target sample by calculating and maximizing the nuclear norm of the target sample in the process of domain adaptation, thus improving the performance of MANN. Finally, extensive experiments were conducted on 11 sizeable open‐source projects. The results indicate&nbsp;that the proposed method exceeds the state of the art under the widely used metrics.},
journal = {IET Software},
month = dec,
pages = {200–213},
numpages = {14},
keywords = {unsupervised learning, software reliability, software quality, neural nets}
}

@inproceedings{10.5555/647460.726104,
author = {Knudsen, Bengt R.},
title = {Fault Prediction in the Telephone Access Loop Using a Neural Network},
year = {1998},
isbn = {3540645756},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Proceedings of the 12th Biennial Conference of the Canadian Society for Computational Studies of Intelligence on Advances in Artificial Intelligence},
pages = {239–245},
numpages = {7},
series = {AI '98}
}

@inproceedings{10.1007/978-3-030-86230-5_43,
author = {Malaguti, Roney and Louren\c{c}o, Nuno and Silva, Cristov\~{a}o},
title = {A Well Lubricated Machine: A Data Driven Model for Lubricant Oil Conditions},
year = {2021},
isbn = {978-3-030-86229-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86230-5_43},
doi = {10.1007/978-3-030-86230-5_43},
abstract = {Diagnostic and predictive failure processes based on intelligent lubricant oil analysis are a important of the condition-based maintenance (CBM) approaches for diesel vehicle fleets. Companies are equipping each vehicle in the fleet with a large number of sensors, which allows the collection of vast amounts of data about the current state of each asset. With all this information now allows for the research and development of predictive models to help a fleet manager make informed decisions about the operating condition of the vehicles. This allows companies to accurately identify the state of wear and tear of a piece of equipment or system, making CBM more effective and reliable.In this paper we present a supervised machine learning framework based on the Random Forest Classifier (RF) to determine the operating condition of lubricant oil in diesel engines based on data from 5 different vehicles. We describe the how practitioners should collect and process data, and which features can be engineered to help describe the state of the lubrication system. This data will then be used by a RF model to determine the operational condition of the lubricating oil.The results presented show that the proposed approach is able to successfully identify the oil operating conditions, with the predictive model obtaining a Recall of 97.9%, a Precision of 99.5% and a F1-score of 98.7%. In addition, we evaluate the importance is the inclusion of new engineered features projected from raw data for better determination of the operating condition.},
booktitle = {Progress in Artificial Intelligence: 20th EPIA Conference on Artificial Intelligence, EPIA 2021, Virtual Event, September 7–9, 2021, Proceedings},
pages = {549–560},
numpages = {12},
keywords = {Random forest classifier, Diesel vehicle, Lubricating oils, Condition-based maintenance (CBM)}
}

@article{10.1007/s10664-014-9346-4,
author = {Ryu, Duksan and Choi, Okjoo and Baik, Jongmoon},
title = {Value-cognitive boosting with a support vector machine for cross-project defect prediction},
year = {2016},
issue_date = {February  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9346-4},
doi = {10.1007/s10664-014-9346-4},
abstract = {It is well-known that software defect prediction is one of the most important tasks for software quality improvement. The use of defect predictors allows test engineers to focus on defective modules. Thereby testing resources can be allocated effectively and the quality assurance costs can be reduced. For within-project defect prediction (WPDP), there should be sufficient data within a company to train any prediction model. Without such local data, cross-project defect prediction (CPDP) is feasible since it uses data collected from similar projects in other companies. Software defect datasets have the class imbalance problem increasing the difficulty for the learner to predict defects. In addition, the impact of imbalanced data on the real performance of models can be hidden by the performance measures chosen. We investigate if the class imbalance learning can be beneficial for CPDP. In our approach, the asymmetric misclassification cost and the similarity weights obtained from distributional characteristics are closely associated to guide the appropriate resampling mechanism. We performed the effect size A-statistics test to evaluate the magnitude of the improvement. For the statistical significant test, we used Wilcoxon rank-sum test. The experimental results show that our approach can provide higher prediction performance than both the existing CPDP technique and the existing class imbalance technique.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {43–71},
numpages = {29},
keywords = {Transfer learning, Cross-project defect prediction, Class imbalance, Boosting}
}

@article{10.1016/j.eswa.2016.06.005,
title = {A multiobjective weighted voting ensemble classifier based on differential evolution algorithm for text sentiment classification},
year = {2016},
issue_date = {November 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {62},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.06.005},
doi = {10.1016/j.eswa.2016.06.005},
abstract = {A novel multi-objective differential evolution algorithm based classifier ensemble for text sentiment classification. An empirical comparison of weighted and unweighted voting schemes. Extensive empirical analysis on metaheuristic based voting schemes for sentiment analysis. High classification accuracies for text sentiment classification (98.86% for Laptop dataset). Typically performed by supervised machine learning algorithms, sentiment analysis is highly useful for extracting subjective information from text documents online. Most approaches that use ensemble learning paradigms toward sentiment analysis involve feature engineering in order to enhance the predictive performance. In response, we sought to develop a paradigm of a multiobjective, optimization-based weighted voting scheme to assign appropriate weight values to classifiers and each output class based on the predictive performance of classification algorithms, all to enhance the predictive performance of sentiment classification. The proposed ensemble method is based on static classifier selection involving majority voting error and forward search, as well as a multiobjective differential evolution algorithm. Based on the static classifier selection scheme, our proposed ensemble method incorporates Bayesian logistic regression, na\"{\i}ve Bayes, linear discriminant analysis, logistic regression, and support vector machines as base learners, whose performance in terms of precision and recall values determines weight adjustment. Our experimental analysis of classification tasks, including sentiment analysis, software defect prediction, credit risk modeling, spam filtering, and semantic mapping, suggests that the proposed classification scheme can predict better than conventional ensemble learning methods such as AdaBoost, bagging, random subspace, and majority voting. Of all datasets examined, the laptop dataset showed the best classification accuracy (98.86%).},
journal = {Expert Syst. Appl.},
month = nov,
pages = {1–16},
numpages = {16}
}

@article{10.1155/2016/7658207,
author = {Tomar, Divya and Agarwal, Sonali},
title = {Prediction of defective software modules using class imbalance learning},
year = {2016},
issue_date = {January 2016},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2016},
issn = {1687-9724},
url = {https://doi.org/10.1155/2016/7658207},
doi = {10.1155/2016/7658207},
abstract = {Software defect predictors are useful to maintain the high quality of software products effectively. The early prediction of defective software modules can help the software developers to allocate the available resources to deliver high quality software products. The objective of software defect prediction system is to find as many defective software modules as possible without affecting the overall performance. The learning process of a software defect predictor is difficult due to the imbalanced distribution of software modules between defective and nondefective classes. Misclassification cost of defective software modules generally incurs much higher cost than the misclassification of nondefective one. Therefore, on considering the misclassification cost issue, we have developed a software defect prediction system using Weighted Least Squares Twin Support Vector Machine (WLSTSVM). This system assigns higher misclassification cost to the data samples of defective classes and lower cost to the data samples of nondefective classes. The experiments on eight software defect prediction datasets have proved the validity of the proposed defect prediction system. The significance of the results has been tested via statistical analysis performed by using nonparametric Wilcoxon signed rank test.},
journal = {Appl. Comp. Intell. Soft Comput.},
month = jan,
articleno = {6},
numpages = {1}
}

@article{10.1504/IJDATS.2017.10003991,
title = {Software fault proneness prediction: a comparative study between bagging, boosting, and stacking ensemble and base learner methods},
year = {2017},
issue_date = {January 2017},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {1},
issn = {1755-8050},
url = {https://doi.org/10.1504/IJDATS.2017.10003991},
doi = {10.1504/IJDATS.2017.10003991},
abstract = {Modules with defects might be the prime reason for decreasing the software quality and increasing the cost of maintenance. Therefore, the prediction of faulty modules of systems under test at early stages contributes to the overall quality of software products. In this research three symmetric ensemble methods: bagging, boosting and stacking are used to predict faulty modules based on evaluating the performance of 11 base learners. The results reveal that the defect prediction performance of the base learner classifier and ensemble learner classifiers is the same for na\"{\i}ve Bayes, Bayes net, PART, random forest, IB1, VFI, decision table, and NB tree base learners, the case was different for boosted SMO, bagged J48 and boosted and bagged random tree. In addition the results showed that the random forest classifier is one of the most significant classifiers that should be stacked with other classifiers to gain the better fault prediction.},
journal = {Int. J. Data Anal. Tech. Strateg.},
month = jan,
pages = {1–16},
numpages = {16}
}

@inproceedings{10.1145/3373477.3373486,
author = {Aggarwal, Simran},
title = {Software code analysis using ensemble learning techniques},
year = {2020},
isbn = {9781450372916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373477.3373486},
doi = {10.1145/3373477.3373486},
abstract = {Ensuing the advent of advancements in software systems, the probability of them containing high severity defects is exponentially on the rise. With each technological addition, the complexity of software is increasing. Reproduction and rectification of a defect requires time and effort. Current state of the art analysis tools cater to the investigation of static aspects of a production level code. However, it is imperative to assess the dynamic development process of a system so as to be able to timely detect erroneous components early on in the development life cycle of a software. A novel automated defect prediction feature enhancement is proposed that analyses the static structure of the current code and state of the software in past releases to extract relevant static and dynamic feature sets. Data generated is modelled for defect trends in the future release of the software by four ensemble classifiers. Results demonstrate the superiority of Voting algorithm for the problem of defect prediction.},
booktitle = {Proceedings of the 1st International Conference on Advanced Information Science and System},
articleno = {9},
numpages = {7},
keywords = {software quality, object-oriented metrics, machine learning, ensemble learning, empirical validation, defect prediction},
location = {Singapore, Singapore},
series = {AISS '19}
}

@article{10.1145/2853073.2853083,
author = {Rathore, Santosh Singh and Kumar, Sandeep},
title = {A Decision Tree Regression based Approach for the Number of Software Faults Prediction},
year = {2016},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2853073.2853083},
doi = {10.1145/2853073.2853083},
abstract = {Software fault prediction is an important activity to make software quality assurance (SQA) process more efficient, economic and targeted. Most of earlier works related to software fault prediction have focused on classifying software modules as faulty or non-faulty. However, prediction of the number of faults in a given software module is not adequately investigated. In this paper, we explore the capability of decision tree regression (DTR) for the number of faults prediction in two different scenarios, intra-release prediction and inter-releases prediction for the given software system. The experimental study is performed over five open-source software projects with their nineteen releases collected from the PROMISE data repository. The predictive accuracy of DTR is evaluated using absolute error and relative error, prediction at level l and goodness-of-t measure. The results show that decision tree regression produced significant prediction accuracy for the number of faults prediction in both the considered scenarios. The relative comparison of intra-release and inter-releases fault prediction shows that intra-project prediction produced better accuracy compared to inter-releases prediction across all the datasets},
journal = {SIGSOFT Softw. Eng. Notes},
month = feb,
pages = {1–6},
numpages = {6},
keywords = {Software Fault Prediction, Number of Faults Prediction, Decision Tree Regression}
}

@article{10.1016/j.camwa.2011.11.019,
author = {Razmjooy, Navid and Mousavi, B. Somayeh and Soleymani, F.},
title = {A real-time mathematical computer method for potato inspection using machine vision},
year = {2012},
issue_date = {January, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {63},
number = {1},
issn = {0898-1221},
url = {https://doi.org/10.1016/j.camwa.2011.11.019},
doi = {10.1016/j.camwa.2011.11.019},
abstract = {Detection of external defects on potatoes is the most important technology in the realization of automatic potato sorting stations. This paper presents a hierarchical grading method applied to the potatoes. In this work a potato defect detection combining with size sorting system using the machine vision will be proposed. This work also will focus on the mathematics methods used in automation with a particular emphasis on the issues associated with designing, implementing and using classification algorithms to solve equations. In the first step, a simple size sorting based on mathematical binarization is described, and the second step is to segment the defects; to do this, color based classifiers are used. All the detection standards for this work are referenced from the United States Agriculture Department, and Canadian Food Industries. Results show that we have a high accuracy in both size sorting and classification. Experimental results show that support vector machines have very high accuracy and speed between classifiers for defect detection.},
journal = {Comput. Math. Appl.},
month = jan,
pages = {268–279},
numpages = {12},
keywords = {Support vector machines, Potato, Otsu thresholding, Mathematical morphology, K nearest neighborhood, Defect detection}
}

@article{10.1145/3488280,
author = {Sowah, Robert A. and Kuditchar, Bernard and Mills, Godfrey A. and Acakpovi, Amevi and Twum, Raphael A. and Buah, Gifty and Agboyi, Robert},
title = {HCBST: An Efficient Hybrid Sampling Technique for Class Imbalance Problems},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {1556-4681},
url = {https://doi.org/10.1145/3488280},
doi = {10.1145/3488280},
abstract = {Class imbalance problem is prevalent in many real-world domains. It has become an active area of research. In binary classification problems, imbalance learning refers to learning from a dataset with a high degree of skewness to the negative class. This phenomenon causes classification algorithms to perform woefully when predicting positive classes with new examples. Data resampling, which involves manipulating the training data before applying standard classification techniques, is among the most commonly used techniques to deal with the class imbalance problem. This article presents a new hybrid sampling technique that improves the overall performance of classification algorithms for solving the class imbalance problem significantly. The proposed method called the Hybrid Cluster-Based Undersampling Technique (HCBST) uses a combination of the cluster undersampling technique to under-sample the majority instances and an oversampling technique derived from Sigma Nearest Oversampling based on Convex Combination, to oversample the minority instances to solve the class imbalance problem with a high degree of accuracy and reliability. The performance of the proposed algorithm was tested using 11 datasets from the National Aeronautics and Space Administration Metric Data Program data repository and University of California Irvine Machine Learning data repository with varying degrees of imbalance. Results were compared with classification algorithms such as the K-nearest neighbours, support vector machines, decision tree, random forest, neural network, AdaBoost, na\"{\i}ve Bayes, and quadratic discriminant analysis. Tests results revealed that for the same datasets, the HCBST performed better with average performances of 0.73, 0.67, and 0.35 in terms of performance measures of area under curve, geometric mean, and Matthews Correlation Coefficient, respectively, across all the classifiers used for this study. The HCBST has the potential of improving the performance of the class imbalance problem, which by extension, will improve on the various applications that rely on the concept for a solution.},
journal = {ACM Trans. Knowl. Discov. Data},
month = nov,
articleno = {57},
numpages = {37},
keywords = {classification, clustering, cluster undersampling technique, data sampling, Class imbalance}
}

@article{10.1016/j.neucom.2018.12.057,
author = {Wang, Kangwei and Zhang, Xin and Hao, Qiushi and Wang, Yan and Shen, Yi},
title = {Application of improved least-square generative adversarial networks for rail crack detection by AE technique},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {332},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.12.057},
doi = {10.1016/j.neucom.2018.12.057},
journal = {Neurocomput.},
month = mar,
pages = {236–248},
numpages = {13},
keywords = {Noise suppression, Least-square, Generative adversarial networks, Acoustic emission, Rail defect detection}
}

@article{10.1016/j.cie.2021.107767,
author = {Kim, Eun-Su and Choi, Seung-Hyun and Lee, Dong-Hee and Kim, Kwang-Jae and Bae, Young-Mok and Oh, Young-Chan},
title = {An oversampling method for wafer map defect pattern classification considering small and imbalanced data},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {162},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2021.107767},
doi = {10.1016/j.cie.2021.107767},
journal = {Comput. Ind. Eng.},
month = dec,
numpages = {12},
keywords = {Convolutional neural networks, Oversampling, Defect pattern classification, Wafer bin map, Small data, Imbalanced data}
}

@article{10.1155/2021/8858545,
author = {Le, Tien-Thinh and Nguyen, Van-Hai and Le, Minh Vuong and Morabito, Francesco Carlo},
title = {Development of Deep Learning Model for the Recognition of Cracks on Concrete Surfaces},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-9724},
url = {https://doi.org/10.1155/2021/8858545},
doi = {10.1155/2021/8858545},
abstract = {This paper is devoted to the development of a deep learning- (DL-) based model to detect crack fractures on concrete surfaces. The developed model for the classification of images was based on a DL Convolutional Neural Network (CNN). To train and validate the CNN model, a database containing 40,000 images of concrete surfaces (with and without cracks) was collected from the available literature. Several conditions on the concrete surfaces were taken into account such as illumination and surface finish (i.e., exposed, plastering, and paint). Various error measurement criteria such as accuracy, precision, recall, specificity, and F1-score were employed for accessing the quality of the developed model. Results showed that for the training dataset (50% of the database), the precision, recall, specificity, F1-score, and accuracy were 99.5%, 99.8%, 99.5%, 99.7%, and 99.7%, respectively. On the other hand, for the validating dataset, the precision, recall, specificity, F1-score, and accuracy are 96.5%, 98.8%, 96.6%, 97.7%, and 97.7%, respectively. Thus, the developed CNN model may be considered valid because it performs the classification of cracks well using the testing data. It is also confirmed that the developed DL-based model was robust and efficient, as it can take into account different conditions on the concrete surfaces. The CNN model developed in this study was compared with other works in the literature, showing that the CNN model could improve the accuracy of image classification, in comparison with previously published results. Finally, in further work, such model could be combined with Unmanned Aerial Vehicles (UAVs) to increase the productivity of concrete infrastructure inspection.},
journal = {Appl. Comp. Intell. Soft Comput.},
month = jan,
numpages = {10}
}

@article{10.1016/j.eswa.2021.114838,
author = {Uzen, Huseyin and Turkoglu, Muammer and Hanbay, Davut},
title = {Texture defect classification with multiple pooling and filter ensemble based on deep neural network},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {175},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114838},
doi = {10.1016/j.eswa.2021.114838},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {11},
keywords = {Classification, Data augment, Support vector machine, Deep features, Texture defect recognition}
}

@article{10.1016/j.asoc.2016.07.048,
author = {Bakar, Noor Hasrina and Kasirun, Zarinah M. and Salleh, Norsaremah and Jalab, Hamid A.},
title = {Extracting features from online software reviews to aid requirements reuse},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.07.048},
doi = {10.1016/j.asoc.2016.07.048},
abstract = {Display Omitted The extraction of software features from Software Requirement Specifications (SRS) is viable only to practitioners who have the access.Online reviews for software products can be used as input for features extraction to assist requirements reuse.Techniques from unsupervised learning and Natural Language Processing is employed as a propose solutions to Requirements Reuse problem.The approach obtained a precision of 87% (62% average) and a recall of 86% (82% average), when evaluated against the truth data set created manually. Sets of common features are essential assets to be reused in fulfilling specific needs in software product line methodology. In Requirements Reuse (RR), the extraction of software features from Software Requirement Specifications (SRS) is viable only to practitioners who have access to these software artefacts. Due to organisational privacy, SRS are always kept confidential and not easily available to the public. As alternatives, researchers opted to use the publicly available software descriptions such as product brochures and online software descriptions to identify potential software features to initiate the RR process. The aim of this paper is to propose a semi-automated approach, known as Feature Extraction for Reuse of Natural Language requirements (FENL), to extract phrases that can represent software features from software reviews in the absence of SRS as a way to initiate the RR process. FENL is composed of four stages, which depend on keyword occurrences from several combinations of nouns, verbs, and/or adjectives. In the experiment conducted, phrases that could reflect software features, which reside within online software reviews were extracted by utilising the techniques from information retrieval (IR) area. As a way to demonstrate the feature groupings phase, a semi-automated approach to group the extracted features were then conducted with the assistance of a modified word overlap algorithm. As for the evaluation, the proposed extraction approach is evaluated through experiments against the truth data set created manually. The performance results obtained from the feature extraction phase indicates that the proposed approach performed comparably with related works in terms of recall, precision, and F-Measure.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1297–1315},
numpages = {19},
keywords = {Unsupervised learning, Software engineering, Requirements reuse, Natural language processing, Latent semantic analysis}
}

@inproceedings{10.5220/0008165504870495,
author = {Martino, Alessio and De Santis, Enrico and Baldini, Luca and Rizzi, Antonello},
title = {Calibration Techniques for Binary Classification Problems: A Comparative Analysis},
year = {2019},
isbn = {9789897583841},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0008165504870495},
doi = {10.5220/0008165504870495},
abstract = {Calibrating a classification system consists in transforming the output scores, which somehow state the confidence of the classifier regarding the predicted output, into proper probability estimates. Having a well-calibrated classifier has a non-negligible impact on many real-world applications, for example decision making systems synthesis for anomaly detection/fault prediction. In such industrial scenarios, risk assessment is certainly related to costs which must be covered. In this paper we review three state-of-the-art calibration techniques (Platt s Scaling, Isotonic Regression and SplineCalib) and we propose three lightweight procedures based on a plain fitting of the reliability diagram. Computational results show that the three proposed techniques have comparable performances with respect to the three state-of-the-art approaches.},
booktitle = {Proceedings of the 11th International Joint Conference on Computational Intelligence},
pages = {487–495},
numpages = {9},
keywords = {Support Vector Machine, Supervised Learning, Probability Estimates., Classification, Calibration},
location = {Vienna, Austria},
series = {IJCCI 2019}
}

@inproceedings{10.1007/978-3-030-85928-2_24,
author = {Chen, Rui and Luo, Lailong and Chen, Yingwen and Xia, Junxu and Guo, Deke},
title = {A Hybrid Framework for&nbsp;Class-Imbalanced Classification},
year = {2021},
isbn = {978-3-030-85927-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-85928-2_24},
doi = {10.1007/978-3-030-85928-2_24},
abstract = {Data classification is a commonly used data processing method in the fields of networks and distributed systems, and it has attracted extensive attention in recent years. Nevertheless, the existing classification algorithms are mainly aimed at relatively balanced datasets, while the data in reality often exhibits imbalanced characteristics. In this paper, we propose a novel Hybrid Resampling-based Ensemble (HRE) model, which aims to solve the classification problem of highly skewed data. The main idea of the HRE is to leverage the resampling approach for tackling class imbalance, and then twelve classifiers are further adopted to construct an ensemble model. Besides, a novel combination of under-sampling and over-sampling is elaborately proposed to balance the heterogeneity among different data categories. We decide the resampling rate in an empirical manner, which provides a practical guideline for the use of sampling methods. We compare the effect of different resampling methods based on the imbalanced network anomaly detection dataset, where few abnormal data need to be distinguished from a large number of common network traffics. The results of extensive experiments show that the HRE model achieves better accuracy performance than the methods without hybrid resampling.},
booktitle = {Wireless Algorithms, Systems, and Applications: 16th International Conference, WASA 2021, Nanjing, China, June 25–27, 2021, Proceedings, Part I},
pages = {301–313},
numpages = {13},
keywords = {Ensemble model, Resampling, Class-imbalanced learning},
location = {Nanjing, China}
}

@article{10.1007/s10586-018-1923-7,
author = {Viji, C. and Rajkumar, N. and Duraisamy, S.},
title = {Prediction of software fault-prone classes using an unsupervised hybrid SOM algorithm},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-018-1923-7},
doi = {10.1007/s10586-018-1923-7},
abstract = {In software engineering fault proneness prediction is one of the important fields for quality measurement using multiple code metrics. The metrics thresholds are very practical in measuring the code quality for fault proneness prediction. It helps to improvise the software quality in short time with very low cost. Many researchers are in the race to develop a measuring attribute for the software quality using various methodologies. Currently so many fault proneness prediction models are available. Among that most of the methods are used to identify the faults either by data history or by special supervising algorithms. In most of the real time cases the fault data bases may not be available so that the process becomes tedious. This article proposes a hybrid model for identifying the faults in the software models and also we proposed coupling model along with the algorithm so that the metrics are used to identify the faults and the coupling model couples the metrics and the faults for the developed system software.},
journal = {Cluster Computing},
month = jan,
pages = {133–143},
numpages = {11},
keywords = {ANN, Fault proneness, Coupling, Fault prediction, Software metrics}
}

@article{10.1155/2021/5549300,
author = {Museba, Tinofirei and Nelwamondo, Fulufhelo and Ouahada, Khmaies and Yi, Yugen},
title = {ADES: A New Ensemble Diversity-Based Approach for Handling Concept Drift},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/5549300},
doi = {10.1155/2021/5549300},
abstract = {Beyond applying machine learning predictive models to static tasks, a significant corpus of research exists that applies machine learning predictive models to streaming environments that incur concept drift. With the prevalence of streaming real-world applications that are associated with changes in the underlying data distribution, the need for applications that are capable of adapting to evolving and time-varying dynamic environments can be hardly overstated. Dynamic environments are nonstationary and change with time and the target variables to be predicted by the learning algorithm and often evolve with time, a phenomenon known as concept drift. Most work in handling concept drift focuses on updating the prediction model so that it can recover from concept drift while little effort has been dedicated to the formulation of a learning system that is capable of learning different types of drifting concepts at any time with minimum overheads. This work proposes a novel and evolving data stream classifier called Adaptive Diversified Ensemble Selection Classifier (ADES) that significantly optimizes adaptation to different types of concept drifts at any time and improves convergence to new concepts by exploiting different amounts of ensemble diversity. The ADES algorithm generates diverse base classifiers, thereby optimizing the margin distribution to exploit ensemble diversity to formulate an ensemble classifier that generalizes well to unseen instances and provides fast recovery from different types of concept drift. Empirical experiments conducted on both artificial and real-world data streams demonstrate that ADES can adapt to different types of drifts at any given time. The prediction performance of ADES is compared to three other ensemble classifiers designed to handle concept drift using both artificial and real-world data streams. The comparative evaluation performed demonstrated the ability of ADES to handle different types of concept drifts. The experimental results, including statistical test results, indicate comparable performances with other algorithms designed to handle concept drift and prove their significance and effectiveness.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {17}
}

@article{10.1007/s00521-017-2862-6,
author = {\"{O}zt\"{u}rk, \c{S}aban and Akdemir, Bayram},
title = {RETRACTED ARTICLE: Fuzzy logic-based segmentation of manufacturing defects on reflective surfaces},
year = {2018},
issue_date = {Apr 2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {29},
number = {8},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-017-2862-6},
doi = {10.1007/s00521-017-2862-6},
abstract = {Automatic defect detection on reflective surfaces is a compelling process. In particular, detection of tiny defects is almost impossible for human eye or simple machine vision methods. Therefore, the need for fast and sensitive machine vision methods has gained importance. In this study, an effective defect detection method is presented for reflective surfaces such as glass, tile, and steel. Defects on the surface of the product are determined automatically without the need for human intervention. The proposed system involves illumination unit, digital camera, and defect detection algorithm. Firstly, color image is taken by digital camera. Then, properties of taken image are selected. At this stage, ambient condition of lighting devices is very important. Reflections are minimized thanks to the true lighting. Selected properties are: red, green, and blue values, and luminance value. These properties are applied to fuzzy inputs. Information from the inputs is evaluated according to determined rules. Finally, each pixel is classified as black or white. Thirty-two glass pieces are tested using the proposed system. The proposed method was compared with commonly used methods. The success rate of the proposed algorithm is 83.5% and is higher than that of other algorithms .},
journal = {Neural Comput. Appl.},
month = apr,
pages = {107–116},
numpages = {10},
keywords = {Defect detection, Reflective surface analysis, Glass defect inspection, Fuzzy logic, Texture analysis, Image segmentation}
}

@inproceedings{10.1145/3387904.3389295,
author = {Lenarduzzi, Valentina and Palomba, Fabio and Taibi, Davide and Tamburri, Damian Andrew},
title = {OpenSZZ: A Free, Open-Source, Web-Accessible Implementation of the SZZ Algorithm},
year = {2020},
isbn = {9781450379588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387904.3389295},
doi = {10.1145/3387904.3389295},
abstract = {The accurate identification of defect-inducing commits represents a key problem for researchers interested in studying the naturalness of defects and defining defect prediction models. To tackle this problem, software engineering researchers have relied on and proposed several implementations of the well-known Sliwerski-Zimmermann-Zeller (SZZ) algorithm. Despite its popularity and wide usage, no open-source, publicly available, and web-accessible implementation of the algorithm has been proposed so far. In this paper, we prototype and make available one such implementation for further use by practitioners and researchers alike. The evaluation of the proposed prototype showed competitive results and lays the foundation for future work. This paper outlines our prototype, illustrating its usage and reporting on its evaluation in action.},
booktitle = {Proceedings of the 28th International Conference on Program Comprehension},
pages = {446–450},
numpages = {5},
keywords = {Web APIs, Software Defect Proneness, Software Defect Prediction, Open-Source Tools},
location = {Seoul, Republic of Korea},
series = {ICPC '20}
}

@article{10.1016/j.procs.2019.09.155,
author = {Miholca, Diana-Lucia and Czibula, Gabriela},
title = {DynGRAR: A dynamic approach to mining gradual relational association rules},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {159},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.09.155},
doi = {10.1016/j.procs.2019.09.155},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {10–19},
numpages = {10},
keywords = {68T35, 03B52, gradual relational association rule 2000 MSC: 68T05, data mining, Unuspervised learning}
}

@article{10.1007/s10845-012-0725-7,
author = {Kuo, Chung-Feng Jeffrey and Hsu, Chien-Tung Max and Liu, Zong-Xian and Wu, Han-Cheng},
title = {Automatic inspection system of LED chip using two-stages back-propagation neural network},
year = {2014},
issue_date = {December  2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {6},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-012-0725-7},
doi = {10.1007/s10845-012-0725-7},
abstract = {This study proposed an automatic LED defect detection system to investigate the defects of LED chips. Such defects include fragment chips, scratch marks and remained gold on the pad area, scratch marks on the luminous zone, and missing luminous zone respectively. The system was based on positioning and image acquisition, appearance feature recognition, and defect classification. The normalized correlation coefficient method was used to locate the chip and acquire its image, the K-means clustering method was used to distinguish the appearance, pad area, and luminous zone of chips. In terms of pad area detection, histogram equalization was used to enhance the pad image contrast, and statistical threshold selection and morphological closing were applied to modify the impure points in the pad. Feature values of the pad area were then calculated. The optimal statistical threshold separated the luminous zone and background from the substrate. After processed with closing operation, features of the luminous zone were extracted. Finally, features of each part were clarified by an efficient two-step back-propagation neural network, where a designed appearance classifier and an internal structure classifier were used for recognition. From experiments, total recognition rate of this study achieved 97.83 %, proving that the detection method proposed by this study can efficiently detect LED chip defects.},
journal = {J. Intell. Manuf.},
month = dec,
pages = {1235–1243},
numpages = {9},
keywords = {Normalized correlation coefficient method, LED, Back propagation neural network, Automatic defect detection}
}

@inproceedings{10.1007/978-3-030-62365-4_46,
author = {Go, Gwang-Myong and Bu, Seok-Jun and Cho, Sung-Bae},
title = {A Deep Metric Neural Network with Disentangled Representation for Detecting Smartphone Glass Defects},
year = {2020},
isbn = {978-3-030-62364-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62365-4_46},
doi = {10.1007/978-3-030-62365-4_46},
abstract = {For defect inspection using computer vision, deep learning models have been introduced to improve the conventional rule-based pattern analysis. A lot of data is a prerequisite to the success of them, but the on-the-spot industrial field suffers from lack of data. In this paper, we propose a deep metric neural network to improve the performance even with insufficient data imbalanced in class.&nbsp;The model is verified with the dataset of new products by evaluating the accuracy with 10-fold cross-validation. Our model is based on the data in the smallest category, 1.2&nbsp;K, which achieves the highest performance of 90.42% using sampled pairs without using all the data for training. High accuracy has been achieved and proven applicability in the industry compared to the conventional machine learning models.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2020: 21st International Conference, Guimaraes, Portugal, November 4–6, 2020, Proceedings, Part II},
pages = {485–494},
numpages = {10},
keywords = {Metric few-shot learning, Deep learning, Convolutional neural network, Smartphone glass inspection, Defect detection},
location = {Guimaraes, Portugal}
}

@article{10.1007/s11063-020-10319-3,
author = {Hu, Jiaojiao and Wang, Xiaofeng and Zhang, Ying and Zhang, Depeng and Zhang, Meng and Xue, Jianru},
title = {Time Series Prediction Method Based on Variant LSTM Recurrent Neural Network},
year = {2020},
issue_date = {Oct 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {2},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-020-10319-3},
doi = {10.1007/s11063-020-10319-3},
abstract = {Time series prediction problems are a difficult type of predictive modeling problem. In this paper, we propose a time series prediction method based on a variant long short-term memory (LSTM) recurrent neural network. In the proposed method, we firstly improve the memory module of the LSTM recurrent neural network by merging its forget gate and input gate into one update gate, and using Sigmoid layer to control information update. Using improved LSTM recurrent neural network, we develop a time series prediction model. In the proposed model, the parameter migration method is used model update to ensure the model has good predictive ability after predicting multi-step sequences. Experimental results show, compared with several typical time series prediction models, the proposed method have better performance for long-sequence data prediction.},
journal = {Neural Process. Lett.},
month = oct,
pages = {1485–1500},
numpages = {16},
keywords = {Variant LSTM network, Recurrent neural network, Time series prediction, Deep learning}
}

@article{10.1016/j.compag.2019.01.041,
author = {Kaya, Aydin and Keceli, Ali Seydi and Catal, Cagatay and Yalic, Hamdi Yalin and Temucin, Huseyin and Tekinerdogan, Bedir},
title = {Analysis of transfer learning for deep neural network based plant classification models},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {158},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2019.01.041},
doi = {10.1016/j.compag.2019.01.041},
journal = {Comput. Electron. Agric.},
month = mar,
pages = {20–29},
numpages = {10},
keywords = {Convolutional neural networks, Fine-tuning, Deep neural networks, Transfer learning, Plant classification}
}

@article{10.1007/s00138-021-01244-z,
author = {Honz\'{a}tko, David and T\"{u}retken, Engin and Bigdeli, Siavash A. and Dunbar, L. Andrea and Fua, Pascal},
title = {Defect segmentation for multi-illumination quality control systems},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {6},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-021-01244-z},
doi = {10.1007/s00138-021-01244-z},
abstract = {Thanks to recent advancements in image processing and deep learning techniques, visual surface inspection in production lines has become an automated process as long as all the defects are visible in a single or a few images. However, it is often necessary to inspect parts under many different illumination conditions to capture all the defects. Training deep networks to perform this task requires large quantities of annotated data, which are rarely available and cumbersome to obtain. To alleviate this problem, we devised an original augmentation approach that, given a small image collection, generates rotated versions of the images while preserving illumination effects, something that random rotations cannot do. We introduce three real multi-illumination datasets, on which we demonstrate the effectiveness of our illumination preserving rotation approach. Training deep neural architectures with our approach delivers a performance increase of up to 51% in terms of AuPRC score over using standard rotations to perform data augmentation.},
journal = {Mach. Vision Appl.},
month = nov,
numpages = {16},
keywords = {Quality control, Photometric stereo, Data augmentation, Deep learning, Multi-illumination, Defect detection}
}

@inproceedings{10.1007/978-3-030-31726-3_42,
author = {Li, Juanjuan and Jing, Xiao-Yuan and Wu, Fei and Sun, Ying and Yang, Yongguang},
title = {A Cost-Sensitive Shared Hidden Layer Autoencoder for Cross-Project Defect Prediction},
year = {2019},
isbn = {978-3-030-31725-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31726-3_42},
doi = {10.1007/978-3-030-31726-3_42},
abstract = {Cross-project defect prediction means training a classifier model using the historical data of the other source project, and then testing whether the target project instance is defective or not. Since source and target projects have different data distributions, and data distribution difference will degrade the performance of classifier. Furthermore, the class imbalance of datasets increases the difficulty of classification. Therefore, a cost-sensitive shared hidden layer autoencoder (CSSHLA) method is proposed. CSSHLA learns a common feature representation between source and target projects by shared hidden layer autoencoder, and makes the different data distributions more similar. To solve the class imbalance problem, CSSHLA introduces a cost-sensitive factor to assign different importance weights to different instances. Experiments on 10 projects of PROMISE dataset show that CSSHLA improves the performance of cross-project defect prediction compared with baselines.},
booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part III},
pages = {491–502},
numpages = {12},
keywords = {Cross-project software defect prediction, Cost-sensitive learning, Shared hidden layer autoencoder},
location = {Xi'an, China}
}

@inproceedings{10.1007/978-3-030-33607-3_41,
author = {Go, Gwang-Myong and Bu, Seok-Jun and Cho, Sung-Bae},
title = {A Deep Learning-Based Surface Defect Inspection System for Smartphone Glass},
year = {2019},
isbn = {978-3-030-33606-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33607-3_41},
doi = {10.1007/978-3-030-33607-3_41},
abstract = {In recent years, convolutional neural network has become a solution to many image processing problems due to high performance. It is particularly useful for applications in automated optical inspection systems related to industrial applications. This paper proposes a system that combines the defect information, which is meta data, with the defect image by modeling. Our model for classification consists of a separate model for embedding location information in order to utilize the defective locations classified as defective candidates and ensemble with the model for classification to enhance the overall system performance. The proposed system incorporates class activation map for preprocessing and augmentation for image acquisition and classification through optical system, and feedback of classification performance by constructing a system for defect detection. Experiment with real-world dataset shows that the proposed system achieved 97.4% accuracy and through various other experiments, we verified that our system is applicable.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2019: 20th International Conference, Manchester, UK, November 14–16, 2019, Proceedings, Part I},
pages = {375–385},
numpages = {11},
keywords = {Deep learning, Convolutional neural network, Class activation map, Smartphone glass inspection, Defect detection, Augmentation, Image preprocessing},
location = {Manchester, United Kingdom}
}

@article{10.1007/s11042-020-09236-3,
author = {Arshaghi, Ali and Ashourian, Mohsen and Ghabeli, Leila},
title = {Feature selection based on buzzard optimization algorithm for potato surface defects detection},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {35–36},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-09236-3},
doi = {10.1007/s11042-020-09236-3},
abstract = {Different methods of feature selection find the best subdivision from the candidate subset. In all methods, based on the application and the type of the definition, a subset is selected as the answer; which can optimize the value of an evaluation function. The large number of features, high spatial and temporal complexity, and even reduced accuracy are common problems in such systems. Therefore, research needs to be performed to optimize these systems. In this paper, for increasing the classification accuracy and reducing their complexity; feature selection techniques are used. In addition, a new feature selection method by using the buzzard optimization algorithm (BUOZA) is proposed. These features would be used in segmentation, feature extraction, and classification steps in related applications; to improve the system performance. The results of the performed experiment on the developed method have shown a high performance while optimizing the system’s working parameters.},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {26623–26641},
numpages = {19},
keywords = {Image processing, Feature selection, Potato defect detection, Global optimization, Buzzard optimization algorithm}
}

@article{10.1504/ijiei.2021.118275,
author = {Mittal, Shruti and Nagpal, Chander Kumar},
title = {Reinforcement learning based predictive analytics framework for survival in stock market},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {3},
issn = {1758-8715},
url = {https://doi.org/10.1504/ijiei.2021.118275},
doi = {10.1504/ijiei.2021.118275},
abstract = {Contemporary research in stock market domain is limited to forecasting of the stock price from one day to one week. Such small period predictions cannot be of much help for continuous gainful survival in the stock market. In fact, there has to be predictive analytics framework which analyses the current situation in the holistic manner and provides the appropriate advice for selling/buying/no action along with the quantity resulting in significant gain for the user/investor. The proposed framework generates various reinforcement signals by applying statistical and machine learning techniques on historical data and studies their impact on the stock prices by analysing future data. The outcome of the process has been used to generate rewards, through the use of fuzzy logic, for various actions in a given state of the environment. Fully automated implementation of the proposed framework can help both institutional and common investor in taking the rational decision.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {294–327},
numpages = {33},
keywords = {single value decomposition, stock technical analysis, stock fundamental, fuzzy rule base, finite state machine, fuzzy sets and logic, reinforcement learning, stock market predictions, machine learning, statistical learning, predictive analytics}
}

@article{10.1007/s10515-020-00279-2,
author = {Almhana, Rafi and Kessentini, Marouane},
title = {Considering dependencies between bug reports to improve bugs triage},
year = {2021},
issue_date = {May 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-020-00279-2},
doi = {10.1007/s10515-020-00279-2},
abstract = {Software development teams need to deal with several open reports of critical bugs to be addressed urgently and simultaneously. The management of these bugs is a complex problem due to the limited resources and the deadlines-pressure. Most of the existing studies treated bug reports in isolation when assigning them to developers. Thus, developers may spend considerable cognitive efforts moving between completely unrelated bug reports thus not sharing any common files to be inspected. In this paper, we propose an automated bugs triage approach based on the dependencies between the open bug reports. Our approach starts by localizing the files to be inspected for each of the pending bug reports. We defined the dependency between two bug reports as the number of common files to be inspected to localize the bugs. Then, we adopted multi-objective search to rank the bug reports for programmers based on both their priorities and the dependency between them. We evaluated our approach on a set of open source programs and compared it to the traditional approach of considering bug reports in isolation based mainly on their priority. The results show a significant time reduction of over 30% in localizing the bugs simultaneously comparing to the traditional bugs prioritization technique based on only priorities.},
journal = {Automated Software Engg.},
month = may,
numpages = {26},
keywords = {Software quality assurance, Search-based software engineering, Bug prioritization, Bug localization, Bug triage, Bugs management}
}

@article{10.1049/iet-sen.2019.0278,
author = {Zhu, Kun and Zhang, Nana and Ying, Shi and Zhu, Dandan},
title = {Within‐project and cross‐project just‐in‐time defect prediction based on denoising autoencoder and convolutional neural network},
year = {2020},
issue_date = {June 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2019.0278},
doi = {10.1049/iet-sen.2019.0278},
abstract = {Just‐in‐time defect prediction is an important and useful branch in software defect prediction. At present, deep learning is a research hotspot in the field of artificial intelligence, which can combine basic defect features into deep semantic features and make up for the shortcomings of machine learning algorithms. However, the mainstream deep learning techniques have not been applied yet in just‐in‐time defect prediction. Therefore, the authors propose a novel just‐in‐time defect prediction model named DAECNN‐JDP based on denoising autoencoder and convolutional neural network in this study, which has three main advantages: (i) Different weights for the position vector of each dimension feature are set, which can be automatically trained by adaptive trainable vector. (ii) Through the training of denoising autoencoder, the input features that are not contaminated by noise can be obtained, thus learning more robust feature representation. (iii) The authors leverage a powerful representation‐learning technique, convolution neural network, to construct the basic change features into the abstract deep semantic features. To evaluate the performance of the DAECNN‐JDP model, they conduct extensive within‐project and cross‐project defect prediction experiments on six large open source projects. The experimental results demonstrate that the superiority of DAECNN‐JDP on five evaluation metrics.},
journal = {IET Software},
month = jun,
pages = {185–195},
numpages = {18},
keywords = {cross-project defect prediction experiments, convolution neural network, autoencoder convolutional neural network, just-in-time defect prediction model, mainstream deep learning techniques, basic defect features, software defect prediction, denoising autoencoder, learning (artificial intelligence), neural nets}
}

@inproceedings{10.1109/ETFA.2019.8869084,
author = {Mittel, Dominik and Kerber, Florian},
title = {Vision-Based Crack Detection using Transfer Learning in Metal Forming Processes},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ETFA.2019.8869084},
doi = {10.1109/ETFA.2019.8869084},
abstract = {Crack detection is an important quality control task for metal working processes. In small and medium-size businesses quality inspection is often performed manually. This approach is time consuming and sensitive to errors. In this work an automated visual inspection system for defect detection is presented which classifies cracks in quality control images of a metal forming process taken under varying ambient conditions. The classification is based on transfer learning with AlexNet and GoogLeNet. Supervised learning based on a stochastic gradient descent (sgd) solver was used to train the convolutional neural network. Oversampling and data augmentation with rotated, scaled and shifted images were applied to overcome limitations of the available dataset like huge imbalances of training data sizes for different classes and to prevent overfitting, respectively. Different training parameters were compared and tested to obtain the best classification results for the specific task. GoogLeNet outperformed AlexNet and reached an accuracy of 0.998 and an F1-score of 0.836 for crack detection. Data pre-processing and labeling as well as tuning of the training parameters had a significant influence on classification accuracy and require human decision making.},
booktitle = {2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)},
pages = {544–551},
numpages = {8},
location = {Zaragoza, Spain}
}

@article{10.1155/2021/9092589,
author = {Wu, Hao and Zhou, Zhi and Khan, Fazlullah},
title = {Using Convolution Neural Network for Defective Image Classification of Industrial Components},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {2021},
issn = {1574-017X},
url = {https://doi.org/10.1155/2021/9092589},
doi = {10.1155/2021/9092589},
abstract = {Computer vision provides effective solutions in many imaging relation problems, including automatic image segmentation and classification. Artificially trained models can be employed to tag images and identify objects spontaneously. In large-scale manufacturing, industrial cameras are utilized to take constant images of components for several reasons. Due to the limitations caused by motion, lens distortion, and noise, some defective images are captured, which are to be identified and separated. One common way to address this problem is by looking into these images manually. However, this solution is not only very time-consuming but is also inaccurate. The paper proposes a deep learning-based artificially intelligent system that can quickly train and identify faulty images. For this purpose, a pretrained convolution neural network based on the PyTorch framework is employed to extract discriminating features from the dataset, which is then used for the classification task. In order to eliminate the chances of overfitting, the proposed model also employed Dropout technology to adjust the network. The experimental study reveals that the system can precisely classify the normal and defective images with an accuracy of over 91%.},
journal = {Mob. Inf. Syst.},
month = jan,
numpages = {8}
}

@inproceedings{10.1007/978-3-030-58811-3_67,
author = {ElGhondakly, Roaa and Moussa, Sherin and Badr, Nagwa},
title = {Handling Faults in Service Oriented Computing: A Comprehensive Study},
year = {2020},
isbn = {978-3-030-58810-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58811-3_67},
doi = {10.1007/978-3-030-58811-3_67},
abstract = {Recently, service-oriented computing paradigms have become a trending development direction, in which software systems are built using a set of loosely coupled services distributed over multiple locations through a service-oriented architecture. Such systems encounter different challenges, as integration, performance, reliability, availability, etc., which made all associated testing activities to be another major challenge to avoid their faults and system failures. Services are considered the substantial element in service-oriented computing. Thus, the quality of services and the service dependability in a web service composition have become essential to manage faults within these software systems. Many studies addressed web service faults from diverse perspectives. In this paper, a comprehensive study is conducted to investigate the different perspectives to manipulate web service faults, including fault tolerance, fault injection, fault prediction and fault localization. An extensive comparison is provided, highlighting the main research gaps, challenges and limitations of each perspective for web services. An analytical discussion is then followed to suggest future research directions that can be adopted to face such obstacles by improving fault handling capabilities for an efficient testing in service-oriented computing systems.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part IV},
pages = {947–959},
numpages = {13},
keywords = {Service oriented computing, Service testing, Quality of Service, Fault injection, Fault prediction, Fault tolerance},
location = {Cagliari, Italy}
}

@article{10.1007/s10845-017-1375-6,
author = {Benmahdi, D. and Rasolofondraibe, L. and Chiementin, X. and Murer, S. and Felkaoui, A.},
title = {RT-OPTICS: real-time classification based on OPTICS method to monitor bearings faults},
year = {2019},
issue_date = {June      2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {5},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-017-1375-6},
doi = {10.1007/s10845-017-1375-6},
abstract = {The complexity of the current installations requires advanced and effective monitoring techniques. The most commonly used technique is the vibratory analysis. Despite the large number of existing methods for detection, diagnosis and monitoring of bearing defects, the scientific community is widely interested in learning methods. These methods allow automatic detection and reliable diagnosis. This paper presents anew real-time unsupervised pattern recognition approach for the detection and diagnosis of bearings defects: RT-OPTICS. This approach focuses on two steps of damage evolution: defect detection by classification and monitoring of the new cluster representing the degraded state of the bearing. These two steps are performed by a two-dimensional method implementing scalar indicators: Kurtosis and Root Mean Square values. These two indicators provide additional information about the presence of defects in the bearing. The first step deploys RT-OPTICS based on the real-time unsupervised ordering points to identify clustering structure (OPTICS) classification to detect defects on inner and/or outer bearing races. The next step is to monitor the state of degradation using three parameters of the new cluster: the center jump, density and contour of this cluster. After a validation on simulated signals which variations of parameters were tested, this approach was tested under experimental conditions on a test bench made up of N.206.E.G15bearings, with varying load and angular velocity. A comparative study is carried out between the suggested approach and (i) a classical approach: monitoring of scalar indicators over time and (ii) a dynamic classification method (DBSCAN).},
journal = {J. Intell. Manuf.},
month = jun,
pages = {2157–2170},
numpages = {14},
keywords = {Vibratory analysis, Unsupervised classification, OPTICS, Diagnosis and monitoring, Bearing}
}

@article{10.1016/j.neucom.2021.09.011,
author = {Liu, Weihua and Sun, Hao and Jia, Zhixiang and Yu, Xinghu},
title = {Surface mounted devices classification using a mixture network of DCNN and DFCN},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {465},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.09.011},
doi = {10.1016/j.neucom.2021.09.011},
journal = {Neurocomput.},
month = nov,
pages = {428–436},
numpages = {9},
keywords = {DFCN, DCNN, Classification, Surface mounted devices, Neural network}
}

@inproceedings{10.1007/978-3-030-97774-0_9,
author = {Wang, Jing and Wan, Meng and Wang, Jue and Wang, Xiaoguang and Wang, Yangang and Liu, Fang and Min, Weixiao and Lei, He and Wang, Lihua},
title = {Defects Detection System of&nbsp;Medical Gloves Based on&nbsp;Deep Learning},
year = {2022},
isbn = {978-3-030-97773-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-97774-0_9},
doi = {10.1007/978-3-030-97774-0_9},
abstract = {In industrial production, medical gloves with tear, stain and other defects will be produced. In traditional manual mode, the efficiency and accuracy of defect detection depend on the proficiency of spot-check workers, which results in uneven glove product quality. In this paper, a surface defect detection system of medical gloves based on deep learning is designed for the automatic detection with high efficiency and accuracy. According to the industrial requirements of high real-time, the system adopts a cache scheme to improve the data reading and writing speed, and an Open Neural Network Exchange (ONNX) to effectively improve the speed of model reasoning. For the demands of high detection accuracy, the system designs a dual model detection strategy, which divides texture detection and edge detection into two steps. The advantage of this strategy is to remove most useless information while ensuring the effective information of the image. Furthermore, two auxiliary models are used to promote the accuracy of detection based on classification methods. Finally, experiments are proposed to verify the functional indicators of the system. After the on-site test of the production line in the medical glove factory, the system has the ability to detect the gloves of two production lines with high real-time. The product missed detection rate is less than 2%, and the product mistakenly picked rate is less than 5/10000. Verified by the industry of gloves, the system can be put into production line.},
booktitle = {Smart Computing and Communication: 6th International Conference, SmartCom 2021, New York City, NY, USA, December 29–31, 2021, Proceedings},
pages = {101–111},
numpages = {11},
keywords = {Auxiliary model, Image recognition, Detection system, Surface defect, Deep learning, Medical gloves},
location = {New York, NY, USA}
}

@article{10.1007/s11042-017-5238-0,
author = {Wang, Yalin and Xia, Haibing and Yuan, Xiaofeng and Li, Ling and Sun, Bei},
title = {Distributed defect recognition on steel surfaces using an improved random forest algorithm with optimal multi-feature-set fusion},
year = {2018},
issue_date = {July      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {77},
number = {13},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-017-5238-0},
doi = {10.1007/s11042-017-5238-0},
abstract = {Inspecting steel surfaces is important to ensure steel quality. Numerous defect-detection methods have been developed for steel surfaces. However, they are primarily used for local defects, and their accuracy in detecting distributed defects is unsatisfactory because such defects are difficult to locate and have complex texture characteristics. To solve these issues, an improved random forest algorithm with optimal multi-feature-set fusion (OMFF-RF algorithm) is proposed for distributed defect recognition in this paper. The OMFF-RF algorithm includes the following three aspects. First, a histogram of oriented gradient (HOG) feature-set and a gray-level co-occurrence matrix (GLCM) feature-set are extracted and fused to describe local and global texture characteristics, respectively. Second, given the small number of samples of distributed defect images and the high dimensionality of the extracted feature-sets, a random forest algorithm is introduced to perform defect classification. Third, the feature-sets vary greatly in performance and dimensionality. To improve the fusion efficiency, OMFF-RF merges the HOG feature-set and the GLCM feature-set through a multi-feature-set fusion factor, which changes the number of decision trees that correspond to each feature-set in the RF algorithm. The OMFF factor is found by optimizing the fitting curve of the classification accuracy of the test set using a stepping multi-feature-set fusion factor. In experiments, the effectiveness of the proposed OMFF-RF was verified using 5 types of distributed defects collected from an actual steel production line. OMFF-RF achieved a recognition accuracy of 91%, a result superior to support vector machine (SVM) and conventional RF algorithms.},
journal = {Multimedia Tools Appl.},
month = jul,
pages = {16741–16770},
numpages = {30},
keywords = {Steel surface, Random forest (RF), Optimal multi-feature-set fusion (OMFF), Histogram of oriented gradient (HOG), Gray-level co-occurrence matrix (GLCM), Distributed defect recognition}
}

@inproceedings{10.5555/3304889.3305050,
author = {Wang, Nan and Zhao, Xibin and Jiang, Yu and Gao, Yue},
title = {Iterative metric learning for imbalance data classification},
year = {2018},
isbn = {9780999241127},
publisher = {AAAI Press},
abstract = {In many classification applications, the amount of data from different categories usually vary significantly, such as software defect predication and medical diagnosis. Under such circumstances, it is essential to propose a proper method to solve the imbalance issue among the data. However, most of the existing methods mainly focus on improving the performance of classifiers rather than searching for an appropriate way to find an effective data space for classification. In this paper, we propose a method named Iterative Metric Learning (IML) to explore the correlations among the imbalance data and construct an effective data space for classification. Given the imbalance training data, it is important to select a subset of training samples for each testing data. Thus, we aim to find a more stable neighborhood for the testing data using the iterative metric learning strategy. To evaluate the effectiveness of the proposed method, we have conducted experiments on two groups of dataset, i.e., the NASA Metrics Data Program (NASA) dataset and UCI Machine Learning Repository (UCI) dataset. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.},
booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence},
pages = {2805–2811},
numpages = {7},
location = {Stockholm, Sweden},
series = {IJCAI'18}
}

@article{10.1007/s10462-012-9360-0,
author = {Jenhani, Ilyes and Elouedi, Zied},
title = {Re-visiting the artificial immune recognition system: a survey and an improved version},
year = {2014},
issue_date = {December  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {42},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-012-9360-0},
doi = {10.1007/s10462-012-9360-0},
abstract = {This paper surveys the major works related to an artificial immune system based classifier that was proposed in the 2000s, namely, the artificial immune recognition system (AIRS) algorithm. This survey has revealed that most works on AIRS was dedicated to the application of the algorithm to real-world problems rather than to theoretical developments of the algorithm. Based on this finding, we propose an improved version of the AIRS algorithm which we dub AIRS3. AIRS3 takes into account an important parameter that was ignored by the original algorithm, namely, the number of training antigens represented by each memory cell at the end of learning (numRepAg). Experiments of the new AIRS3 algorithm on data sets taken from the UCI machine learning repository have shown that taking into account the numRepAg information enhances the classification accuracy of AIRS.},
journal = {Artif. Intell. Rev.},
month = dec,
pages = {821–833},
numpages = {13},
keywords = {Machine learning, Classification, Artificial immune systems, Artificial immune recognition systems (AIRS)}
}

@article{10.1016/j.patrec.2021.01.034,
author = {Wu, Xinhua and Liu, Xiujie},
title = {Building crack identification and total quality management method based on deep learning},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {145},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2021.01.034},
doi = {10.1016/j.patrec.2021.01.034},
journal = {Pattern Recogn. Lett.},
month = may,
pages = {225–231},
numpages = {7},
keywords = {Image recognition, Quality management, Deep learning, Image segmentation, Crack detection}
}

@inproceedings{10.1007/978-3-642-27549-4_49,
author = {Ramler, Rudolf and Natschl\"{a}ger, Thomas},
title = {Applying heuristic approaches for predicting defect-prone software components},
year = {2011},
isbn = {9783642275487},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-27549-4_49},
doi = {10.1007/978-3-642-27549-4_49},
abstract = {Effective and efficient quality assurance has to focus on those parts of a software system that are most likely to fail. Defect prediction promises to indicate the defect-prone components of a software system. In this paper we investigate the viability of predicting defect-prone components in upcoming releases of a large industrial software system. Prediction models constructed with heuristic machine learning are used to classify the components of future versions of the software system as defective or defect-free. It could be shown that the accuracy of the predictions made for the next version is significantly higher (around 74%) than guessing even when taking only new or modified components into account. Furthermore, the results reveal that, depending on the specific prediction model, acceptable accuracy can be achieved for up to three versions in the future.},
booktitle = {Proceedings of the 13th International Conference on Computer Aided Systems Theory - Volume Part I},
pages = {384–391},
numpages = {8},
keywords = {software defect prediction, machine learning},
location = {Las Palmas de Gran Canaria, Spain},
series = {EUROCAST'11}
}

@article{10.1016/j.jss.2016.06.006,
author = {Okutan, Ahmet and Taner Yildiz, Olcay},
title = {A novel kernel to predict software defectiveness},
year = {2016},
issue_date = {September 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {119},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.06.006},
doi = {10.1016/j.jss.2016.06.006},
abstract = {We propose new kernels for defect prediction that are based on the source code similarity.We model the relationship between source code similarity and defectiveness.The precomputed kernels are used with SVM and KNN classifiers.The proposed technique performs better than the SVM with linear kernel.It also achieves comparable performance when compared to the KNN classifier. Although the software defect prediction problem has been researched for a long time, the results achieved are not so bright. In this paper, we propose to use novel kernels for defect prediction that are based on the plagiarized source code, software clones and textual similarity. We generate precomputed kernel matrices and compare their performance on different data sets to model the relationship between source code similarity and defectiveness. Each value in a kernel matrix shows how much parallelism exists between the corresponding files of a software system chosen. Our experiments on 10 real world datasets indicate that support vector machines (SVM) with a precomputed kernel matrix performs better than the SVM with the usual linear kernel in terms of F-measure. Similarly, when used with a precomputed kernel, the k-nearest neighbor classifier (KNN) achieves comparable performance with respect to KNN classifier. The results from this preliminary study indicate that source code similarity can be used to predict defect proneness.},
journal = {J. Syst. Softw.},
month = sep,
pages = {109–121},
numpages = {13},
keywords = {SVM, Kernel methods, Defect prediction}
}

@article{10.1016/j.eswa.2019.113085,
author = {Pandey, Sushant Kumar and Mishra, Ravi Bhushan and Tripathi, Anil Kumar},
title = {BPDET: An effective software bug prediction model using deep representation and ensemble learning techniques},
year = {2020},
issue_date = {Apr 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113085},
doi = {10.1016/j.eswa.2019.113085},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {22},
keywords = {Heterogeneous Ensemble learning technique, Staked denoising auto-encoder, Boosting, Deep representation, Software metrics, Classification technique, Software bug prediction}
}

@article{10.1016/j.engappai.2021.104387,
author = {Yu, Jianbo and Shen, Zongli and Wang, Shijin},
title = {Wafer map defect recognition based on deep transfer learning-based densely connected convolutional network and deep forest},
year = {2021},
issue_date = {Oct 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {105},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2021.104387},
doi = {10.1016/j.engappai.2021.104387},
journal = {Eng. Appl. Artif. Intell.},
month = oct,
numpages = {11},
keywords = {Deep forest, Convolution neural network, Transfer learning, Wafer map defect, Semiconductor manufacturing}
}

@article{10.1007/s00500-020-05005-4,
author = {Malhotra, Ruchika and Lata, Kusum},
title = {A systematic literature review on empirical studies towards prediction of software maintainability},
year = {2020},
issue_date = {Nov 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {21},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05005-4},
doi = {10.1007/s00500-020-05005-4},
abstract = {Software maintainability prediction in the earlier stages of software development involves the construction of models for the accurate estimation of maintenance effort. This guides the software practitioners to manage the resources optimally. This study aims at systematically reviewing the prediction models from January 1990 to October 2019 for predicting software maintainability. We analyze the effectiveness of these models according to various aspects. To meet the goal of the research, we have identified 36 research papers. On investigating these papers, we found that various machine learning (ML), statistical (ST), and hybridized (HB) techniques have been applied to develop prediction models to predict software maintainability. The significant finding of this review is that the overall performance of ML-based models is better than that of ST models. The use of HB techniques for prediction of software maintainability is limited. The results of this review revealed that software maintainability prediction (SMP) models developed using ML techniques outperformed models developed using ST techniques. Also, the prediction performance of few models developed using HB techniques is encouraging, yet no conclusive results about the performance of HB techniques could be reported because different HB techniques are applied in a few studies.},
journal = {Soft Comput.},
month = nov,
pages = {16655–16677},
numpages = {23},
keywords = {Hybridized techniques, Statistical techniques, Machine learning techniques, Software maintainability, Software maintenance}
}

@article{10.5555/3337636.3337642,
title = {Threshold-based empirical validation of object-oriented metrics on different severity levels},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {7},
number = {2–3},
issn = {1758-8715},
abstract = {Software metrics has become desideratum for the fault-proneness, reusability and effort prediction. To enhance and intensify the sufficiency of object-oriented OO metrics, it is crucial to perceive the relationship between OO metrics and fault-proneness at distinct severity levels. This paper characterise on the investigation of the software parts with higher probability of occurrence of faults. We examined the effect of thresholds on the OO metrics and build the predictive model based on those threshold values. This paper also instanced on the empirical validation of threshold values calculated for the OO metrics for predicting faults at different severity levels and builds the statistical model using logistic regression. This paper depicts the detection of fault-proneness by extracting the relevant OO metrics and focus on those projects that falls outside the specified risk level for allocating the more resources to them. We presented the effects of threshold values at different risk levels and also validated results on the KC1 dataset using machine learning and different classifiers.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {231–262},
numpages = {32}
}

@article{10.1155/2021/8464612,
author = {Yan, Chenqi and Tan, Mengchao and Venkateswaran, Narasimhan},
title = {The Use of Artificial Intelligence-Based Optical Remote Sensing and Positioning Technology in Microelectronic Processing Technology},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/8464612},
doi = {10.1155/2021/8464612},
abstract = {The purpose is to make defect detection in microelectronic processing technology fast, accurate, reliable, and efficient. A new optical remote sensing-optical beam induced resistance change (ORS-OBIRCH) target recognition and location defect detection method is proposed based on an artificial intelligence algorithm, optical remote sensing (ORS), and optical beam induced resistance change (OBIRCH) location technology using deep convolutional neural network. This method integrates the characteristics of high resolution and rich details of the image obtained by ORS technology and combines the advantages of photosensitive temperature characteristics in OBIRCH positioning technology. It can be adopted to identify, capture, and locate the defects of microdevices in the process of microelectronic processing. Simulation results show that this method can quickly reduce the detection range and locate defects accurately and efficiently. The experimental results reveal that the ORS-OBIRCH target recognition defect location detection method can complete the dynamic synchronization of the IC detection system and obtain high-quality images by changing the laser beam irradiation cycle. Moreover, it can analyze and process the detection results to quickly, accurately, and efficiently locate the defect location. Unlike the traditional detection methods, the success rate of detection has been greatly improved, which is about 95.8%, an increase of nearly 40%; the detection time has been reduced by more than half, from 5.5 days to 1.9 days, and the improvement rate has reached more than 65%. In a word, this method has good practical application value in the field of microelectronic processing.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {10}
}

@inproceedings{10.1007/978-3-030-61609-0_40,
author = {Xia, Bangfeng and Zhang, Yueling and Chen, Weiting and Wang, Xiangfeng and Wang, Jiangtao},
title = {EdgeAugment: Data Augmentation by Fusing and Filling Edge Maps},
year = {2020},
isbn = {978-3-030-61608-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-61609-0_40},
doi = {10.1007/978-3-030-61609-0_40},
abstract = {Data augmentation is an effective technique for improving the accuracy of network. However, current data augmentation can not generate more diverse training data. In this article, we overcome this problem by proposing a novel form of data augmentation to fuse and fill different edge maps. The edge fusion augmentation pipeline consists of four parts. We first use the Sobel operator to extract the edge maps from the training images. Then a simple integrated strategy is used to integrate the edge maps extracted from different images. After that we use an edge fuse GAN (Generative Adversarial Network) to fuse the integrated edge maps to synthesize new edge maps. Finally, an edge filling GAN is used to fill the edge maps to generate new training images. This augmentation pipeline can augment data effectively by making full use of the features from training set. We verified our edge fusion augmentation pipeline on different datasets combining with different edge integrated strategies. Experimental results illustrate a superior performance of our pipeline comparing to the existing work. Moreover, as far as we know, we are the first using GAN to augment data by fusing and filling feature from multiple edge maps.},
booktitle = {Artificial Neural Networks and Machine Learning – ICANN 2020: 29th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 15–18, 2020, Proceedings, Part I},
pages = {504–516},
numpages = {13},
keywords = {Convolution neural network, Deep learning, Adversarial generation networks, Data augmentation},
location = {Bratislava, Slovakia}
}

@article{10.1016/j.eswa.2010.08.130,
author = {Alan, Oral and Catal, Cagatay},
title = {Thresholds based outlier detection approach for mining class outliers: An empirical case study on software measurement datasets},
year = {2011},
issue_date = {April, 2011},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {38},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2010.08.130},
doi = {10.1016/j.eswa.2010.08.130},
abstract = {Predicting the fault-proneness labels of software program modules is an emerging software quality assurance activity and the quality of datasets collected from previous software version affects the performance of fault prediction models. In this paper, we propose an outlier detection approach using metrics thresholds and class labels to identify class outliers. We evaluate our approach on public NASA datasets from PROMISE repository. Experiments reveal that this novel outlier detection method improves the performance of robust software fault prediction models based on Naive Bayes and Random Forests machine learning algorithms.},
journal = {Expert Syst. Appl.},
month = apr,
pages = {3440–3445},
numpages = {6},
keywords = {Software metrics thresholds, Software fault prediction, Outlier detection, Empirical software engineering}
}

@inproceedings{10.1007/978-3-030-68851-6_2,
author = {Chen, Jinyin and Wang, Xueke and Zhang, Yan and Zheng, Haibin and Ji, Shouling},
title = {Attention Mechanism Based Adversarial Attack Against Deep Reinforcement Learning},
year = {2020},
isbn = {978-3-030-68850-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68851-6_2},
doi = {10.1007/978-3-030-68851-6_2},
abstract = {Deep reinforcement learning (DRL) aims to maximize long-term future rewards to achieve specific goals by learning polices based on deep learning models. However, existing research has found that machine learning models are vulnerable to maliciously craft adversarial examples, so does the DRL since it uses deep model to learn policies. Usually gradient information is adopted to generate adversarial perturbation on the clean observation states to fail DRL. In order to develop a novel attack method for further defect detection of DRL, we propose a novel attention mechanism based adversarial attack. Instead of gradient information, we make full use of hidden features extracted in the DRL by attention operations to generate more effective adversarial examples. Both channel attention and pixel attention are applied to extract feature to modify the clean state to an adversarial one. Deep Q-Learing Network (DQN), one of the state-of-the-art DRL models, is utilized as the target model to train Flappybird game environment to guarantee continuous running and high success rate. Comprehensive attack experiments are carried out on DQN to testify the attack performance in aspects of reward and loss convergence.},
booktitle = {Security, Privacy, and Anonymity in Computation, Communication, and Storage: 13th International Conference, SpaCCS 2020, Nanjing, China, December 18-20, 2020, Proceedings},
pages = {19–43},
numpages = {25},
keywords = {Feature transformation, Attention mechanism, White-box attack, DQN, Deep reinforcement learning},
location = {Nanjing, China}
}

@article{10.1016/j.ins.2019.04.060,
author = {Le, Tuong and Vo, Bay and Fujita, Hamido and Nguyen, Ngoc-Thanh and Baik, Sung Wook},
title = {A fast and accurate approach for bankruptcy forecasting using squared logistics loss with GPU-based extreme gradient boosting},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {494},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.04.060},
doi = {10.1016/j.ins.2019.04.060},
journal = {Inf. Sci.},
month = aug,
pages = {294–310},
numpages = {17},
keywords = {Class imbalance problem, GPU computing, Squared logistics loss, Extreme gradient boosting, Bankruptcy forecasting}
}

@inproceedings{10.1109/ISSRE.2014.35,
author = {Lu, Huihua and Kocaguneli, Ekrem and Cukic, Bojan},
title = {Defect Prediction between Software Versions with Active Learning and Dimensionality Reduction},
year = {2014},
isbn = {9781479960330},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2014.35},
doi = {10.1109/ISSRE.2014.35},
abstract = {Accurate detection of defects prior to product release helps software engineers focus verification activities on defect prone modules, thus improving the effectiveness of software development. A common scenario is to use the defects from prior releases to build the prediction model for the upcoming release, typically through a supervised learning method. As software development is a dynamic process, fault characteristics in subsequent releases may vary. Therefore, supplementing the defect information from prior releases with limited information about the defects from the current release detected early seems to offer intuitive and practical benefits. We propose active learning as a way to automate the development of models which improve the performance of defect prediction between successive releases. Our results show that the integration of active learning with uncertainty sampling consistently outperforms the corresponding supervised learning approach. We further improve the prediction performance with feature compression techniques, where feature selection or dimensionality reduction is applied to defect data prior to active learning. We observe that dimensionality reduction techniques, particularly multidimensional scaling with random forest similarity, work better than feature selection due to their ability to identify and combine essential information in data set features. We present the improvements offered by this methodology through the prediction of defective modules in the three successive versions of Eclipse.},
booktitle = {Proceedings of the 2014 IEEE 25th International Symposium on Software Reliability Engineering},
pages = {312–322},
numpages = {11},
keywords = {Software defect prediction, Machine learning, Dimensionality reduction, Complexity measures, Active learning},
series = {ISSRE '14}
}

@article{10.1016/j.eswa.2015.03.013,
author = {\"{O}zt\"{u}rk, Muhammed Maruf and Cavusoglu, Unal and Zengin, Ahmet},
title = {A novel defect prediction method for web pages using k-means++},
year = {2015},
issue_date = {November 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {19},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.03.013},
doi = {10.1016/j.eswa.2015.03.013},
abstract = {Presents a novel defect clustering method.Shed new light to defect prediction methods.Depicts the prominence of k-means++ for software testing.Unveils the density of error rates of web elements. With the increase of the web software complexity, defect detection and prevention have become crucial processes in the software industry. Over the past decades, defect prediction research has reported encouraging results for reducing software product costs. Despite promising results, these researches have hardly been applied to web based systems using clustering algorithms. An appropriate implementation of the clustering in defect prediction may facilitate to estimate defects in a web page source code. One of the widely used clustering algorithms is k-means whose derived versions such as k-means++ show good performance on large-data sets. Here, we present a new defect clustering method using k-means++ for web page source codes. According to the experimental results, almost half of the defects are detected in the middle of web pages. k-means++ is significantly better than the other four clustering algorithms in three criteria on four data set. We also tested our method on four classifiers and the results have shown that after the clustering, Linear Discriminant Analysis is, in general, better than the other three classifiers.},
journal = {Expert Syst. Appl.},
month = nov,
pages = {6496–6506},
numpages = {11},
keywords = {k-means++, Software testing, Fault clustering, Defect prediction}
}

@article{10.1016/j.compind.2019.04.015,
author = {Yu, Jianbo and Zheng, Xiaoyun and Liu, Jiatong},
title = {Stacked convolutional sparse denoising auto-encoder for identification of defect patterns in semiconductor wafer map},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {109},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2019.04.015},
doi = {10.1016/j.compind.2019.04.015},
journal = {Comput. Ind.},
month = aug,
pages = {121–133},
numpages = {13},
keywords = {Pattern recognition, Convolutional neural network, Deep learning, Wafer map, Semiconductor manufacturing}
}

@inproceedings{10.1145/3382025.3414960,
author = {Str\"{u}der, Stefan and Mukelabai, Mukelabai and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Feature-oriented defect prediction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414960},
doi = {10.1145/3382025.3414960},
abstract = {Software errors are a major nuisance in software development and can lead not only to reputation damages, but also to considerable financial losses for companies. Therefore, numerous techniques for predicting software defects, largely based on machine learning methods, have been developed over the past decades. These techniques usually rely on code and process metrics in order to predict defects at the granularity of typical software assets, such as subsystems, components, and files. In this paper, we present the first systematic investigation of feature-oriented defect prediction: the prediction of defects at the granularity of features---domain-oriented entities abstractly representing (and often cross-cutting) typical software assets. Feature-oriented prediction can be beneficial, since: (i) particular features might be more error-prone than others, (ii) characteristics of features known as defective might be useful to predict other error-prone features, (iii) feature-specific code might be especially prone to faults arising from feature interactions. We present a dataset derived from 12 software projects and introduce two metric sets for feature-oriented defect prediction. We evaluated seven machine learning classifiers with three different attribute sets each, using our two new metric sets as well as an existing metric set from the literature. We observe precision and recall values of around 85% and better robustness when more diverse metrics sets with richer feature information are used.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {21},
numpages = {12},
keywords = {prediction, feature, defect, classification},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@phdthesis{10.5555/AAI28745130,
author = {Simons, Taylor Scott},
advisor = {Dah-Jye, Lee,},
title = {High-Speed Image Classification for Resource-Limited Systems Using Binary Values},
year = {2021},
isbn = {9798494448750},
publisher = {Brigham Young University},
address = {USA},
abstract = {Image classification is a memory- and compute-intensive task. It is difficult to implement high-speed image classification algorithms on resource-limited systems like FPGAs and embedded computers. Most image classification algorithms require many fixed- and/or floating-point operations and values. In this work, we explore the use of binary values to reduce the memory and compute requirements of image classification algorithms. Our objective was to implement these algorithms on resource-limited systems while maintaining comparable accuracy and high speeds. By implementing high-speed image classification algorithms on resource-limited systems like embedded computers, FPGAs, and ASICs, automated visual inspection can be performed on small low-powered systems. Industries like manufacturing, medicine, and agriculture can benefit from compact, high-speed, low-power visual inspection systems. Tasks like defect detection in manufactured products and quality sorting of harvested produce can be performed cheaper and more quickly. In this work, we present ECO Jet Features, an algorithm adapted to use binary values for visual inspection. The ECO Jet Features algorithm ran 3.7\texttimes{} faster than the original ECO Features algorithm on embedded computers. It also allowed the algorithm to be implemented on an FPGA, achieving 78\texttimes{} speedup over full-sized desktop systems, using a fraction of the power and space. We reviewed Binarized Neural Nets (BNNs), neural networks that use binary values for weights and activations. These networks are particularly well suited for FPGA implementation and we compared and contrasted various FPGA implementations found throughout the literature. Finally, we combined the deep learning methods used in BNNs with the efficiency of Jet Features to make Neural Jet Features. Neural Jet Features are binarized convolutional layers that are learned through deep learning and learn classic computer vision kernels like the Gaussian and Sobel kernels. These kernels are efficiently computed as a group and their outputs can be reused when forming output channels. They performed just as well as BNN convolutions on visual inspection tasks and are more stable when trained on small models.},
note = {AAI28745130}
}

@article{10.1016/j.eswa.2019.113122,
author = {Tubishat, Mohammad and Idris, Norisma and Shuib, Liyana and Abushariah, Mohammad A.M. and Mirjalili, Seyedali},
title = {Improved Salp Swarm Algorithm based on opposition based learning and novel local search algorithm for feature selection},
year = {2020},
issue_date = {May 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {145},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113122},
doi = {10.1016/j.eswa.2019.113122},
journal = {Expert Syst. Appl.},
month = may,
numpages = {10},
keywords = {Opposition Based Learning, Algorithm, Machine Learning, Optimization, Feature selection, Classification, Salp Swarm Algorithm}
}

@inproceedings{10.1145/3205651.3208262,
author = {Ebert, Samuel and Farhana, Effat and Heber, Steffen},
title = {A parallel island model for biogeography-based classification rule mining in julia},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3208262},
doi = {10.1145/3205651.3208262},
abstract = {In this paper, we present a distributed island model implementation of biogeography-based optimization for classification rule mining (island BBO-RM). Island BBO-RM is an evolutionary algorithm for rule mining that uses Pittsburgh style classification rule encoding, which represents an entire ruleset (classifier) as a single chromosome. Our algorithm relies on biogeography-based optimization (BBO), an optimization technique that is inspired by species migration pattern between habitats. Biogeography-based optimization has been reported to perform well in various applications ranging from function optimization to image classification. A major limitation of evolutionary rule mining algorithms is their high computational cost and running time. To address this challenge, we have applied a distributed island model to parallelize the rule extraction phase via BBO. We have explored several different migration topologies and data windowing techniques. Our algorithm is implemented in Julia, a dynamic programming language designed for high-performance and parallel computation. Our results show that our distributed implementation is able to achieve considerable speedups when compared to a serial implementation. Without data windowing, we obtain speedups up to a factor of nine without a loss of classification accuracy. With data windowing, we obtain speedups up to a factor of 30 with a small loss of accuracy in some cases.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1284–1291},
numpages = {8},
keywords = {island model, genetics-based machine learning, evolutionary algorithms, biogeography-based optimization},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@article{10.1007/s11042-020-09915-1,
author = {Singh, Om Dev and Malik, Anjali and Yadav, Vishakha and Gupta, Shailender and Dora, Shirin},
title = {Deep Segmenter system for recognition of micro cracks in solar cell},
year = {2021},
issue_date = {Feb 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {5},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-09915-1},
doi = {10.1007/s11042-020-09915-1},
abstract = {A solar panel is array of Photo-Voltaic modules (PVC) that are mounted together in a mechanical frame and are placed in the open fields so that sunlight impinges on those cells to produce electricity. The effectiveness of solar panels is cogently restricted by the impurities and defects present in the PVC. These imperfections bring profound energy levels in the semiconductor bandgap, depreciating the carrier lifetime and quantum efficiency of cells. It is significant to recognize the defects physics so that apposite methods may be employed to restrain the formation of severe flaws. In various past techniques, image processing, machine learning, and deep learning techniques are implemented to recognize, classify, or predict the probability of defects and their effect on PVC’s overall performance. One of these approaches is an automatic recognition of micro-cracks, which is a compelling but challenging task. To achieve this, a deep learning approach based on the classification and segmentation process is proposed in this paper. This mechanism not only detects the micro-cracks but also effectively locates the area of the defected pixels. For the categorization of defects, VGG16 is used as a CNN classifier, and a Deep crack approach for the segmentation process is used. Thresholding and Decision Making are added to remove redundant pixels related to diverse types of frames present in PVC’s, and finally, a decision is made. An unsharp filter is utilized because of efficient performance. This technique exhibits effective results in decision making, whether the solar cell needs to be replaced or not based on the percentage area of irregularity. The proposed model outperforms state-of-the-art methods with better performance in all aspects.},
journal = {Multimedia Tools Appl.},
month = feb,
pages = {6509–6533},
numpages = {25},
keywords = {VGG16, Unsharp filter, Solar panel, Segmentation, Machine learning, Image processing, Deep Segmenter, Crack detection, Classification, CNN}
}

@inproceedings{10.1145/3387904.3389263,
author = {He, Jianjun and Xu, Ling and Yan, Meng and Xia, Xin and Lei, Yan},
title = {Duplicate Bug Report Detection Using Dual-Channel Convolutional Neural Networks},
year = {2020},
isbn = {9781450379588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387904.3389263},
doi = {10.1145/3387904.3389263},
abstract = {Developers rely on bug reports to fix bugs. The bug reports are usually stored and managed in bug tracking systems. Due to the different expression habits, different reporters may use different expressions to describe the same bug in the bug tracking system. As a result, the bug tracking system often contains many duplicate bug reports. Automatically detecting these duplicate bug reports would save a large amount of effort for bug analysis. Prior studies have found that deep-learning technique is effective for duplicate bug report detection. Inspired by recent Natural Language Processing (NLP) research, in this paper, we propose a duplicate bug report detection approach based on Dual-Channel Convolutional Neural Networks (DC-CNN). We present a novel bug report pair representation, i.e., dual-channel matrix through concatenating two single-channel matrices representing bug reports. Such bug report pairs are fed to a CNN model to capture the correlated semantic relationships between bug reports. Then, our approach uses the association features to classify whether a pair of bug reports are duplicate or not. We evaluate our approach on three large datasets from three open-source projects, including Open Office, Eclipse, Net Beans and a larger combined dataset, and the accuracy of classification reaches 0.9429, 0.9685, 0.9534, 0.9552 respectively. Such performance outperforms the two state-of-the-art approaches which also use deep-learning techniques. The results indicate that our dual-channel matrix representation is effective for duplicate bug report detection.},
booktitle = {Proceedings of the 28th International Conference on Program Comprehension},
pages = {117–127},
numpages = {11},
keywords = {Software Quality Assurance, Software Maintenance, Duplicate Bug Report Detection, Dual-Channel, Convolutional Neural Networks},
location = {Seoul, Republic of Korea},
series = {ICPC '20}
}

@article{10.1016/j.eswa.2021.114753,
author = {Gonzalez-Rodriguez, Angel Gaspar and Gonzalez-Rodriguez, Antonio and Castillo-Garcia, Fernando Jose},
title = {A league-winner algorithm for defect classification in an industrial web inspection system},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {175},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114753},
doi = {10.1016/j.eswa.2021.114753},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {14},
keywords = {gradient descent, supervised training, decision tree, artificial neural networks, pairwise comparison, Pattern recognition}
}

@article{10.1016/j.procs.2021.09.121,
author = {B\l{}aszczyk, Miko\l{}aj and Jundefineddrzejowicz, Joanna},
title = {Framework for imbalanced data classification},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {192},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.09.121},
doi = {10.1016/j.procs.2021.09.121},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {3477–3486},
numpages = {10},
keywords = {dynamic selection of classifiers, oversampling, imbalanced data}
}

@inproceedings{10.1007/978-3-030-86230-5_34,
author = {Salgueiro, Andr\'{e} and Santos, Sofia and Pereira, Artur and Cunha, Bernardo and Pedrosa, Eurico and Azevedo, Jos\'{e} Luis and Lau, Nuno and Lopes, Paulo and Gomes, Tiago},
title = {Neural Network Classifier and Robotic Manipulation for an Autonomous Industrial Cork Feeder},
year = {2021},
isbn = {978-3-030-86229-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86230-5_34},
doi = {10.1007/978-3-030-86230-5_34},
abstract = {This paper presents a solution for an autonomous cork puncher feeder with a robotic arm using image processing techniques and a convolutional neural network. Due to the need for cork strips to be inserted into the puncher with a specific orientation, to produce high quality cork stoppers, the identification of the orientation of each cork strip on the conveyor belt is a necessity. In response to this problem a convolutional neural network is used to analyse images processed with subtracted background, to create a robust solution for cork strips classification. In the tests carried out, a classification accuracy of 100% was obtained in a test data set with 12 different cork strips.},
booktitle = {Progress in Artificial Intelligence: 20th EPIA Conference on Artificial Intelligence, EPIA 2021, Virtual Event, September 7–9, 2021, Proceedings},
pages = {433–444},
numpages = {12},
keywords = {Computer vision, Universal Robots, Convolutional neural network, Deep learning, Cork}
}

@article{10.1016/j.procs.2018.05.071,
author = {Pandey, Sushant Kumar and Mishra, Ravi Bhushan and Triphathi, Anil Kumar},
title = {Software Bug Prediction Prototype Using Bayesian Network Classifier: A Comprehensive Model},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.071},
doi = {10.1016/j.procs.2018.05.071},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {1412–1421},
numpages = {10},
keywords = {Bayesian network, bug prediction, classification techniques}
}

@inproceedings{10.5555/2022348.2022375,
author = {Di Martino, Sergio and Ferrucci, Filomena and Gravino, Carmine and Sarro, Federica},
title = {A genetic algorithm to configure support vector machines for predicting fault-prone components},
year = {2011},
isbn = {9783642218422},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {In some studies, Support Vector Machines (SVMs) have been turned out to be promising for predicting fault-prone software components. Nevertheless, the performance of the method depends on the setting of some parameters. To address this issue, we propose the use of a Genetic Algorithm (GA) to search for a suitable configuration of SVMs parameters that allows us to obtain optimal prediction performance. The approach has been assessed carrying out an empirical analysis based on jEdit data from the PROMISE repository. We analyzed both the inter- and the intra-release performance of the proposed method. As benchmarks we exploited SVMs with Grid-search and several other machine learning techniques. The results show that the proposed approach let us to obtain an improvement of the performance with an increasing of the Recall measure without worsening the Precision one. This behavior was especially remarkable for the inter-release use with respect to the other prediction techniques.},
booktitle = {Proceedings of the 12th International Conference on Product-Focused Software Process Improvement},
pages = {247–261},
numpages = {15},
keywords = {support vector machines, genetic algorithm, fault prediction},
location = {Torre Canne, Italy},
series = {PROFES'11}
}

@inproceedings{10.1145/2875913.2875922,
author = {Tang, Hao and Lan, Tian and Hao, Dan and Zhang, Lu},
title = {Enhancing Defect Prediction with Static Defect Analysis},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875922},
doi = {10.1145/2875913.2875922},
abstract = {In the software development process, how to develop better software at lower cost has been a major issue of concern. One way that helps is to find more defects as early as possible, on which defect prediction can provide effective guidance. The most popular defect prediction technique is to build defect prediction models based on machine learning. To improve the performance of defect prediction model, selecting appropriate features is critical. On the other hand, static analysis is usually used in defect detection. As static defect analyzers detects defects by matching some well-defined "defect patterns", its result is useful for locating defects. However, defect prediction and static defect analysis are supposed to be two parallel areas due to the differences in research motivation, solution and granularity.In this paper, we present a possible approach to improve the performance of defect prediction with the help of static analysis techniques. Specifically, we present to extract features based on defect patterns from static defect analyzers to improve the performance of defect prediction models. Based on this approach, we implemented a defect prediction tool and set up experiments to measure the effect of the features.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {43–51},
numpages = {9},
keywords = {static defect analyzer, predictive model, machine learning, defect pattern, code feature, Defect},
location = {Wuhan, China},
series = {Internetware '15}
}

@inproceedings{10.1007/978-3-030-78612-0_5,
author = {Xu, Haitao and Duan, Ruifeng and Yang, Shengsong and Guo, Lei},
title = {An Empirical Study on Data Sampling for Just-in-Time Defect Prediction},
year = {2021},
isbn = {978-3-030-78611-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78612-0_5},
doi = {10.1007/978-3-030-78612-0_5},
abstract = {In this paper, the impact of Data Sampling on Just-in-Time defect prediction is explored. We find that there is a significant negative relationship between the class imbalance ratio of the dataset and the performance of the instant software defect prediction model. Secondly although most software defect data are not as unbalanced as expected, a moderate degree of imbalance is sufficient to affect the performance of traditional learning. This means that if the training data for immediate software defects show moderate or more severe imbalances, one need not expect good defect prediction performance and the data sampling approach to balancing the training data can improve the performance of the model. Finally, the empirical approach shows that although the under-sampling method slightly improves model performance, the different sampling methods do not have a substantial impact on the evaluation of immediate software defect prediction models.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part II},
pages = {54–69},
numpages = {16},
keywords = {Empirical study, Just-in-time defect, Data sampling},
location = {Dublin, Ireland}
}

@article{10.1007/s10515-014-0155-1,
author = {Huang, Liguo and Ng, Vincent and Persing, Isaac and Chen, Mingrui and Li, Zeheng and Geng, Ruili and Tian, Jeff},
title = {AutoODC: Automated generation of orthogonal defect classifications},
year = {2015},
issue_date = {March     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-014-0155-1},
doi = {10.1007/s10515-014-0155-1},
abstract = {Orthogonal defect classification (ODC), the most influential framework for software defect classification and analysis, provides valuable in-process feedback to system development and maintenance. Conducting ODC classification on existing organizational defect reports is human-intensive and requires experts' knowledge of both ODC and system domains. This paper presents AutoODC, an approach for automating ODC classification by casting it as a supervised text classification problem. Rather than merely applying the standard machine learning framework to this task, we seek to acquire a better ODC classification system by integrating experts' ODC experience and domain knowledge into the learning process via proposing a novel relevance annotation framework. We have trained AutoODC using two state-of-the-art machine learning algorithms for text classification, Naive Bayes (NB) and support vector machine (SVM), and evaluated it on both an industrial defect report from the social network domain and a larger defect list extracted from a publicly accessible defect tracker of the open source system FileZilla. AutoODC is a promising approach: not only does it leverage minimal human effort beyond the human annotations typically required by standard machine learning approaches, but it achieves overall accuracies of 82.9 % (NB) and 80.7 % (SVM) on the industrial defect report, and accuracies of 77.5 % (NB) and 75.2 % (SVM) on the larger, more diversified open source defect list.},
journal = {Automated Software Engg.},
month = mar,
pages = {3–46},
numpages = {44},
keywords = {Text classification, Orthogonal defect classification (ODC), Natural language processing, Machine learning}
}

@article{10.1007/s00354-020-00119-7,
author = {Sharma, Nonita and Dev, Jaiditya and Mangla, Monika and Wadhwa, Vaishali Mehta and Mohanty, Sachi Nandan and Kakkar, Deepti},
title = {A Heterogeneous Ensemble Forecasting Model for Disease Prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Ohmsha},
address = {JPN},
volume = {39},
number = {3},
issn = {0288-3635},
url = {https://doi.org/10.1007/s00354-020-00119-7},
doi = {10.1007/s00354-020-00119-7},
abstract = {The manuscript presents a bragging-based ensemble forecasting model for predicting the number of incidences of a disease based on past occurrences. The objectives of this research work are to enhance accuracy, reduce overfitting, and handle overdrift; the proposed model has shown promising results in terms of error metrics. The collated dataset of the diseases is collected from the official government site of Hong Kong from the year 2010 to 2019. The preprocessing is done using log transformation and z score transformation. The proposed ensemble model is applied, and its applicability to a specific disease dataset is presented. The proposed ensemble model is compared against the ensemble models, namely dynamic ensemble for time series, arbitrated dynamic ensemble, and random forest using different error metrics. The proposed model shows the reduced value of MAE (mean average error) by 27.18%, 3.07%, 11.58%, 13.46% for tuberculosis, dengue, food poisoning, and chickenpox, respectively. The comparison drawn between the proposed model and the existing models shows that the proposed ensemble model gives better accuracy in the case of all the four-disease datasets.},
journal = {New Gen. Comput.},
month = nov,
pages = {701–715},
numpages = {15},
keywords = {Bootstrapping, Bragging, Disease forecasting, Ensemble, Time series forecasting}
}

@inproceedings{10.1145/3127005.3127007,
author = {Minku, Leandro L. and Hou, Siqing},
title = {Clustering Dycom: An Online Cross-Company Software Effort Estimation Study},
year = {2017},
isbn = {9781450353052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127005.3127007},
doi = {10.1145/3127005.3127007},
abstract = {Background: Software Effort Estimation (SEE) can be formulated as an online learning problem, where new projects are completed over time and may become available for training. In this scenario, a Cross-Company (CC) SEE approach called Dycom can drastically reduce the number of Within-Company (WC) projects needed for training, saving the high cost of collecting such training projects. However, Dycom relies on splitting CC projects into different subsets in order to create its CC models. Such splitting can have a significant impact on Dycom's predictive performance. Aims: This paper investigates whether clustering methods can be used to help finding good CC splits for Dycom. Method: Dycom is extended to use clustering methods for creating the CC subsets. Three different clustering methods are investigated, namely Hierarchical Clustering, K-Means, and Expectation-Maximisation. Clustering Dycom is compared against the original Dycom with CC subsets of different sizes, based on four SEE databases. A baseline WC model is also included in the analysis. Results: Clustering Dycom with K-Means can potentially help to split the CC projects, managing to achieve similar or better predictive performance than Dycom. However, K-Means still requires the number of CC subsets to be pre-defined, and a poor choice can negatively affect predictive performance. EM enables Dycom to automatically set the number of CC subsets while still maintaining or improving predictive performance with respect to the baseline WC model. Clustering Dycom with Hierarchical Clustering did not offer significant advantage in terms of predictive performance. Conclusion: Clustering methods can be an effective way to automatically generate Dycom's CC subsets.},
booktitle = {Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {12–21},
numpages = {10},
keywords = {Software effort estimation, concept drift, cross-company learning, ensembles, online learning},
location = {Toronto, Canada},
series = {PROMISE}
}

@inproceedings{10.1007/978-3-030-32409-4_1,
author = {Liu, Yang and Ma, Lei and Zhao, Jianjun},
title = {Secure Deep Learning Engineering: A Road Towards Quality Assurance of Intelligent Systems},
year = {2019},
isbn = {978-3-030-32408-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-32409-4_1},
doi = {10.1007/978-3-030-32409-4_1},
abstract = {Over the past decades, deep learning (DL) systems have achieved tremendous success and gained great popularity in various applications, such as intelligent machines, image processing, speech processing, and medical diagnostics. Deep neural networks are the key driving force behind its recent success, but still seem to be a magic black box lacking interpretability and understanding. This brings up many open safety and security issues with enormous and urgent demands on rigorous methodologies and engineering practice for quality enhancement. A plethora of studies have shown that state-of-the-art DL systems suffer from defects and vulnerabilities that can lead to severe loss and tragedies, especially when applied to real-world safety-critical applications.In this paper, we perform a large-scale study and construct a paper repository of 223 relevant works to the quality assurance, security, and interpretation of deep learning. Based on this, we, from a software quality assurance perspective, pinpoint challenges and future opportunities to facilitate drawing the attention of the software engineering community towards addressing the pressing industrial demand of secure intelligent systems.},
booktitle = {Formal Methods and Software Engineering: 21st International Conference on Formal Engineering Methods, ICFEM 2019, Shenzhen, China, November 5–9, 2019, Proceedings},
pages = {3–15},
numpages = {13},
keywords = {Deep learning engineering, Reliability, Quality assurance, Security, Software engineering, Deep learning, Artificial intelligence},
location = {Shenzhen, China}
}

@article{10.1007/s00521-020-04750-9,
author = {Li, Wenjing and Wu, Zhongcheng and Zhang, Jun and Ren, Tingting and Li, Fang},
title = {LGSim: local task-invariant and global task-specific similarity for few-shot classification},
year = {2020},
issue_date = {Aug 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04750-9},
doi = {10.1007/s00521-020-04750-9},
abstract = {Few-shot learning is one of the most challenging problems in computer vision due to the difficulty of sample collection in many real-world applications. It aims at classifying a sample when the number of training samples for each identity is limited. Most of the existing few-shot learning models learn a distance metric with pairwise or triplet constraints. In this paper, we make initial attempts on learning local and global similarities simultaneously to improve the few-shot classification performance in terms of accuracy. In particular, our system differs in two aspects. Firstly, we develop a neural network to learn the pairwise local relationship between each pair of samples in the union set that is composed of support set and query set, which fully utilize the supervision. Secondly, we design a global similarity function from the manifold perspective. The latent assumption is that if the neighbors of one sample are similar to those of another sample, the global similarity between them will be high. Otherwise, the global similarity of the two samples will become very low even if the local similarity between them is high. Meanwhile, we propose a new loss according to the pairwise local loss and task-specific global loss, encouraging the model toward better generalization. Extensive experiments on three popular benchmarks (Omniglot, miniImageNet and tieredImageNet) demonstrate that our simple, yet effective approach can achieve competitive accuracy compared to the state-of-the-art methods.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {13065–13076},
numpages = {12},
keywords = {Meta-learning, Global similarity, Local similarity, Few-shot learning}
}

@inproceedings{10.1145/3383972.3384008,
author = {Yang, Gao and Hao, Gong and Weijia, Lu and Qinghua, Wang and Chen, Su and Zhang, Ni},
title = {An Attentive Pruning Method for Edge Computing},
year = {2020},
isbn = {9781450376426},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383972.3384008},
doi = {10.1145/3383972.3384008},
abstract = {Nowadays, the power of an edge computing hardware is usually the bottleneck of AI application. Most of the embedding devices in factory have no GPU, some of them even using Intel i3 or ARM chips. Model compression is very convenient and effective way to handle this problem. But it still has two major limitations, the arbitrariness in pruning ratio setup and inevitable accuracy drop. In this paper, we propose an adaptive network channel pruning method without a priori knowledge of pruning ratio. This method is based on the attentive weights from modified SE block, establishes a detectable and trainable mask learning module from the original to-be-prune network. Moreover we make innovative modifications on SE block, to enhance the sparsity of attentive weights. Extensive experiments afterwards indicate that our method can not only accelerate model inference process or equivalently decrease model footprint, but also get better performance in test set. Even a tiny network like Yolo cifar-10 with 15 layers can be pruned about 50% FLOPs without accuracy decrease using proposed method.},
booktitle = {Proceedings of the 2020 12th International Conference on Machine Learning and Computing},
pages = {6–10},
numpages = {5},
keywords = {Model Compress, Keep Accuracy, Improved SE block},
location = {Shenzhen, China},
series = {ICMLC '20}
}

@article{10.3233/JIFS-169344,
author = {Li, Chen and Wei, Fajie and Wang, Cheng and Zhou, Shenghan and Guirao, Juan L.G. and Gao, Wei},
title = {Fault diagnosis and prediction of complex system based on Hidden Markov model},
year = {2017},
issue_date = {2017},
publisher = {IOS Press},
address = {NLD},
volume = {33},
number = {5},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-169344},
doi = {10.3233/JIFS-169344},
abstract = {To guarantee the performance and security of the complex system, in this paper, we focus on the problem of fault diagnosis and fault prediction method for the complex system. The proposed fault diagnosis and prediction system is made up of three parts: 1) Data preprocessing, 2) Degradation state detection, and 3) Fault diagnosis. Afterwards, we exploit the Wavelet transform correlation filter to extract features for complex system fault diagnosis and prediction. Particularly, the direct spatial correlations of wavelet transform contents are used to search the locations of edges. To promote the performance of Hidden Markov model, we propose a HMM-based semi-nonparametric method by the probabilistic transition frequency profile matrix and the average probabilistic emission matrix. Then, the training sequence which is the most similar to a particular sequence can be found by the modified HMM model. Finally, experimental results prove that the proposed algorithm can effectively enhance the accuracy of equipment fault diagnosis and equipment state recognition task.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {2937–2944},
numpages = {8},
keywords = {fault prediction, fault diagnosis, Hidden Markov model, Complex system}
}

@inproceedings{10.1007/978-3-030-40605-9_31,
author = {Ting, Yu-Chieh and Lin, Daw-Tung and Chen, Chih-Feng and Tsai, Bor-Chen},
title = {Automatic Optical Inspection for Millimeter Scale Probe Surface Stripping Defects Using Convolutional Neural Network},
year = {2020},
isbn = {978-3-030-40604-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-40605-9_31},
doi = {10.1007/978-3-030-40605-9_31},
abstract = {Surface defect inspection is a crucial step during the production process of IC probe. The traditional way of identifying defective IC probes mostly relies on the human visual examination through the microscope screen. However, this approach will be affected by some subjective factors or misjudgments of inspectors, and the accuracy and efficiency are not sufficiently stable. Therefore, we propose an automatic optical inspection system by incorporating the ResNet-101 deep learning architecture into the faster region-based convolutional neural network (Faster R-CNN) to detect the stripping-gold defect on the IC probe surface. The training samples were collected through our designed multi-function investigation platform IMSLAB. To circumvent the challenge of insufficient images in our datasets, we introduce data augmentation using cycle generative adversarial networks (CycleGAN). The proposed system was evaluated using 133 probes. The experimental results revealed our method performed high accuracy in stripping defect detection. The overall mean average precision (mAP) was 0.732, and the defect IC probe classification accuracy rate was 97.74%.},
booktitle = {Advanced Concepts for Intelligent Vision Systems: 20th International Conference, ACIVS 2020, Auckland, New Zealand, February 10–14, 2020, Proceedings},
pages = {360–369},
numpages = {10},
keywords = {Automatic optical inspection, IC probe, Surface defect detection, Object detection, Deep learning},
location = {Auckland, New Zealand}
}

@inproceedings{10.1145/2070821.2070829,
author = {Zhang, Dongmei and Dang, Yingnong and Lou, Jian-Guang and Han, Shi and Zhang, Haidong and Xie, Tao},
title = {Software analytics as a learning case in practice: approaches and experiences},
year = {2011},
isbn = {9781450310222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2070821.2070829},
doi = {10.1145/2070821.2070829},
abstract = {Software analytics is to enable software practitioners to perform data exploration and analysis in order to obtain insightful and actionable information for data-driven tasks around software and services. In this position paper, we advocate that when applying analytic technologies in practice of software analytics, one should (1) incorporate a broad spectrum of domain knowledge and expertise, e.g., management, machine learning, large-scale data processing and computing, and information visualization; and (2) investigate how practitioners take actions on the produced information, and provide effective support for such information-based action taking. Our position is based on our experiences of successful technology transfer on software analytics at Microsoft Research Asia.},
booktitle = {Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering},
pages = {55–58},
numpages = {4},
keywords = {technology transfer, software analytics, machine learning},
location = {Lawrence, Kansas, USA},
series = {MALETS '11}
}

@inproceedings{10.1007/978-3-031-02444-3_8,
author = {Li, Huanyu and Zhang, Cuicao and Li, Chunlei and Liu, Zhoufeng and Dong, Yan and Tang, Shuili},
title = {Rapid and&nbsp;High-Purity Seed Grading Based on&nbsp;Pruned Deep Convolutional Neural Network},
year = {2021},
isbn = {978-3-031-02443-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-02444-3_8},
doi = {10.1007/978-3-031-02444-3_8},
abstract = {The crop seed grading method based on deep learning has achieved ideal recognition results. However, an effective deep neural network model for seed grading usually needs a relatively high computational complexity, memory space, or inference time, which critically hampers the utilization of complex CNNs on devices with limited computational resources. For this reason, a method of combining layer pruning and filter pruning is proposed to realize fast and high-purity seed grading. First, we propose an effective approach based on feature representation to eliminate redundant convolutional layers, which greatly reduces the model’s consumption of device storage resources. Then, the filter-level pruning based on the Taylor expansion criterion is introduced to further eliminate the redundant information existing in the convolutional layer. Finally, an effective and practical knowledge distillation technology (MEAL V2) is adopted to transfer knowledge of well-performing models, to compensate for the information loss caused by the pruning of the network. Experiments on red kidney bean datasets demonstrate that the method is effective and feasible. We proposed the Vgg_Beannet, which can achieve 4\texttimes{} inference acceleration while the accuracy is only reduced by 0.13% when the filter is pruned by 90%. Moreover, we also compared some handcrafted lightweight architectures such as MobileNetv2, MixNet, etc. The results show that the pruned network outperforms the above network in inference time (2.07&nbsp;ms vs. 7.83&nbsp;ms, 22.23&nbsp;ms) and accuracy (96.33% vs. 95.94%, 94.89%).},
booktitle = {Pattern Recognition: 6th Asian Conference, ACPR 2021, Jeju Island, South Korea, November 9–12, 2021, Revised Selected Papers, Part II},
pages = {101–115},
numpages = {15},
keywords = {Knowledge distillation, Neural network pruning, Deep learning, Seed grading},
location = {Jeju Island, Korea (Republic of)}
}

@article{10.1016/j.jss.2014.08.034,
author = {Alsawalqah, Hamad I. and Kang, Sungwon and Lee, Jihyun},
title = {A method to optimize the scope of a software product platform based on end-user features},
year = {2014},
issue_date = {December 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {98},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.08.034},
doi = {10.1016/j.jss.2014.08.034},
abstract = {A novel method to optimize the scope of a software product platform is proposed.The method is supported with a mathematical formulation and an optimization solver.Depending on the input parameters and the objectives, competing scopes can exist.The method shows how trade-off analysis can be performed among competing scopes.The results of the method were validated as "satisfiable" to "very satisfiable". ContextDue to increased competition and the advent of mass customization, many software firms are utilizing product families - groups of related products derived from a product platform - to provide product variety in a cost-effective manner. The key to designing a successful software product family is the product platform, so it is important to determine the most appropriate product platform scope related to business objectives, for product line development. AimThis paper proposes a novel method to find the optimized scope of a software product platform based on end-user features. MethodThe proposed method, PPSMS (Product Platform Scoping Method for Software Product Lines), mathematically formulates the product platform scope selection as an optimization problem. The problem formulation targets identification of an optimized product platform scope that will maximize life cycle cost savings and the amount of commonality, while meeting the goals and needs of the envisioned customers' segments. A simulated annealing based algorithm that can solve problems heuristically is then used to help the decision maker in selecting a scope for the product platform, by performing tradeoff analysis of the commonality and cost savings objectives. ResultsIn a case study, PPSMS helped in identifying 5 non-dominated solutions considered to be of highest preference for decision making, taking into account both cost savings and commonality objectives. A quantitative and qualitative analysis indicated that human experts perceived value in adopting the method in practice, and that it was effective in identifying appropriate product platform scope.},
journal = {J. Syst. Softw.},
month = dec,
pages = {79–106},
numpages = {28},
keywords = {Software product line engineering, Product platform scope, Commonality decision}
}

@inproceedings{10.1007/978-3-030-37599-7_59,
author = {Jabbar, Eva and Besse, Philippe and Loubes, Jean-Michel and Merle, Christophe},
title = {Conditional Anomaly Detection for Quality and Productivity Improvement of Electronics Manufacturing Systems},
year = {2019},
isbn = {978-3-030-37598-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37599-7_59},
doi = {10.1007/978-3-030-37599-7_59},
abstract = {Today the integration of Artificial Intelligence (AI) solutions is part of the strategy in the industrial environment. We focus on anomaly detection in the framework of manufacturing electronic cards manufacturing under mass production conditions (24/7). Early anomaly detection is critical to avoid defects. Researches and applications of anomaly detection techniques in the industry have been published but when they face production constraints success is not guaranteed. Today’s manufacturing systems are complex and involve different behaviors. We propose and evaluate a new realistic methodology for detecting conditional anomalies that could be successfully implemented in production. The proposed solution is based on Variational Autoencoders (VAEs) which provide interesting scores under the near real-time constraints of the production environment. The results have been thoroughly evaluated and validated with the support of expert process engineers.},
booktitle = {Machine Learning, Optimization, and Data Science: 5th International Conference, LOD 2019, Siena, Italy, September 10–13, 2019, Proceedings},
pages = {711–724},
numpages = {14},
keywords = {Deep conditional anomaly detection, Artificial Intelligence, Electronic circuit manufacturing, Smart factory},
location = {Siena, Italy}
}

@inproceedings{10.1109/COASE.2019.8843280,
author = {Li, Yanfeng and Gao, Xiangdong and Zhang, Yanxi and You, Deyong and Wang, Congyi and Song, Yaowu and Zhang, Nanfeng},
title = {Detection model of invisible weld defects using magneto-optical imaging induced by rotating magnetic field},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8843280},
doi = {10.1109/COASE.2019.8843280},
abstract = {Magneto-optical (MO) imaging non-destructive testing (NDT) system excited by rotating magnetic field is proposed for feature extraction and detection classification of invisible arbitrary-angle weld defects. Based on Faraday rotation effect, the relationship between the imaging characteristics of weld defect MO image and the leakage magnetic field intensity is analyzed. The gray-level co-occurrence matrix (GLCM) method is used to extract texture features of the weld defect MO images, and the texture features of the images can reflect the leakage magnetic field characteristics of the defects. These texture features of the weld defect MO images are used as the input vector of the defect classification model based on support vector machine (SVM). The effectiveness and feasibility of the classification model are verified by the weld defect detection experiment. Experimental results show that the established recognition model can accurately classify invisible arbitrary-angle weld defects.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {1–5},
numpages = {5},
location = {Vancouver, BC, Canada}
}

@article{10.1016/j.cie.2016.05.009,
author = {Chen, Ying-Jen and Fan, Chu-Yuan and Chang, Kuo-Hao},
title = {Manufacturing intelligence for reducing false alarm of defect classification by integrating similarity matching approach in CMOS image sensor manufacturing},
year = {2016},
issue_date = {September 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {99},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2016.05.009},
doi = {10.1016/j.cie.2016.05.009},
abstract = {This study proposes similarity matching to reduce false alarm of defect classification.This study uses AUR as an index to select number of features for similarity matching.The proposed approach has robust performance based on experiments using real data. For CMOS image sensor (CIS) manufacturing, automatic optical inspection (AOI) is the critical equipment for defect reduction and yield enhancement. The capability of automated defect classification embedded in AOI equipment is the key factor to empower manufacturing intelligence. In manufacturing practice, catching rate (CR) and false alarm rate (FAR) are two indices to evaluate the performance of classification results. Rather than enhancing catching rate, reducing false alarm rate of the classification result is more concerned for the domain engineers since false alarms may cause poor decision-making and waste resource. Hence, domain users are easy to lose their confidence for the classification model even though the model had good performance on catching rate. Focusing on the realistic needs, this study aims to develop a manufacturing intelligence framework integrating defect inspection, feature extraction, support vector machine classifier, and similarity matching approach to reduce false alarm of defect classification, while the catching rate is enhanced. An empirical study was conducted in a leading CIS manufacturing company in Taiwan to estimate the validity and the results also demonstrated the practical value of the proposed approach.},
journal = {Comput. Ind. Eng.},
month = sep,
pages = {465–473},
numpages = {9},
keywords = {Yield enhancement, Similarity matching, Manufacturing intelligence, Defect detection and classification, Data mining and big data analytics, Automatic optical inspection}
}

@article{10.1007/s00371-020-01901-w,
author = {Yang, Tiejun and Zhang, Tianshu and Huang, Lin},
title = {Detection of defects in voltage-dependent resistors using stacked-block-based convolutional neural networks},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {37},
number = {6},
issn = {0178-2789},
url = {https://doi.org/10.1007/s00371-020-01901-w},
doi = {10.1007/s00371-020-01901-w},
abstract = {Voltage-dependent resistors (VDRs) are important circuit-protection devices. Their performance is affected by packaging quality. To identify VDR packaging defects more accurately and efficiently, we have proposed a convolutional neural network (CNN)-based VDR appearance quality inspection method that includes four stages: image acquisition, data augmentation, neural architecture design, and CNN training and testing. In designing the neural architecture, we have proposed two VDR-oriented network blocks, which consist of a compressed subnet and a multiscale subnet. Then, a stacking-block-based neural architecture design (BlockNAD) strategy is employed to determine the number of blocks. The last block is connected to a classification layer composed of a global average pooling (GAP) layer and a full connection (FC) layer. Further, using a VDR dataset containing 8058 images, we compared the identification performances of the candidate networks with different structures on 12 categories of VDR defects by adopting a variety of indicators, such as the mean average precision (mAP) and average test time per sample. The experimental results of the proposed method demonstrate competitive results compared to the state-of-the-art methods in identifying VDR defects, with a mAP value of approximately 99.9% and an average test time per sample of approximately 3&nbsp;ms.},
journal = {Vis. Comput.},
month = jun,
pages = {1559–1567},
numpages = {9},
keywords = {Voltage-dependent resistors, Defect detection, Deep convolutional neural networks, Neural architecture design}
}

@inproceedings{10.1145/3178212.3178221,
author = {Rizwan, Syed and Tiantian, Wang and Xiaohong, Su and Salahuddin},
title = {Empirical Study on Software Bug Prediction},
year = {2017},
isbn = {9781450354882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3178212.3178221},
doi = {10.1145/3178212.3178221},
abstract = {Software defect prediction is a vital research direction in software engineering field. Software defect prediction predicts whether software errors are present in the software by using machine learning analysis on software metrics. It can help software developers to improve the quality of the software. Software defect prediction is usually a binary classification problem, which relies on software metrics and the use of classifiers. There have been many research efforts to improve accuracy in software defect prediction using a variety of classifiers and data preprocessing techniques. However, the "classic classifier validity" and "data preprocessing techniques can enhance the functionality of software defect prediction" has not yet been answered explicitly. Therefore, it is necessary to conduct an empirical analysis to compare these studies. In software defect prediction, the category of interest is a defective module, and the number of defective modules is much less than that of a non-defective module in data. This leads to a category of imbalance problem that reduces the accuracy of the prediction. Therefore, the problem of imbalance is a key problem that needs to be solved in software defect prediction. In this paper, we proposed an experimental model and used the NASA MDP data set to analyze the software defect prediction. Five research questions were defined and analyzed experimentally. In addition to experimental analysis, this paper focuses on the improvement of SMOTE. SMOTE ASMO algorithm has been proposed to overcome the shortcomings of SMOTE.},
booktitle = {Proceedings of the 2017 International Conference on Software and E-Business},
pages = {55–59},
numpages = {5},
keywords = {SMOTE, Defect prediction, Data preprocessing, Classification},
location = {Hong Kong, Hong Kong},
series = {ICSEB '17}
}

@article{10.1007/s10664-018-9596-7,
author = {Ferrari, Alessio and Gori, Gloria and Rosadini, Benedetta and Trotta, Iacopo and Bacherini, Stefano and Fantechi, Alessandro and Gnesi, Stefania},
title = {Detecting requirements defects with NLP patterns: an industrial experience in the railway domain},
year = {2018},
issue_date = {December  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9596-7},
doi = {10.1007/s10664-018-9596-7},
abstract = {In the railway safety-critical domain requirements documents have to abide to strict quality criteria. Rule-based natural language processing (NLP) techniques have been developed to automatically identify quality defects in natural language requirements. However, the literature is lacking empirical studies on the application of these techniques in industrial settings. Our goal is to investigate to which extent NLP can be practically applied to detect defects in the requirements documents of a railway signalling manufacturer. To address this goal, we first identified a set of typical defects classes, and, for each class, an engineer of the company implemented a set of defect-detection patterns by means of the GATE tool for text processing. After a preliminary analysis, we applied the patterns to a large set of 1866 requirements previously annotated for defects. The output of the patterns was further inspected by two domain experts to check the false positive cases. Additional discard-patterns were defined to automatically remove these cases. Finally, SREE, a tool that searches for typically ambiguous terms, was applied to the requirements. The experiments show that SREE and our patterns may play complementary roles in the detection of requirements defects. This is one of the first works in which defect detection NLP techniques are applied on a very large set of industrial requirements annotated by domain experts. We contribute with a comparison between traditional manual techniques used in industry for requirements analysis, and analysis performed with NLP. Our experience shows that several discrepancies can be observed between the two approaches. The analysis of the discrepancies offers hints to improve the capabilities of NLP techniques with company specific solutions, and suggests that also company practices need to be modified to effectively exploit NLP tools.},
journal = {Empirical Softw. Engg.},
month = dec,
pages = {3684–3733},
numpages = {50},
keywords = {Requirements engineering, Requirements analysis, Recall, Railway, Precision, Natural language requirements, Natural language processing, Industrial case study, Defect detection, Ambiguity}
}

@article{10.1016/j.aei.2019.01.001,
author = {Yang, Xiaohui and Chen, Wenkai and Li, Anyi and Yang, Chunsheng and Xie, Zihao and Dong, Huanyu},
title = {BA-PNN-based methods for power transformer fault diagnosis},
year = {2019},
issue_date = {Jan 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {39},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2019.01.001},
doi = {10.1016/j.aei.2019.01.001},
journal = {Adv. Eng. Inform.},
month = jan,
pages = {178–185},
numpages = {8},
keywords = {Fault diagnosis, Power transformer, Smooth factor, Probability neural network, Bat algorithm}
}

@inproceedings{10.1007/978-3-030-71278-5_7,
author = {Sharma, Saurabh and Yu, Ning and Fritz, Mario and Schiele, Bernt},
title = {Long-Tailed Recognition Using Class-Balanced Experts},
year = {2020},
isbn = {978-3-030-71277-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-71278-5_7},
doi = {10.1007/978-3-030-71278-5_7},
abstract = {Deep learning enables impressive performance in image recognition using large-scale artificially-balanced datasets. However, real-world datasets exhibit highly class-imbalanced distributions, yielding two main challenges: relative imbalance amongst the classes and data scarcity for mediumshot or fewshot classes. In this work, we address the problem of long-tailed recognition wherein the training set is highly imbalanced and the test set is kept balanced. Differently from existing paradigms relying on data-resampling, cost-sensitive learning, online hard example mining, loss objective reshaping, and/or memory-based modeling, we propose an ensemble of class-balanced experts that combines the strength of diverse classifiers. Our ensemble of class-balanced experts reaches results close to state-of-the-art and an extended ensemble establishes a new state-of-the-art on two benchmarks for long-tailed recognition. We conduct extensive experiments to analyse the performance of the ensembles, and discover that in modern large-scale datasets, relative imbalance is a harder problem than data scarcity. The training and evaluation code is available at .},
booktitle = {Pattern Recognition: 42nd DAGM German Conference, DAGM GCPR 2020, T\"{u}bingen, Germany, September 28 – October 1, 2020, Proceedings},
pages = {86–100},
numpages = {15},
location = {T\"{u}bingen, Germany}
}

@article{10.1016/j.neucom.2015.10.042,
author = {Zakaryazad, Ashkan and Duman, Ekrem},
title = {A profit-driven Artificial Neural Network (ANN) with applications to fraud detection and direct marketing},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {175},
number = {PA},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2015.10.042},
doi = {10.1016/j.neucom.2015.10.042},
abstract = {The rapid growth in data capture and computational power has led to an increasing focus on data-driven research. So far, most of the research is focused on predictive modeling using statistical optimization, while profit maximization has been given less priority. It is exactly this gap that will be addressed in this study by taking a profit-driven approach to develop a profit-driven Artificial Neural Network (ANN) classification technique. In order to do this, we have first introduced an ANN model with a new penalty function which gives variable penalties to the misclassification of instances considering their individual importance (profit of correctly classification and/or cost of misclassification) and then we have considered maximizing the total net profit. In order to generate individual penalties, we have modified the sum of squared errors (SSE) function by changing its values with respect to profit of each instance. We have implemented different versions of ANN of which five of them are new ones contributed in this study and two benchmarks from relevant literature. We appraise the effectiveness of the proposed models on two real-life data sets from fraud detection and a University of California Irvine (UCI) repository data set about bank direct marketing. For the comparison, we have considered both statistical and profit-driven performance metrics. Empirical results revealed that, although in most cases the statistical performance of new models are not better than previous ones, they turn out to be better when profit is the concern.},
journal = {Neurocomput.},
month = jan,
pages = {121–131},
numpages = {11},
keywords = {Sum of squared errors (SSE), Profit-driven neural network, Neural network, Individual profit and cost}
}

@article{10.1016/j.eswa.2011.09.029,
author = {Timm, Fabian and Barth, Erhardt},
title = {Novelty detection for the inspection of light-emitting diodes},
year = {2012},
issue_date = {February, 2012},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {39},
number = {3},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2011.09.029},
doi = {10.1016/j.eswa.2011.09.029},
abstract = {We propose novel feature-extraction and classification methods for the automatic visual inspection of manufactured LEDs. The defects are located at the area of the p-electrodes and lead to a malfunction of the LED. Besides the complexity of the defects, low contrast and strong image noise make this problem very challenging.For the extraction of image characteristic we compute radially-encoded features that measure discontinuities along the p-electrode. Therefore, we propose two different methods: the first method divides the object into several radial segments for which mean and standard deviation are computed and the second method computes mean and standard deviation along different orientations. For both methods we combine the features over several segments or orientations by computing simple measures such as the ratio between maximum and mean or standard deviation.Since defect-free LEDs are frequent and defective LEDs are rare, we apply and evaluate different novelty-detection methods for classification. Therefore, we use a kernel density estimator, kernel principal component analysis, and a one-class support vector machine. We further compare our results to Pearson's correlation coefficient, which is evaluated using an artificial reference image.The combination of one-class support vector machine and radially-encoded segment features yields the best overall performance by far, with a false alarm rate of only 0.13% at a 100% defect detection rate, which means that every defect is detected and only very few defect-free p-electrodes are rejected.Our inspection system does not only show superior performance, but is also computationally efficient and can therefore be applied to further real-time applications, for example solder joint inspection. Moreover, we believe that novelty detection as used here can be applied to various expert-system applications.},
journal = {Expert Syst. Appl.},
month = feb,
pages = {3413–3422},
numpages = {10},
keywords = {One-class SVM, Novelty detection, Light emitting diodes, Kernel density estimation, Kernel PCA, Feature extraction, Defect detection}
}

@inproceedings{10.1109/ITSC.2019.8917062,
author = {Pahwa, Ramanpreet Singh and Chandrasekhar, Vijay Ramaseshan and Chao, Jin and Paul, Jestine and Li, Yiqun and Lay Nwe, Ma Tin and Xie, Shudong and James, Ashish and Ambikapathi, Arulmurugan and Zeng, Zeng},
title = {FaultNet: Faulty Rail-Valves Detection using Deep Learning and Computer Vision},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC.2019.8917062},
doi = {10.1109/ITSC.2019.8917062},
abstract = {Regular inspection of rail valves and engines is an important task to ensure safety and efficiency of railway networks around the globe. Over the past decade, computer vision and pattern recognition based techniques have gained traction for such inspection and defect detection tasks. An automated end-to-end trained system can potentially provide a low-cost, high throughput, and cheap alternative to manual visual inspection of these components. However, such systems require huge amount of defective images for networks to understand complex defects. In this paper, a multi-phase deep learning based technique is proposed to perform accurate fault detection of rail-valves. Our approach uses a two-step method to perform high precision image segmentation of rail-valves resulting in pixel-wise accurate segmentation. Thereafter, a computer vision technique is used to identify faulty valves. We demonstrate that the proposed approach results in improved detection performance when compared to current state-of-the-art techniques used in fault detection.},
booktitle = {2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
pages = {559–566},
numpages = {8},
location = {Auckland, New Zealand}
}

@article{10.1016/j.compag.2021.106451,
author = {Dolata, Przemys\l{}aw and Wr\'{o}blewski, Pawe\l{} and Mrzyg\l{}\'{o}d, Mariusz and Reiner, Jacek},
title = {Instance segmentation of root crops and simulation-based learning to estimate their physical dimensions for on-line machine vision yield monitoring},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {190},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2021.106451},
doi = {10.1016/j.compag.2021.106451},
journal = {Comput. Electron. Agric.},
month = nov,
numpages = {12},
keywords = {Synthetic dataset, Image segmentation, Machine learning, Machine vision, Yield estimation}
}

@article{10.1016/j.micpro.2019.102971,
author = {Subha Seethalakshmi, V. and Karthigaivel, R. and Vengadachalam, N. and Selvakumaran, S.},
title = {RETRACTED: Application of Machine Learning and Big Data in Doubly Fed Induction Generator based Stability Analysis of Multi Machine System using Substantial Transformative Optimization Algorithm},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {73},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2019.102971},
doi = {10.1016/j.micpro.2019.102971},
journal = {Microprocess. Microsyst.},
month = mar,
numpages = {13}
}

@article{10.1155/2021/6662932,
author = {Gupta, Mansi and Rajnish, Kumar and Bhattacharjee, Vandana and Gou, Jianping},
title = {Impact of Parameter Tuning for Optimizing Deep Neural Network Models for Predicting Software Faults},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/6662932},
doi = {10.1155/2021/6662932},
abstract = {Deep neural network models built by the appropriate design decisions are crucial to obtain the desired classifier performance. This is especially desired when predicting fault proneness of software modules. When correctly identified, this could help in reducing the testing cost by directing the efforts more towards the modules identified to be fault prone. To be able to build an efficient deep neural network model, it is important that the parameters such as number of hidden layers, number of nodes in each layer, and training details such as learning rate and regularization methods be investigated in detail. The objective of this paper is to show the importance of hyperparameter tuning in developing efficient deep neural network models for predicting fault proneness of software modules and to compare the results with other machine learning algorithms. It is shown that the proposed model outperforms the other algorithms in most cases.},
journal = {Sci. Program.},
month = jan,
numpages = {17}
}

@article{10.1016/j.aei.2018.05.004,
author = {H\"{u}thwohl, Philipp and Brilakis, Ioannis},
title = {Detecting healthy concrete surfaces},
year = {2018},
issue_date = {Aug 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {37},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2018.05.004},
doi = {10.1016/j.aei.2018.05.004},
journal = {Adv. Eng. Inform.},
month = aug,
pages = {150–162},
numpages = {13},
keywords = {Healthy concrete, Automated bridge inspection, Defect detection, Bridge inspection}
}

@inproceedings{10.1145/1774088.1774612,
author = {Sami, Ashkan and Fakhrahmad, Seyed Mostafa},
title = {Design-level metrics estimation based on code metrics},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774612},
doi = {10.1145/1774088.1774612},
abstract = {Fault detection based on mining code and design metrics has been an active research area for many years. Basically "module"-based metrics for source code and design level are calculated or obtained and data mining is used to build predictor models. However, in many projects due to organizational or software process models, design level metrics are not available and/or accurate. It has been shown that performance of these classifiers or predictors decline if only source code features are used for training them. Based on best of our know knowledge no set of rule to estimate design level metrics based on code level metrics has been presented since it is believed that design level metrics have additional information and cannot be estimated without access to design artifacts. In this study we present a fuzzy modeling system to find and present these relationships for projects presented in NASA Metrics Data Repository (MDP) datasets. Interestingly, we could find a set of empirical rules that govern all the projects regardless of size, programming language and software development methodology. Comparison of fault detectors built based on estimated design metrics with actual design metrics on various projects showed a very small difference in accuracy of classifiers and validated our hypothesis that estimation of design metrics based on source code attributes can become a practical exercise.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {2531–2535},
numpages = {5},
keywords = {software metrics, software defect prediction, parameter estimation, fuzzy classification, approximate dependencies},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@article{10.1016/j.neucom.2016.03.038,
author = {Wang, Yongxiong and Li, Xuan and Ding, Xueming},
title = {Probabilistic framework of visual anomaly detection for unbalanced data},
year = {2016},
issue_date = {August 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {201},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2016.03.038},
doi = {10.1016/j.neucom.2016.03.038},
abstract = {This paper proposes a novel probabilistic detection framework of weighted combining semi-supervised k-means clustering and Posterior Probability SVM (PPSVM) for unbalanced data based on robot vision. Within the framework, an algorithm for learning synchronously the k in k-means and features is introduced based on hybrid wrapper and filter criterion. Then the optimal hierarchical probabilistic model by combining k-means and PPSVM is used to anomaly detection so as to alleviate the problems of imbalanced data with small samples, improve the detection accuracy, and deal with the difficult problem of defining the anomaly classes. The other contributions of our approach include the following three aspects: (1) it classifies anomaly candidates by using their class probability distributions rather than the direct extracted features; (2) the relevant classes are automatically built by learning the samples' multimodal Gaussian distribution; and (3) the cost-sensitive idea and filter criterion are integrated in learning k and features via cost function of Tabu search. Experimental results on real-world data sets show the proposed approach obtains a satisfactory detection performance within limited time in inspecting the condition of Heating, and Ventilation and Air-Conditioning (HVAC) ductwork. A probabilistic framework of semi-supervised k-means and Posterior Probability SVM.Integrate the cost-sensitive idea and filter criterion via Tabu search synchronously.Alleviate the problem of imbalanced data with small samples.Built the classes automatically by learning samples' multimodal Gaussian distribution.},
journal = {Neurocomput.},
month = aug,
pages = {12–18},
numpages = {7},
keywords = {Unbalance distribution, Posterior probability, Parameter learning, Anomaly detection}
}

@article{10.1016/j.neucom.2020.01.120,
author = {Malhotra, Ruchika and Lata, Kusum},
title = {An empirical study to investigate the impact of data resampling techniques on the performance of class maintainability prediction models},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {459},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2020.01.120},
doi = {10.1016/j.neucom.2020.01.120},
journal = {Neurocomput.},
month = oct,
pages = {432–453},
numpages = {22},
keywords = {Object-oriented metrics, Search-based techniques, Machine learning techniques, Data resampling techniques, Imbalanced data, Maintainability prediction}
}

@article{10.1007/s11704-017-6015-y,
author = {Zhang, Yun and Lo, David and Xia, Xin and Sun, Jianling},
title = {Combined classifier for cross-project defect prediction: an extended empirical study},
year = {2018},
issue_date = {April     2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {12},
number = {2},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-017-6015-y},
doi = {10.1007/s11704-017-6015-y},
abstract = {To facilitate developers in effective allocation of their testing and debugging efforts, many software defect prediction techniques have been proposed in the literature. These techniques can be used to predict classes that are more likely to be buggy based on the past history of classes, methods, or certain other code elements. These techniques are effective provided that a sufficient amount of data is available to train a prediction model. However, sufficient training data are rarely available for new software projects. To resolve this problem, cross-project defect prediction, which transfers a prediction model trained using data from one project to another, was proposed and is regarded as a new challenge in the area of defect prediction. Thus far, only a few cross-project defect prediction techniques have been proposed. To advance the state of the art, in this study, we investigated seven composite algorithms that integrate multiple machine learning classifiers to improve cross-project defect prediction. To evaluate the performance of the composite algorithms, we performed experiments on 10 open-source software systems from the PROMISE repository, which contain a total of 5,305 instances labeled as defective or clean. We compared the composite algorithms with the combined defect predictor where logistic regression is used as the meta classification algorithm (CODEPLogistic), which is the most recent cross-project defect prediction algorithm in terms of two standard evaluation metrics: cost effectiveness and F-measure. Our experimental results show that several algorithms outperform CODEPLogistic: Maximum voting shows the best performance in terms of F-measure and its average F-measure is superior to that of CODEPLogistic by 36.88%. Bootstrap aggregation (BaggingJ48) shows the best performance in terms of cost effectiveness and its average cost effectiveness is superior to that of CODEPLogistic by 15.34%.},
journal = {Front. Comput. Sci.},
month = apr,
pages = {280–296},
numpages = {17},
keywords = {defect prediction, cross-project, classifier combination}
}

@article{10.1016/j.cageo.2019.104357,
author = {Saikia, Pallabi and Baruah, Rashmi Dutta and Singh, Sanjay Kumar and Chaudhuri, Pradip Kumar},
title = {Artificial Neural Networks in the domain of reservoir characterization: A review from shallow to deep models},
year = {2020},
issue_date = {Feb 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {135},
number = {C},
issn = {0098-3004},
url = {https://doi.org/10.1016/j.cageo.2019.104357},
doi = {10.1016/j.cageo.2019.104357},
journal = {Comput. Geosci.},
month = feb,
numpages = {13},
keywords = {Back propagation, Machine learning, Deep learning, Artificial neural network (ANN), Reservoir modeling, Well log data, Seismic data, Reservoir characterization}
}

@article{10.1007/s10845-018-01462-9,
author = {Stoyanov, Stoyan and Ahsan, Mominul and Bailey, Chris and Wotherspoon, Tracy and Hunt, Craig},
title = {Predictive analytics methodology for smart qualification testing of electronic components},
year = {2019},
issue_date = {Mar 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-018-01462-9},
doi = {10.1007/s10845-018-01462-9},
abstract = {In electronics manufacturing, the required quality of electronic modules (e.g. packaged electronic devices) are evaluated through qualification testing using standards and user-defined requirements. The challenge for the electronics industry is that product qualification testing is time-consuming and costly. This paper focuses on the development and demonstration of a novel approach for smarter qualification using test data from the production line along with integrated computational techniques for data mining/analytics and data-driven forecasting (i.e. prognostics) modelling. The most common type of testing in the electronics industry--sequentially run electrical multi-parameter tests on the Device-under-Test (DUT), is considered. The proposed data mining (DM) framework can identify the tests that have strong correlation to pending failure of the device in the qualification (tests sensitive to pending failure) as well as to evaluate the similarity in test measurements, thus generating knowledge on potentially redundant tests. Mining the data in this context and with the proposed approach represents a major new contribution because it uncovers embedded knowledge and information in the production test data that can enable intelligent optimisation of the tests' sequence and reduce the number of tests. The intelligent manufacturing concept behind the development of data-driven prognostics models using machine learning techniques is to use data only from a small number of tests from the full qualification specification as training data in the process of model construction. This model can then forecast the overall qualification outcome for a DUT--Pass or Fail--without performing all other remaining tests. The novelty in the context of machine learning is in the selection of the data features for the training dataset using results from tests sensitive to pending failure. Support Vector Machine (SVM) binary classifiers SVM models built with data from tests sensitive to the outcome that the module will fail are shown to have superior performance compared with models trained with other datasets of tests. Case studies based on the use of real industrial production test data for an electronic module are included in the paper to demonstrate and validate the computational approach. This work is both novel and original because at present, to the best knowledge of the authors, such predictive analytics methodology applied to qualification testing and providing benefits of test time and hence cost reduction are non-existent in the electronics industry. The integrated data analytics-prognostics approach, deployable for both off-line and in-line optimisation of production test procedures, has the potential to transform current practices by exploiting in a smarter way information and knowledge available with large datasets of qualification test data.},
journal = {J. Intell. Manuf.},
month = mar,
pages = {1497–1514},
numpages = {18},
keywords = {Smart qualification testing, Prognostics modelling, Machine learning, Intelligent manufacturing, Electronic components, Data mining}
}

@article{10.1016/j.procs.2018.07.216,
author = {Miholca, Diana-Lucia and Czibula, Gabriela and Crivei, Liana Maria},
title = {A new incremental relational association rules mining approach},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {126},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.07.216},
doi = {10.1016/j.procs.2018.07.216},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {126–135},
numpages = {10},
keywords = {68P15, 68T05, Relational association rules 2000 MSC: 6207, Unsupervised learning, Data mining}
}

@article{10.1016/j.neucom.2019.01.080,
author = {Wang, Shuo and Minku, Leandro L. and Chawla, Nitesh and Yao, Xin},
title = {Learning in the presence of class imbalance and concept drift},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {343},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.01.080},
doi = {10.1016/j.neucom.2019.01.080},
journal = {Neurocomput.},
month = may,
pages = {1–2},
numpages = {2}
}

@article{10.1016/j.micpro.2020.103090,
author = {Dhakshina Kumar, S. and Esakkirajan, S. and Bama, S. and Keerthiveena, B.},
title = {A microcontroller based machine vision approach for tomato grading and sorting using SVM classifier},
year = {2020},
issue_date = {Jul 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {76},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2020.103090},
doi = {10.1016/j.micpro.2020.103090},
journal = {Microprocess. Microsyst.},
month = jul,
numpages = {13},
keywords = {Tomato, Ripeness, Diseases detection, Gabor wavelet transforms, SVM, Microcontroller}
}

@inproceedings{10.5555/2040660.2040688,
author = {Wahyudin, Dindin and Ramler, Rudolf and Biffl, Stefan},
title = {A framework for defect prediction in specific software project contexts},
year = {2008},
isbn = {9783642223853},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software defect prediction has drawn the attention of many researchers in empirical software engineering and software maintenance due to its importance in providing quality estimates and to identify the needs for improvement from project management perspective. However, most defect prediction studies seem valid primarily in a particular context and little concern is given on how to find out which prediction model is well suited for a given project context. In this paper we present a framework for conducting software defect prediction as aid for the project manager in the context of a particular project or organization. The framework has been aligned with practitioners' requirements and is supported by our findings from a systematical literature review on software defect prediction. We provide a guide to the body of existing studies on defect prediction by mapping the results of the systematic literature review to the framework.},
booktitle = {Proceedings of the Third IFIP TC 2 Central and East European Conference on Software Engineering Techniques},
pages = {261–274},
numpages = {14},
keywords = {systematical literature review, software defect prediction, metric-based defect prediction},
location = {Brno, Czech Republic},
series = {CEE-SET'08}
}

@inproceedings{10.5555/3437539.3437674,
author = {Alawieh, Mohamed Baker and Boning, Duane and Pan, David Z.},
title = {Wafer map defect patterns classification using deep selective learning},
year = {2020},
isbn = {9781450367257},
publisher = {IEEE Press},
abstract = {With the continuous drive toward integrated circuits scaling, efficient yield analysis is becoming more crucial yet more challenging. In this paper, we propose a novel methodology for wafer map defect pattern classification using deep selective learning. Our proposed approach features an integrated reject option where the model chooses to abstain from predicting a class label when misclassification risk is high. Thus, providing a trade-off between prediction coverage and misclassification risk. This selective learning scheme allows for new defect class detection, concept shift detection, and resource allocation. Besides, and to address the class imbalance problem in the wafer map classification, we propose a data augmentation framework built around a convolutional auto-encoder model for synthetic sample generation. The efficacy of our proposed approach is demonstrated on the WM-811k industrial dataset where it achieves 94% accuracy under full coverage and 99% with selective learning while successfully detecting new defect types.},
booktitle = {Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference},
articleno = {135},
numpages = {6},
location = {Virtual Event, USA},
series = {DAC '20}
}

@inproceedings{10.1145/3102254.3102275,
author = {Ardimento, Pasquale and Dinapoli, Andrea},
title = {Knowledge extraction from on-line open source bug tracking systems to predict bug-fixing time},
year = {2017},
isbn = {9781450352253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3102254.3102275},
doi = {10.1145/3102254.3102275},
abstract = {1For large scale software systems, many bugs can be reported over a long period of time. For software quality assurance and software project management, it is important to assign adequate resources to resolve the reported bug. An important issue concerning assignment is the ability to predict bug-fixing time because it can help a project team better estimate software maintenance efforts and better manage software projects. In this paper, we propose a model that can predict the bug-fixing time using the text information extracted from Bugzilla, an on-line open source Bug Tracking System (BTS). We perform an empirical investigation for the bugs of Novell, OpenOffice and LiveCode, three open source projects using Bugzilla. Proposed model is based on historical data stored on the BTS. For each bug-report we build a classification model to predict the time of its resolution, as slow or fast. In this work we used, as classifier, Support Vector Machine (SVM) but different classifier can be easily used. Our model, differently from existing work reported in the literature, selects all and only the attributes useful for prediction and filters appropriately attributes for the test-set. Experimental results show the model is effective. In the future, we will use and compare other different classification method to select the best one for a specific data-set.},
booktitle = {Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics},
articleno = {7},
numpages = {9},
keywords = {text categorization, support vector machine (SVM), supervised learning, bug-fix time prediction, bug triage},
location = {Amantea, Italy},
series = {WIMS '17}
}

@article{10.1016/j.asoc.2015.03.053,
author = {Godoy, Wagner Fontes and da Silva, Ivan Nunes and Goedtel, Alessandro and Cunha Pal\'{a}cios, Rodrigo Henrique},
title = {Evaluation of stator winding faults severity in inverter-fed induction motors},
year = {2015},
issue_date = {July 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {32},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.03.053},
doi = {10.1016/j.asoc.2015.03.053},
abstract = {Graphical abstractDisplay Omitted HighlightsPresent a comprehensive evaluation of intelligent classifiers to identify stator faults in inverter-fed induction motors are presented.Proposed methodology uses the current signal in time domain as the inputs of the pattern classifiers for fault diagnosis.Experimental results with different inverters, operating frequencies and mechanical loads are presented.Three different intelligent methods are presented and compared for multiple faults under dynamic sampling rate. Three-phase induction motor are one of the most important elements of electromechanical energy conversion in the production process. However, they are subject to inherent faults or failures under operating conditions. The purpose of this paper is to present a comparative study among intelligent tools to classify short-circuit faults in stator windings of induction motors operating with three different models of frequency inverters. This is performed by analyzing the amplitude of the stator current signal in the time domain, using a dynamic acquisition rate according to machine frequency supply. To assess the classification accuracy across the various levels of faults severity, the performance of three different learning machine techniques were compared: (i) fuzzy ARTMAP network; (ii) multilayer perceptron network; and (iii) support vector machine. Results obtained from 2.268 experimental tests are presented to validate the study, which considered a wide range of operating frequencies and load conditions.},
journal = {Appl. Soft Comput.},
month = jul,
pages = {420–431},
numpages = {12},
keywords = {Three-phase induction motor, Stator faults, Intelligent systems, Fault prediction}
}

@article{10.1007/s10586-019-03029-6,
author = {Yogesh and Dubey, Ashwani Kumar and Ratan, Rajeev and Rocha, Alvaro},
title = {Computer vision based analysis and detection of defects in fruits causes due to nutrients deficiency},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {3},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-019-03029-6},
doi = {10.1007/s10586-019-03029-6},
abstract = {Presently, the fruit industry requires a fast and efficient method for classification and recognition of the quality of fruits in bulk processing. Fruit recognition based on computer vision is quite challenging as it is based on the intensity, size, contour, and texture features extraction from fruits along with their suitable classifier selection. In this paper, the pixels containing the defected regions are segmented and their features are extracted. Further, a support vector machine (SVM) classifier is used to identify the defects and recognizes the cause with its stage. During the process of classification, fruits are categorized into two groups, defected and no-defect. The sample image observed defected further classified into three categories as the first, second and final stage of fruit defect. The sample testing at an early stage helps one to further proceed with the production or halt based on the outcome of a computer vision-based recognition system.},
journal = {Cluster Computing},
month = sep,
pages = {1817–1826},
numpages = {10},
keywords = {Segmentation, Recognition, Image processing, Fruits classification, Computer vision}
}

@article{10.1016/j.knosys.2021.107541,
author = {Pandey, Sushant Kumar and Tripathi, Anil Kumar},
title = {DNNAttention: A deep neural network and attention based architecture for cross project defect number prediction},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {233},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107541},
doi = {10.1016/j.knosys.2021.107541},
journal = {Know.-Based Syst.},
month = dec,
numpages = {30},
keywords = {Software defect number prediction, Long short term memory (LSTM), Attention layer, Deep neural network, Cross project defect prediction}
}

@article{10.1016/j.compind.2019.02.015,
author = {Yu, Jianbo},
title = {A selective deep stacked denoising autoencoders ensemble with negative correlation learning for gearbox fault diagnosis},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {108},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2019.02.015},
doi = {10.1016/j.compind.2019.02.015},
journal = {Comput. Ind.},
month = jun,
pages = {62–72},
numpages = {11},
keywords = {Negative correlation learning, Stacked denoising autoencoder, Selective ensemble learning, Deep learning, Gearbox fault diagnosis}
}

@inproceedings{10.1145/2491627.2491629,
author = {Clements, Paul and Krueger, Charles and Shepherd, James and Winkler, Andrew},
title = {A PLE-based auditing method for protecting restricted content in derived products},
year = {2013},
isbn = {9781450319683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491627.2491629},
doi = {10.1145/2491627.2491629},
abstract = {Many organizations that produce a portfolio of products for different customers need to ensure that sensitive or restricted content that may appear in some products must not appear in others. Examples of this need include complying with statutes in different countries of sale, protection of intellectual property developed specifically for one customer, and more. For organizations operating under these requirements and producing their products under a product line engineering paradigm that relies on automation in product derivation, there is a need for a method to ensure that the content restrictions have been met in the derived products. This paper describes an auditing method that meets this need. It was created for use in the Second Generation Product Line Engineering approach that is being applied by Lockheed Martin in their AEGIS ship combat system product line.},
booktitle = {Proceedings of the 17th International Software Product Line Conference},
pages = {218–226},
numpages = {9},
keywords = {variation points, software product lines, second generation product line engineering, product portfolio, product line engineering, product derivation, product configurator, product baselines, product audit, hierarchical product lines, feature profiles, feature modeling, bill-of-features},
location = {Tokyo, Japan},
series = {SPLC '13}
}

@article{10.1016/j.neucom.2019.06.072,
author = {Xu, Wei and Liu, Wei and Chi, Haoyuan and Qiu, Song and Jin, Yu},
title = {Self-paced learning with privileged information},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {362},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.06.072},
doi = {10.1016/j.neucom.2019.06.072},
journal = {Neurocomput.},
month = oct,
pages = {147–155},
numpages = {9},
keywords = {Learning with privileged information, Self-paced learning, Curriculum learning}
}

@article{10.1016/j.knosys.2021.107306,
author = {Zhou, Hao and Dong, Xianyong and Xia, Shuyin and Wang, Guoyin},
title = {Weighted oversampling algorithms for imbalanced problems and application in prediction of streamflow▪},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {229},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107306},
doi = {10.1016/j.knosys.2021.107306},
journal = {Know.-Based Syst.},
month = oct,
numpages = {13},
keywords = {Label noise, W-SMOTEs, Weight, Interpolation location, Oversampling}
}

@inproceedings{10.1109/COMPSAC.2015.143,
author = {Mori, Keita and Mizuno, Osamu},
title = {An Implementation of Just-in-Time Fault-Prone Prediction Technique Using Text Classifier},
year = {2015},
isbn = {9781467365642},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2015.143},
doi = {10.1109/COMPSAC.2015.143},
abstract = {Since the fault prediction is an important technique to help allocating software maintenance effort, much research on fault prediction has been proposed so far. The goal of these studies is applying their prediction technique to actual software development. In this paper, we implemented a prototype fault-prone module prediction tool using a text-filtering based technique named "Fault-Prone Filtering". Our tool aims to show the result of fault prediction for each change (i.e., Commits) as a probability that a source code file to be faulty. The result is shown on a Web page and easy to track the histories of prediction. A case study performed on three open source projects shows that our tool could detect 90 percent of the actual fault modules (i.e., The recall of 0.9) with the accuracy of 0.67 and the precision of 0.63 on average.},
booktitle = {Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 03},
pages = {609–612},
numpages = {4},
keywords = {spam filter, software maintenance, software development support tool, mining software repository, machine learning, fault prediction},
series = {COMPSAC '15}
}

@article{10.1007/s10845-019-01502-y,
author = {Kim, Myeongso and Lee, Minyoung and An, Minjeong and Lee, Hongchul},
title = {Effective automatic defect classification process based on CNN with stacking ensemble model for TFT-LCD panel},
year = {2020},
issue_date = {Jun 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {31},
number = {5},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-019-01502-y},
doi = {10.1007/s10845-019-01502-y},
abstract = {The classification of defect types during LCD panel production is very important because it is closely related to deciding whether a defect panel is restorable. But since defect areas are very small compared to the panel area, it is hard to classify defect types by images. Therefore, we need to eliminate the background pattern of the panel, but this is not an easy task because the brightness and saturation of the background varies, even in a single image. In this paper, we propose an indicator that can distinguish between defect and background area, which is robust to brightness change and minor noises. With this indicator, we got useful defect information and images with patterns eliminated to make a more efficient defect classifier. The convolutional neural network with stacked ensemble techniques played a great role in improving defect classification performance, when various information from image preprocessing was combined.},
journal = {J. Intell. Manuf.},
month = jun,
pages = {1165–1174},
numpages = {10},
keywords = {Pattern elimination, Convolutional neural network, Defect classification}
}

@article{10.1016/j.patcog.2021.108135,
author = {Aversano, Lerina and Bernardi, Mario Luca and Cimitile, Marta and Pecori, Riccardo},
title = {Deep neural networks ensemble to detect COVID-19 from CT scans},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {120},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2021.108135},
doi = {10.1016/j.patcog.2021.108135},
journal = {Pattern Recogn.},
month = dec,
numpages = {15},
keywords = {Coronavirus, COVID-19, CT Scan images, Deep learning}
}

@inproceedings{10.1145/3377813.3381356,
author = {Zhang, Xindong and Zhu, Chenguang and Li, Yi and Guo, Jianmei and Liu, Lihua and Gu, Haobo},
title = {Precfix: large-scale patch recommendation by mining defect-patch pairs},
year = {2020},
isbn = {9781450371230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377813.3381356},
doi = {10.1145/3377813.3381356},
abstract = {Patch recommendation is the process of identifying errors in software systems and suggesting suitable fixes for them. Patch recommendation can significantly improve developer productivity by reducing both the debugging and repairing time. Existing techniques usually rely on complete test suites and detailed debugging reports, which are often absent in practical industrial settings. In this paper, we propose Precfix, a pragmatic approach targeting large-scale industrial codebase and making recommendations based on previously observed debugging activities. Precfix collects defect-patch pairs from development histories, performs clustering, and extracts generic reusable patching patterns as recommendations. We conducted experimental study on an industrial codebase with 10K projects involving diverse defect patterns. We managed to extract 3K templates of defect-patch pairs, which have been successfully applied to the entire codebase. Our approach is able to make recommendations within milliseconds and achieves a false positive rate of 22% confirmed by manual review. The majority (10/12) of the interviewed developers appreciated Precfix, which has been rolled out to Alibaba to support various critical businesses.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice},
pages = {41–50},
numpages = {10},
keywords = {patch recommendation, patch generation, defect detection},
location = {Seoul, South Korea},
series = {ICSE-SEIP '20}
}

@article{10.1002/smr.1639,
author = {Cavalcanti, Yguarat\~{a} Cerqueira and Mota Silveira Neto, Paulo Anselmo and Machado, Ivan do Carmo and Vale, Tassio Ferreira and Almeida, Eduardo Santana and Meira, Silvio Romero de Lemos},
title = {Challenges and opportunities for software change request repositories: a systematic mapping study},
year = {2014},
issue_date = {July 2014},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {26},
number = {7},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.1639},
doi = {10.1002/smr.1639},
abstract = {Software maintenance starts as soon as the first artifacts are delivered and is essential for the success of the software. However, keeping maintenance activities and their related artifacts on track comes at a high cost. In this respect, change request CR repositories are fundamental in software maintenance. They facilitate the management of CRs and are also the central point to coordinate activities and communication among stakeholders. However, the benefits of CR repositories do not come without issues, and commonly occurring ones should be dealt with, such as the following: duplicate CRs, the large number of CRs to assign, or poorly described CRs. Such issues have led researchers to an increased interest in investigating CR repositories, by considering different aspects of software development and CR management. In this paper, we performed a systematic mapping study to characterize this research field. We analyzed 142 studies, which we classified in two ways. First, we classified the studies into different topics and grouped them into two dimensions: challenges and opportunities. Second, the challenge topics were classified in accordance with an existing taxonomy for information retrieval models. In addition, we investigated tools and services for CR management, to understand whether and how they addressed the topics identified. Copyright © 2013 John Wiley &amp; Sons, Ltd.},
journal = {J. Softw. Evol. Process},
month = jul,
pages = {620–653},
numpages = {34},
keywords = {software quality assurance, software maintenance, software evolution, change request repository, bug tracking, bug report}
}

@article{10.1016/j.eswa.2021.115428,
author = {Briones-Segovia, V\'{\i}ctor A. and Jim\'{e}nez-Villar, V\'{\i}ctor and Carrasco-Ochoa, Jes\'{u}s Ariel and Mart\'{\i}nez-Trinidad, Jos\'{e} Fco.},
title = {A new oversampling method in the string space},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {183},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115428},
doi = {10.1016/j.eswa.2021.115428},
journal = {Expert Syst. Appl.},
month = nov,
numpages = {7},
keywords = {SMOTE, Edit distance, String space, Oversampling}
}

@article{10.1007/s10115-021-01577-1,
author = {Pascual-Triana, Jos\'{e} Daniel and Charte, David and Andr\'{e}s&nbsp;Arroyo, Marta and Fern\'{a}ndez, Alberto and Herrera, Francisco},
title = {Revisiting data complexity metrics based on morphology for overlap and imbalance: snapshot, new overlap number of balls metrics and singular problems prospect},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {63},
number = {7},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-021-01577-1},
doi = {10.1007/s10115-021-01577-1},
abstract = {Data Science and Machine Learning have become fundamental assets for companies and research institutions alike. As one of its fields, supervised classification allows for class prediction of new samples, learning from given training data. However, some properties can cause datasets to be problematic to classify. In order to evaluate a dataset a priori, data complexity metrics have been used extensively. They provide information regarding different intrinsic characteristics of the data, which serve to evaluate classifier compatibility and a course of action that improves performance. However, most complexity metrics focus on just one characteristic of the data, which can be insufficient to properly evaluate the dataset towards the classifiers’ performance. In fact, class overlap, a very detrimental feature for the classification process (especially when imbalance among class labels is also present) is hard to assess. This research work focuses on revisiting complexity metrics based on data morphology. In accordance to their nature, the premise is that they provide both good estimates for class overlap, and great correlations with the classification performance. For that purpose, a novel family of metrics has been developed. Being based on ball coverage by classes, they are named after Overlap Number of Balls. Finally, some prospects for the adaptation of the former family of metrics to singular (more complex) problems are discussed.},
journal = {Knowl. Inf. Syst.},
month = jul,
pages = {1961–1989},
numpages = {29},
keywords = {Singular problems, Imbalanced classification, Morphology, Overlap, Data complexity metrics}
}

@inproceedings{10.1007/978-3-030-90436-4_7,
author = {Kocaman, Veysel and Shir, Ofer M. and B\"{a}ck, Thomas},
title = {The Unreasonable Effectiveness of the Final Batch Normalization Layer},
year = {2021},
isbn = {978-3-030-90435-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90436-4_7},
doi = {10.1007/978-3-030-90436-4_7},
abstract = {Early-stage disease indications are rarely recorded in real-world domains, such as Agriculture and Healthcare, and yet, their accurate identification is critical in that point of time. In this type of highly imbalanced classification problems, which encompass complex features, deep learning (DL) is much needed because of its strong detection capabilities. At the same time, DL is observed in practice to favor majority over minority classes and consequently suffer from inaccurate detection of the targeted early-stage indications. In this work, we extend the study done by &nbsp;[11], showing that the final BN layer, when placed before the softmax output layer, has a considerable impact in highly imbalanced image classification problems as well as undermines the role of the softmax outputs as an uncertainty measure. This current study addresses additional hypotheses and reports on the following findings: (i) the performance gain after adding the final BN layer in highly imbalanced settings could still be achieved after removing this additional BN layer in inference; (ii) there is a certain threshold for the imbalance ratio upon which the progress gained by the final BN layer reaches its peak; (iii) the batch size also plays a role and affects the outcome of the final BN application; (iv) the impact of the BN application is also reproducible on other datasets and when utilizing much simpler neural architectures; (v) the reported BN effect occurs only per a single majority class and multiple minority classes – i.e., no improvements are evident when there are two majority classes; and finally, (vi) utilizing this BN layer with sigmoid activation has almost no impact when dealing with a strongly imbalanced image classification tasks.},
booktitle = {Advances in Visual Computing: 16th International Symposium, ISVC 2021, Virtual Event, October 4-6, 2021, Proceedings, Part II},
pages = {81–93},
numpages = {13}
}

@inproceedings{10.1109/SIBGRAPI.2010.54,
author = {Amorim, Willian Paraguassu and Pistori, Hemerson and Pereira, Mauro Conti and Jacinto, Manuel Antonio Chagas},
title = {Attributes Reduction Applied to Leather Defects Classification},
year = {2010},
isbn = {9780769542300},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SIBGRAPI.2010.54},
doi = {10.1109/SIBGRAPI.2010.54},
abstract = {This paper presents a study on attributes reduction, comparing five discriminant analysis techniques: FisherFace, CLDA, DLDA, YLDA and KLDA. Attributes reduction has been applied to the problem of leather defect classification using four different classifiers: C4.5, kNN, Na"{i}ve Bayes and Support Vector Machines. The results of several experiments on the performance of discriminant analysis applied to the problem of defect detection are reported.},
booktitle = {Proceedings of the 2010 23rd SIBGRAPI Conference on Graphics, Patterns and Images},
pages = {353–359},
numpages = {7},
keywords = {linear discriminant analysis, leather defect detection, attributes reduction},
series = {SIBGRAPI '10}
}

@inproceedings{10.1109/IDAACS.2019.8924337,
author = {Augustaukas, Rytis and Lipnickas, Ar\={u}nas},
title = {Pixel-wise Road Pavement Defects Detection Using U-Net Deep Neural Network},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IDAACS.2019.8924337},
doi = {10.1109/IDAACS.2019.8924337},
abstract = {Textured surface defects detection can be a complicated task. Maintenance and monitoring of big infrastructures, such as roads, is expensive, time-consuming, and requires many human resources. In many areas, humans are being replaced by computer vision systems that perform faster and more precise. Moreover, some inspection tasks can reach incredibly high levels of complexity. Recently, deep learning approaches showed impressive results in object detection and image segmentation. It can provide a state-of-the-art solution for most computer vision tasks, including pattern inspection and defect detection. In this work, we present a pixel-wise road pavement defects detection method by using U-Net convolutional neural network. We have experimentally evaluated the impact of a different number of layers, filter sizes and the number of features in segmentation performance and processing time. The best-suggested configuration for road pavement cracks segmentation task has received up to 98.92% of accuracy in 0.049 s per image.},
booktitle = {2019 10th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)},
pages = {468–471},
numpages = {4},
location = {Metz, France}
}

@inproceedings{10.1007/978-3-030-91452-3_12,
author = {Amasaki, Sousuke and Aman, Hirohisa and Yokogawa, Tomoyuki},
title = {Searching for Bellwether Developers for Cross-Personalized Defect Prediction},
year = {2021},
isbn = {978-3-030-91451-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91452-3_12},
doi = {10.1007/978-3-030-91452-3_12},
abstract = {Context: Recent progress in the use of commit data for software defect prediction has driven research on personalized defect prediction. An idea applying one personalized model to another developer came in for seeking an alternative model predicting better than one’s own model. A question arose whether such exemplary developer (bellwether) existed as observed in traditional defect prediction. Objective: To investigate whether bellwether developers existed and how they behaved. Method: Experiments were conducted on 9 OSS projects. Models based on active developers in a project were compared with each other to seek bellwethers, whose models beaten models of the other active developers. Their performance was evaluated with new unseen data from the other active developers and the remaining non-active developers. Results: Bellwether developers were identified in all nine projects. Their performance on new unseen data from the other active developers was not higher than models learned by those developers. The bellwether was only a practical choice for the non-active developers. Conclusion: Bellwethers were a useful prediction model for the non-active developers but not for the other active developers.},
booktitle = {Product-Focused Software Process Improvement: 22nd International Conference, PROFES 2021, Turin, Italy, November 26, 2021, Proceedings},
pages = {183–198},
numpages = {16},
keywords = {Bellwether effect, Transfer learning, Personalized defect prediction},
location = {Turin, Italy}
}

@article{10.3233/JIFS-210374,
author = {Yue, Xiaofeng and Ma, Guoyuan and Liu, Fuqiuxuan and Gao, Xueliang},
title = {Research on image classification method of strip steel surface defects based on improved Bat algorithm optimized BP neural network},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {41},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-210374},
doi = {10.3233/JIFS-210374},
abstract = {Due to the complexity and variety of textures on Strip steel, it is very difficult to detect defects on rigid surfaces. This paper proposes a metal surface defect classification method based on an improved bat algorithm to optimize BP neural network. First, this paper uses the Local Binary Pattern(LBP) algorithm to extract features from six types of defect images including inclusion, patches, crazing, pitted, rolled-in, and scratches, and build a feature sample library with the extracted feature values. Then, the WG-BA-BP network is used to classify the defect images with different characteristics. The weighted experience factor added by the network can control the flight speed of the bat according to the number of iterations and the change of the fitness function. And the gamma distribution is added in the process of calculating loudness, which enhances the local searchability. The BP network optimized by this method has higher accuracy. Finally, to verify the effectiveness of the method, this article introduces the five evaluation indicators of accuracy, precision, sensitivity, specificity, and F1 value under the multi-class model. To prove that this algorithm is more feasible and effective compared with other swarm intelligence algorithms. The best prediction performance of WG-BA-BP is 0.010905, and the accuracy rate can reach 0.9737.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {1509–1521},
numpages = {13},
keywords = {Gamma distribution, weighted experience factor, Bat Algorithm, BP neural network, Image classification}
}

@inproceedings{10.5555/978-3-030-62463-7_fm,
title = {Front Matter},
year = {2020},
isbn = {978-3-030-62462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part III},
pages = {i–xv},
location = {Guangzhou, China}
}

@article{10.1007/s11042-020-10036-y,
author = {Tan, Aijiao and Zhou, Guoxiong and He, Mingfang},
title = {Surface defect identification of Citrus based on KF-2D-Renyi and ABC-SVM},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {6},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-10036-y},
doi = {10.1007/s11042-020-10036-y},
abstract = {In allusion to the problems of citrus surface defect identification such as blurred edges, unclear images, more interference and difficulty in defect identification, surface defect identification of citrus based on KF-2D-Renyi and ABC-SVM was proposed in this paper. First, the method based on the dark channel prior (DCP) was used to defog the citrus images collected. Then, the firefly algorithm based on Kent chaos was used to optimize two-dimensional Renyi entropy threshold segmentation algorithm (2D-Renyi). The citrus surface defects were segmented, and the image features were extracted. Finally, the image feature vectors were input into the ABC-SVM classifier to determine the citrus defect types. We selected 8 kinds of citrus surface defects to carry on the experiment. In testing the segmentation algorithms, compared with the traditional threshold segmentation algorithms, the KF-2D-Renyi segmentation algorithm has a great improvement. The recognition rates for the defects whose features are obvious such as Sooty mould and Anthracnose could reach 100%. The recognition rates for the defects which are difficult to identify such as Thrips scar, Oleocellosis and Scale injury reached 95.18%, 96.37% and 98.43% respectively. In testing the classification algorithms, compared with the standard SVM classifier, the PSO-SVM classifier and the neural network classifiers, the average recognition rate of the ABC-SVM classifier reached 98.45%. The experimental results show that the method in this paper can effectively detect and classify citrus surface defects.},
journal = {Multimedia Tools Appl.},
month = mar,
pages = {9109–9136},
numpages = {28},
keywords = {Threshold segmentation, Support vector machine, Defect recognition, Citrus classification, Computer vision}
}

@article{10.1016/j.jss.2021.111050,
author = {Myllyaho, Lalli and Raatikainen, Mikko and M\"{a}nnist\"{o}, Tomi and Mikkonen, Tommi and Nurminen, Jukka K.},
title = {Systematic literature review of validation methods for AI systems},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {181},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111050},
doi = {10.1016/j.jss.2021.111050},
journal = {J. Syst. Softw.},
month = nov,
numpages = {22},
keywords = {Systematic literature review, V&amp;V, Testing, Validation, Machine learning, Artificial intelligence}
}

@inproceedings{10.1007/978-3-030-28377-3_50,
author = {Czarnowski, Ireneusz and Jundefineddrzejowicz, Piotr},
title = {An Approach to Imbalanced Data Classification Based on Instance Selection and Over-Sampling},
year = {2019},
isbn = {978-3-030-28376-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-28377-3_50},
doi = {10.1007/978-3-030-28377-3_50},
abstract = {The paper referees to a problem of learning from class-imbalanced data. The class imbalance problem arises when the number of instances from different classes differs substantially. Instance selection aims at deciding which instances from the training set should be retained and used during the learning process. Over-sampling is an approach dedicated to duplicate minority class instances. In the paper, a hybrid approach for the imbalanced data learning using the over-sampling and instance selection techniques is proposed. Instances are selected to reduce the number of instances belonging to the majority class, while the number of instances belonging to the minority class is expanded. The process of instance selection is based on clustering, where the authors’ approach to clustering and instance selection using an agent-based population learning algorithm is applied. As a result a more balanced distribution of instances belonging to different classes is obtained and a dataset size is reduced. The proposed approach is validated experimentally using several benchmark datasets.},
booktitle = {Computational Collective Intelligence: 11th International Conference, ICCCI 2019, Hendaye, France, September 4–6, 2019, Proceedings, Part I},
pages = {601–610},
numpages = {10},
keywords = {Under-sampling, Over-sampling, Imbalanced data, Clustering, Instance selection},
location = {Hendaye, France}
}

@article{10.1007/s10462-018-9667-6,
author = {Fazel Zarandi, Mohammad Hossein and Sadat Asl, Ali Akbar and Sotudian, Shahabeddin and Castillo, Oscar},
title = {A state of the art review of intelligent scheduling},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {1},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-018-9667-6},
doi = {10.1007/s10462-018-9667-6},
abstract = {Intelligent scheduling covers various tools and techniques for successfully and efficiently solving the scheduling problems. In this paper, we provide a survey of intelligent scheduling systems by categorizing them into five major techniques containing fuzzy logic, expert systems, machine learning, stochastic local search optimization algorithms and constraint programming. We also review the application case studies of these techniques.},
journal = {Artif. Intell. Rev.},
month = jan,
pages = {501–593},
numpages = {93},
keywords = {Constraint programming, Stochastic local search optimization algorithms, Machine learning, Expert system, Fuzzy logic, Intelligent scheduling}
}

@inproceedings{10.1145/3475716.3475781,
author = {Croft, Roland and Newlands, Dominic and Chen, Ziyu and Babar, M. Ali},
title = {An Empirical Study of Rule-Based and Learning-Based Approaches for Static Application Security Testing},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475781},
doi = {10.1145/3475716.3475781},
abstract = {Background: Static Application Security Testing (SAST) tools purport to assist developers in detecting security issues in source code. These tools typically use rule-based approaches to scan source code for security vulnerabilities. However, due to the significant shortcomings of these tools (i.e., high false positive rates), learning-based approaches for Software Vulnerability Prediction (SVP) are becoming a popular approach. Aims: Despite the similar objectives of these two approaches, their comparative value is unexplored. We provide an empirical analysis of SAST tools and SVP models, to identify their relative capabilities for source code security analysis. Method: We evaluate the detection and assessment performance of several common SAST tools and SVP models on a variety of vulnerability datasets. We further assess the viability and potential benefits of combining the two approaches. Results: SAST tools and SVP models provide similar detection capabilities, but SVP models exhibit better overall performance for both detection and assessment. Unification of the two approaches is difficult due to lacking synergies. Conclusions: Our study generates 12 main findings which provide insights into the capabilities and synergy of these two approaches. Through these observations we provide recommendations for use and improvement.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {8},
numpages = {12},
keywords = {Static Application Security Testing, Security, Machine Learning},
location = {Bari, Italy},
series = {ESEM '21}
}

@inproceedings{10.1145/2393596.2393619,
author = {Caglayan, Bora and Misirli, Ayse Tosun and Calikli, Gul and Bener, Ayse and Aytac, Turgay and Turhan, Burak},
title = {Dione: an integrated measurement and defect prediction solution},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393596.2393619},
doi = {10.1145/2393596.2393619},
abstract = {We present an integrated measurement and defect prediction tool: Dione. Our tool enables organizations to measure, monitor, and control product quality through learning based defect prediction. Similar existing tools either provide data collection and analytics, or work just as a prediction engine. Therefore, companies need to deal with multiple tools with incompatible interfaces in order to deploy a complete measurement and prediction solution. Dione provides a fully integrated solution where data extraction, defect prediction and reporting steps fit seamlessly. In this paper, we present the major functionality and architectural elements of Dione followed by an overview of our demonstration.},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {20},
numpages = {2},
keywords = {software tool, software defect prediction, measurement},
location = {Cary, North Carolina},
series = {FSE '12}
}

@inproceedings{10.1007/978-3-030-87355-4_18,
author = {Yang, Yanqing and Mao, Jianxu and Zhang, Hui and Chen, Yurong and Zhong, Hang and Huang, Zhihong and Wang, Yaonan},
title = {Semi-supervised Cloud Edge Collaborative Power Transmission Line Insulator Anomaly Detection Framework},
year = {2021},
isbn = {978-3-030-87354-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87355-4_18},
doi = {10.1007/978-3-030-87355-4_18},
abstract = {The widely deployed power transmission line expedites developing the age of electricity. Thus, it is necessary to maintain a power system with a great quantity of manpower and material resources, especially for crucial equipment, such as insulator string. However, the current main inspection method relies on artificial with the problem of time-consuming and labor-intensive. There is a trend of utilizing deep learning techniques on unmanned aerial vehicles (UAVs) to accomplish the inspection task, but its development is restricted by the limitation of energy. In this paper, we propose a semi-supervised cloud edge collaborative insulator string anomaly detection framework. Specifically, an anchor-free object detector is deployed on the edge device for locating the insulator. On the cloud side, we propose a generative insulator defect detection model based on the autoencoder (AE) with a generator-discriminator pattern. Particularly, we introduce the variational memory encoder-decoder architecture to model defect-free insulator data distribution. Furthermore, the adversarial strategy is employed to regularize the generated data space with input data space. In the end, the anomaly can be detected if its data space is an outlier of training defect-free distribution. Comprehensive experiments demonstrate that our method can effectively reduce the computational load, meanwhile archiving superior performance, including accuracy (0.968) and recall (0.985), for defect recognition using a standard insulator data set.},
booktitle = {Image and Graphics: 11th International Conference, ICIG 2021, Haikou, China, August 6–8, 2021, Proceedings, Part I},
pages = {210–221},
numpages = {12},
keywords = {Autoencoder, Defect recognition, Insulator detection},
location = {Haikou, China}
}

@inproceedings{10.1145/3472883.3486995,
author = {Suneja, Sahil and Zheng, Yunhui and Zhuang, Yufan and Laredo, Jim A. and Morari, Alessandro},
title = {Towards Reliable AI for Source Code Understanding},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3486995},
doi = {10.1145/3472883.3486995},
abstract = {Cloud maturity and popularity have resulted in Open source software (OSS) proliferation. And, in turn, managing OSS code quality has become critical in ensuring sustainable Cloud growth. On this front, AI modeling has gained popularity in source code understanding tasks, promoted by the ready availability of large open codebases. However, we have been observing certain peculiarities with these black-boxes, motivating a call for their reliability to be verified before offsetting traditional code analysis. In this work, we highlight and organize different reliability issues affecting AI-for-code into three stages of an AI pipeline- data collection, model training, and prediction analysis. We highlight the need for concerted efforts from the research community to ensure credibility, accountability, and traceability for AI-for-code. For each stage, we discuss unique opportunities afforded by the source code and software engineering setting to improve AI reliability.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {403–411},
numpages = {9},
keywords = {signal awareness, reliability, machine learning, explainability},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@article{10.1007/s10489-020-02026-2,
author = {Van Nguyen, Sinh and Tran, Ha Manh},
title = {An automated fault detection system for communication networks and distributed systems},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {8},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-02026-2},
doi = {10.1007/s10489-020-02026-2},
abstract = {Automating fault detection in communication networks and distributed systems is a challenging process that usually requires the involvement of supporting tools and the expertise of system operators. Automated event monitoring and correlating systems produce event data that is forwarded to system operators for analyzing error events and creating fault reports. Machine learning methods help not only analyzing event data more precisely but also forecasting possible error events by learning from existing faults. This study introduces an automated fault detection system that assists system operators in detecting and forecasting faults. This system is characterized by the capability of exploiting bug knowledge resources at various online repositories, log events and status parameters from the monitored system; and applying bug analysis and event filtering methods for evaluating events and forecasting faults. The system contains a fault data model to collect bug reports, a feature and semantic filtering method to correlate log events, and machine learning methods to evaluate the severity, priority and relation of log events and forecast the forthcoming critical faults of the monitored system. We have evaluated the prototyping implementation of the proposed system on a high performance computing cluster system and provided analysis with lessons learned.},
journal = {Applied Intelligence},
month = aug,
pages = {5405–5419},
numpages = {15},
keywords = {Bug tracking system, Random forest, Machine learning, Automation, Fault detection}
}

@article{10.1007/s42979-020-00202-2,
author = {Kovacs, Tibor and Ko, Andrea},
title = {Monitoring Pneumatic Actuators’ Behavior Using Real-World Data Set},
year = {2020},
issue_date = {Jul 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {4},
url = {https://doi.org/10.1007/s42979-020-00202-2},
doi = {10.1007/s42979-020-00202-2},
abstract = {Developing a big data signal processing method is to monitor the behavior of a common component: a pneumatic actuator. The method is aimed at supporting condition-based maintenance activities: monitoring signals over an extended period, and identifying, classifying different machine states that may indicate abnormal behavior. Furthermore, preparing a balanced data set for training supervised machine learning models that represent the component’s all identified conditions. Peak detection, garbage removal and down-sampling by interpolation were applied for signal preprocessing. Undersampling the over-represented signals, Ward’s hierarchical clustering with multivariate Euclidean distance calculation and Kohonen self-organizing map (KSOM) methods were used for identifying and grouping similar signal patterns. The study demonstrated that the behavior of equipment displaying complex signals could be monitored with the method described. Both hierarchical clustering and KSOM are suitable methods for identifying and clustering signals of different machine states that may be overlooked if screened by humans. Using the proposed methods, signals could be screened thoroughly and over a long period of time that is critical when failures or abnormal behavior is rare. Visual display of the identified clusters over time could help analyzing the deterioration of machine conditions. The clustered signals could be used to create a balanced set of training data for developing supervised machine learning models to automatically identify previously recognized machine conditions that indicate abnormal behavior.},
journal = {SN Comput. Sci.},
month = jun,
numpages = {12},
keywords = {Signal pattern identification, Fault detection, Condition-based maintenance, Kohonen self-organizing map, Clustering, Big data processing, Machine learning}
}

@inproceedings{10.1145/3377811.3380369,
author = {Bertolino, Antonia and Guerriero, Antonio and Miranda, Breno and Pietrantuono, Roberto and Russo, Stefano},
title = {Learning-to-rank vs ranking-to-learn: strategies for regression testing in continuous integration},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380369},
doi = {10.1145/3377811.3380369},
abstract = {In Continuous Integration (CI), regression testing is constrained by the time between commits. This demands for careful selection and/or prioritization of test cases within test suites too large to be run entirely. To this aim, some Machine Learning (ML) techniques have been proposed, as an alternative to deterministic approaches. Two broad strategies for ML-based prioritization are learning-to-rank and what we call ranking-to-learn (i.e., reinforcement learning). Various ML algorithms can be applied in each strategy. In this paper we introduce ten of such algorithms for adoption in CI practices, and perform a comprehensive study comparing them against each other using subjects from the Apache Commons project. We analyze the influence of several features of the code under test and of the test process. The results allow to draw criteria to support testers in selecting and tuning the technique that best fits their context.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1–12},
numpages = {12},
keywords = {continuous integration, machine learning, regression testing, test prioritization, test selection},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1007/978-3-030-19945-6_15,
author = {Al Mamun, S. M. Abdullah and Beyaz, Mehmet},
title = {LSTM Recurrent Neural Network (RNN) for Anomaly Detection in Cellular Mobile Networks},
year = {2018},
isbn = {978-3-030-19944-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-19945-6_15},
doi = {10.1007/978-3-030-19945-6_15},
abstract = {Anomaly detection can show significant behavior changes in the cellular mobile network. It can explain much important missing information and which can be monitored using advanced AI (Artificial Intelligent) applications/tools. In this paper, we have proposed LSTM (Long Short-Term Memory) based RNN (Recurrent Neural Network) which can model a time series profile for LTE network based on cell KPI values. We have shown in this paper that the dynamic behavior of a single cell can be simplified using a combination of a set for neighbor cells. We can predict the profile and anomalous behavior using this method. According to the best of our knowledge this approach is applied here for the first time for cell level performance profile generation and anomaly detection. In a related work, they have proposed ensemble method to compare different KPIs and cell performance using machine learning algorithm. We have applied DNN (Deep Neural Network) to generate a profile on KPI features from historical data. It gave us deeper insight into how the cell is performing over time and can connect with the root causes or hidden fault of a major failure in the cellular network.},
booktitle = {Machine Learning for Networking: First International Conference, MLN 2018, Paris, France, November 27–29, 2018, Revised Selected Papers},
pages = {222–237},
numpages = {16},
keywords = {Anomaly detection, Deep Neural Network, Cell performance degradation, Recurrent Neural Network (RNN), Cell diagnostics},
location = {Paris, France}
}

@inproceedings{10.1109/ICSE43902.2021.00026,
author = {Kim, Seohyun and Zhao, Jinman and Tian, Yuchi and Chandra, Satish},
title = {Code Prediction by Feeding Trees to Transformers},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00026},
doi = {10.1109/ICSE43902.2021.00026},
abstract = {Code prediction, more specifically autocomplete, has become an essential feature in modern IDEs. Autocomplete is more effective when the desired next token is at (or close to) the top of the list of potential completions offered by the IDE at cursor position. This is where the strength of the underlying machine learning system that produces a ranked order of potential completions comes into play.We advance the state-of-the-art in the accuracy of code prediction (next token prediction) used in autocomplete systems. Our work uses Transformers as the base neural architecture. We show that by making the Transformer architecture aware of the syntactic structure of code, we increase the margin by which a Transformer-based system outperforms previous systems. With this, it outperforms the accuracy of several state-of-the-art next token prediction systems by margins ranging from 14% to 18%.We present in the paper several ways of communicating the code structure to the Transformer, which is fundamentally built for processing sequence data. We provide a comprehensive experimental evaluation of our proposal, along with alternative design choices, on a standard Python dataset, as well as on a company internal Python corpus. Our code and data preparation pipeline will be available in open source.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {150–162},
numpages = {13},
keywords = {code prediction, code embedding, autocomplete},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1109/TSE.2010.90,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
title = {A General Software Defect-Proneness Prediction Framework},
year = {2011},
issue_date = {May 2011},
publisher = {IEEE Press},
volume = {37},
number = {3},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2010.90},
doi = {10.1109/TSE.2010.90},
abstract = {BACKGROUND—Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE—We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD—The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS—The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS—Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.},
journal = {IEEE Trans. Softw. Eng.},
month = may,
pages = {356–370},
numpages = {15},
keywords = {software defect-proneness prediction, scheme evaluation., machine learning, Software defect prediction}
}

@inproceedings{10.1109/ASE.2015.56,
author = {Nam, Jaechang and Kim, Sunghun},
title = {CLAMI: defect prediction on unlabeled datasets},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.56},
doi = {10.1109/ASE.2015.56},
abstract = {Defect prediction on new projects or projects with limited historical data is an interesting problem in software engineering. This is largely because it is difficult to collect defect information to label a dataset for training a prediction model. Cross-project defect prediction (CPDP) has tried to address this problem by reusing prediction models built by other projects that have enough historical data. However, CPDP does not always build a strong prediction model because of the different distributions among datasets. Approaches for defect prediction on unlabeled datasets have also tried to address the problem by adopting unsupervised learning but it has one major limitation, the necessity for manual effort.In this study, we propose novel approaches, CLA and CLAMI, that show the potential for defect prediction on unlabeled datasets in an automated manner without need for manual effort. The key idea of the CLA and CLAMI approaches is to label an unlabeled dataset by using the magnitude of metric values. In our empirical study on seven open-source projects, the CLAMI approach led to the promising prediction performances, 0.636 and 0.723 in average f-measure and AUC, that are comparable to those of defect prediction based on supervised learning.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {452–463},
numpages = {12},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@article{10.1016/j.engappai.2015.11.005,
author = {Fontes, Cristiano Hora and Pereira, Otac\'{\i}lio},
title = {Pattern recognition in multivariate time series - A case study applied to fault detection in a gas turbine},
year = {2016},
issue_date = {March 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {49},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2015.11.005},
doi = {10.1016/j.engappai.2015.11.005},
abstract = {Advances in information technology, together with the evolution of systems in control, automation and instrumentation have enabled the recovery, storage and manipulation of a large amount of data from industrial plants. This development has motivated the advancement of research in fault detection, especially based on process history data. Although a large amount of work has been conducted in recent years on the diagnostics of gas turbines, few of them present the use of clustering approaches applied to multivariate time series, adopting PCA similarity factor (SPCA) in order to detect and/or prevent failures. This paper presents a comprehensive method for pattern recognition associated to fault prediction in gas turbines using time series mining techniques. Algorithms comprising appropriate similarity metrics, subsequence matching and fuzzy clustering were applied on data extracted from a Plant Information Management System (PIMS) represented by multivariate time series. A real case study comprising the fault detection in a gas turbine was investigated. The results suggest the existence of a safe way to start the turbine that can be useful to support the development of a dynamic system for monitoring and predicting the probability of failure and for decision-making at operational level. Real case study comprising the fault detection in a gas turbine.Comprehensive method for pattern recognition associated to fault prediction in gas turbines.Results show the efficiency of the proposed approach for decision-making at operational level.The whole three step method presented is flexible and portable.An extended version of the FCM algorithm suitable for the clustering of multivariate time series is applied.},
journal = {Eng. Appl. Artif. Intell.},
month = mar,
pages = {10–18},
numpages = {9},
keywords = {Multivariate time series, Gas turbines, Fault detection, Data mining, Clustering}
}

@inproceedings{10.1007/978-3-030-88081-1_45,
author = {Nguyen, Anh and Thai, Huong and Le, Thanh},
title = {Severity Assessment of Facial Acne},
year = {2021},
isbn = {978-3-030-88080-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-88081-1_45},
doi = {10.1007/978-3-030-88081-1_45},
abstract = {Nowadays, facial acne is a popular skin disease. Acne is distributed in different regions on the face, and the severity of acne varies from patient to patient. Therefore, it is necessary to have an exact and objective diagnosis for each patient’s case before treatment. The problem of assessing severity of acne on human face is highly applicable in practice, as acne severity is essential for dermatologists to make a precise and standardized treatment decision. We perform surveys of automatic acne detection and classification systems. Our work follows the implementation by Xiaoping Wu et al. that grades and counts acne via label distribution learning applying on ACNE04 dataset, and the method of transfer learning regression model using image rolling data augmentation from Microsoft and Nestl\'{e} collaboration. We give discussion and conclusion about the two approaches from different experiments’ result.},
booktitle = {Computational Collective Intelligence: 13th International Conference, ICCCI 2021, Rhodes, Greece, September 29 – October 1, 2021, Proceedings},
pages = {599–612},
numpages = {14},
keywords = {Label distribution learning, Deep learning, Acne severity},
location = {Rhodos, Greece}
}

@article{10.1016/j.infsof.2013.05.002,
author = {Rodriguez, Daniel and Ruiz, Roberto and Riquelme, Jose C. and Harrison, Rachel},
title = {A study of subgroup discovery approaches for defect prediction},
year = {2013},
issue_date = {October, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {10},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.05.002},
doi = {10.1016/j.infsof.2013.05.002},
abstract = {Context: Although many papers have been published on software defect prediction techniques, machine learning approaches have yet to be fully explored. Objective: In this paper we suggest using a descriptive approach for defect prediction rather than the precise classification techniques that are usually adopted. This allows us to characterise defective modules with simple rules that can easily be applied by practitioners and deliver a practical (or engineering) approach rather than a highly accurate result. Method: We describe two well-known subgroup discovery algorithms, the SD algorithm and the CN2-SD algorithm to obtain rules that identify defect prone modules. The empirical work is performed with publicly available datasets from the Promise repository and object-oriented metrics from an Eclipse repository related to defect prediction. Subgroup discovery algorithms mitigate against characteristics of datasets that hinder the applicability of classification algorithms and so remove the need for preprocessing techniques. Results: The results show that the generated rules can be used to guide testing effort in order to improve the quality of software development projects. Such rules can indicate metrics, their threshold values and relationships between metrics of defective modules. Conclusions: The induced rules are simple to use and easy to understand as they provide a description rather than a complete classification of the whole dataset. Thus this paper represents an engineering approach to defect prediction, i.e., an approach which is useful in practice, easily understandable and can be applied by practitioners.},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {1810–1822},
numpages = {13},
keywords = {Subgroup discovery, Rules, Imbalanced datasets, Defect prediction}
}

@inproceedings{10.1007/978-3-031-14135-5_14,
author = {White, Gary and Diuwe, Jaroslaw and Fonseca, Erika and O’Brien, Owen},
title = {MMRCA: MultiModal Root Cause Analysis},
year = {2021},
isbn = {978-3-031-14134-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-14135-5_14},
doi = {10.1007/978-3-031-14135-5_14},
abstract = {Cloud systems are becoming increasingly complex and more difficult for human operators to manage due to the scale and interconnectedness of microservices. Increased observability and anomaly detection are able to alert when something has gone wrong, however a fault can propagate throughout the cloud leading to a large number of alerts. It is difficult for operators to manage these large number of alerts and to differentiate between the symptoms that have propagated due to the fault and the actual root cause. In this paper we present a MultiModal Root Cause Analysis algorithm called MMRCA. This algorithm leverages data from traces, topology, configurations and metrics to accurately predict the root cause of the fault. Our approach consists of a three step pipeline of topology reduction, metric causality and metric reduction. The experimental results show that MMRCA can accurately detect the root cause in a number of different data sets, while maintaining an efficient use of resources and scaling to a large deployment.},
booktitle = {Service-Oriented Computing – ICSOC 2021 Workshops:  AIOps, STRAPS, AI-PA and Satellite Events, Dubai, United Arab Emirates, November 22–25, 2021, Proceedings},
pages = {177–189},
numpages = {13},
keywords = {MultiModal data, Unsupervised learning, Causality analysis, Cloud computing, Root cause analysis}
}

@inproceedings{10.5555/978-3-030-62223-7_fm,
title = {Front Matter},
year = {2020},
isbn = {978-3-030-62222-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part I},
pages = {i–xxvii},
location = {Guangzhou, China}
}

@inproceedings{10.1007/978-3-030-16145-3_25,
author = {Li, Heng-Yi and Shi, Shu-Ting and Thung, Ferdian and Huo, Xuan and Xu, Bowen and Li, Ming and Lo, David},
title = {DeepReview: Automatic Code Review Using Deep Multi-instance Learning},
year = {2019},
isbn = {978-3-030-16144-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-16145-3_25},
doi = {10.1007/978-3-030-16145-3_25},
abstract = {Code review, an inspection of code changes in order to identify and fix defects before integration, is essential in Software Quality Assurance (SQA). Code review is a time-consuming task since the reviewers need to understand, analysis and provide comments manually. To alleviate the burden of reviewers, automatic code review is needed. However, this task has not been well studied before. To bridge this research gap, in this paper, we formalize automatic code review as a multi-instance learning task that each change consisting of multiple hunks is regarded as a bag, and each hunk is described as an instance. We propose a novel deep learning model named DeepReview based on Convolutional Neural Network (CNN), which is an end-to-end model that learns feature representation to predict whether one change is approved or rejected. Experimental results on open source projects show that DeepReview is effective in automatic code review tasks. In terms of F1 score and AUC, DeepReview outperforms the performance of traditional single-instance based model TFIDF-SVM and the state-of-the-art deep feature based model Deeper.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 23rd Pacific-Asia Conference, PAKDD 2019, Macau, China, April 14-17, 2019, Proceedings, Part II},
pages = {318–330},
numpages = {13},
keywords = {Software mining, Machine learning, Multi-instance learning, Automatic code review},
location = {Macau, China}
}

@article{10.1007/s10489-018-1323-y,
author = {Singh, Deepak and Singh, Pradeep and Sisodia, Dilip Singh},
title = {Evolutionary based ensemble framework for realizing transfer learning in HIV-1 Protease cleavage sites prediction},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {4},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-018-1323-y},
doi = {10.1007/s10489-018-1323-y},
abstract = {The role of human immunodeficiency virus (HIV) protease in viral maturation is indispensable as the drug therapy primarily targets the HIV protease for the treatment of human immunodeficiency virus infection. Protease inhibitors are designed to block the active site of the protease, thereby restraining the replication of the viral particle. However, designing efficient inhibitors is challenging due to little or no similarity of the sequence among the cleaved sites and availability of few experimentally-verified sites. In order to learn the sequence structure, support vector machines have been comprehensively used however insufficient training data degrades the performance. Thus, a cross-domain approach is adopted by the proposed ensemble model for predicting the HIV-1 protease cleavage sites. In this study, a method for combining multiple weighted classifiers optimally by incorporating the knowledge derived from various amino acid encoding techniques is proposed. As a result, each classifier pair with a specific type of heterogeneous information which is generated by the different encoding method, and the final prediction could be obtained by aggregating the locally trained classifiers. The optimally coupled sequence of features and classifiers that characterized the heterogeneous feature is achieved promptly by genetic algorithm. Furthermore, the efficiency of the model is verified by the tests conducted on the four HIV-1 protease datasets offered at UCI machine learning database. The performance parameters such as average accuracy, standard deviation, and area under curve have been evaluated on the proposed model to justify the advancements over the other state- of-the-art methods. In addition, Friedman and post hoc tests were conducted to show the significant improvement achieved by the proposed framework. These results quantified the enhancement of the proposed ensemble model performance.},
journal = {Applied Intelligence},
month = apr,
pages = {1260–1282},
numpages = {23},
keywords = {Transfer learning, HIV-1 proteases, Genetic algorithm, Ensemble learner, Cross-domain adaptation}
}

@article{10.1016/j.eswa.2019.113005,
author = {Ghaderi Zefrehi, Hossein and Alt\i{}n\c{c}ay, Hakan},
title = {Imbalance learning using heterogeneous ensembles},
year = {2020},
issue_date = {Mar 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {142},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113005},
doi = {10.1016/j.eswa.2019.113005},
journal = {Expert Syst. Appl.},
month = mar,
numpages = {15},
keywords = {Multiple balancing methods, Heterogeneous ensembles, Boosting, Bagging, Classifier ensembles, Imbalance learning}
}

@article{10.1016/j.jpdc.2017.06.022,
author = {Hussain, Shahid and Keung, Jacky and Khan, Arif Ali and Ahmad, Awais and Cuomo, Salvatore and Piccialli, Francesco and Jeon, Gwanggil and Akhunzada, Adnan},
title = {Implications of deep learning for the automation of design patterns organization},
year = {2018},
issue_date = {Jul 2018},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {117},
number = {C},
issn = {0743-7315},
url = {https://doi.org/10.1016/j.jpdc.2017.06.022},
doi = {10.1016/j.jpdc.2017.06.022},
journal = {J. Parallel Distrib. Comput.},
month = jul,
pages = {256–266},
numpages = {11},
keywords = {Classifiers, Performance, Feature set, Deep learning, Design patterns}
}

@inproceedings{10.1007/978-3-030-16142-2_17,
author = {Li, Heng-Yi and Li, Ming and Zhou, Zhi-Hua},
title = {Towards One Reusable Model for Various Software Defect Mining Tasks},
year = {2019},
isbn = {978-3-030-16141-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-16142-2_17},
doi = {10.1007/978-3-030-16142-2_17},
abstract = {Software defect mining is playing an important role in software quality assurance. Many deep neural network based models have been proposed for software defect mining tasks, and have pushed forward the state-of-the-art mining performance. These deep models usually require a huge amount of task-specific source code for training to capture the code functionality to mine the defects. But such requirement is often hard to be satisfied in practice. On the other hand, lots of free source code and corresponding textual explanations are publicly available in the open source software repositories, which is potentially useful in modeling code functionality. However, no previous studies ever leverage these resources to help defect mining tasks. In this paper, we propose a novel framework to learn one reusable deep model for code functional representation using the huge amount of publicly available task-free source code as well as their textual explanations. And then reuse it for various software defect mining tasks. Experimental results on three major defect mining tasks with real world datasets indicate that by reusing this model in specific tasks, the mining performance outperforms its counterpart that learns deep models from scratch, especially when the training data is insufficient.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 23rd Pacific-Asia Conference, PAKDD 2019, Macau, China, April 14-17, 2019, Proceedings, Part III},
pages = {212–224},
numpages = {13},
keywords = {Software defect mining, Machine learning, Model reuse},
location = {Macau, China}
}

@article{10.1016/j.aei.2021.101333,
author = {Li, Tianshu and Alipour, Mohamad and Harris, Devin K.},
title = {Context-aware sequence labeling for condition information extraction from historical bridge inspection reports},
year = {2021},
issue_date = {Aug 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2021.101333},
doi = {10.1016/j.aei.2021.101333},
journal = {Adv. Eng. Inform.},
month = aug,
numpages = {16},
keywords = {Data-driven bridge management, Deep learning, Context-aware, Information extraction, Bridge inspection report}
}

@article{10.1007/s10044-021-01013-8,
author = {Maskey, Manil and Newman, Timothy S.},
title = {On measuring and employing texture directionality for image classification},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {4},
issn = {1433-7541},
url = {https://doi.org/10.1007/s10044-021-01013-8},
doi = {10.1007/s10044-021-01013-8},
abstract = {Directionality is useful in many computer vision, pattern recognition, visualization, and multimedia applications since it is considered as an important pre-attentive attribute in human vision. To support using directionality (i.e., orientedness) for texture discrimination, a new measure that uses both local and global aspects of texture, with such use, to our knowledge, novel vis-\`{a}-vis prior state-of-the-art, to determine the directionality status for a texture is described and validated in this paper. This paper has four major elements. Element one is the measure we have developed that examines both local and global aspects of directionality to signal if a texture is directional or not. The local aspect is provided mostly from local pixel intensity differences, while a frequency domain analysis provides most of the global aspect. Element two is a comparison study of the measure (which exhibits the best outcomes) versus the known alternatives for determining texture directionality. Element three considers the measure relative to human experience. Element four considers applications of the measure to image classification. The second element (i.e., the study) is a comprehensive comparison study of existing texture directionality measures, based on the full set of Brodatz textures and human sentiment, which is the first such study.},
journal = {Pattern Anal. Appl.},
month = nov,
pages = {1649–1665},
numpages = {17},
keywords = {Orientation measure, Classification, User study, Orientedness, Directionality, Texture}
}

@article{10.1016/j.compind.2019.02.010,
author = {Nacereddine, Nafaa and Goumeidane, Aicha Baya and Ziou, Djemel},
title = {Unsupervised weld defect classification in radiographic images using multivariate generalized Gaussian mixture model with exact computation of mean and shape parameters},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {108},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2019.02.010},
doi = {10.1016/j.compind.2019.02.010},
journal = {Comput. Ind.},
month = jun,
pages = {132–149},
numpages = {18},
keywords = {Classification, Weld defect, Radiography, Multivariate GGD, Mixture model}
}

@article{10.1049/iet-sen.2020.0025,
author = {Shatnawi, Raed},
title = {Comparison of threshold identification techniques for object‐oriented software metrics},
year = {2020},
issue_date = {December 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {6},
url = {https://doi.org/10.1049/iet-sen.2020.0025},
doi = {10.1049/iet-sen.2020.0025},
abstract = {Quality assurance is a continuous process throughout the project lifecycle from inception till post‐delivery. Software metrics are tools to help developers in achieving software quality objectives. Software metrics are used to predict the fault‐proneness of classes in software using machine‐learning and statistical techniques. However, these methodologies are difficult for daily tasks. Simpler and on the fly methodologies such as threshold values are needed. Metric thresholds can be used to control software quality and to recommend improvements on software code. Thresholds detect the parts of software that need more verification and validation. Many threshold identification techniques were proposed in previous research. However, the techniques do not provide consistent thresholds. The authors compare eight threshold identification techniques to diagnose software fault‐proneness. The eight techniques are derived from diagnosis measures such as specificity, sensitivity, recall and precision. Five threshold identification techniques have derived thresholds that are skewed and have large standard deviations. Only three techniques are selected for threshold identification based on consistency and variation in selecting thresholds of software metrics in the systems under study. These techniques find thresholds that have the least variation among the studied techniques. The median of the 11 systems is selected as a representative of all thresholds.},
journal = {IET Software},
month = oct,
pages = {727–738},
numpages = {12},
keywords = {software validation, software verification, machine learning, project lifecycle, software fault proneness, software code, metric thresholds, software quality assurance, statistical techniques, object oriented software metrics, threshold identification techniques, program verification, object‐oriented methods, statistical analysis, product life cycle management, project management, software metrics, software fault tolerance, software quality, learning (artificial intelligence)}
}

@inproceedings{10.1145/2639490.2639504,
author = {Russo, Barbara},
title = {A proposed method to evaluate and compare fault predictions across studies},
year = {2014},
isbn = {9781450328982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639490.2639504},
doi = {10.1145/2639490.2639504},
abstract = {Studies on fault prediction often pay little attention to empirical rigor and presentation. Researchers might not have full command over the statistical method they use, full understanding of the data they have, or tend not to report key details about their work. What does it happen when we want to compare such studies for building a theory on fault prediction? There are two issues that if not addressed, we believe, prevent building such theory. The first concerns how to compare and report prediction performance across studies on different data sets. The second regards fitting performance of prediction models. Studies tend not to control and report the performance of predictors on historical data underestimating the risk that good predictors may poorly perform on past data. The degree of both fitting and prediction performance determines the risk managers are requested to take when they use such predictors. In this work, we propose a framework to compare studies on categorical fault prediction that aims at addressing the two issues. We propose three algorithms that automate our framework. We finally review baseline studies on fault prediction to discuss the application of the framework.},
booktitle = {Proceedings of the 10th International Conference on Predictive Models in Software Engineering},
pages = {2–11},
numpages = {10},
keywords = {confusion matrix, fault, machine learning, model comparison},
location = {Turin, Italy},
series = {PROMISE '14}
}

@article{10.1007/s11063-016-9532-z,
author = {Wan, Jianwu and Wang, Hongyuan and Yang, Ming},
title = {Cost Sensitive Semi-Supervised Canonical Correlation Analysis for Multi-view Dimensionality Reduction},
year = {2017},
issue_date = {April     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {45},
number = {2},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-016-9532-z},
doi = {10.1007/s11063-016-9532-z},
abstract = {To deal with the cost sensitive and semi-supervised learning problems in Multi-view Dimensionality Reduction (MDR), we propose a Cost Sensitive Semi-Supervised Canonical Correlation Analysis $$(hbox {CS}^{3}hbox {CCA}). hbox {CS}^{3}hbox {CCA}$$(CS3CCA).CS3CCA first uses the $$L_2$$L2 norm approach to obtain the soft label for each unlabeled data, and then embed the misclassification cost into the framework of Canonical Correlation Analysis (CCA). Compared with existing CCA based methods, $$hbox {CS}^{3}hbox {CCA}$$CS3CCA has the following advantages: (1) It uses the $$L_2$$L2 norm approach to infer the soft label for unlabeled data, which is computationally efficient and effective, especially for cost sensitive face recognition. (2) The objective function of $$hbox {CS}^{3}hbox {CCA}$$CS3CCA not only maximizes the soft cost sensitive within-class correlations and minimizes the soft cost sensitive between-class correlations in the inter-view, but also considers the class imbalance problem simultaneously. With the discriminant projections learned by $$hbox {CS}^{3}hbox {CCA}$$CS3CCA, we employ it for cost sensitive face recognition. The experimental results on four well-known face data sets, including AR, Extended Yale B, PIE and ORL, demonstrate the effectiveness of $$hbox {CS}^{3}hbox {CCA}$$CS3CCA.},
journal = {Neural Process. Lett.},
month = apr,
pages = {411–430},
numpages = {20},
keywords = {Semi-supervised, Multi-view learning, Face recognition, Cost sensitive learning, Canonical correlation analysis}
}

@article{10.1016/j.neucom.2019.10.067,
author = {Zhao, Yudi and Hao, Kuangrong and He, Haibo and Tang, Xuesong and Wei, Bing},
title = {A visual long-short-term memory based integrated CNN model for fabric defect image classification},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {380},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.10.067},
doi = {10.1016/j.neucom.2019.10.067},
journal = {Neurocomput.},
month = mar,
pages = {259–270},
numpages = {12},
keywords = {Visual long-term memory, Visual short-term memory, Visual perception, Visual system, Image classification, Fabric defects}
}

@article{10.1007/s11042-020-10321-w,
author = {Fekri-Ershad, Shervan},
title = {Cell phenotype classification using multi threshold uniform local ternary patterns in fluorescence microscope images},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {8},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-10321-w},
doi = {10.1007/s11042-020-10321-w},
abstract = {Identifying locations of protein expression in live cells plays an important role in several medical applications ranging from early disease diagnosis to monitoring effectiveness of drugs. Protein localization is directly related to their cell types. Today florescence imaging is widely used to understand biology at the cellular level. Hence, cell phenotype classification in fluorescence microscope images, is related with protein localization. Today it is performed by human, which is very time consuming with low accuracy. According to the visual structure, it can be seen that samples of a unique cell type have quite similar texture, but the texture of different cell types, are very different. In this respect, texture information can be used more widely than shape or color information, to classify types. Local ternary pattern is a noise-resistant texture descriptor that provides discriminative features. In this paper a local texture analysis descriptor is proposed titled multi threshold uniform-based local ternary patterns with notation MT-ULTP. MT-ULTP extracts local significant texture information in different locality levels. In this respect, local ternary patterns are extracted in different thresholds and finally the occurrence probability of the uniform patterns is extracted as features. MT-ULTP is a skillful combination of LTP and MLBP with novelty in feature extracting and local pattern selecting. Performance of the proposed descriptor is evaluated on 2d-hela dataset in terms of accuracy. 2d-hela is the benchmark dataset of cell phenotype images. Experimental results show that MT-ULTP provides higher classification rates than very well-known texture descriptors such as lbp-like descriptors. In other experiments, it has been shown that ignoring uniform textural patterns in the image analysis can increase the accuracy of cell phenotype classification and some other computer vision-based applications. The results also showed that extraction uniform patterns based on a combination of thresholds provide better results than the simple form in local ternary patterns. The proposed image texture descriptor is a general case which can be used in many computer vision applications to describe the image contents.},
journal = {Multimedia Tools Appl.},
month = mar,
pages = {12103–12116},
numpages = {14},
keywords = {Multi threshold uniform local ternary patterns, Texture image analysis, Feature extraction, Fluorescence microscope images, Cell phenotype classification}
}

@article{10.3233/JIFS-192071,
author = {Ameen, Mustafa and Alrahmawy, Mohammed and AbouEleneen, Amal and Tolba, Ahmad},
title = {Neighborhood preserving perceptual fidelity aware MSE for visual inspection of industrial flat surface products},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {39},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-192071},
doi = {10.3233/JIFS-192071},
abstract = {Automated visual inspection is becoming an important field of computer vision in many industries. The real-time inspection of flat surface products is a task full of challenges in industrial aspects that requires fast and accurate algorithms for detection and localisation of defects. Structural, statistical and filter-based approaches, such as Gabor Filter Banks, Log-Gabor filter and Wavelets, have high computational complexity.This paper introduces a fast and accurate model for inspection and localization of industrial flat surface products: Neighborhood Preserving Perceptual Fidelity Aware Mean Squared Error (NP-PAMSE). The Extreme Learning Machine (ELM) is used for classification. ELM is found to be the perfect classifier for detecting defects. The proposed model resulted in defect detection accuracy of 99.86%, with 98.16% sensitivity, and 99.90% specificity.These results show that the proposed model outperforms many existing defect detection approaches. The discriminant power displays the efficiency of ELM in differentiation between normal and abnormal surfaces.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {1183–1196},
numpages = {14},
keywords = {extreme learning machine (ELM), perceptual fidelity aware mean squared error (PAMSE), Automated visual inspection (AVI)}
}

@article{10.1016/j.datak.2008.10.005,
author = {Turhan, Burak and Bener, Ayse},
title = {Analysis of Naive Bayes' assumptions on software fault data: An empirical study},
year = {2009},
issue_date = {February, 2009},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {68},
number = {2},
issn = {0169-023X},
url = {https://doi.org/10.1016/j.datak.2008.10.005},
doi = {10.1016/j.datak.2008.10.005},
abstract = {Software defect prediction is important for reducing test times by allocating testing resources effectively. In terms of predicting the defects in software, Naive Bayes outperforms a wide range of other methods. However, Naive Bayes assumes the 'independence' and 'equal importance' of attributes. In this work, we analyze these assumptions of Naive Bayes using public software defect data from NASA. Our analysis shows that independence assumption is not harmful for software defect data with PCA pre-processing. Our results also indicate that assigning weights to static code attributes may increase the prediction performance significantly, while removing the need for feature subset selection.},
journal = {Data Knowl. Eng.},
month = feb,
pages = {278–290},
numpages = {13},
keywords = {Software defect prediction, Naive Bayes, Empirical study}
}

@article{10.1016/j.compeleceng.2013.11.024,
author = {Chandrashekar, Girish and Sahin, Ferat},
title = {A survey on feature selection methods},
year = {2014},
issue_date = {January, 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {40},
number = {1},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2013.11.024},
doi = {10.1016/j.compeleceng.2013.11.024},
abstract = {Plenty of feature selection methods are available in literature due to the availability of data with hundreds of variables leading to data with very high dimension. Feature selection methods provides us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications. In this paper we provide an overview of some of the methods present in literature. The objective is to provide a generic introduction to variable elimination which can be applied to a wide array of machine learning problems. We focus on Filter, Wrapper and Embedded methods. We also apply some of the feature selection techniques on standard datasets to demonstrate the applicability of feature selection techniques.},
journal = {Comput. Electr. Eng.},
month = jan,
pages = {16–28},
numpages = {13}
}

@inproceedings{10.1145/3295500.3356185,
author = {Jauk, David and Yang, Dai and Schulz, Martin},
title = {Predicting faults in high performance computing systems: an in-depth survey of the state-of-the-practice},
year = {2019},
isbn = {9781450362290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3295500.3356185},
doi = {10.1145/3295500.3356185},
abstract = {As we near exascale, resilience remains a major technical hurdle. Any technique with the goal of achieving resilience suffers from having to be reactive, as failures can appear at any time. A wide body of research aims at predicting failures, i.e., forecasting failures so that evasive actions can be taken while the system is still fully functional, which has the benefit of giving insight into the global system state.This research area has grown very diverse with a large number of approaches, yet is currently poorly classified, making it hard to understand the impact and coverage of existing work. In this paper, we perform an extensive survey of existing literature in failure prediction by analyzing and comparing more than 30 different failure prediction approaches. We develop a taxonomy, which aids in categorizing the methods, and we show how this can help us to understand the state-of-the-practice of this field and to identify opportunities, gaps as well as future work.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {30},
numpages = {13},
keywords = {resillience, high performance computing, fault prediction, exascale computing},
location = {Denver, Colorado},
series = {SC '19}
}

@article{10.1016/j.ins.2019.01.047,
author = {Azmi, Mohamed and Runger, George C. and Berrado, Abdelaziz},
title = {Interpretable regularized class association rules algorithm for classification in a categorical data space},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {483},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.01.047},
doi = {10.1016/j.ins.2019.01.047},
journal = {Inf. Sci.},
month = may,
pages = {313–331},
numpages = {19},
keywords = {Class association rules, Regularization, Pruning, Association rules, Ensemble learning, Classification}
}

@article{10.1007/s11704-019-9094-0,
author = {Husnain, Mujtaba and Missen, Malik Muhammad Saad and Akhtar, Nadeem and Coustaty, Micka\"{e}l and Mumtaz, Shahzad and Prasath, V. B. Surya},
title = {A systematic study on the role of SentiWordNet in opinion mining},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {4},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-019-9094-0},
doi = {10.1007/s11704-019-9094-0},
abstract = {Sentiment lexicons (SL) (aka lexical resources) are the repositories of one or several dictionaries that consist of known and precompiled sentiment terms. These lexicons play an important role in performing several different opinion mining tasks. The efficacy of the lexicon-based approaches in performing opinion mining (OM) tasks solely depends on selecting an appropriate opinion lexicon to analyze the text. Therefore, one has to explore the available sentiment lexicons and then select the most suitable resource. Among available resources, SentiWordNet (SWN) is the most widely used lexicon to perform tasks related to opinion mining. In SWN, each synset of WordNet is being assigned the three sentiment numerical scores; positive, negative and objective that are calculated using by a set of classifiers. In this paper, a detailed and comprehensive review of the work related to opinion mining using SentiWordNet is provided in a very distinctive way. This survey will be useful for the researchers contributing to the field of opinion mining. Following features make our contribution worthwhile and unique among the reviews of similar kind: (i) our review classifies the existing literature with respect to opinion mining tasks and subtasks (ii) it covers a very different outlook of the opinion mining field by providing in-depth discussions of the existing works at different granularity levels (word, sentences, document, aspect, clause, and concept levels) (iii) this state-of-art review covers each article in the following dimensions: the designated task performed, granularity level of the task completed, results obtained, and feature dimensions, and (iv) lastly it concludes the summary of the related articles according to the granularity levels, publishing years, related tasks (or subtasks), and types of classifiers used. In the end, major challenges and tasks related to lexicon-based approaches towards opinion mining are also discussed.},
journal = {Front. Comput. Sci.},
month = aug,
numpages = {19},
keywords = {opinion strength, SentiWordNet, lexical based resources, opinion mining}
}

@article{10.1504/ijiei.2020.112051,
author = {Kaur, Sandeep and Chahal, Kuljit Kaur},
title = {Hybrid ANFIS-genetic algorithm based forecasting model for predicting Cholera-waterborne disease},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {8},
number = {4},
issn = {1758-8715},
url = {https://doi.org/10.1504/ijiei.2020.112051},
doi = {10.1504/ijiei.2020.112051},
abstract = {Cholera is one of the rapidly spreading waterborne diseases which are caused by bacteria named Vibrio Cholerae. As population grows, so as the data related to patients, doctors and health staff. So far, different types of machine learning models have been proposed for classification of Cholera infection. However, the majority of these suffers from pre-mature convergence and stuck in local optimal issues. In this paper, ANFIS-GA based forecasting model for the prediction of Cholera virus has been proposed. In the proposed model, non-dominated sorting genetic algorithm (NSGA) is used to tune hyper-parameters of ANFIS. The comparisons are done among the designed NSGA-ANFIS and the existing models on the benchmark Cholera dataset. Performance analysis illustrates that the designed NSGA-ANFIS model performs significantly better than the existing models such as ANFIS, PSO-ANFIS and GA-ANFIS in terms of accuracy, sensitivity, kappa statistics, specificity and F-measure, as 99.2%, 99.04%, 99.11%, 99.49% and 98.85%, respectively.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {374–393},
numpages = {19},
keywords = {optimisation, data granulation, fitness function, non-dominated sorting genetic algorithm, NSGA, machine learning model, genetic algorithm, Cholera, ANFIS}
}

@inproceedings{10.1145/2884781.2884857,
author = {Tantithamthavorn, Chakkrit and McIntosh, Shane and Hassan, Ahmed E. and Matsumoto, Kenichi},
title = {Automated parameter optimization of classification techniques for defect prediction models},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884857},
doi = {10.1145/2884781.2884857},
abstract = {Defect prediction models are classifiers that are trained to identify defect-prone software modules. Such classifiers have configurable parameters that control their characteristics (e.g., the number of trees in a random forest classifier). Recent studies show that these classifiers may underperform due to the use of suboptimal default parameter settings. However, it is impractical to assess all of the possible settings in the parameter spaces. In this paper, we investigate the performance of defect prediction models where Caret --- an automated parameter optimization technique --- has been applied. Through a case study of 18 datasets from systems that span both proprietary and open source domains, we find that (1) Caret improves the AUC performance of defect prediction models by as much as 40 percentage points; (2) Caret-optimized classifiers are at least as stable as (with 35% of them being more stable than) classifiers that are trained using the default settings; and (3) Caret increases the likelihood of producing a top-performing classifier by as much as 83%. Hence, we conclude that parameter settings can indeed have a large impact on the performance of defect prediction models, suggesting that researchers should experiment with the parameters of the classification techniques. Since automated parameter optimization techniques like Caret yield substantially benefits in terms of performance improvement and stability, while incurring a manageable additional computational cost, they should be included in future defect prediction studies.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {321–332},
numpages = {12},
keywords = {software defect prediction, parameter optimization, experimental design, classification techniques},
location = {Austin, Texas},
series = {ICSE '16}
}

@article{10.1007/s10115-019-01342-5,
author = {Liu, Ruochen and Wang, Fangfang and He, Manman and Jiao, Licheng},
title = {An adjustable fuzzy classification algorithm using an improved multi-objective genetic strategy based on decomposition for imbalance dataset},
year = {2019},
issue_date = {Dec 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {61},
number = {3},
issn = {0219-1377},
url = {https://doi.org/10.1007/s10115-019-01342-5},
doi = {10.1007/s10115-019-01342-5},
abstract = {In this paper, we propose an adjustable fuzzy classification algorithm using multi-objective genetic strategy based on decomposition (AFC_MOGD) to solve imbalance classification problem. In AFC_MOGD, firstly, an improved multi-objective genetic strategy based on decomposition is adopted as the basic optimization algorithm in which a new updating pattern getting good solutions is designed. Then, an adjustable parameter which is ranged in the interval [0, 1] is used to adjust complexity of each classifier artificially. Finally, a normalized method which takes class percentage into account to determine class label and rule weight of each rule is introduced so as to obtain more reasonable rules. The proposed algorithm is compared with three typical algorithms on eleven imbalance datasets in terms of area under the ROC of convex hull. The Wilcoxon signed-rank test is also carried out to show that our algorithm is superior to other algorithms.},
journal = {Knowl. Inf. Syst.},
month = dec,
pages = {1583–1605},
numpages = {23},
keywords = {Decomposition, Multi-objective optimization, Adjustable fuzzy classifiers, Imbalance dataset}
}

@inproceedings{10.1007/978-3-319-47955-2_19,
author = {Murillo-Morera, Juan and Castro-Herrera, Carlos and Arroyo, Javier and Fuentes-Fern\'{a}ndez, Rub\'{e}n},
title = {An Empirical Validation of Learning Schemes Using an Automated Genetic Defect Prediction Framework},
year = {2016},
isbn = {978-3-319-47954-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-47955-2_19},
doi = {10.1007/978-3-319-47955-2_19},
abstract = {Today, it is common for software projects to collect measurement data through development processes. With these data, defect prediction software can try to estimate the defect proneness of a software module, with the objective of assisting and guiding software practitioners. With timely and accurate defect predictions, practitioners can focus their limited testing resources on higher risk areas. This paper reports a benchmarking study that uses a genetic algorithm that automatically generates and compares different learning schemes (preprocessing + attribute selection + learning algorithms). Performance of the software development defect prediction models (using AUC, Area Under the Curve) was validated using NASA-MDP and PROMISE data sets. Twelve data sets from NASA-MDP (8) and PROMISE (4) projects were analyzed running a -fold cross-validation. We used a genetic algorithm to select the components of the learning schemes automatically, and to evaluate and report those with the best performance. In all, 864 learning schemes were studied. The most common learning schemes were: data preprocessors: Log and CoxBox + attribute selectors: Backward Elimination, BestFirst and LinearForwardSelection + learning algorithms: NaiveBayes, NaiveBayesSimple, SimpleLogistic, MultilayerPerceptron, Logistic, LogitBoost, BayesNet, and OneR. The genetic algorithm reported steady performance and runtime among data sets, according to statistical analysis.},
booktitle = {Advances in Artificial Intelligence - IBERAMIA 2016: 15th Ibero-American Conference on AI, San Jos\'{e}, Costa Rica, November 23-25, 2016, Proceedings},
pages = {222–234},
numpages = {13},
keywords = {Software quality, Fault prediction models, Genetic algorithms, Learning schemes, Learning algorithms, Machine learning},
location = {San Jos\'{e}, Costa Rica}
}

@inproceedings{10.1145/2811411.2811544,
author = {Siebra, Clauirton A. and Mello, Michael A. B.},
title = {The importance of replications in software engineering: a case study in defect prediction},
year = {2015},
isbn = {9781450337380},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811411.2811544},
doi = {10.1145/2811411.2811544},
abstract = {Prediction of defects in software is an important investigation area in software engineering, since such technique is able to return indications of parts of the code that are prone to contain problems. Thus, test teams can optimize the allocation of their resources by directing them to modules that are more defect-prone. The use of supervised learning is one of the approaches to support the design of prediction models. However, the erroneous use of training datasets can lead to poor models and, consequently, false results regarding accuracy. This work replicates important experiments of the area and shows how they could provide reliable results via the use of simple techniques of pre-processing. Based on the results, we discuss the importance of replications as method to find problems in current results and how this method is being motivated inside the software engineering area.},
booktitle = {Proceedings of the 2015 Conference on Research in Adaptive and Convergent Systems},
pages = {376–381},
numpages = {6},
keywords = {supervised learning, replication, defect prediction},
location = {Prague, Czech Republic},
series = {RACS '15}
}

@inproceedings{10.1007/978-3-030-61166-8_3,
author = {Graziani, Mara and Lompech, Thomas and M\"{u}ller, Henning and Depeursinge, Adrien and Andrearczyk, Vincent},
title = {Interpretable CNN Pruning for Preserving Scale-Covariant Features in Medical Imaging},
year = {2020},
isbn = {978-3-030-61165-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-61166-8_3},
doi = {10.1007/978-3-030-61166-8_3},
abstract = {Image scale carries crucial information in medical imaging, e.g. the size and spatial frequency of local structures, lesions, tumors and cell nuclei. With feature transfer being a common practice, scale-invariant features implicitly learned from pretraining on ImageNet tend to be preferred over scale-covariant features. The pruning strategy in this paper proposes a way to maintain scale covariance in the transferred features. Deep learning interpretability is used to analyze the layer-wise encoding of scale information for popular architectures such as InceptionV3 and ResNet50. Interestingly, the covariance of scale peaks at central layers and decreases close to softmax. Motivated by these results, our pruning strategy removes the layers where invariance to scale is learned. The pruning operation leads to marked improvements in the regression of both nuclei areas and magnification levels of histopathology images. These are relevant applications to enlarge the existing medical datasets with open-access images as those of PubMed Central. All experiments are performed on publicly available data and the code is shared on GitHub.},
booktitle = {Interpretable and Annotation-Efficient Learning for Medical Image Computing: Third International Workshop, IMIMIC 2020, Second International Workshop, MIL3ID 2020, and 5th International Workshop, LABELS 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4–8, 2020, Proceedings},
pages = {23–32},
numpages = {10},
keywords = {Transfer, Histopathology, Scale, Interpretability},
location = {Lima, Peru}
}

@article{10.1016/j.ins.2021.08.067,
author = {Gao, Can and Zhou, Jie and Miao, Duoqian and Yue, Xiaodong and Wan, Jun},
title = {Granular-conditional-entropy-based attribute reduction for partially labeled data with proxy labels},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {580},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2021.08.067},
doi = {10.1016/j.ins.2021.08.067},
journal = {Inf. Sci.},
month = nov,
pages = {111–128},
numpages = {18},
keywords = {Proxy label, Information granularity, Conditional entropy, Semi-supervised attribute reduction, Rough sets}
}

@article{10.1016/j.eswa.2018.12.024,
author = {Raghuwanshi, Bhagat Singh and Shukla, Sanyam},
title = {Generalized class-specific kernelized extreme learning machine for multiclass imbalanced learning},
year = {2019},
issue_date = {May 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {121},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2018.12.024},
doi = {10.1016/j.eswa.2018.12.024},
journal = {Expert Syst. Appl.},
month = may,
pages = {244–255},
numpages = {12},
keywords = {Classification, Multiclass imbalanced learning, Generalized class-specific kernelized extreme learning machine, Kernelized extreme learning machine}
}

@article{10.1016/j.imavis.2019.06.008,
author = {He, Di and Xu, Ke and Wang, Dadong},
title = {Design of multi-scale receptive field convolutional neural network for surface inspection of hot rolled steels},
year = {2019},
issue_date = {Sep 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {89},
number = {C},
issn = {0262-8856},
url = {https://doi.org/10.1016/j.imavis.2019.06.008},
doi = {10.1016/j.imavis.2019.06.008},
journal = {Image Vision Comput.},
month = sep,
pages = {12–20},
numpages = {9},
keywords = {Surface inspection, Hot rolled steels, Defect identification, Convolutional neural networks, AutoEncoder}
}

@article{10.5555/2984642.2984647,
author = {Panda, Mrutyunjaya and Hassanien, Aboul Ella and Abraham, Ajith},
title = {Hybrid Data Mining Approach for Image Segmentation Based Classification},
year = {2016},
issue_date = {April 2016},
publisher = {IGI Global},
address = {USA},
volume = {3},
number = {2},
issn = {2334-4598},
abstract = {Evolutionary harmony search algorithm is used for its capability in finding solution space both locally and globally. In contrast, Wavelet based feature selection, for its ability to provide localized frequency information about a function of a signal, makes it a promising one for efficient classification. Research in this direction states that wavelet based neural network may be trapped to fall in a local minima whereas fuzzy harmony search based algorithm effectively addresses that problem and able to get a near optimal solution. In this, a hybrid wavelet based radial basis function RBF neural network WRBF and feature subset harmony search based fuzzy discernibility classifier HSFD approaches are proposed as a data mining technique for image segmentation based classification. In this paper, the authors use Lena RGB image; Magnetic resonance image MR and Computed Tomography CT Image for analysis. It is observed from the obtained simulation results that Wavelet based RBF neural network outperforms the harmony search based fuzzy discernibility classifiers.},
journal = {Int. J. Rough Sets Data Anal.},
month = apr,
pages = {65–81},
numpages = {17},
keywords = {Wavelet, Radial Basis Function, PSNR, Image Segmentation, Image 5-D, Histogram Equalisation, Harmony Search, Gaussian Filter, Fuzzy Discernibility, Feature Extraction}
}

@article{10.1007/s10489-019-01423-6,
author = {Lopez-Garcia, Pedro and Masegosa, Antonio D. and Osaba, Eneko and Onieva, Enrique and Perallos, Asier},
title = {Ensemble classification for imbalanced data based on feature space partitioning and hybrid metaheuristics},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {8},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-019-01423-6},
doi = {10.1007/s10489-019-01423-6},
abstract = {One of the most challenging issues when facing a classification problem is to deal with imbalanced datasets. Recently, ensemble classification techniques have proven to be very successful in addressing this problem. We present an ensemble classification approach based on feature space partitioning for imbalanced classification. A hybrid metaheuristic called GACE is used to optimize the different parameters related to the feature space partitioning. To assess the performance of the proposal, an extensive experimentation over imbalanced and real-world datasets compares different configurations and base classifiers. Its performance is competitive with that of reference techniques in the literature.},
journal = {Applied Intelligence},
month = aug,
pages = {2807–2822},
numpages = {16},
keywords = {Imbalanced classification, Hybrid metaheuristics, Feature space partitioning, Ensemble classification}
}

@article{10.1007/s00766-015-0232-4,
author = {Dargan, John L. and Wasek, James S. and Campos-Nanez, Enrique},
title = {Systems performance prediction using requirements quality attributes classification},
year = {2016},
issue_date = {November  2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {4},
issn = {0947-3602},
url = {https://doi.org/10.1007/s00766-015-0232-4},
doi = {10.1007/s00766-015-0232-4},
abstract = {Poor requirements definition can adversely impact system cost and performance for government acquisition programs. This can be mitigated by ensuring requirements statements are written in a clear and unambiguous manner with high linguistic quality. This paper introduces a statistical model that uses requirements quality factors to predict system operational performance. This work explores four classification techniques (Logistic Regression, Na\"{\i}ve Bayes Classifier, Support Vector Machine, and K-Nearest Neighbor) to develop the predictive model. This model is created using empirical data from current major acquisition programs within the federal government. Operational Requirements Documents and Operational Test Reports are the data sources, respectively, for the system requirements statements and the accompanying operational test results used for model development. A commercial-off-the-shelf requirements quality analysis tool is used to determine the requirements linguistic quality metrics used in the model. Subsequent to model construction, the predictive value of the model is confirmed through execution of a sensitivity analysis, cross-validation of the data, and an overfitting analysis. Lastly, Receiver Operating Characteristics are examined to determine the best performing model. In all, the results establish that requirements quality is indeed a predictive factor for end-system operational performance, and the resulting statistical model can influence requirements development based on likelihood of successful operational performance.},
journal = {Requir. Eng.},
month = nov,
pages = {553–572},
numpages = {20},
keywords = {Requirements quality attributes, Requirements engineering, Requirements definition, Poor requirements, Natural language requirements}
}

@inproceedings{10.1145/3297662.3365800,
author = {Elhariri, Esraa and El-Bendary, Nashwa and Taie, Shereen A.},
title = {Performance Analysis of Using Feature Fusion for Crack Detection in Images of Historical Buildings},
year = {2020},
isbn = {9781450362382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297662.3365800},
doi = {10.1145/3297662.3365800},
abstract = {In this paper, three types of feature sets are used for evaluating the performance of a proposed approach for crack detection in images of historical buildings. The feature sets are hand-crafted features, Convolutional Neural Network (CNN) learned features, and fusion of hand-crafted and CNN-learned features. The proposed approach is validated by implementing several Machine Learning (ML) classifiers with applying 3-fold cross validation. Two datasets of crack images are used for developing the feature sets. Experimental results show that both Support Vector Machine (SVM) and stacked ensemble classifiers achieve highest accuracy of 98% for crack detection using the CNN-learned features with dimensionality reduction. The significance of this study is to highlight the impact of different types of feature sets on the performance of the classification process for crack detection.},
booktitle = {Proceedings of the 11th International Conference on Management of Digital EcoSystems},
pages = {308–315},
numpages = {8},
keywords = {hand-crafted features, feature fusion, dimensionality reduction, data augmentation, crack detection, Principle Component Analysis (PCA), Machine Learning (ML), Local Binary Pattern (LBP), Histogram of Gradient (HOG), Convolutional Neural Network (CNN)},
location = {Limassol, Cyprus},
series = {MEDES '19}
}

@inproceedings{10.5555/3466184.3466446,
author = {Rodriguez, Brodderick and Yilmaz, Levent},
title = {Learning rule-based explanatory models from exploratory multi-simulation for decision-support under uncertainty},
year = {2021},
isbn = {9781728194998},
publisher = {IEEE Press},
abstract = {Exploratory modeling and simulation is an effective strategy when there are substantial contextual uncertainty and representational ambiguity in problem formulation. However, two significant challenges impede the use of an ensemble of models in exploratory simulation. The first challenge involves streamlining the maintenance and synthesis of multiple models from plausible features that are identified from and subject to the constraints of the research hypothesis. The second challenge is making sense of the data generated by multi-simulation over a model ensemble. To address both challenges, we introduce a computational framework that integrates feature-driven variability management with an anticipatory learning classifier system to generate explanatory rules from multi-simulation data.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2293–2304},
numpages = {12},
location = {Orlando, Florida},
series = {WSC '20}
}

@inproceedings{10.1007/978-3-030-31321-0_39,
author = {Jafari-Tabrizi, Atae and Lichtenegger, Hannah Luise and Gruber, Dieter P.},
title = {A Method for the Evaluation and Classification of the Orange Peel Effect on Painted Injection Moulded Part Surfaces},
year = {2019},
isbn = {978-3-030-31320-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31321-0_39},
doi = {10.1007/978-3-030-31321-0_39},
abstract = {Orange peel effect, the wavy appearance on the surface, is one of the frequently encountered defects on the painted injection moulded parts. In this work, a method for evaluation and classification of the orange peel effect on a black-painted high-gloss surface using image processing and frequency analysis is presented. A monochrome camera is used to acquire images from the surface of the part, while an LED-bar is illuminating it. Because the part is complex shaped, in order to inspect the whole surface, a robotic manipulator is used to handle the part in front of the camera. After taking images, the region of interest (the region in the image illuminated by the light source) is selected manually. Based on the result of the image processing and frequency analysis assessing the waviness of the ROI, a score to evaluate and classify the intensity of the orange peel effect is calculated. Finally, the outcomes of this method are compared with the subjective evaluation of the experts, in order to examine the reliability of the evaluation method.},
booktitle = {Pattern Recognition and Image Analysis: 9th Iberian Conference, IbPRIA 2019, Madrid, Spain, July 1–4, 2019, Proceedings, Part II},
pages = {453–464},
numpages = {12},
keywords = {Surface inspection, Orange peel effect, Image processing},
location = {Madrid, Spain}
}

@article{10.1016/j.procs.2017.09.066,
author = {Mehdiyev, Nijat and Lahann, Johannes and Emrich, Andreas and Enke, David and Fettke, Peter and Loos, Peter},
title = {Time Series Classification using Deep Learning for Process Planning},
year = {2017},
issue_date = {November 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {114},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2017.09.066},
doi = {10.1016/j.procs.2017.09.066},
abstract = {Multivariate time series classification has been broadly applied in diverse domains over the past few decades. However, before applying the classification algorithms, the vast majority of current studies extract hand-engineered features that are assumed to detect local patterns in the time series. Therefore, the efficiency and precision of these classification approaches are heavily dependent on the quality of variables defined by domain experts. Recent improvements in the deep learning domain offer opportunities to avoid such an intensive hand-crafted feature engineering which is particularly important for managing the processes based on time-series data obtained from various sensor networks. In our paper, we propose a framework to extract the features in an unsupervised (or self-supervised) manner using deep learning, particularly stacked LSTM Autoencoder Networks. The compressed representation of the time-series data obtained from LSTM Autoencoders are then provided to Deep Feedforward Neural Networks for classification. We apply the proposed framework on sensor time series data from the process industry to detect the quality of the semi-finished products and accordingly predict the next production process step. To validate the efficiency of the proposed approach, we used real-world data from the steel industry.},
journal = {Procedia Comput. Sci.},
month = nov,
pages = {242–249},
numpages = {8},
keywords = {Time Series Classification, Steel Surface Defect Detection, Process Industry, Deep Learning}
}

@inproceedings{10.1109/IECON43393.2020.9255236,
author = {Verma, Sagar and Henwood, Nicolas and Castella, Marc and Jebai, Al Kassem and Pesquet, Jean-Christophe},
title = {Neural Networks based Speed-Torque Estimators for Induction Motors and Performance Metrics},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON43393.2020.9255236},
doi = {10.1109/IECON43393.2020.9255236},
abstract = {This paper focuses on the quantitative analysis of deep neural networks used in data-driven modeling of induction motor dynamics. With the availability of a large amount of data generated by industrial sensor networks, it is now possible to train deep neural networks. Recently researchers have started exploring the usage of such networks for physics modeling, online control, monitoring, and fault prediction in induction motor operations. We consider the problem of estimating speed and torque from currents and voltages of an induction motor. Neural networks provide quite good performance for this task when analysed from a machine learning perspective using standard metrics. We show, however, that there are some caveats in using machine learning metrics to analyze a neural network model when applied to induction motor problems. Given the mission- critical nature of induction motor operations, the performance of neural networks has to be validated from an electrical engineering point of view. To this end, we evaluate several traditional neural network architectures and recent state of the art architectures on dynamic and quasi-static benchmarks using electrical engineering metrics.},
booktitle = {IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society},
pages = {495–500},
numpages = {6},
location = {Singapore, Singapore}
}

@article{10.1007/s11063-017-9703-6,
author = {Ding, Sha and Chen, Zhi and Zhao, Shi-Yuan and Lin, Tao},
title = {Pruning the Ensemble of ANN Based on Decision Tree Induction},
year = {2018},
issue_date = {August    2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {48},
number = {1},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-017-9703-6},
doi = {10.1007/s11063-017-9703-6},
abstract = {Ensemble learning is a powerful approach for achieving more accurate predictions compared with single classifier. However, this powerful classification ability is achieved at the expense of heavy storage requirements and computational burdens on the ensemble. Ensemble pruning is a crucial step for the reduction of the predictive overhead without worsening the performance of original ensemble. This paper suggests an efficient and effective ordering-based ensemble pruning based on the induction of decision tree. The suggested method maps the dataset and base classifiers to a new dataset where the ensemble pruning can be transformed to a feature selection problem. Furthermore, a set of accurate, diverse and complementary base classifiers can be selected by the induction of decision tree. Moreover, an evaluation function that deliberately favors the candidate sub-ensembles with an improved performance in classifying low margin instances has also been designed. The comparative experiments on 24 benchmark datasets demonstrate the effectiveness of our proposed method.},
journal = {Neural Process. Lett.},
month = aug,
pages = {53–70},
numpages = {18},
keywords = {Ordering-based ensemble pruning, Neural network ensemble, Margin distribution, Diversity, Decision tree induction}
}

@inproceedings{10.1145/3340482.3342742,
author = {Borg, Markus and Svensson, Oscar and Berg, Kristian and Hansson, Daniel},
title = {SZZ unleashed: an open implementation of the SZZ algorithm - featuring example usage in a study of just-in-time bug prediction for the Jenkins project},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340482.3342742},
doi = {10.1145/3340482.3342742},
abstract = {Machine learning applications in software engineering often rely on detailed information about bugs. While issue trackers often contain information about when bugs were fixed, details about when they were introduced to the system are often absent. As a remedy, researchers often rely on the SZZ algorithm as a heuristic approach to identify bug-introducing software changes. Unfortunately, as reported in a recent systematic literature review, few researchers have made their SZZ implementations publicly available. Consequently, there is a risk that research effort is wasted as new projects based on SZZ output need to initially reimplement the approach. Furthermore, there is a risk that newly developed (closed source) SZZ implementations have not been properly tested, thus conducting research based on their output might introduce threats to validity. We present SZZ Unleashed, an open implementation of the SZZ algorithm for git repositories. This paper describes our implementation along with a usage example for the Jenkins project, and conclude with an illustrative study on just-in-time bug prediction. We hope to continue evolving SZZ Unleashed on GitHub, and warmly invite the community to contribute.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
pages = {7–12},
numpages = {6},
keywords = {mining software repositories, issue tracking, defect prediction, SZZ},
location = {Tallinn, Estonia},
series = {MaLTeSQuE 2019}
}

@article{10.1016/j.neunet.2019.08.018,
author = {Shukla, Sanyam and Raghuwanshi, Bhagat Singh},
title = {Online sequential class-specific extreme learning machine for binary imbalanced learning},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {119},
number = {C},
issn = {0893-6080},
url = {https://doi.org/10.1016/j.neunet.2019.08.018},
doi = {10.1016/j.neunet.2019.08.018},
journal = {Neural Netw.},
month = nov,
pages = {235–248},
numpages = {14},
keywords = {Classification, Online sequential class-specific extreme learning machine, Imbalanced learning, Extreme learning machine}
}

@inproceedings{10.5555/2818754.2818850,
author = {Ghotra, Baljinder and McIntosh, Shane and Hassan, Ahmed E.},
title = {Revisiting the impact of classification techniques on the performance of defect prediction models},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Defect prediction models help software quality assurance teams to effectively allocate their limited resources to the most defect-prone software modules. A variety of classification techniques have been used to build defect prediction models ranging from simple (e.g., logistic regression) to advanced techniques (e.g., Multivariate Adaptive Regression Splines (MARS)). Surprisingly, recent research on the NASA dataset suggests that the performance of a defect prediction model is not significantly impacted by the classification technique that is used to train it. However, the dataset that is used in the prior study is both: (a) noisy, i.e., contains erroneous entries and (b) biased, i.e., only contains software developed in one setting. Hence, we set out to replicate this prior study in two experimental settings. First, we apply the replicated procedure to the same (known-to-be noisy) NASA dataset, where we derive similar results to the prior study, i.e., the impact that classification techniques have appear to be minimal. Next, we apply the replicated procedure to two new datasets: (a) the cleaned version of the NASA dataset and (b) the PROMISE dataset, which contains open source software developed in a variety of settings (e.g., Apache, GNU). The results in these new datasets show a clear, statistically distinct separation of groups of techniques, i.e., the choice of classification technique has an impact on the performance of defect prediction models. Indeed, contrary to earlier research, our results suggest that some classification techniques tend to produce defect prediction models that outperform others.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {789–800},
numpages = {12},
location = {Florence, Italy},
series = {ICSE '15}
}

@article{10.1007/s00500-019-03757-2,
author = {Tsai, Cheng-Jung},
title = {New feature selection and voting scheme to improve classification accuracy},
year = {2019},
issue_date = {Nov 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {22},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-019-03757-2},
doi = {10.1007/s00500-019-03757-2},
abstract = {Classification is a classic technique employed in data mining. Many ensemble learning methods have been introduced to improve the predictive accuracy of classification. A typical ensemble learning method consists of three steps: selection, building, and integration. Of the three steps, the first and third significantly affect the predictive accuracy of the classification. In this paper, we propose a new selection and integration scheme. Our method can improve the accuracy of subtrees and maintain their diversity. Through a new voting scheme, the predictive accuracy of ensemble learning is improved. We also theoretically analyzed the selection and integration steps of our method. The results of experimental analyses show that our method can achieve better accuracy than two state-of-the-art tree-based ensemble learning approaches.},
journal = {Soft Comput.},
month = nov,
pages = {12017–12030},
numpages = {14},
keywords = {Voting, Feature selection, Ensemble learning, Decision tree, Classification, Data mining}
}

@inproceedings{10.5555/1345530.1345608,
author = {Yi, Jaeyoung and Kim, Kang-ho and Jung, Sung-Hwan},
title = {Lens Inspection System Using LoG and Multi-level Thresholds},
year = {2007},
isbn = {9780769529301},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {An automatic defect detection system for the micro lens of a cellular phone was studied. We presented a defect detection method using LoG filter and multiple-level thresholds. We could find general defects such as scratch and even the stain defects that the detection might be difficult because of the low contrast between its background and a defect in the lens images. We did experiment using 50 spherical lens images with defects. As the experimental results, it showed the average recall and precision are about 92%, 77%, respectively in the case of sigma=2.5.},
booktitle = {Proceedings of the Sixth International Conference on Advanced Language Processing and Web Information Technology (ALPIT 2007)},
pages = {298–303},
numpages = {6},
keywords = {defect detection systemmicro lenscellular phone},
series = {ALPIT '07}
}

@article{10.3233/JIFS-201296,
author = {Gao, Xin Wen and Li, ShuaiQing and Jin, Bang Yang and Hu, Min and Ding, Wei},
title = {Intelligent crack damage detection system in shield tunnel using combination of retinanet and optimal adaptive selection},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-201296},
doi = {10.3233/JIFS-201296},
abstract = {With the large-scale construction of urban subways, the detection of tunnel cracks becomes particularly important. Due to the complexity of the tunnel environment, it is difficult for traditional tunnel crack detection algorithms to detect and segment such cracks quickly and accurately. The article presents an optimal adaptive selection model (RetinaNet-AOS) based on deep learning RetinaNet for semantic segmentation on tunnel crack images quickly and accurately. The algorithm uses the ROI merge mask to obtain a minimum detection area of the crack in the field of view. A scorer is designed to measure the effect of ROI region segmentation to achieve optimal results, and further optimized with a multi-dimensional classifier. The algorithm is compared with the standard detection based on RetinaNet algorithm with an optimal adaptive selection based on RetinaNet algorithm for different crack types. The results show that our crack detection algorithm not only addresses interference due to mash cracks, slender cracks, and water stains but also the false detection rate decreases from 25.5–35.5% to about 3.6%. Meanwhile, the experimental results focus on the execution time to be calculated on the algorithm, FCN, PSPNet, UNet. The algorithm gives better performance in terms of time complexity.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {4453–4469},
numpages = {17},
keywords = {ROI merge, optimal adaptive selection, retinanet, deep learning, Crack detection}
}

@inproceedings{10.1145/2003653.2003658,
author = {Wang, Fan and Yuan, Chang and Xu, Xinyu and van Beek, Peter},
title = {Supervised and semi-supervised online boosting tree for industrial machine vision application},
year = {2011},
isbn = {9781450308328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2003653.2003658},
doi = {10.1145/2003653.2003658},
abstract = {Machine learning techniques are being used extensively for knowledge discovery and data mining in industrial inspection applications. Traditionally, all of the training samples are required to be presented for training a classifier at a batch mode. However, in most industrial inspection applications, only a small amount of training samples are available initially and larger amount of them become sequentially available during online prediction. In addition, data properties could be changing over time. We propose supervised and semi-supervised online learning with a Boosting Tree (BT) to adapt and evolve the classifier in an online fashion and thus accommodate new information that becomes available sequentially in industrial inspection applications. The supervised online BT can efficiently expand and update existing BTs to add new knowledge without time consuming batch re-training. The semi-supervised BT utilizes co-training to improve classification accuracy by making use of the information in the unlabeled samples and thus reduce the labeling burden of a human operator. We also proposed compact knowledge representation such that data can be fit into limited memory and a fixed computational complexity can be maintained.},
booktitle = {Proceedings of the Fifth International Workshop on Knowledge Discovery from Sensor Data},
pages = {43–51},
numpages = {9},
keywords = {online learning, defect detection, defect classification, boosting tree},
location = {San Diego, California},
series = {SensorKDD '11}
}

@inproceedings{10.1007/978-3-030-27272-2_5,
author = {Han, Xu and Yu, Haoran and Gu, Haisong},
title = {Visual Inspection with Federated Learning},
year = {2019},
isbn = {978-3-030-27271-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27272-2_5},
doi = {10.1007/978-3-030-27272-2_5},
abstract = {In industrial applications of AI, challenges for visual inspection include data shortage and security. In this paper, we propose a Federated Learning (FL) framework to address these issues. This method is incorporated with our novel DataonomySM approach which can overcome the limited size of industrial dataset in each inspection task. The models pre-trained in the server can continuously and regularly update, and help each client upgrade its inspection model over time. The FL approach only requires clients to send to the server certain information derived from raw images, and thus does not sacrifice data security. Some preliminary tests are done to examine the workability of the proposed framework. This study is expected to bring the field of automated inspection to a new level of security, reliability, and efficiency, and to unlock significant potentials of deep learning applications.},
booktitle = {Image Analysis and Recognition: 16th International Conference, ICIAR 2019, Waterloo, ON, Canada, August 27–29, 2019, Proceedings, Part II},
pages = {52–64},
numpages = {13},
keywords = {DataonomySM, Federated Learning, Visual Inspection},
location = {Waterloo, ON, Canada}
}

@article{10.1016/j.image.2021.116392,
author = {Shu, Xin and Song, Zhigang and Shi, Jinlong and Huang, Shucheng and Wu, Xiao-Jun},
title = {Multiple channels local binary pattern for color texture representation and classification},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {98},
number = {C},
issn = {0923-5965},
url = {https://doi.org/10.1016/j.image.2021.116392},
doi = {10.1016/j.image.2021.116392},
journal = {Image Commun.},
month = oct,
numpages = {11},
keywords = {Multiple channels local binary pattern, Local binary pattern, Color texture feature, Texture classification, Texture descriptor}
}

@article{10.1007/s11042-017-5107-x,
author = {Singh, Sanjay Kumar and Singh, Amit Kumar and Kumar, Basant and Sarkar, Subir Kumar and Arya, Karm Veer},
title = {Guest Editorial: Multimedia for Predictive Analytics},
year = {2018},
issue_date = {April     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {77},
number = {7},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-017-5107-x},
doi = {10.1007/s11042-017-5107-x},
journal = {Multimedia Tools Appl.},
month = apr,
pages = {9189–9201},
numpages = {13}
}

@inproceedings{10.1109/ISCA45697.2020.00045,
author = {Reddi, Vijay Janapa and Cheng, Christine and Kanter, David and Mattson, Peter and Schmuelling, Guenther and Wu, Carole-Jean and Anderson, Brian and Breughe, Maximilien and Charlebois, Mark and Chou, William and Chukka, Ramesh and Coleman, Cody and Davis, Sam and Deng, Pan and Diamos, Greg and Duke, Jared and Fick, Dave and Gardner, J. Scott and Hubara, Itay and Idgunji, Sachin and Jablin, Thomas B. and Jiao, Jeff and John, Tom St. and Kanwar, Pankaj and Lee, David and Liao, Jeffery and Lokhmotov, Anton and Massa, Francisco and Meng, Peng and Micikevicius, Paulius and Osborne, Colin and Pekhimenko, Gennady and Rajan, Arun Tejusve Raghunath and Sequeira, Dilip and Sirasao, Ashish and Sun, Fei and Tang, Hanlin and Thomson, Michael and Wei, Frank and Wu, Ephrem and Xu, Lingjie and Yamada, Koichi and Yu, Bing and Yuan, George and Zhong, Aaron and Zhang, Peizhao and Zhou, Yuchen},
title = {MLPerf inference benchmark},
year = {2020},
isbn = {9781728146614},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISCA45697.2020.00045},
doi = {10.1109/ISCA45697.2020.00045},
abstract = {Machine-learning (ML) hardware and software system demand is burgeoning. Driven by ML applications, the number of different ML inference systems has exploded. Over 100 organizations are building ML inference chips, and the systems that incorporate existing models span at least three orders of magnitude in power consumption and five orders of magnitude in performance; they range from embedded devices to data-center solutions. Fueling the hardware are a dozen or more software frameworks and libraries. The myriad combinations of ML hardware and ML software make assessing ML-system performance in an architecture-neutral, representative, and reproducible manner challenging. There is a clear need for industry-wide standard ML benchmarking and evaluation criteria. MLPerf Inference answers that call. In this paper, we present our benchmarking method for evaluating ML inference systems. Driven by more than 30 organizations as well as more than 200 ML engineers and practitioners, MLPerf prescribes a set of rules and best practices to ensure comparability across systems with wildly differing architectures. The first call for submissions garnered more than 600 reproducible inference-performance measurements from 14 organizations, representing over 30 systems that showcase a wide range of capabilities. The submissions attest to the benchmark's flexibility and adaptability.},
booktitle = {Proceedings of the ACM/IEEE 47th Annual International Symposium on Computer Architecture},
pages = {446–459},
numpages = {14},
keywords = {machine learning, inference, benchmarking},
location = {Virtual Event},
series = {ISCA '20}
}

@inproceedings{10.5555/2417502.2418608,
author = {Gao, Yu and Yang, Tianshe and Feng, Junhua and Xu, Minqiang},
title = {A Neural Network Approach for Satellite Telemetry Data Prediction},
year = {2012},
isbn = {9780769548067},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Fault prediction is the core content and crucial technology for health monitoring of the in-orbit satellite, and predicting the future trend of satellite telemetry data is the prerequisite and basis for fault prediction. In this paper, a neural network approach for satellite telemetry data prediction is presented. By taking advantage of the self learning, self-adapting and nonlinear approximate ability, a three-layer BP neural network is used to establish the prediction model of satellite telemetry data. The BP neural network model has a rapid velocity of convergence and a high precision of prediction. The experimental results show that the method is efficient and practical for telemetry data prediction of the in-orbit satellite.},
booktitle = {Proceedings of the 2012 International Conference on Electronics, Communications and Control},
pages = {150–153},
numpages = {4},
keywords = {time series prediction, telemetry data, satellite, fault prediction, BP neural network},
series = {ICECC '12}
}

@inproceedings{10.1145/2979779.2979783,
author = {Maheshwari, Suchi and Agarwal, Sonali},
title = {Three-way decision based Defect Prediction for Object Oriented Software},
year = {2016},
isbn = {9781450342131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2979779.2979783},
doi = {10.1145/2979779.2979783},
abstract = {Early prediction of defective software module plays critical role in the software project development to reduce the overall development time, budgets and increases the customer satisfaction. The bug prediction based on two-way classification method classifies the software module as defective or non-defective. This method provides good accuracy measure but this metric is not sufficient in case if misclassification cost is concerned. Classifying the defective module as non-defective will lead to higher cost of entire software project at the end. In this study, three-way decision based classification method and Random Forest ensemble are used to predict the defect in Object Oriented Software to reduce the misclassification cost which will lead to avoid the cost overrun. The eclipse bug prediction dataset is used and experimental results show that the decision cost is reduced and accuracy is increased using our proposed method.},
booktitle = {Proceedings of the International Conference on Advances in Information Communication Technology &amp; Computing},
articleno = {4},
numpages = {6},
keywords = {Three-way decision, Software defect prediction, Random Forest, Na\"{\i}ve Bayes, Eclipse Bug Prediction dataset},
location = {Bikaner, India},
series = {AICTC '16}
}

@article{10.1007/s10845-016-1275-1,
author = {Kuo, Chung-Feng Jeffrey and Tung, Chun-Ping and Weng, Wei-Han},
title = {Applying the support vector machine with optimal parameter design into an automatic inspection system for classifying micro-defects on surfaces of light-emitting diode chips},
year = {2019},
issue_date = {Feb 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {2},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-016-1275-1},
doi = {10.1007/s10845-016-1275-1},
abstract = {This study discusses the optimal design of an automatic inspection system for processing light-emitting diode (LED) chips. Based on support vector machine (SVM) with optimal theory, the classifications of micro-defects in light area and electrode area on the chip surface, and develop a robust classification module will be analyzed. In order to design the SVM-based defect classification system effectively, the multiple quality characteristics parameter design. The Taguchi method is used to improve the classifier design, and meanwhile, PCA is used for analysis of multiple quality characteristics on influence of characteristics on multi-class intelligent classifier, to regularly select effective features, and reduce classification data. Aim to reduce the classification data and dimensions, and with features containing higher score of principal component as decision tree support vector machine classification module training basis, the optimal multi-class support vector machine model was established for subdivision of micro-defects of electrode area and light area. The comparison of traditional binary structure support vector machine and neural network classifier was conducted. The overall recognition rate of the inspection system herein was more than 96%, and the classification speed for 500 micro-defects was only 3&nbsp;s. It is clear that we have effectively established an inspection process, which is highly effective even under disturbance. The process can realize the subdivision of micro-defects, and with quick classification, high accuracy, and high stability. It is applicable to precise LED detection and can be used for accurate inspection of LED of mass production effectively to replace visual inspection, economizing on labor cost.},
journal = {J. Intell. Manuf.},
month = feb,
pages = {727–741},
numpages = {15},
keywords = {Multi-class support vector machine model, Decision tree support vector machine, Principal component analysis, Taguchi methods}
}

@inproceedings{10.1007/978-3-030-96600-3_13,
author = {B\u{a}dic\u{a}, Amelia and B\u{a}dic\u{a}, Costin and Bolanowski, Marek and Fidanova, Stefka and Ganzha, Maria and Harizanov, Stanislav and Ivanovic, Mirjana and Lirkov, Ivan and Paprzycki, Marcin and Paszkiewicz, Andrzej and Tomczyk, Kacper},
title = {Cascaded Anomaly Detection with Coarse Sampling in Distributed Systems},
year = {2021},
isbn = {978-3-030-96599-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-96600-3_13},
doi = {10.1007/978-3-030-96600-3_13},
abstract = {In this contribution, analysis of usefulness of selected parameters of a distributed information system, for early detection of anomalies in its operation, is considered. Use of statistical analysis, or machine learning (ML), can result in high computational complexity and requirement to transfer large amount of data from the monitored system’s elements. This enforces monitoring of only major components (e.g., access link, key machine components, filtering of selected traffic parameters). To overcome this limitation, a model in which an arbitrary number of elements could be monitored, using microservices, is proposed. For this purpose, it is necessary to determine the sampling threshold value and the influence of sampling coarseness on the quality of anomaly detection. To validate the proposed approach, the ST4000DM000 (Disk failure) and CICIDS2017 (DDoS) datasets were used, to study effects of limiting the number of parameters and the sampling rate reduction on the detection performance of selected classic ML algorithms. Moreover, an example of microservice architecture for coarse network anomaly detection for a network node is presented.},
booktitle = {Big-Data-Analytics in Astronomy, Science, and Engineering: 9th International Conference on Big Data Analytics, BDA 2021, Virtual Event, December 7–9, 2021, Proceedings},
pages = {181–200},
numpages = {20},
keywords = {Computer network management, Complex distributed system, Anomaly prediction, Anomaly detection}
}

@inproceedings{10.1145/3437963.3441659,
author = {Pang, Guansong and Cao, Longbing and Aggarwal, Charu},
title = {Deep Learning for Anomaly Detection: Challenges, Methods, and Opportunities},
year = {2021},
isbn = {9781450382977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437963.3441659},
doi = {10.1145/3437963.3441659},
abstract = {In this tutorial we aim to present a comprehensive survey of the advances in deep learning techniques specifically designed for anomaly detection (deep anomaly detection for short). Deep learning has gained tremendous success in transforming many data mining and machine learning tasks, but popular deep learning techniques are inapplicable to anomaly detection due to some unique characteristics of anomalies, e.g., rarity, heterogeneity, boundless nature, and prohibitively high cost of collecting large-scale anomaly data. Through this tutorial, audiences would gain a systematic overview of this area, learn the key intuitions, objective functions, underlying assumptions, advantages and disadvantages of different categories of state-of-the-art deep anomaly detection methods, and recognize its broad real-world applicability in diverse domains. We also discuss what challenges the current deep anomaly detection methods can address and envision this area from multiple different perspectives. Any audience who may be interested in deep learning, anomaly/outlier/novelty detection, out-of-distribution detection, representation learning with limited labeled data, and self-supervised representation learning would find it very helpful in attending this tutorial. Researchers and practitioners in finance, cybersecurity, healthcare would also find the tutorial helpful in practice.},
booktitle = {Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
pages = {1127–1130},
numpages = {4},
keywords = {representation learning, outlier detection, novelty detection, neural networks, deep learning, anomaly detection},
location = {Virtual Event, Israel},
series = {WSDM '21}
}

@article{10.1016/j.cl.2017.12.001,
author = {Adesina, Opeyemi O. and Lethbridge, Timothy C. and Som\'{e}, St\'{e}phane S. and Abdelzad, Vahdat and Belle, Alvine Boaye},
title = {Improving formal analysis of state machines with particular emphasis on and-cross transitions},
year = {2018},
issue_date = {Dec 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {54},
number = {C},
issn = {1477-8424},
url = {https://doi.org/10.1016/j.cl.2017.12.001},
doi = {10.1016/j.cl.2017.12.001},
journal = {Comput. Lang. Syst. Struct.},
month = dec,
pages = {544–585},
numpages = {42},
keywords = {Software quality assurance, Model checking, Model-driven engineering, Umple, Cross transitions, State diagrams}
}

@inproceedings{10.1007/978-3-662-44415-3_24,
author = {Hajizadeh, Siamak and Li, Zili and Dollevoet, Rolf P. and Tax, David M.},
title = {Evaluating Classification Performance with only Positive and Unlabeled Samples},
year = {2014},
isbn = {9783662444146},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-662-44415-3_24},
doi = {10.1007/978-3-662-44415-3_24},
abstract = {Testing binary classifiers usually requires a test set with labeled positive and negative examples. In many real-world applications however, some positive objects are manually labeled while negative objects are not labeled explicitly. For instance in the detection of defects in a large collection of objects, the most obvious defects are normally found with ease, while normal-looking objects may just be ignored. In this situation, datasets will consist of only positive and unlabeled samples. Here we propose a measure to estimate the performance of a classifier with test sets lacking labeled negative examples. Experiments are performed to show the effect of several criteria on the accuracy of our estimation, including that of the assumption of "random sampling of the labeled positives". We put the measure into use for classification of real-world defect detection data with no available validation sets.},
booktitle = {Proceedings of the Joint IAPR International Workshop on Structural, Syntactic, and Statistical Pattern Recognition - Volume 8621},
pages = {233–242},
numpages = {10},
keywords = {unlabeled examples, binary classification, Classifier performance measure},
location = {Joensuu, Finland},
series = {S+SSPR 2014}
}

@inproceedings{10.1145/3472735.3474458,
author = {Boutaba, Raouf and Shahriar, Nashid and Salahuddin, Mohammad A. and Chowdhury, Shihabur R. and Saha, Niloy and James, Alexander},
title = {AI-driven Closed-loop Automation in 5G and beyond Mobile Networks},
year = {2021},
isbn = {9781450386340},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472735.3474458},
doi = {10.1145/3472735.3474458},
abstract = {The 5th Generation (5G) mobile networks support a wide range of services that impose diverse and stringent QoS requirements. This will be further exacerbated with the evolution towards 6th Generation mobile networks. Inevitably, 5G and beyond mobile networks must provide stricter, differentiated QoS guarantees to meet the increasing demands of future applications, which cannot be satisfied with traditional human-in-the-loop service orchestration and network management approaches. In this paper, we lay out our vision for closed-loop service orchestration and network management of 5G and beyond mobile networks. We extend the MAPE (i.e., monitor, analyze, plan, and execute) control loop to facilitate closed-loop automation, and discuss the quintessential role of Artificial Intelligence/Machine Learning in its realization. We also instigate open research challenges for closed-loop automation of 5G and beyond mobile networks.},
booktitle = {Proceedings of the 4th FlexNets Workshop on Flexible Networks Artificial Intelligence Supported Network Flexibility and Agility},
pages = {1–6},
numpages = {6},
keywords = {machine learning, closed-loop orchestration and management, artificial intelligence, 5G},
location = {Virtual Event, USA},
series = {FlexNets '21}
}

@article{10.1016/j.infsof.2009.11.001,
author = {Rabiser, Rick and Gr\"{u}nbacher, Paul and Dhungana, Deepak},
title = {Requirements for product derivation support: Results from a systematic literature review and an expert survey},
year = {2010},
issue_date = {March, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2009.11.001},
doi = {10.1016/j.infsof.2009.11.001},
abstract = {Context: An increasing number of publications in product line engineering address product derivation, i.e., the process of building products from reusable assets. Despite its importance, there is still no consensus regarding the requirements for product derivation support. Objective: Our aim is to identify and validate requirements for tool-supported product derivation. Method: We identify the requirements through a systematic literature review and validate them with an expert survey. Results: We discuss the resulting requirements and provide implementation examples from existing product derivation approaches. Conclusions: We conclude that key requirements are emerging in the research literature and are also considered relevant by experts in the field.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {324–346},
numpages = {23},
keywords = {Systematic literature review, Software product line, Product line engineering, Product derivation}
}

@inproceedings{10.1007/978-3-030-00776-8_37,
author = {Zhang, Yang and Song, Jia and Zhang, Huiming and He, Jingwu and Guo, Yanwen},
title = {Tiny Surface Defects on Small Ring Parts Using Normal Maps},
year = {2018},
isbn = {978-3-030-00775-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-00776-8_37},
doi = {10.1007/978-3-030-00776-8_37},
abstract = {Detection of tiny surface defects on small ring parts remains challenging due to the unnoticeable visual features of such defects and the interference of small surface scratches. This paper proposes a novel method for detecting tiny surface defects based on normal maps of metal parts. To better characterize features of tiny defects and differentiate them from small scratches, we recover the normal map of the metal part through analyzing its directional reflections obtained with our specifically designed directional light units. Based on the normal map, a cascaded detector trained by the AdaBoost approach combined with the joint features and fast feature pyramid is used to localize the defects, achieving fast and accurate detection of tiny surface defects. The proposed method can achieve high detection accuracy with extremely fast speed, only 23&nbsp;ms per metal part, and comparisons against other methods show our superiority.},
booktitle = {Advances in Multimedia Information Processing – PCM 2018: 19th Pacific-Rim Conference on Multimedia, Hefei, China, September 21-22, 2018, Proceedings, Part I},
pages = {403–413},
numpages = {11},
keywords = {Defect detection, Tiny surface defect, Normal maps, Combined light units},
location = {Hefei, China}
}

@article{10.3233/JIFS-17888,
author = {Zhai, Junhai and Zhang, Sufang},
title = {Three-way decisions model based on rough fuzzy set},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {34},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-17888},
doi = {10.3233/JIFS-17888},
abstract = {Three-way decisions model proposed by Yao gives a semantic interpretation of positive region, negative region and boundary region. This model was developed in the framework of classical rough set, the approached target concept is a crisp set, the employed knowledge is a equivalence relation. In this paper, we extend the three-way decisions model to rough fuzzy set. Specifically, the target concept is extended to a fuzzy set, while the used knowledge is also a equivalence relation. An example is given to illustrate the computation processes of the proposed three-way decisions model. The extended model can deal with the problems described by fuzzy decision tables with symbolic-valued conditional attributes and fuzzy decision attributes.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {2051–2059},
numpages = {9},
keywords = {fuzzy set, rough fuzzy set, rough set, Three-way decisions}
}

@inproceedings{10.1145/3282286.3282300,
author = {Liu, Zhoufeng and Liu, Shanliang and Li, Chunlei and Ding, Shumin and Dong, Yan},
title = {Fabric Defects Detection based on SSD},
year = {2018},
isbn = {9781450363860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282286.3282300},
doi = {10.1145/3282286.3282300},
abstract = {In this paper, Fabric defect detection is a challenging task because of the complex texture. Deep learning technology provide a promising solution. As a kind of deep learning object detection model. Single Shot Multibox Detector(SSD)achieves good detection performance. However, the original SSD model may fail to detect the small objects. In this paper, we proposed a novel SSD model for fabric defect detection. Experimental results showed that the improved SSD model can accurately detect the defect region.},
booktitle = {Proceedings of the 2nd International Conference on Graphics and Signal Processing},
pages = {74–78},
numpages = {5},
keywords = {SSD, Object detection, Fabric defect, Deep learning},
location = {Sydney, NSW, Australia},
series = {ICGSP '18}
}

@article{10.1016/j.comcom.2021.09.005,
author = {Zhang, SuYu and Lagutkina, Margarita and Akpinar, Kevser Ovaz and Akpinar, Mustafa},
title = {Improving performance and data transmission security in VANETs},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {180},
number = {C},
issn = {0140-3664},
url = {https://doi.org/10.1016/j.comcom.2021.09.005},
doi = {10.1016/j.comcom.2021.09.005},
journal = {Comput. Commun.},
month = dec,
pages = {126–133},
numpages = {8},
keywords = {5G, Machine learning, Support Vector Machine, Big data, Vehicular ad hoc networks}
}

@article{10.1016/j.eswa.2007.10.033,
author = {Chang, Chuan-Yu and Li, ChunHsi and Chang, Jia-Wei and Jeng, MuDer},
title = {An unsupervised neural network approach for automatic semiconductor wafer defect inspection},
year = {2009},
issue_date = {January, 2009},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {36},
number = {1},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2007.10.033},
doi = {10.1016/j.eswa.2007.10.033},
abstract = {Semiconductor wafer defect inspection is an important process before die packaging. The defective regions are usually identified through visual judgment with the aid of a scanning electron microscope. Dozens of people visually check wafers and hand-mark their defective regions. Consequently, potential misjudgment may be introduced due to human fatigue. In addition, the process can incur significant personnel costs. Prior work has proposed automated visual wafer defect inspection that is based on supervised neural networks. Since it requires learned patterns specific to each application, its disadvantage is the lack of product flexibility. Self-organizing neural networks (SONNs) have been proven to have the capabilities of unsupervised auto-clustering. In this paper, an automatic wafer inspection system based on a self-organizing neural network is proposed. Based on real-world data, experimental results show, with good performance, that the proposed method successfully identifies the defective regions on wafers.},
journal = {Expert Syst. Appl.},
month = jan,
pages = {950–958},
numpages = {9},
keywords = {Wafer inspection, Unsupervised learning, Self-organizing neural network}
}

@article{10.1007/s00138-021-01195-5,
author = {Mery, Domingo},
title = {Aluminum Casting Inspection using Deep Object Detection Methods and Simulated Ellipsoidal Defects},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {3},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-021-01195-5},
doi = {10.1007/s00138-021-01195-5},
abstract = {In the automotive industry, light-alloy aluminum castings are an important element for determining roadworthiness. X-ray testing with computer vision is used during automated inspections of aluminum castings to identify defects inside of the test object that are not visible to the naked eye. In this article, we evaluate eight state-of-the-art deep object detection methods (based on YOLO, RetinaNet, and EfficientDet) that are used to detect aluminum casting defects. We propose a training strategy that uses a low number of defect-free X-ray images of castings with superimposition of simulated defects (avoiding manual annotations). The proposed solution is simple, effective, and fast. In our experiments, the YOLOv5s object detector was trained in just 2.5 h, and the performance achieved on the testing dataset (with only real defects) was very high (average precision was 0.90 and the F1 factor was 0.91). This method can process 90 X-ray images per second, i.e.&nbsp;,this solution can be used to help human operators conduct real-time inspections. The code and datasets used in this paper have been uploaded to a public repository for future studies. It is clear that deep learning-based methods will be used more by the aluminum castings industry in the coming years due to their high level of effectiveness. This paper offers an academic contribution to such efforts.},
journal = {Mach. Vision Appl.},
month = may,
numpages = {16},
keywords = {Deep learning, X-ray testing, Aluminum inspection, Object detection}
}

@article{10.1155/2018/4832972,
author = {Xu, Xinjun and Lei, Yang and Yang, Feng and Lanza-Guti\'{e}rrez, Jos\'{e} M.},
title = {Railway Subgrade Defect Automatic Recognition Method Based on Improved Faster R-CNN},
year = {2018},
issue_date = {2018},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2018},
issn = {1058-9244},
url = {https://doi.org/10.1155/2018/4832972},
doi = {10.1155/2018/4832972},
abstract = {Railway subgrade defect is the serious threat to train safety. Vehicle-borne GPR method has become the main railway subgrade detection technology with its advantages of rapidness and nondestructiveness. However, due to the large amount of detection data and the variety in defect shape and size, defect recognition is a challenging task. In this work, the method based on deep learning is proposed to recognize defects from the ground penetrating radar (GPR) profile of subgrade detection data. Based on the Faster R-CNN framework, the improvement strategies of feature cascade, adversarial spatial dropout network (ASDN), Soft-NMS, and data augmentation have been integrated to improve recognition accuracy, according to the characteristics of subgrade defects. The experimental results indicates that compared with traditional SVM+HOG method and the baseline Faster R-CNN, the improved model can achieve better performance. The model robustness is demonstrated by a further comparison experiment of various defect types. In addition, the improvements to model performance of each improvement strategy are verified by an ablation experiment of improvement strategies. This paper tries to explore the new thinking for the application of deep learning method in the field of railway subgrade defect recognition.},
journal = {Sci. Program.},
month = jan,
numpages = {12}
}

@article{10.1007/s11042-020-10084-4,
author = {Shakoor, Mohammad Hossein and Boostani, Reza},
title = {Noise robust and rotation invariant texture classification based on local distribution transform},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {6},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-020-10084-4},
doi = {10.1007/s11042-020-10084-4},
abstract = {Applying local binary pattern (LBP) to images with uniform distribution leads to generate discriminative features; however, the distribution of all images is not necessarily uniform. The distribution of an image can be uniformzed if it passes through its cumulative distribution function (CDF), while estimation of CDF is highly sensitive to additive noises. In this paper, we propose a novel transform, which locally uniformize all patches of an image and approximately estimate a robust CDF. The proposed local distribution transform (LDT) generates continuous values and by quantizing them into discrete values, a histogram of features is constructed. We have fused the LDT features to the features of rotation invariant LBP and local variance (VAR) in order to provide a rich set of robust-to-noise features, which can detect both uniform and non-uniform patterns. The performance of the proposed LDT-LBP_VAR is assessed over a wide range of datasets like Outex, UIUC, CUReT, Coral Reef, Virus and ORL. The datasets are also corrupted by additive Gaussian noise with different signal to noise ratio (SNR) and the empirical results demonstrate that the proposed hybrid features provide superior classification results (P &lt; 0.05) to the plenty of advanced descriptors over the datasets in both noise-free and noisy conditions.},
journal = {Multimedia Tools Appl.},
month = mar,
pages = {8639–8666},
numpages = {28},
keywords = {Noise robust descriptor, Texture classification, Local binary pattern, Local variance, Local distribution transform}
}

@article{10.1007/s10836-011-5220-0,
author = {Gon\c{c}alves, Luiz Fernando and Bosa, Jefferson Luiz and Balen, Tiago Roberto and Lubaszewski, Marcelo Soares and Schneider, Eduardo Luis and Henriques, Renato Ventura},
title = {Fault Detection, Diagnosis and Prediction in Electrical Valves Using Self-Organizing Maps},
year = {2011},
issue_date = {August    2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {4},
issn = {0923-8174},
url = {https://doi.org/10.1007/s10836-011-5220-0},
doi = {10.1007/s10836-011-5220-0},
abstract = {This paper presents a proactive maintenance scheme for fault detection, diagnosis and prediction in electrical valves. The proposed scheme is validated with a case study, considering a specific valve used for controlling the oil flow in a distribution network. The scheme is based in self-organizing maps, which perform fault detection and diagnosis, and temporal self-organizing maps for fault prediction. The adopted fault model considers deviations either in torque, in the valve's gate position or in the opening or closing time. The map which performs the fault detection, diagnosis and prediction, is trained with the energy spectral density information, obtained from the torque and position signals by applying the wavelet packet transform. These signals are provided by a mathematical model devised for the electrical valve. The training is performed by fault injection based on parameter deviations over this same mathematical model. The proposed system is embedded into an FPGA-based platform. Experimental results demonstrate the effectiveness of the proposed approaches.},
journal = {J. Electron. Test.},
month = aug,
pages = {551–564},
numpages = {14},
keywords = {Test of electromechanical systems, Self-organizing maps, Proactive maintenance, Fault prediction}
}

@inproceedings{10.1145/3483845.3483896,
author = {Liu, Mengxi and Li, Yingliang and Wang, Zheng},
title = {A propelled multiple fusion Deep Belief Network for weld defects detection},
year = {2021},
isbn = {9781450390453},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483845.3483896},
doi = {10.1145/3483845.3483896},
abstract = {With the characteristics including fuzzy edges, high image noise, low pixels and contrast, X-ray images of weld defect are difficult to be effectively recognized. Various well-known deep network is used for improving image recognition performance, so that researchers pay more attention on weld defects detection by using deep network with stack structure. However, such stack structure shows some disadvantages, such as inaccuracy recognition on confusion feature, low uncertainty-handling efficiency, time-consuming and complex computation. In this paper, a propelled multiple fusion Deep Belief Network (PMF-DBN) structure with Fuzzy Classifiers (FC) is created for weld defect classification and recognition. The proposed PMF-DBN enjoy both the ability of DBN neural representation and the of capability of fuzzy representation in order to meet the requirements of variant image feature processing. Meanwhile, instead of time-consuming fine-tuning training, the outputs feature data of each layer is fused in a propelled way, by which effective feature extraction can be achieved. Experiments on weld defects multi-classification demonstrate effectiveness of the PMF-DBN. Compared with the DBN, PMF-DBN has higher recognition accuracy and better fitting performance.},
booktitle = {Proceedings of the 2021 2nd International Conference on Control, Robotics and Intelligent System},
pages = {141–146},
numpages = {6},
keywords = {weld defect recognition, propelled multiple fusion, fuzzy classifiers},
location = {Qingdao, China},
series = {CCRIS '21}
}

@inproceedings{10.1145/3373509.3373534,
author = {Liu, Zhoufeng and Liu, Shanliang and Dong, Yan and He, Zhiyong and Li, Chunlei},
title = {Fabric Defects Detection based on Multi-Sources Features Fusion},
year = {2020},
isbn = {9781450376570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373509.3373534},
doi = {10.1145/3373509.3373534},
abstract = {For fabric object inspection, the traditional approaches (e.g., Low rank approximation and sparse representation) have achieved the excellent accuracy in some certain texture fabric, whereas some methods based on convolutional neural network have the advantage of higher efficiency and prime accuracy with various texture fabric. To furthermore improve the detection accuracy, in this paper, we propose a novel defect model based on transform learning. In the process of model training, both the multiple layer features of the image and the useful information of the source model are fused to meliorate the availability. Additionally, a novel training model called Multiple Sources Features Fusion (MSFF) is presented, which solve the situation of limited negative samples are available and demand to obtain fleet and precise quantification automatically for fabric image assessment. In this paper, we address this question quantitatively by comparing the performances of MSFF detection based on feature transfer network and Object Detection Network (ODN). And our proposed method improves Average Precision (AP) by more 5.9% relative to other result on TILDA-achieving an AP of 93.9%, and achieving an AP of 98.8% on ZYFD datasets, and false positive rate (FP) of 0.2%. Experimental results demonstrate the good performance in the defect detection for patterned fabric and more complex warp-knitted fabric.},
booktitle = {Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition},
pages = {100–105},
numpages = {6},
keywords = {transfer learning, multiple sources features fusion, deep neural network, Object detection},
location = {Beijing, China},
series = {ICCPR '19}
}

@article{10.5555/2873642.2873720,
author = {Hentech, Rim and Jenhani, Ilyes and Elouedi, Zied},
title = {Possibilistic AIRS induction from uncertain data},
year = {2016},
issue_date = {January   2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {1},
issn = {1432-7643},
abstract = {This paper presents a new approach in machine learning, especially, in supervised classification and reasoning under uncertainty. For many classification problems, uncertainty is often inherent in modeling applications and should be treated carefully and not rejected to make better decisions. Artificial immune recognition system (AIRS) is a well-known classifier that has provided good results with certain data. However, this method is not able to cope with uncertainty. To overcome this limitation, we propose a new classification approach combining the AIRS and possibility theory. The new approach is allowing to deal with uncertain attribute and also class values of training instances. The uncertainty is expressed via possibility distributions. Experimentations on real datasets from the U.C.I machine learning repository show good performances of the proposed approach.},
journal = {Soft Comput.},
month = jan,
pages = {3–17},
numpages = {15},
keywords = {Possibility theory, Classification under uncertainty, Artificial immune recognition system}
}

@inproceedings{10.1007/978-3-030-21290-2_42,
author = {Reinhartz-Berger, Iris and Shimshoni, Ilan and Abdal, Aviva},
title = {Behavior-Derived Variability Analysis: Mining Views for Comparison and Evaluation},
year = {2019},
isbn = {978-3-030-21289-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-21290-2_42},
doi = {10.1007/978-3-030-21290-2_42},
abstract = {The large variety of computerized solutions (software and information systems) calls for a systematic approach to their comparison and evaluation. Different methods have been proposed over the years for analyzing the similarity and variability of systems. These methods get artifacts, such as requirements, design models, or code, of different systems (commonly in the same domain), identify and calculate their similarities, and represent the variability in models, such as feature diagrams. Most methods rely on implementation considerations of the input systems and generate outcomes based on predefined, fixed strategies of comparison (referred to as variability views). In this paper, we introduce an approach for mining relevant views for comparison and evaluation, based on the input artifacts. Particularly, we equip SOVA – a Semantic and Ontological Variability Analysis method – with data mining techniques in order to identify relevant views that highlight variability or similarity of the input artifacts (natural language requirement documents). The comparison is done using entropy and Rand index measures. The method and its outcomes are evaluated on a case of three photo sharing applications.},
booktitle = {Advanced Information Systems Engineering: 31st International Conference, CAiSE 2019, Rome, Italy, June 3–7, 2019, Proceedings},
pages = {675–690},
numpages = {16},
keywords = {Software Product Line Engineering, Variability analysis, Requirements specifications, Feature diagrams},
location = {Rome, Italy}
}

@article{10.1016/j.compag.2010.11.006,
author = {Unay, Devrim and Gosselin, Bernard and Kleynen, Olivier and Leemans, Vincent and Destain, Marie-France and Debeir, Olivier},
title = {Original paper: Automatic grading of Bi-colored apples by multispectral machine vision},
year = {2011},
issue_date = {January, 2011},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {75},
number = {1},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2010.11.006},
doi = {10.1016/j.compag.2010.11.006},
abstract = {In this paper we present a novel application work for grading of apple fruits by machine vision. Following precise segmentation of defects by minimal confusion with stem/calyx areas on multispectral images, statistical, textural and geometric features are extracted from the segmented area. Using these features, statistical and syntactical classifiers are trained for two- and multi-category grading of the fruits. Results showed that feature selection provided improved performance by retaining only the important features, and statistical classifiers outperformed their syntactical counterparts. Compared to the state-of-the-art, our two-category grading solution achieved better recognition rates (93.5% overall accuracy). In this work we further provided a more realistic multi-category grading solution, where different classification architectures are evaluated. Our observations showed that the single-classifier architecture is computationally less demanding, while the cascaded one is more accurate.},
journal = {Comput. Electron. Agric.},
month = jan,
pages = {204–212},
numpages = {9},
keywords = {Multispectral images, Fruit grading, Feature selection, Feature extraction, Defect detection, Classification}
}

@article{10.1007/s00138-020-01142-w,
author = {Saeedi, Jamal and Dotta, Matteo and Galli, Andrea and Nasciuti, Adriano and Maradia, Umang and Boccadoro, Marco and Gambardella, Luca Maria and Giusti, Alessandro},
title = {Measurement and inspection of electrical discharge machined steel surfaces using deep neural networks},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {1},
issn = {0932-8092},
url = {https://doi.org/10.1007/s00138-020-01142-w},
doi = {10.1007/s00138-020-01142-w},
abstract = {We propose an industrial measurement and inspection system for steel workpieces eroded by electrical discharge machining, which uses deep neural networks for surface roughness estimation and defect detection. Specifically, a convolutional neural network (CNN) is used as a regressor in order to obtain steel surface roughness and a CNN based on spatial pooling pyramid is applied for defect classification.
 In addition, a new method for the region of interest selection based on morphological reconstruction and mean shift filtering is proposed for defect detection and localization. The regressor and classifier based on deep neural networks proposed here outperform state-of-the-art methods using handcrafted feature extraction. We achieve a mean absolute percentage error of 7.32% on roughness estimation; on defect detection, our approach yields an accuracy of 97.26% and an area under the ROC curve metric of 99.09%.},
journal = {Mach. Vision Appl.},
month = jan,
numpages = {15},
keywords = {Mean shift filtering, Morphological reconstruction, Spatial pooling pyramid, Convolutional neural networks, Electrical discharge machining}
}

@inproceedings{10.1109/ACT.2009.212,
author = {Singh, Pradeep and Verma, Shirish},
title = {An Investigation of the Effect of Discretization on Defect Prediction Using Static Measures},
year = {2010},
isbn = {9780769539157},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ACT.2009.212},
doi = {10.1109/ACT.2009.212},
abstract = {Software repositories with defect logs are main resource for defect prediction. In recent years, researchers have used the vast amount of data that is contained by software repositories to predict the location of defect in the code that caused problems. In this paper we evaluate the effectiveness of software fault prediction with Naive-Bayes classifiers and J48 classifier by integrating with supervised discretization algorithm developed by Fayyad and Irani. Public datasets from the promise repository have been explored for this purpose. The repository contains software metric data and error data at the function/method level. Our experiment shows that integration of discretization method improves the software fault prediction accuracy when integrated with Naive-Bayes and J48 classifiers},
booktitle = {Proceedings of the 2009 International Conference on Advances in Computing, Control, and Telecommunication Technologies},
pages = {837–839},
numpages = {3},
keywords = {Software metrics, Machine learning, Defect prediction},
series = {ACT '09}
}

@inproceedings{10.1145/3372454.3372479,
author = {Guo, Yiming and Xia, Zhijie and Zhang, Zhisheng and Sun, Mengze},
title = {A Multi-sensor Big Data fusion Method in Quality Prediction of the Plasma Enhanced Chemical Vapor Deposition Process},
year = {2020},
isbn = {9781450372015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372454.3372479},
doi = {10.1145/3372454.3372479},
abstract = {Plasma Enhanced Chemical Vapor Deposition (PECVD) is a critical process in the processing of solar cells. Large quantities of the process data are collected from different sensors during the PECVD process, which are high-dimensional and highly correlated. Most existing research only focus on the analysis of single sensor data instead of multi-sensor data. However, the information contained in single sensor data is incomplete. In this paper, the method of Convolutional Neural Networks (CNN) is adopted to analysis multi-sensor big data form PECVD process. The regression model between the multi-sensor data and the quality of solar cells is established for quality prediction. The impact of various types of hyper-parameters on the performance of the model is analyzed, and the predictive performance of the model is optimized by adjusting the hyper-parameters. The performance of the proposed method is compared with existing methods in a real-world case study.},
booktitle = {Proceedings of the 3rd International Conference on Big Data Research},
pages = {24–29},
numpages = {6},
keywords = {Quality prediction, PECVD, Multi-sensor data, CNN, Big data},
location = {Cergy-Pontoise, France},
series = {ICBDR '19}
}

@article{10.1007/s10766-019-00650-1,
author = {Yang, Wensi and Yao, Qingfeng and Ye, Kejiang and Xu, Cheng-Zhong},
title = {Empirical Mode Decomposition and Temporal Convolutional Networks for Remaining Useful Life Estimation},
year = {2020},
issue_date = {Feb 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {48},
number = {1},
issn = {0885-7458},
url = {https://doi.org/10.1007/s10766-019-00650-1},
doi = {10.1007/s10766-019-00650-1},
abstract = {Remaining useful life (RUL) prediction plays an important role in guaranteeing safe operation and reducing maintenance cost in modern industry. In this paper, we present a novel deep learning method for RUL estimation based on time empirical mode decomposition (EMD) and temporal convolutional networks (TCN). The proposed framework can effectively reveal the non-stationary characteristics of bearing degradation signals and acquire time-series degradation signals which namely intrinsic mode functions through empirical mode decomposition. Furthermore, the feature information is used as the input to convolution layer and trained by TCN to predict remaining useful life. The proposed EMD–TCN model structure maintains a superior result compared to several state-of-the-art convolutional algorithms on public data sets. Experimental results show that the average score of EMD–TCN model is improved by 10–20% than traditional convolutional algorithms.},
journal = {Int. J. Parallel Program.},
month = feb,
pages = {61–79},
numpages = {19},
keywords = {Reliability, Remaining useful life, Empirical mode decomposition, Convolutional neural networks}
}

@article{10.1007/s11219-014-9241-7,
author = {Madeyski, Lech and Jureczko, Marian},
title = {Which process metrics can significantly improve defect prediction models? An empirical study},
year = {2015},
issue_date = {September 2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-014-9241-7},
doi = {10.1007/s11219-014-9241-7},
abstract = {The knowledge about the software metrics which serve as defect indicators is vital for the efficient allocation of resources for quality assurance. It is the process metrics, although sometimes difficult to collect, which have recently become popular with regard to defect prediction. However, in order to identify rightly the process metrics which are actually worth collecting, we need the evidence validating their ability to improve the product metric-based defect prediction models. This paper presents an empirical evaluation in which several process metrics were investigated in order to identify the ones which significantly improve the defect prediction models based on product metrics. Data from a wide range of software projects (both, industrial and open source) were collected. The predictions of the models that use only product metrics (simple models) were compared with the predictions of the models which used product metrics, as well as one of the process metrics under scrutiny (advanced models). To decide whether the improvements were significant or not, statistical tests were performed and effect sizes were calculated. The advanced defect prediction models trained on a data set containing product metrics and additionally Number of Distinct Committers (NDC) were significantly better than the simple models without NDC, while the effect size was medium and the probability of superiority (PS) of the advanced models over simple ones was high (  $$p=.016$$ p = . 016 ,  $$r=-.29$$ r = - . 29 ,  $$hbox {PS}=.76$$ PS = . 76 ), which is a substantial finding useful in defect prediction. A similar result with slightly smaller PS was achieved by the advanced models trained on a data set containing product metrics and additionally all of the investigated process metrics (  $$p=.038$$ p = . 038 ,  $$r=-.29$$ r = - . 29 ,  $$hbox {PS}=.68$$ PS = . 68 ). The advanced models trained on a data set containing product metrics and additionally Number of Modified Lines (NML) were significantly better than the simple models without NML, but the effect size was small (  $$p=.038$$ p = . 038 ,  $$r=.06$$ r = . 06 ). Hence, it is reasonable to recommend the NDC process metric in building the defect prediction models.},
journal = {Software Quality Journal},
month = sep,
pages = {393–422},
numpages = {30},
keywords = {Software metrics, Software defect prediction, Product metrics, Process metrics, Defect prediction models}
}

@article{10.1155/2021/5567017,
author = {Zheng, Tianyi and Peng, Bao and Zhou, Guofu and Liu, Xin},
title = {Industrial Internet of Things for Mobile Phone Shell Intelligent Detection in Smart Cities},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/5567017},
doi = {10.1155/2021/5567017},
abstract = {Industrial Internet of Things is the core field of smart city. And intelligent detection is an important application field of industrial Internet of Things. Demand of the industrial is particularly urgent. In particular, the defect detection of mobile phone shells (MPS) has always been a common problem for famous mobile phone companies. A compression-free defect detection method (CFDDM) for MPS based on machine vision is proposed in this paper. Firstly, affine transformation is utilized to solve the angle deviation of MPS in different images. Then, edge detection, binarization, and open operation are combined to highlight the edge region based on the results of angle adjustment. It is convenient for region of interest (ROI) extraction and clipping. Finally, the method of gray histogram contrasting is utilized for defect detection according to the results of ROI clipping. And the detection results are obtained. In this paper, MPS data set is utilized for many tests. The results show that the proposed method can effectively detect whether there are defects in MPS data set without image compression. The recognition accuracy is 100%. The recognition time of a single image is about 4.56 s, which is better than other defect detection methods.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {12}
}

@inproceedings{10.1145/3460319.3464840,
author = {Pan, Cong and Pradel, Michael},
title = {Continuous test suite failure prediction},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464840},
doi = {10.1145/3460319.3464840},
abstract = {Continuous integration advocates to run the test suite of a project frequently, e.g., for every code change committed to a shared repository. This process imposes a high computational cost and sometimes also a high human cost, e.g., when developers must wait for the test suite to pass before a change appears in the main branch of the shared repository. However, only 4% of all test suite invocations turn a previously passing test suite into a failing test suite. The question arises whether running the test suite for each code change is really necessary. This paper presents continuous test suite failure prediction, which reduces the cost of continuous integration by predicting whether a particular code change should trigger the test suite at all. The core of the approach is a machine learning model based on features of the code change, the test suite, and the development history. We also present a theoretical cost model that describes when continuous test suite failure prediction is worthwhile. Evaluating the idea with 15k test suite runs from 242 open-source projects shows that the approach is effective at predicting whether running the test suite is likely to reveal a test failure. Moreover, we find that our approach improves the AUC over baselines that use features proposed for just-in-time defect prediction and test case failure prediction by 13.9% and 2.9%, respectively. Overall, continuous test suite failure prediction can significantly reduce the cost of continuous integration.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {553–565},
numpages = {13},
keywords = {machine learning, cost model, continuous test suite failure prediction, continuous integration},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.5555/1193212.1193789,
author = {Mertik, Matej and Lenic, Mitja and Stiglic, Gregor and Kokol, Peter},
title = {Estimating Software Quality with Advanced Data Mining Techniques},
year = {2006},
isbn = {0769527035},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Current software quality estimation models often involve the use of supervised learning methods for building a software fault prediction models. In such models, dependent variable usually represents a software quality measurement indicating the quality of a module by risk-basked class membership, or the number of faults. Independent variables include various software metrics as McCabe, Error Count, Halstead, Line of Code, etc... In this paper we present the use of advanced tool for data mining called Multimethod on the case of building software fault prediction model. Multimethod combines different aspects of supervised learning methods in dynamical environment and therefore can improve accuracy of generated prediction model. We demonstrate the use Multimethod tool on the real data from the Metrics Data Project Data (MDP) Repository. Our preliminary empirical results show promising potentials of this approach in predicting software quality in a software measurement and quality dataset.},
booktitle = {Proceedings of the International Conference on Software Engineering Advances},
pages = {19},
keywords = {Supervised learning, Software quality, Software fault prediction models, Multimethod data mining},
series = {ICSEA '06}
}

@inproceedings{10.1109/ICMV.2009.53,
author = {Behravan, Mina and Boostani, Reza and Tajeripour, Farshad and Azimifar, Zohre},
title = {A Hybrid Scheme for Online Detection and Classification of Textural Fabric Defects},
year = {2010},
isbn = {9780769539447},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMV.2009.53},
doi = {10.1109/ICMV.2009.53},
abstract = {Online automatic fabric defect detection and classification of the localized defect types are two vital stages in production line of textile manufactures. Here a hybrid approach is proposed for online detection of defects through serial fabric images and then classifying the localized defect types. First, defects are detected and localized by using a modified local binary pattern (LBP) operator and second, to characterize the defective regions, textons are utilized. Different classes of fabric defects locally cause different types of texture and therefore the classification of defects can be formulated as a texture classification problem. In the state-of-the-art texture analysis approaches a texture is characterized through textons describing local properties of textures. For the first time, in this paper the approach is used for classification of fabric defects. The employed dataset in this study is provided by fabric laboratory of University of Hong Kong. Images in the dot-patterned fabric database contain six types of well-known defects. Experimental results have yielded excellent results such that classification accuracy of detected defect types is determined 100%. The low computational complexity and high robustness of the proposed scheme confirm the usefulness of this approach for online fabric inspection.},
booktitle = {Proceedings of the 2009 Second International Conference on Machine Vision},
pages = {118–122},
numpages = {5},
keywords = {Texture Classification, Texton, LBPs, Fabric Defect Classification, Defect Detection},
series = {ICMV '09}
}

@article{10.1016/j.eswa.2021.115234,
author = {Ma, Liang and Ding, Yu and Wang, Zili and Wang, Chao and Ma, Jian and Lu, Chen},
title = {An interpretable data augmentation scheme for machine fault diagnosis based on a sparsity-constrained generative adversarial network},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {182},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115234},
doi = {10.1016/j.eswa.2021.115234},
journal = {Expert Syst. Appl.},
month = nov,
numpages = {13},
keywords = {Raw vibration signal, Machine fault diagnosis, Mechanism interpretation, Data augmentation, Generative adversarial networks}
}

@article{10.1016/j.jksuci.2014.03.024,
author = {Vinodhini, G. and Chandrasekaran, R.M.},
title = {A comparative performance evaluation of neural network based approach for sentiment classification of online reviews},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {28},
number = {1},
issn = {1319-1578},
url = {https://doi.org/10.1016/j.jksuci.2014.03.024},
doi = {10.1016/j.jksuci.2014.03.024},
abstract = {The aim of sentiment classification is to efficiently identify the emotions expressed in the form of text messages. Machine learning methods for sentiment classification have been extensively studied, due to their predominant classification performance. Recent studies suggest that ensemble based machine learning methods provide better performance in classification. Artificial neural networks (ANNs) are rarely being investigated in the literature of sentiment classification. This paper compares neural network based sentiment classification methods (back propagation neural network (BPN), probabilistic neural network (PNN) &amp; homogeneous ensemble of PNN (HEN)) using varying levels of word granularity as features for feature level sentiment classification. They are validated using a dataset of product reviews collected from the Amazon reviews website. An empirical analysis is done to compare results of ANN based methods with two statistical individual methods. The methods are evaluated using five different quality measures and results show that the homogeneous ensemble of the neural network method provides better performance. Among the two neural network approaches used, probabilistic neural networks (PNNs) outperform in classifying the sentiment of the product reviews. The integration of neural network based sentiment classification methods with principal component analysis (PCA) as a feature reduction technique provides superior performance in terms of training time also.},
journal = {J. King Saud Univ. Comput. Inf. Sci.},
month = jan,
pages = {2–12},
numpages = {11},
keywords = {Text classification, Support vector machine, Sentiment analysis, Opinion mining, Artificial neural networks}
}

@article{10.1016/j.infsof.2019.05.009,
author = {Nashaat, Mona and Ghosh, Aindrila and Miller, James and Quader, Shaikh and Marston, Chad},
title = {M-Lean: An end-to-end development framework for predictive models in B2B scenarios},
year = {2019},
issue_date = {Sep 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {113},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.05.009},
doi = {10.1016/j.infsof.2019.05.009},
journal = {Inf. Softw. Technol.},
month = sep,
pages = {131–145},
numpages = {15},
keywords = {Case study, User trust, Business-to-business, Machine learning, Big data}
}

@inproceedings{10.1145/3356422.3356459,
author = {Ji, Xuyuan and Guo, Hui and Hu, Minghong},
title = {Features Extraction and Classification of Wood Defect Based on Hu Invariant Moment and Wavelet Moment and BP Neural Network},
year = {2019},
isbn = {9781450376266},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3356422.3356459},
doi = {10.1145/3356422.3356459},
abstract = {Wood defect will reduce wood properties, wood quality and use value, so it is of great practical significance to detect wood defect[1]. The key to feature extraction of target defect image is target recognition and classification. Moment feature is a common feature descriptor in defect extraction algorithm. Aiming at the problem that the seven feature components of Hu moments differ greatly in magnitude and are affected by scale factor, based on the principle and characteristics of invariant moments and wavelet energy, a feature extraction algorithm based on wavelet moments is proposed and applied to the feature extraction of wood defects. Finally, the experiment collects the actual wood defect image, decomposes the preprocessed image into three sub-images by wavelet transform, calculates the modified Hu moment invariants for the sub-images, takes the moment invariants as the feature variables, and obtains the recognition results by using the minimum neighborhood distance classification. The experimental results show that the feature extracted by this method has the invariance of translation, rotation and scale, and can reflect the important and original attributes of the target image. Compared with the traditional Hu moment, the recognition rate is significantly improved, and the expected goal is achieved.},
booktitle = {Proceedings of the 12th International Symposium on Visual Information Communication and Interaction},
articleno = {37},
numpages = {5},
keywords = {Wavelet moment, Hu invariant moment, Features extraction, Defect detection, BP neural network},
location = {Shanghai, China},
series = {VINCI '19}
}

@article{10.1016/j.jss.2014.10.032,
author = {Moeyersoms, Julie and Junqu\'{e} de Fortuny, Enric and Dejaeger, Karel and Baesens, Bart and Martens, David},
title = {Comprehensible software fault and effort prediction},
year = {2015},
issue_date = {February 2015},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {100},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2014.10.032},
doi = {10.1016/j.jss.2014.10.032},
abstract = {HighlightsWe argue that comprehensibility is crucial in software effort and fault prediction.We extracted new datasets based on the Android repository.ALPA extracts a tree that mimics the performance of the complex model.The extracted trees are not only comprehensible but also more accurate. Software fault and effort prediction are important tasks to minimize costs of a software project. In software effort prediction the aim is to forecast the effort needed to complete a software project, whereas software fault prediction tries to identify fault-prone modules. In this research both tasks are considered, thereby using different data mining techniques. The predictive models not only need to be accurate but also comprehensible, demanding that the user can understand the motivation behind the model's prediction. Unfortunately, to obtain predictive performance, comprehensibility is often sacrificed and vice versa. To overcome this problem, we extract trees from well performing Random Forests (RFs) and Support Vector Machines for regression (SVRs) making use of a rule extraction algorithm ALPA. This method builds trees (using C4.5 and REPTree) that mimic the black-box model (RF, SVR) as closely as possible. The proposed methodology is applied to publicly available datasets, complemented with new datasets that we have put together based on the Android repository. Surprisingly, the trees extracted from the black-box models by ALPA are not only comprehensible and explain how the black-box model makes (most of) its predictions, but are also more accurate than the trees obtained by working directly on the data.},
journal = {J. Syst. Softw.},
month = feb,
pages = {80–90},
numpages = {11},
keywords = {Software fault and effort prediction, Rule extraction, Comprehensibility}
}

@article{10.1016/j.asoc.2008.10.002,
author = {Huang, Chenn-Jung and Chen, You-Jia and Wu, Chi-Feng and Huang, Yi-An},
title = {Application of neural networks and genetic algorithms to the screening for high quality chips},
year = {2009},
issue_date = {March, 2009},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {9},
number = {2},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2008.10.002},
doi = {10.1016/j.asoc.2008.10.002},
abstract = {During electrical testing, each die on a wafer must be tested to determine whether it functions as originally designed. For a clustered defect on a wafer, for example scratches, stains, or localized failure patterns, defective dies in the flawed area may not all be detected during the electrical testing stage. To prevent the defective dies from proceeding to the final assembly, the testing factory must assign some workers to identify patterns in the layout of defective dies for labeling other potential defects. Although a previously developed defect detection program enables full automation of the testing process in a testing factory, numerous defective dies in recognized clusters are not picked out, or in some clusters are even not captured in certain circumstances. This work thus proposes two automatic wafer-scale defect cluster identifiers, which utilize neural networks and genetic algorithms for detecting the defect clusters, and compares them with that presented in our earlier work. The experimental results confirm that both of the proposed algorithms are more effective in identifying defect clusters than the defect detection program presently used by the testing factory.},
journal = {Appl. Soft Comput.},
month = mar,
pages = {824–832},
numpages = {9},
keywords = {Single-linkage clustering, Multilayer perceptron, Median filter, Genetic algorithm, Defect detection, Cellular neural networks}
}

@article{10.1016/j.asoc.2021.107702,
author = {Jiang, Xiaomo and Yang, Shuhua and Wang, Fumin and Xu, Shengli and Wang, Xiaofang and Cheng, Xueyu},
title = {OrbitNet: A new CNN model for automatic fault diagnostics of turbomachines},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {110},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107702},
doi = {10.1016/j.asoc.2021.107702},
journal = {Appl. Soft Comput.},
month = oct,
numpages = {17},
keywords = {Turbomachine, Shaft orbits, Fault diagnostics, CNN, Bayesian wavelet signal processing}
}

@inproceedings{10.1109/ICMLA.2009.17,
author = {Altidor, Wilker and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {Wrapper-Based Feature Ranking for Software Engineering Metrics},
year = {2009},
isbn = {9780769539263},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2009.17},
doi = {10.1109/ICMLA.2009.17},
abstract = {The application of feature ranking to software engineering datasets is rare at best. In this study, we consider wrapper-based feature ranking where nine performance metrics aided by a particular learner are evaluated. We consider five learners and take two different approaches, each in conjunction with one of two different methodologies: 3-fold Cross-Validation (CV) and 3-fold Cross-Validation Risk Impact (CV-R). The classifiers are Na\i{}ve Bayes (NB), Multi Layer Perceptron (MLP), k- Nearest Neighbors (kNN), Support Vector Machines (SVM), and Logistic Regression (LR). The performance metrics used as ranking techniques are Overall Accuracy (OA), F-Measure(FM), Geometric Mean (GM), Arithmetic Mean (AM), Area under ROC (AUC), Area under PRC (PRC), Best F-Measure (BFM), Best Geometric Mean (BGM), and Best Arithmetic Mean (BAM). To evaluate the classifier performance after feature selection has been applied, we use AUC as the performance evaluator. This paper represents a preliminary report on our proposed wrapper-based feature ranking approach to software defect prediction problems.},
booktitle = {Proceedings of the 2009 International Conference on Machine Learning and Applications},
pages = {241–246},
numpages = {6},
keywords = {wrapper-based feature ranking, software engineering metrics, performance metrics, feature selection},
series = {ICMLA '09}
}

@article{10.1007/s11042-016-4199-z,
author = {Jian, Chuanxia and Gao, Jian and Ao, Yinhui},
title = {Imbalanced defect classification for mobile phone screen glass using multifractal features and a new sampling method},
year = {2017},
issue_date = {Nov 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {22},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-016-4199-z},
doi = {10.1007/s11042-016-4199-z},
abstract = {Defect classification has drawn significant attention in the mobile phone screen glass (MPSG) manufacturing field because it helps to determine problems in the manufacturing process. Two problems exist in MPSG defect classification: (1) the high dimensionality of the defect feature; (2) imbalanced defect example classification. The first problem tends to yield low accuracy for classifying overall defect examples, and the second problem has a low accuracy for minority ones. To address these two problems, an imbalanced MPSG defect classification scheme is presented. First, based on the multifractal spectrum, defect features are extracted to reduce the feature dimensionality. Defect features are distinguishably characterized by two multifractal metrics to promote the performance of classifying defects. Second, considering example contributions to determine the classification boundary, a new sampling method is proposed to address the imbalanced defect example classification. This method improves the classification accuracy of the minority class through implementation of different sampling strategies to SVs (support vectors) and NSVs (non support vectors) in the majority and minority classes. Experiments are conducted on real MPSG defect examples, and the experimental results show that the imbalanced MPSG defect classification scheme achieves a 96.61% overall accuracy and a 93.27% geometric mean of the classification accuracies of four-type defects; these results are superior to the results achieved by other methods used in the experiment.},
journal = {Multimedia Tools Appl.},
month = nov,
pages = {24413–24434},
numpages = {22},
keywords = {Sampling, Multifractal features, Mobile phone screen glass, Imbalanced datasets, Defect classification}
}

@article{10.3103/S0147688221060046,
author = {Gibadullin, R. F. and Lekomtsev, D. V. and Perukhin, M. Y.},
title = {Analysis of Industrial Network Parameters Using Neural Network Processing},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {48},
number = {6},
issn = {0147-6882},
url = {https://doi.org/10.3103/S0147688221060046},
doi = {10.3103/S0147688221060046},
journal = {Sci. Tech. Inf. Process.},
month = dec,
pages = {446–451},
numpages = {6},
keywords = {data preprocessing, machine learning, artificial neural networks, network diagnostics, Industrial Ethernet, PROFINET}
}

@article{10.1016/j.infsof.2017.08.004,
title = {MULTI},
year = {2018},
issue_date = {January 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {93},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.08.004},
doi = {10.1016/j.infsof.2017.08.004},
abstract = {Context: Just-in-time software defect prediction (JIT-SDP) aims to conduct defect prediction on code changes, which have finer granularity. A recent study by Yang etal. has shown that there exist some unsupervised methods, which are comparative to supervised methods in effort-aware JIT-SDP.Objective: However, we still believe that supervised methods should have better prediction performance since they effectively utilize the gathered defect prediction datasets. Therefore we want to design a new supervised method for JIT-SDP with better performance.Method: In this article, we propose a multi-objective optimization based supervised method MULTI to build JIT-SDP models. In particular, we formalize JIT-SDP as a multi-objective optimization problem. One objective is designed to maximize the number of identified buggy changes and another object is designed to minimize the efforts in software quality assurance activities. There exists an obvious conflict between these two objectives. MULTI uses logistic regression to build the models and uses NSGA-II to generate a set of non-dominated solutions, which each solution denotes the coefficient vector for the logistic regression.Results: We design and conduct a large-scale empirical studies to compare MULTI with 43 state-of-the-art supervised and unsupervised methods under the three commonly used performance evaluation scenarios: cross-validation, cross-project-validation, and timewise-cross-validation. Based on six open-source projects with 227,417 changes in total, our experimental results show that MULTI can perform significantly better than all of the state-of-the-art methods when considering ACC and POPT performance metrics.Conclusion: By using multi-objective optimization, MULTI can perform significantly better than the state-of-the-art supervised and unsupervised methods in the three performance evaluation scenarios. The results confirm that supervised methods are still promising in effort-aware JIT-SDP.},
journal = {Inf. Softw. Technol.},
month = jan,
pages = {1–13},
numpages = {13}
}

@inproceedings{10.5555/2373291.2374465,
author = {Gao, Erjin and Wu, Xiaobing},
title = {The Research of Texture-based Classification of Fabric Surface Defect Image},
year = {2012},
isbn = {9780769547046},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper mainly studies the BP neural network and wavelet neural network classifiers, using the BP neural network and wavelet neural network for the defect recognition of defect image. Through the comparative analysis between the results of recognition we know that the wavelet neural network has stronger approximation ability, faster convergence rate, and the selection of the network parameters (the numbers of the hidden layer points and the weights) are on the basis of the theory.},
booktitle = {Proceedings of the 2012 Second International Conference on Electric Technology and Civil Engineering},
pages = {3320–3323},
numpages = {4},
keywords = {Wavelet neural network, Defect detection, BP neural network},
series = {ICETCE '12}
}

@inproceedings{10.1145/3345629.3345635,
author = {Wang, Song and Bansal, Chetan and Nagappan, Nachiappan and Philip, Adithya Abraham},
title = {Leveraging Change Intents for Characterizing and Identifying Large-Review-Effort Changes},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345635},
doi = {10.1145/3345629.3345635},
abstract = {Code changes to software occur due to various reasons such as bug fixing, new feature addition, and code refactoring. In most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis.In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (LRE) changes regarding review effort---changes with large review effort. Specifically, we first propose a feedback-driven and heuristics-based approach to obtain change intents. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying LRE changes. We conduct our study on a large-scale project from Microsoft and three large-scale open source projects, i.e., Qt, Android, and OpenStack. Our results show that, (i) code changes with some intents are more likely to be LRE changes, (ii) machine learning based prediction models can efficiently help identify LRE changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average. The tool developed in this study has already been used in Microsoft to provide the review effort and intent information of changes for reviewers to accelerate the review process.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {46–55},
numpages = {10},
keywords = {Code review, change intent, machine learning, review effort},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@article{10.1007/s10462-012-9348-9,
author = {Elish, Mahmoud O.},
title = {A comparative study of fault density prediction in aspect-oriented systems using MLP, RBF, KNN, RT, DENFIS and SVR models},
year = {2014},
issue_date = {December  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {42},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-012-9348-9},
doi = {10.1007/s10462-012-9348-9},
abstract = {This paper investigates and empirically evaluates and compares six popular computational intelligence models in the context of fault density prediction in aspect-oriented systems. These models are multi-layer perceptron (MLP), radial basis function (RBF), k-nearest neighbor (KNN), regression tree (RT), dynamic evolving neuro-fuzzy inference system (DENFIS), and support vector regression (SVR). The models were trained and tested, using leave-one-out procedure, on a dataset that consists of twelve aspect-level metrics (explanatory variables) that measure different structural properties of an aspect. It was observed that the DENFIS, SVR, and RT models were more accurate in predicting fault density compared to the MLP, RBF, and KNN models. The MLP model was the worst model, and all the other models were significantly better than it.},
journal = {Artif. Intell. Rev.},
month = dec,
pages = {695–703},
numpages = {9},
keywords = {Fault density prediction, Computational intelligence, Aspect-oriented software}
}

@inproceedings{10.1145/3377816.3381738,
author = {Arokiam, Jude and Bradbury, Jeremy S.},
title = {Automatically predicting bug severity early in the development process},
year = {2020},
isbn = {9781450371261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377816.3381738},
doi = {10.1145/3377816.3381738},
abstract = {Bug severity is an important factor in prioritizing which bugs to fix first. The process of triaging bug reports and assigning a severity requires developer expertise and knowledge of the underlying software. Methods to automate the assignment of bug severity have been developed to reduce the developer cost, however, many of these methods require 70-90% of the project's bug reports as training data and delay their use until later in the development process. Not being able to automatically predict a bug report's severity early in a project can greatly reduce the benefits of automation. We have developed a new bug report severity prediction method that leverages how bug reports are written rather than what the bug reports contain. Our method allows for the prediction of bug severity at the beginning of the project by using an organization's historical data, in the form of bug reports from past projects, to train the prediction classifier. In validating our approach, we conducted over 1000 experiments on a dataset of five NASA robotic mission software projects. Our results demonstrate that our method was not only able to predict the severity of bugs earlier in development, but it was also able to outperform an existing keyword-based classifier for a majority of the NASA projects.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {17–20},
numpages = {4},
keywords = {natural language processing, machine learning, bug severity},
location = {Seoul, South Korea},
series = {ICSE-NIER '20}
}

@article{10.5555/1454341.1454344,
author = {Guzaitis, Jonas and Verikas, Antanas},
title = {An Efficient Technique to Detect Visual Defects in Particleboards},
year = {2008},
issue_date = {August 2008},
publisher = {IOS Press},
address = {NLD},
volume = {19},
number = {3},
issn = {0868-4952},
abstract = {This paper is concerned with the problem of image analysis based detection of local defects embedded in particleboard surfaces. Though simple, but efficient technique developed is based on the analysis of the discrete probability distribution of the image intensity values and the 2D discrete Walsh transform. Robust global features characterizing a surface texture are extracted and then analyzed by a pattern classifier. The classifier not only assigns the pattern into the quality or detective class, but also provides the certainty value attributed to the decision. A 100% correct classification accuracy was obtained when testing the technique proposed on a set of 200 images.},
journal = {Informatica},
month = aug,
pages = {363–376},
numpages = {14},
keywords = {image analysis, defect detection, Walsh transform}
}

@inproceedings{10.1109/ISCID.2013.199,
author = {Xia, Ye and Yan, Guoying and Si, Qianran},
title = {A Study on the Significance of Software Metrics in Defect Prediction},
year = {2013},
isbn = {9780769550794},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISCID.2013.199},
doi = {10.1109/ISCID.2013.199},
abstract = {In the case of metrics-based software defect prediction, an intelligent selection of metrics plays an important role in improving the model performance. In this paper, we use different ways for feature selection and dimensionality reduction to determine the most important software metrics. Three different classifiers are utilized, namely Na\"{\i}ve Bayes, support vector machine and decision tree. On the publicly NASA data, a comparative experiment results show that instead of 22 or more metrics, less than 10 metrics can get better performance.},
booktitle = {Proceedings of the 2013 Sixth International Symposium on Computational Intelligence and Design - Volume 02},
pages = {343–346},
numpages = {4},
keywords = {software metric, feature selection, defect prediction, classifier},
series = {ISCID '13}
}

@inproceedings{10.1007/978-3-030-71593-9_22,
author = {Burrello, Alessio and Pagliari, Daniele Jahier and Bartolini, Andrea and Benini, Luca and Macii, Enrico and Poncino, Massimo},
title = {Predicting Hard Disk Failures in Data Centers Using Temporal Convolutional Neural Networks},
year = {2020},
isbn = {978-3-030-71592-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-71593-9_22},
doi = {10.1007/978-3-030-71593-9_22},
abstract = {In modern data centers, storage system failures are major contributors to downtimes and maintenance costs. Predicting these failures by collecting measurements from disks and analyzing them with machine learning techniques can effectively reduce their impact, enabling timely maintenance. While there is a vast literature on this subject, most approaches attempt to predict hard disk failures using either classic machine learning solutions, such as Random Forests (RFs) or deep Recurrent Neural Networks (RNNs). In this work, we address hard disk failure prediction using Temporal Convolutional Networks (TCNs), a novel type of deep neural network for time series analysis. Using a real-world dataset, we show that TCNs outperform both RFs and RNNs. Specifically, we can improve the Fault Detection Rate (FDR) of ≈7.5% (FDR = 89.1%) compared to the state-of-the-art, while simultaneously reducing the False Alarm Rate (FAR = 0.052%). Moreover, we explore the network architecture design space showing that TCNs are consistently superior to RNNs for a given model size and complexity and that even relatively small TCNs can reach satisfactory performance. All the codes to reproduce the results presented in this paper are available at .},
booktitle = {Euro-Par 2020: Parallel Processing Workshops: Euro-Par 2020 International Workshops, Warsaw, Poland, August 24–25, 2020, Revised Selected Papers},
pages = {277–289},
numpages = {13},
keywords = {Temporal Convolutional Networks, Sequence analysis, Deep learning, IoT, Predictive maintenance},
location = {Warsaw, Poland}
}

@inproceedings{10.1145/3109761.3158399,
author = {Balogun, Vincent A. and Otanocha, Omonigho B. and Oladapo, Bankole I.},
title = {Development of smart linear velocity measuring device by embedding sensors with the arduino microcontroller},
year = {2017},
isbn = {9781450352437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109761.3158399},
doi = {10.1145/3109761.3158399},
abstract = {The change of an object's position with respect to time and a reference point is usually adopted to determine its velocity. This is usually a function of time. Velocity can be deduced in terms of its speed and direction of motion. It is an important concept in the description of kinematics and mechanics of bodies which entails the definitions of the bodies magnitude and direction. This project is one of the teaching series of smart technology development for the step change and technological awareness on the introduction of the IoT global influx. It focuses on the measurement of velocity using ultrasonic sensor. The Ultrasonic module HC - SR04 that has a range between 2 cm - 400 cm and a non-contact measurement function was adopted and linked to the Arduino UNO board for data processing and conversion before the output displays the specific measurement of the object velocity. The accuracy of the Ultrasonic module HC - SR04 ranges up to 3 mm. This module comprises of the ultrasonic transmitters, the receiver and the control circuit [1]. This is to teach and encourage students within the developing countries such as Nigeria to exploit and contribute to the global trend of the IoT smart technology advancement.},
booktitle = {Proceedings of the 1st International Conference on Internet of Things and Machine Learning},
articleno = {64},
numpages = {5},
keywords = {ultrasonic sensor, smart technology, instrumentation, arduino, IoT},
location = {Liverpool, United Kingdom},
series = {IML '17}
}

@article{10.1145/3439950,
author = {Pang, Guansong and Shen, Chunhua and Cao, Longbing and Hengel, Anton Van Den},
title = {Deep Learning for Anomaly Detection: A Review},
year = {2021},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3439950},
doi = {10.1145/3439950},
abstract = {Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection, has emerged as a critical direction. This article surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in 3 high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages, and disadvantages and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {38},
numpages = {38},
keywords = {outlier detection, one-class classification, novelty detection, deep learning, Anomaly detection}
}

@article{10.1016/j.infsof.2010.06.006,
author = {Tosun, Ay\c{s}e and Bener, Ay\c{s}e and Turhan, Burak and Menzies, Tim},
title = {Practical considerations in deploying statistical methods for defect prediction: A case study within the Turkish telecommunications industry},
year = {2010},
issue_date = {November, 2010},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {52},
number = {11},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2010.06.006},
doi = {10.1016/j.infsof.2010.06.006},
abstract = {Context: Building defect prediction models in large organizations has many challenges due to limited resources and tight schedules in the software development lifecycle. It is not easy to collect data, utilize any type of algorithm and build a permanent model at once. We have conducted a study in a large telecommunications company in Turkey to employ a software measurement program and to predict pre-release defects. Based on our prior publication, we have shared our experience in terms of the project steps (i.e. challenges and opportunities). We have further introduced new techniques that improve our earlier results. Objective: In our previous work, we have built similar predictors using data representative for US software development. Our task here was to check if those predictors were specific solely to US organizations or to a broader class of software. Method: We have presented our approach and results in the form of an experience report. Specifically, we have made use of different techniques for improving the information content of the software data and the performance of a Naive Bayes classifier in the prediction model that is locally tuned for the company. We have increased the information content of the software data by using module dependency data and improved the performance by adjusting the hyper-parameter (decision threshold) of the Naive Bayes classifier. We have reported and discussed our results in terms of defect detection rates and false alarms. We also carried out a cost-benefit analysis to show that our approach can be efficiently put into practice. Results: Our general result is that general defect predictors, which exist across a wide range of software (in both US and Turkish organizations), are present. Our specific results indicate that concerning the organization subject to this study, the use of version history information along with code metrics decreased false alarms by 22%, the use of dependencies between modules further reduced false alarms by 8%, and the decision threshold optimization for the Naive Bayes classifier using code metrics and version history information further improved false alarms by 30% in comparison to a prediction using only code metrics and a default decision threshold. Conclusion: Implementing statistical techniques and machine learning on a real life scenario is a difficult yet possible task. Using simple statistical and algorithmic techniques produces an average detection rate of 88%. Although using dependency data improves our results, it is difficult to collect and analyze such data in general. Therefore, we would recommend optimizing the hyper-parameter of the proposed technique, Naive Bayes, to calibrate the defect prediction model rather than employing more complex classifiers. We also recommend that researchers who explore statistical and algorithmic methods for defect prediction should spend less time on their algorithms and more time on studying the pragmatic considerations of large organizations.},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {1242–1257},
numpages = {16},
keywords = {Static code attributes, Software defect prediction, Na\"{\i}ve Bayes, Experience report}
}

@inproceedings{10.1007/978-3-030-64243-3_35,
author = {Bao, Yaru and Tang, Feilong and Cao, Lijun},
title = {Failure Prediction with Hierarchical Approach in Private Cloud},
year = {2020},
isbn = {978-3-030-64242-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64243-3_35},
doi = {10.1007/978-3-030-64243-3_35},
abstract = {Cloud computing is widely adopted in real-world data centers. Most companies choose to build a private cloud service with the consideration of privacy. In these circumstances, they provide the service through Infrastructure as a Service (IaaS). However, with the scale of the data center, the possibility of cloud failure is increasing and become urgent in cloud computing. Current methods mainly use the proactive approach that monitors the failure and process it afterward. These methods are inefficient, and may always cause the service to break down. In this paper, we propose a new approach HFP (Hierarchical Failure Prediction) that can effectively monitor and predict the failure in advance. We firstly design and implement a new monitor structure that can effectively collect data. Then, a failure prediction method is proposed to predict the failure in advance. We implement this system with OpenStack, the synthetic result on the collected dataset shows that our method can achieve 98.3% accuracy in the prediction of cloud failure.},
booktitle = {Green, Pervasive, and Cloud Computing: 15th International Conference, GPC 2020, Xi'an, China, November 13–15, 2020, Proceedings},
pages = {469–480},
numpages = {12},
keywords = {Machine learning, Failure prediction, Cloud computing},
location = {Xi'an, China}
}

@inproceedings{10.1145/3471985.3472371,
author = {Fukumitsu, Yoshinobu and Nakamichi, Keita and Uwano, Hidetake and Fukuoka, Hiroshi},
title = {Defect Classification using Pressure Change of Sleeve Soldering Machine},
year = {2021},
isbn = {9781450387484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3471985.3472371},
doi = {10.1145/3471985.3472371},
abstract = {Abstract: The solder joint significantly affects the quality of the electronic equipment. Recent researches focus on the automatic inspection of solder joints to detect the fault with high accuracy. The sleeve soldering system is one of the soldering equipment. The system puts a heated ceramic sleeve over the through-hole of the print circuit board and melts the solder piece dropped into the sleeve. The system also feeds a certain amount of nitrogen gas into the sleeve continuously, and the gas goes out through the lower end of the sleeve. Pressure in the sleeve is changed by narrowing down or blocking the exit hole in each soldering process, such as the sleeve approaches to the print circuit board, drop off the solder piece, and solder melting. Here, the pressure at each process may differ between correct and incorrect soldering. In this paper, the authors classify the correct and incorrect soldering from the pressure change's features. The results of the experiment show that both correct and incorrect are classified with 98.3% accuracy.},
booktitle = {2021 the 5th International Conference on Robotics, Control and Automation},
pages = {43–47},
numpages = {5},
keywords = {soldering, sleeve soldering, machine learning, fault classification},
location = {Seoul, Republic of Korea},
series = {ICRCA 2021}
}

@inproceedings{10.1007/978-3-030-39431-8_49,
author = {Zhou, Jianwen and Zhao, Wenjing and Guo, Lei and Xu, Xinying and Xie, Gang},
title = {Real Time Detection of Surface Defects with Inception-Based MobileNet-SSD Detection Network},
year = {2019},
isbn = {978-3-030-39430-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-39431-8_49},
doi = {10.1007/978-3-030-39431-8_49},
abstract = {Effective surface defect detection are of great significance for the production of high quality products. Aiming at real-time detection of surface defect, we propose a reusable and high-efficiency Inception-based MobileNet-SSD method for surface defect inspection in industrial environment. First, convolutional layers for feature extraction used in SSD were replaced by depthwise separable convolutions utilized in MobileNet so that the speed of the network can be faster. Then, the layer in the base network as convolutional feature layer is constructed as Inception which can extract more rich features through multiple convolution combinations of different scales. Finally, predictions from multiple feature maps with different resolutions are combined by the network to naturally handle objects of various sizes. Experimental results on a surface defect dataset containing 2750 images of 5 classes we established confirm that our network has competitive accuracy and is much faster. For 300 \texttimes{} 300 input, ours network achieves 96.1% mAP on DAGM 2007 test at 73FPS on a NVIDIA GTX 1080Ti, outperforming a comparable state-of-the-art FCN model.},
booktitle = {Advances in Brain Inspired Cognitive Systems: 10th International Conference, BICS 2019, Guangzhou, China, July 13–14, 2019, Proceedings},
pages = {510–519},
numpages = {10},
keywords = {MobileNet-SSD, Inception, Real time detection, Surface defect},
location = {Guangzhou, China}
}

@inproceedings{10.5555/3504035.3504589,
author = {Zhao, Xibin and Wang, Nan and Shi, Heyuan and Wan, Hai and Huang, Jin and Gao, Yue},
title = {Hypergraph learning with cost interval optimization},
year = {2018},
isbn = {978-1-57735-800-8},
publisher = {AAAI Press},
abstract = {In many classification tasks, the misclassification costs of different categories usually vary significantly. Under such circumstances, it is essential to identify the importance of different categories and thus assign different misclassifica-tion losses in many applications, such as medical diagnosis, saliency detection and software defect prediction. However, we note that it is infeasible to determine the accurate cost value without great domain knowledge. In most common cases, we may just have the information that which category is more important than the other categories, i.e., the identification of defect-prone softwares is more important than that of defect-free. To tackle these issues, in this paper, we propose a hypergraph learning method with cost interval optimization, which is able to handle cost interval when data is formulated using the high-order relationships. In this way, data correlations are modeled by a hypergraph structure, which has the merit to exploit the underlying relationships behind the data. With a cost-sensitive hypergraph structure, in order to improve the performance of the classifier without precise cost value, we further introduce cost interval optimization to hypergraph learning. In this process, the optimization on cost interval achieves better performance instead of choosing uncertain fixed cost in the learning process. To evaluate the effectiveness of the proposed method, we have conducted experiments on two groups of dataset, i.e., the NASA Metrics Data Program (NASA) dataset and UCI Machine Learning Repository (UCI) dataset. Experimental results and comparisons with state-of-the-art methods have exhibited better performance of our proposed method.},
booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {554},
numpages = {8},
location = {New Orleans, Louisiana, USA},
series = {AAAI'18/IAAI'18/EAAI'18}
}

@inproceedings{10.1145/3387904.3389255,
author = {Roy, Devjeet and Fakhoury, Sarah and Lee, John and Arnaoudova, Venera},
title = {A Model to Detect Readability Improvements in Incremental Changes},
year = {2020},
isbn = {9781450379588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387904.3389255},
doi = {10.1145/3387904.3389255},
abstract = {Identifying source code that has poor readability allows developers to focus maintenance efforts on problematic code. Therefore, the effort to develop models that can quantify the readability of a piece of source code has been an area of interest for software engineering researchers for several years. However, recent research questions the usefulness of these readability models in practice. When applying these models to readability improvements that are made in practice, i.e., commits, they are unable to capture these incremental improvements, despite a clear perceived improvement by the developers. This results in a discrepancy between the models we have built to measure readability, and the actual perception of readability in practice.In this work, we propose a model that is able to detect incremental readability improvements made by developers in practice with an average precision of 79.2% and an average recall of 67% on an unseen test set. We then investigate the metrics that our model associates with developer perceived readability improvements as well as non-readability changes. Finally, we compare our model to existing state-of-the-art readability models, which our model outperforms by at least 23% in terms of precision and 42% in terms of recall.},
booktitle = {Proceedings of the 28th International Conference on Program Comprehension},
pages = {25–36},
numpages = {12},
keywords = {Source code readability, Machine learning, Code quality},
location = {Seoul, Republic of Korea},
series = {ICPC '20}
}

@article{10.1007/s11192-019-03167-z,
author = {Wang, Pancheng and Li, Shasha and Zhou, Haifang and Tang, Jintao and Wang, Ting},
title = {Cited text spans identification with an improved balanced ensemble model},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {120},
number = {3},
issn = {0138-9130},
url = {https://doi.org/10.1007/s11192-019-03167-z},
doi = {10.1007/s11192-019-03167-z},
abstract = {Scientific summarization aims to provide condensed summary of important contributions of scientific papers. This problem has been extensively explored and recent interest has been aroused to taking advantage of the cited text spans to generate summaries. Cited text spans are the texts in the cited paper that most accurately reflect the citation. They can be viewed as important aspects of the cited paper which are annotated by academic community. Hence, identifying cited text spans is of vital importance for providing a different scientific summarization. In this paper, we explore three potential improvements towards our previous work which is a two-layer ensemble model to tackle the cited text spans identification problem. We first view cited text spans identification as an imbalanced classification problem and carry out comparison on preprocessing methods to handle the imbalanced dataset. Then we propose RANdom Sampling Aggregating&nbsp;(RANSA) algorithm to train classifiers in the first ensemble layer model. Finally, an improved stacking framework Hybrid-Stacking is applied to combine the models of the first layer. Our new ensemble model overcomes flaws of the previous work, and shows improved performance on cited text spans identification.},
journal = {Scientometrics},
month = sep,
pages = {1111–1145},
numpages = {35},
keywords = {Stacking, Ensemble, Cited text spans, Scientific summarization}
}

@article{10.1155/2018/1312787,
author = {Hoang, Nhat-Duc and Rodriguez, Alvaro},
title = {Classification of Asphalt Pavement Cracks Using Laplacian Pyramid-Based Image Processing and a Hybrid Computational Approach},
year = {2018},
issue_date = {2018},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2018},
issn = {1687-5265},
url = {https://doi.org/10.1155/2018/1312787},
doi = {10.1155/2018/1312787},
abstract = {To improve the efficiency of the periodic surveys of the asphalt pavement condition, this study puts forward an intelligent method for automating the classification of pavement crack patterns. The new approach relies on image processing techniques and computational intelligence algorithms. The image processing techniques of Laplacian pyramid and projection integral are employed to extract numerical features from digital images. Least squares support vector machine (LSSVM) and Differential Flower Pollination (DFP) are the two computational intelligence algorithms that are employed to construct the crack classification model based on the extracted features. LSSVM is employed for data classification. In addition, the model construction phase of LSSVM requires a proper setting of the regularization and kernel function parameters. This study relies on DFP to fine-tune these two parameters of LSSVM. A dataset consisting of 500 image samples and five class labels of alligator crack, diagonal crack, longitudinal crack, no crack, and transverse crack has been collected to train and verify the established approach. The experimental results show that the Laplacian pyramid is really helpful to enhance the pavement images and reveal the crack patterns. Moreover, the hybridization of LSSVM and DFP, named as DFP-LSSVM, used with the Laplacian pyramid at the level 4 can help us to achieve the highest classification accuracy rate of 93.04%. Thus, the new hybrid approach of DFP-LSSVM is a promising tool to assist transportation agencies in the task of pavement condition surveying.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {16}
}

@inproceedings{10.1145/2791060.2791103,
author = {Mazo, Ra\'{u}l and Mu\~{n}oz-Fern\'{a}ndez, Juan C. and Rinc\'{o}n, Luisa and Salinesi, Camille and Tamura, Gabriel},
title = {VariaMos: an extensible tool for engineering (dynamic) product lines},
year = {2015},
isbn = {9781450336130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791060.2791103},
doi = {10.1145/2791060.2791103},
abstract = {This paper presents the new release of VariaMos, a Java-based tool for defining variability modeling languages, modeling (dynamic) product lines and cyber-physical self-adaptive systems, and supporting automated verification, analysis, configuration and simulation of these models. In particular, we describe the characteristics of this new version regarding its first release: (1) the capability to create languages for modeling systems with variability, even with different views; (2) the capability to use the created language to model (dynamic) product lines; (3) the capability to analyze and configure these models according to the changing context and requirements; and (4) the capability to execute them over several simulation scenarios. Finally, we show how to use VariaMos with an example, and we compare it with other tools found in the literature.},
booktitle = {Proceedings of the 19th International Conference on Software Product Line},
pages = {374–379},
numpages = {6},
keywords = {variability, tool, simulation, product line engineering, dynamic product line models, constraints},
location = {Nashville, Tennessee},
series = {SPLC '15}
}

@inproceedings{10.5555/3291656.3291668,
author = {Das, Anwesha and Mueller, Frank and Hargrove, Paul and Roman, Eric and Baden, Scott},
title = {Doomsday: predicting which node will fail when on supercomputers},
year = {2018},
publisher = {IEEE Press},
abstract = {Predicting which node will fail and how soon remains a challenge for HPC resilience, yet may pave the way to exploiting proactive remedies before jobs fail. Not only for increasing scalability up to exascale systems but even for contemporary supercomputer architectures does it require substantial efforts to distill anomalous events from noisy raw logs. To this end, we propose a novel phrase extraction mechanism called TBP (time-based phrases) to pin-point node failures, which is unprecedented. Our study, based on real system data and statistical machine learning, demonstrates the feasibility to predict which specific node will fail in Cray systems. TBP achieves no less than 83% recall rates with lead times as high as 2 minutes. This opens up the door for enhancing prediction lead times for supercomputing systems in general, thereby facilitating efficient usage of both computing capacity and power in large scale production systems.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {9},
numpages = {14},
keywords = {machine learning, failure analysis, HPC},
location = {Dallas, Texas},
series = {SC '18}
}

@inproceedings{10.1109/SC.2018.00012,
author = {Das, Anwesha and Mueller, Frank and Hargrove, Paul and Roman, Eric and Baden, Scott},
title = {Doomsday: predicting which node will fail when on supercomputers},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC.2018.00012},
doi = {10.1109/SC.2018.00012},
abstract = {Predicting which node will fail and how soon remains a challenge for HPC resilience, yet may pave the way to exploiting proactive remedies before jobs fail. Not only for increasing scalability up to exascale systems but even for contemporary supercomputer architectures does it require substantial efforts to distill anomalous events from noisy raw logs. To this end, we propose a novel phrase extraction mechanism called TBP (time-based phrases) to pin-point node failures, which is unprecedented. Our study, based on real system data and statistical machine learning, demonstrates the feasibility to predict which specific node will fail in Cray systems. TBP achieves no less than 83% recall rates with lead times as high as 2 minutes. This opens up the door for enhancing prediction lead times for supercomputing systems in general, thereby facilitating efficient usage of both computing capacity and power in large scale production systems.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {9},
numpages = {14},
keywords = {machine learning, failure analysis, HPC},
location = {Dallas, Texas},
series = {SC '18}
}

@article{10.1007/s11042-019-7207-2,
author = {Armi, Laleh and Fekri-Ershad, Shervan},
title = {Texture image Classification based on improved local Quinary patterns},
year = {2019},
issue_date = {Jul 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {78},
number = {14},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-019-7207-2},
doi = {10.1007/s11042-019-7207-2},
abstract = {Texture image classification is an active research topic in computer vision that play an important role in many applications such as visual inspection systems, object tracking, medical image analysis, image segmentation, etc. So far, there are many descriptors for texture image analysis such as local binary patterns (LBP). LBP is a nonparametric operator, which describes the local spatial structure and the local contrast of an image. Local quinary patterns (LQP) is one of the improved versions of LBP in terms of classification accuracy. Statistic input parameters and don't providing significant binary patterns are some disadvantages of LQP. In this paper a new version of LBP is proposed, which is known as improved local quinary patterns (ILQP). In this paper, a new definition is proposed to divide local quinary codes to four binary patterns. Each extracted binary patterns represent a subset of local features. Also, a new algorithm is proposed here to provide dynamic thresholds in dividing process of LQP. The proposed approach is evaluated using Outex, and Brodatz data sets. Our approach has been compared with some state-of-the-art methods. It is experimentally demonstrated that the proposed approach achieves the highest accuracy in comparison with most of the state-of-the-art texture classification approaches. Low computational complexity, rotation invariant, low impulse-noise sensitivity and high usability are advantages of the proposed texture analysis descriptor.},
journal = {Multimedia Tools Appl.},
month = jul,
pages = {18995–19018},
numpages = {24},
keywords = {Texture image classification, Local binary patterns, Local Quinary patterns, Feature extraction}
}

@article{10.1016/j.neucom.2011.08.040,
author = {Wang, Huanjing and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {Software measurement data reduction using ensemble techniques},
year = {2012},
issue_date = {September, 2012},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {92},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2011.08.040},
doi = {10.1016/j.neucom.2011.08.040},
abstract = {Software defect prediction models are used to identify program modules that are high-risk, or likely to have a high number of faults. These models are built using software metrics which are collected during the software development process. Various techniques and approaches have been created for improving fault predictions. One of these is feature (metric) selection. Choosing the most important features is important to improve the effectiveness of defect predictors. However, using a single feature subset selection method may generate local optima. Ensembles of feature selection methods attempt to combine multiple feature selection methods instead of using a single one. In this paper, we present a comprehensive empirical study examining 17 different ensembles of feature ranking techniques (rankers) including six commonly used feature ranking techniques, the signal-to-noise filter technique, and 11 threshold-based feature ranking techniques. This study utilized 16 real-world software measurement data sets of different sizes and built 54,400 classification models using four well known classifiers. The main conclusion is that ensembles of very few rankers are very effective and even better than ensembles of many or all rankers.},
journal = {Neurocomput.},
month = sep,
pages = {124–132},
numpages = {9},
keywords = {Feature selection, Ensembles of feature ranking techniques, Defect prediction}
}

@article{10.1016/j.asoc.2020.106113,
author = {Li, Han and Zhao, Wei and Zhang, Yuxi and Zio, Enrico},
title = {Remaining useful life prediction using multi-scale deep convolutional neural network},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {89},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.106113},
doi = {10.1016/j.asoc.2020.106113},
journal = {Appl. Soft Comput.},
month = apr,
numpages = {13},
keywords = {Deep learning, Multi-scale, Convolutional neural network, Remaining useful life}
}

@article{10.1007/s10586-017-1327-0,
author = {Elmougy, Samir and Hossain, M. Shamim and Tolba, Ahmed S. and Alhamid, Mohammed F. and Muhammad, Ghulam},
title = {A parameter based growing ensemble of self-organizing maps for outlier detection in healthcare},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-017-1327-0},
doi = {10.1007/s10586-017-1327-0},
abstract = {Outlier detection is critical for many applications such as healthcare, health insurance, medical diagnosis, predictive analytics, pattern recognition, intrusion detection, anomaly or defect detection, video surveillance, credit card fraud detection and text mining. Outlier detection techniques could be statistics, distance- or model based. Techniques, which are based on a single method for outlier detection usually have weaknesses and strengths and are mostly unstable. Outlier detection ensembles harness the strengths of individual detectors and result in stable performance. This paper presents a new parameter based growing self-organizing maps ensemble (GSOME) for outlier detection in multivariate patterns. For outlier detection, the proposed GSOME transforms non-linear relationships between high dimensional patterns into a simple 1D geometric relationship. Whatever the pattern dimensionality is, it is mapped to a single point of a line. The dispersion of mapped points will be used to locate the outliers and measure the degree of outlyingness. Several experiments on both real and synthetic data sets show the promising performance of the proposed GSOME.},
journal = {Cluster Computing},
month = jan,
pages = {2437–2460},
numpages = {24},
keywords = {Healthcare, Diversity, Ensembles, Anomaly detection, Outlier detection, Self-organizing map}
}

@article{10.1007/s11265-017-1316-9,
author = {Si, Jia and Li, Yibin and Ma, Sile},
title = {Intelligent Fault Diagnosis for Industrial Big Data},
year = {2018},
issue_date = {September 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {90},
number = {8–9},
issn = {1939-8018},
url = {https://doi.org/10.1007/s11265-017-1316-9},
doi = {10.1007/s11265-017-1316-9},
abstract = {With the rapid development of the Internet of Things (IoT), industrial big data can now be collected through many different sources, such as multimedia. Intelligent fault diagnosis is recognized as an important and promising approach in using these data, because it can provide accurate diagnosis and adjust to different deployed environments. In this study, intelligent fault diagnosis approaches for real machine data sets are comprehensively investigated. First, support vector machine (SVM) and popular neural network approaches are implemented and compared. Results show that while the neural network-based method is very efficient in many high-dimensional applications, such as video, SVM performs well enough for intelligent fault diagnosis. Second, the relation between the number of samples and the efficiency of diagnosis are studied, Findings indicate that a small number of samples can produce an optimal result. Furthermore, accuracy does not increase with training data because of the inherent fuzziness of machine monitoring data. Finally, the accuracy of conditioning and diagnosis is demonstrated for several kinds of machine data.},
journal = {J. Signal Process. Syst.},
month = sep,
pages = {1221–1233},
numpages = {13},
keywords = {SVM, Neural network, Internet of things, Fault diagnosis, Big data}
}

@inproceedings{10.1007/978-3-031-08999-2_5,
author = {Meissen, Felix and Kaissis, Georgios and Rueckert, Daniel},
title = {Challenging Current Semi-supervised Anomaly Segmentation Methods for&nbsp;Brain MRI},
year = {2021},
isbn = {978-3-031-08998-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-08999-2_5},
doi = {10.1007/978-3-031-08999-2_5},
abstract = {In this work, we tackle the problem of Semi-Supervised Anomaly Segmentation (SAS) in Magnetic Resonance Images (MRI) of the brain, which is the task of automatically identifying pathologies in brain images. Our work challenges the effectiveness of current Machine Learning (ML) approaches in this application domain by showing that thresholding Fluid-attenuated inversion recovery (FLAIR) MR scans provides better anomaly segmentation maps than several different ML-based anomaly detection models. Specifically, our method achieves better Dice similarity coefficients and Precision-Recall curves than the competitors on various popular evaluation data sets for the segmentation of tumors and multiple sclerosis lesions. (Code available under: )},
booktitle = {Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 7th International Workshop, BrainLes 2021, Held in Conjunction with MICCAI 2021, Virtual Event, September 27, 2021, Revised Selected Papers, Part I},
pages = {63–74},
numpages = {12},
keywords = {Brain MRI, Anomaly detection, Semi-supervised Anomaly Segmentation}
}

@article{10.1016/j.neucom.2018.04.088,
author = {de Morais, Romero F.A.B. and Vasconcelos, Germano C.},
title = {Boosting the performance of over-sampling algorithms through under-sampling the minority class},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {343},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.04.088},
doi = {10.1016/j.neucom.2018.04.088},
journal = {Neurocomput.},
month = may,
pages = {3–18},
numpages = {16},
keywords = {Noisy data, Under-sampling, Over-sampling, Imbalanced learning}
}

@article{10.1504/ijcse.2021.115645,
author = {Panda, Rama Ranjan and Nagwani, Naresh Kumar},
title = {Multi-label software bug categorisation based on fuzzy similarity},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {24},
number = {3},
issn = {1742-7185},
url = {https://doi.org/10.1504/ijcse.2021.115645},
doi = {10.1504/ijcse.2021.115645},
abstract = {The efficiency of the software depends on timely detection of bugs. For better quality and low-cost development bug fixing time should be minimised. Categorisation of software bugs helps to understand the root cause of software bugs and to improve triaging. As the software development approach is modular and multi-skilled, it is possible that one software bug can affect multiple modules, and multiple developers can fix newly reported bugs. Hence, a multi-label categorisation of software bugs is needed. Fuzzy similarity techniques can be helpful in understanding the belongingness of software bugs in multiple categories. In this paper a multi-label fuzzy similarity based categorisation technique is presented for effective categorisation of software bugs. Fuzzy similarity between a pair of bugs is computed and, based on a user defined threshold value, the bugs are categorised. Experiments are performed on software bug data sets, and the performance of the proposed classifier is evaluated.},
journal = {Int. J. Comput. Sci. Eng.},
month = jan,
pages = {244–258},
numpages = {14},
keywords = {software bug repository, MLC, multi-label classification, fuzzy similarity, software bug classification, software bug mining}
}

@article{10.1016/j.procs.2020.03.274,
author = {Taneja, Divya and Singh, Rajvir and Singh, Ajmer and Malik, Himanshu},
title = {A Novel technique for test case minimization in object oriented testing},
year = {2020},
issue_date = {2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {167},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2020.03.274},
doi = {10.1016/j.procs.2020.03.274},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {2221–2228},
numpages = {8},
keywords = {Object oriented metrics, Test Case Minimization, machine learning, object oriented testing}
}

@inproceedings{10.5555/1940632.1940654,
author = {Cacciola, Matteo and Ripepi, Giuseppe and Yang, Guang and Tian, Gui Yun and Morabito, Francesco Carlo},
title = {ICA based Algorithms for Flaw Classification in Pulsed Eddy Current Data: A Study},
year = {2011},
isbn = {9781607506911},
publisher = {IOS Press},
address = {NLD},
abstract = {Pulsed Eddy Current (PEC) is a new emerging Non Destructive Evaluation technique for sub-surface defect detection. It provides new challenges to signal analysis and interpretation approach applied to the inspection evaluation. For instance, PEC could suffer from noise and be not sufficient to extract more information about the defects. This paper aims to approach the challenge of flaw identification in PECs. Due to non-Gaussianity of PEC measurements, we applied Independent Component Analysis (ICA) in extracting information from PEC responses. We considered three different approaches implementing ICA, in order to project the response signals of various defects into the Independent Components (ICs) feature space. Then, useful ICs of each algorithm were used as features for machine learning algorithms, in order to solve the inverse problem of pattern classification. Since the nongaussianity of the OEC measurements, we retained ICs with highest kurtosis. The considered different kinds of defects were: metal loss, sub-surface cracks, surface defects and slants. We compared the performances of our implemented algorithms with results available in scientific literature. We obtained improvements in reliability of the pattern classification algorithm, as well as in reducing the computational load, obtaining a classification error of 8.54% over 3063 testing patterns.},
booktitle = {Proceedings of the 2011 Conference on Neural Nets WIRN10: Proceedings of the 20th Italian Workshop on Neural Nets},
pages = {162–171},
numpages = {10}
}

@article{10.1155/2021/5298882,
author = {Meng, Meng and Zhu, Kun and Chen, Keqin and Qu, Hang and Perera, Ricardo},
title = {A Modified Fully Convolutional Network for Crack Damage Identification Compared with Conventional Methods},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5591},
url = {https://doi.org/10.1155/2021/5298882},
doi = {10.1155/2021/5298882},
abstract = {Large-scale structural health monitoring and damage detection of concealed underwater structures are always the urgent and state-of-art problems to be solved in the field of civil engineering. With the development of artificial intelligence especially the combination of deep learning and computer vision, greater advantages have been brought to the concrete crack detection based on convolutional neural network (CNN) over the traditional methods. However, these machine learning (ML) methods still have some defects, such as it being inaccurate or not strong, having poor generalization ability, or the accuracy still needs to be improved, and the running speed is slow. In this article, a modified fully convolutional network (FCN) with more robustness and more effectiveness is proposed, which makes it convenient and low cost for long-term structural monitoring and inspection compared with other methods. Meanwhile, to improve the accuracy of recognition and prediction, innovations were conducted in this study as follows. Moreover, differed from the common simple deconvolution, it also includes a subpixel convolution layer, which can greatly reduce the sampling time. Then, the proposed method was verified its practicability with the overall recognition accuracy reaching up to 97.92% and 12% efficiency improvement.},
journal = {Model. Simul. Eng.},
month = jan,
numpages = {14}
}

@inproceedings{10.1007/978-3-030-58802-1_45,
author = {Han, Yohan and Jeong, Jongpil},
title = {Real-Time Inspection of Multi-sided Surface Defects Based on PANet Model},
year = {2020},
isbn = {978-3-030-58801-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58802-1_45},
doi = {10.1007/978-3-030-58802-1_45},
abstract = {Quality of products is the most important factor in manufacturing. Machine vision is a technique that mainly performs human cognitive judgment in the industrial field or performs a task that is generally difficult for a human. However the detection of traditional methods of scanning with human eyes has many difficulties due to repetitive tasks. Recently, an artificial intelligence machine vision has been studied to improve these problems. Using the vision inspection system, it is possible to collect information such as the number of products, defect detection, and types without human intervention, which maximizes the operation-al efficiency of a company such as productivity improvement, quality improvement, and cost reduction. Most of the vision inspection systems currently in use are single-sided images, which collect and inspect one image of the product. However, in the actual manufacturing industry, products that are valid for single-sided image inspection are limited to some product groups, and most require multi-sided image inspection. In addition, the inspection system used in the field must meet the production speed required by the actual manufacturing site and inspect the defects of the product. In this paper, we propose a deep neural network-based vision inspection system that satisfies the multi-sided image inspection and fast production speed of products. By implementing seven cameras and optical technology, multi-sided images of the product are collected simultaneously, and a defect in the product can be quickly detected in real time using a PANet (Path Aggregation Network) model. Through the proposed system, it is possible to inspect product defects at the level required at the manufacturing site, and the information obtained in the inspection process will be used as a very important data to evaluate and improve product quality.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part II},
pages = {623–633},
numpages = {11},
keywords = {PANet, Defect inspection, Machine vision, Deep learning, AI},
location = {Cagliari, Italy}
}

@article{10.1007/s10270-011-0220-1,
author = {Hubaux, Arnaud and Heymans, Patrick and Schobbens, Pierre-Yves and Deridder, Dirk and Abbasi, Ebrahim Khalil},
title = {Supporting multiple perspectives in feature-based configuration},
year = {2013},
issue_date = {July      2013},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {12},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-011-0220-1},
doi = {10.1007/s10270-011-0220-1},
abstract = {Feature diagrams have become commonplace in software product line engineering as a means to document variability early in the life cycle. Over the years, their application has also been extended to assist stakeholders in the configuration of software products. However, existing feature-based configuration techniques offer little support for tailoring configuration views to the profiles of the various stakeholders. In this paper, we propose a lightweight, yet formal and flexible, mechanism to leverage multidimensional separation of concerns in feature-based configuration. We propose a technique to specify concerns in feature diagrams and to generate automatically concern-specific configuration views. Three alternative visualisations are proposed. Our contributions are motivated and illustrated through excerpts from a real web-based meeting management application which was also used for a preliminary evaluation. We also report on the progress made in the development of a tool supporting multi-view feature-based configuration.},
journal = {Softw. Syst. Model.},
month = jul,
pages = {641–663},
numpages = {23},
keywords = {Software product line engineering, Separation of concerns, Multi-view, Feature-based configuration, Feature diagram}
}

@article{10.1007/s10664-020-09915-7,
author = {Temple, Paul and Perrouin, Gilles and Acher, Mathieu and Biggio, Battista and J\'{e}z\'{e}quel, Jean-Marc and Roli, Fabio},
title = {Empirical assessment of generating adversarial configurations for software product lines},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09915-7},
doi = {10.1007/s10664-020-09915-7},
abstract = {Software product line (SPL) engineering allows the derivation of products tailored to stakeholders’ needs through the setting of a large number of configuration options. Unfortunately, options and their interactions create a huge configuration space which is either intractable or too costly to explore exhaustively. Instead of covering all products, machine learning (ML) approximates the set of acceptable products (e.g., successful builds, passing tests) out of a training set (a sample of configurations). However, ML techniques can make prediction errors yielding non-acceptable products wasting time, energy and other resources. We apply adversarial machine learning techniques to the world of SPLs and craft new configurations faking to be acceptable configurations but that are not and vice-versa. It allows to diagnose prediction errors and take appropriate actions. We develop two adversarial configuration generators on top of state-of-the-art attack algorithms and capable of synthesizing configurations that are both adversarial and conform to logical constraints. We empirically assess our generators within two case studies: an industrial video synthesizer (MOTIV) and an industry-strength, open-source Web-app configurator (JHipster). For the two cases, our attacks yield (up to) a 100% misclassification rate without sacrificing the logical validity of adversarial configurations. This work lays the foundations of a quality assurance framework for ML-based SPLs.},
journal = {Empirical Softw. Engg.},
month = jan,
numpages = {49},
keywords = {Quality assurance, Machine learning, Software testing, Software variability, Configurable system, Software product line}
}

@inproceedings{10.1109/SMC52423.2021.9658637,
author = {Li, Nanjian and Zhao, Yawei and Li, Donghui and Guan, Wei},
title = {Real-time Prediction of Highway Equipment Faults Based on GCN and GRU Algorithms},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC52423.2021.9658637},
doi = {10.1109/SMC52423.2021.9658637},
abstract = {The maintenance and renewal of the highway equipment requires a large amount of financial investment, and it is extremely expensive to directly inspect all the equipment in the highway equipment. Therefore, a cost-effective equipment failure prediction technology is needed, such as a failure prediction model, which can detect highway equipment failures in time and reduce maintenance costs. In this paper, knowledge map technology is introduced to construct a highway equipment map, and a highway equipment fault prediction model based on the combination of semi-supervised Graph Convolution Network (GCN) and Gated Recurrent Unit (GRU) is proposed. This model is based on the GCN’s device network feature perception process, with the fault prediction of highway equipment, which uses GRU to extract the real-time features of the device. The initial values of parameters in GCN and GRU adopt Gaussian distribution and uniform distribution respectively. We apply our model to the problem of active maintenance of highway equipment, and have an experiment with the model using a real data set from a Chinese highway company. The results show that our model can effectively use equipment map information and real-time information, and effectively predict the fault of highway equipment only by partial samples, thereby saving fault response time and maintenance costs.},
booktitle = {2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
pages = {3252–3257},
numpages = {6},
location = {Melbourne, Australia}
}

@inproceedings{10.5555/978-3-030-61616-8_fm,
title = {Front Matter},
year = {2020},
isbn = {978-3-030-61615-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Artificial Neural Networks and Machine Learning – ICANN 2020: 29th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 15–18, 2020, Proceedings, Part II},
pages = {i–xxvii},
location = {Bratislava, Slovakia}
}

@inproceedings{10.5555/978-3-030-61609-0_fm,
title = {Front Matter},
year = {2020},
isbn = {978-3-030-61608-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
booktitle = {Artificial Neural Networks and Machine Learning – ICANN 2020: 29th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 15–18, 2020, Proceedings, Part I},
pages = {i–xxvii},
location = {Bratislava, Slovakia}
}

@article{10.5555/1718140.1718142,
author = {Podgorelec, Vili},
title = {Improved mining of software complexity data on evolutionary filtered training sets},
year = {2009},
issue_date = {November 2009},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
address = {Stevens Point, Wisconsin, USA},
volume = {6},
number = {11},
issn = {1790-0832},
abstract = {With the evolution of information technology and software systems, software reliability has become one of the most important topics of software engineering. As the dependency of society on software systems increase, so increases also the importance of efficient software fault prediction. In this paper we present a new approach to improving the classification of faulty software modules. The proposed approach is based on filtering training sets with the introduction of data outliers identification and removal method. The method uses an ensemble of evolutionary induced decision trees to identify the outliers. We argue that a classifier trained by a filtered dataset captures a more general knowledge model and should therefore perform better also on unseen cases. The proposed method is applied on a real-world software reliability analysis dataset and the obtained results are discussed.},
journal = {WSEAS Trans. Info. Sci. and App.},
month = nov,
pages = {1751–1760},
numpages = {10},
keywords = {software fault prediction, search-based software engineering, filtering training sets, evolutionary decision trees, data mining, classification}
}

@article{10.1016/j.neucom.2019.08.086,
author = {Zhang, Hui and Kang, Danqing and He, Haibo and Wang, Fei-Yue},
title = {APLNet: Attention-enhanced progressive learning network},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {371},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.08.086},
doi = {10.1016/j.neucom.2019.08.086},
journal = {Neurocomput.},
month = jan,
pages = {166–176},
numpages = {11},
keywords = {Attention enhancement, Progressive learning, Object detection}
}

@article{10.1155/2018/6791683,
author = {Ji, Haijin and Huang, Song and Gutierrez, Pedro Antonio},
title = {Kernel Entropy Component Analysis with Nongreedy L1-Norm Maximization},
year = {2018},
issue_date = {2018},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2018},
issn = {1687-5265},
url = {https://doi.org/10.1155/2018/6791683},
doi = {10.1155/2018/6791683},
abstract = {Kernel entropy component analysis (KECA) is a newly proposed dimensionality reduction (DR) method, which has showed superiority in many pattern analysis issues previously solved by principal component analysis (PCA). The optimized KECA (OKECA) is a state-of-the-art variant of KECA and can return projections retaining more expressive power than KECA. However, OKECA is sensitive to outliers and accused of its high computational complexities due to its inherent properties of L2-norm. To handle these two problems, we develop a new extension to KECA, namely, KECA-L1, for DR or feature extraction. KECA-L1 aims to find a more robust kernel decomposition matrix such that the extracted features retain information potential as much as possible, which is measured by L1-norm. Accordingly, we design a nongreedy iterative algorithm which has much faster convergence than OKECA’s. Moreover, a general semisupervised classifier is developed for KECA-based methods and employed into the data classification. Extensive experiments on data classification and software defect prediction demonstrate that our new method is superior to most existing KECA- and PCA-based approaches. Code has been also made publicly available.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {9}
}

@inproceedings{10.1145/2393216.2393300,
author = {Anitha, S. and Radha, V.},
title = {Performance of detecting defects in textile fabric using Gabor Wavelet with statistical and Morphological filters},
year = {2012},
isbn = {9781450313100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393216.2393300},
doi = {10.1145/2393216.2393300},
abstract = {Automatic visual inspection is the backbone of any manufacturing industry. Manual inspections of textile fabrics are ineffective due to the fatigue and speed requirement. The Gabor wavelets network provides an effective way to analyze the input images and to extract the fabric features. This paper addresses the functionality of Gabor Wavelet with statistical features and Morphological filtering. The first method extracts statistical features of the input image using Gabor wavelet. Another method combines Gabor wavelet with morphological filtering to select appropriate structuring element. Finally, thresholding of the features are done to produce a binary image. In addition, the performance of the algorithms is evaluated to verify their efficiency in identifying the defective fabric image based on the segmented results.},
booktitle = {Proceedings of the Second International Conference on Computational Science, Engineering and Information Technology},
pages = {501–504},
numpages = {4},
keywords = {morphological filter, fabric, defect detection, Gabor wavelet},
location = {Coimbatore UNK, India},
series = {CCSEIT '12}
}

@inproceedings{10.1145/3336294.3336309,
author = {Temple, Paul and Acher, Mathieu and Perrouin, Gilles and Biggio, Battista and Jezequel, Jean-Marc and Roli, Fabio},
title = {Towards Quality Assurance of Software Product Lines with Adversarial Configurations},
year = {2019},
isbn = {9781450371384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336294.3336309},
doi = {10.1145/3336294.3336309},
abstract = {Software product line (SPL) engineers put a lot of effort to ensure that, through the setting of a large number of possible configuration options, products are acceptable and well-tailored to customers' needs. Unfortunately, options and their mutual interactions create a huge configuration space which is intractable to exhaustively explore. Instead of testing all products, machine learning is increasingly employed to approximate the set of acceptable products out of a small training sample of configurations. Machine learning (ML) techniques can refine a software product line through learned constraints and a priori prevent non-acceptable products to be derived. In this paper, we use adversarial ML techniques to generate adversarial configurations fooling ML classifiers and pinpoint incorrect classifications of products (videos) derived from an industrial video generator. Our attacks yield (up to) a 100% misclassification rate and a drop in accuracy of 5%. We discuss the implications these results have on SPL quality assurance.},
booktitle = {Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A},
pages = {277–288},
numpages = {12},
keywords = {software variability, software testing, software product line, quality assurance, machine learning},
location = {Paris, France},
series = {SPLC '19}
}

@inproceedings{10.1145/3055635.3056630,
author = {Kim, Woongsik},
title = {Wireless Operation Monitoring and Remote Control System Implementation Using the Smartphone-Based Video Camera},
year = {2017},
isbn = {9781450348171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3055635.3056630},
doi = {10.1145/3055635.3056630},
abstract = {In this paper, we show the wireless operation monitoring and remote control system implementation using the smartphone-based video camera. The injection molding machine operation is monitored through a video camera and the defective product is determined by the pattern comparison of the injection product, so that more accurate and quantitative inspection and statistical processing can be performed for the total quality control. This study developed a product that can improve productivity and reduce cost by utilizing existing facilities. It is a product that can be developed according to production equipment and products of each company and can be customized according to characteristics of company. t can be used for the development of production facilities capable of real-time monitoring and control using mobile devices such as smartphones and tablet PCs, which have been actively applied recently.},
booktitle = {Proceedings of the 9th International Conference on Machine Learning and Computing},
pages = {426–431},
numpages = {6},
keywords = {wireless control system, video camera, smart phone, remote control, monitoring},
location = {Singapore, Singapore},
series = {ICMLC '17}
}

@article{10.1016/j.compag.2020.105235,
author = {Mohd Ali, Maimunah and Hashim, Norhashila and Abdul Hamid, Ahmad Shahid},
title = {Combination of laser-light backscattering imaging and computer vision for rapid determination of oil palm fresh fruit bunches maturity},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {169},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2020.105235},
doi = {10.1016/j.compag.2020.105235},
journal = {Comput. Electron. Agric.},
month = feb,
numpages = {9},
keywords = {Oil palm, Maturity, Fresh fruit bunches, Computer vision, Backscattering imaging}
}

@inproceedings{10.1007/978-3-642-33666-9_46,
author = {Ali, Shaukat and Yue, Tao and Briand, Lionel and Walawege, Suneth},
title = {A product line modeling and configuration methodology to support model-based testing: an industrial case study},
year = {2012},
isbn = {9783642336652},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-33666-9_46},
doi = {10.1007/978-3-642-33666-9_46},
abstract = {Product Line Engineering (PLE) is expected to enhance quality and productivity, speed up time-to-market and decrease development effort, through reuse—the key mechanism of PLE. In addition, one can also apply PLE to support systematic testing and more specifically model-based testing (MBT) of product lines—the original motivation behind this work. MBT has shown to be cost-effective in many industry sectors but at the expense of building models of the system under test (SUT). However, the modeling effort to support MBT can significantly be reduced if an adequate product line modeling and configuration methodology is followed, which is the main motivation of this paper. The initial motivation for this work emerged while working with MBT for a Video Conferencing product line at Cisco Systems, Norway. In this paper, we report on our experience in modeling product family models and various types of behavioral variability in the Saturn product line. We focus on behavioral variability in UML state machines since the Video Conferencing Systems (VCSs) exhibit strong state-based behavior and these models are the main drivers for MBT; however, the approach can be also tailored to other UML diagrams. We also provide a mechanism to specify and configure various types of variability using stereotypes and Aspect-Oriented Modeling (AOM). Results of applying our methodology to the Saturn product line modeling and configuration process show that the effort required for modeling and configuring products of the product line family can be significantly reduced.},
booktitle = {Proceedings of the 15th International Conference on Model Driven Engineering Languages and Systems},
pages = {726–742},
numpages = {17},
keywords = {product line engineering, model-based testing, behavioral variability, aspect-oriented modeling, UML state machine},
location = {Innsbruck, Austria},
series = {MODELS'12}
}

@inproceedings{10.1145/3317640.3317661,
author = {Wu, Yang and Liu, Jie and Zhang, Yaqin and Yu, Lianshuang and Wu, Jingchun},
title = {Detection Algorithm of Aluminum Surface Defects Using Machine Vision},
year = {2019},
isbn = {9781450361750},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3317640.3317661},
doi = {10.1145/3317640.3317661},
abstract = {With the growth of global economic and the widespread use of aluminum profile, the consumption of the global aluminum profile increases year by year. In this paper, we proposed a novel detection algorithm of aluminum surface defects using machine vision. Firstly, the aluminum images are acquired and analyzed sequentially, then a number of image processing strategies were used to detect various surface defects. The main contribution is a new area partition method, which can automatically assign texture and no-texture regions with texture information. The proposed method is proven able to detect defects on aluminum profile surfaces, such as cracks, pits, rust or scratches, rapidly and precisely. Robustness and effectiveness in the practical aluminum casting process are improved by using the proposed system.},
booktitle = {Proceedings of the 2019 International Conference on Image, Video and Signal Processing},
pages = {16–22},
numpages = {7},
keywords = {Surface Defect, Region Segmentation, Machine Vision, Detection, Aluminum},
location = {Shanghai, China},
series = {IVSP '19}
}

@article{10.1016/j.eswa.2016.05.018,
author = {Arar, \"{O}mer Faruk and Ayan, K\"{u}r\c{s}at},
title = {Deriving thresholds of software metrics to predict faults on open source software},
year = {2016},
issue_date = {November 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {61},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2016.05.018},
doi = {10.1016/j.eswa.2016.05.018},
abstract = {We empirically examined if there are effective thresholds for software metrics.Open-source software systems were used as benchmarking datasets.The learner model was created using logistic regression and the Bender method.Experimental results revealed that some metrics have effective threshold values. Object-oriented metrics aim to exhibit the quality of source code and give insight to it quantitatively. Each metric assesses the code from a different aspect. There is a relationship between the quality level and the risk level of source code. The objective of this paper is to empirically examine whether or not there are effective threshold values for source code metrics. It is targeted to derive generalized thresholds that can be used in different software systems. The relationship between metric thresholds and fault-proneness was investigated empirically in this study by using ten open-source software systems. Three types of fault-proneness were defined for the software modules: non-fault-prone, more-than-one-fault-prone, and more-than-three-fault-prone. Two independent case studies were carried out to derive two different threshold values. A single set was created by merging ten datasets and was used as training data by the model. The learner model was created using logistic regression and the Bender method. Results revealed that some metrics have threshold effects. Seven metrics gave satisfactory results in the first case study. In the second case study, eleven metrics gave satisfactory results. This study makes contributions primarily for use by software developers and testers. Software developers can see classes or modules that require revising; this, consequently, contributes to an increment in quality for these modules and a decrement in their risk level. Testers can identify modules that need more testing effort and can prioritize modules according to their risk levels.},
journal = {Expert Syst. Appl.},
month = nov,
pages = {106–121},
numpages = {16},
keywords = {Threshold, Software quality metrics, Software fault prediction, Machine learning, Logistic regression, Bender method}
}

@article{10.1155/2018/6798042,
author = {Guo, Huaping and Diao, Xiaoyu and Liu, Hongbing and Gutierrez, Pedro Antonio},
title = {Embedding Undersampling Rotation Forest for Imbalanced Problem},
year = {2018},
issue_date = {2018},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2018},
issn = {1687-5265},
url = {https://doi.org/10.1155/2018/6798042},
doi = {10.1155/2018/6798042},
abstract = {Rotation Forest is an ensemble learning approach achieving better performance comparing to Bagging and Boosting through building accurate and diverse classifiers using rotated feature space. However, like other conventional classifiers, Rotation Forest does not work well on the imbalanced data which are characterized as having much less examples of one class (minority class) than the other (majority class), and the cost of misclassifying minority class examples is often much more expensive than the contrary cases. This paper proposes a novel method called Embedding Undersampling Rotation Forest (EURF) to handle this problem (1) sampling subsets from the majority class and learning a projection matrix from each subset and (2) obtaining training sets by projecting re-undersampling subsets of the original data set to new spaces defined by the matrices and constructing an individual classifier from each training set. For the first method, undersampling is to force the rotation matrix to better capture the features of the minority class without harming the diversity between individual classifiers. With respect to the second method, the undersampling technique aims to improve the performance of individual classifiers on the minority class. The experimental results show that EURF achieves significantly better performance comparing to other state-of-the-art methods.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {15}
}

@inproceedings{10.1109/MSR.2017.4,
author = {Rajbahadur, Gopi Krishnan and Wang, Shaowei and Kamei, Yasutaka and Hassan, Ahmed E.},
title = {The impact of using regression models to build defect classifiers},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.4},
doi = {10.1109/MSR.2017.4},
abstract = {It is common practice to discretize continuous defect counts into defective and non-defective classes and use them as a target variable when building defect classifiers (discretized classifiers). However, this discretization of continuous defect counts leads to information loss that might affect the performance and interpretation of defect classifiers. Another possible approach to build defect classifiers is through the use of regression models then discretizing the predicted defect counts into defective and non-defective classes (regression-based classifiers).In this paper, we compare the performance and interpretation of defect classifiers that are built using both approaches (i.e., discretized classifiers and regression-based classifiers) across six commonly used machine learning classifiers (i.e., linear/logistic regression, random forest, KNN, SVM, CART, and neural networks) and 17 datasets. We find that: i) Random forest based classifiers outperform other classifiers (best AUC) for both classifier building approaches; ii) In contrast to common practice, building a defect classifier using discretized defect counts (i.e., discretized classifiers) does not always lead to better performance.Hence we suggest that future defect classification studies should consider building regression-based classifiers (in particular when the defective ratio of the modeled dataset is low). Moreover, we suggest that both approaches for building defect classifiers should be explored, so the best-performing classifier can be used when determining the most influential features.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {135–145},
numpages = {11},
keywords = {random forest, non-discretization, model interpretation, discretization, classification via regression, bug prediction},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1109/SPLC.2008.28,
author = {Chae, Wonseok and Blume, Matthias},
title = {Building a Family of Compilers},
year = {2008},
isbn = {9780769533032},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SPLC.2008.28},
doi = {10.1109/SPLC.2008.28},
abstract = {We have developed and maintained a set of closely related compilers. Although much of their code is duplicated and shared, they have been maintained separately because they are treated as different compilers. Even if they were merged together, the combined code would become too complicated to serve as the base for another extension. We describe our experience to address this problem by adopting the product line engineering paradigm to build a family of compilers. This paradigm encourages developers to focus on developing a set of compilers rather than on developing one particular compiler. We show engineering activities for a family of compilers from product line analysis through product line architecture design to product line component design. Then, we present how to build particular compilers from core assets resulting from the previous activities and how to take advantage of modern programming language technology to organize this task. Our experience demonstrates that the product line engineering as a developing paradigm can ease the construction of a family of compilers.},
booktitle = {Proceedings of the 2008 12th International Software Product Line Conference},
pages = {307–316},
numpages = {10},
keywords = {standard ml, product line engineering, module system, feature-oriented, compilers},
series = {SPLC '08}
}

@inproceedings{10.1109/MSR.2019.00016,
author = {Hoang, Thong and Dam, Hoa Khanh and Kamei, Yasutaka and Lo, David and Ubayashi, Naoyasu},
title = {DeepJIT: an end-to-end deep learning framework for just-in-time defect prediction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00016},
doi = {10.1109/MSR.2019.00016},
abstract = {Software quality assurance efforts often focus on identifying defective code. To find likely defective code early, change-level defect prediction - aka. Just-In-Time (JIT) defect prediction - has been proposed. JIT defect prediction models identify likely defective changes and they are trained using machine learning techniques with the assumption that historical changes are similar to future ones. Most existing JIT defect prediction approaches make use of manually engineered features. Unlike those approaches, in this paper, we propose an end-to-end deep learning framework, named DeepJIT, that automatically extracts features from commit messages and code changes and use them to identify defects. Experiments on two popular software projects (i.e., QT and OPENSTACK) on three evaluation settings (i.e., cross-validation, short-period, and long-period) show that the best variant of DeepJIT (DeepJIT-Combined), compared with the best performing state-of-the-art approach, achieves improvements of 10.36--11.02% for the project QT and 9.51--13.69% for the project OPENSTACK in terms of the Area Under the Curve (AUC).},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {34–45},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@article{10.1007/s10836-020-05893-2,
author = {Piccoli, Leonardo B. and Henriques, Renato V. B. and Balen, Tiago R.},
title = {Design of an Integrated System for On-line Test and Diagnosis of Rotary Actuators},
year = {2020},
issue_date = {Aug 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {36},
number = {4},
issn = {0923-8174},
url = {https://doi.org/10.1007/s10836-020-05893-2},
doi = {10.1007/s10836-020-05893-2},
abstract = {In this paper, the design of an on-chip Fault Detection and Diagnosis System for Condition Based Maintenance of electromechanical actuators is presented. The proposed system is based on signal processing algorithms integrated in a customized Application Specific Integrated Circuit (ASIC). The design was synthesized using a 90nm CMOS standard cell library. As a case study, post-synthesis simulations were performed using signals acquired from a real electromechanical valve, using torque and vibration sensors considering both fault-free and defective situations for the actuator. Results show the effectiveness of the system in performing real-time fault detection and identification, with low power consumption and low silicon area utilization.},
journal = {J. Electron. Test.},
month = aug,
pages = {547–553},
numpages = {7},
keywords = {Electromechanical actuators, On-line test, Electric valves, Diagnosis, Fault prediction, Fault detection, Condition-based maintenance}
}

@article{10.1007/s10489-017-1106-x,
author = {Xia, Xin and Lin, Tao and Chen, Zhi},
title = {Maximum relevancy maximum complementary based ordered aggregation for ensemble pruning},
year = {2018},
issue_date = {September 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {48},
number = {9},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-017-1106-x},
doi = {10.1007/s10489-017-1106-x},
abstract = {Ensemble methods have delivered exceptional performance in various applications. However, this exceptional performance is achieved at the expense of heavy storage requirements and slower predictions. Ensemble pruning aims at reducing the complexity of this popular learning paradigm without worsening its performance. This paper presents an efficient and effective ordering-based ensemble pruning methods which ranks all the base classifiers with respect to a maximum relevancy maximum complementary (MRMC) measure. The MRMC measure evaluates the base classifier's classification ability as well as its complementariness to the ensemble, and thereby a set of accurate and complementary base classifiers can be selected. Moreover, an evaluation function that deliberately favors the candidate sub-ensembles with a better performance in classifying low margin instances has also been proposed. Experiments performed on 25 benchmark datasets demonstrate the effectiveness of our proposed method.},
journal = {Applied Intelligence},
month = sep,
pages = {2568–2579},
numpages = {12},
keywords = {Ordering-based ensemble pruning, Mutual information, Margin distribution, Diversity}
}

@inproceedings{10.1007/978-3-319-30285-0_3,
author = {Chmielewski, Leszek J. and Or\l{}owski, Arkadiusz and undefinedmieta\'{n}ska, Katarzyna and G\'{o}rski, Jaros\l{}aw and Krajewski, Krzysztof and Janowicz, Maciej and Wilkowski, Jacek and Kietli\'{n}ska, Krystyna},
title = {Detection of Surface Defects of Type ‘orange skin’ in Furniture Elements with Conventional Image Processing Methods},
year = {2015},
isbn = {978-3-319-30284-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-30285-0_3},
doi = {10.1007/978-3-319-30285-0_3},
abstract = {An attempt was made to differentiate between surfaces of furniture elements having the orange skin defect and those free from it. As the detectors, the directional derivative of the image intensity along the dominating light direction and the modulus of the image intensity gradient were used. The detectors were tested on series of images with the small and large light incident angles. In case of both detectors, there existed sufficiently wide ranges of thresholds for which both sensitivity and specificity were  for all the 19&nbsp;images tested. The ranges of thresholds were wider for the light closer to tangential, and for the detector using the gradient modulus, than for the other cases. The optimum scale of the detectors was found different for each light conditions.},
booktitle = {Image and Video Technology – PSIVT 2015 Workshops: RV 2015, GPID 2013, VG 2015, EO4AS 2015, MCBMIIA 2015, and VSWS 2015, Auckland, New Zealand, November 23-27, 2015. Revised Selected Papers},
pages = {26–37},
numpages = {12},
keywords = {Image intensity, Gradient modulus, Directional derivative, Orange skin, Furniture elements, Quality inspection, Defect detection},
location = {Auckland, New Zealand}
}

@article{10.1016/j.knosys.2015.01.010,
author = {Lu, Jie and Behbood, Vahid and Hao, Peng and Zuo, Hua and Xue, Shan and Zhang, Guangquan},
title = {Transfer learning using computational intelligence},
year = {2015},
issue_date = {May 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {80},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.01.010},
doi = {10.1016/j.knosys.2015.01.010},
abstract = {Transfer learning aims to provide a framework to utilize previously-acquired knowledge to solve new but similar problems much more quickly and effectively. In contrast to classical machine learning methods, transfer learning methods exploit the knowledge accumulated from data in auxiliary domains to facilitate predictive modeling consisting of different data patterns in the current domain. To improve the performance of existing transfer learning methods and handle the knowledge transfer process in real-world systems, computational intelligence has recently been applied in transfer learning. This paper systematically examines computational intelligence-based transfer learning techniques and clusters related technique developments into four main categories: (a) neural network-based transfer learning; (b) Bayes-based transfer learning; (c) fuzzy transfer learning, and (d) applications of computational intelligence-based transfer learning. By providing state-of-the-art knowledge, this survey will directly support researchers and practice-based professionals to understand the developments in computational intelligence-based transfer learning research and applications.},
journal = {Know.-Based Syst.},
month = may,
pages = {14–23},
numpages = {10},
keywords = {Transfer learning, Neural network, Genetic algorithm, Fuzzy sets and systems, Computational intelligence, Bayes}
}

@inproceedings{10.1145/2499393.2499395,
author = {Herbold, Steffen},
title = {Training data selection for cross-project defect prediction},
year = {2013},
isbn = {9781450320160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499393.2499395},
doi = {10.1145/2499393.2499395},
abstract = {Software defect prediction has been a popular research topic in recent years and is considered as a means for the optimization of quality assurance activities. Defect prediction can be done in a within-project or a cross-project scenario. The within-project scenario produces results with a very high quality, but requires historic data of the project, which is often not available. For the cross-project prediction, the data availability is not an issue as data from other projects is readily available, e.g., in repositories like PROMISE. However, the quality of the defect prediction results is too low for practical use. Recent research showed that the selection of appropriate training data can improve the quality of cross-project defect predictions. In this paper, we propose distance-based strategies for the selection of training data based on distributional characteristics of the available data. We evaluate the proposed strategies in a large case study with 44 data sets obtained from 14 open source projects. Our results show that our training data selection strategy improves the achieved success rate of cross-project defect predictions significantly. However, the quality of the results still cannot compete with within-project defect prediction.},
booktitle = {Proceedings of the 9th International Conference on Predictive Models in Software Engineering},
articleno = {6},
numpages = {10},
keywords = {cross-project prediction, defect-prediction, machine learning},
location = {Baltimore, Maryland, USA},
series = {PROMISE '13}
}

@article{10.1016/j.patrec.2018.12.013,
author = {Han, Hui and Gao, Chenqiang and Zhao, Yue and Liao, Shisha and Tang, Lin and Li, Xindou},
title = {Polycrystalline silicon wafer defect segmentation based on deep convolutional neural networks},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {130},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2018.12.013},
doi = {10.1016/j.patrec.2018.12.013},
journal = {Pattern Recogn. Lett.},
month = feb,
pages = {234–241},
numpages = {8},
keywords = {65D17, 65D05, 41A10, 41A05, CNN, Defects segmentation, RPN, Polycrystalline silicon wafer}
}

@article{10.1016/j.jss.2017.07.006,
author = {Lu, Wei and Li, Zhe and Chu, Jinghui},
title = {Adaptive Ensemble Undersampling-Boost},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {132},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.07.006},
doi = {10.1016/j.jss.2017.07.006},
abstract = {We propose a framework for imbalanced classification tasks with ensemble learning.We propose a weight modification method to give each classifier an adaptive weight.We introduce OTSU algorithm to determine the optimal threshold adaptively.We make comparisons between our proposals and several state-of-the-art algorithms. As one of the most challenging and attractive problems in the pattern recognition and machine intelligence field, imbalanced classification has received a large amount of research attention for many years. In binary classification tasks, one class usually tends to be underrepresented when it consists of far fewer patterns than the other class, which results in undesirable classification results, especially for the minority class. Several techniques, including resampling, boosting and cost-sensitive methods have been proposed to alleviate this problem. Recently, some ensemble methods that focus on combining individual techniques to obtain better performance have been observed to present better classification performance on the minority class. In this paper, we propose a novel ensemble framework called Adaptive Ensemble Undersampling-Boost for imbalanced learning. Our proposal combines the Ensemble of Undersampling (EUS) technique, Real Adaboost, cost-sensitive weight modification, and adaptive boundary decision strategy to build a hybrid algorithm. The superiority of our method over other state-of-the-art ensemble methods is demonstrated by experiments on 18 real world data sets with various data distributions and different imbalance ratios. Given the experimental results and further analysis, our proposal is proven to be a promising alternative that can be applied to various imbalanced classification domains.},
journal = {J. Syst. Softw.},
month = oct,
pages = {272–282},
numpages = {11},
keywords = {Voting algorithm, Real Adaboost, Imbalanced data sets, Ensemble Undersampling, Classification, Adaptive decision boundary, 07.05.Kf}
}

@article{10.1016/j.cosrev.2020.100297,
author = {Nayak, Janmenjoy and Vakula, Kanithi and Dinesh, Paidi and Naik, Bighnaraj and Pelusi, Danilo},
title = {Intelligent food processing: Journey from artificial neural network to deep learning},
year = {2020},
issue_date = {Nov 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {38},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2020.100297},
doi = {10.1016/j.cosrev.2020.100297},
journal = {Comput. Sci. Rev.},
month = nov,
numpages = {28},
keywords = {Deep learning, Machine learning, Artificial neural network, Artificial intelligence, Food processing}
}

@article{10.1007/s11265-020-01571-w,
author = {Hotait, H. and Chiementin, X. and Mouchaweh, M. Sayed and Rasolofondraibe, L.},
title = {Monitoring of Ball Bearing Based on Improved Real-Time OPTICS Clustering},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {93},
number = {2–3},
issn = {1939-8018},
url = {https://doi.org/10.1007/s11265-020-01571-w},
doi = {10.1007/s11265-020-01571-w},
abstract = {This paper presents a new methodology of the Real-Time monitoring (IRT-OPTICS) for the detection of defect in rolling bearing by combining three domain features (time, frequency and scale), and reducing dimension by two methods: Principal Component Analysis (PCA) and Kernel Principal Component Analysis (KPCA), then classifying data by OPTICS method (Ordering Points To Identify the Clustering Structure). This methodology generated in three loops: initialization, detection and follow-up. The initialization loop is the fundamental and the based loop to start the surveillance. The detection loop is the phase where machines defects can be detected, in case there is defect, the third loop will start. The third loop is the follow-up; it aims to observe the degradation state. The decision to replace a component can be taken in the follow-up. These three loops use the combination of three features extraction methods: time domain, frequency domain and time scale domain also they use reduction of dimension by two methods, to combine features in three components and then to classify them by the OPTICS method. The proposed method has been validated numerically and experimentally.},
journal = {J. Signal Process. Syst.},
month = mar,
pages = {221–237},
numpages = {17},
keywords = {And RT-OPTICS, PCA, KPCA, Fault diagnosis, Rolling bearing, Vibratory monitoring, Classification}
}

@inproceedings{10.1109/IST48021.2019.9010098,
author = {Wei, Jiaqi and Zhu, Peiyuan and Qian, Xiang and Zhu, Shidong},
title = {One-stage object detection networks for inspecting the surface defects of magnetic tiles},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IST48021.2019.9010098},
doi = {10.1109/IST48021.2019.9010098},
abstract = {One of the core components of the permanent magnet motor is magnetic tile and surface defect detection of it is of vital importance to ensure the performance and service life of the motor. This paper employs a deep learning method based on computer vision to detect the surface defects on magnetic tiles in order to replace manual inspection and increase productivity. Considering the real-time requirements of the industrial site, three designed one-stage object detection networks of different depth are compared on our Inner-R surface dataset of magnetic tiles. The whole image is input into the networks which regard the object detection as a regression problem and output the value of class probability and position coordinate of the object. This approach can detect more than one defects on the same image as well as the location of defects which provides advantages to find the number of defects per class and improve the manufacturing process. As the result shows, the YOLOv3 network is the most applicable one in this magnetic tile surface defect detection problem and the detection time is less than 23 ms, which is an eye-catching result.},
booktitle = {2019 IEEE International Conference on Imaging Systems and Techniques (IST)},
pages = {1–6},
numpages = {6},
location = {Abu Dhabi, United Arab Emirates}
}

@article{10.1007/s10664-020-09856-1,
author = {Ros, Rasmus and Hammar, Mikael},
title = {Data-driven software design with Constraint Oriented Multi-variate Bandit Optimization (COMBO)},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09856-1},
doi = {10.1007/s10664-020-09856-1},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3841–3872},
numpages = {32},
keywords = {Combinatorial optimization, Multi-armed bandits, Machine learning, A/B testing, Continuous experimentation}
}

@article{10.1007/s11219-010-9112-9,
author = {Bak\i{}r, Ay\c{s}e and Turhan, Burak and Bener, Ay\c{s}e},
title = {A comparative study for estimating software development effort intervals},
year = {2011},
issue_date = {September 2011},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-010-9112-9},
doi = {10.1007/s11219-010-9112-9},
abstract = {Software cost/effort estimation is still an open challenge. Many researchers have proposed various methods that usually focus on point estimates. Until today, software cost estimation has been treated as a regression problem. However, in order to prevent overestimates and underestimates, it is more practical to predict the interval of estimations instead of the exact values. In this paper, we propose an approach that converts cost estimation into a classification problem and that classifies new software projects in one of the effort classes, each of which corresponds to an effort interval. Our approach integrates cluster analysis with classification methods. Cluster analysis is used to determine effort intervals while different classification algorithms are used to find corresponding effort classes. The proposed approach is applied to seven public datasets. Our experimental results show that the hit rate obtained for effort estimation are around 90---100%, which is much higher than that obtained by related studies. Furthermore, in terms of point estimation, our results are comparable to those in the literature although a simple mean/median is used for estimation. Finally, the dynamic generation of effort intervals is the most distinctive part of our study, and it results in time and effort gain for project managers through the removal of human intervention.},
journal = {Software Quality Journal},
month = sep,
pages = {537–552},
numpages = {16},
keywords = {Software effort estimation, Machine learning, Interval prediction, Cluster analysis, Classification}
}

