@inproceedings{10.1007/978-3-030-90785-3_16,
author = {Wang, Baoping and Wang, Wennan and Zhu, Linkai and Liu, Wenjian},
title = {Research on Cross-Project Software Defect Prediction Based on Machine Learning},
year = {2021},
isbn = {978-3-030-90784-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90785-3_16},
doi = {10.1007/978-3-030-90785-3_16},
abstract = {In recent years, machine learning technology has developed vigorously. The research on software defect prediction in the field of software engineering is increasingly adopting various algorithms of machine learning. This article has carried out a systematic literature review on the field of defect prediction. First, this article studies the development process of defect prediction, from correlation to prediction model. then this article studies the development process of cross-project defect prediction based on machine learning algorithms (naive Bayes, decision tree, random forest, neural network, etc.). Finally, this paper looks forward to the research difficulties and future directions of software defect prediction, such as imbalance in classification, cost of data labeling, and cross-project data distribution.},
booktitle = {Advances in Web-Based Learning – ICWL 2021: 20th International Conference, ICWL 2021, Macau, China, November 13–14, 2021, Proceedings},
pages = {160–165},
numpages = {6},
keywords = {Machine learning, Software defect prediction model, Metric},
location = {Macau, China}
}

@article{10.1016/j.jss.2021.111026,
author = {Zhu, Kun and Ying, Shi and Zhang, Nana and Zhu, Dandan},
title = {Software defect prediction based on enhanced metaheuristic feature selection optimization and a hybrid deep neural network},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111026},
doi = {10.1016/j.jss.2021.111026},
journal = {J. Syst. Softw.},
month = oct,
numpages = {25},
keywords = {Software defect prediction, Metaheuristic feature selection, Whale optimization algorithm, Convolutional neural network, Kernel extreme learning machine}
}

@inproceedings{10.1145/3416508.3417114,
author = {Aljamaan, Hamoud and Alazba, Amal},
title = {Software defect prediction using tree-based ensembles},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417114},
doi = {10.1145/3416508.3417114},
abstract = {Software defect prediction is an active research area in software engineering. Accurate prediction of software defects assists software engineers in guiding software quality assurance activities. In machine learning, ensemble learning has been proven to improve the prediction performance over individual machine learning models. Recently, many Tree-based ensembles have been proposed in the literature, and their prediction capabilities were not investigated in defect prediction. In this paper, we will empirically investigate the prediction performance of seven Tree-based ensembles in defect prediction. Two ensembles are classified as bagging ensembles: Random Forest and Extra Trees, while the other five ensembles are boosting ensembles: Ada boost, Gradient Boosting, Hist Gradient Boosting, XGBoost and CatBoost. The study utilized 11 publicly available MDP NASA software defect datasets. Empirical results indicate the superiority of Tree-based bagging ensembles: Random Forest and Extra Trees ensembles over other Tree-based boosting ensembles. However, none of the investigated Tree-based ensembles was significantly lower than individual decision trees in prediction performance. Finally, Adaboost ensemble was the worst performing ensemble among all Tree-based ensembles.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {1–10},
numpages = {10},
keywords = {Bagging, Boosting, Classification, Ensemble Learning, Machine Learning, Prediction, Software Defect},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@inproceedings{10.1145/3368926.3369711,
author = {Ha, Duy-An and Chen, Ting-Hsuan and Yuan, Shyan-Ming},
title = {Unsupervised methods for Software Defect Prediction},
year = {2019},
isbn = {9781450372459},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368926.3369711},
doi = {10.1145/3368926.3369711},
abstract = {Software Defect Prediction (SDP) aims to assess software quality by using machine learning techniques. Recently, by proposing the connectivity-based unsupervised learning method, Zhang et al. have been proven that unsupervised classification has great potential to apply to this problem. Inspiring by this idea, in our work we try to replicate the results of Zhang et al.'s experiment and attempt to improve the performance by examining different techniques at each step of the approach using unsupervised learning methods to solve the SDP problem. Specifically, we try to follow the steps of the experiment described in their work strictly and examine three other clustering methods with four other ways for feature selection besides using all. To the best of our knowledge, these methods are first applied in SDP to evaluate their predictive power. For replicating the results, generally results in our experiments are not as good as the previous work. It may be due to we do not know which features are used in their experiment exactly. Fluid clustering and spectral clustering give better results than Newman clustering and CNM clustering in our experiments. Additionally, the experiments also show that using Kernel Principal Component Analysis (KPCA) or Non-Negative Matrix Factorization (NMF) for feature selection step gives better performance than using all features in the case of unlabeled data. Lastly, to make replicating our work easy, a lightweight framework is created and released on Github.},
booktitle = {Proceedings of the 10th International Symposium on Information and Communication Technology},
pages = {49–55},
numpages = {7},
keywords = {Community Structure Detection, Machine Learning, Software Defect Prediction, Software Engineering, Unsupervised Learning},
location = {Hanoi, Ha Long Bay, Viet Nam},
series = {SoICT '19}
}

@inproceedings{10.1145/3387940.3391463,
author = {Omri, Safa and Sinz, Carsten},
title = {Deep Learning for Software Defect Prediction: A Survey},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391463},
doi = {10.1145/3387940.3391463},
abstract = {Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {209–214},
numpages = {6},
keywords = {deep learning, machine learning, software defect prediction, software quality assurance, software testing},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3474198.3478215,
author = {Du, Xiaozhi and Yue, Hehe and Dong, Honglei},
title = {Software Defect Prediction Method based on Hybrid Sampling},
year = {2022},
isbn = {9781450390149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474198.3478215},
doi = {10.1145/3474198.3478215},
abstract = {Software defect prediction is an essential technology to provide guidance and assistance for software testers and developers. However, the problem of imbalanced data sets limits the effect and application of the software defect prediction. To address this issue, this paper proposes a software defect prediction method based on hybrid sampling, which combines the strategies of over-sampling with under-sampling. For minority class, over-sampling uses k-means to cluster samples, then adopts SMOTE to generate artificial data based on safe areas of the clustering outcome. For majority class, under-sampling uses logistic regression classifier to get the misclassification probability of each sample and its instance hardness value. Then the samples, whose instance hardness values are lower than the threshold, are removed from the datasets. The experimental results show that our method is superior to the previous methods. Compared with SMOTE-kNN, SMOTE-Tomek, SMOTE and DBSMOTE, the accuracy of our method is improved by 17.60%, 6.99%, 8.66% and 26.18% on average respectively.},
booktitle = {International Conference on Frontiers of Electronics, Information and Computation Technologies},
articleno = {93},
numpages = {9},
keywords = {Data imbalance, Hybrid sampling, Software defect prediction},
location = {Changsha, China},
series = {ICFEICT 2021}
}

@inproceedings{10.1145/3474124.3474127,
author = {Rajnish, Kumar and Bhattacharjee, Vandana and Chandrabanshi, Vishnu},
title = {Applying Cognitive and Neural Network Approach over Control Flow Graph for Software Defect Prediction},
year = {2021},
isbn = {9781450389204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474124.3474127},
doi = {10.1145/3474124.3474127},
booktitle = {Proceedings of the 2021 Thirteenth International Conference on Contemporary Computing},
pages = {13–17},
numpages = {5},
keywords = {CFGs, Cognitive Complexity, Cognitive Measures, Graph Convolutional Network, Neural Network, Software Defect Prediction},
location = {Noida, India},
series = {IC3-2021}
}

@article{10.1007/s10586-018-1730-1,
author = {Jayanthi, R. and Florence, Lilly},
title = {Software defect prediction techniques using metrics based on neural network classifier},
year = {2019},
issue_date = {Jan 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {1},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-018-1730-1},
doi = {10.1007/s10586-018-1730-1},
abstract = {Software industries strive for software quality improvement by consistent bug prediction, bug removal and prediction of fault-prone module. This area has attracted researchers due to its significant involvement in software industries. Various techniques have been presented for software defect prediction. Recent researches have recommended data-mining using machine learning as an important paradigm for software bug prediction. state-of-art software defect prediction task suffer from various issues such as classification accuracy. However, software defect datasets are imbalanced in nature and known fault prone due to its huge dimension. To address this issue, here we present a combined approach for software defect prediction and prediction of software bugs. Proposed approach delivers a concept of feature reduction and artificial intelligence where feature reduction is carried out by well-known principle component analysis (PCA) scheme which is further improved by incorporating maximum-likelihood estimation for error reduction in PCA data reconstruction. Finally, neural network based classification technique is applied which shows prediction results. A framework is formulated and implemented on NASA software dataset where four datasets i.e., KC1, PC3, PC4 and JM1 are considered for performance analysis using MATLAB simulation tool. An extensive experimental study is performed where confusion, precision, recall, classification accuracy etc. parameters are computed and compared with existing software defect prediction techniques. Experimental study shows that proposed approach can provide better performance for software defect prediction.},
journal = {Cluster Computing},
month = jan,
pages = {77–88},
numpages = {12},
keywords = {Defect prediction models, Machine learning techniques, Software defect prediction, Software metrics}
}

@article{10.1007/s00521-020-04960-1,
author = {Wang, Kechao and Liu, Lin and Yuan, Chengjun and Wang, Zhifei},
title = {Software defect prediction model based on LASSO–SVM},
year = {2021},
issue_date = {Jul 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {14},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04960-1},
doi = {10.1007/s00521-020-04960-1},
abstract = {A software defect report is a bug in the software system that developers and users submit to the software defect library during software development and maintenance. Managing a software defect report that is overwhelming is a challenging task. The traditional method is manual identification, which is time-consuming and laborious and delays the repair of important software defects. Based on the above background, the purpose of this paper is to study the software defect prediction (SDP) model based on LASSO–SVM. In this paper, the problem of poor prediction accuracy of most SDP models is proposed. A SDP model combining minimum absolute value compression and selection method and support vector machine algorithm is proposed. Firstly, the feature selection ability of the minimum absolute value compression and selection method is used to reduce the dimension of the original data set, and the data set not related to SDP is removed. Then, the optimal value of SVM is obtained by using the parameter optimization ability of cross-validation algorithm. Finally, the SDP is completed by the nonlinear computing ability of SVM. The accuracy of simulation results is 93.25% and 66.67%, recall rate is 78.04%, and f-metric is 72.72%. The results show that the proposed defect prediction model has higher prediction accuracy than the traditional defect prediction model, and the prediction speed is faster.},
journal = {Neural Comput. Appl.},
month = jul,
pages = {8249–8259},
numpages = {11},
keywords = {Software defect prediction, Feature selection, Support vector machine, Cross-validation}
}

@article{10.1016/j.infsof.2021.106664,
author = {Yao, Jingxiu and Shepperd, Martin},
title = {The impact of using biased performance metrics on software defect prediction research},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106664},
doi = {10.1016/j.infsof.2021.106664},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {14},
keywords = {Software engineering, Machine learning, Software defect prediction, Computational experiment, Classification metrics}
}

@article{10.1016/j.neucom.2019.11.067,
author = {Qiao, Lei and Li, Xuesong and Umer, Qasim and Guo, Ping},
title = {Deep learning based software defect prediction},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {385},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.11.067},
doi = {10.1016/j.neucom.2019.11.067},
journal = {Neurocomput.},
month = apr,
pages = {100–110},
numpages = {11},
keywords = {Software defect prediction, Deep learning, Software quality, Software metrics, Robustness evaluation}
}

@article{10.1007/s11334-021-00399-2,
author = {Suresh Kumar, P. and Behera, H. S. and Nayak, Janmenjoy and Naik, Bighnaraj},
title = {Bootstrap aggregation ensemble learning-based reliable approach for software defect prediction by using characterized code feature},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {17},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-021-00399-2},
doi = {10.1007/s11334-021-00399-2},
abstract = {To ensure software quality, software defect prediction plays a prominent role for the software developers and practitioners. Software defect prediction can assist us with distinguishing software defect modules and enhance the software quality. In present days, many supervised machine learning algorithms have proved their efficacy to identify defective modules. However, those are limited to prove their major significance due to the limitations such as the adaptation of parameters with the environment and complexity. So, it is important to develop a key methodology to improve the efficiency of the prediction module. In this paper, an ensemble learning technique called&nbsp;Bootstrap&nbsp;aggregating has been proposed for software defect prediction object-oriented modules. The proposed method's accuracy, recall, precision, F-measure, and AUC-ROC efficiency were compared to those of many qualified machine learning algorithms. Simulation results and performance comparison are evident that the proposed method outperformed well compared to other approaches.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {355–379},
numpages = {25},
keywords = {Ensemble learning, Software defect prediction, Software reliability, Machine learning}
}

@inproceedings{10.1109/ICSE43902.2021.00050,
author = {Shrikanth, N. C. and Majumder, Suvodeep and Menzies, Tim},
title = {Early Life Cycle Software Defect Prediction: Why? How?},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00050},
doi = {10.1109/ICSE43902.2021.00050},
abstract = {Many researchers assume that, for software analytics, "more data is better." We write to show that, at least for learning defect predictors, this may not be true.To demonstrate this, we analyzed hundreds of popular GitHub projects. These projects ran for 84 months and contained 3,728 commits (median values). Across these projects, most of the defects occur very early in their life cycle. Hence, defect predictors learned from the first 150 commits and four months perform just as well as anything else. This means that, at least for the projects studied here, after the first few months, we need not continually update our defect prediction models.We hope these results inspire other researchers to adopt a "simplicity-first" approach to their work. Some domains require a complex and data-hungry analysis. But before assuming complexity, it is prudent to check the raw data looking for "short cuts" that can simplify the analysis.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {448–459},
numpages = {12},
keywords = {analytics, defect prediction, early, sampling},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1007/s11063-020-10355-z,
author = {Niu, Liang and Wan, Jianwu and Wang, Hongyuan and Zhou, Kaiwei},
title = {Cost-sensitive Dictionary Learning for Software Defect Prediction},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {3},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-020-10355-z},
doi = {10.1007/s11063-020-10355-z},
abstract = {In recent years, software defect prediction has been recognized as a cost-sensitive learning problem. To deal with the unequal misclassification losses resulted by different classification errors, some cost-sensitive dictionary learning methods have been proposed recently. Generally speaking, these methods usually define the misclassification costs to measure the unequal losses and then propose to minimize the cost-sensitive reconstruction loss by embedding the cost information into the reconstruction function of dictionary learning. Although promising performance has been achieved, their cost-sensitive reconstruction functions are not well-designed. In addition, no sufficient attentions are paid to the coding coefficients which can also be helpful to reduce the reconstruction loss. To address these issues, this paper proposes a new cost-sensitive reconstruction loss function and introduces an additional cost-sensitive discrimination regularization for the coding coefficients. Both the two terms are jointly optimized in a unified cost-sensitive dictionary learning framework. By doing so, we can achieve the minimum reconstruction loss and thus obtain a more cost-sensitive dictionary for feature encoding of test data. In the experimental part, we have conducted extensive experiments on twenty-five software projects from four benchmark datasets of NASA, AEEEM, ReLink and Jureczko. The results, in comparison with ten state-of-the-art software defect prediction methods, demonstrate the effectiveness of learned cost-sensitive dictionary for software defect prediction.},
journal = {Neural Process. Lett.},
month = dec,
pages = {2415–2449},
numpages = {35},
keywords = {Software defect prediction, Cost-sensitive, Dictionary learning, Discrimination}
}

@inproceedings{10.1007/978-3-030-37352-8_13,
author = {Cui, Mengtian and Huang, Yameng and Luo, Jing},
title = {Software Defect Prediction Model Based on GA-BP Algorithm},
year = {2019},
isbn = {978-3-030-37351-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-37352-8_13},
doi = {10.1007/978-3-030-37352-8_13},
abstract = {The novel software defect prediction model based on GA-BP algorithm was proposed in the paper considering the disadvantage of traditional BP (abbreviated for Back Propagation) neural network, which has the problem of easy to fall into local optimization when constructing software defect prediction model, and finally affects the prediction accuracy. Firstly, the optimization ability of GA (abbreviated for Genetic Algorithms) is introduced to optimize the weights and thresholds of Back Propagation neural network. Then the prediction model was constructed based on the GA-BP. Meanwhile the public dataset MDP from NASA was selected and the tool WEKA was used to clean the data and format conversion and as the result, four datasets is available. In the end, experimental results show that the proposed method in the paper is effective for software defect prediction.},
booktitle = {Cyberspace Safety and Security: 11th International Symposium, CSS 2019, Guangzhou, China, December 1–3, 2019, Proceedings, Part II},
pages = {151–161},
numpages = {11},
keywords = {Software defect prediction, Machine learning, Genetic Algorithms, BP neural network},
location = {Guangzhou, China}
}

@article{10.1049/iet-sen.2019.0149,
author = {Deng, Jiehan and Lu, Lu and Qiu, Shaojian},
title = {Software defect prediction via LSTM},
year = {2020},
issue_date = {August 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {4},
url = {https://doi.org/10.1049/iet-sen.2019.0149},
doi = {10.1049/iet-sen.2019.0149},
abstract = {Software quality plays an important role in the software lifecycle. Traditional software defect prediction approaches mainly focused on using hand‐crafted features to detect defects. However, like human languages, programming languages contain rich semantic and structural information, and the cause of defective code is closely related to its context. Failing to catch this significant information, the performance of traditional approaches is far from satisfactory. In this study, the authors leveraged a long short‐term memory (LSTM) network to automatically learn the semantic and contextual features from the source code. Specifically, they first extract the program's Abstract Syntax Trees (ASTs), which is made up of AST nodes, and then evaluate what and how much information they can preserve for several node types. They traverse the AST of each file and fed them into the LSTM network to automatically the semantic and contextual features of the program, which is then used to determine whether the file is defective. Experimental results on several opensource projects showed that the proposed LSTM method is superior to the state‐of‐the‐art methods.},
journal = {IET Software},
month = aug,
pages = {443–450},
numpages = {8},
keywords = {feature extraction, learning (artificial intelligence), public domain software, program diagnostics, program debugging, software quality, recurrent neural nets, trees (mathematics), program abstract syntax trees, AST node sequence, semantic features, contextual features, LSTM, software quality, software lifecycle, software defect prediction approaches, machine learning techniques, programming languages, human languages, structural information, defective code, long short-term memory network, open source projects, numerical vectors, word embedding techniques}
}

@article{10.1007/s11219-016-9353-3,
author = {Bowes, David and Hall, Tracy and Petri\'{c}, Jean},
title = {Software defect prediction: do different classifiers find the same defects?},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9353-3},
doi = {10.1007/s11219-016-9353-3},
abstract = {During the last 10 years, hundreds of different defect prediction models have been published. The performance of the classifiers used in these models is reported to be similar with models rarely performing above the predictive performance ceiling of about 80% recall. We investigate the individual defects that four classifiers predict and analyse the level of prediction uncertainty produced by these classifiers. We perform a sensitivity analysis to compare the performance of Random Forest, Na\"{\i}ve Bayes, RPart and SVM classifiers when predicting defects in NASA, open source and commercial datasets. The defect predictions that each classifier makes is captured in a confusion matrix and the prediction uncertainty of each classifier is compared. Despite similar predictive performance values for these four classifiers, each detects different sets of defects. Some classifiers are more consistent in predicting defects than others. Our results confirm that a unique subset of defects can be detected by specific classifiers. However, while some classifiers are consistent in the predictions they make, other classifiers vary in their predictions. Given our results, we conclude that classifier ensembles with decision-making strategies not based on majority voting are likely to perform best in defect prediction.},
journal = {Software Quality Journal},
month = jun,
pages = {525–552},
numpages = {28},
keywords = {Machine learning, Prediction modelling, Software defect prediction}
}

@article{10.1002/smr.2362,
author = {Guo, Shikai and Dong, Jian and Li, Hui and Wang, Jiahui},
title = {Software defect prediction with imbalanced distribution by radius‐synthetic minority over‐sampling technique},
year = {2021},
issue_date = {July 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {7},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2362},
doi = {10.1002/smr.2362},
abstract = {Software defect prediction, which can identify the defect‐prone modules, is an effective technology to ensure the quality of software products. Due to the importance in software maintenance, many learning‐based software defect prediction models are presented in recent years. Actually, the defects usually occupy a very small proportions in software source codes; thus, the imbalanced distributions between defect‐prone modules and non‐defect‐prone modules increase the learning difficulty of the classification task. To address this issue, we present a random over‐sampling mechanism used to generate minority‐class samples from high‐dimensional sampling space to deal with the imbalanced distributions in software defect prediction, in which two constraints are applied to provide a robust way to generate new synthetic samples, that is, scaling the random over‐sampling scope to a reasonable area and distinguishing the majority‐class samples in a critical region. Based on nine open datasets of software projects, we experimentally verify that our presented method is effective on predict the defect‐prone modules, and the effect is superior to the traditional imbalanced processing methods.},
journal = {J. Softw. Evol. Process},
month = jul,
numpages = {21},
keywords = {imbalanced learning, software defect prediction, software quality}
}

@inproceedings{10.1007/978-3-030-58817-5_45,
author = {Balogun, Abdullateef O. and Lafenwa-Balogun, Fatimah B. and Mojeed, Hammed A. and Adeyemo, Victor E. and Akande, Oluwatobi N. and Akintola, Abimbola G. and Bajeh, Amos O. and Usman-Hamza, Fatimah E.},
title = {SMOTE-Based Homogeneous Ensemble Methods for Software Defect Prediction},
year = {2020},
isbn = {978-3-030-58816-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58817-5_45},
doi = {10.1007/978-3-030-58817-5_45},
abstract = {Class imbalance is a prevalent problem in machine learning which affects the prediction performance of classification algorithms. Software Defect Prediction (SDP) is no exception to this latent problem. Solutions such as data sampling and ensemble methods have been proposed to address the class imbalance problem in SDP. This study proposes a combination of Synthetic Minority Oversampling Technique (SMOTE) and homogeneous ensemble (Bagging and Boosting) methods for predicting software defects. The proposed approach was implemented using Decision Tree (DT) and Bayesian Network (BN) as base classifiers on defects datasets acquired from NASA software corpus. The experimental results showed that the proposed approach outperformed other experimental methods. High accuracy of 86.8% and area under operating receiver characteristics curve value of 0.93% achieved by the proposed technique affirmed its ability to differentiate between the defective and non-defective labels without bias.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part VI},
pages = {615–631},
numpages = {17},
keywords = {Software Defect Prediction, Class imbalance, Data sampling, Ensemble methods},
location = {Cagliari, Italy}
}

@article{10.1016/j.jss.2021.111038,
author = {Eken, Beyza and Tosun, Ayse},
title = {Investigating the performance of personalized models for software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {181},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111038},
doi = {10.1016/j.jss.2021.111038},
journal = {J. Syst. Softw.},
month = nov,
numpages = {17},
keywords = {Personalized, Change-level, Defect prediction, Software recommendation systems}
}

@article{10.4018/IJDSST.2020070105,
author = {Kakkar, Misha and Jain, Sarika and Bansal, Abhay and Grover, P. S.},
title = {Nonlinear Geometric Framework for Software Defect Prediction},
year = {2020},
issue_date = {Jul 2020},
publisher = {IGI Global},
address = {USA},
volume = {12},
number = {3},
issn = {1941-6296},
url = {https://doi.org/10.4018/IJDSST.2020070105},
doi = {10.4018/IJDSST.2020070105},
abstract = {Humans use the software in every walk of life thus it is essential to have the best quality software. Software defect prediction models assist in identifying defect prone modules with the help of historical data, which in turn improves software quality. Historical data consists of data related to modules /files/classes which are labeled as buggy or clean. As the number of buggy artifacts as less as compared to clean artifacts, the nature of historical data becomes imbalance. Due to this uneven distribution of the data, it difficult for classification algorithms to build highly effective SDP models. The objective of this study is to propose a new nonlinear geometric framework based on SMOTE and ensemble learning to improve the performance of SDP models. The study combines the traditional SMOTE algorithm and the novel ensemble Support Vector Machine (SVM) is used to develop the proposed framework called SMEnsemble. SMOTE algorithm handles the class imbalance problem by generating synthetic instances of the minority class. Ensemble learning generates multiple classification models to select the best performing SDP model. For experimentation, datasets from three different software repositories that contain both open source as well as proprietary projects are used in the study. The results show that SMEnsemble performs better than traditional methods for identifying the minority class i.e. buggy artifacts. Also, the proposed model performance is better than the latest state of Art SDP model- SMOTUNED. The proposed model is capable of handling imbalance classes when compared with traditional methods. Also, by carefully selecting the number of ensembles high performance can be achieved in less time.},
journal = {Int. J. Decis Support Syst. Technol.},
month = jul,
pages = {85–100},
numpages = {16},
keywords = {Classification, Data Analytics For Software Engineering, Ensemble Learning, Imbalanced Data, Preprocessing, SMOTE, Software Defect Prediction}
}

@article{10.1155/2019/6230953,
author = {Fan, Guisheng and Diao, Xuyang and Yu, Huiqun and Yang, Kang and Chen, Liqiong and Vitiello, Autilia},
title = {Software Defect Prediction via Attention-Based Recurrent Neural Network},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1058-9244},
url = {https://doi.org/10.1155/2019/6230953},
doi = {10.1155/2019/6230953},
abstract = {In order to improve software reliability, software defect prediction is applied to the process of software maintenance to identify potential bugs. Traditional methods of software defect prediction mainly focus on designing static code metrics, which are input into machine learning classifiers to predict defect probabilities of the code. However, the characteristics of these artificial metrics do not contain the syntactic structures and semantic information of programs. Such information is more significant than manual metrics and can provide a more accurate predictive model. In this paper, we propose a framework called defect prediction via attention-based recurrent neural network (DP-ARNN). More specifically, DP-ARNN first parses abstract syntax trees (ASTs) of programs and extracts them as vectors. Then it encodes vectors which are used as inputs of DP-ARNN by dictionary mapping and word embedding. After that, it can automatically learn syntactic and semantic features. Furthermore, it employs the attention mechanism to further generate significant features for accurate defect prediction. To validate our method, we choose seven open-source Java projects in Apache, using F1-measure and area under the curve (AUC) as evaluation criteria. The experimental results show that, in average, DP-ARNN improves the F1-measure by 14% and AUC by 7% compared with the state-of-the-art methods, respectively.},
journal = {Sci. Program.},
month = jan,
numpages = {14}
}

@inproceedings{10.1145/3352411.3352412,
author = {Li, Ran and Zhou, Lijuan and Zhang, Shudong and Liu, Hui and Huang, Xiangyang and Sun, Zhong},
title = {Software Defect Prediction Based on Ensemble Learning},
year = {2019},
isbn = {9781450371414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352411.3352412},
doi = {10.1145/3352411.3352412},
abstract = {Software defect prediction is one of the important ways to guarantee the quality of software systems. Combining various algorithms in machine learning to predict software defects has become a hot topic in the current study. The paper uses the datasets of MDP as the experimental research objects and takes ensemble learning as research focus to construct software defect prediction model. With experimenting five different types of ensemble algorithms and analyzing the features and procedures, this paper discusses the best ensemble algorithm which is Random Forest through experimental comparison. Then we utilize the SMOTE over-sampling and Resample methods to improve the quality of datasets to build a complete new software defect prediction model. Therefore, the results show that the model can improve defect classification performance effectively.},
booktitle = {Proceedings of the 2019 2nd International Conference on Data Science and Information Technology},
pages = {1–6},
numpages = {6},
keywords = {Ensemble algorithm, Over-sampling, Software defect prediction, Under-sampling},
location = {Seoul, Republic of Korea},
series = {DSIT 2019}
}

@article{10.1016/j.neucom.2019.05.100,
author = {Huo, Xuan and Li, Ming},
title = {On cost-effective software defect prediction: Classification or ranking?},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {363},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.05.100},
doi = {10.1016/j.neucom.2019.05.100},
journal = {Neurocomput.},
month = oct,
pages = {339–350},
numpages = {12},
keywords = {Software mining, Software defect prediction, Ranking model, Classification model}
}

@inproceedings{10.1007/978-3-030-86472-9_28,
author = {Shakhovska, Natalya and Yakovyna, Vitaliy},
title = {Feature Selection and Software Defect Prediction by Different Ensemble Classifiers},
year = {2021},
isbn = {978-3-030-86471-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86472-9_28},
doi = {10.1007/978-3-030-86472-9_28},
abstract = {Software defect prediction can improve its quality and is actively studied during the last decade. This paper focuses on the improvement of software defect prediction accuracy by proper feature selection techniques and using ensemble classifier. The software code metrics were used to predict the defective modules. JM1 public NASA dataset from PROMISE Software Engineering Repository was used in this study. Boruta, ACE, regsubsets and simple correlation are used for feature selection. The results of selection are formed based on hard voting of all features selectors. A new stacking classifier for software defects prediction is presented in this paper. The stacking classifier for defects prediction algorithm is based on combination of 5 weak classifiers. Random forest algorithm is used to combine the predictions. The obtained prediction accuracy was up to 96.26%.},
booktitle = {Database and Expert Systems Applications: 32nd International Conference, DEXA 2021, Virtual Event, September 27–30, 2021, Proceedings, Part I},
pages = {307–313},
numpages = {7},
keywords = {Ensemble of classifiers, Feature selection, Software defect analysis}
}

@article{10.1007/s00500-020-05159-1,
author = {Jin, Cong},
title = {Software defect prediction model based on distance metric learning},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {1},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05159-1},
doi = {10.1007/s00500-020-05159-1},
abstract = {Software defect prediction (SDP) is a very important way for analyzing software quality and reducing development costs. The data during software lifecycle can be used to predict software defect. Currently, many SDP models have been proposed; however, their performance was not always ideal. In many existing prediction models based on machine learning, the distance metric between samples has significant impact on the performance of the SDP model. In addition, most samples are usually class imbalanced. To solve these issues, in this paper, a novel distance metric learning based on cost-sensitive learning (CSL) is proposed for reducing the impact of class imbalance of samples, which is then applied to the large margin distribution machine (LDM) to substitute the traditional kernel function. Further, the improvement and optimization of LDM based on CSL are also studied, and the improved LDM is used as the SDP model, called as CS-ILDM. Subsequently, the proposed CS-ILDM is applied to five publicly available data sets from the NASA Metrics Data Program repository and its performance is compared to other existing SDP models. The experimental results confirm that the proposed CS-ILDM not only has good prediction performance, but also can reduce the misprediction cost and avoid the impact of class imbalance of samples.},
journal = {Soft Comput.},
month = jan,
pages = {447–461},
numpages = {15},
keywords = {Software defect prediction, Software attributes, Distance metric learning, Cost-sensitive learning, Misprediction cost, Class imbalance of samples}
}

@article{10.1016/j.eswa.2021.114637,
author = {Jin, Cong},
title = {Cross-project software defect prediction based on domain adaptation learning and optimization},
year = {2021},
issue_date = {Jun 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {171},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114637},
doi = {10.1016/j.eswa.2021.114637},
journal = {Expert Syst. Appl.},
month = jun,
numpages = {14},
keywords = {Software defect prediction, Optimization, Domain adaptation, Cross-project defect prediction, Improved quantum particle swarm optimization}
}

@article{10.1016/j.jss.2018.06.025,
author = {\"{O}zak\i{}nc\i{}, Rana and Tarhan, Ay\c{c}a},
title = {Early software defect prediction: A systematic map and review},
year = {2018},
issue_date = {Oct 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2018.06.025},
doi = {10.1016/j.jss.2018.06.025},
journal = {J. Syst. Softw.},
month = oct,
pages = {216–239},
numpages = {24},
keywords = {Early defect prediction, Software defect, Software quality, Prediction model, Systematic mapping, Systematic literature review}
}

@inproceedings{10.1007/978-3-030-62463-7_33,
author = {Lei, Tianwei and Xue, Jingfeng and Han, Weijie},
title = {Cross-Project Software Defect Prediction Based on Feature Selection and Transfer Learning},
year = {2020},
isbn = {978-3-030-62462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62463-7_33},
doi = {10.1007/978-3-030-62463-7_33},
abstract = {Cross-project software defect prediction solves the problem that traditional defect prediction can’t get enough data, but how to apply the model learned from the data of different mechanisms to the target data set is a new problem. At the same time, there is the problem that information redundancy in the training process leads to low accuracy. Based on the difference of projects, this paper uses MIC to filter features to solve the problem of information redundancy. At the same time, combined with the TrAdaboost algorithm, which is based on the idea of aggravating multiple classification error samples, this paper proposes a cross-project software prediction method based on feature selection and migration learning. Experimental results show that the algorithm proposed in this paper has better experimental results on AUC and F1.},
booktitle = {Machine Learning for Cyber Security: Third International Conference, ML4CS 2020, Guangzhou, China, October 8–10, 2020, Proceedings, Part III},
pages = {363–371},
numpages = {9},
keywords = {Transfer learning, TrAdaboost, MIC, Cross-project software defect prediction},
location = {Guangzhou, China}
}

@article{10.1016/j.asoc.2015.04.045,
author = {Arar, \"{O}mer Faruk and Ayan, K\"{u}r\c{s}at},
title = {Software defect prediction using cost-sensitive neural network},
year = {2015},
issue_date = {August 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {33},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.04.045},
doi = {10.1016/j.asoc.2015.04.045},
abstract = {Software defect prediction model was built by Artificial Neural Network (ANN).ANN connection weights were optimized by Artificial Bee Colony (ABC).Parametric cost-sensitivity feature was added to ANN by using a new error function.Model was applied to five publicly available datasets from the NASA repository.Results were compared with other cost-sensitive and non-cost-sensitive studies. The software development life cycle generally includes analysis, design, implementation, test and release phases. The testing phase should be operated effectively in order to release bug-free software to end users. In the last two decades, academicians have taken an increasing interest in the software defect prediction problem, several machine learning techniques have been applied for more robust prediction. A different classification approach for this problem is proposed in this paper. A combination of traditional Artificial Neural Network (ANN) and the novel Artificial Bee Colony (ABC) algorithm are used in this study. Training the neural network is performed by ABC algorithm in order to find optimal weights. The False Positive Rate (FPR) and False Negative Rate (FNR) multiplied by parametric cost coefficients are the optimization task of the ABC algorithm. Software defect data in nature have a class imbalance because of the skewed distribution of defective and non-defective modules, so that conventional error functions of the neural network produce unbalanced FPR and FNR results. The proposed approach was applied to five publicly available datasets from the NASA Metrics Data Program repository. Accuracy, probability of detection, probability of false alarm, balance, Area Under Curve (AUC), and Normalized Expected Cost of Misclassification (NECM) are the main performance indicators of our classification approach. In order to prevent random results, the dataset was shuffled and the algorithm was executed 10 times with the use of n-fold cross-validation in each iteration. Our experimental results showed that a cost-sensitive neural network can be created successfully by using the ABC optimization algorithm for the purpose of software defect prediction.},
journal = {Appl. Soft Comput.},
month = aug,
pages = {263–277},
numpages = {15},
keywords = {Artificial Bee Colony, Artificial Neural Network, Cost-sensitive classification, Machine learning, Software defect prediction, Software quality}
}

@inproceedings{10.1007/978-3-030-58802-1_25,
author = {Ronchieri, Elisabetta and Canaparo, Marco and Belgiovine, Mauro},
title = {Software Defect Prediction on Unlabelled Datasets: A Comparative Study},
year = {2020},
isbn = {978-3-030-58801-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58802-1_25},
doi = {10.1007/978-3-030-58802-1_25},
abstract = {Background: Defect prediction on unlabelled datasets is a challenging and widespread problem in software engineering. Machine learning is of great value in this context because it provides techniques - called unsupervised - that are applicable to unlabelled datasets. Objective: This study aims at comparing various approaches employed over the years on unlabelled datasets to predict the defective modules, i.e. the ones which need more attention in the testing phase. Our comparison is based on the measurement of performance metrics and on the real defective information derived from software archives. Our work leverages a new dataset that has been obtained by extracting and preprocessing its metrics from a C++ software. Method: Our empirical study has taken advantage of CLAMI with its improvement CLAMI+ that we have applied on high energy physics software datasets. Furthermore, we have used clustering techniques such as the K-means algorithm to find potentially critical modules. Results: Our experimental analysis have been carried out on 1 open source project with 34 software releases. We have applied 17 ML techniques to the labelled datasets obtained by following the CLAMI and CLAMI+ approaches. The two approaches have been evaluated by using different performance metrics, our results show that CLAMI+ performs better than CLAMI. The predictive average accuracy metric is around 95% for 4 ML techniques (4 out of 17) that show a Kappa statistic greater than 0.80. We applied K-means on the same dataset and obtained 2 clusters labelled according to the output of CLAMI and CLAMI+. Conclusion: Based on the results of the different statistical tests, we conclude that no significant performance differences have been found in the selected classification techniques.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part II},
pages = {333–353},
numpages = {21},
keywords = {Unlabelled dataset, Defect prediction, Unsupervised methods, Machine learning},
location = {Cagliari, Italy}
}

@phdthesis{10.5555/AAI28389525,
author = {Rahman, Ashiqur},
advisor = {R, Cordy, James},
title = {Software Defect Prediction Using Rich Contextualized Language Use Vectors},
year = {2020},
isbn = {9798708779250},
publisher = {Queen's University (Canada)},
abstract = {Context. Software defect prediction aims to find defect prone source code, and thus reduce the effort, time and cost involved with ensuring the quality of software systems. Both code and non-code metrics are commonly used in this process to train machine learning algorithms to predict software defects. Studies have shown that such metrics-based approaches are failing to give satisfactory results, and have reached a performance ceiling. This thesis explores the idea of using code profiles as an alternative to traditional metrics to predict software defects. This code profile-based method proves to be more promising than traditional metrics-based approaches.Aims. This thesis aims to improve software defect prediction using code profiles as feature variables in place of traditional metrics. Software code profiles encode the density of language feature use and the context of such use in Rich Contextualized Language Use Vectors (RCLUVs) by analysing the parse tree of the source code. This thesis explores whether code profiles can be used to train machine learning algorithms, and compares the performance of the derived models to traditional metrics-based approaches.Methods. To achieve these aims the learning curves of several machine learning algorithms are analyzed, and the performance of the derived models are evaluated against traditional metrics-based approaches. Two benchmark bug datasets, the Eclipse bug dataset and the Github bug database, are used to train the models.Results. The learning curves of the models show machine learning algorithms can learn from RCLUV-based code profiles. Performance evaluation against existing metrics-based approaches reveals that the code profile-based approach is more promising than traditional metrics-based approaches. However, the predictive performance of both metrics and code profile-based approaches drops in cross-version predictions.Conclusions. Unlike traditional metrics-based approaches, this thesis uses vectors generated by analyzing language feature use from the parse trees of source code as feature variables to train machine learning algorithms. Experimental results using learning algorithms encourages us to use software code profiles as an alternative to traditional metrics to predict software defects.},
note = {AAI28389525}
}

@article{10.1155/2021/2323100,
author = {Liu, Wenjian and Wang, Baoping and Wang, Wennan and Ni, Tongguang},
title = {Deep Learning Software Defect Prediction Methods for Cloud Environments Research},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/2323100},
doi = {10.1155/2021/2323100},
abstract = {This paper provides an in-depth study and analysis of software defect prediction methods in a cloud environment and uses a deep learning approach to justify software prediction. A cost penalty term is added to the supervised part of the deep ladder network; that is, the misclassification cost of different classes is added to the model. A cost-sensitive deep ladder network-based software defect prediction model is proposed, which effectively mitigates the negative impact of the class imbalance problem on defect prediction. To address the problem of lack or insufficiency of historical data from the same project, a flow learning-based geodesic cross-project software defect prediction method is proposed. Drawing on data information from other projects, a migration learning approach was used to embed the source and target datasets into a Gaussian manifold. The kernel encapsulates the incremental changes between the differences and commonalities between the two domains. To this point, the subspace is the space of two distributional approximations formed by the source and target data transformations, with traditional in-project software defect classifiers used to predict labels. It is found that real-time defect prediction is more practical because it has a smaller amount of code to review; only individual changes need to be reviewed rather than entire files or packages while making it easier for developers to assign fixes to defects. More importantly, this paper combines deep belief network techniques with real-time defect prediction at a fine-grained level and TCA techniques to deal with data imbalance and proposes an improved deep belief network approach for real-time defect prediction, while trying to change the machine learning classifier underlying DBN for different experimental studies, and the results not only validate the effectiveness of using TCA techniques to solve the data imbalance problem but also show that the defect prediction model learned by the improved method in this paper has better prediction performance.},
journal = {Sci. Program.},
month = jan,
numpages = {11}
}

@article{10.1016/j.infsof.2021.106662,
author = {Feng, Shuo and Keung, Jacky and Yu, Xiao and Xiao, Yan and Zhang, Miao},
title = {Investigation on the stability of SMOTE-based oversampling techniques in software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {139},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106662},
doi = {10.1016/j.infsof.2021.106662},
journal = {Inf. Softw. Technol.},
month = nov,
numpages = {14},
keywords = {Software defect prediction, Class imbalance, Oversampling, SMOTE, Empirical Software Engineering}
}

@article{10.1007/s10515-016-0194-x,
author = {Zhang, Zhi-Wu and Jing, Xiao-Yuan and Wang, Tie-Jian},
title = {Label propagation based semi-supervised learning for software defect prediction},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {1},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-016-0194-x},
doi = {10.1007/s10515-016-0194-x},
abstract = {Software defect prediction can automatically predict defect-prone software modules for efficient software test in software engineering. When the previous defect labels of modules are limited, predicting the defect-prone modules becomes a challenging problem. In static software defect prediction, there exist the similarity among software modules, a software module can be approximated by a sparse representation of the other part of the software modules, and class-imbalance problem, the number of defect-free modules is much larger than that of defective ones. In this paper, we propose to use graph based semi-supervised learning technique to predict software defect. By using Laplacian score sampling strategy for the labeled defect-free modules, we construct a class-balance labeled training dataset firstly. And then, we use a nonnegative sparse algorithm to compute the nonnegative sparse weights of a relationship graph which serve as clustering indicators. Lastly, on the nonnegative sparse graph, we use a label propagation algorithm to iteratively predict the labels of unlabeled software modules. We thus propose a nonnegative sparse graph based label propagation approach for software defect classification and prediction, which uses not only few labeled data but also abundant unlabeled ones to improve the generalization capability. We vary the size of labeled software modules from 10 to 30 % of all the datasets in the widely used NASA projects. Experimental results show that the NSGLP outperforms several representative state-of-the-art semi-supervised software defect prediction methods, and it can fully exploit the characteristics of static code metrics and improve the generalization capability of the software defect prediction model.},
journal = {Automated Software Engg.},
month = mar,
pages = {47–69},
numpages = {23},
keywords = {Label propagation, Nonnegative sparse graph, Nonnegative sparse graph based label propagation (NSGLP), Semi-supervised learning, Software defect prediction}
}

@article{10.1007/s10515-021-00289-8,
author = {Ali, Aftab and Khan, Naveed and Abu-Tair, Mamun and Noppen, Joost and McClean, Sally and McChesney, Ian},
title = {Discriminating features-based cost-sensitive approach for software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-021-00289-8},
doi = {10.1007/s10515-021-00289-8},
abstract = {Correlated quality metrics extracted from a source code repository can be utilized to design a model to automatically predict defects in a software system. It is obvious that the extracted metrics will result in a highly unbalanced data, since the number of defects in a good quality software system should be far less than the number of normal instances. It is also a fact that the selection of the best discriminating features significantly improves the robustness and accuracy of a prediction model. Therefore, the contribution of this paper is twofold, first it selects the best discriminating features that help in accurately predicting a defect in a software component. Secondly, a cost-sensitive logistic regression and decision tree ensemble-based prediction models are applied to the best discriminating features for precisely predicting a defect in a software component. The proposed models are compared with the most recent schemes in the literature in terms of accuracy, area under the curve, and recall. The models are evaluated using 11 datasets and it is evident from the results and analysis that the performance of the proposed prediction models outperforms the schemes in the literature.},
journal = {Automated Software Engg.},
month = nov,
numpages = {18},
keywords = {Software bugs/defects, Machine learning models, Discriminating features, Cost-sensitivity, AUC, Recall}
}

@article{10.1016/j.neucom.2021.05.043,
author = {Harzevili, Nima Shiri and Alizadeh, Sasan H.},
title = {Analysis and modeling conditional mutual dependency of metrics in software defect prediction using latent variables},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {460},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.05.043},
doi = {10.1016/j.neucom.2021.05.043},
journal = {Neurocomput.},
month = oct,
pages = {309–330},
numpages = {22},
keywords = {Software defect prediction Software metrics, Naive Bayes classifier, Latent variable, 00–01, 99–00}
}

@inproceedings{10.1145/3475716.3475790,
author = {Wang, Song and Wang, Junjie and Nam, Jaechang and Nagappan, Nachiappan},
title = {Continuous Software Bug Prediction},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475790},
doi = {10.1145/3475716.3475790},
abstract = {Background: Many software bug prediction models have been proposed and evaluated on a set of well-known benchmark datasets. We conducted pilot studies on the widely used benchmark datasets and observed common issues among them. Specifically, most of existing benchmark datasets consist of randomly selected historical versions of software projects, which poses non-trivial threats to the validity of existing bug prediction studies since the real-world software projects often evolve continuously. Yet how to conduct software bug prediction in the real-world continuous software development scenarios is not well studied.Aims: In this paper, to bridge the gap between current software bug prediction practice and real-world continuous software development, we propose new approaches to conduct bug prediction in real-world continuous software development regarding model building, updating, and evaluation.Method: For model building, we propose ConBuild, which leverages distributional characteristics of bug prediction data to guide the training version selection. For model updating, we propose ConUpdate, which leverages the evolution of distributional characteristics of bug prediction data between versions to guide the reuse or update of bug prediction models in continuous software development. For model evaluation, we propose ConEA, which leverages the evolution of buggy probability of files between versions to conduct effort-aware evaluation.Results: Experiments on 120 continuously release versions that span across six large-scale open-source software systems show the practical value of our approaches.Conclusions: This paper provides new insights and guidelines for conducting software bug prediction in the context of continuous software development.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {14},
numpages = {12},
keywords = {Empirical software engineering, continuous software development, software defect prediction, software quality},
location = {Bari, Italy},
series = {ESEM '21}
}

@article{10.1007/s11277-017-5117-z,
author = {Zhou, Lijuan and Li, Ran and Zhang, Shudong and Wang, Hua},
title = {Imbalanced Data Processing Model for Software Defect Prediction},
year = {2018},
issue_date = {Sep 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {2},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-5117-z},
doi = {10.1007/s11277-017-5117-z},
abstract = {In the field of software engineering, software defect prediction is the hotspot of the researches which can effectively guarantee the quality during software development. However, the problem of class imbalanced datasets will affect the accuracy of overall classification of software defect prediction, which is the key issue to be solved urgently today. In order to better solve this problem, this paper proposes a model named ASRA which combines attribute selection, sampling technologies and ensemble algorithm. The model adopts the Chi square test of attribute selection and then utilizes the combined sampling technique which includes SMOTE over-sampling and under-sampling to remove the redundant attributes and make the datasets balance. Afterwards, the model ASRA is eventually established by ensemble algorithm named Adaboost with basic classifier J48 decision tree. The data used in the experiments comes from UCI datasets. It can draw the conclusion that the effect of software defect prediction classification which using this model is improved and better than before by comparing the precision P, F-measure and AUC values from the results of the experiments.},
journal = {Wirel. Pers. Commun.},
month = sep,
pages = {937–950},
numpages = {14},
keywords = {Attribute selection, Class imbalance, Ensemble algorithm, Sampling, Software defect prediction}
}

@article{10.1007/s11219-016-9342-6,
author = {Chen, Lin and Fang, Bin and Shang, Zhaowei and Tang, Yuanyan},
title = {Tackling class overlap and imbalance problems in software defect prediction},
year = {2018},
issue_date = {March     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-016-9342-6},
doi = {10.1007/s11219-016-9342-6},
abstract = {Software defect prediction (SDP) is a promising solution to save time and cost in the software testing phase for improving software quality. Numerous machine learning approaches have proven effective in SDP. However, the unbalanced class distribution in SDP datasets could be a problem for some conventional learning methods. In addition, class overlap increases the difficulty for the predictors to learn the defective class accurately. In this study, we propose a new SDP model which combines class overlap reduction and ensemble imbalance learning to improve defect prediction. First, the neighbor cleaning method is applied to remove the overlapping non-defective samples. The whole dataset is then randomly under-sampled several times to generate balanced subsets so that multiple classifiers can be trained on these data. Finally, these individual classifiers are assembled with the AdaBoost mechanism to build the final prediction model. In the experiments, we investigated nine highly unbalanced datasets selected from a public software repository and confirmed that the high rate of overlap between classes existed in SDP data. We assessed the performance of our proposed model by comparing it with other state-of-the-art methods including conventional SDP models, imbalance learning and data cleaning methods. Test results and statistical analysis show that the proposed model provides more reasonable defect prediction results and performs best in terms of G-mean and AUC among all tested models.},
journal = {Software Quality Journal},
month = mar,
pages = {97–125},
numpages = {29},
keywords = {Class imbalance, Class overlap, Machine learning, Software defect prediction}
}

@article{10.1007/s10664-020-09861-4,
author = {Morasca, Sandro and Lavazza, Luigi},
title = {On the assessment of software defect prediction models via ROC curves},
year = {2020},
issue_date = {Sep 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09861-4},
doi = {10.1007/s10664-020-09861-4},
abstract = {Software defect prediction models are classifiers often built by setting a threshold t on a defect proneness model, i.e., a scoring function. For instance, they classify a software module non-faulty if its defect proneness is below t and positive otherwise. Different values of t may lead to different defect prediction models, possibly with very different performance levels. Receiver Operating Characteristic (ROC) curves provide an overall assessment of a defect proneness model, by taking into account all possible values of t and thus all defect prediction models that can be built based on it. However, using a defect proneness model with a value of t is sensible only if the resulting defect prediction model has a performance that is at least as good as some minimal performance level that depends on practitioners’ and researchers’ goals and needs. We introduce a new approach and a new performance metric (the Ratio of Relevant Areas) for assessing a defect proneness model by taking into account only the parts of a ROC curve corresponding to values of t for which defect proneness models have higher performance than some reference value. We provide the practical motivations and theoretical underpinnings for our approach, by: 1) showing how it addresses the shortcomings of existing performance metrics like the Area Under the Curve and Gini’s coefficient; 2) deriving reference values based on random defect prediction policies, in addition to deterministic ones; 3) showing how the approach works with several performance metrics (e.g., Precision and Recall) and their combinations; 4) studying misclassification costs and providing a general upper bound for the cost related to the use of any defect proneness model; 5) showing the relationships between misclassification costs and performance metrics. We also carried out a comprehensive empirical study on real-life data from the SEACRAFT repository, to show the differences between our metric and the existing ones and how more reliable and less misleading our metric can be.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {3977–4019},
numpages = {43},
keywords = {Software defect prediction model, Software defect proneness, ROC, Thresholds, AUC, Gini}
}

@inproceedings{10.1007/978-3-031-08421-8_41,
author = {Giorgio, Lazzarinetti and Nicola, Massarenti and Fabio, Sgr\`{o} and Andrea, Salafia},
title = {Continuous Defect Prediction in CI/CD Pipelines: A Machine Learning-Based Framework},
year = {2021},
isbn = {978-3-031-08420-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-08421-8_41},
doi = {10.1007/978-3-031-08421-8_41},
abstract = {Recent advances in information technology has led to an increasing number of applications to be developed and maintained daily by product teams. Ensuring that a software application works as expected and that it is absent of bugs requires a lot of time and resources. Thanks to the recent adoption of DevOps methodologies, it is often the case where code commits and application builds are centralized and standardized. Thanks to this new approach, it is now possible to retrieve log and build data to ease the development and management operations of product teams. However, even if such approaches include code control to detect unit or integration errors, they do not check for the presence of logical bugs that can raise after code builds. For such reasons in this work we propose a framework for continuous defect prediction based on machine learning algorithms trained on a publicly available dataset. The framework is composed of a machine learning model for detecting the presence of logical bugs in code on the basis of the available data generated by DevOps tools and a dashboard to monitor the software projects status. We also describe the serverless architecture we designed for hosting the aforementioned framework.},
booktitle = {AIxIA 2021 – Advances in Artificial Intelligence: 20th International Conference of the Italian Association for Artificial Intelligence, Virtual Event, December 1–3, 2021, Revised Selected Papers},
pages = {591–606},
numpages = {16},
keywords = {Continuous defect prediction, Machine learning, DevOps, Continuous integration}
}

@inproceedings{10.1109/ASE.2019.00071,
author = {Gong, Lina and Jiang, Shujuan and Wang, Rongcun and Jiang, Li},
title = {Empirical evaluation of the impact of class overlap on software defect prediction},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00071},
doi = {10.1109/ASE.2019.00071},
abstract = {Software defect prediction (SDP) utilizes the learning models to detect the defective modules in project, and their performance depends on the quality of training data. The previous researches mainly focus on the quality problems of class imbalance and feature redundancy. However, training data often contains some instances that belong to different class but have similar values on features, and this leads to class overlap to affect the quality of training data. Our goal is to investigate the impact of class overlap on software defect prediction. At the same time, we propose an improved K-Means clustering cleaning approach (IKMCCA) to solve both the class overlap and class imbalance problems. Specifically, we check whether K-Means clustering cleaning approach (KMCCA) or neighborhood cleaning learning (NCL) or IKMCCA is feasible to improve defect detection performance for two cases (i) within-project defect prediction (WPDP) (ii) cross-project defect prediction (CPDP). To have an objective estimate of class overlap, we carry out our investigations on 28 open source projects, and compare the performance of state-of-the-art learning models for the above-mentioned cases by using IKMCCA or KMCCA or NCL VS. without cleaning data. The experimental results make clear that learning models obtain significantly better performance in terms of balance, Recall and AUC for both WPDP and CPDP when the overlapping instances are removed. Moreover, it is better to consider both class overlap and class imbalance.},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {698–709},
numpages = {12},
keywords = {K-Means clustering, class overlap, machine learning, software defect prediction},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3377811.3380389,
author = {Chen, Jinyin and Hu, Keke and Yu, Yue and Chen, Zhuangzhi and Xuan, Qi and Liu, Yi and Filkov, Vladimir},
title = {Software visualization and deep transfer learning for effective software defect prediction},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380389},
doi = {10.1145/3377811.3380389},
abstract = {Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort. Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules. Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models.To bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools. To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction. Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction. Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {578–589},
numpages = {12},
keywords = {cross-project defect prediction, deep transfer learning, self-attention, software visualization, within-project defect prediction},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3374549.3374553,
author = {Zong, Liang},
title = {Classification Based Software Defect Prediction Model for Finance Software System - An Industry Study},
year = {2020},
isbn = {9781450376495},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3374549.3374553},
doi = {10.1145/3374549.3374553},
abstract = {Automated software defect prediction is an important and fundamental activity in the domain of software development. Successful software defect prediction can save testing effort thus reduce the time and cost for software development. However, software systems for finance company are inherently large and complex with numerous interfaces with other systems. Thus, identifying and selecting a good model and a set of features is important but challenging problem. In our paper, we first define the problem we want to solve. Then we propose a prediction model based on binary classification and a set of novel features, which is more specific for finance software systems. We collected 15 months real production data and labelled it as our dataset. The experiment shows our model and features can give a better prediction accuracy for finance systems. In addition, we demonstrate how our prediction model helps improve our production quality further. Unlike other research papers, our proposal focuses to solve problem in real finance industry.},
booktitle = {Proceedings of the 2019 3rd International Conference on Software and E-Business},
pages = {60–65},
numpages = {6},
keywords = {Faulty change, Finance system, Machine learning, Software defect prediction},
location = {Tokyo, Japan},
series = {ICSEB '19}
}

@article{10.1007/s11219-018-9436-4,
author = {Ji, Haijin and Huang, Song and Wu, Yaning and Hui, Zhanwei and Zheng, Changyou},
title = {A new weighted naive Bayes method based on information diffusion for software defect prediction},
year = {2019},
issue_date = {Sep 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9436-4},
doi = {10.1007/s11219-018-9436-4},
abstract = {Software defect prediction (SDP) plays a significant part in identifying the most defect-prone modules before software testing and allocating limited testing resources. One of the most commonly used classifiers in SDP is naive Bayes (NB). Despite the simplicity of the NB classifier, it can often perform better than more complicated classification models. In NB, the features are assumed to be equally important, and the numeric features are assumed to have a normal distribution. However, the features often do not contribute equivalently to the classification, and they usually do not have a normal distribution after performing a Kolmogorov-Smirnov test; this may harm the performance of the NB classifier. Therefore, this paper proposes a new weighted naive Bayes method based on information diffusion (WNB-ID) for SDP. More specifically, for the equal importance assumption, we investigate six weight assignment methods for setting the feature weights and then choose the most suitable one based on the F-measure. For the normal distribution assumption, we apply the information diffusion model (IDM) to compute the probability density of each feature instead of the acquiescent probability density function of the normal distribution. We carry out experiments on 10 software defect data sets of three types of projects in three different programming languages provided by the PROMISE repository. Several well-known classifiers and ensemble methods are included for comparison. The final experimental results demonstrate the effectiveness and practicability of the proposed method.},
journal = {Software Quality Journal},
month = sep,
pages = {923–968},
numpages = {46},
keywords = {Software defect prediction, Naive Bayes, Feature weighting, Information diffusion}
}

@article{10.1049/iet-sen.2017.0148,
author = {Li, Zhiqiang and Jing, Xiao-Yuan and Zhu, Xiaoke},
title = {Progress on approaches to software defect prediction},
year = {2018},
issue_date = {June 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2017.0148},
doi = {10.1049/iet-sen.2017.0148},
abstract = {Software defect prediction is one of the most popular research topics in software engineering. It aims to predict defect‐prone software modules before defects are discovered, therefore it can be used to better prioritise software quality assurance effort. In recent years, especially for recent 3 years, many new defect prediction studies have been proposed. The goal of this study is to comprehensively review, analyse and discuss the state‐of‐the‐art of defect prediction. The authors survey almost 70 representative defect prediction papers in recent years (January 2014–April 2017), most of which are published in the prominent software engineering journals and top conferences. The selected defect prediction papers are summarised to four aspects: machine learning‐based prediction algorithms, manipulating the data, effort‐aware prediction and empirical studies. The research community is still facing a number of challenges for building methods and many research opportunities exist. The identified challenges can give some practical guidelines for both software engineering researchers and practitioners in future software defect prediction.},
journal = {IET Software},
month = jun,
pages = {161–175},
numpages = {15},
keywords = {software quality, software reliability, quality assurance, research and development, software defect prediction, software engineering journals, defect-prone software modules, software quality assurance, machine learning-based prediction algorithms, data manipulation, effort-aware prediction, empirical studies}
}

@article{10.1504/ijcat.2020.110428,
author = {Bai, Xue and Zhou, Hua and Yang, Hongji and Wang, Dong},
title = {Connecting historical changes for cross-version software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {63},
number = {4},
issn = {0952-8091},
url = {https://doi.org/10.1504/ijcat.2020.110428},
doi = {10.1504/ijcat.2020.110428},
abstract = {In the whole software life cycle, software defects are inevitable and increase the cost of software development and evolution. Cross-Version Software Defect Prediction (CVSDP) aims at learning the defect patterns from the historical data of previous software versions to distinguish buggy software modules from clean ones. In CVSDP, metrics are intrinsic properties associated with the external manifestation of defects. However, traditional software defect measures ignore the sequential information of changes during software evolution process which may play a crucial role in CVSDP. Therefore, researchers tried to connect traditional metrics across versions as a new kind of evolution metrics. This study proposes a new way to connect historical sequence of metrics based on change sequence named HCSM and designs a novel deep learning algorithm GDNN as a classifier to process it. Compared to the traditional metrics approaches and other relevant approaches, the proposed approach fits in projects with stable and orderly defect control trend.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {371–383},
numpages = {12},
keywords = {software testing, cross-version defect prediction, software metrics, historical change sequences, deep learning, DNN, deep neural networks, gate recurrent unit}
}

@article{10.1049/iet-sen.2018.5439,
author = {Yu, Qiao and Jiang, Shujuan and Qian, Junyan and Bo, Lili and Jiang, Li and Zhang, Gongjie},
title = {Process metrics for software defect prediction in object‐oriented programs},
year = {2020},
issue_date = {June 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2018.5439},
doi = {10.1049/iet-sen.2018.5439},
abstract = {Software evolution is an important activity in the life cycle of a modern software system. In the process of software evolution, the repair of historical defects and the increasing demands may introduce new defects. Therefore, evolution‐oriented defect prediction has attracted much attention of researchers in recent years. At present, some researchers have proposed the process metrics to describe the characteristics of software evolution. However, compared with the traditional software defect prediction methods, the research on evolution‐oriented defect prediction is still inadequate. Based on the evolution data of object‐oriented programs, this study presented two new process metrics from the defect rates of historical packages and the change degree of classes. To show the effectiveness of the proposed process metrics, the authors made comparisons with the code metrics and other process metrics. An empirical study was conducted on 33 versions of nine open‐source projects. The results showed that adding the proposed process metrics could improve the performance of evolution‐oriented defect prediction effectively.},
journal = {IET Software},
month = jun,
pages = {283–292},
numpages = {10},
keywords = {object-oriented programming, software fault tolerance, software maintenance, software metrics, software quality, software packages, defect rates, process metrics, evolution-oriented defect prediction, object-oriented programs, software evolution, modern software system, historical defects, traditional software defect prediction methods, evolution data}
}

@article{10.1007/s00500-021-06096-3,
author = {Pandey, Sushant Kumar and Tripathi, Anil Kumar},
title = {An empirical study toward dealing with noise and class imbalance issues in software defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {21},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06096-3},
doi = {10.1007/s00500-021-06096-3},
abstract = {The quality of the defect datasets is a critical issue in the domain of software defect prediction (SDP). These datasets are obtained through the mining of software repositories. Recent studies claim over the quality of the defect dataset. It is because of inconsistency between bug/clean fix keyword in fault reports and the corresponding link in the change management logs. Class Imbalance (CI) problem is also a big challenging issue in SDP models. The defect prediction method trained using noisy and imbalanced data leads to inconsistent and unsatisfactory results. Combined analysis over noisy instances and CI problem needs to be required. To the best of our knowledge, there are insufficient studies that have been done over such aspects. In this paper, we deal with the impact of noise and CI problem on five baseline SDP models; we manually added the various noise level (0–80%) and identified its impact on the performance of those SDP models. Moreover, we further provide guidelines for the possible range of tolerable noise for baseline models. We have also suggested the SDP model, which has the highest noise tolerable ability and outperforms over other classical methods. The True Positive Rate (TPR) and False Positive Rate (FPR) values of the baseline models reduce between 20–30% after adding 10–40% noisy instances. Similarly, the ROC (Receiver Operating Characteristics) values of SDP models reduce to 40–50%. The suggested model leads to avoid noise between 40–60% as compared to other traditional models.},
journal = {Soft Comput.},
month = nov,
pages = {13465–13492},
numpages = {28},
keywords = {Software testing, Software fault prediction, Class imbalance, Noisy instance, Machine learning, Software metrics, Fault proneness}
}

@article{10.1016/j.infsof.2018.02.003,
author = {Mahmood, Zaheed and Bowes, David and Hall, Tracy and Lane, Peter C.R. and Petri\'{c}, Jean},
title = {Reproducibility and replicability of software defect prediction studies},
year = {2018},
issue_date = {Jul 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {99},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2018.02.003},
doi = {10.1016/j.infsof.2018.02.003},
journal = {Inf. Softw. Technol.},
month = jul,
pages = {148–163},
numpages = {16},
keywords = {Replication, Reproducibility, Software defect prediction}
}

@article{10.1002/smr.2381,
author = {Eken, Beyza and Tufan, Selda and Tunaboylu, Alper and Guler, Tevfik and Atar, Rifat and Tosun, Ayse},
title = {Deployment of a change‐level software defect prediction solution into an industrial setting},
year = {2021},
issue_date = {November 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {11},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2381},
doi = {10.1002/smr.2381},
abstract = {Applying change‐level software defect prediction (SDP) in practice has several challenges regarding model validation techniques, data accuracy, and prediction performance consistency. A few studies report on these challenges in an industrial context. We share our experience in integrating an SDP into an industrial context. We investigate whether an “offline” SDP could reflect its “online” (real‐life) performance, and other deployment decisions: the model re‐training process and update period. We employ an online prediction strategy by considering the actual labels of training commits at the time of prediction and compare its performance against an offline prediction. We empirically assess the online SDP's performance with various lengths of the time gap between the train and test set and model update periods. Our online SDP's performance could successfully reach its offline performance. The time gap between the train and test commits, and model update period significantly impacts the online performance by 37% and 18% in terms of probability of detection (pd), respectively. We deploy the best SDP solution (73% pd) with an 8‐month time gap and a 3‐day update period. Contextual factors may determine the model performance in practice, its consistency, and trustworthiness. As future work, we plan to investigate the reasons for fluctuations in model performance over time.We share our experience in integrating a change‐level software defect prediction (SDP) model into an industrial context. We empirically investigate whether an ‘offline’ SDP could reflect its ‘online’ (real‐life) performance, and other deployment decisions: The model re‐training process and update period. Our online SDP's performance could successfully reach its offline performance. The time gap between the train and test commits, and model update period significantly impact the online performance by 37% and 18% in terms of probability of detection, respectively. 


image
image},
journal = {J. Softw. Evol. Process},
month = nov,
numpages = {25},
keywords = {change‐level defect prediction, deployment, industrial case study, online prediction}
}

@inproceedings{10.1145/3416506.3423577,
author = {Yang, Xingguang and Yu, Huiqun and Fan, Guisheng and Yang, Kang},
title = {A differential evolution-based approach for effort-aware just-in-time software defect prediction},
year = {2020},
isbn = {9781450381253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416506.3423577},
doi = {10.1145/3416506.3423577},
abstract = {Software defect prediction technology is an effective method to improve software quality. Effort-aware just-in-time software defect prediction (JIT-SDP) aims to identify more defective changes in limited effort. Although many methods have been proposed for JIT-SDP, the prediction performance of existing prediction models still needs to be improved. To improve the effort-aware prediction performance, we propose a new method called DEJIT based on differential evolution algorithm. First, we propose a metric called density-percentile-average (DPA), which is used as the optimization objective of models on the training set. Then, we use logistic regression to build models and use the differential evolution algorithm to determine coefficients of logistic regression. We conduct empirical research on six open source projects. Empirical results demonstrate that the proposed method significantly outperforms the state-of-the-art 4 supervised models and 4 unsupervised models.},
booktitle = {Proceedings of the 1st ACM SIGSOFT International Workshop on Representation Learning for Software Engineering and Program Languages},
pages = {13–16},
numpages = {4},
keywords = {defect prediction, differential evolution, just-in-time},
location = {Virtual, USA},
series = {RL+SE&amp;PL 2020}
}

@inproceedings{10.1145/3238147.3240469,
author = {Qu, Yu and Liu, Ting and Chi, Jianlei and Jin, Yangxu and Cui, Di and He, Ancheng and Zheng, Qinghua},
title = {node2defect: using network embedding to improve software defect prediction},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240469},
doi = {10.1145/3238147.3240469},
abstract = {Network measures have been proved to be useful in predicting software defects. Leveraging the dependency relationships between software modules, network measures can capture various structural features of software systems. However, existing studies have relied on user-defined network measures (e.g., degree statistics or centrality metrics), which are inflexible and require high computation cost, to describe the structural features. In this paper, we propose a new method called node2defect which uses a newly proposed network embedding technique, node2vec, to automatically learn to encode dependency network structure into low-dimensional vector spaces to improve software defect prediction. Specifically, we firstly construct a program's Class Dependency Network. Then node2vec is used to automatically learn structural features of the network. After that, we combine the learned features with traditional software engineering features, for accurate defect prediction. We evaluate our method on 15 open source programs. The experimental results show that in average, node2defect improves the state-of-the-art approach by 9.15% in terms of F-measure.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {844–849},
numpages = {6},
keywords = {Software defect, defect prediction, network embedding, software metrics},
location = {Montpellier, France},
series = {ASE '18}
}

@article{10.1007/s11227-019-03051-w,
author = {NezhadShokouhi, Mohammad Mahdi and Majidi, Mohammad Ali and Rasoolzadegan, Abbas},
title = {Software defect prediction using over-sampling and feature extraction based on Mahalanobis distance},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {1},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-019-03051-w},
doi = {10.1007/s11227-019-03051-w},
abstract = {As the size of software projects becomes larger, software defect prediction (SDP) will play a key role in allocating testing resources reasonably, reducing testing costs, and speeding up the development process. Most SDP methods have used machine learning techniques based on common software metrics such as Halstead and McCabe’s cyclomatic. Datasets produced by these metrics usually do not follow Gaussian distribution, and also, they have overlaps in defect and non-defect classes. In addition, in many of software defect datasets, the number of defective modules (minority class) is considerably less than non-defective modules (majority class). In this situation, the performance of machine learning methods is reduced dramatically. Therefore, we first need to create a balance between minority and majority classes and then transfer the samples into a new space in which pair samples with same class (must-link set) are near to each other as close as possible and pair samples with different classes (cannot-link) stay as far as possible. To achieve the mentioned objectives, in this paper, Mahalanobis distance in two manners will be used. First, the minority class is oversampled based on the Mahalanobis distance such that generated synthetic data are more diverse from other minority data, and minority class distribution is not changed significantly. Second, a feature extraction method based on Mahalanobis distance metric learning is used which try to minimize distances of sample pairs in must-links and maximize the distance of sample pairs in cannot-links. To demonstrate the effectiveness of the proposed method, we performed some experiments on 12 publicly available datasets which are collected NASA repositories and compared its result by some powerful previous methods. The performance is evaluated in F-measure, G-Mean, and Matthews correlation coefficient. Generally, the proposed method has better performance as compared to the mentioned methods.},
journal = {J. Supercomput.},
month = jan,
pages = {602–635},
numpages = {34},
keywords = {Software defect prediction, Software metrics, Mahalanobis distance, Over-sampling, Feature extraction}
}

@article{10.1049/sfw2.12052,
author = {Bennin, Kwabena Ebo and Tahir, Amjed and MacDonell, Stephen G. and B\"{o}rstler, J\"{u}rgen},
title = {An empirical study on the effectiveness of data resampling approaches for cross‐project software defect prediction},
year = {2021},
issue_date = {April 2022},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {16},
number = {2},
url = {https://doi.org/10.1049/sfw2.12052},
doi = {10.1049/sfw2.12052},
abstract = {Cross‐project defect prediction (CPDP), where data from different software projects are used to predict defects, has been proposed as a way to provide data for software projects that lack historical data. Evaluations of CPDP models using the Nearest Neighbour (NN) Filter approach have shown promising results in recent studies. A key challenge with defect‐prediction datasets is class imbalance, that is, highly skewed datasets where non‐buggy modules dominate the buggy modules. In the past, data resampling approaches have been applied to within‐projects defect prediction models to help alleviate the negative effects of class imbalance in the datasets. To address the class imbalance issue in CPDP, the authors assess the impact of data resampling approaches on CPDP models after the NN Filter is applied. The impact on prediction performance of five oversampling approaches (MAHAKIL, SMOTE, Borderline‐SMOTE, Random Oversampling and ADASYN) and three undersampling approaches (Random Undersampling, Tomek Links and One‐sided selection) is investigated and results are compared to approaches without data resampling. The authors examined six defect prediction models on 34 datasets extracted from the PROMISE repository. The authors' results show that there is a significant positive effect of data resampling on CPDP performance, suggesting that software quality teams and researchers should consider applying data resampling approaches for improved recall (pd) and g‐measure prediction performance. However, if the goal is to improve precision and reduce false alarm (pf) then data resampling approaches should be avoided.},
journal = {IET Software},
month = nov,
pages = {185–199},
numpages = {15},
keywords = {class imbalance, defect prediction, software metrics, software quality}
}

@article{10.1504/ijcse.2020.106871,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {A benchmarking framework using nonlinear manifold detection techniques for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {21},
number = {4},
issn = {1742-7185},
url = {https://doi.org/10.1504/ijcse.2020.106871},
doi = {10.1504/ijcse.2020.106871},
abstract = {Prediction of software defects in time improves quality and helps in locating the defect-prone areas accurately. Although earlier considerable methods were applied, actually none of those measures was found to be fool-proof and accurate. Hence, a newer framework includes nonlinear manifold detection model, and its algorithm originated for defect prediction using different techniques of nonlinear manifold detection (nonlinear MDs) along with 14 different machine learning techniques (MLTs) on eight defective software datasets. A critical analysis cum exhaustive comparative estimation revealed that nonlinear manifold detection model has a more accurate and effective impact on defect prediction as compared to feature selection techniques. The outcome of the experiment was statistically tested by Friedman and post hoc analysis using Nemenyi test, which validates that hidden Markov model (HMM) along with nonlinear manifold detection model outperforms and is significantly different from MLTs.},
journal = {Int. J. Comput. Sci. Eng.},
month = jan,
pages = {593–614},
numpages = {21},
keywords = {dimensionality reduction, feature selection, Friedman test, machine learning, Nemenyi test, nonlinear manifold detection, software defect prediction, post hoc analysis}
}

@inproceedings{10.1109/IRI.2018.00047,
author = {Xu, Ling and Wang, Bei and Liu, Ling and Zhou, Mo and Liao, Shengping and Yan, Meng},
title = {Misclassification Cost-Sensitive Software Defect Prediction},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IRI.2018.00047},
doi = {10.1109/IRI.2018.00047},
abstract = {Software defect prediction helps developers focus on defective modules for efficient software quality assurance. A common goal shared by existing software defect prediction methods is to attain low classification error rates. These proposals suffer from two practical problems: (i) Most of the prediction methods rely on a large number of labeled training data. However, collecting labeled data is a difficult and expensive task. It is hard to obtain classification labels over new software projects or existing projects without historical defect data. (ii) Software defect datasets are highly imbalanced. In many real-world applications, the misclassification cost of defective modules is generally several times higher than that of non-defective ones. In this paper, we present a misclassification Cost-sensitive approach to Software Defect Prediction (CSDP). The CSDP approach is novel in two aspects: First, CSDP addresses the problem of unlabeled software detect datasets by combining an unsupervised sampling method with a domain specific misclassification cost model. This preprocessing step selectively samples a small percentage of modules through estimating their classification labels. Second, CSDP builds a cost-sensitive support vector machine model to predict defect-proneness of the rest of modules with both overall classification error rate and domain specific misclassification cost as quality metrics. CSDP is evaluated on four NASA projects. Experimental results highlight three interesting observations: (1) CSDP achieves higher Normalized Expected Cost of Misclassification (NECM) compared with state-of-art supervised learning models under imbalanced training data with limited labeling. (2) CSDP outperforms state-of-art semi-supervised learning methods, which disregards classification costs, especially in recall rate. (3) CSDP enhanced through unsupervised sampling as a preprocessing step prior to training and prediction outperforms the baseline CSDP without the sampling process.},
booktitle = {2018 IEEE International Conference on Information Reuse and Integration (IRI)},
pages = {256–263},
numpages = {8},
location = {Salt Lake City, UT, USA}
}

@article{10.1504/ijcsm.2020.112675,
author = {Wang, Junyan},
title = {A hybrid grid-based many-objective optimisation algorithm for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {4},
issn = {1752-5055},
url = {https://doi.org/10.1504/ijcsm.2020.112675},
doi = {10.1504/ijcsm.2020.112675},
abstract = {How to apply limited test resources to detect error module is one of the challenges of software defect prediction problem. To solve the problem, a many-objective software defect prediction model is proposed by considering the probability of detection and false alarm rate, the Balance value and F-measure as defect prediction objectives. At the same time, a hybrid grid-based many-objective optimisation algorithm is designed to solve the model. In the designed algorithm, the adaptive dominant region operator is introduced into the grid-based many-objective optimisation algorithm to improve the performance of algorithm in balancing dynamically the convergence and diversity of population. The simulation results show that the proposed algorithm has better performance in solving many-objective the software defect prediction problem.},
journal = {Int. J. Comput. Sci. Math.},
month = jan,
pages = {374–384},
numpages = {10},
keywords = {software defect prediction problem, the probability of detection, false alarm rate, adaptive dominant region operator, convergence, diversity, many-objective optimisation}
}

@article{10.1016/j.neucom.2019.03.076,
author = {Zhao, Linchang and Shang, Zhaowei and Zhao, Ling and Zhang, Taiping and Tang, Yuan Yan},
title = {Software defect prediction via cost-sensitive Siamese parallel fully-connected neural networks},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {352},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.03.076},
doi = {10.1016/j.neucom.2019.03.076},
journal = {Neurocomput.},
month = aug,
pages = {64–74},
numpages = {11},
keywords = {Siamese parallel fully-connected networks, Cost-sensitive learning, Deep learning, Few-shot learning, Software defect prediction}
}

@inproceedings{10.1145/3377813.3381367,
author = {Shrikanth, N. C. and Menzies, Tim},
title = {Assessing practitioner beliefs about software defect prediction},
year = {2020},
isbn = {9781450371230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377813.3381367},
doi = {10.1145/3377813.3381367},
abstract = {Just because software developers say they believe in "X", that does not necessarily mean that "X" is true. As shown here, there exist numerous beliefs listed in the recent Software Engineering literature which are only supported by small portions of the available data. Hence we ask what is the source of this disconnect between beliefs and evidence?.To answer this question we look for evidence for ten beliefs within 300,000+ changes seen in dozens of open-source projects. Some of those beliefs had strong support across all the projects; specifically, "A commit that involves more added and removed lines is more bug-prone" and "Files with fewer lines contributed by their owners (who contribute most changes) are bug-prone".Most of the widely-held beliefs studied are only sporadically supported in the data; i.e. large effects can appear in project data and then disappear in subsequent releases. Such sporadic support explains why developers believe things that were relevant to their prior work, but not necessarily their current work.Our conclusion will be that we need to change the nature of the debate with Software Engineering. Specifically, while it is important to report the effects that hold right now, it is also important to report on what effects change over time.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice},
pages = {182–190},
numpages = {9},
keywords = {beliefs, defects, empirical software engineering, practitioner},
location = {Seoul, South Korea},
series = {ICSE-SEIP '20}
}

@inproceedings{10.1007/978-3-030-34885-4_27,
author = {Ali, Aftab and Abu-Tair, Mamun and Noppen, Joost and McClean, Sally and Lin, Zhiwei and McChesney, Ian},
title = {Contributing Features-Based Schemes for Software Defect Prediction},
year = {2019},
isbn = {978-3-030-34884-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-34885-4_27},
doi = {10.1007/978-3-030-34885-4_27},
abstract = {Automated defect prediction of large and complex software systems is a challenging task. However, by utilising correlated quality metrics, a defect prediction model can be devised to automatically predict the defects in a software system. The robustness and accuracy of a prediction model is highly dependent on the selection of contributing and non-contributing features. Hence, in this regard, the contribution of this paper is twofold, first it separates those features which are contributing towards the development of a defect in a software component from those which are non-contributing features. Secondly, a logistic regression and Ensemble Bagged Trees-based prediction model are applied on the contributing features for accurately predicting a defect in a software component. The proposed models are compared with the most recent scheme in the literature in terms of accuracy and area under the curve (AUC). It is evident from the results and analysis that the performance of the proposed prediction models outperforms the schemes in the literature.},
booktitle = {Artificial Intelligence XXXVI: 39th SGAI International Conference on Artificial Intelligence, AI 2019, Cambridge, UK, December 17–19, 2019, Proceedings},
pages = {350–361},
numpages = {12},
keywords = {Machine learning, Intelligent information retrieval, Prediction models},
location = {Cambridge, United Kingdom}
}

@article{10.5555/2684939.2684969,
author = {Ma, Ying and Pan, Weiwei and Zhu, Shunzhi and Yin, Huayi and Luo, Jian},
title = {An improved semi-supervised learning method for software defect prediction},
year = {2014},
issue_date = {September 2014},
publisher = {IOS Press},
address = {NLD},
volume = {27},
number = {5},
issn = {1064-1246},
abstract = {This paper presents an improved semi-supervised learning approach for defect prediction involving class imbalanced and limited labeled data problem. This approach employs random under-sampling technique to resample the original training set and updating training set in each round for co-train style algorithm. It makes the defect predictor more practical for real applications, by combating these problems. In comparison with conventional machine learning approaches, our method has significant superior performance. Experimental results also show that with the proposed learning approach, it is possible to design better method to tackle the class imbalanced problem in semi-supervised learning.},
journal = {J. Intell. Fuzzy Syst.},
month = sep,
pages = {2473–2480},
numpages = {8},
keywords = {Class Imbalance, Co-Train, Defect Prediction, Random Sampling, Semi-Supervised Learning}
}

@inproceedings{10.1007/978-3-030-29551-6_23,
author = {Miholca, Diana-Lucia and Czibula, Gabriela},
title = {Software Defect Prediction Using a Hybrid Model Based on Semantic Features Learned from the Source Code},
year = {2019},
isbn = {978-3-030-29550-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-29551-6_23},
doi = {10.1007/978-3-030-29551-6_23},
abstract = {Software defect prediction has extensive applicability thus being a very active research area in Search-Based Software Engineering. A high proportion of the software defects are caused by violated couplings. In this paper, we investigate the relevance of semantic coupling in assessing the software proneness to defects. We propose a hybrid classification model combining Gradual Relational Association Rules with Artificial Neural Networks, which detects the defective software entities based on semantic features automatically learned from the source code. The experiments we have performed led to results that confirm the interplay between conceptual coupling and software defects proneness.},
booktitle = {Knowledge Science, Engineering and Management: 12th International Conference, KSEM 2019, Athens, Greece, August 28–30, 2019, Proceedings, Part I},
pages = {262–274},
numpages = {13},
keywords = {Software defect prediction, Machine learning, Conceptual coupling},
location = {Athens, Greece}
}

@article{10.1016/j.asoc.2016.06.023,
author = {Mesquita, Diego P.P. and Rocha, Lincoln S. and Gomes, Joo Paulo P. and Rocha Neto, Ajalmar R.},
title = {Classification with reject option for software defect prediction},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.06.023},
doi = {10.1016/j.asoc.2016.06.023},
abstract = {Graphical abstractDisplay Omitted HighlightsWe propose the use of classification with reject option for software defect prediction (SDP) as a way to incorporate additional knowledge in the SDP process.We propose two variants of the extreme learning machine with reject option.It is proposed an ELM with reject option for imbalanced datasets.The proposed method is tested on five real world software datasets.An example is shown to illustrate how the rejected software modules can be further analyzed to improve the final SDP accuracy. ContextSoftware defect prediction (SDP) is an important task in software engineering. Along with estimating the number of defects remaining in software systems and discovering defect associations, classifying the defect-proneness of software modules plays an important role in software defect prediction. Several machine-learning methods have been applied to handle the defect-proneness of software modules as a classification problem. This type of yes or no decision is an important drawback in the decision-making process and if not precise may lead to misclassifications. To the best of our knowledge, existing approaches rely on fully automated module classification and do not provide a way to incorporate extra knowledge during the classification process. This knowledge can be helpful in avoiding misclassifications in cases where system modules cannot be classified in a reliable way. ObjectiveWe seek to develop a SDP method that (i) incorporates a reject option in the classifier to improve the reliability in the decision-making process; and (ii) makes it possible postpone the final decision related to rejected modules for an expert analysis or even for another classifier using extra domain knowledge. MethodWe develop a SDP method called rejoELM and its variant, IrejoELM. Both methods were built upon the weighted extreme learning machine (ELM) with reject option that makes it possible postpone the final decision of non-classified modules, the rejected ones, to another moment. While rejoELM aims to maximize the accuracy for a rejection rate, IrejoELM maximizes the F-measure. Hence, IrejoELM becomes an alternative for classification with reject option for imbalanced datasets. ResultsrejoEM and IrejoELM are tested on five datasets of source code metrics extracted from real world open-source software projects. Results indicate that rejoELM has an accuracy for several rejection rates that is comparable to some state-of-the-art classifiers with reject option. Although IrejoELM shows lower accuracies for several rejection rates, it clearly outperforms all other methods when the F-measure is used as a performance metric. ConclusionIt is concluded that rejoELM is a valid alternative for classification with reject option problems when classes are nearly equally represented. On the other hand, IrejoELM is shown to be the best alternative for classification with reject option on imbalanced datasets. Since SDP problems are usually characterized as imbalanced learning problems, the use of IrejoELM is recommended.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1085–1093},
numpages = {9},
keywords = {Classification with reject option, Extreme learning machines, Software defect prediction}
}

@article{10.1007/s10664-021-09991-3,
author = {Tahir, Amjed and Bennin, Kwabena E. and Xiao, Xun and MacDonell, Stephen G.},
title = {Does class size matter? An in-depth assessment of the effect of class size in software defect prediction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09991-3},
doi = {10.1007/s10664-021-09991-3},
abstract = {In the past 20 years, defect prediction studies have generally acknowledged the effect of class size on software prediction performance. To quantify the relationship between object-oriented (OO) metrics and defects, modelling has to take into account the direct, and potentially indirect, effects of class size on defects. However, some studies have shown that size cannot be simply controlled or ignored, when building prediction models. As such, there remains a question whether, and when, to control for class size. This study provides a new in-depth examination of the impact of class size on the relationship between OO metrics and software defects or defect-proneness. We assess the impact of class size on the number of defects and defect-proneness in software systems by employing a regression-based mediation (with bootstrapping) and moderation analysis to investigate the direct and indirect effect of class size in count and binary defect prediction. Our results show that the size effect is not always significant for all metrics. Of the seven OO metrics we investigated, size consistently has significant mediation impact only on the relationship between Coupling Between Objects (CBO) and defects/defect-proneness, and a potential moderation impact on the relationship between Fan-out and defects/defect-proneness. Other metrics show mixed results, in that they are significant for some systems but not for others. Based on our results we make three recommendations. One, we encourage researchers and practitioners to examine the impact of class size for the specific data they have in hand and through the use of the proposed statistical mediation/moderation procedures. Two, we encourage empirical studies to investigate the indirect effect of possible additional variables in their models when relevant. Three, the statistical procedures adopted in this study could be used in other empirical software engineering research to investigate the influence of potential mediators/moderators.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {38},
keywords = {Defect prediction, Class size, Metrics, Software quality}
}

@article{10.1049/sfw2.12029,
author = {Zhang, Nana and Ying, Shi and Zhu, Kun and Zhu, Dandan},
title = {Software defect prediction based on stacked sparse denoising autoencoders and enhanced extreme learning machine},
year = {2021},
issue_date = {February 2022},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {16},
number = {1},
url = {https://doi.org/10.1049/sfw2.12029},
doi = {10.1049/sfw2.12029},
abstract = {Software defect prediction is an important software quality assurance technique. Nevertheless, the prediction performance of the constructed model is easily susceptible to irrelevant or redundant features in the software projects and is not predominant enough. To address these two issues, a novel defect prediction model called SSEPG based on Stacked Sparse Denoising AutoEncoders (SSDAE) and Extreme Learning Maching (ELM) optimised by Particle Swarm Optimisation (PSO) and another complementary Gravitational Search Algorithm (GSA) are proposed in this paper, which has two main merits: (1) employ a novel deep neural network – SSDAE to extract new combined features, which can effectively learn the robust deep semantic feature representation. (2) integrate strong exploitation capacity of PSO with strong exploration capability of GSA to optimise the input weights and hidden layer biases of ELM, and utilise the superior discriminability of the enhanced ELM to predict the defective modules. The SSDAE is compared with eleven state‐of‐the‐art feature extraction methods in effect and efficiency, and the SSEPG model is compared with multiple baseline models that contain five classic defect predictors and three variants across 24 software defect projects. The experimental results exhibit the superiority of the SSDAE and the SSEPG on six evaluation metrics.},
journal = {IET Software},
month = may,
pages = {29–47},
numpages = {19},
keywords = {software reliability, image denoising, feature extraction, learning (artificial intelligence), particle swarm optimisation, search problems, neural nets, software maintenance, software quality}
}

@inproceedings{10.1145/3239576.3239622,
author = {Yang, Zhao and Qian, Hongbing},
title = {Automated Parameter Tuning of Artificial Neural Networks for Software Defect Prediction},
year = {2018},
isbn = {9781450364607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239576.3239622},
doi = {10.1145/3239576.3239622},
abstract = {Defect prediction can help predict defect-prone software modules and improve the efficiency and accuracy of defect location and repair, which plays an extremely important role in software quality assurance. Artificial Neural Networks (ANNs), a family of powerful machine learning regression or classification models, have been widely applied for defect prediction. However, the performance of these models will be degraded if they use suboptimal default parameter settings (e.g., the number of units in the hidden layer). This paper utilizes an automated parameter tuning technique-Caret to optimize parameter settings. In our study, 30 datasets are downloaded from the Tera-PROMISE Repository. According to the characteristics of the datasets, we select key features (metrics) as predictors to train defect prediction models. The experiment applies feed-forward, single hidden layer artificial neural network as classifier to build different defect prediction models respectively with optimized parameter settings and with default parameter settings. Confusion matrix and ROC curve are used for evaluating the quality of the models above. The results show that the models trained with optimized parameter settings outperform the models trained with default parameter settings. Hence, we suggest that researchers should pay attention to tuning parameter settings by Caret for ANNs instead of using suboptimal default settings if they select ANNs for training models in the future defect prediction studies.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
pages = {203–209},
numpages = {7},
keywords = {Artificial Neural Networks, Automated Parameter Tuning, Metrics, Software defect prediction},
location = {Chengdu, China},
series = {ICAIP '18}
}

@article{10.1007/s10515-015-0179-1,
author = {Wang, Tiejian and Zhang, Zhiwu and Jing, Xiaoyuan and Zhang, Liqiang},
title = {Multiple kernel ensemble learning for software defect prediction},
year = {2016},
issue_date = {December  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-015-0179-1},
doi = {10.1007/s10515-015-0179-1},
abstract = {Software defect prediction aims to predict the defect proneness of new software modules with the historical defect data so as to improve the quality of a software system. Software historical defect data has a complicated structure and a marked characteristic of class-imbalance; how to fully analyze and utilize the existing historical defect data and build more precise and effective classifiers has attracted considerable researchers' interest from both academia and industry. Multiple kernel learning and ensemble learning are effective techniques in the field of machine learning. Multiple kernel learning can map the historical defect data to a higher-dimensional feature space and make them express better, and ensemble learning can use a series of weak classifiers to reduce the bias generated by the majority class and obtain better predictive performance. In this paper, we propose to use the multiple kernel learning to predict software defect. By using the characteristics of the metrics mined from the open source software, we get a multiple kernel classifier through ensemble learning method, which has the advantages of both multiple kernel learning and ensemble learning. We thus propose a multiple kernel ensemble learning (MKEL) approach for software defect classification and prediction. Considering the cost of risk in software defect prediction, we design a new sample weight vector updating strategy to reduce the cost of risk caused by misclassifying defective modules as non-defective ones. We employ the widely used NASA MDP datasets as test data to evaluate the performance of all compared methods; experimental results show that MKEL outperforms several representative state-of-the-art defect prediction methods.},
journal = {Automated Software Engg.},
month = dec,
pages = {569–590},
numpages = {22},
keywords = {Ensemble learning, Multiple kernel ensemble learning (MKEL), Multiple kernel learning, Software defect prediction}
}

@article{10.1016/j.neucom.2018.04.090,
author = {Malhotra, Ruchika and Kamal, Shine},
title = {An empirical study to investigate oversampling methods for improving software defect prediction using imbalanced data},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {343},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.04.090},
doi = {10.1016/j.neucom.2018.04.090},
journal = {Neurocomput.},
month = may,
pages = {120–140},
numpages = {21},
keywords = {Defect prediction, Imbalanced data, Oversampling methods, MetaCost learners, Machine learning techniques, Procedural metrics}
}

@article{10.4018/IJOSSP.2017100102,
author = {Akour, Mohammed and Melhem, Wasen Yahya},
title = {Software Defect Prediction Using Genetic Programming and Neural Networks},
year = {2017},
issue_date = {October 2017},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {4},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2017100102},
doi = {10.4018/IJOSSP.2017100102},
abstract = {This article describes how classification methods on software defect prediction is widely researched due to the need to increase the software quality and decrease testing efforts. However, findings of past researches done on this issue has not shown any classifier which proves to be superior to the other. Additionally, there is a lack of research that studies the effects and accuracy of genetic programming on software defect prediction. To find solutions for this problem, a comparative software defect prediction experiment between genetic programming and neural networks are performed on four datasets from the NASA Metrics Data repository. Generally, an interesting degree of accuracy is detected, which shows how the metric-based classification is useful. Nevertheless, this article specifies that the application and usage of genetic programming is highly recommended due to the detailed analysis it provides, as well as an important feature in this classification method which allows the viewing of each attributes impact in the dataset.},
journal = {Int. J. Open Source Softw. Process.},
month = oct,
pages = {32–51},
numpages = {20},
keywords = {Classification, Genetic Algorithm, Genetic Programming, Machine learning, Nasa Metrics, Neural Networks, Software Defect Prediction, Testing}
}

@article{10.1504/ijista.2019.102667,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {Statistical assessment of nonlinear manifold detection-based software defect prediction techniques},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {6},
issn = {1740-8865},
url = {https://doi.org/10.1504/ijista.2019.102667},
doi = {10.1504/ijista.2019.102667},
abstract = {Prediction of software defects has immense importance for obtaining desired outcome at minimised cost and so attracted researchers working on this topic applying various techniques, which were not found fully effective. Software datasets comprise of redundant features that hinder effective application of techniques resulting inappropriate defect prediction. Hence, it requires newer application of nonlinear manifold detection techniques (nonlinear MDTs) that has been examined for accurate prediction of defects at lesser time and cost using different classification techniques. In this work, we analysed and tested the effect of nonlinear MDTs to find out accurate and best classification technique for all datasets. Comparison has been made between the results of without or with nonlinear MDTs and paired two-tailed T-test has been performed for statistical testing and verifying the performance of classifiers using nonlinear MDTs on all datasets. Outcome revealed that among all nonlinear MDTs, FastMVU makes most accurate prediction of software defects.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {579–605},
numpages = {26},
keywords = {dimensionality reduction, fast maximum variance unfolding, FastMVU, machine learning, manifold detection, nonlinear, promise repository, software defect prediction}
}

@inproceedings{10.5555/3432601.3432619,
author = {Jahanshahi, Hadi and Cevik, Mucahit and Ba\c{s}ar, Ay\c{s}e},
title = {Moving from cross-project defect prediction to heterogeneous defect prediction: a partial replication study},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software defect prediction heavily relies on the metrics collected from software projects. Earlier studies often used machine learning techniques to build, validate, and improve bug prediction models using either a set of metrics collected within a project or across different projects. However, techniques applied and conclusions derived by those models are restricted by how identical those metrics are. Knowledge coming from those models will not be extensible to a target project if no sufficient overlapping metrics have been collected in the source projects. To explore the feasibility of transferring knowledge across projects without common labeled metrics, we systematically integrated Heterogeneous Defect Prediction (HDP) by replicating and validating the obtained results. Our main goal is to extend prior research and explore the feasibility of HDP and finally to compare its performance with that of its predecessor, Cross-Project Defect Prediction. We construct an HDP model on different publicly available datasets. Moreover, we propose a new ensemble voting approach in the HDP context to utilize the predictive power of multiple available datasets. The result of our experiment is comparable to that of the original study. However, we also explored the feasibility of HDP in real cases. Our results shed light on the infeasibility of many cases for the HDP algorithm due to its sensitivity to the parameter selection. In general, our analysis gives a deep insight into why and how to perform transfer learning from one domain to another, and in particular, provides a set of guidelines to help researchers and practitioners to disseminate knowledge to the defect prediction domain.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {133–142},
numpages = {10},
keywords = {defect prediction, heterogeneous metrics, software quality, transfer learning},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@phdthesis{10.5555/AAI28862075,
author = {Rao, Sunil Srinivasa Manjanbail and Konstantinos, Tsakalis, and Devarajan, Srinivasan,},
advisor = {Andreas, Spanias, and Cihan, Tepedelenlioglu,},
title = {Fault Detection and Classification in Photovoltaic Arrays using Machine Learning},
year = {2021},
isbn = {9798759962939},
publisher = {Arizona State University},
address = {USA},
abstract = {Operational efficiency of solar energy farms requires detailed analytics and information on each panel regarding voltage, current, temperature, and irradiance. Monitoring utility-scale solar arrays was shown to minimize the cost of maintenance and help optimize the performance of photovoltaic (PV) arrays under various conditions. This dissertation describes a project that focuses on the development of machine learning and neural network algorithms. It also describes an 18kW solar array testbed for the purpose of PV monitoring and control. The use of the 18kW Sensor Signal and Information Processing (SenSIP) PV testbed which consists of 104 modules fitted with smart monitoring devices (SMDs) is described in detail. Each of the SMDs has embedded, a wireless transceiver, and relays that enable continuous monitoring, fault detection, and real-time connection topology changes. Data is obtained in real time using the SenSIP PV testbed. Machine learning and neural network algorithms for PV fault classification is are studied in depth. More specifically, the development of a series of customized neural networks for detection and classification of solar array faults that include soiling, shading, degradation, short circuits and standard test conditions is considered. The evaluation of fault detection and classification methods using metrics such as accuracy, confusion matrices, and the Risk Priority Number (RPN) is performed. The examination and assessment the classification performance of customized neural networks with dropout regularizers is presented in detail. The development and evaluation of neural network pruning strategies and illustration of the trade-off between fault classification model accuracy and algorithm complexity is studied. This study includes data from the National Renewable Energy Laboratory (NREL) database and also real-time data collected from the SenSIP testbed at MTW under various loading and shading conditions. The overall approach for detection and classification promises to elevate the performance and robustness of PV arrays.},
note = {AAI28862075}
}

@article{10.1049/iet-sen.2017.0198,
author = {Zhang, Zhi-Wu and Jing, Xiao-Yuan and Wu, Fei},
title = {Low‐rank representation for semi‐supervised software defect prediction},
year = {2018},
issue_date = {December 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {6},
url = {https://doi.org/10.1049/iet-sen.2017.0198},
doi = {10.1049/iet-sen.2017.0198},
abstract = {Software defect prediction based on machine learning is an active research topic in the field of software engineering. The historical defect data in software repositories may contain noises because automatic defect collection is based on modified logs and defect reports. When the previous defect labels of modules are limited, predicting the defect‐prone modules becomes a challenging problem. In this study, the authors propose a graph‐based semi‐supervised defect prediction approach to solve the problems of insufficient labelled data and noisy data. Graph‐based semi‐supervised learning methods used the labelled and unlabelled data simultaneously and consider them as the nodes of the graph at the training phase. Therefore, they solve the problem of insufficient labelled samples. To improve the stability of noisy defect data, a powerful clustering method, low‐rank representation (LRR), and neighbourhood distance are used to construct the relationship graph of samples. Therefore, they propose a new semi‐supervised defect prediction approach, named low‐rank representation‐based semi‐supervised software defect prediction (LRRSSDP). The widely used datasets from NASA projects and noisy datasets are employed as test data to evaluate the performance. Experimental results show that (i) LRRSSDP outperforms several representative state‐of‐the‐art semi‐supervised defect prediction methods; and (ii) LRRSSDP can maintain robustness in noisy environments.},
journal = {IET Software},
month = dec,
pages = {527–535},
numpages = {9},
keywords = {software engineering, learning (artificial intelligence), pattern clustering, graph theory, program diagnostics, semisupervised software defect prediction, software engineering, historical defect data, software repositories, automatic defect collection, defect reports, defect-prone modules, semisupervised defect prediction approach, insufficient labelled data, noisy data, unlabelled data, insufficient labelled samples, noisy defect data, low-rank representation, LRRSSDP}
}

@article{10.1007/s42979-020-0119-4,
author = {Khuat, Thanh Tung and Le, My Hanh},
title = {Evaluation of Sampling-Based Ensembles of Classifiers on Imbalanced Data for Software Defect Prediction Problems},
year = {2020},
issue_date = {Mar 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {2},
url = {https://doi.org/10.1007/s42979-020-0119-4},
doi = {10.1007/s42979-020-0119-4},
abstract = {Defect prediction in software projects plays a crucial role to reduce quality-based risk and increase the capability of detecting faulty program modules. Hence, classification approaches to anticipate software defect proneness based on static code characteristics have become a hot topic with a great deal of attention in recent years. While several novel studies show that the use of a single classifier causes the performance bottleneck, ensembles of classifiers might effectively enhance classification performance compared to a single classifier. However, the class imbalance property of software defect data severely hinders the classification efficiency of ensemble learning. To cope with this problem, resampling methods are usually combined into ensemble models.
This paper empirically assesses the importance of sampling with regard to ensembles of various classifiers on imbalanced data in software defect prediction problems. Extensive experiments with the combination of seven different kinds of classification algorithms, three sampling methods, and two balanced data learning schemata were conducted over ten datasets. Empirical results indicated the positive effects of combining sampling techniques and the ensemble learning model on the performance of defect prediction regarding datasets with imbalanced class distributions.},
journal = {SN Comput. Sci.},
month = mar,
numpages = {16},
keywords = {Software defect prediction, Random undersampling, Random oversampling, SMOTE, Data balancing, Ensemble learning, Imbalanced data}
}

@article{10.1007/s11277-017-5069-3,
author = {Dong, Feng and Wang, Junfeng and Li, Qi and Xu, Guoai and Zhang, Shaodong},
title = {Defect Prediction in Android Binary Executables Using Deep Neural Network},
year = {2018},
issue_date = {October   2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {3},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-5069-3},
doi = {10.1007/s11277-017-5069-3},
abstract = {Software defect prediction locates defective code to help developers improve the security of software. However, existing studies on software defect prediction are mostly limited to the source code. Defect prediction for Android binary executables (called apks) has never been explored in previous studies. In this paper, we propose an explorative study of defect prediction in Android apks. We first propose smali2vec, a new approach to generate features that capture the characteristics of smali (decompiled files of apks) files in apks. Smali2vec extracts both token and semantic features of the defective files in apks and such comprehensive features are needed for building accurate prediction models. Then we leverage deep neural network (DNN), which is one of the most common architecture of deep learning networks, to train and build the defect prediction model in order to achieve accuracy. We apply our defect prediction model to more than 90,000 smali files from 50 Android apks and the results show that our model could achieve an AUC (the area under the receiver operating characteristic curve) of 85.98% and it is capable of predicting defects in apks. Furthermore, the DNN is proved to have a better performance than the traditional shallow machine learning algorithms (e.g., support vector machine and naive bayes) used in previous studies. The model has been used in our practical work and helped locate many defective files in apks.},
journal = {Wirel. Pers. Commun.},
month = oct,
pages = {2261–2285},
numpages = {25},
keywords = {Android binary executables, Deep neural network, Machine learning, Mobile security, Software defect prediction}
}

@article{10.1007/s10515-020-00277-4,
author = {Esteves, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
title = {Understanding machine learning software defect predictions},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {3–4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-020-00277-4},
doi = {10.1007/s10515-020-00277-4},
abstract = {Software defects are well-known in software development and might cause several problems for users and developers aside. As a result, researches employed distinct techniques to mitigate the impacts of these defects in the source code. One of the most notable techniques focuses on defect prediction using machine learning methods, which could support developers in handling these defects before they are introduced in the production environment. These studies provide alternative approaches to predict the likelihood of defects. However, most of these works concentrate on predicting defects from a vast set of software features. Another key issue with the current literature is the lack of a satisfactory explanation of the reasons that drive the software to a defective state. Specifically, we use a tree boosting algorithm (XGBoost) that receives as input a training set comprising records of easy-to-compute characteristics of each module and outputs whether the corresponding module is defect-prone. To exploit the link between predictive power and model explainability, we propose a simple model sampling approach that finds accurate models with the minimum set of features. Our principal idea is that features not contributing to increasing the predictive power should not be included in the model. Interestingly, the reduced set of features helps to increase model explainability, which is important to provide information to developers on features related to each module of the code which is more defect-prone. We evaluate our models on diverse projects within Jureczko datasets, and we show that (i) features that contribute most for finding best models may vary depending on the project and (ii) it is possible to find effective models that use few features leading to better understandability. We believe our results are useful to developers as we provide the specific software features that influence the defectiveness of selected projects.},
journal = {Automated Software Engg.},
month = dec,
pages = {369–392},
numpages = {24},
keywords = {Software defects, Explainable models, Jureczko datasets, SHAP values}
}

@article{10.1155/2021/4997459,
author = {Li, Zhen and Li, Tong and Wu, YuMei and Yang, Liu and Miao, Hong and Wang, DongSheng and Precup, Radu-Emil},
title = {Software Defect Prediction Based on Hybrid Swarm Intelligence and Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/4997459},
doi = {10.1155/2021/4997459},
abstract = {In order to improve software quality and testing efficiency, this paper implements the prediction of software defects based on deep learning. According to the respective advantages and disadvantages of the particle swarm algorithm and the wolf swarm algorithm, the two algorithms are mixed to realize the complementary advantages of the algorithms. At the same time, the hybrid algorithm is used in the search of model hyperparameter optimization, the loss function of the model is used as the fitness function, and the collaborative search ability of the swarm intelligence population is used to find the global optimal solution in multiple local solution spaces. Through the analysis of the experimental results of six data sets, compared with the traditional hyperparameter optimization method and a single swarm intelligence algorithm, the model using the hybrid algorithm has higher and better indicators. And, under the processing of the autoencoder, the performance of the model has been further improved.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {17}
}

@article{10.1007/s00500-021-06254-7,
author = {Sotto-Mayor, Bruno and Kalech, Meir},
title = {Cross-project smell-based defect prediction},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {22},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-06254-7},
doi = {10.1007/s00500-021-06254-7},
abstract = {Defect prediction is a technique introduced to optimize the testing phase of the software development pipeline by predicting which components in the software may contain defects. Its methodology trains a classifier with data regarding a set of features measured on each component from the target software project to predict whether the component may be defective or not. However, suppose the defective information is not available in the training set. In that case, we need to rely on an alternate approach that uses the training set of external projects to train the classifier. This approached is called cross-project defect prediction. Bad code smells are a category of features that have been previously explored in defect prediction and have been shown to be a good predictor of defects. Code smells are patterns of poor development in the code and indicate flaws in its design and implementation. Although they have been previously studied in the context of defect prediction, they have not been studied as features for cross-project defect prediction. In our experiment, we train defect prediction models for 100 projects to evaluate the predictive performance of the bad code smells. We implemented four cross-project approaches known in the literature and compared the performance of 37 smells with 56 code metrics, commonly used for defect prediction. The results show that the cross-project defect prediction models trained with code smells significantly improved 6.50% on the ROC AUC compared against the code metrics.},
journal = {Soft Comput.},
month = nov,
pages = {14171–14181},
numpages = {11},
keywords = {Cross-project defect prediction, Defect prediction, Code smell, Mining software repositories, Software quality, Software engineering}
}

@article{10.1504/ijcat.2019.100297,
author = {Jayanthi, R. and Florence, M. Lilly},
title = {Improved Bayesian regularisation using neural networks based on feature selection for software defect prediction},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {60},
number = {3},
issn = {0952-8091},
url = {https://doi.org/10.1504/ijcat.2019.100297},
doi = {10.1504/ijcat.2019.100297},
abstract = {Demand for software-based applications has grown drastically in various real-time applications. However, software testing schemes have been developed which include manual and automatic testing. Manual testing requires human effort and chances of error may still affect the quality of software. To overcome this issue, automatic software testing techniques based on machine learning techniques have been developed. In this work, we focus on the machine learning scheme for early prediction of software defects using Levenberg-Marquardt algorithm (LM), Back Propagation (BP) and Bayesian Regularisation (BR) techniques. Bayesian regularisation achieves better performance in terms of bug prediction. However, this performance can be enhanced further. Hence, we developed a novel approach for attribute selection-based feature selection technique to improve the performance of BR classification. An extensive study is carried out with the PROMISE repository where we considered KC1 and JM1 datasets. Experimental study shows that the proposed approach achieves better performance in predicting the defects in software.},
journal = {Int. J. Comput. Appl. Technol.},
month = jan,
pages = {225–241},
numpages = {16},
keywords = {defect prediction model, machine learning techniques, software defect prediction, software metrics, gradient descent optimisation, gradient-based approach, feature subset selection, cross entropy error function, adaptive computation process}
}

@article{10.1007/s11390-019-1958-0,
author = {Chen, Xiang and Zhang, Dun and Cui, Zhan-Qi and Gu, Qing and Ju, Xiao-Lin},
title = {DP-Share: Privacy-Preserving Software Defect Prediction Model Sharing Through Differential Privacy},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {5},
issn = {1000-9000},
url = {https://doi.org/10.1007/s11390-019-1958-0},
doi = {10.1007/s11390-019-1958-0},
abstract = {In current software defect prediction (SDP) research, most previous empirical studies only use datasets provided by PROMISE repository and this may cause a threat to the external validity of previous empirical results. Instead of SDP dataset sharing, SDP model sharing is a potential solution to alleviate this problem and can encourage researchers in the research community and practitioners in the industrial community to share more models. However, directly sharing models may result in privacy disclosure, such as model inversion attack. To the best of our knowledge, we are the first to apply differential privacy (DP) to privacy-preserving SDP model sharing and then propose a novel method DP-Share, since DP mechanisms can prevent this attack when the privacy budget is carefully selected. In particular, DP-Share first performs data preprocessing for the dataset, such as over-sampling for minority instances (i.e., defective modules) and conducting discretization for continuous features to optimize privacy budget allocation. Then, it uses a novel sampling strategy to create a set of training sets. Finally it constructs decision trees based on these training sets and these decision trees can form a random forest (i.e., model). The last phase of DP-Share uses Laplace and exponential mechanisms to satisfy the requirements of DP. In our empirical studies, we choose nine experimental subjects from real software projects. Then, we use AUC (area under ROC curve) as the performance measure and holdout as our model validation technique. After privacy and utility analysis, we find that DP-Share can achieve better performance than a baseline method DF-Enhance in most cases when using the same privacy budget. Moreover, we also provide guidelines to effectively use our proposed method. Our work attempts to fill the research gap in terms of differential privacy for SDP, which can encourage researchers and practitioners to share more SDP models and then effectively advance the state of the art of SDP.},
journal = {J. Comput. Sci. Technol.},
month = sep,
pages = {1020–1038},
numpages = {19},
keywords = {software defect prediction, model sharing, differential privacy, cross project defect prediction, empirical study}
}

@article{10.1016/j.procs.2015.02.161,
author = {Arora, Ishani and Tetarwal, Vivek and Saha, Anju},
title = {Open Issues in Software Defect Prediction},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.161},
doi = {10.1016/j.procs.2015.02.161},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {906–912},
numpages = {7},
keywords = {data mining, defect prediction, machine learning, software quality, software testing}
}

@article{10.3233/KES-210061,
author = {Shatnawi, Raed},
title = {Software fault prediction using machine learning techniques with metric thresholds},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {25},
number = {2},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-210061},
doi = {10.3233/KES-210061},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {159–172},
numpages = {14},
keywords = {Fault prediction, software metrics, threshold values, machine learning}
}

@article{10.1016/j.ins.2018.02.027,
author = {Miholca, Diana-Lucia and Czibula, Gabriela and Czibula, Istvan Gergely},
title = {A novel approach for software defect prediction through hybridizing gradual relational association rules with artificial neural networks},
year = {2018},
issue_date = {May 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {441},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2018.02.027},
doi = {10.1016/j.ins.2018.02.027},
abstract = {The growing complexity of software projects requires increasing consideration of their analysis and testing. Identifying defective software entities is essential for software quality assurance and it also improves activities related to software testing. In this study, we developed a novel supervised classification method called HyGRAR for software defect prediction. HyGRAR is a non-linear hybrid model that combines gradual relational association rule mining and artificial neural networks to discriminate between defective and non-defective software entities. Experiments performed based on 10 open-source data sets demonstrated the excellent performance of the HYGRAR classifier. HyGRAR performed better than most of the previously proposed approaches for software defect prediction in performance evaluations using the same data sets.},
journal = {Inf. Sci.},
month = may,
pages = {152–170},
numpages = {19},
keywords = {Artificial neural network, Gradual relational association rule, Machine learning, Software defect prediction}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00056,
author = {Aleithan, Reem},
title = {Explainable just-in-time bug prediction: are we there yet?},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00056},
doi = {10.1109/ICSE-Companion52605.2021.00056},
abstract = {Explaining the prediction results of software bug prediction models is a challenging task, which can provide useful information for developers to understand and fix the predicted bugs. Recently, Jirayus et al. [4] proposed to use two model-agnostic techniques (i.e., LIME and iBreakDown) to explain the prediction results of bug prediction models. Although their experiments on file-level bug prediction show promising results, the performance of these techniques on explaining the results of just-in-time (i.e., change-level) bug prediction is unknown. This paper conducts the first empirical study to explore the explainability of these model-agnostic techniques on just-in-time bug prediction models. Specifically, this study takes a three-step approach, 1) replicating previously widely used just-in-time bug prediction models, 2) applying Local Interpretability Model-agnostic Explanation Technique (LIME) and iBreakDown on the prediction results, and 3) manually evaluating the explanations for buggy instances (i.e. positive predictions) against the root cause of the bugs. The results of our experiment show that LIME and iBreakDown fail to explain defect prediction explanations for just-in-time bug prediction models, unlike file-level [4]. This paper urges for new approaches for explaining the results of just-in-time bug prediction models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {129–131},
numpages = {3},
keywords = {bug prediction, prediction explanation},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@article{10.1016/j.knosys.2015.09.035,
author = {Li, Weiwei and Huang, Zhiqiu and Li, Qing},
title = {Three-way decisions based software defect prediction},
year = {2016},
issue_date = {January 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {91},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.09.035},
doi = {10.1016/j.knosys.2015.09.035},
abstract = {Based on a two-stage classification method and a two-stage ranking method on three-way decisions, this paper introduces a three-way decisions framework for cost-sensitive software defect prediction. For the classification problem in software defect prediction, traditional two-way decisions methods usually generate a higher classification error and more decision cost. Here, a two-stage classification method that integrates three-way decisions and ensemble learning to predict software defect is proposed. Experimental results on NASA data sets show that our method can obtain a higher accuracy and a lower decision cost. For the ranking problem in software defect prediction, a two-stage ranking method is introduced. In the first stage, all software modules are classified into three different regions based on three-way decisions. A dominance relation rough set based ranking algorithm is next applied to rank the modules in each region. Comparison experiments with 6 other ranking methods present that our proposed method can obtain a better result on FPA measure.},
journal = {Know.-Based Syst.},
month = jan,
pages = {263–274},
numpages = {12},
keywords = {Software defect classification, Software defect ranking, Three-way decisions}
}

@inproceedings{10.1145/3342999.3343010,
author = {Cui, Mengtian and Sun, Yue and Lu, Yang and Jiang, Yue},
title = {Study on the Influence of the Number of Features on the Performance of Software Defect Prediction Model},
year = {2019},
isbn = {9781450371605},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342999.3343010},
doi = {10.1145/3342999.3343010},
abstract = {The software defect prediction model based on machine learning technology is the key to improve the reliability of software. The influence of the number of features on the performance of different software defect prediction models was proposed in this paper. First, a new data sets was built, which is increasing by the number of features based on the NASA public data sets. Then, the eight predictive models are experimented based on these data sets. Next, the influence of the number of features on the performance of different prediction models was analyzed based on the experimental results. Next, the AUC values obtained from the experiment were used to evaluate the performance of different prediction models, and the coefficient of variation C·V values was used to evaluate the performance stability of different prediction models while the number of features changed. In the end, the experiments show that the performance of the predictive model C4.5 is highly susceptible to changes in the number of features, while the performance of the predictive model SMO is relatively stable.},
booktitle = {Proceedings of the 2019 3rd International Conference on Deep Learning Technologies},
pages = {32–37},
numpages = {6},
keywords = {software defect prediction, number of features, machine learning, feature selection},
location = {Xiamen, China},
series = {ICDLT '19}
}

@article{10.1016/j.procs.2018.05.012,
author = {Ghosh, Soumi and Rana, Ajay and Kansal, Vineet},
title = {A Nonlinear Manifold Detection based Model for Software Defect Prediction},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.012},
doi = {10.1016/j.procs.2018.05.012},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {581–594},
numpages = {14},
keywords = {Feature Selection techniques, Friedman test, Nonlinear Manifold Detection techniques, Paired two-tailed T-test, Software Defect Prediction}
}

@inproceedings{10.1145/3377811.3380403,
author = {Tabassum, Sadia and Minku, Leandro L. and Feng, Danyi and Cabral, George G. and Song, Liyan},
title = {An investigation of cross-project learning in online just-in-time software defect prediction},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380403},
doi = {10.1145/3377811.3380403},
abstract = {Just-In-Time Software Defect Prediction (JIT-SDP) is concerned with predicting whether software changes are defect-inducing or clean based on machine learning classifiers. Building such classifiers requires a sufficient amount of training data that is not available at the beginning of a software project. Cross-Project (CP) JIT-SDP can overcome this issue by using data from other projects to build the classifier, achieving similar (not better) predictive performance to classifiers trained on Within-Project (WP) data. However, such approaches have never been investigated in realistic online learning scenarios, where WP software changes arrive continuously over time and can be used to update the classifiers. It is unknown to what extent CP data can be helpful in such situation. In particular, it is unknown whether CP data are only useful during the very initial phase of the project when there is little WP data, or whether they could be helpful for extended periods of time. This work thus provides the first investigation of when and to what extent CP data are useful for JIT-SDP in a realistic online learning scenario. For that, we develop three different CP JIT-SDP approaches that can operate in online mode and be updated with both incoming CP and WP training examples over time. We also collect 2048 commits from three software repositories being developed by a software company over the course of 9 to 10 months, and use 19,8468 commits from 10 active open source GitHub projects being developed over the course of 6 to 14 years. The study shows that training classifiers with incoming CP+WP data can lead to improvements in G-mean of up to 53.90% compared to classifiers using only WP data at the initial stage of the projects. For the open source projects, which have been running for longer periods of time, using CP data to supplement WP data also helped the classifiers to reduce or prevent large drops in predictive performance that may occur over time, leading to up to around 40% better G-Mean during such periods. Such use of CP data was shown to be beneficial even after a large number of WP data were received, leading to overall G-means up to 18.5% better than those of WP classifiers.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {554–565},
numpages = {12},
keywords = {class imbalance, concept drift, cross-project learning, online learning, software defect prediction, transfer learning, verification latency},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/2896387.2900324,
author = {Rahman, Md. Habibur and Sharmin, Sadia and Sarwar, Sheikh Muhammad and Shoyaib, Mohammad},
title = {Software Defect Prediction Using Feature Space Transformation},
year = {2016},
isbn = {9781450340632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896387.2900324},
doi = {10.1145/2896387.2900324},
abstract = {In software quality estimation research, software defect prediction is a key topic. A defect prediction model is generally constructed using a variety of software attributes and each attribute may have positive, negative or neutral effect on a specific model. Selection of an optimal set of attributes for model development remains a vital yet unexplored issue. In this paper, we have introduced a new feature space transformation process with a normalization technique to improve the defect prediction accuracy. We proposed a feature space transformation technique and classify the instances using Support Vector Machine (SVM) with its histogram intersection kernel. The proposed method is evaluated using the data sets from NASA metric data repository and its application demonstrates acceptable accuracy.},
booktitle = {Proceedings of the International Conference on Internet of Things and Cloud Computing},
articleno = {72},
numpages = {6},
keywords = {Software defect prediction, Feature space transformation, Attribute selection},
location = {Cambridge, United Kingdom},
series = {ICC '16}
}

@inproceedings{10.1145/3180374.3181331,
author = {Li, Yuting and Su, Jianmin and Yang, Xiaoxing},
title = {Multi-Objective vs. Single-Objective Approaches for Software Defect Prediction},
year = {2018},
isbn = {9781450354318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180374.3181331},
doi = {10.1145/3180374.3181331},
abstract = {Software defect prediction employs attributes of software modules to identify defect-prone modules and thus improves software reliability by allocating testing resources more efficiently. Realizing that single-objective methods might be insufficient for solving defect prediction problems, some researchers have proposed multi-objective learning approaches, and proved better performance of multi-objective than single-objective methods. However, existing compared single-objective methods optimize a completely different goal from goals of multi-objective approaches, which might lead to bias. In this paper, we compare a multi-objective approach that optimizes two objectives and a single-objective approach that directly optimizes a trade-off of the two objectives, in order to further investigate the comparison of multi-objective and single-objective approaches. The conclusion will help to appropriately choose multi-objective or single-objective learning approaches for defect prediction.},
booktitle = {Proceedings of the 2018 2nd International Conference on Management Engineering, Software Engineering and Service Sciences},
pages = {122–127},
numpages = {6},
keywords = {software defect prediction, single-objective learning, effectiveness, cost, Multi-objective learning},
location = {Wuhan, China},
series = {ICMSS 2018}
}

@article{10.1007/s10515-011-0092-1,
author = {Li, Ming and Zhang, Hongyu and Wu, Rongxin and Zhou, Zhi-Hua},
title = {Sample-based software defect prediction with active and semi-supervised learning},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0092-1},
doi = {10.1007/s10515-011-0092-1},
abstract = {Software defect prediction can help us better understand and control software quality. Current defect prediction techniques are mainly based on a sufficient amount of historical project data. However, historical data is often not available for new projects and for many organizations. In this case, effective defect prediction is difficult to achieve. To address this problem, we propose sample-based methods for software defect prediction. For a large software system, we can select and test a small percentage of modules, and then build a defect prediction model to predict defect-proneness of the rest of the modules. In this paper, we describe three methods for selecting a sample: random sampling with conventional machine learners, random sampling with a semi-supervised learner and active sampling with active semi-supervised learner. To facilitate the active sampling, we propose a novel active semi-supervised learning method ACoForest which is able to sample the modules that are most helpful for learning a good prediction model. Our experiments on PROMISE datasets show that the proposed methods are effective and have potential to be applied to industrial practice.},
journal = {Automated Software Engg.},
month = jun,
pages = {201–230},
numpages = {30},
keywords = {Software defect prediction, Sampling, Quality assurance, Machine learning, Active semi-supervised learning}
}

@inproceedings{10.1007/978-3-030-59003-1_27,
author = {Shakhovska, Natalya and Yakovyna, Vitaliy and Kryvinska, Natalia},
title = {An Improved Software Defect Prediction Algorithm Using Self-organizing Maps Combined with Hierarchical Clustering and Data Preprocessing},
year = {2020},
isbn = {978-3-030-59002-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59003-1_27},
doi = {10.1007/978-3-030-59003-1_27},
abstract = {An improved software defects prediction algorithm based on combination of Kohonen map and hierarchical clustering is presented in this paper. The need for software reliability assessment and analysis growths rapidly due to increasing dependence of our day-to-day life on software-controlled devices and systems. Software reliability prediction is the only tool available at early stage of software development lifecycle when the debugging cost risk of faulty operation is minimal. Artificial intelligence and machine learning in particular are promising techniques to solve this task. Various classification methods have been used previously to build software defect prediction models, ranging from simple, like logistic regression, to advanced methods, e.g. multivariate adaptive regression splicing. However, the available literature still does not allow to make unambiguous conclusion concerning the choice of the best classifier and trying different dimensions to overcome potential bias is suggested. The purpose of the paper is to analyze the software code metrics to find dependences be-tween software module’s defect-proneness and its metrics. JM1 public NASA dataset from PROMISE Software Engineering Repository was used in this study. To increase the classification accuracy, we combine self-organizing maps with hierarchical clustering and data preprocessing.},
booktitle = {Database and Expert Systems Applications: 31st International Conference, DEXA 2020, Bratislava, Slovakia, September 14–17, 2020, Proceedings, Part I},
pages = {414–424},
numpages = {11},
keywords = {Prediction algorithm, Hierarchical clustering, Software defect analysis},
location = {Bratislava, Slovakia}
}

@inproceedings{10.1145/3028842.3028859,
author = {Gao, Yan and Yang, Chunhui},
title = {Software defect prediction based on manifold learning in subspace selection},
year = {2016},
isbn = {9781450347990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3028842.3028859},
doi = {10.1145/3028842.3028859},
abstract = {Software defects will lead to software running error and system crashes. In order to detect software defect as early as possible at early stage of software development, a series of machine learning approaches have been studied and applied to predict defects in software modules. Unfortunately, the imbalanceof software defect datasets brings great challenge to software defect prediction model training. In this paper, a new manifold learning based subspace learning algorithm, Discriminative Locality Alignment(DLA), is introduced into software defects prediction. Experimental results demonstrate that DLA is consistently superior to LDA (Linear Discriminant Analysis) and PCA (Principal Component Analysis) in terms of discriminate information extraction and prediction performance. In addition, DLA reveals some attractive intrinsic properties for numeric calculation, e.g. it can overcome the matrix singular problem and small sample size problem in software defect prediction.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Information Processing},
articleno = {17},
numpages = {6},
keywords = {support vector machine, software defect prediction, manifold learning, discriminative locality alignment},
location = {Wuhan, China},
series = {ICIIP '16}
}

@inproceedings{10.1145/3106237.3106257,
author = {Fu, Wei and Menzies, Tim},
title = {Revisiting unsupervised learning for defect prediction},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3106257},
doi = {10.1145/3106237.3106257},
abstract = {Collecting quality data from software projects can be time-consuming and expensive. Hence, some researchers explore "unsupervised" approaches to quality prediction that does not require labelled data. An alternate technique is to use "supervised" approaches that learn models from project data labelled with, say, "defective" or "not-defective". Most researchers use these supervised models since, it is argued, they can exploit more knowledge of the projects. At FSE-16, Yang et al. reported startling results where unsupervised defect predictors outperformed supervised predictors for effort-aware just-in-time defect prediction. If confirmed, these results would lead to a dramatic simplification of a seemingly complex task (data mining) that is widely explored in the software engineering literature. This paper repeats and refutes those results as follows. (1) There is much variability in the efficacy of the Yang et al. predictors so even with their approach, some supervised data is required to prune weaker predictors away. (2) Their findings were grouped across N projects. When we repeat their analysis on a project-by-project basis, supervised predictors are seen to work better. Even though this paper rejects the specific conclusions of Yang et al., we still endorse their general goal. In our our experiments, supervised predictors did not perform outstandingly better than unsupervised ones for effort-aware just-in-time defect prediction. Hence, they may indeed be some combination of unsupervised learners to achieve comparable performance to supervised ones. We therefore encourage others to work in this promising area.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {72–83},
numpages = {12},
keywords = {software repository mining, empirical studies, defect prediction, data analytics for software engineering},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@article{10.1016/j.infsof.2017.11.008,
author = {Tong, Haonan and Liu, Bin and Wang, Shihai},
title = {Software defect prediction using stacked denoising autoencoders and two-stage ensemble learning},
year = {2018},
issue_date = {Apr 2018},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {96},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2017.11.008},
doi = {10.1016/j.infsof.2017.11.008},
journal = {Inf. Softw. Technol.},
month = apr,
pages = {94–111},
numpages = {18},
keywords = {Deep learning, Software metrics, Ensemble learning, Stacked denoising autoencoders, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-87007-2_26,
author = {Szamosv\"{o}lgyi, Zsolt J\'{a}nos and V\'{a}radi, Endre Tam\'{a}s and T\'{o}th, Zolt\'{a}n and J\'{a}sz, Judit and Ferenc, Rudolf},
title = {Assessing Ensemble Learning Techniques in Bug Prediction},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_26},
doi = {10.1007/978-3-030-87007-2_26},
abstract = {The application of ensemble learning techniques is continuously increasing, since they have proven to be superior over traditional machine learning techniques in various domains. These algorithms could be employed for bug prediction purposes as well. Existing studies investigated the performance of ensemble learning techniques only for PROMISE and the NASA MDP public datasets; however, it is important to evaluate the ensemble learning techniques on additional public datasets in order to test the generalizability of the techniques. We investigated the performance of the two most widely-used ensemble learning techniques AdaBoost and Bagging on the Unified Bug Dataset, which encapsulates 3 class level public bug datasets in a uniformed format with a common set of software product metrics used as predictors. Additionally, we investigated the effect of using 3 different resampling techniques on the dataset. Finally, we studied the performance of using Decision Tree and Na\"{\i}ve Bayes as the weak learners in the ensemble learning. We also fine tuned the parameters of the weak learners to have the best possible end results.We experienced that AdaBoost with Decision Tree weak learner outperformed other configurations. We could achieve 54.61% F-measure value (81.96% Accuracy, 50.92% Precision, 58.90% Recall) with the configuration of 300 estimators and 0.05 learning rate. Based on the needs, one can apply RUS resampling to get a recall value up&nbsp;to 75.14% (of course losing precision at the same time).},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {368–381},
numpages = {14},
keywords = {Unified bug dataset, Resampling, Bug prediction, AdaBoost},
location = {Cagliari, Italy}
}

@article{10.1155/2019/2384706,
author = {Yang, Xingguang and Yu, Huiqun and Fan, Guisheng and Shi, Kai and Chen, Liqiong and Tramontana, Emiliano},
title = {Local versus Global Models for Just-In-Time Software Defect Prediction},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {1058-9244},
url = {https://doi.org/10.1155/2019/2384706},
doi = {10.1155/2019/2384706},
abstract = {Just-in-time software defect prediction (JIT-SDP) is an active topic in software defect prediction, which aims to identify defect-inducing changes. Recently, some studies have found that the variability of defect data sets can affect the performance of defect predictors. By using local models, it can help improve the performance of prediction models. However, previous studies have focused on module-level defect prediction. Whether local models are still valid in the context of JIT-SDP is an important issue. To this end, we compare the performance of local and global models through a large-scale empirical study based on six open-source projects with 227417 changes. The experiment considers three evaluation scenarios of cross-validation, cross-project-validation, and timewise-cross-validation. To build local models, the experiment uses the k-medoids to divide the training set into several homogeneous regions. In addition, logistic regression and effort-aware linear regression (EALR) are used to build classification models and effort-aware prediction models, respectively. The empirical results show that local models perform worse than global models in the classification performance. However, local models have significantly better effort-aware prediction performance than global models in the cross-validation and cross-project-validation scenarios. Particularly, when the number of clusters k is set to 2, local models can obtain optimal effort-aware prediction performance. Therefore, local models are promising for effort-aware JIT-SDP.},
journal = {Sci. Program.},
month = jan,
numpages = {13}
}

@inproceedings{10.1007/978-3-030-87007-2_27,
author = {Aladics, Tam\'{a}s and J\'{a}sz, Judit and Ferenc, Rudolf},
title = {Bug Prediction Using Source Code Embedding Based on Doc2Vec},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_27},
doi = {10.1007/978-3-030-87007-2_27},
abstract = {Bug prediction is a resource demanding task that is hard to automate using static source code analysis. In many fields of computer science, machine learning has proven to be extremely useful in tasks like this, however, for it to work we need a way to use source code as input. We propose a simple, but meaningful representation for source code based on its abstract syntax tree and the Doc2Vec embedding algorithm. This representation maps the source code to a fixed length vector which can be used for various upstream tasks – one of which is bug prediction. We measured this approach’s validity by itself and its effectiveness compared to bug prediction based solely on code metrics. We also experimented on numerous machine learning approaches to check the connection between different embedding parameters with different machine learning models. Our results show that this representation provides meaningful information as it improves the bug prediction accuracy in most cases, and is always at least as good as only using code metrics as features.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {382–397},
numpages = {16},
keywords = {Doc2Vec, Java, Bug prediction, Code metrics, Source code embedding},
location = {Cagliari, Italy}
}

@inproceedings{10.1145/3383219.3383281,
author = {Khan, Bilal and Iqbal, Danish and Badshah, Sher},
title = {Cross-Project Software Fault Prediction Using Data Leveraging Technique to Improve Software Quality},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383281},
doi = {10.1145/3383219.3383281},
abstract = {Software fault prediction is a process to detect bugs in software projects. Fault prediction in software engineering has attracted much attention from the last decade. The early prognostication of faults in software minimize the cost and effort of errors that come at later stages. Different machine learning techniques have been utilized for fault prediction, that is proven to be utilizable. Despite, the significance of fault prediction most of the companies do not consider fault prediction in practice and do not build useful models due to lack of data or lack of enough data to strengthen the power of fault predictors. However, models trained and tested on less amount of data are difficult to generalize, because they do not consider project size, project differences, and features selection. To overcome these issues, we proposed an instance-based transfer learning through data leveraging using logistic linear regression as a base proposed statistical methodology. In our study, we considered three software projects within the same domain. Finally, we performed a comparative analysis of three different experiments for building models (targeted project). The experimental results of the proposed approach show promising improvements in (SFP).},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {434–438},
numpages = {5},
keywords = {data leveraging, Software fault prediction, Software Quality, Machine learning, Instance-based learning, Cross-project},
location = {Trondheim, Norway},
series = {EASE '20}
}

@article{10.1016/j.infsof.2019.07.003,
author = {Zhou, Tianchi and Sun, Xiaobing and Xia, Xin and Li, Bin and Chen, Xiang},
title = {Improving defect prediction with deep forest},
year = {2019},
issue_date = {Oct 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {114},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.07.003},
doi = {10.1016/j.infsof.2019.07.003},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {204–216},
numpages = {13},
keywords = {Empirical evaluation, Cascade strategy, Deep forest, Software defect prediction}
}

@article{10.1049/iet-sen.2017.0111,
author = {Qiu, Shaojian and Lu, Lu and Jiang, Siyu},
title = {Multiple‐components weights model for cross‐project software defect prediction},
year = {2018},
issue_date = {August 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {12},
number = {4},
url = {https://doi.org/10.1049/iet-sen.2017.0111},
doi = {10.1049/iet-sen.2017.0111},
abstract = {Software defect prediction (SDP) technology is receiving widely attention and most of SDP models are trained on data from the same project. However, at an early phase of the software lifecycle, there are little to no within‐project training data to learn an available supervised defect‐prediction model. Thus, cross‐project defect prediction (CPDP), which is learning a defect predictor for a target project by using labelled data from a source project, has shown promising value in SDP. To better perform the CPDP, most current studies focus on filtering instances or selecting features to weaken the impact of irrelevant cross‐project data. Instead, the authors propose a novel multiple‐components weights (MCWs) learning model to analyse the varying auxiliary power of multiple components in a source project to construct a more precise ensemble classifiers for a target project. By combining the MCW model with kernel mean matching algorithm, their proposed approach adjusts the source‐instance weights and source‐component weights to jointly alleviate the negative impacts of irrelevant cross‐project data. They conducted comprehensive experiments by employing 15 real‐world datasets to demonstrate the advantages and effectiveness of their proposed approach.},
journal = {IET Software},
month = aug,
pages = {345–355},
numpages = {11},
keywords = {learning (artificial intelligence), software quality, cross-project defect prediction, CPDP, MCW model, source-instance weights, source-component weights, cross-project software defect prediction, SDP models, software lifecycle, within-project training data, Multiple-components weights model, MCW learning model}
}

@article{10.1049/iet-sen.2020.0119,
author = {Pandey, Sushant Kumar and Rathee, Deevashwer and Tripathi, Anil Kumar},
title = {Software defect prediction using K‐PCA and various kernel‐based extreme learning machine: an empirical study},
year = {2021},
issue_date = {December 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {7},
url = {https://doi.org/10.1049/iet-sen.2020.0119},
doi = {10.1049/iet-sen.2020.0119},
abstract = {Predicting defects during software testing reduces an enormous amount of testing effort and help to deliver a high‐quality software system. Owing to the skewed distribution of public datasets, software defect prediction (SDP) suffers from the class imbalance problem, which leads to unsatisfactory results. Overfitting is also one of the biggest challenges for SDP. In this study, the authors performed an empirical study of these two problems and investigated their probable solution. They have conducted 4840 experiments over five different classifiers using eight NASA projects and 14&nbsp;PROMISE repository datasets. They suggested and investigated the varying kernel function of an extreme learning machine (ELM) along with kernel principal component analysis (K‐PCA) and found better results compared with other classical SDP models. They used the synthetic minority oversampling technique as a sampling method to address class imbalance problems and k‐fold cross‐validation to avoid the overfitting problem. They found ELM‐based SDP has a high receiver operating characteristic curve over 11 out of 22 datasets. The proposed model has higher precision and F‐score values over ten and nine, respectively, compared with other state‐of‐the‐art models. The Mathews correlation coefficient (MCC) of 17 datasets of the proposed model surpasses other classical models' MCC.},
journal = {IET Software},
month = feb,
pages = {768–782},
numpages = {15},
keywords = {sampling methods, learning (artificial intelligence), program testing, principal component analysis, software quality, F, K, Mathews correlation coefficient, sampling method, synthetic minority oversampling technique, NASA projects, high‐quality software system, software testing, kernel‐based extreme learning machine, high receiver operating characteristic curve, ELM‐based SDP, overfitting problem, classical SDP models, K‐PCA, kernel principal component analysis, kernel function, PROMISE repository datasets, class imbalance problem, software defect prediction, public datasets}
}

@article{10.1016/j.jss.2019.03.012,
author = {Ni, Chao and Chen, Xiang and Wu, Fangfang and Shen, Yuxiang and Gu, Qing},
title = {An empirical study on pareto based multi-objective feature selection for software defect prediction},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {152},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.03.012},
doi = {10.1016/j.jss.2019.03.012},
journal = {J. Syst. Softw.},
month = jun,
pages = {215–238},
numpages = {24},
keywords = {Empirical study, Multi-Objective optimization, Feature selection, Search based software engineering, Software defect prediction, xx-xx, xx-xx}
}

@article{10.1007/s10664-018-9633-6,
author = {Bennin, Kwabena Ebo and Keung, Jacky W. and Monden, Akito},
title = {On the relative value of data resampling approaches for software defect prediction},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9633-6},
doi = {10.1007/s10664-018-9633-6},
abstract = {Software defect data sets are typically characterized by an unbalanced class distribution where the defective modules are fewer than the non-defective modules. Prediction performances of defect prediction models are detrimentally affected by the skewed distribution of the faulty minority modules in the data set since most algorithms assume both classes in the data set to be equally balanced. Resampling approaches address this concern by modifying the class distribution to balance the minority and majority class distribution. However, very little is known about the best distribution for attaining high performance especially in a more practical scenario. There are still inconclusive results pertaining to the suitable ratio of defect and clean instances (Pfp), the statistical and practical impacts of resampling approaches on prediction performance and the more stable resampling approach across several performance measures. To assess the impact of resampling approaches, we investigated the bias and effect of commonly used resampling approaches on prediction accuracy in software defect prediction. Analyzes of six resampling approaches on 40 releases of 20 open-source projects across five performance measures and five imbalance rates were performed. The experimental results obtained indicate that there were statistical differences between the prediction results with and without resampling methods when evaluated with the geometric-mean, recall(pd), probability of false alarms(pf ) and balance performance measures. However, resampling methods could not improve the AUC values across all prediction models implying that resampling methods can help in defect classification but not defect prioritization. A stable Pfp rate was dependent on the performance measure used. Lower Pfp rates are required for lower pf values while higher Pfp values are required for higher pd values. Random Under-Sampling and Borderline-SMOTE proved to be the more stable resampling method across several performance measures among the studied resampling methods. Performance of resampling methods are dependent on the imbalance ratio, evaluation measure and to some extent the prediction model. Newer oversampling methods should aim at generating relevant and informative data samples and not just increasing the minority samples.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {602–636},
numpages = {35},
keywords = {Class imbalance, Data resampling approaches, Empirical study, Imbalanced data, Software defect prediction}
}

@inproceedings{10.1109/ICSE.2019.00076,
author = {Cabral, George G. and Minku, Leandro L. and Shihab, Emad and Mujahid, Suhaib},
title = {Class imbalance evolution and verification latency in just-in-time software defect prediction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2019.00076},
doi = {10.1109/ICSE.2019.00076},
abstract = {Just-in-Time Software Defect Prediction (JIT-SDP) is an SDP approach that makes defect predictions at the software change level. Most existing JIT-SDP work assumes that the characteristics of the problem remain the same over time. However, JIT-SDP may suffer from class imbalance evolution. Specifically, the imbalance status of the problem (i.e., how much underrepresented the defect-inducing changes are) may be intensified or reduced over time. If occurring, this could render existing JIT-SDP approaches unsuitable, including those that rebuild classifiers over time using only recent data. This work thus provides the first investigation of whether class imbalance evolution poses a threat to JIT-SDP. This investigation is performed in a realistic scenario by taking into account verification latency - the often overlooked fact that labeled training examples arrive with a delay. Based on 10 GitHub projects, we show that JIT-SDP suffers from class imbalance evolution, significantly hindering the predictive performance of existing JIT-SDP approaches. Compared to state-of-the-art class imbalance evolution learning approaches, the predictive performance of JIT-SDP approaches was up to 97.2% lower in terms of g-mean. Hence, it is essential to tackle class imbalance evolution in JIT-SDP. We then propose a novel class imbalance evolution approach for the specific context of JIT-SDP. While maintaining top ranked g-means, this approach managed to produce up to 63.59% more balanced recalls on the defect-inducing and clean classes than state-of-the-art class imbalance evolution approaches. We thus recommend it to avoid overemphasizing one class over the other in JIT-SDP.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {666–676},
numpages = {11},
keywords = {verification latency, software defect prediction, online learning, ensembles, concept drift, class imbalance},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@article{10.1002/stvr.1610,
author = {Wang, Tiejian and Zhang, Zhiwu and Jing, Xiaoyuan and Liu, Yanli},
title = {Non-negative sparse-based SemiBoost for software defect prediction},
year = {2016},
issue_date = {November 2016},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {26},
number = {7},
issn = {0960-0833},
url = {https://doi.org/10.1002/stvr.1610},
doi = {10.1002/stvr.1610},
abstract = {Software defect prediction is an important decision support activity in software quality assurance. The limitation of the labelled modules usually makes the prediction difficult, and the class-imbalance characteristic of software defect data leads to negative influence on decision of classifiers. Semi-supervised learning can build high-performance classifiers by using large amount of unlabelled modules together with the labelled modules. Ensemble learning achieves a better prediction capability for class-imbalance data by using a series of weak classifiers to reduce the bias generated by the majority class. In this paper, we propose a new semi-supervised software defect prediction approach, non-negative sparse-based SemiBoost learning. The approach is capable of exploiting both labelled and unlabelled data and is formulated in a boosting framework. In order to enhance the prediction ability, we design a flexible non-negative sparse similarity matrix, which can fully exploit the similarity of historical data by incorporating the non-negativity constraint into sparse learning for better learning the latent clustering relationship among software modules. The widely used datasets from NASA projects are employed as test data to evaluate the performance of all compared methods. Experimental results show that non-negative sparse-based SemiBoost learning outperforms several representative state-of-the-art semi-supervised software defect prediction methods. Copyright © 2016 John Wiley &amp; Sons, Ltd.},
journal = {Softw. Test. Verif. Reliab.},
month = nov,
pages = {498–515},
numpages = {18},
keywords = {ensemble learning, non-negative sparse based SemiBoost NSSB, semi-supervised learning, software defect prediction}
}

@inproceedings{10.4108/icst.bict.2014.257871,
author = {Malhotra, Ruchika and Raje, Rajeev},
title = {An empirical comparison of machine learning techniques for software defect prediction},
year = {2014},
isbn = {9781631900532},
publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
address = {Brussels, BEL},
url = {https://doi.org/10.4108/icst.bict.2014.257871},
doi = {10.4108/icst.bict.2014.257871},
abstract = {Software systems are exposed to various types of defects. The timely identification of defective classes is essential in early phases of software development to reduce the cost of testing the software. This will guide the software practitioners and researchers for planning of the proper allocation of testing resources. Software metrics can be used in conjunction with defect data to develop models for predicting defective classes. There have been various machine learning techniques proposed in the literature for analyzing complex relationships and extracting useful information from problems in less time. However, more studies comparing these techniques are needed to provide evidence so that confidence is established on the performance of one technique over the other. In this paper we address four issues (i) comparison of the machine learning techniques over unpopular used data sets (ii) use of inappropriate performance measures for measuring the performance of defect prediction models (iii) less use of statistical tests and (iv) validation of models from the same data set from which they are trained. To resolve these issues, in this paper, we compare 18 machine learning techniques for investigating the effect of Object-Oriented metrics on defective classes. The results are validated on six releases of the 'MMS' application package of recent widely used mobile operating system -- Android. The overall results of the study indicate the predictive capability of the machine learning techniques and an endorsement of one particular ML technique to predict defects.},
booktitle = {Proceedings of the 8th International Conference on Bioinspired Information and Communications Technologies},
pages = {320–327},
numpages = {8},
keywords = {object-oriented metrics, machine learning, empirical validation, defect prediction},
location = {Boston, Massachusetts},
series = {BICT '14}
}

@inproceedings{10.1145/3028842.3028858,
author = {Gao, Yan and Yang, Chunhui and Liang, Lixin},
title = {Pseudo-samples generation in Gaussian mixture distribution for software defect prediction},
year = {2016},
isbn = {9781450347990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3028842.3028858},
doi = {10.1145/3028842.3028858},
abstract = {In this paper, we present GCRF method based on pseudo-samples generation and conditional random field (CRF) for software defect prediction in Gaussian Mixture Distribution. In the proposed method, firstly, we leverage Gaussian Mixture Distribution (GMM) to generate pseudo-samples, which can increase the samples of minority class for balancing the train dataset. Secondly, we propose to apply CRF model in the balanced train dataset because the CRF model can handle complex features in nonlinear high dimensional subspace. Moreover, in order to avoid explicit modeling of the observed data, the proposed method can incorporate the classification of software defect data with different statistics characteristics into a unified probabilistic framework. Interestingly, the experiments show that the GCRF method achieves much better prediction performance than the other approach as shown in the software defect data classification task.},
booktitle = {Proceedings of the 1st International Conference on Intelligent Information Processing},
articleno = {16},
numpages = {6},
keywords = {software defect prediction, imbalance distribution, gaussian mixture distribution, conditional random field},
location = {Wuhan, China},
series = {ICIIP '16}
}

@inproceedings{10.1145/3382025.3414960,
author = {Str\"{u}der, Stefan and Mukelabai, Mukelabai and Str\"{u}ber, Daniel and Berger, Thorsten},
title = {Feature-oriented defect prediction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414960},
doi = {10.1145/3382025.3414960},
abstract = {Software errors are a major nuisance in software development and can lead not only to reputation damages, but also to considerable financial losses for companies. Therefore, numerous techniques for predicting software defects, largely based on machine learning methods, have been developed over the past decades. These techniques usually rely on code and process metrics in order to predict defects at the granularity of typical software assets, such as subsystems, components, and files. In this paper, we present the first systematic investigation of feature-oriented defect prediction: the prediction of defects at the granularity of features---domain-oriented entities abstractly representing (and often cross-cutting) typical software assets. Feature-oriented prediction can be beneficial, since: (i) particular features might be more error-prone than others, (ii) characteristics of features known as defective might be useful to predict other error-prone features, (iii) feature-specific code might be especially prone to faults arising from feature interactions. We present a dataset derived from 12 software projects and introduce two metric sets for feature-oriented defect prediction. We evaluated seven machine learning classifiers with three different attribute sets each, using our two new metric sets as well as an existing metric set from the literature. We observe precision and recall values of around 85% and better robustness when more diverse metrics sets with richer feature information are used.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {21},
numpages = {12},
keywords = {prediction, feature, defect, classification},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1007/978-3-030-87007-2_18,
author = {G\'{a}l, P\'{e}ter},
title = {Bug Prediction Capability of Primitive Enthusiasm Metrics},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_18},
doi = {10.1007/978-3-030-87007-2_18},
abstract = {Bugs in software development life cycle are unavoidable. Manually finding these bugs is not always the most effective way. To aid this, various bug prediction approaches which are using code metrics are developed and are also still in active development.In a previous work, the Primitive Enthusiasm code metrics were introduced to add detection capabilities for Primitive Obsession code smells. This paper explores the usability of the Primitive Enthusiasm metrics in a bug prediction scenario. To evaluate the new metrics, an existing source code bug data set was used. The correlation between existing metrics and the new PE metrics was investigated. Furthermore the effectiveness of bug prediction is investigated by building training models with and without the new metrics. Using a cross-project and a project version-based evaluation the results show that adding PE metrics can be beneficial for bug prediction.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {246–262},
numpages = {17},
keywords = {Static analysis, Primitive enthusiasm, Primitive obsession, Code metrics, Bug prediction},
location = {Cagliari, Italy}
}

@article{10.4018/IJOSSP.2018010101,
author = {Kakkar, Misha and Jain, Sarika and Bansal, Abhay and Grover, P.S.},
title = {Combining Data Preprocessing Methods With Imputation Techniques for Software Defect Prediction},
year = {2018},
issue_date = {January 2018},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {1},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2018010101},
doi = {10.4018/IJOSSP.2018010101},
abstract = {Software Defect Prediction SDP models are used to predict, whether software is clean or buggy using the historical data collected from various software repositories. The data collected from such repositories may contain some missing values. In order to estimate missing values, imputation techniques are used, which utilizes the complete observed values in the dataset. The objective of this study is to identify the best-suited imputation technique for handling missing values in SDP dataset. In addition to identifying the imputation technique, the authors have investigated for the most appropriate combination of imputation technique and data preprocessing method for building SDP model. In this study, four combinations of imputation technique and data preprocessing methods are examined using the improved NASA datasets. These combinations are used along with five different machine-learning algorithms to develop models. The performance of these SDP models are then compared using traditional performance indicators. Experiment results show that among different imputation techniques, linear regression gives the most accurate imputed value. The combination of linear regression with correlation based feature selector outperforms all other combinations. To validate the significance of data preprocessing methods with imputation the findings are applied to open source projects. It was concluded that the result is in consistency with the above conclusion.},
journal = {Int. J. Open Source Softw. Process.},
month = jan,
pages = {1–19},
numpages = {19},
keywords = {Software Defect Prediction, Missing Value Imputation, Instance Selection, Feature Selection}
}

@article{10.1007/s00607-016-0538-1,
author = {Gupta, Shivani and Gupta, Atul},
title = {A set of measures designed to identify overlapped instances in software defect prediction},
year = {2017},
issue_date = {September 2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {99},
number = {9},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-016-0538-1},
doi = {10.1007/s00607-016-0538-1},
abstract = {The performance of the learning models will intensely rely on the characteristics of the training data. The previous outcomes recommend that the overlapping between classes and the presence of noise have the most grounded impact on the performance of learning algorithm, and software defect datasets are no exceptions. The class overlap problem is concerned with the performance of machine learning classifiers critical problem is class overlap in which data samples appear as valid examples of more than one class which may be responsible for the presence of noise in datasets. We aim to investigate how the presence of overlapped instances in a dataset influences the classifier's performance, and how to deal with class overlapping problem. To have a close estimate of class overlapping, we have proposed four different measures namely, nearest enemy ratio, subconcept ratio, likelihood ratio and soft margin ratio. We performed our investigations using 327 binary defect classification datasets obtained from 54 software projects, where we first identified overlapped datasets using three data complexity measures proposed in the literature. We also include treatment effort into the prediction process. Subsequently, we used our proposed measures to find overlapped instances in the identified overlapped datasets. Our results indicated that by training a classifier on a training data free from overlapped instances led to an improved classifier performance on the test data containing overlapped instances. The classifiers perform significantly better when the evaluation measure takes the effort into account.},
journal = {Computing},
month = sep,
pages = {889–914},
numpages = {26},
keywords = {Software defect prediction, Machine learning, Data mining, Data complexity measures, Class overlapping}
}

@inproceedings{10.1145/3220267.3220286,
author = {El-Shorbagy, Sara Adel and El-Gammal, Wael Mohamed and Abdelmoez, Walid M.},
title = {Using SMOTE and Heterogeneous Stacking in Ensemble learning for Software Defect Prediction},
year = {2018},
isbn = {9781450364690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3220267.3220286},
doi = {10.1145/3220267.3220286},
abstract = {Nowadays, there are a lot of classifications models used for predictions in the software engineering field such as effort estimation and defect prediction. One of these models is the ensemble learning machine that improves model performance by combining multiple models in different ways to get a more powerful model.One of the problems facing the prediction model is the misclassification of the minority samples. This problem mainly appears in the case of defect prediction. Our aim is the classification of defects which are considered minority samples during the training phase. This can be improved by implementing the Synthetic Minority Over-Sampling Technique (SMOTE) before the implementation of the ensemble model which leads to over-sample the minority class instances.In this paper, our work propose applying a new ensemble model by combining the SMOTE technique with the heterogeneous stacking ensemble to get the most benefit and performance in training a dataset that focus on the minority subset as in the software prediction study. Our proposed model shows better performance that overcomes other techniques results applied on the minority samples of the defect prediction.},
booktitle = {Proceedings of the 7th International Conference on Software and Information Engineering},
pages = {44–47},
numpages = {4},
keywords = {Stacking, Software Engineering, SMOTE, Machine Learning, Heterogeneous, Ensemble, Defect Prediction, Classification},
location = {Cairo, Egypt},
series = {ICSIE '18}
}

@article{10.1049/sfw2.12012,
author = {Zou, Quanyi and Lu, Lu and Qiu, Shaojian and Gu, Xiaowei and Cai, Ziyi},
title = {Correlation feature and instance weights transfer learning for cross project software defect prediction},
year = {2021},
issue_date = {February 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {15},
number = {1},
url = {https://doi.org/10.1049/sfw2.12012},
doi = {10.1049/sfw2.12012},
abstract = {Due to the differentiation between training and testing data in the feature space, cross‐project defect prediction (CPDP) remains unaddressed within the field of traditional machine learning. Recently, transfer learning has become a research hot‐spot for building classifiers in the target domain using the data from the related source domains. To implement better CPDP models, recent studies focus on either feature transferring or instance transferring to weaken the impact of irrelevant cross‐project data. Instead, this work proposes a dual weighting mechanism to aid the learning process, considering both feature transferring and instance transferring. In our method, a local data gravitation between source and target domains determines instance weight, while features that are highly correlated with the learning task, uncorrelated with other features and minimizing the difference between the domains are rewarded with a higher feature weight. Experiments on 25 real‐world datasets indicate that the proposed approach outperforms the existing CPDP methods in most cases. By assigning weights based on the different contribution of features and instances to the predictor, the proposed approach is able to build a better CPDP model and demonstrates substantial improvements over the state‐of‐the‐art CPDP models.},
journal = {IET Software},
month = jan,
pages = {55–74},
numpages = {20},
keywords = {learning (artificial intelligence), pattern classification, software reliability}
}

@inproceedings{10.1145/2568225.2568320,
author = {Jing, Xiao-Yuan and Ying, Shi and Zhang, Zhi-Wu and Wu, Shan-Shan and Liu, Jin},
title = {Dictionary learning based software defect prediction},
year = {2014},
isbn = {9781450327565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568225.2568320},
doi = {10.1145/2568225.2568320},
abstract = {In order to improve the quality of a software system, software defect prediction aims to automatically identify defective software modules for efficient software test. To predict software defect, those classification methods with static code attributes have attracted a great deal of attention. In recent years, machine learning techniques have been applied to defect prediction. Due to the fact that there exists the similarity among different software modules, one software module can be approximately represented by a small proportion of other modules. And the representation coefficients over the pre-defined dictionary, which consists of historical software module data, are generally sparse. In this paper, we propose to use the dictionary learning technique to predict software defect. By using the characteristics of the metrics mined from the open source software, we learn multiple dictionaries (including defective module and defective-free module sub-dictionaries and the total dictionary) and sparse representation coefficients. Moreover, we take the misclassification cost issue into account because the misclassification of defective modules generally incurs much higher risk cost than that of defective-free ones. We thus propose a cost-sensitive discriminative dictionary learning (CDDL) approach for software defect classification and prediction. The widely used datasets from NASA projects are employed as test data to evaluate the performance of all compared methods. Experimental results show that CDDL outperforms several representative state-of-the-art defect prediction methods.},
booktitle = {Proceedings of the 36th International Conference on Software Engineering},
pages = {414–423},
numpages = {10},
keywords = {sparse representation, dictionary learning, cost-sensitive discriminative dictionary learning (CDDL), Software defect prediction},
location = {Hyderabad, India},
series = {ICSE 2014}
}

@article{10.1155/2021/5069016,
author = {Balogun, Abdullateef O. and Basri, Shuib and Mahamad, Saipunidzam and Capretz, Luiz Fernando and Imam, Abdullahi Abubakar and Almomani, Malek A. and Adeyemo, Victor E. and Kumar, Ganesh and Dourado, Ant\'{o}nio},
title = {A Novel Rank Aggregation-Based Hybrid Multifilter Wrapper Feature Selection Method in Software Defect Prediction},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/5069016},
doi = {10.1155/2021/5069016},
abstract = {The high dimensionality of software metric features has long been noted as a data quality problem that affects the performance of software defect prediction (SDP) models. This drawback makes it necessary to apply feature selection (FS) algorithm(s) in SDP processes. FS approaches can be categorized into three types, namely, filter FS (FFS), wrapper FS (WFS), and hybrid FS (HFS). HFS has been established as superior because it combines the strength of both FFS and WFS methods. However, selecting the most appropriate FFS (filter rank selection problem) for HFS is a challenge because the performance of FFS methods depends on the choice of datasets and classifiers. In addition, the local optima stagnation and high computational costs of WFS due to large search spaces are inherited by the HFS method. Therefore, as a solution, this study proposes a novel rank aggregation-based hybrid multifilter wrapper feature selection (RAHMFWFS) method for the selection of relevant and irredundant features from software defect datasets. The proposed RAHMFWFS is divided into two stepwise stages. The first stage involves a rank aggregation-based multifilter feature selection (RMFFS) method that addresses the filter rank selection problem by aggregating individual rank lists from multiple filter methods, using a novel rank aggregation method to generate a single, robust, and non-disjoint rank list. In the second stage, the aggregated ranked features are further preprocessed by an enhanced wrapper feature selection (EWFS) method based on a dynamic reranking strategy that is used to guide the feature subset selection process of the HFS method. This, in turn, reduces the number of evaluation cycles while amplifying or maintaining its prediction performance. The feasibility of the proposed RAHMFWFS was demonstrated on benchmarked software defect datasets with Na\"{\i}ve Bayes and Decision Tree classifiers, based on accuracy, the area under the curve (AUC), and F-measure values. The experimental results showed the effectiveness of RAHMFWFS in addressing filter rank selection and local optima stagnation problems in HFS, as well as the ability to select optimal features from SDP datasets while maintaining or enhancing the performance of SDP models. To conclude, the proposed RAHMFWFS achieved good performance by improving the prediction performances of SDP models across the selected datasets, compared to existing state-of-the-arts HFS methods.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {19}
}

@article{10.1155/2020/8852705,
author = {Zheng, Shang and Gai, Jinjing and Yu, Hualong and Zou, Haitao and Gao, Shang and Briola, Daniela},
title = {Software Defect Prediction Based on Fuzzy Weighted Extreme Learning Machine with Relative Density Information},
year = {2020},
issue_date = {2020},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2020},
issn = {1058-9244},
url = {https://doi.org/10.1155/2020/8852705},
doi = {10.1155/2020/8852705},
abstract = {To identify software modules that are more likely to be defective, machine learning has been used to construct software defect prediction (SDP) models. However, several previous works have found that the imbalanced nature of software defective data can decrease the model performance. In this paper, we discussed the issue of how to improve imbalanced data distribution in the context of SDP, which can benefit software defect prediction with the aim of finding better methods. Firstly, a relative density was introduced to reflect the significance of each instance within its class, which is irrelevant to the scale of data distribution in feature space; hence, it can be more robust than the absolute distance information. Secondly, a K-nearest-neighbors-based probability density estimation (KNN-PDE) alike strategy was utilised to calculate the relative density of each training instance. Furthermore, the fuzzy memberships of sample were designed based on relative density in order to eliminate classification error coming from noise and outlier samples. Finally, two algorithms were proposed to train software defect prediction models based on the weighted extreme learning machine. This paper compared the proposed algorithms with traditional SDP methods on the benchmark data sets. It was proved that the proposed methods have much better overall performance in terms of the measures including G-mean, AUC, and Balance. The proposed algorithms are more robust and adaptive for SDP data distribution types and can more accurately estimate the significance of each instance and assign the identical total fuzzy coefficients for two different classes without considering the impact of data scale.},
journal = {Sci. Program.},
month = jan,
numpages = {18}
}

@inproceedings{10.5555/3432601.3432618,
author = {Grigoriou, Marios-Stavros and Kontogiannis, Kostas and Giammaria, Alberto and Brealey, Chris},
title = {Report on evaluation experiments using different machine learning techniques for defect prediction},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {With the emergence of AI, it is of no surprise that the application of Machine Learning techniques has attracted the attention of numerous software maintenance groups around the world. For defect proneness classification in particular, the use of Machine Learning classifiers has been touted as a promising approach. As a consequence, a large volume of research works has been published in the related research literature, utilizing either proprietary data sets or the PROMISE data repository which, for the purposes of this study, focuses only on the use of source code metrics as defect prediction training features. It has been argued though by several researchers, that process metrics may provide a better option as training features than source code metrics. For this paper, we have conducted a detailed extraction of GitHub process metrics from 148 open source systems, and we report on the findings of experiments conducted by using different Machine Learning classification algorithms for defect proneness classification. The main purpose of the paper is not to propose yet another Machine Learning technique for defect proneness classification, but to present to the community a very large data set using process metrics as opposed to source code metrics, and draw some initial interesting conclusions from this statistically significant data set.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {123–132},
numpages = {10},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@inproceedings{10.1145/2591062.2591151,
author = {Jing, Xiao-Yuan and Zhang, Zhi-Wu and Ying, Shi and Wang, Feng and Zhu, Yang-Ping},
title = {Software defect prediction based on collaborative representation classification},
year = {2014},
isbn = {9781450327688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2591062.2591151},
doi = {10.1145/2591062.2591151},
abstract = {In recent years, machine learning techniques have been successfully applied into software defect prediction. Although they can yield reasonably good prediction results, there still exists much room for improvement on the aspect of prediction accuracy. Sparse representation is one of the most advanced machine learning techniques. It performs well with respect to signal compression and classification, but suffers from its time-consuming sparse coding. Compared with sparse representation, collaborative representation classification (CRC) can yield significantly lower computational complexity and competitive classification performance in pattern recognition domains. To achieve better defect prediction results, we introduce the CRC technique in this paper and propose a CRC based software defect prediction (CSDP) approach. We first design a CRC based learner to build a prediction model, whose computational burden is low. Then, we design a CRC based predictor to classify whether the query software modules are defective or defective-free. Experimental results on the widely used NASA datasets demonstrate the effectiveness and efficiency of the proposed approach.},
booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
pages = {632–633},
numpages = {2},
keywords = {Software defect prediction, Prediction model, Machine learning, Collaborative representation classification},
location = {Hyderabad, India},
series = {ICSE Companion 2014}
}

@article{10.1016/j.asoc.2017.01.050,
author = {Maua, Goran and Galinac Grbac, Tihana},
title = {Co-evolutionary multi-population genetic programming for classification in software defect prediction},
year = {2017},
issue_date = {June 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {55},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.01.050},
doi = {10.1016/j.asoc.2017.01.050},
abstract = {Evolving diverse ensembles using genetic programming has recently been proposed for classification problems with unbalanced data. Population diversity is crucial for evolving effective algorithms. Multilevel selection strategies that involve additional colonization and migration operations have shown better performance in some applications. Therefore, in this paper, we are interested in analysing the performance of evolving diverse ensembles using genetic programming for software defect prediction with unbalanced data by using different selection strategies. We use colonization and migration operators along with three ensemble selection strategies for the multi-objective evolutionary algorithm. We compare the performance of the operators for software defect prediction datasets with varying levels of data imbalance. Moreover, to generalize the results, gain a broader view and understand the underlying effects, we replicated the same experiments on UCI datasets, which are often used in the evolutionary computing community. The use of multilevel selection strategies provides reliable results with relatively fast convergence speeds and outperforms the other evolutionary algorithms that are often used in this research area and investigated in this paper. This paper also presented a promising ensemble strategy based on a simple convex hull approach and at the same time it raised the question whether ensemble strategy based on the whole population should also be investigated.},
journal = {Appl. Soft Comput.},
month = jun,
pages = {331–351},
numpages = {21},
keywords = {Software defect prediction, Genetic programming, Coevolution, Classification}
}

@inproceedings{10.1007/978-3-030-87007-2_14,
author = {Peng\H{o}, Edit},
title = {Examining the Bug Prediction Capabilities of Primitive Obsession Metrics},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_14},
doi = {10.1007/978-3-030-87007-2_14},
abstract = {Bug prediction is an approach that helps make bug detection more automated during software development. Based on a bug dataset a prediction model is built to locate future bugs. Bug datasets contain information about previous defects in the code, process metrics, or source code metrics, etc. As code smells can indicate potential flaws in the source code, they can be used for bug prediction as well.In our previous work, we introduced several source code metrics to detect and describe the occurrence of Primitive Obsession in Java. This paper is a further study on three of the Primitive Obsession metrics. We integrated them into an existing, source code metrics-based bug dataset, and studied the effectiveness of the prediction built upon it. We performed a 10 fold cross-validation on the whole dataset and a cross-project validation as well. We compared the new models with the results of the original dataset. While the cross-validation showed no significant change, in the case of the cross-project validation, we have found that the amount of improvement exceeded the amount of deterioration by 5%. Furthermore, the variance added to the dataset was confirmed by correlation and PCA calculations.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {185–200},
numpages = {16},
keywords = {Refactoring, Static analysis, Primitive obsession, Code smells, Bug prediction},
location = {Cagliari, Italy}
}

@article{10.1002/smr.2203,
author = {Ni, Chao and Chen, Xiang and Xia, Xin and Gu, Qing and Zhao, Yingquan},
title = {Multitask defect prediction},
year = {2019},
issue_date = {December 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {12},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2203},
doi = {10.1002/smr.2203},
abstract = {Within‐project defect prediction assumes that we have sufficient labeled data from the same project, while cross‐project defect prediction assumes that we have plenty of labeled data from source projects. However, in practice, we might only have limited labeled data from both the source and target projects in some scenarios. In this paper, we want to apply multitask learning to investigate such a new scenario. To our best knowledge, this problem (ie, both the source project and the target project have limited labeled data) has not been thoroughly investigated, and we are the first to propose a novel multitask defect prediction approach mask. mask consists of a differential evolution optimization phase and a multitask learning phase. The former phase aims to find optimal weights for shared and nonshared information in related projects (ie, the target project and its related source projects), while the latter phase builds prediction models for each project simultaneously. To verify the effectiveness of mask, we perform experimental studies on 18 real‐world software projects and compare our approach with four state‐of‐the‐art baseline approaches: single‐task learning (STL), simple combined learning (SCL), Peters filter, and Burak filter. Experimental results show that mask can achieve F1 of 0.397 and AUC of 0.608 on average with a few labeled data (ie, 10% of data). Across the 18 projects, mask can outperform baseline methods significantly in terms of F1 and AUC. Therefore, by utilizing the relatedness among multiple projects, mask can perform significantly better than the state‐of‐the‐art methods. The results confirm that mask is promising for software defect prediction when the source and target projects both have limited training data.We propose a new usage scenario for software defect prediction in which both the source and target projects have limited training data and provide a novel approach named Mask to solve the issue. We conduct empirical studies to demonstrate the effectiveness of Mask and find that Mask can achieve a substantial improvement over classical baseline approaches.


image
image},
journal = {J. Softw. Evol. Process},
month = dec,
numpages = {18},
keywords = {differential evolution, empirical studies, multitask learning, software defect prediction}
}

@article{10.1016/j.asoc.2017.05.043,
author = {Arar, mer Faruk and Ayan, Krat},
title = {A feature dependent Naive Bayes approach and its application to the software defect prediction problem},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {59},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.05.043},
doi = {10.1016/j.asoc.2017.05.043},
abstract = {Display Omitted In Naive Bayes, features are assumed to be independent and have equal weight. But, In practice, features are interrelated.In this study, features are included for calculation as pairs using the proposed Feature Dependent Naive Bayes (FDNB) method.Eight data sets from the NASA PROMISE repository were used for the software defect prediction problem.Results were compared with other modified NBs. Increased classification performance was found after use of the proposed FDNB. Naive Bayes is one of the most widely used algorithms in classification problems because of its simplicity, effectiveness, and robustness. It is suitable for many learning scenarios, such as image classification, fraud detection, web mining, and text classification. Naive Bayes is a probabilistic approach based on assumptions that features are independent of each other and that their weights are equally important. However, in practice, features may be interrelated. In that case, such assumptions may cause a dramatic decrease in performance. In this study, by following preprocessing steps, a Feature Dependent Naive Bayes (FDNB) classification method is proposed. Features are included for calculation as pairs to create dependence between one another. This method was applied to the software defect prediction problem and experiments were carried out using widely recognized NASA PROMISE data sets. The obtained results show that this new method is more successful than the standard Naive Bayes approach and that it has a competitive performance with other feature-weighting techniques. A further aim of this study is to demonstrate that to be reliable, a learning model must be constructed by using only training data, as otherwise misleading results arise from the use of the entire data set.},
journal = {Appl. Soft Comput.},
month = oct,
pages = {197–209},
numpages = {13},
keywords = {Software defect prediction, Naive Bayes, Feature independence, Discretization, Data mining}
}

@proceedings{10.1145/3472674,
title = {MaLTESQuE 2021: Proceedings of the 5th International Workshop on Machine Learning Techniques for Software Quality Evolution},
year = {2021},
isbn = {9781450386258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the fifth edition of the workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE 2021) to be held virtually on August 23, 2021, co-located with the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2021).},
location = {Athens, Greece}
}

@inproceedings{10.1145/3239576.3239607,
author = {Du, Yuntao and Zhang, Lu and Shi, Jiahao and Tang, Jingjuan and Yin, Ying},
title = {Feature-Grouping-Based Two Steps Feature Selection Algorithm in Software Defect Prediction},
year = {2018},
isbn = {9781450364607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239576.3239607},
doi = {10.1145/3239576.3239607},
abstract = {In order to improve the effect of software defect prediction, many algorithms including feature selection, have been proposed. Based on Wrapper and Filter hybrid framework, a feature-grouping-based feature selection algorithm is proposed in this paper. The algorithm is composed of two steps. In the first step, in order to remove the redundant features, we group the features according to the redundancy between the features. The symmetry uncertainty is used as the constant indicator of the correlation and the FCBF-based grouping algorithm is used to group the features. In the second step, a subset of the features are selected from each group to form the final subset of features. Many classical methods select the representative feature from each group. We consider that when the number of intra-group features is large, the representative features are not enough to reflect the information in this group. Therefore, we require that at least one feature be selected within each group, in this step, the PSO algorithm is used for Searching Randomly from each group. We tested on the open source NASA and PROMISE data sets. Using three kinds of classifier. Compared to the other methods tested in this article, our method resulted in 90% improvement in the predictive performance of 30 sets of results on 10 data sets. Compared with the algorithms without feature selection, the AUC values of this method in the Logistic regression, Naive Bayesian, and K-neighbor classifiers are improved by 5.94% and 4.69% And 8.05%. The FCBF algorithm can also be regarded as a kind of first performing feature grouping. Compared with the FCBF algorithm, the AUC values of this method are improved by 4.78%, 6.41% and 4.4% on the basis of Logistic regression, Naive Bayes and K-neighbor. We can also see that for the FCBF-based grouping algorithm, it could be better to choose a characteristic cloud from each group than to choose a representative one.},
booktitle = {Proceedings of the 2nd International Conference on Advances in Image Processing},
pages = {173–178},
numpages = {6},
keywords = {Software defect prediction, PSO, Intra-group feature selection, Feature grouping, FCBF-based grouping algorithm},
location = {Chengdu, China},
series = {ICAIP '18}
}

@article{10.1007/s00500-018-3546-6,
author = {Khuat, Thanh Tung and Le, My Hanh},
title = {Binary teaching–learning-based optimization algorithm with a new update mechanism for sample subset optimization in software defect prediction},
year = {2019},
issue_date = {Oct 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {20},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-018-3546-6},
doi = {10.1007/s00500-018-3546-6},
abstract = {Software defect prediction has gained considerable attention in recent years. A broad range of computational methods has been developed for accurate prediction of faulty modules based on code and design metrics. One of the challenges in training classifiers is the highly imbalanced class distribution in available datasets, leading to an undesirable bias in the prediction performance for the minority class. Data sampling is a widespread technique to tackle this problem. However, traditional sampling methods, which depend mainly on random resampling from a given dataset, do not take advantage of useful information available in training sets, such as sample quality and representative instances. To cope with this limitation, evolutionary undersampling methods are usually used for identifying an optimal sample subset for the training dataset. This paper proposes a binary teaching–learning- based optimization algorithm employing a distribution-based solution update rule, namely BTLBOd, to generate a balanced subset of highly valuable examples. This subset is then applied to train a classifier for reliable prediction of potentially defective modules in a software system. Each individual in BTLBOd includes two vectors: a real-valued vector generated by the distribution-based update mechanism, and a binary vector produced from the corresponding real vector by a proposed mapping function. Empirical results showed that the optimal sample subset produced by BTLBOd might ameliorate the classification accuracy of the predictor on highly imbalanced software defect data. Obtained results also demonstrated the superior performance of the proposed sampling method compared to other popular sampling techniques.},
journal = {Soft Comput.},
month = oct,
pages = {9919–9935},
numpages = {17},
keywords = {Software defect prediction, Imbalanced learning, Sample subset optimization, Distribution-based update, Binary teaching–learning-based optimization, Teaching–learning-based optimization}
}

@article{10.1016/j.jss.2019.110402,
author = {Xu, Zhou and Li, Shuai and Xu, Jun and Liu, Jin and Luo, Xiapu and Zhang, Yifeng and Zhang, Tao and Keung, Jacky and Tang, Yutian},
title = {LDFR: Learning deep feature representation for software defect prediction},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {158},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110402},
doi = {10.1016/j.jss.2019.110402},
journal = {J. Syst. Softw.},
month = dec,
numpages = {20},
keywords = {99-00, 00-01, Deep neural network, Weighted cross-entropy loss, Triplet loss, Deep feature representation, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-91452-3_12,
author = {Amasaki, Sousuke and Aman, Hirohisa and Yokogawa, Tomoyuki},
title = {Searching for Bellwether Developers for Cross-Personalized Defect Prediction},
year = {2021},
isbn = {978-3-030-91451-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-91452-3_12},
doi = {10.1007/978-3-030-91452-3_12},
abstract = {Context: Recent progress in the use of commit data for software defect prediction has driven research on personalized defect prediction. An idea applying one personalized model to another developer came in for seeking an alternative model predicting better than one’s own model. A question arose whether such exemplary developer (bellwether) existed as observed in traditional defect prediction. Objective: To investigate whether bellwether developers existed and how they behaved. Method: Experiments were conducted on 9 OSS projects. Models based on active developers in a project were compared with each other to seek bellwethers, whose models beaten models of the other active developers. Their performance was evaluated with new unseen data from the other active developers and the remaining non-active developers. Results: Bellwether developers were identified in all nine projects. Their performance on new unseen data from the other active developers was not higher than models learned by those developers. The bellwether was only a practical choice for the non-active developers. Conclusion: Bellwethers were a useful prediction model for the non-active developers but not for the other active developers.},
booktitle = {Product-Focused Software Process Improvement: 22nd International Conference, PROFES 2021, Turin, Italy, November 26, 2021, Proceedings},
pages = {183–198},
numpages = {16},
keywords = {Bellwether effect, Transfer learning, Personalized defect prediction},
location = {Turin, Italy}
}

@inproceedings{10.1145/2351676.2351734,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {Software defect prediction using semi-supervised learning with dimension reduction},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2351676.2351734},
doi = {10.1145/2351676.2351734},
abstract = {Accurate detection of fault prone modules offers the path to high quality software products while minimizing non essential assurance expenditures. This type of quality modeling requires the availability of software modules with known fault content developed in similar environment. Establishing whether a module contains a fault or not can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics. Our results show that the semi-supervised learning algorithm with dimension-reduction preforms significantly better than one of the best performing supervised learning algorithms, random forest, in situations when few modules with known fault content are available for training.},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {314–317},
numpages = {4},
keywords = {software metrics, semi-supervised learning, dimension reduction, Software fault prediction},
location = {Essen, Germany},
series = {ASE '12}
}

@article{10.1016/j.knosys.2015.10.009,
author = {Rana, Zeeshan Ali and Mian, M. Awais and Shamail, Shafay},
title = {Improving Recall of software defect prediction models using association mining},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {90},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2015.10.009},
doi = {10.1016/j.knosys.2015.10.009},
abstract = {Use of software product metrics in defect prediction studies highlights the utility of these metrics. Public availability of software defect data based on the product metrics has resulted in the development of defect prediction models. These models experience a limitation in learning Defect-prone (D) modules because the available datasets are imbalanced. Most of the datasets are dominated by Not Defect-prone (ND) modules as compared to D modules. This affects the ability of classification models to learn the D modules more accurately. This paper presents an association mining based approach that allows the defect prediction models to learn D modules in imbalanced datasets. The proposed algorithm preprocesses data by setting specific metric values as missing and improves the prediction of D modules. The proposed algorithm has been evaluated using 5 public datasets. A Naive Bayes (NB) classifier has been developed before and after the proposed preprocessing. It has been shown that Recall of the classifier after the proposed preprocessing has improved. Stability of the approach has been tested by experimenting the algorithm with different number of bins. The results show that the algorithm has resulted in up to 40% performance gain.},
journal = {Know.-Based Syst.},
month = dec,
pages = {1–13},
numpages = {13},
keywords = {Software defect prediction, PROMISE repository, Naive Bayes, Improving Recall, Imbalanced data, Association mining}
}

@article{10.1007/s10664-021-09984-2,
author = {Ulan, Maria and L\"{o}we, Welf and Ericsson, Morgan and Wingkvist, Anna},
title = {Weighted software metrics aggregation and its application to defect prediction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09984-2},
doi = {10.1007/s10664-021-09984-2},
abstract = {It is a well-known practice in software engineering to aggregate software metrics to assess software artifacts for various purposes, such as their maintainability or their proneness to contain bugs. For different purposes, different metrics might be relevant. However, weighting these software metrics according to their contribution to the respective purpose is a challenging task. Manual approaches based on experts do not scale with the number of metrics. Also, experts get confused if the metrics are not independent, which is rarely the case. Automated approaches based on supervised learning require reliable and generalizable training data, a ground truth, which is rarely available. We propose an automated approach to weighted metrics aggregation that is based on unsupervised learning. It sets metrics scores and their weights based on probability theory and aggregates them. To evaluate the effectiveness, we conducted two empirical studies on defect prediction, one on ca. 200 000 code changes, and another ca. 5 000 software classes. The results show that our approach can be used as an agnostic unsupervised predictor in the absence of a ground truth.},
journal = {Empirical Softw. Engg.},
month = sep,
numpages = {34},
keywords = {Weighting, Aggregation, Software metrics, Defect prediction, Quantitative methods, Software assessment}
}

@article{10.1007/s11219-020-09538-7,
author = {Eken, Beyza and Palma, Francis and Ay\c{s}e, Ba\c{s}ar and Ay\c{s}e, Tosun},
title = {An empirical study on the effect of community smells on bug prediction},
year = {2021},
issue_date = {Mar 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09538-7},
doi = {10.1007/s11219-020-09538-7},
abstract = {Community-aware metrics through socio-technical developer networks or organizational structures have already been studied in the&nbsp;software bug prediction field. Community smells are also proposed to identify communication and collaboration patterns in developer communities. Prior work reports a statistical association between community smells and code smells identified in software modules. We investigate the contribution of community smells on predicting bug-prone classes and compare their contribution with that of code smell-related information and state-of-the-art process metrics. We conduct our empirical analysis on ten open-source projects with varying sizes, buggy and smelly class ratios. We build seven different bug prediction models to answer three RQs: a baseline model including a state-of-the-art metric set used, three models incorporating a particular metric set, namely community smells, code smells, code smell intensity, into the baseline, and three models incorporating a combination of smell-related metrics into the baseline. The performance of these models is reported in terms of recall, false positive rates, F-measure and AUC and statistically compared using Scott–Knott ESD tests. Community smells improve the prediction performance of a baseline model by up to 3% in terms of AUC, while code smell intensity improves the baseline models by up to 40% in terms of F-measure and up to 17% in terms of AUC. The conclusions are significantly influenced by the validation strategies used, algorithms and the selected projects’ data characteristics. While the code smell intensity metric captures the most information about technical flaws in predicting bug-prone classes, the community smells also contribute to bug prediction models by revealing communication and collaboration flaws in software development teams. Future research is needed to capture the communication patterns through multiple channels and to understand whether socio-technical flaws could be used in a cross-project bug prediction setting.},
journal = {Software Quality Journal},
month = mar,
pages = {159–194},
numpages = {36},
keywords = {Mining software repositories, Bug prediction, Community smells}
}

@inproceedings{10.1145/2810146.2810150,
author = {Mahmood, Zaheed and Bowes, David and Lane, Peter C. R. and Hall, Tracy},
title = {What is the Impact of Imbalance on Software Defect Prediction Performance?},
year = {2015},
isbn = {9781450337151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2810146.2810150},
doi = {10.1145/2810146.2810150},
abstract = {Software defect prediction performance varies over a large range. Menzies suggested there is a ceiling effect of 80% Recall [8]. Most of the data sets used are highly imbalanced. This paper asks, what is the empirical effect of using different datasets with varying levels of imbalance on predictive performance? We use data synthesised by a previous meta-analysis of 600 fault prediction models and their results. Four model evaluation measures (the Mathews Correlation Coefficient (MCC), F-Measure, Precision and Recall) are compared to the corresponding data imbalance ratio. When the data are imbalanced, the predictive performance of software defect prediction studies is low. As the data become more balanced, the predictive performance of prediction models increases, from an average MCC of 0.15, until the minority class makes up 20% of the instances in the dataset, where the MCC reaches an average value of about 0.34. As the proportion of the minority class increases above 20%, the predictive performance does not significantly increase. Using datasets with more than 20% of the instances being defective has not had a significant impact on the predictive performance when using MCC. We conclude that comparing the results of defect prediction studies should take into account the imbalance of the data.},
booktitle = {Proceedings of the 11th International Conference on Predictive Models and Data Analytics in Software Engineering},
articleno = {4},
numpages = {4},
keywords = {Data Imbalance, Defect Prediction, Machine Learning},
location = {Beijing, China},
series = {PROMISE '15}
}

@inproceedings{10.1109/MSR.2019.00017,
author = {Dam, Hoa Khanh and Pham, Trang and Ng, Shien Wee and Tran, Truyen and Grundy, John and Ghose, Aditya and Kim, Taeksu and Kim, Chul-Joo},
title = {Lessons learned from using a deep tree-based model for software defect prediction in practice},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00017},
doi = {10.1109/MSR.2019.00017},
abstract = {Defects are common in software systems and cause many problems for software users. Different methods have been developed to make early prediction about the most likely defective modules in large codebases. Most focus on designing features (e.g. complexity metrics) that correlate with potentially defective code. Those approaches however do not sufficiently capture the syntax and multiple levels of semantics of source code, a potentially important capability for building accurate prediction models. In this paper, we report on our experience of deploying a new deep learning tree-based defect prediction model in practice. This model is built upon the tree-structured Long Short Term Memory network which directly matches with the Abstract Syntax Tree representation of source code. We discuss a number of lessons learned from developing the model and evaluating it on two datasets, one from open source projects contributed by our industry partner Samsung and the other from the public PROMISE repository.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {46–57},
numpages = {12},
keywords = {defect prediction, deep learning},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/3400934.3400950,
author = {Qosim, Helmi and Zulkarnain},
title = {Fault Detection System Using Machine Learning on Synthesis Loop Ammonia Plant},
year = {2020},
isbn = {9781450376006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3400934.3400950},
doi = {10.1145/3400934.3400950},
abstract = {Synthesis loop is one of the critical systems in ammonia plant. Therefore, there is urgency for maintaining the reliability and availability of this system. Most of the shutdown events occur suddenly after the alarm is reached. So, there needs to be an early detection system to ensure anomaly problem captured by the operator before touching the alarm settings. The implementation of machine learning algorithms in making fault detection models has been used in various industries and objects. The algorithm used is the basic and ensemble classifier to compare which algorithms generate the best classification results. This research can provide a new idea and perspective into ammonia plant industry to prevent unscheduled shutdown by utilizing data using machine learning algorithm.},
booktitle = {Proceedings of the 3rd Asia Pacific Conference on Research in Industrial and Systems Engineering},
pages = {74–80},
numpages = {7},
keywords = {Machine Learning, Fault Detection, Classification, Ammonia Plant},
location = {Depok, Indonesia},
series = {APCORISE '20}
}

@article{10.1007/s00521-021-05892-0,
author = {Rajakumar, M. P. and Ramya, J. and Maheswari, B. Uma},
title = {Health monitoring and fault prediction using a lightweight deep convolutional neural network optimized by Levy flight optimization algorithm},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {19},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05892-0},
doi = {10.1007/s00521-021-05892-0},
abstract = {Agricultural machines (AMs) refer to equipment usually used in agriculture such as tractors, hand tools, and power tools. It reduces the labor work, increases farms produce, enhances goods quality, and reduces farming time and cost-saving. However, the faults in the fuel system, blades, engine of the AM will often result in degraded vehicle performance, compromising the vehicle’s efficiency and strength. To overcome these problems, fault detection algorithms are developed to identify the faults even before they occur with high classification accuracy. The deep convolutional neural network (DCNN) is a popular deep learning model that offers a high classification recognition rate, and it is widely adopted in similar fields for monitoring the health status of machines. Very few state-of-the-art works are available to identify the health state of agricultural machines using deep learning techniques and extracting the acoustic features from an audio recording. The acoustic signal-based agricultural machine health monitoring and fault prediction model using smartphones is a cost-effective option that is deployed in this proposed work. To optimize the network structure of the DCNN, this paper proposes a Levy flight optimization algorithm (LFOA). The DCNN-LFOA model is implemented on the smartphone’s on-board device (OBD) along with the health monitoring application. The LFOA algorithm minimizes the number of neurons in the DCNN hidden layer and the number of input features from the audio recordings and enhances the classification accuracy. The LFOA algorithm provides the optimal solution which is essential in developing a lightweight DCNN model to implement in the edge processor (smartphone). The experimental results prove that the proposed model gives improved accuracy for the six faults to be classified and serves as a new research model to identify the health condition of the vehicles.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {12513–12534},
numpages = {22},
keywords = {Agricultural vehicles, Convolutional neural network, Levy flight optimization algorithm, Fault detection, Short-term audio signals}
}

@inproceedings{10.1007/978-3-030-78609-0_28,
author = {Sun, Ying and Sun, Yanfei and Wu, Fei and Jing, Xiao-Yuan},
title = {Deep Adversarial Learning Based Heterogeneous Defect Prediction},
year = {2021},
isbn = {978-3-030-78608-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78609-0_28},
doi = {10.1007/978-3-030-78609-0_28},
abstract = {Cross-project defect prediction (CPDP) is a hot study that predicts defects in the new project by utilizing the model trained on the data from other projects. However, existing CPDP methods usually assume that source and target projects have the same metrics. Heterogeneous defect prediction (HDP) is proposed and has attracted increasing attention, which refers to the metric sets from source and target projects are different in CPDP. HDP conducts prediction model using the instances with heterogeneous metrics from external projects and then use this model to predict defect-prone software instances in source project. However, building HDP methods is challenging including the distribution difference between source and target projects with heterogeneous metrics. In this paper, we propose a Deep adversarial learning based HDP (DHDP) approach. DHDP leverages deep neural network to learn nonlinear transformation for each project to obtain common feature represent, which the heterogeneous data from different projects can be compared directly. DHDP consists of two parts: a discriminator and a classifier that compete with each other. A classifier tries to minimize the similarity across classes and maximize the inter-class similarity. A discriminator tries to distinguish the source of instances that is source or target project on the common feature space. Expensive experiments are performed on 10 public projects from two datasets in terms of F-measure and G-measure. The experimental results show that DHDP gains superior prediction performance improvement compared to a range of competing methods.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part I},
pages = {326–337},
numpages = {12},
keywords = {Heterogeneous defect prediction, Metric learning, Adversarial learning},
location = {Dublin, Ireland}
}

@article{10.1016/j.asoc.2020.106686,
author = {Haouari, Ahmed Taha and Souici-Meslati, Labiba and Atil, Fadila and Meslati, Djamel},
title = {Empirical comparison and evaluation of Artificial Immune Systems in inter-release software fault prediction},
year = {2020},
issue_date = {Nov 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {96},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.106686},
doi = {10.1016/j.asoc.2020.106686},
journal = {Appl. Soft Comput.},
month = nov,
numpages = {18},
keywords = {Neural Network, Artificial Immune Recognition System, Inter-projects fault prediction, Software defect prediction, Artificial Immune Systems}
}

@inproceedings{10.1145/3368089.3417062,
author = {Suh, Alexander},
title = {Adapting bug prediction models to predict reverted commits at Wayfair},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3417062},
doi = {10.1145/3368089.3417062},
abstract = {Researchers have proposed many algorithms to predict software bugs. Given a software entity (e.g., a file or method), these algorithms predict whether the entity is bug-prone. However, since these algorithms cannot identify specific bugs, this does not tend to be particularly useful in practice. In this work, we adapt this prior work to the related problem of predicting whether a commit is likely to be reverted. Given the batch nature of continuous integration deployment at scale, this allows developers to find time-sensitive bugs in production more quickly. The models in this paper are based on features extracted from the revision history of a codebase that are typically used in bug prediction. Our experiments, performed on the three main repositories for the Wayfair website, show that our models can rank reverted commits above 80% of non-reverted commits on average. Moreover, when given to Wayfair developers, our models reduce the amount of time needed to find certain kinds of bugs by 55%. Wayfair continues to use our findings and models today to help find bugs during software deployments.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1251–1262},
numpages = {12},
keywords = {software deployment, software defect prediction, reverted commits},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1007/s10845-018-1431-x,
author = {Wang, Tian and Qiao, Meina and Zhang, Mengyi and Yang, Yi and Snoussi, Hichem},
title = {Data-driven prognostic method based on self-supervised learning approaches for fault detection},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {31},
number = {7},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-018-1431-x},
doi = {10.1007/s10845-018-1431-x},
abstract = {As a part of prognostics and health management (PHM), fault detection has been used in many fields to improve the reliability of the system and reduce the manufacturing costs. Due to the complexity of the system and the richness of the sensors, fault detection still faces some challenges. In this paper, we propose a data-driven method in a self-supervised manner, which is different from previous prognostic methods. In our algorithm, we first extract feature indices of each batch and concatenate them into one feature vector. Then the principal components are extracted by Kernel PCA. Finally, the fault is detected by the reconstruction error in the feature space. Samples with high reconstruction error are identified as faulty. To demonstrate the effectiveness of the proposed algorithm, we evaluate our algorithm on a benchmark dataset for fault detection, and the results show that our algorithm outperforms other fault detection methods.},
journal = {J. Intell. Manuf.},
month = oct,
pages = {1611–1619},
numpages = {9},
keywords = {Fault detection, Self-supervised, Kernel PCA, Prognostics and health management}
}

@article{10.1016/j.asoc.2021.107870,
author = {Kabir, Md Alamgir and Keung, Jacky and Turhan, Burak and Bennin, Kwabena Ebo},
title = {Inter-release defect prediction with feature selection using temporal chunk-based learning: An empirical study},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {113},
number = {PA},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107870},
doi = {10.1016/j.asoc.2021.107870},
journal = {Appl. Soft Comput.},
month = dec,
numpages = {17},
keywords = {Feature selection, Inter-release defect prediction, Software defect prediction}
}

@inproceedings{10.1145/2961111.2962610,
author = {Petri\'{c}, Jean and Bowes, David and Hall, Tracy and Christianson, Bruce and Baddoo, Nathan},
title = {Building an Ensemble for Software Defect Prediction Based on Diversity Selection},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962610},
doi = {10.1145/2961111.2962610},
abstract = {Background: Ensemble techniques have gained attention in various scientific fields. Defect prediction researchers have investigated many state-of-the-art ensemble models and concluded that in many cases these outperform standard single classifier techniques. Almost all previous work using ensemble techniques in defect prediction rely on the majority voting scheme for combining prediction outputs, and on the implicit diversity among single classifiers. Aim: Investigate whether defect prediction can be improved using an explicit diversity technique with stacking ensemble, given the fact that different classifiers identify different sets of defects. Method: We used classifiers from four different families and the weighted accuracy diversity (WAD) technique to exploit diversity amongst classifiers. To combine individual predictions, we used the stacking ensemble technique. We used state-of-the-art knowledge in software defect prediction to build our ensemble models, and tested their prediction abilities against 8 publicly available data sets. Conclusion: The results show performance improvement using stacking ensembles compared to other defect prediction models. Diversity amongst classifiers used for building ensembles is essential to achieving these performance improvements.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {46},
numpages = {10},
keywords = {stacking, software faults, ensembles of learning machines, diversity, Software defect prediction},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@inproceedings{10.1145/3377812.3381403,
author = {Sohn, Jeongju},
title = {Bridging fault localisation and defect prediction},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3381403},
doi = {10.1145/3377812.3381403},
abstract = {Identifying the source of a program failure plays an integral role in maintaining software quality. Both fault localisation and defect prediction aim to locate faults: fault localisation aims to locate faults after they are revealed while defect prediction aims to locate yet-to-happen faults. Despite sharing a similar goal, fault localisation and defect prediction have been studied as separate topics, mainly due to the difference in available data to exploit. In our doctoral research, we aim to bridge fault localisation and defect prediction. Our work is divided into three parts: 1) applying defect prediction to fault localisation, i.e., DP2FL, 2) applying fault localisation to defect prediction, i.e., FL2DP, 3) consecutive application of DP2FL and FL2DP in a single framework. We expect the synergy between fault localisation and defect prediction not only to improve the accuracy of each process but to allow us to build a single model that gradually improve the overall software quality throughout the entire software development life-cycle.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {214–217},
numpages = {4},
keywords = {fault localisation, defect prediction, SBSE},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1016/j.jss.2016.09.001,
author = {Andreou, Andreas S. and Chatzis, Sotirios P.},
title = {Software defect prediction using doubly stochastic Poisson processes driven by stochastic belief networks},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.09.001},
doi = {10.1016/j.jss.2016.09.001},
abstract = {This research aims at better addressing the challenges related with software defect prediction.We develop a novel Bayesian inference approach driven from appropriate metrics.Formulation of our method is based on a doubly stochastic homogeneous Poisson process.Our model better learns from data with multiple modes in their distributions.We evaluate generalization across software classes, subsequent releases, and projects. Accurate prediction of software defects is of crucial importance in software engineering. Software defect prediction comprises two major procedures: (i) Design of appropriate software metrics to represent characteristic software system properties; and (ii) development of effective regression models for count data, allowing for accurate prediction of the number of software defects. Although significant research effort has been devoted to software metrics design, research in count data regression has been rather limited. More specifically, most used methods have not been explicitly designed to tackle the problem of metrics-driven software defect counts prediction, thus postulating irrelevant assumptions, such as (log-)linearity of the modeled data. In addition, a lack of simple and efficient algorithms for posterior computation has made more elaborate hierarchical Bayesian approaches appear unattractive in the context of software defect prediction. To address these issues, in this paper we introduce a doubly stochastic Poisson process for count data regression, the failure log-rate of which is driven by a novel latent space stochastic feedforward neural network. Our approach yields simple and efficient updates for its complicated conditional distributions by means of sampling importance resampling and error backpropagation. We exhibit the efficacy of our approach using publicly available and benchmark datasets.},
journal = {J. Syst. Softw.},
month = dec,
pages = {72–82},
numpages = {11},
keywords = {Stochastic belief network, Software defect prediction, Sampling importance resampling, Doubly stochastic Poisson process}
}

@article{10.1016/j.ins.2013.12.031,
author = {Czibula, Gabriela and Marian, Zsuzsanna and Czibula, Istvan Gergely},
title = {Software defect prediction using relational association rule mining},
year = {2014},
issue_date = {April, 2014},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {264},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2013.12.031},
doi = {10.1016/j.ins.2013.12.031},
abstract = {This paper focuses on the problem of defect prediction, a problem of major importance during software maintenance and evolution. It is essential for software developers to identify defective software modules in order to continuously improve the quality of a software system. As the conditions for a software module to have defects are hard to identify, machine learning based classification models are still developed to approach the problem of defect prediction. We propose a novel classification model based on relational association rules mining. Relational association rules are an extension of ordinal association rules, which are a particular type of association rules that describe numerical orderings between attributes that commonly occur over a dataset. Our classifier is based on the discovery of relational association rules for predicting whether a software module is or it is not defective. An experimental evaluation of the proposed model on the open source NASA datasets, as well as a comparison to similar existing approaches is provided. The obtained results show that our classifier overperforms, for most of the considered evaluation measures, the existing machine learning based techniques for defect prediction. This confirms the potential of our proposal.},
journal = {Inf. Sci.},
month = apr,
pages = {260–278},
numpages = {19},
keywords = {Software engineering, Defect prediction, Data mining, Association rule}
}

@article{10.1049/iet-sen.2019.0278,
author = {Zhu, Kun and Zhang, Nana and Ying, Shi and Zhu, Dandan},
title = {Within‐project and cross‐project just‐in‐time defect prediction based on denoising autoencoder and convolutional neural network},
year = {2020},
issue_date = {June 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {3},
url = {https://doi.org/10.1049/iet-sen.2019.0278},
doi = {10.1049/iet-sen.2019.0278},
abstract = {Just‐in‐time defect prediction is an important and useful branch in software defect prediction. At present, deep learning is a research hotspot in the field of artificial intelligence, which can combine basic defect features into deep semantic features and make up for the shortcomings of machine learning algorithms. However, the mainstream deep learning techniques have not been applied yet in just‐in‐time defect prediction. Therefore, the authors propose a novel just‐in‐time defect prediction model named DAECNN‐JDP based on denoising autoencoder and convolutional neural network in this study, which has three main advantages: (i) Different weights for the position vector of each dimension feature are set, which can be automatically trained by adaptive trainable vector. (ii) Through the training of denoising autoencoder, the input features that are not contaminated by noise can be obtained, thus learning more robust feature representation. (iii) The authors leverage a powerful representation‐learning technique, convolution neural network, to construct the basic change features into the abstract deep semantic features. To evaluate the performance of the DAECNN‐JDP model, they conduct extensive within‐project and cross‐project defect prediction experiments on six large open source projects. The experimental results demonstrate that the superiority of DAECNN‐JDP on five evaluation metrics.},
journal = {IET Software},
month = jun,
pages = {185–195},
numpages = {18},
keywords = {neural nets, learning (artificial intelligence), denoising autoencoder, software defect prediction, basic defect features, mainstream deep learning techniques, just-in-time defect prediction model, autoencoder convolutional neural network, convolution neural network, cross-project defect prediction experiments}
}

@article{10.1016/j.neunet.2019.05.022,
author = {Zhao, Haitao and Lai, Zhihui and Chen, Yudong},
title = {Global-and-local-structure-based neural network for fault detection},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {118},
number = {C},
issn = {0893-6080},
url = {https://doi.org/10.1016/j.neunet.2019.05.022},
doi = {10.1016/j.neunet.2019.05.022},
journal = {Neural Netw.},
month = oct,
pages = {43–53},
numpages = {11},
keywords = {Dimension reduction, Principal component analysis, Feedforward neural network, Fault detection, Statistical process monitoring}
}

@inproceedings{10.1145/3460319.3464819,
author = {Zeng, Zhengran and Zhang, Yuqun and Zhang, Haotian and Zhang, Lingming},
title = {Deep just-in-time defect prediction: how far are we?},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464819},
doi = {10.1145/3460319.3464819},
abstract = {Defect prediction aims to automatically identify potential defective code with minimal human intervention and has been widely studied in the literature. Just-in-Time (JIT) defect prediction focuses on program changes rather than whole programs, and has been widely adopted in continuous testing. CC2Vec, state-of-the-art JIT defect prediction tool, first constructs a hierarchical attention network (HAN) to learn distributed vector representations of both code additions and deletions, and then concatenates them with two other embedding vectors representing commit messages and overall code changes extracted by the existing DeepJIT approach to train a model for predicting whether a given commit is defective. Although CC2Vec has been shown to be the state of the art for JIT defect prediction, it was only evaluated on a limited dataset and not compared with all representative baselines. Therefore, to further investigate the efficacy and limitations of CC2Vec, this paper performs an extensive study of CC2Vec on a large-scale dataset with over 310,370 changes (8.3 X larger than the original CC2Vec dataset). More specifically, we also empirically compare CC2Vec against DeepJIT and representative traditional JIT defect prediction techniques. The experimental results show that CC2Vec cannot consistently outperform DeepJIT, and neither of them can consistently outperform traditional JIT defect prediction. We also investigate the impact of individual traditional defect prediction features and find that the added-line-number feature outperforms other traditional features. Inspired by this finding, we construct a simplistic JIT defect prediction approach which simply adopts the added-line-number feature with the logistic regression classifier. Surprisingly, such a simplistic approach can outperform CC2Vec and DeepJIT in defect prediction, and can be 81k X/120k X faster in training/testing. Furthermore, the paper also provides various practical guidelines for advancing JIT defect prediction in the near future.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {427–438},
numpages = {12},
keywords = {Software Defect Prediction, Just-In-Time Prediction, Deep Learning},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@article{10.1007/s10664-018-9638-1,
author = {Mori, Toshiki and Uchihira, Naoshi},
title = {Balancing the trade-off between accuracy and interpretability in software defect prediction},
year = {2019},
issue_date = {April     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9638-1},
doi = {10.1007/s10664-018-9638-1},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {779–825},
numpages = {47},
keywords = {Ensemble learning, Interpretability, Model approximation, Naive Bayes classifier, Predictive accuracy, Software defect prediction, Trade-off analysis, Weights of evidence}
}

@article{10.1504/IJICA.2017.088162,
title = {Hybrid algorithm for two-objective software defect prediction problem},
year = {2017},
issue_date = {January 2017},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {8},
number = {4},
issn = {1751-648X},
url = {https://doi.org/10.1504/IJICA.2017.088162},
doi = {10.1504/IJICA.2017.088162},
abstract = {Static software defect prediction problem is one crucial problem in software test, to measure the performance, several indexes are introduced. In this paper, a two-objective software defect prediction model is employed, while probability of false alarm rate and probability of detection are taken as two objectives. To solve this model, one hybrid algorithm combined with support vector machine SVM and cuckoo search algorithm is designed. SVM is one general tool for this problem, and the performance is significantly influenced by two parameters. To provide a good classification results, one multi-objective cuckoo search algorithm is designed to optimise these two parameters. In this algorithm, the global best position is extended to be one collection including all non-dominated solutions, and the local search manner is changed to increase the local search speed. Simulation results show our hybrid algorithm is effective.},
journal = {Int. J. Innov. Comput. Appl.},
month = jan,
pages = {207–212},
numpages = {6}
}

@article{10.5555/3324436.3324448,
title = {A statistical comparison for evaluating the effectiveness of linear and nonlinear manifold detection techniques for software defect prediction},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {3–4},
issn = {1755-0386},
abstract = {Most of the software systems are released without predicting defects and therefore, this paper presents a new effective technique-manifold detection technique MDT is essential and different than earlier applied defect prediction methods like regression, feature selection methods, etc. In this paper, performance of classifiers has been compared with or without MDTs to evaluate the effectiveness of different MDTs linear and nonlinear by reducing the dimensions of software datasets. In this process, eight classifiers were applied to four PROMISE datasets to determine the best performing classifier with respect to prediction performance measuring factors accuracy, precision, recall, F-measure, AUC, misclassification error with or without MDTs. The experimental results statistically tested by paired two-tailed t-test proved that FastMVU is the most accurate result producing technique as compared to all other nonlinear MDTs and Bayesian network BN is the most effective technique for software defect prediction using with or without MDTs.},
journal = {Int. J. Adv. Intell. Paradigms},
month = jan,
pages = {370–391},
numpages = {22}
}

@inproceedings{10.1109/ICSME.2014.96,
author = {Parizy, Matthieu and Takayama, Koichiro and Kanazawa, Yuji},
title = {Software Defect Prediction for LSI Designs},
year = {2014},
isbn = {9781479961467},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSME.2014.96},
doi = {10.1109/ICSME.2014.96},
abstract = {While mining software repositories is a field which has greatly grown over the last ten years, Large Scale Integrated circuit (LSI) design repository mining has yet to reach the momentum of software's. We felt that it represents untouched potential especially for defect prediction. In an LSI, referred to as hardware later on, verification has a high cost compared to design. After studying existing software defect prediction techniques based on repository mining, we decided to adapt some for hardware design repositories in the hope of saving precious resources by focusing design and verification effort on the most defect prone parts of the design. By focusing our resources on the previously mentioned parts, we hope to improve our designs quality. We discuss how we applied these prediction techniques to hardware and show our results are promising for the future of hardware repository mining. Our results allowed us to estimate a possible total verification time reduction of 12%.},
booktitle = {Proceedings of the 2014 IEEE International Conference on Software Maintenance and Evolution},
pages = {565–568},
numpages = {4},
keywords = {LSI, code change, code metrics, defect prediction, hardware, repository mining},
series = {ICSME '14}
}

@article{10.1007/s10664-021-09965-5,
author = {Qu, Yu and Yin, Heng},
title = {Evaluating network embedding techniques’ performances in software bug prediction},
year = {2021},
issue_date = {Jul 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-021-09965-5},
doi = {10.1007/s10664-021-09965-5},
abstract = {Software bug prediction techniques can be very helpful in testing and code inspection. Over the past decade, network measures have been successfully used in bug prediction. Following the same intuition, recently, researchers started using network embedding techniques in bug prediction. However, existing studies only evaluated the Skip-gram and CBOW models with random walk. Considering network embedding is a fast-developing research direction, it is important to evaluate other network embedding techniques’ performances in bug prediction. Moreover, existing studies have not investigated the application and performance of network embedding in effort-aware bug prediction, which is thought to be a more realistic scenario that evaluates the cost effectiveness of bug prediction models. In this paper, we conduct an extensive empirical study to evaluate network embedding algorithms in bug prediction by utilizing and extending node2defect, a newly proposed bug prediction model that combines the embedded vectors with traditional software engineering metrics through concatenation. Experiments are conducted based on seven network embedding algorithms, two effort-aware models, and 13 open-source Java systems. Experimental results show that node2defect outperforms traditional metrics by + 14.64% in terms of MCC score, and by + 7.51% to + 16.57% in effort-aware bug prediction. More interestingly, when combined with CBS + , the embedded vectors alone can achieve the best performance. Among different network embedding algorithms, the newly proposed algorithm ProNE has the best performance.},
journal = {Empirical Softw. Engg.},
month = jul,
numpages = {44},
keywords = {Empirical study, Effort-aware bug prediction, Network representation learning, Network embedding, Bug prediction, Software bug}
}

@article{10.1002/smr.2330,
author = {Shi, Ke and Lu, Yang and Liu, Guangliang and Wei, Zhenchun and Chang, Jingfei},
title = {MPT‐embedding: An unsupervised representation learning of code for software defect prediction},
year = {2021},
issue_date = {April 2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {33},
number = {4},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2330},
doi = {10.1002/smr.2330},
abstract = {Software project defect prediction can help developers allocate debugging resources. Existing software defect prediction models are usually based on machine learning methods, especially deep learning. Deep learning‐based methods tend to build end‐to‐end models that directly use source code‐based abstract syntax trees (ASTs) as input. They do not pay enough attention to the front‐end data representation. In this paper, we propose a new framework to represent source code called multiperspective tree embedding (MPT‐embedding), which is an unsupervised representation learning method. MPT‐embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on both cross‐project defect prediction (CPDP) and within‐project defect prediction (WPDP) show that, on average, MPT‐embedding provides improvements over the state‐of‐the‐art method.Source code‐based automatic representations are more objective and accurate than traditional handcrafted metrics. This article proposed a new framework to represent code called multiperspective tree embedding (MPT‐embedding), which is an unsupervised representation learning method. MPT‐embedding parses the nodes of ASTs from multiple perspectives and encodes the structural information of a tree into a vector sequence. Experiments on the tasks of defect prediction show the effectiveness of the model.


image
image},
journal = {J. Softw. Evol. Process},
month = apr,
numpages = {20},
keywords = {tree embedding, representation learning, defect prediction, deep learning}
}

@article{10.1007/s00521-020-05033-z,
author = {Verma, Amar Kumar and Nagpal, Shivika and Desai, Aditya and Sudha, Radhika},
title = {An efficient neural-network model for real-time fault detection in industrial machine},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {4},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05033-z},
doi = {10.1007/s00521-020-05033-z},
abstract = {Induction machines have extensive demand in industries as they are used for large-scale production and, therefore, vulnerable to both electrical and mechanical faults. Automated continuous condition monitoring of industrial machines to identify these faults has become one of the key areas in research for the past decade. Among various faults, early-stage identification of insulation failure in stator winding is of significant demand as it is often occurring and accounts for 37% of the overall machine failures. Also, this fault, if identified at its incipient stage, can predominantly improvise machine downtime and maintenance cost. In the proposed work, stator current signal data in the time domain from the experimental setup of both healthy and faulty induction machines are used to train the artificial neural-network models in order to identify the machine’s condition. Reducing the time required to train the neural network, features are extracted from the raw current signal data and then fed to the classifiers. Various performance characteristics of eleven neural-network models such as the number of features, number of epoch runs, training time, activation functions, learning rate, model loss function, and accuracy concerning each model are quantified. Only a few neural networks could classify a healthy and a faulty induction machine with 94.73% efficiency on generalization the neural-network model with the raw data, whereas 98.43% efficiency with the statistical featured data.},
journal = {Neural Comput. Appl.},
month = feb,
pages = {1297–1310},
numpages = {14},
keywords = {Fault detection, Stator inter-turn fault (SITF), Neural network, Activation function, Pattern recognition, Squirrel-cage induction motor}
}

@article{10.1007/s10846-018-0781-0,
author = {Cho, Chang Nho and Hong, Ji Tae and Kim, Hong Ju},
title = {Neural Network Based Adaptive Actuator Fault Detection Algorithm for Robot Manipulators},
year = {2019},
issue_date = {July      2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {95},
number = {1},
issn = {0921-0296},
url = {https://doi.org/10.1007/s10846-018-0781-0},
doi = {10.1007/s10846-018-0781-0},
abstract = {In order to improve the reliability of robotic systems, various fault detection and isolation (FDI) algorithms have been proposed. However, most of these algorithms are model-based and thus, an accurate model of the robot is required although it is hard to obtain and often time-varying. Acceleration estimation is an additional challenge in dynamic model-based algorithms as it is hard to measure accurately in practice. In this study, a neural network based fault detection algorithm that does not require the use of physical robot model and acceleration is proposed. By utilizing neural network, the fault torque can be estimated, which allows effective fault detection and diagnosis. The feasibility of the proposed fault detection algorithm is validated through various simulations and experiments.},
journal = {J. Intell. Robotics Syst.},
month = jul,
pages = {137–147},
numpages = {11},
keywords = {Fault detection, Neural network, Residual observer, Robot safety}
}

@inproceedings{10.1145/3410352.3410747,
author = {Almaghairbe, Rafig and Roper, Marc and Almabruk, Tahani},
title = {Machine Learning Techniques for Automated Software Fault Detection via Dynamic Execution Data: Empirical Evaluation Study},
year = {2020},
isbn = {9781450377362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410352.3410747},
doi = {10.1145/3410352.3410747},
abstract = {The biggest obstacle of automated software testing is the construction of test oracles. Today, it is possible to generate enormous amount of test cases for an arbitrary system that reach a remarkably high level of coverage, but the effectiveness of test cases is limited by the availability of test oracles that can distinguish failing executions. Previous work by the authors has explored the use of unsupervised and semi-supervised learning techniques to develop test oracles so that the correctness of software outputs and behaviours on new test cases can be predicated [1], [2], [10], and experimental results demonstrate the promise of this approach. In this paper, we present an evaluation study for test oracles based on machine-learning approaches via dynamic execution data (firstly, input/output pairs and secondly, amalgamations of input/output pairs and execution traces) by comparing their effectiveness with existing techniques from the specification mining domain (the data invariant detector Daikon [5]). The two approaches are evaluated on a range of mid-sized systems and compared in terms of their fault detection ability and false positive rate. The empirical study also discuss the major limitations and the most important properties related to the application of machine learning techniques as test oracles in practice. The study also gives a road map for further research direction in order to tackle some of discussed limitations such as accuracy and scalability. The results show that in most cases semi-supervised learning techniques performed far better as an automated test classifier than Daikon (especially in the case that input/output pairs were augmented with their execution traces). However, there is one system for which our strategy struggles and Daikon performed far better. Furthermore, unsupervised learning techniques performed on a par when compared with Daikon in several cases particularly when input/output pairs were used together with execution traces.},
booktitle = {Proceedings of the 6th International Conference on Engineering &amp; MIS 2020},
articleno = {15},
numpages = {12},
keywords = {Automated Testing Oracles, Empirical Study, Machine Learning Techniques, Specification Mining},
location = {Almaty, Kazakhstan},
series = {ICEMIS'20}
}

@article{10.1007/s00521-018-3658-z,
author = {Taqvi, Syed A. and Tufa, Lemma Dendana and Zabiri, Haslinda and Maulud, Abdulhalim Shah and Uddin, Fahim},
title = {Fault detection in distillation column using NARX neural network},
year = {2020},
issue_date = {Apr 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {8},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-018-3658-z},
doi = {10.1007/s00521-018-3658-z},
abstract = {Fault detection in the process industries is one of the most challenging tasks. It requires timely detection of anomalies which are present with noisy measurements of a large number of variable, highly correlated data with complex interactions and fault symptoms. This study proposes the robust fault detection method for the distillation column. Fault detection and diagnosis (FDD) for process monitoring and control has been an effective field of research for two decades. This area has been used widely in sophisticated engineering design applications to ensure the proper functionality and performance diagnosis of advanced and complex technologies. Robust fault detection of the realistic faults in distillation column in dynamic condition has been considered in this study. For early detection of faults, the model is based on nonlinear autoregressive with exogenous input (NARX) network. Tapped delays lines (TDLs) have been used for the input and output sequences. A case study was carried out with three different fault scenarios, i.e., valve sticking at reflux and reboiler, and tray upset. These faults would cause the product degradation. The normal data (no fault) is used for the training of neural network in all three cases. It is shown that the proposed algorithm can be used for the detection of both internal and external faults in the distillation column for dynamic system monitoring and to predict the probability of failure.},
journal = {Neural Comput. Appl.},
month = apr,
pages = {3503–3519},
numpages = {17},
keywords = {Aspen plus® simulation, Distillation column, Fault detection, NARX neural network, Nonlinear process, Process monitoring}
}

@article{10.1016/j.eswa.2018.12.033,
author = {Turabieh, Hamza and Mafarja, Majdi and Li, Xiaodong},
title = {Iterated feature selection algorithms with layered recurrent neural network for software fault prediction},
year = {2019},
issue_date = {May 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2018.12.033},
doi = {10.1016/j.eswa.2018.12.033},
journal = {Expert Syst. Appl.},
month = may,
pages = {27–42},
numpages = {16},
keywords = {Layered recurrent neural network, Feature selection, Software fault prediction}
}

@inproceedings{10.1145/3178212.3178221,
author = {Rizwan, Syed and Tiantian, Wang and Xiaohong, Su and Salahuddin},
title = {Empirical Study on Software Bug Prediction},
year = {2017},
isbn = {9781450354882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3178212.3178221},
doi = {10.1145/3178212.3178221},
abstract = {Software defect prediction is a vital research direction in software engineering field. Software defect prediction predicts whether software errors are present in the software by using machine learning analysis on software metrics. It can help software developers to improve the quality of the software. Software defect prediction is usually a binary classification problem, which relies on software metrics and the use of classifiers. There have been many research efforts to improve accuracy in software defect prediction using a variety of classifiers and data preprocessing techniques. However, the "classic classifier validity" and "data preprocessing techniques can enhance the functionality of software defect prediction" has not yet been answered explicitly. Therefore, it is necessary to conduct an empirical analysis to compare these studies. In software defect prediction, the category of interest is a defective module, and the number of defective modules is much less than that of a non-defective module in data. This leads to a category of imbalance problem that reduces the accuracy of the prediction. Therefore, the problem of imbalance is a key problem that needs to be solved in software defect prediction. In this paper, we proposed an experimental model and used the NASA MDP data set to analyze the software defect prediction. Five research questions were defined and analyzed experimentally. In addition to experimental analysis, this paper focuses on the improvement of SMOTE. SMOTE ASMO algorithm has been proposed to overcome the shortcomings of SMOTE.},
booktitle = {Proceedings of the 2017 International Conference on Software and E-Business},
pages = {55–59},
numpages = {5},
keywords = {SMOTE, Defect prediction, Data preprocessing, Classification},
location = {Hong Kong, Hong Kong},
series = {ICSEB '17}
}

@article{10.1007/s11219-020-09515-0,
author = {Ferenc, Rudolf and T\'{o}th, Zolt\'{a}n and Lad\'{a}nyi, Gergely and Siket, Istv\'{a}n and Gyim\'{o}thy, Tibor},
title = {A public unified bug dataset for java and its assessment regarding metrics and bug prediction},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09515-0},
doi = {10.1007/s11219-020-09515-0},
abstract = {Bug datasets have been created and used by many researchers to build and validate novel bug prediction models. In this work, our aim is to collect existing public source code metric-based bug datasets and unify their contents. Furthermore, we wish to assess the plethora of collected metrics and the capabilities of the unified bug dataset in bug prediction. We considered 5 public datasets and we downloaded the corresponding source code for each system in the datasets and performed source code analysis to obtain a common set of source code metrics. This way, we produced a unified bug dataset at class and file level as well. We investigated the diversion of metric definitions and values of the different bug datasets. Finally, we used a decision tree algorithm to show the capabilities of the dataset in bug prediction. We found that there are statistically significant differences in the values of the original and the newly calculated metrics; furthermore, notations and definitions can severely differ. We compared the bug prediction capabilities of the original and the extended metric suites (within-project learning). Afterwards, we merged all classes (and files) into one large dataset which consists of 47,618 elements (43,744 for files) and we evaluated the bug prediction model build on this large dataset as well. Finally, we also investigated cross-project capabilities of the bug prediction models and datasets. We made the unified dataset publicly available for everyone. By using a public unified dataset as an input for different bug prediction related investigations, researchers can make their studies reproducible, thus able to be validated and verified.},
journal = {Software Quality Journal},
month = dec,
pages = {1447–1506},
numpages = {60},
keywords = {Bug prediction, Static code analysis, Code metrics, Bug dataset}
}

@article{10.1109/TSE.2016.2550458,
author = {Lee, Taek and Nam, Jaechang and Han, Donggyun and Kim, Sunghun and Peter In, Hoh},
title = {Developer Micro Interaction Metrics for Software Defect Prediction},
year = {2016},
issue_date = {November 2016},
publisher = {IEEE Press},
volume = {42},
number = {11},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2016.2550458},
doi = {10.1109/TSE.2016.2550458},
abstract = {To facilitate software quality assurance, defect prediction metrics, such as source code metrics, change churns, and the number of previous defects, have been actively studied. Despite the common understanding that developer behavioral interaction patterns can affect software quality, these widely used defect prediction metrics do not consider developer behavior. We therefore propose micro interaction metrics (MIMs), which are metrics that leverage developer interaction information. The developer interactions, such as file editing and browsing events in task sessions, are captured and stored as information by Mylyn, an Eclipse plug-in. Our experimental evaluation demonstrates that MIMs significantly improve overall defect prediction accuracy when combined with existing software measures, perform well in a cost-effective manner, and provide intuitive feedback that enables developers to recognize their own inefficient behaviors during software development.},
journal = {IEEE Trans. Softw. Eng.},
month = nov,
pages = {1015–1035},
numpages = {21}
}

@article{10.1007/s10664-012-9218-8,
author = {Okutan, Ahmet and Y\i{}ld\i{}z, Olcay Taner},
title = {Software defect prediction using Bayesian networks},
year = {2014},
issue_date = {February  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-012-9218-8},
doi = {10.1007/s10664-012-9218-8},
abstract = {There are lots of different software metrics discovered and used for defect prediction in the literature. Instead of dealing with so many metrics, it would be practical and easy if we could determine the set of metrics that are most important and focus on them more to predict defectiveness. We use Bayesian networks to determine the probabilistic influential relationships among software metrics and defect proneness. In addition to the metrics used in Promise data repository, we define two more metrics, i.e. NOD for the number of developers and LOCQ for the source code quality. We extract these metrics by inspecting the source code repositories of the selected Promise data repository data sets. At the end of our modeling, we learn the marginal defect proneness probability of the whole software system, the set of most effective metrics, and the influential relationships among metrics and defectiveness. Our experiments on nine open source Promise data repository data sets show that response for class (RFC), lines of code (LOC), and lack of coding quality (LOCQ) are the most effective metrics whereas coupling between objects (CBO), weighted method per class (WMC), and lack of cohesion of methods (LCOM) are less effective metrics on defect proneness. Furthermore, number of children (NOC) and depth of inheritance tree (DIT) have very limited effect and are untrustworthy. On the other hand, based on the experiments on Poi, Tomcat, and Xalan data sets, we observe that there is a positive correlation between the number of developers (NOD) and the level of defectiveness. However, further investigation involving a greater number of projects is needed to confirm our findings.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {154–181},
numpages = {28},
keywords = {Defect prediction, Bayesian networks}
}

@phdthesis{10.5555/AAI28414631,
author = {Gatling, Teia C. and Blackburn, Timothy},
advisor = {Oluwatomi, Adetunji, and Amirhossein, Etemadi,},
title = {Applying Documentation Metrics in Cross Version Defect Prediction Modeling},
year = {2021},
isbn = {9798708754837},
publisher = {The George Washington University},
abstract = {Software documentation such as documented Application Programming Interface (API) and comments embedded with the software code aid in faster debugging of software defects. The existence of this documentation is used as a measurement of software quality. Over the last 40 years, a series of object-oriented metrics-based defect prediction models have been successfully developed. However, documentation metrics in combination with object-oriented metrics in software defect prediction modeling has not been explored in predicting defects. By leveraging a publicly available GitHub dataset that contains both documentation and object-oriented metrics and applying the cross version defect prediction approach, this research determined documentation metrics impact on defects across a project and developed a predictive model using these metric in combination with baseline metrics to improve model performance. As a result, Boosting ensemble method returned improved model performance when combining the documentation metrics with commonly used object-oriented code metrics. Likewise, the Random Forest returned an improved model when using a feature subset. Random Forest using a subset of metrics provided the most promising results with F-Measure performance improvement of 8.9 percent. The results of this research highlight quantitatively the impact documentation metrics have on software defect prediction and that model performance can improve when identifying a subset of metrics. The results also demonstrate the use of data from three previous versions versus solely using the latest version, the models perform within an average of five percentage points of each other. This knowledge can be leveraged by managers to enhance the application of documentation throughout the lifecycle of software.},
note = {AAI28414631}
}

@article{10.1007/s11219-021-09553-2,
author = {Wu, Jie and Wu , Yingbo and Niu, Nan and Zhou, Min},
title = {MHCPDP: multi-source heterogeneous cross-project defect prediction via multi-source transfer learning and autoencoder},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-021-09553-2},
doi = {10.1007/s11219-021-09553-2},
abstract = {Heterogeneous cross-project defect prediction (HCPDP) is aimed at building a defect prediction model for the target project by reusing datasets from source projects, where the source project datasets and target project dataset have different features. Most existing HCPDP methods only remove redundant or unrelated features without exploring the underlying features of cross-project datasets. Additionally, when the&nbsp;transfer learning method is used in HCPDP, these methods ignore the negative effect of transfer learning. In this paper, we propose a novel HCPDP method called multi-source heterogeneous cross-project defect prediction (MHCPDP). To reduce the gap between the target datasets and the source datasets, MHCPDP uses the autoencoder to extract the intermediate features from the original datasets instead of simply removing redundant and unrelated features and adopts a modified autoencoder algorithm to make instance selection for eliminating irrelevant instances from the source domain datasets. Furthermore, by incorporating multiple source projects to increase the number of source datasets, MHCPDP develops a multi-source transfer learning algorithm to reduce the impact of negative transfers and upgrade the performance of the classifier. We comprehensively evaluate MHCPDP on five open source datasets; our experimental results show that MHCPDP not only has significant improvement in two performance metrics but also overcomes the shortcomings of the conventional HCPDP methods.},
journal = {Software Quality Journal},
month = jun,
pages = {405–430},
numpages = {26},
keywords = {Modified autoencoder, Multi-source transfer learning, Heterogeneous cross-project defect prediction, Autoencoder}
}

@book{10.5555/3175829,
author = {Rashid, Ekbal and Rashid, Ekbal},
title = {Enhancing Software Fault Prediction With Machine Learning: Emerging Research and Opportunities},
year = {2017},
isbn = {1522531858},
publisher = {IGI Global},
address = {USA},
edition = {1st},
abstract = {Software development and design is an intricate and complex process that requires a multitude of steps to ultimately create a quality product. One crucial aspect of this process is minimizing potential errors through software fault prediction. Enhancing Software Fault Prediction With Machine Learning: Emerging Research and Opportunities is an innovative source of material on the latest advances and strategies for software quality prediction. Including a range of pivotal topics such as case-based reasoning, rate of improvement, and expert systems, this book is an ideal reference source for engineers, researchers, academics, students, professionals, and practitioners interested in novel developments in software design and analysis.}
}

@inproceedings{10.1109/ITSC48978.2021.9564437,
author = {Shi, Xiaojie and Dai, Shenghua},
title = {Fault Prediction of Turnout Equipment Based on Double-layer Gated Recurrent Unit Neural Network},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC48978.2021.9564437},
doi = {10.1109/ITSC48978.2021.9564437},
abstract = {Turnout is an important railway equipment, and the failure of the turnout equipment will have a great impact on the safe operation of the train. In order to predict the failure of the turnout equipment in advance, this paper combines the double-layer gated recurrent unit (DL-GRU) neural network with the failure prediction of the turnout. This paper extracts the features of the current curves generated during multiple actions before the turnout fails, and uses the method of kernel principal component analysis (KPCA) to reduce the dimensions of the extracted features. Finally, the time series data set of turnout action current fault feature is established, which is used as the input of the DL-GRU neural network to realize the fault prediction of the turnout. The simulation results show that the DL-GRU network has a high prediction accuracy, compared with LSTM network and single-layer GRU neural network, the DL-GRU has better prediction performance.},
booktitle = {2021 IEEE International Intelligent Transportation Systems Conference (ITSC)},
pages = {2336–2341},
numpages = {6},
location = {Indianapolis, IN, USA}
}

@article{10.1504/ijsnet.2021.118488,
author = {Atiga, Jamila and Hamdi, Monia and Ejbali, Ridha and Zaied, Mourad},
title = {Recurrent neural network NARX for distributed fault detection in wireless sensor networks},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {37},
number = {2},
issn = {1748-1279},
url = {https://doi.org/10.1504/ijsnet.2021.118488},
doi = {10.1504/ijsnet.2021.118488},
abstract = {Wireless sensor networks (WSNs) comprise a collection of sensors used to collect data, which allow knowing the state of a zone or a monitored system. Sensor are usually deployed in harsh environments, where failures are common. In this work, we propose a distributed fault detection (DFD) algorithm based on the nonlinear automatic regression recurrent non-linear autoregressive with exogenous inputs (NARX) for failure detection. Defective sensors are identified by comparisons between series of actually measured values and their predicted values. The proposed method, in the first step, divides the network into a set of cliques, forming different areas. In the next step, the damaged cliques are identified using the Gaussian distribution theorem. Finally, the NARX approach is applied only to the damaged cliques to determine the defective nodes. The comparisons of simulation results to other existing algorithms show that the proposed method reaches the best results.},
journal = {Int. J. Sen. Netw.},
month = jan,
pages = {100–111},
numpages = {11},
keywords = {WSN, wireless sensor network, fault detection, DFD algorithm, NARX, non-linear autoregressive with exogenous inputs, Gaussian distribution theorem}
}

@phdthesis{10.5555/AAI29159899,
author = {Arar, \"{O}mer Faruk and undefinedBrahim, \"{O}Z\c{c}elik, and G\"{u}ltekin, \c{C}agil, and Pakize, Erdogmu\c{s}, and Onay, Durdu, Pinar},
advisor = {K\"{u}r\c{s}at, Ayan,},
title = {Makine \"{o}\u{g}renme algoritmalar\i{} kullan\i{}larak yaz\i{}l\i{}m Hata Kestiriminin iyile\c{s}tirilmesi / Using Machine Learning Algorithms to Improve Software Defect Prediction},
year = {2016},
isbn = {9798835589593},
publisher = {Sakarya Universitesi (Turkey)},
abstract = {Yaz\i{}l\i{}m sistemleri g\"{u}nl\"{u}k ya\c{s}ant\i{}m\i{}zda \c{c}ok \"{o}nemli bir role sahiptir ve her ge\c{c}en g\"{u}n kullan\i{}m\i{} daha da yayg\i{}nla\c{s}maktad\i{}r. Makinelerin ve servislerin b\"{u}y\"{u}k \c{c}o\u{g}unlu\u{g}u kendi i\c{c}lerinde farkl\i{} t\"{u}rde yaz\i{}l\i{}m i\c{c}erirler. Yaz\i{}l\i{}m geli\c{s}tiriciler, g\"{u}nl\"{u}k kullan\i{}m\i{}n\i{} yayg\i{}nla\c{s}t\i{}rmak ve rekabette geri kalmamak i\c{c}in m\"{u}mk\"{u}n oldu\u{g}unca h\i{}zl\i{} bir \c{s}ekilde yaz\i{}l\i{}mlar\i{} geli\c{s}tirmektedirler. Yaz\i{}l\i{}m ya\c{s}am d\"{o}ng\"{u}s\"{u}; genellikle analiz, tasar\i{}m, kodlama, test ve kurulum safhalar\i{}ndan olu\c{s}tur. Son kullan\i{}c\i{}ya hatadan ar\i{}nd\i{}r\i{}lm\i{}\c{s} bir yaz\i{}l\i{}m sunabilmek i\c{c}in test safhas\i{} etkili olarak y\"{u}r\"{u}t\"{u}lmelidir. Yaz\i{}l\i{}m metrikleri, kaynak kodun kalitesini yans\i{}tmay\i{} ama\c{c}larlar ve i\c{c}eri\u{g}i ile ilgili niceliksel bilgi verirler. Her bir metrik kodun farkl\i{} bir y\"{o}n\"{u}n\"{u} de\u{g}erlendirir. Kaynak kodun kalitesi seviyesi ile risk seviyesi aras\i{}nda bir ili\c{s}ki vard\i{}r. Son 20 y\i{}ll\i{}k d\"{o}nemde, akademisyenler, yaz\i{}l\i{}m hata kestirimi problemine giderek artan bir ilgi g\"{o}stermi\c{s}ler, daha g\"{u}rb\"{u}z bir kestirim i\c{c}in \c{c}e\c{s}itli makine \"{o}\u{g}renmesi yakla\c{s}\i{}mlar\i{} uygulanm\i{}\c{s}t\i{}r. Bu \c{c}al\i{}\c{s}mada da bu problem i\c{c}in \c{c}e\c{s}itli makine \"{o}\u{g}renmesi modelleri \"{o}nerilmi\c{s}tir. Yapay Sinir A\u{g}\i{} ve Yapay Ar\i{} Kolonisi kombinasyonu, Lojistik Regresyon-tabanl\i{} Bender Metot ve Naive Bayes bu \c{c}al\i{}\c{s}mada kullan\i{}lan algoritmalard\i{}r. \"{O}nerilen yakla\c{s}\i{}mlar, herkese a\c{c}\i{}k NASA Metrik Veri Program\i{} ve PROMISE havuzunda bulunan veri setlerine uygulanm\i{}\c{s}t\i{}r. undefinedstatistiki olarak g\"{u}venilir sonu\c{c}lar elde etmek ve \"{o}rneklem yanl\i{}l\i{}\u{g}\i{}n\i{} azaltmak i\c{c}in deneyler n-k\"{u}me \c{c}apraz validasyon ile kurgulanm\i{}\c{s}t\i{}r. Performans\i{} artt\i{}rmak i\c{c}in \"{o}nerilen modellere \"{o}zellik se\c{c}imi, normalizasyon ve ayr\i{}kla\c{s}t\i{}rma gibi \c{c}e\c{s}itli veri \"{o}n i\c{s}leme teknikleri uygulanm\i{}\c{s}t\i{}r. Deneylerden elde edilen sonu\c{c}lar di\u{g}er \c{c}al\i{}\c{s}malar ile kar\c{s}\i{}la\c{s}t\i{}r\i{}lm\i{}\c{s}t\i{}r. Bu \c{c}al\i{}\c{s}ma, \"{o}zellikle, yaz\i{}l\i{}m geli\c{s}tiricileri ve test personelinin kullan\i{}m\i{} y\"{o}n\"{u}yle katk\i{} yapmaktad\i{}r. Yaz\i{}l\i{}m geli\c{s}tiricileri, d\"{u}zenlemeye ihtiya\c{c} duyulan s\i{}n\i{}f veya mod\"{u}lleri g\"{o}r\"{u}rler; dolay\i{}s\i{}yla, bu mod\"{u}llerin kalitesinin artt\i{}r\i{}lmas\i{}na ve risk seviyelerinin azalt\i{}lmas\i{}na katk\i{} yapm\i{}\c{s} olurlar. Test personeli, daha \c{c}ok test yo\u{g}unla\c{s}mas\i{} gerektiren mod\"{u}lleri tespit eder ve bunun neticesinde mod\"{u}llerin \"{o}nceliklendirmesinin risk seviyelerine g\"{o}re yap\i{}lmas\i{} sa\u{g}lanm\i{}\c{s} olunur.},
note = {AAI29159899}
}

@article{10.1016/j.jss.2019.110493,
author = {Pascarella, Luca and Palomba, Fabio and Bacchelli, Alberto},
title = {On the performance of method-level bug prediction: A negative result},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {161},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110493},
doi = {10.1016/j.jss.2019.110493},
journal = {J. Syst. Softw.},
month = mar,
numpages = {15},
keywords = {Mining software repositories, Empirical software engineering, Defect prediction}
}

@book{10.5555/2809060,
author = {Ahmet, Okutan},
title = {Software Defect Prediction using Bayesian Networks and Kernel Methods},
year = {2015},
isbn = {3639703464},
publisher = {Scholar's Press},
abstract = {There are lots of different software metrics discovered and used for defect prediction in the literature. Instead of dealing with so many metrics, it would be practical and easy if we could determine the set of metrics that are most important and focus on them more to predict defectiveness. In this book, we use Bayesian modeling to determine the influential relationships among software metrics and defect proneness. Furthermore, we propose a novel technique for defect prediction that uses plagiarism detection tools. We use kernel programming to model the relationship between source code similarity and defectiveness and suggest that source code similarity is a good means of predicting both defectiveness and the number of defects in software systems.}
}

@inproceedings{10.1109/CIS.2013.61,
author = {Shuai, Bo and Li, Haifeng and Li, Mengjun and Zhang, Quan and Tang, Chaojing},
title = {Software Defect Prediction Using Dynamic Support Vector Machine},
year = {2013},
isbn = {9781479925490},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CIS.2013.61},
doi = {10.1109/CIS.2013.61},
abstract = {In order to solve the problems of traditional SVM classifier for software defect prediction, this paper proposes a novel dynamic SVM method based on improved cost-sensitive SVM (CSSVM) which is optimized by the Genetic Algorithm (GA). Through selecting the geometric classification accuracy as the fitness function, the GA method could improve the performance of CSSVM by enhancing the accuracy of defective modules and reducing the total cost in the whole decision. Experimental results show that the GA-CSSVM method could achieve higher AUC value which denotes better prediction accuracy both for minority and majority samples in the imbalanced software defect data set.},
booktitle = {Proceedings of the 2013 Ninth International Conference on Computational Intelligence and Security},
pages = {260–263},
numpages = {4},
keywords = {AUC, CSSVM, GA, software defect},
series = {CIS '13}
}

@article{10.5555/3302663.3302666,
title = {Adaptive two-SVM multi-objective cuckoo search algorithm for software defect prediction},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {6},
issn = {1752-5055},
abstract = {Two-support vector machine is a new prediction model for software defect. For this model, one multi-objective oriented cuckoo search is designed to optimise several objects simultaneously to improve the defect accuracy, and the ratio of dataset plays an important role to determine the number of big/small modules. In this paper, we provide one extension for the multi-objective oriented cuckoo search, so that it can also adaptive optimise this ratio. Simulation results show our modification achieves the best performance when compared with two other software defect prediction models.},
journal = {Int. J. Comput. Sci. Math.},
month = jan,
pages = {547–554},
numpages = {8}
}

@article{10.3233/JIFS-179619,
author = {Lyu, Yi and Jiang, YiJie and Zhang, Weiping},
title = {Examination on avionics system fault prediction technology based on ashy neural network and fuzzy recognition},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {38},
number = {4},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-179619},
doi = {10.3233/JIFS-179619},
abstract = {The purpose of this paper is to accurately locate the fault prediction and diagnosis technology, to have a high degree of automation, and to handle it quickly, for the large aircraft avionics system failure presents the feature of multiple coupling, complex impact and rapid spread. At the same time, the fault prediction diagnosis technology is one of the most important contents of the avionics system equipment prediction, so how to quickly and effectively predict the failure of key system parts of avionics is the core essential to ensure the complete operation of the whole system. This paper through establishing the gray neural network model, combining the advantages of gray model to deal with poor information and the characteristics of artificial neural network processing nonlinear data, to realize the fault prediction of avionics system, At the same time, At the same time, through the fuzzy recognition method based on the deterioration degree, established the bridge between the two, in turn, to achieve the health prediction management of system. The method mainly includes: Firstly, by combining gray theory and artificial neural network algorithm with fuzzy recognition to establish a network model that contains gray neural network models and can reflect the excellent characteristics of fuzzy recognition and conduct experimental analysis; Second, on this basis, improve the weight update strategy of the gray neural network by using additional learning rate method which based on momentum and improve the accuracy of the algorithm. Therefore, it can be concluded that the predictions presented in this paper should not be directly imitated when the system disturbance factor is too large or the system is abnormally caused by a serious disturbance suddenly appearing at a certain point in time, but should properly processed the data firstly according to the actual situation. According to the time series of the actual situation, several models are established, and the data correction is explained from the model prediction effect, and the gray model and description are improved. The improved combination of gray neural network and gray neural network can not only improve the prediction accuracy, but also provide a feasible method for such time series prediction, which provides a practical and effective technical method for avionics system fault prediction.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {3939–3947},
numpages = {9},
keywords = {Ashy neural network, avionics system, fuzzy recognition, fault prediction, combined forecast}
}

@inproceedings{10.1145/3324884.3416612,
author = {Perera, Anjana and Aleti, Aldeida and B\"{o}hme, Marcel and Turhan, Burak},
title = {Defect prediction guided search-based software testing},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416612},
doi = {10.1145/3324884.3416612},
abstract = {Today, most automated test generators, such as search-based software testing (SBST) techniques focus on achieving high code coverage. However, high code coverage is not sufficient to maximise the number of bugs found, especially when given a limited testing budget. In this paper, we propose an automated test generation technique that is also guided by the estimated degree of defectiveness of the source code. Parts of the code that are likely to be more defective receive more testing budget than the less defective parts. To measure the degree of defectiveness, we leverage Schwa, a notable defect prediction technique.We implement our approach into EvoSuite, a state of the art SBST tool for Java. Our experiments on the Defects4J benchmark demonstrate the improved efficiency of defect prediction guided test generation and confirm our hypothesis that spending more time budget on likely defective parts increases the number of bugs found in the same time budget.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {448–460},
numpages = {13},
keywords = {automated test generation, defect prediction, search-based software testing},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@article{10.1504/IJWMC.2016.076145,
author = {Li, Feixiang and Rong, Xiaotao and Cui, Zhihua},
title = {A hybrid CRBA-SVM model for software defect prediction},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {10},
number = {2},
issn = {1741-1084},
url = {https://doi.org/10.1504/IJWMC.2016.076145},
doi = {10.1504/IJWMC.2016.076145},
abstract = {Support vector machine SVM model is becoming an increasingly popular method in software defects prediction. This model has strong non-linear classifying ability. However, SVM model lacks effective method to determine the best parameters. In this paper, a modified bat algorithm, named changing range bat algorithm, is employed to optimise the parameters of SVM model. To test the performance of this new model, several public datasets of software defect prediction are employed and then the results are compared with other five approaches. Experimental results show that the classification ability of hybrid CRBA-SVM model surpasses all other approaches.},
journal = {Int. J. Wire. Mob. Comput.},
month = apr,
pages = {191–196},
numpages = {6}
}

@inproceedings{10.1145/3472674.3473979,
author = {Pravilov, Mikhail and Bogomolov, Egor and Golubev, Yaroslav and Bryksin, Timofey},
title = {Unsupervised learning of general-purpose embeddings for code changes},
year = {2021},
isbn = {9781450386258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472674.3473979},
doi = {10.1145/3472674.3473979},
abstract = {Applying machine learning to tasks that operate with code changes requires their numerical representation. In this work, we propose an approach for obtaining such representations during pre-training and evaluate them on two different downstream tasks — applying changes to code and commit message generation. During pre-training, the model learns to apply the given code change in a correct way. This task requires only code changes themselves, which makes it unsupervised. In the task of applying code changes, our model outperforms baseline models by 5.9 percentage points in accuracy. As for the commit message generation, our model demonstrated the same results as supervised models trained for this specific task, which indicates that it can encode code changes well and can be improved in the future by pre-training on a larger dataset of easily gathered code changes.},
booktitle = {Proceedings of the 5th International Workshop on Machine Learning Techniques for Software Quality Evolution},
pages = {7–12},
numpages = {6},
keywords = {Unsupervised learning, Commit message generation, Code changes},
location = {Athens, Greece},
series = {MaLTESQuE 2021}
}

@inproceedings{10.1145/2875913.2875944,
author = {Qing, He and Biwen, Li and Beijun, Shen and Xia, Yong},
title = {Cross-Project Software Defect Prediction Using Feature-Based Transfer Learning},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875944},
doi = {10.1145/2875913.2875944},
abstract = {Cross-project defect prediction is taken as an effective means of predicting software defects when the data shortage exists in the early phase of software development. Unfortunately, the precision of cross-project defect prediction is usually poor, largely because of the differences between the reference and the target projects. Having realized the project differences, this paper proposes CPDP, a feature-based transfer learning approach to cross-project defect prediction. The core insight of CPDP is to (1) filter and transfer highly-correlated data based on data samples in the target projects, and (2) evaluate and choose learning schemas for transferring data sets. Models are then built for predicting defects in the target projects. We have also conducted an evaluation of the proposed approach on PROMISE datasets. The evaluation results show that, the proposed approach adapts to cross-project defect prediction in that f-measure of 81.8% of projects can get improved, and AUC of 54.5% projects improved. It also achieves similar f-measure and AUC as some inner-project defect prediction approaches.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {74–82},
numpages = {9},
keywords = {transfer learning, feature-based transfer, cross-project defect prediction},
location = {Wuhan, China},
series = {Internetware '15}
}

@article{10.1016/j.infsof.2011.09.007,
author = {Ma, Ying and Luo, Guangchun and Zeng, Xue and Chen, Aiguo},
title = {Transfer learning for cross-company software defect prediction},
year = {2012},
issue_date = {March, 2012},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {54},
number = {3},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2011.09.007},
doi = {10.1016/j.infsof.2011.09.007},
abstract = {Context: Software defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction? Objective: In this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model. Method: Unlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built. Results: This article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods. Conclusion: It is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {248–256},
numpages = {9},
keywords = {Transfer learning, Software defect prediction, Naive Bayes, Machine learning, Different distribution}
}

@article{10.1016/j.eswa.2019.113156,
author = {Majd, Amirabbas and Vahidi-Asl, Mojtaba and Khalilian, Alireza and Poorsarvi-Tehrani, Pooria and Haghighi, Hassan},
title = {SLDeep: Statement-level software defect prediction using deep-learning model on static code features},
year = {2020},
issue_date = {Jun 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {147},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113156},
doi = {10.1016/j.eswa.2019.113156},
journal = {Expert Syst. Appl.},
month = jun,
numpages = {14},
keywords = {Software metric, Fault prediction model, Machine learning, Software fault proneness, Defect}
}

@article{10.1016/j.compind.2021.103505,
author = {Gashi, Milot and Ofner, Patrick and Ennsbrunner, Helmut and Thalmann, Stefan},
title = {Dealing with missing usage data in defect prediction: A case study of a welding supplier},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2021.103505},
doi = {10.1016/j.compind.2021.103505},
journal = {Comput. Ind.},
month = nov,
numpages = {10},
keywords = {Defect prediction, End-of-line testing, Welding industry, Predictive maintenance, Multi-component systems}
}

@proceedings{10.1145/3416505,
title = {MaLTeSQuE 2020: Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the fourth edition of the workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE 2020) to be held virtually on November 16, 2020, co-located with the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2020).},
location = {Virtual, USA}
}

@article{10.1016/j.procs.2018.05.115,
author = {Singh, Ajmer and Bhatia, Rajesh and Singhrova, Anita},
title = {Taxonomy of machine learning algorithms in software fault prediction using object oriented metrics},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.115},
doi = {10.1016/j.procs.2018.05.115},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {993–1001},
numpages = {9},
keywords = {Software fault prediction, Object Oriented Testing, Object Oriented Coupling, software faults prediction, machine learning}
}

@article{10.1145/3467895,
author = {Falessi, Davide and Ahluwalia, Aalok and Penta, Massimiliano DI},
title = {The Impact of Dormant Defects on Defect Prediction: A Study of 19 Apache Projects},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3467895},
doi = {10.1145/3467895},
abstract = {Defect prediction models can be beneficial to prioritize testing, analysis, or code review activities, and has been the subject of a substantial effort in academia, and some applications in industrial contexts. A necessary precondition when creating a defect prediction model is the availability of defect data from the history of projects. If this data is noisy, the resulting defect prediction model could result to be unreliable. One of the causes of noise for defect datasets is the presence of “dormant defects,” i.e., of defects discovered several releases after their introduction. This can cause a class to be labeled as defect-free while it is not, and is, therefore “snoring.” In this article, we investigate the impact of snoring on classifiers' accuracy and the effectiveness of a possible countermeasure, i.e., dropping too recent data from a training set. We analyze the accuracy of 15 machine learning defect prediction classifiers, on data from more than 4,000 defects and 600 releases of 19 open source projects from the Apache ecosystem. Our results show that on average across projects (i) the presence of dormant defects decreases the recall of defect prediction classifiers, and (ii) removing from the training set the classes that in the last release are labeled as not defective significantly improves the accuracy of the classifiers. In summary, this article provides insights on how to create defects datasets by mitigating the negative effect of dormant defects on defect prediction.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {4},
numpages = {26},
keywords = {dataset bias, fix-inducing changes, Defect prediction}
}

@inproceedings{10.1109/ISISE.2012.114,
author = {Wang, Pei and Jin, Cong and Jin, Shu-Wei},
title = {Software Defect Prediction Scheme Based on Feature Selection},
year = {2012},
isbn = {9780769549514},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISISE.2012.114},
doi = {10.1109/ISISE.2012.114},
abstract = {Predicting defect-prone software modules accurately and effectively are important ways to control the quality of a software system during software development. Feature selection can highly improve the accuracy and efficiency of the software defect prediction model. The main purpose of this paper is to discuss the best size of feature subset for building a prediction model and prove that feature selection method is useful for establishing software defect prediction model. Mutual information is an outstanding indicator of relevance between variables, and it has been used as a measurement in our feature selection algorithm. We also introduce a nonlinear factor to our evaluation function for feature selection to improve its performance. The results of our feature selection algorithm are validated by different machine learning methods. The experiment results show that all the classifiers achieve higher accuracy by using the feature subset provided by our algorithm.},
booktitle = {Proceedings of the 2012 Fourth International Symposium on Information Science and Engineering},
pages = {477–480},
numpages = {4},
keywords = {feature selection, mutual information, software defect prediction},
series = {ISISE '12}
}

@inproceedings{10.1145/3183440.3183449,
author = {Eken, Beyza},
title = {Assessing personalized software defect predictors},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3183449},
doi = {10.1145/3183440.3183449},
abstract = {Software defect prediction models guide developers and testers to identify defect prone software modules in fewer time and effort, compared to manual inspections of the source code. The state-of-the-art predictors on publicly available software engineering data could catch around 70% of the defects. While early studies mostly utilize static code properties of the software, recent studies incorporate the people factor into the prediction models, such as the number of developers that touched a code unit, the experience of the developer, and interaction and cognitive behaviors of developers. Those information could give a stronger clue about the defect-prone parts because they could explain defect injection patterns in software development. Personalization has been emerging in many other systems such as social platforms, web search engines such that people get customized recommendations based on their actions, profiles and interest. Following this point of view, customization in defect prediction with respect to each developer would increase predictions' accuracy and usefulness than traditional, general models. In this thesis, we focus on building a personalized defect prediction framework that gives instant feedback to the developer at change level, based on historical defect and change data. Our preliminary analysis of the personalized prediction models of 121 developers in six open source projects indicate that, a personalized approach is not always the best model when compared to general models built for six projects. Other factors such as project characteristics, developer's historical data, the context and frequency of contributions, and/or development methodologies might affect which model to consider in practice. Eventually, this topic is open to improvement with further empirical studies on each of these factors.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {488–491},
numpages = {4},
keywords = {bug prediction, customization, personalized defect prediction},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1016/j.compeleceng.2021.107370,
author = {Zheng, Shang and Gai, Jinjing and Yu, Hualong and Zou, Haitao and Gao, Shang},
title = {Training data selection for imbalanced cross-project defect prediction},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {94},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107370},
doi = {10.1016/j.compeleceng.2021.107370},
journal = {Comput. Electr. Eng.},
month = sep,
numpages = {11},
keywords = {Cross-project software prediction, Data selection, Jensen-Shannon divergence, Relative density}
}

@article{10.4018/IJOSSP.2017010102,
author = {Alsukhni, Emad and Saifan, Ahmad A. and Alawneh, Hanadi},
title = {A New Data Mining-Based Framework to Test Case Prioritization Using Software Defect Prediction},
year = {2017},
issue_date = {January 2017},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {1},
issn = {1942-3926},
url = {https://doi.org/10.4018/IJOSSP.2017010102},
doi = {10.4018/IJOSSP.2017010102},
abstract = {Test cases do not have the same importance when used to detect faults in software; therefore, it is more efficient to test the system with the test cases that have the ability to detect the faults. This research proposes a new framework that combines data mining techniques to prioritize the test cases. It enhances fault prediction and detection using two different techniques: 1 the data mining regression classifier that depends on software metrics to predict defective modules, and 2 the k-means clustering technique that is used to select and prioritize test cases to identify the fault early. Our approach of test case prioritization yields good results in comparison with other studies. The authors used the Average Percentage of Faults Detection APFD metric to evaluate the proposed framework, which results in 19.9% for all system modules and 25.7% for defective ones. Our results give us an indication that it is effective to start the testing process with the most defective modules instead of testing all modules arbitrary arbitrarily.},
journal = {Int. J. Open Source Softw. Process.},
month = jan,
pages = {21–41},
numpages = {21},
keywords = {Data Mining, Software Defect Prediction, Software Testing, Test Case Prioritization}
}

@inproceedings{10.1007/978-3-319-49586-6_11,
author = {Siers, Michael J. and Islam, Md Zahidul},
title = {Addressing Class Imbalance and Cost Sensitivity in Software Defect Prediction by Combining Domain Costs and Balancing Costs},
year = {2016},
isbn = {978-3-319-49585-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-49586-6_11},
doi = {10.1007/978-3-319-49586-6_11},
abstract = {Effective methods for identification of software defects help minimize the business costs of software development. Classification methods can be used to perform software defect prediction. When cost-sensitive methods are used, the predictions are optimized for business cost. The data sets used as input for these methods typically suffer from the class imbalance problem. That is, there are many more defect-free code examples than defective code examples to learn from. This negatively impacts the classifier’s ability to correctly predict defective code examples. Cost-sensitive classification can also be used to mitigate the affects of the class imbalance problem by setting the costs to reflect the level of imbalance in the training data set. Through an experimental process, we have developed a method for combining these two different types of costs. We demonstrate that by using our proposed approach, we can produce more cost effective predictions than several recent cost-sensitive methods used for software defect prediction. Furthermore, we examine the software defect prediction models built by our method and present the discovered insights.},
booktitle = {Advanced Data Mining and Applications: 12th International Conference, ADMA 2016, Gold Coast, QLD, Australia, December 12-15, 2016, Proceedings},
pages = {156–171},
numpages = {16},
keywords = {Cost sensitive, Software defect prediction, Class imbalance},
location = {Gold Coast, Australia}
}

@inproceedings{10.1145/2961111.2962620,
author = {Shippey, Thomas and Hall, Tracy and Counsell, Steve and Bowes, David},
title = {So You Need More Method Level Datasets for Your Software Defect Prediction? Voil\`{a}!},
year = {2016},
isbn = {9781450344272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2961111.2962620},
doi = {10.1145/2961111.2962620},
abstract = {Context: Defect prediction research is based on a small number of defect datasets and most are at class not method level. Consequently our knowledge of defects is limited. Identifying defect datasets for prediction is not easy and extracting quality data from identified datasets is even more difficult. Goal: Identify open source Java systems suitable for defect prediction and extract high quality fault data from these datasets. Method: We used the Boa to identify candidate open source systems. We reduce 50,000 potential candidates down to 23 suitable for defect prediction using a selection criteria based on the system's software repository and its defect tracking system. We use an enhanced SZZ algorithm to extract fault information and calculate metrics using JHawk. Result: We have produced 138 fault and metrics datasets for the 23 identified systems. We make these datasets (the ELFF datasets) and our data extraction tools freely available to future researchers. Conclusions: The data we provide enables future studies to proceed with minimal effort. Our datasets significantly increase the pool of systems currently being used in defect analysis studies.},
booktitle = {Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {12},
numpages = {6},
keywords = {Defects, Defect linking, Defect Prediction, Data Mining, Boa},
location = {Ciudad Real, Spain},
series = {ESEM '16}
}

@inproceedings{10.1145/2491411.2494581,
author = {Zhang, Hongyu and Cheung, S. C.},
title = {A cost-effectiveness criterion for applying software defect prediction models},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2494581},
doi = {10.1145/2491411.2494581},
abstract = {Ideally, software defect prediction models should help organize software quality assurance (SQA) resources and reduce cost of finding defects by allowing the modules most likely to contain defects to be inspected first. In this paper, we study the cost-effectiveness of applying defect prediction models in SQA and propose a basic cost-effectiveness criterion. The criterion implies that defect prediction models should be applied with caution. We also propose a new metric FN/(FN+TN) to measure the cost-effectiveness of a defect prediction model.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {643–646},
numpages = {4},
keywords = {evaluation metrics, cost effectiveness, Defect prediction},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@article{10.1049/sfw2.12053,
author = {Huang, Qingan and Ma, Le and Jiang, Siyu and Wu, Guobin and Song, Hengjie and Jiang, Libiao and Zheng, Chunyun},
title = {A cross‐project defect prediction method based on multi‐adaptation and nuclear norm},
year = {2021},
issue_date = {April 2022},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {16},
number = {2},
url = {https://doi.org/10.1049/sfw2.12053},
doi = {10.1049/sfw2.12053},
abstract = {Cross‐project defect prediction (CPDP) is an important research direction in software defect prediction. Traditional CPDP methods based on hand‐crafted features ignore the semantic information in the source code. Existing CPDP methods based on the&nbsp;deep learning model may not fully consider the differences among projects. Additionally, these methods may not accurately classify the samples near the classification boundary. To solve these problems, the authors propose a model based on multi‐adaptation and nuclear norm (MANN) to deal with samples in projects. The feature of samples were embedded into the multi‐core Hilbert space for distribution and the multi‐kernel maximum mean discrepancy method was utilised to reduce differences among projects. More importantly, the nuclear norm module was constructed, which improved the discriminability and diversity of the target sample by calculating and maximizing the nuclear norm of the target sample in the process of domain adaptation, thus improving the performance of MANN. Finally, extensive experiments were conducted on 11 sizeable open‐source projects. The results indicate&nbsp;that the proposed method exceeds the state of the art under the widely used metrics.},
journal = {IET Software},
month = dec,
pages = {200–213},
numpages = {14},
keywords = {unsupervised learning, software reliability, software quality, neural nets}
}

@inproceedings{10.1109/COMPSAC.2014.65,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {A Semi-supervised Approach to Software Defect Prediction},
year = {2014},
isbn = {9781479935758},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2014.65},
doi = {10.1109/COMPSAC.2014.65},
abstract = {Accurate detection of software components that need to be exposed to additional verification and validation offers the path to high quality products while minimizing non essential software assurance expenditures. In this type of quality modeling we assume that software modules with known fault content developed in similar environment are available. Supervised learning algorithms are the traditional methods of choice for training on existing modules. The models are then used to predict fault content for newly developed software components prior to product release. However, one needs to realize that establishing whether a module contains a fault or not, only to be used for model training, can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available, thus reducing the overall cost of quality assurance. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics used for prediction. Our results show that the dimension-reduction with semi-supervised learning algorithm preforms significantly better than one of the best performing supervised learning algorithm - random forest - in situations when few modules with known fault content are available. We compare our results with the published benchmarks and clearly demonstrate performance benefits.},
booktitle = {Proceedings of the 2014 IEEE 38th Annual Computer Software and Applications Conference},
pages = {416–425},
numpages = {10},
keywords = {software fault prediction, semi-supervised learning, dimension reduction, software metrics},
series = {COMPSAC '14}
}

@inproceedings{10.1145/3273934.3273938,
author = {Amasaki, Sousuke},
title = {Cross-Version Defect Prediction using Cross-Project Defect Prediction Approaches: Does it work?},
year = {2018},
isbn = {9781450365932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3273934.3273938},
doi = {10.1145/3273934.3273938},
abstract = {Background: Specifying and removing defects before release deserve extra cost for the success of software projects. Long-running projects experience multiple releases, and it is a natural choice to adopt cross-version defect prediction (CVDP) that uses information from older versions. A past study shows that feeding multi older versions data may have a positive influence on the performance. The study also suggests that cross-project defect prediction (CPDP) may fit the situation but one CPDP approach was only examined.Aims: To investigate whether feeding multiple older versions data is effective for CVDP using CPDP approaches. The investigation also involves performance comparisons of the CPDP approaches under CVDP situation. Method: We chose a style of replication of the comparative study on CPDP approaches by Herbold et al. under CVDP situation. Results: Feeding multiple older versions had a positive effect for more than a half CPDP approaches. However, almost all of the CPDP approaches did not perform significantly better than a simple rule-based prediction. Although the best CPDP approach could work better than it and with-in project defect prediction, we found no effect of feeding multiple older versions for it. Conclusions: Feeding multiple older versions could improve CPDP approaches under CVDP situation. However, it did not work for the best CPDP approach in the study.},
booktitle = {Proceedings of the 14th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {32–41},
numpages = {10},
keywords = {Comparative Study, Cross-Project Defect Prediction, Cross-Version Defect Prediction},
location = {Oulu, Finland},
series = {PROMISE'18}
}

@article{10.1007/s10664-018-9679-5,
author = {Kondo, Masanari and Bezemer, Cor-Paul and Kamei, Yasutaka and Hassan, Ahmed E. and Mizuno, Osamu},
title = {The impact of feature reduction techniques on defect prediction models},
year = {2019},
issue_date = {August    2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9679-5},
doi = {10.1007/s10664-018-9679-5},
abstract = {Defect prediction is an important task for preserving software quality. Most prior work on defect prediction uses software features, such as the number of lines of code, to predict whether a file or commit will be defective in the future. There are several reasons to keep the number of features that are used in a defect prediction model small. For example, using a small number of features avoids the problem of multicollinearity and the so-called `curse of dimensionality'. Feature selection and reduction techniques can help to reduce the number of features in a model. Feature selection techniques reduce the number of features in a model by selecting the most important ones, while feature reduction techniques reduce the number of features by creating new, combined features from the original features. Several recent studies have investigated the impact of feature selection techniques on defect prediction. However, there do not exist large-scale studies in which the impact of multiple feature reduction techniques on defect prediction is investigated. In this paper, we study the impact of eight feature reduction techniques on the performance and the variance in performance of five supervised learning and five unsupervised defect prediction models. In addition, we compare the impact of the studied feature reduction techniques with the impact of the two best-performing feature selection techniques (according to prior work). The following findings are the highlights of our study: (1) The studied correlation and consistency-based feature selection techniques result in the best-performing supervised defect prediction models, while feature reduction techniques using neural network-based techniques (restricted Boltzmann machine and autoencoder) result in the best-performing unsupervised defect prediction models. In both cases, the defect prediction models that use the selected/generated features perform better than those that use the original features (in terms of AUC and performance variance). (2) Neural network-based feature reduction techniques generate features that have a small variance across both supervised and unsupervised defect prediction models. Hence, we recommend that practitioners who do not wish to choose a best-performing defect prediction model for their data use a neural network-based feature reduction technique.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1925–1963},
numpages = {39},
keywords = {Restricted Boltzmann machine, Neural network, Feature selection, Feature reduction, Defect prediction}
}

@article{10.1016/j.procs.2018.05.071,
author = {Pandey, Sushant Kumar and Mishra, Ravi Bhushan and Triphathi, Anil Kumar},
title = {Software Bug Prediction Prototype Using Bayesian Network Classifier: A Comprehensive Model},
year = {2018},
issue_date = {2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2018.05.071},
doi = {10.1016/j.procs.2018.05.071},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {1412–1421},
numpages = {10},
keywords = {Bayesian network, bug prediction, classification techniques}
}

@article{10.1109/TSE.2017.2731766,
author = {Bennin, Kwabena Ebo and Keung, Jacky and Phannachitta, Passakorn and Monden, Akito and Mensah, Solomon},
title = {MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction},
year = {2018},
issue_date = {June 2018},
publisher = {IEEE Press},
volume = {44},
number = {6},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2017.2731766},
doi = {10.1109/TSE.2017.2731766},
abstract = {Highly imbalanced data typically make accurate predictions difficult. Unfortunately, software defect datasets tend to have fewer defective modules than non-defective modules. Synthetic oversampling approaches address this concern by creating new minority defective modules to balance the class distribution before a model is trained. Notwithstanding the successes achieved by these approaches, they mostly result in over-generalization (high rates of false alarms) and generate near-duplicated data instances (less diverse data). In this study, we introduce MAHAKIL, a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with SMOTE, Borderline-SMOTE, ADASYN, Random Oversampling and the No sampling approach using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant &lt;italic&gt;pf&lt;/italic&gt; values than the other oversampling approaches, based on Brunner's statistical significance test and Cliff's effect sizes. Therefore, MAHAKIL is strongly recommended as an efficient alternative for defect prediction models built on highly imbalanced datasets.},
journal = {IEEE Trans. Softw. Eng.},
month = jun,
pages = {534–550},
numpages = {17}
}

@inproceedings{10.1145/3475716.3475791,
author = {Gesi, Jiri and Li, Jiawei and Ahmed, Iftekhar},
title = {An Empirical Examination of the Impact of Bias on Just-in-time Defect Prediction},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3475791},
doi = {10.1145/3475716.3475791},
abstract = {Background: Just-In-Time (JIT) defect prediction models predict if a commit will introduce defects in the future. DeepJIT and CC2Vec are two state-of-the-art JIT Deep Learning (DL) techniques. Usually, defect prediction techniques are evaluated, treating all training data equally. However, data is usually imbalanced not only in terms of the overall class label (e.g., defect and non-defect) but also in terms of characteristics such as File Count, Edit Count, Multiline Comments, Inward Dependency Sum etc. Prior research has investigated the impact of class imbalance on prediction technique's performance but not the impact of imbalance of other characteristics. Aims: We aim to explore the impact of different commit related characteristic's imbalance on DL defect prediction. Method: We investigated different characteristic's impact on the overall performance of DeepJIT and CC2Vec. We also propose a Siamese network based few-shot learning framework for JIT defect prediction (SifterJIT) combining Siamese network and DeepJIT. Results: Our results show that DeepJIT and CC2Vec lose out on the performance by around 20% when trained and tested on imbalanced data. However, SifterJIT can outperform state-of-the-art DL techniques with an average of 8.65% AUC score, 11% precision, and 6% F1-score improvement. Conclusions: Our results highlight that dataset imbalanced in terms of commit characteristics can significantly impact prediction performance, and few-shot learning based techniques can help alleviate the situation.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {7},
numpages = {12},
keywords = {software engineering, few-shot learning, defect prediction, Deep learning},
location = {Bari, Italy},
series = {ESEM '21}
}

@inproceedings{10.1145/3090354.3090365,
author = {Khoudry, Elmahdi and Belfqih, Abdelaziz and Dazahra, Mohamed Nouh},
title = {Neural Network Approach for Fault Detection in Substations},
year = {2017},
isbn = {9781450348522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3090354.3090365},
doi = {10.1145/3090354.3090365},
abstract = {This paper presents a fault detection algorithm for substations. The algorithm was based on neural network approach. The neural network was trained with Levenberg-Marquardt backpropagation algorithm and the training set was formed from the input-output pairs (generator currents, load currents) generated by the substation physical model which was modeled in SIMULINK® by an ideal generator, a three phase transformer and a resistive load.Then under the no-fault condition, the substation neural network model outputs were compared to the substation physical model outputs and maximum errors were computed for each phase(A,B and C). The simulation of the fault detection algorithm consisted of comparing, for each phase, the squared errors between the substation neural network model outputs and the substation physical model outputs; provided that for the fault condition, they would exceed the square of maximum errors previously computed.The simulation results show that the fault detection algorithm is valid and that it can be improved by increasing the size of the training set and by choosing the right neural network architecture.},
booktitle = {Proceedings of the 2nd International Conference on Big Data, Cloud and Applications},
articleno = {11},
numpages = {6},
keywords = {Fault detection, Levenberg-Marquardt backpropagation algorithm, Neural Network (NN), Substations},
location = {Tetouan, Morocco},
series = {BDCA'17}
}

@inproceedings{10.1109/ICSE-C.2017.72,
author = {Wu, Fei and Jing, Xiao-Yuan and Dong, Xiwei and Cao, Jicheng and Xu, Mingwei and Zhang, Hongyu and Ying, Shi and Xu, Baowen},
title = {Cross-project and within-project semi-supervised software defect prediction problems study using a unified solution},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.72},
doi = {10.1109/ICSE-C.2017.72},
abstract = {When there exists not enough historical defect data for building accurate prediction model, semi-supervised defect prediction (SSDP) and cross-project defect prediction (CPDP) are two feasible solutions. Existing CPDP methods assume that the available source data is well labeled. However, due to expensive human efforts for labeling a large amount of defect data, usually, we can only make use of the suitable unlabeled source data to help build the prediction model. We call CPDP in this scenario as cross-project semi-supervised defect prediction (CSDP). As to within-project semi-supervised defect prediction (WSDP), although some WSDP methods have been developed in recent years, there still exists much room for improvement. In this paper, we aim to provide an effective solution for both CSDP and WSDP problems. We introduce the semi-supervised dictionary learning technique, an effective machine learning technique, into defect prediction and propose a semi-supervised structured dictionary learning (SSDL) approach for CSDP and WSDP. SSDL can make full use of the useful information in limited labeled defect data and a large amount of unlabeled data. Experiments on two public datasets indicate that SSDL can obtain better prediction performance than related SSDP methods in the CSDP scenario.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {195–197},
numpages = {3},
keywords = {within-project semi-supervised defect prediction, semi-supervised structured dictionary learning, cross-project semi-supervised defect prediction},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1109/ETFA.2019.8869230,
author = {Mishra, Krishna Mohan and Huhtala, Kalevi J.},
title = {Fault Detection of Elevator Systems Using Multilayer Perceptron Neural Network},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ETFA.2019.8869230},
doi = {10.1109/ETFA.2019.8869230},
abstract = {In this research, we propose a generic multilayer perceptron (MLP) neural network model based on deep learning algorithm for automatic calculation of highly informative deep features from the elevator time series data and based on extracted deep features faults are detected. Sensor data are labelled as healthy or faulty based on the maintenance actions recorded. The remaining healthy data are used for validation of the model to prove its efficacy in terms of avoiding false positives. We have achieved nearly 100% accuracy in fault detection along with avoiding false positives based on new extracted deep features, which outperform the results using existing features. Existing features are also classified with random forest (RF) to compare results. Multilayer perceptron neural network model based on deep learning approach provides better results due to the new deep features extracted from the dataset compared to existing features. Cross-validation method used with multilayer perceptron plays a significant role in improving accuracy of fault detection. Our model provides good classification and is robust against overfitting characteristics. This research will help various predictive maintenance systems to detect false alarms, which will reduce unnecessary visits of service technicians to installation sites.},
booktitle = {2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)},
pages = {904–909},
numpages = {6},
location = {Zaragoza, Spain}
}

@article{10.1007/s00521-018-3663-2,
author = {Ji, Zhendong and Liu, Wei},
title = {Open-circuit fault detection for three-phase inverter based on backpropagation neural network},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {31},
number = {9},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-018-3663-2},
doi = {10.1007/s00521-018-3663-2},
abstract = {To realize real-time fault detection in power devices and enhance reliability of inverter circuits, this paper proposes a detection method based on Park’s transform algorithm and neural network. Park’s transform is applied to obtain the three-phase current base wave amplitude as the characteristic variable for fault detection. Faulty switch devices can be located using a backpropagation neural network in combination with simple logic analyses. The simulation results verify the effectiveness and the feasibility of the proposed method.},
journal = {Neural Comput. Appl.},
month = sep,
pages = {4665–4674},
numpages = {10},
keywords = {BP neural network, Three-phase inverter, Fault detection, Park’s transform}
}

@inproceedings{10.1007/978-3-030-78612-0_5,
author = {Xu, Haitao and Duan, Ruifeng and Yang, Shengsong and Guo, Lei},
title = {An Empirical Study on Data Sampling for Just-in-Time Defect Prediction},
year = {2021},
isbn = {978-3-030-78611-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78612-0_5},
doi = {10.1007/978-3-030-78612-0_5},
abstract = {In this paper, the impact of Data Sampling on Just-in-Time defect prediction is explored. We find that there is a significant negative relationship between the class imbalance ratio of the dataset and the performance of the instant software defect prediction model. Secondly although most software defect data are not as unbalanced as expected, a moderate degree of imbalance is sufficient to affect the performance of traditional learning. This means that if the training data for immediate software defects show moderate or more severe imbalances, one need not expect good defect prediction performance and the data sampling approach to balancing the training data can improve the performance of the model. Finally, the empirical approach shows that although the under-sampling method slightly improves model performance, the different sampling methods do not have a substantial impact on the evaluation of immediate software defect prediction models.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part II},
pages = {54–69},
numpages = {16},
keywords = {Empirical study, Just-in-time defect, Data sampling},
location = {Dublin, Ireland}
}

@article{10.1016/j.engappai.2021.104504,
author = {Vaish, Rachna and Dwivedi, U.D. and Tewari, Saurabh and Tripathi, S.M.},
title = {Machine learning applications in power system fault diagnosis: Research advancements and perspectives},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {106},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2021.104504},
doi = {10.1016/j.engappai.2021.104504},
journal = {Eng. Appl. Artif. Intell.},
month = nov,
numpages = {33},
keywords = {Unsupervised learning, Transfer learning, Supervised learning, Reinforcement learning, Machine learning (ML)}
}

@article{10.3233/JIFS-210229,
author = {Narendiranath Babu, T. and Singh, Prabhu Pal and Somesh, M. and Jha, Harshit Kumar and Rama Prabha, D. and Venkatesan, S. and Ramesh Babu, V.},
title = {Vibration analysis of planetary gearbox using empirical mode decomposition and automatic fault prediction using artificial neural network},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {41},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-210229},
doi = {10.3233/JIFS-210229},
abstract = {The planetary gearbox works on an epicyclic gear train consisting of sun gear meshed with planets gears and ring gear. It got advantages due to its large torque to weight ratio and reduced vibrations. It is mostly employed in analog clocks, automobile automatic gearbox, Lathe machines, and other heavy industries. Therefore, it was imperative to analyze the various faults occurring in a gearbox. Furthermore, come up with a method so that failures can be avoided at the early stage. It was also a reason why it became the field of intensive research. Moreover, the technology of neural networks emerged recently, where machine learning models are trained to detect uneven vibrations on their own. This attracted many researchers to perform the study to devise their own methods of prediction. The central concept of fault prediction by the neural network without human beings’ interference inspired this study. Most industries always wanted to know if their operation line is working fine or not. In this study, an attempt was made to apply the method of deep learning on one of the most critical gearboxes because of its components and functionality. A significant part of the study also involved filtering the vibration data obtained while testing. Comparative analysis of the variation of the peak of acceleration was performed for healthy and faulty conditions.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6407–6427},
numpages = {21},
keywords = {Planetary gearbox, neural networks, deep learning}
}

@article{10.1016/j.infsof.2014.11.006,
author = {He, Peng and Li, Bing and Liu, Xiao and Chen, Jun and Ma, Yutao},
title = {An empirical study on software defect prediction with a simplified metric set},
year = {2015},
issue_date = {March 2015},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {59},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2014.11.006},
doi = {10.1016/j.infsof.2014.11.006},
abstract = {ContextSoftware defect prediction plays a crucial role in estimating the most defect-prone components of software, and a large number of studies have pursued improving prediction accuracy within a project or across projects. However, the rules for making an appropriate decision between within- and cross-project defect prediction when available historical data are insufficient remain unclear. ObjectiveThe objective of this work is to validate the feasibility of the predictor built with a simplified metric set for software defect prediction in different scenarios, and to investigate practical guidelines for the choice of training data, classifier and metric subset of a given project. MethodFirst, based on six typical classifiers, three types of predictors using the size of software metric set were constructed in three scenarios. Then, we validated the acceptable performance of the predictor based on Top-k metrics in terms of statistical methods. Finally, we attempted to minimize the Top-k metric subset by removing redundant metrics, and we tested the stability of such a minimum metric subset with one-way ANOVA tests. ResultsThe study has been conducted on 34 releases of 10 open-source projects available at the PROMISE repository. The findings indicate that the predictors built with either Top-k metrics or the minimum metric subset can provide an acceptable result compared with benchmark predictors. The guideline for choosing a suitable simplified metric set in different scenarios is presented in Table 12. ConclusionThe experimental results indicate that (1) the choice of training data for defect prediction should depend on the specific requirement of accuracy; (2) the predictor built with a simplified metric set works well and is very useful in case limited resources are supplied; (3) simple classifiers (e.g., Na\"{\i}ve Bayes) also tend to perform well when using a simplified metric set for defect prediction; and (4) in several cases, the minimum metric subset can be identified to facilitate the procedure of general defect prediction with acceptable loss of prediction precision in practice.},
journal = {Inf. Softw. Technol.},
month = mar,
pages = {170–190},
numpages = {21},
keywords = {Defect prediction, Metric set simplification, Software metrics, Software quality}
}

@inproceedings{10.1007/978-3-030-27878-6_8,
author = {LaCasse, Phillip M. and Otieno, Wilkistar and Maturana, Francisco P.},
title = {Operationalization of a Machine Learning and Fuzzy Inference-Based Defect Prediction Case Study in a Holonic Manufacturing System},
year = {2019},
isbn = {978-3-030-27877-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27878-6_8},
doi = {10.1007/978-3-030-27878-6_8},
abstract = {Industry 4.0 capabilities have enabled manufacturers to collect and analyze smart manufacturing data across a broad array of diverse domains including but not limited to scheduling, production, maintenance, process, and quality. This development necessarily proceeds in a logical sequence by which first the organization develops the capability to capture and store this data and, at best concurrently but frequently lagging, develops and refines the competencies to analyze and effectively utilize it. This research presents an applied case study in surface mount technology (SMT) manufacture of printed circuit board (PCB) assemblies. Parametric data captured at the solder paste inspection (SPI) station is analyzed with machine learning models to identify patterns and relationships that can be harnessed to preempt electrical defects at downline inspection stations. This project is enabled by the recent conclusion of an Industrial Internet of Things (IIoT) capability enhancement at the manufacturing facility from which the data is drawn and is the logical next step in achieving value from the newly-available smart manufacturing data. The operationalization of this analysis is contextualized within the product-resource-order-staff architecture (PROSA) of a Holonic Manufacturing Systems (HMS). A Trigger Holon is nested between the Resource Holarchy and Product Holarchy that, at scheduling, distributes implementation instructions for the defect-prediction model. The Defect Prediction Holon is containerized within the Product Holarchy and provides instructions for corrective action when the model flags a record as exhibiting increased probability of a downline electrical defect.},
booktitle = {Industrial Applications of Holonic and Multi-Agent Systems: 9th International Conference, HoloMAS 2019, Linz, Austria, August 26–29, 2019, Proceedings},
pages = {96–104},
numpages = {9},
keywords = {Ball grid array, Solder paste inspection, Surface mount technology, Printed circuit board, Defect prediction, Machine learning, Holonic manufacturing system},
location = {Linz, Austria}
}

@inproceedings{10.1145/3439961.3439979,
author = {Santos, Geanderson and Figueiredo, Eduardo and Veloso, Adriano and Viggiato, Markos and Ziviani, Nivio},
title = {Predicting Software Defects with Explainable Machine Learning},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439979},
doi = {10.1145/3439961.3439979},
abstract = {Most software systems must evolve to cope with stakeholders’ requirements and fix existing defects. Hence, software defect prediction represents an area of interest in both academia and the software industry. As a result, predicting software defects can help the development team to maintain substantial levels of software quality. For this reason, machine learning models have increased in popularity for software defect prediction and have demonstrated effectiveness in many scenarios. In this paper, we evaluate a machine learning approach for selecting features to predict software module defects. We use a tree boosting algorithm that receives as input a training set comprising records of software features encoding characteristics of each module and outputs whether the corresponding module is defective prone. For nine projects within the widely known NASA data program, we build prediction models from a set of easy-to-compute module features. We then sample this sizable model space by randomly selecting software features to compose each model. This significant number of models allows us to structure our work along model understandability and predictive accuracy. We argue that explaining model predictions is meaningful to provide information to developers on features related to each module defective-prone. We show that (i) features that contribute most to finding the best models may vary depending on the project, and (ii) effective models are highly understandable based on a survey with 40 developers.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {18},
numpages = {10},
keywords = {software defects, explainable models, SHAP values, NASA datasets},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@inproceedings{10.1145/3468264.3468549,
author = {Cai, Yan and Yun, Hao and Wang, Jinqiu and Qiao, Lei and Palsberg, Jens},
title = {Sound and efficient concurrency bug prediction},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468549},
doi = {10.1145/3468264.3468549},
abstract = {Concurrency bugs are extremely difficult to detect. Recently, several dynamic techniques achieve sound analysis. M2 is even complete for two threads. It is designed to decide whether two events can occur consecutively. However, real-world concurrency bugs can involve more events and threads. Some can occur when the order of two or more events can be exchanged even if they occur not consecutively. We propose a new technique SeqCheck to soundly decide whether a sequence of events can occur in a specified order. The ordered sequence represents a potential concurrency bug. And several known forms of concurrency bugs can be easily encoded into event sequences where each represents a way that the bug can occur. To achieve it, SeqCheck explicitly analyzes branch events and includes a set of efficient algorithms. We show that SeqCheck is sound; and it is also complete on traces of two threads.  We have implemented SeqCheck to detect three types of concurrency bugs and evaluated it on 51 Java benchmarks producing up to billions of events. Compared with M2 and other three recent sound race detectors, SeqCheck detected 333 races in ~30 minutes; while others detected from 130 to 285 races in ~6 to ~12 hours. SeqCheck detected 20 deadlocks in ~6 seconds. This is only one less than Dirk; but Dirk spent more than one hour. SeqCheck also detected 30 atomicity violations in ~20 minutes. The evaluation shows SeqCheck can significantly outperform existing concurrency bug detectors.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {255–267},
numpages = {13},
keywords = {deadlocks, data races, atomicity violations, Concurrency bugs},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1109/CCBD.2015.22,
author = {Liu, Lu and Li, Kewen and Shao, Mingwen and Liu, Wenying},
title = {Fuzzy Integral Based on Mutual Information for Software Defect Prediction},
year = {2015},
isbn = {9781467383509},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCBD.2015.22},
doi = {10.1109/CCBD.2015.22},
abstract = {Software defect prediction is an important research direction in the field of software reliability. In the process of software defect prediction, the interaction among the various attributes will affect classification performance of classifier. In order to fully reflect the importance of attributes and the interaction among the attributes in the process of classification, the paper proposes a fuzzy integral method based on the mutual information (MIFI) to predict the software defect. The algorithm uses the mutual information between the various attributes to determined the fuzzy measure set function, which reflect the attributes information and interaction information among attributes. The experimental results show that MIFI algorithm proposed in this paper can achieve better prediction effect than other three methods.},
booktitle = {Proceedings of the 2015 International Conference on Cloud Computing and Big Data (CCBD)},
pages = {93–96},
numpages = {4},
series = {CCBD '15}
}

@article{10.1504/IJBIC.2018.092808,
title = {An improved twin support vector machine based on multi-objective cuckoo search for software defect prediction},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {11},
number = {4},
issn = {1758-0366},
url = {https://doi.org/10.1504/IJBIC.2018.092808},
doi = {10.1504/IJBIC.2018.092808},
abstract = {Recently, software defect prediction SDP has drawn much attention as software size becomes larger and consumers hold higher reliability expectations. The premise of SDP is to guide the detection of software bugs and to conserve computational resources. However, in prior research, data imbalances among software defect modules were largely ignored to focus instead on how to improve defect prediction accuracy. In this paper, a novel SDP model based on twin support vector machines TSVM and a multi-objective cuckoo search MOCS is proposed, called MOCSTSVM. We set the probability of detection and the probability of false alarm as the SDP objectives. We use TSVM to predict defected modules and employ MOCS to optimise TSVM for this dual-objective optimisation problem. To test our approach, we conduct a series of experiments on a public dataset from the PROMISE repository. The experimental results demonstrate that our approach achieves good performance compared with other SDP models.},
journal = {Int. J. Bio-Inspired Comput.},
month = jan,
pages = {282–291},
numpages = {10}
}

@article{10.1007/s00521-021-05811-3,
author = {Mehta, Sweta and Patnaik, K. Sridhar},
title = {Improved prediction of software defects using ensemble machine learning techniques},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05811-3},
doi = {10.1007/s00521-021-05811-3},
abstract = {Software testing process is a crucial part in software development. Generally the errors made by developers get fixed at a later stage of the software development process. This increases the impact of the defect. To prevent this, defects need to be predicted during the initial days of the software development, which in turn helps in efficient utilization of the testing resources. Defect prediction process involves classification of software modules into defect prone and non-defect prone. This paper aims to reduce the impact of two major issues faced during defect prediction, i.e., data imbalance and high dimensionality of the defect datasets. In this research work, various software metrics are evaluated using feature selection techniques such as Recursive Feature Elimination (RFE), Correlation-based feature selection, Lasso, Ridge, ElasticNet and Boruta. Logistic Regression, Decision Trees, K-nearest neighbor, Support Vector Machines and Ensemble Learning are some of the algorithms in machine learning that have been used in combination with the feature extraction and feature selection techniques for classifying the modules in software as defect prone and non-defect prone. The proposed model uses combination of Partial Least Square (PLS) Regression and RFE for dimension reduction which is further combined with Synthetic Minority Oversampling Technique due to the imbalanced nature of the used datasets. It has been observed that XGBoost and Stacking Ensemble technique gave best results for all the datasets with defect prediction accuracy more than 0.9 as compared to algorithms used in the research work.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {10551–10562},
numpages = {12},
keywords = {Stacking ensemble classifier, XGBoost, Machine learning algorithms, Data imbalance, Dimension reduction, Defect prediction}
}

@article{10.1007/s00521-021-06158-5,
author = {Nevendra, Meetesh and Singh, Pradeep},
title = {Defect count prediction via metric-based convolutional neural network},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {22},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-06158-5},
doi = {10.1007/s00521-021-06158-5},
abstract = {With the increasing complexity and volume of the software, the number of defects in software modules is also increasing consistently, which affects the quality and delivery of software in time and budget. To improve the software quality and timely allocation of resources, defects should be detected at the initial phases of the software development life cycle. However, the existing defect prediction methodology based on high-dimensional and limited data only focuses on predicting defective modules. In contrast, the number of defects present in the software module has not been explored so far, especially using deep neural network. Also, whether deep learning could enhance the performance of defect count prediction is still uninvestigated. To fill this gap, we proposed an improved Convolutional Neural Network model, called metrics-based convolutional neural network (MB-CNN), which combines the advantages of appropriate metrics and an improved CNN method by introducing dropout for regularization between convolutions and dense layer. The proposed method predicts the presented defect count in the software module for homogeneous scenarios as within-version and cross-version. The experimental results show that, on average, across the fourteen real-world defect datasets, the proposed approach improves Li’s CNN architecture by 31% in within-version prediction and 28% in cross-version prediction. Moreover, the Friedman ranking test and Wilcoxon nonparametric test reveal the usefulness of our proposed approach over ten benchmark learning algorithms to predict defect count.},
journal = {Neural Comput. Appl.},
month = nov,
pages = {15319–15344},
numpages = {26},
keywords = {Cross-project, CNN, Deep learning, Software defect count prediction}
}

@inproceedings{10.1145/3412841.3442019,
author = {Zhao, Kunsong and Xu, Zhou and Yan, Meng and Tang, Yutian and Fan, Ming and Catolino, Gemma},
title = {Just-in-time defect prediction for Android apps via imbalanced deep learning model},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442019},
doi = {10.1145/3412841.3442019},
abstract = {Android mobile apps have played important roles in our daily life and work. To meet new requirements from users, the mobile apps encounter frequent updates, which involves in a large quantity of code commits. Previous studies proposed to apply Just-in-Time (JIT) defect prediction for mobile apps to timely identify whether new code commits can introduce defects into apps, aiming to assure the quality of mobile apps. In general, the number of defective commit instances is much fewer than that of clean ones, in other words, the defect data is class imbalanced. In this work, we propose a novel Imbalanced Deep Learning model, called IDL, to conduct JIT defect prediction task for Android mobile apps. More specifically, we introduce a state-of-the-art cost-sensitive cross-entropy loss function into the deep neural network to learn the high-level feature representation, in which the loss function alleviates the class imbalance issue by taking the prior probability of the two types of classes into account. We conduct experiments on a benchmark defect data consisting of 12 Android mobile apps. The results of rigorous experiments show that our proposed IDL model performs significantly better than 23 comparative imbalanced learning methods in terms of Matthews correlation coefficient performance indicator.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1447–1454},
numpages = {8},
keywords = {JIT defect prediction, imbalanced learning, mobile apps},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@article{10.1007/s11219-015-9287-1,
author = {Ryu, Duksan and Jang, Jong-In and Baik, Jongmoon},
title = {A transfer cost-sensitive boosting approach for cross-project defect prediction},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-015-9287-1},
doi = {10.1007/s11219-015-9287-1},
abstract = {Software defect prediction has been regarded as one of the crucial tasks to improve software quality by effectively allocating valuable resources to fault-prone modules. It is necessary to have a sufficient set of historical data for building a predictor. Without a set of sufficient historical data within a company, cross-project defect prediction (CPDP) can be employed where data from other companies are used to build predictors. In such cases, a transfer learning technique, which extracts common knowledge from source projects and transfers it to a target project, can be used to enhance the prediction performance. There exists the class imbalance problem, which causes difficulties for the learner to predict defects. The main impacts of imbalanced data under cross-project settings have not been investigated in depth. We propose a transfer cost-sensitive boosting method that considers both knowledge transfer and class imbalance for CPDP when given a small amount of labeled target data. The proposed approach performs boosting that assigns weights to the training instances with consideration of both distributional characteristics and the class imbalance. Through comparative experiments with the transfer learning and the class imbalance learning techniques, we show that the proposed model provides significantly higher defect detection accuracy while retaining better overall performance. As a result, a combination of transfer learning and class imbalance learning is highly effective for improving the prediction performance under cross-project settings. The proposed approach will help to design an effective prediction model for CPDP. The improved defect prediction performance could help to direct software quality assurance activities and reduce costs. Consequently, the quality of software can be managed effectively.},
journal = {Software Quality Journal},
month = mar,
pages = {235–272},
numpages = {38},
keywords = {Transfer learning, Software defect prediction, Cross-project defect prediction, Cost-sensitive learning, Class imbalance, Boosting}
}

@inproceedings{10.1007/978-3-030-30952-7_16,
author = {Liu, Xinyue and Li, Yanhui},
title = {Is Bigger Data Better for Defect Prediction: Examining the Impact of Data Size on Supervised and Unsupervised Defect Prediction},
year = {2019},
isbn = {978-3-030-30951-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30952-7_16},
doi = {10.1007/978-3-030-30952-7_16},
abstract = {Defect prediction could help software practitioners to predict the future occurrence of bugs in the software code regions. In order to improve the accuracy of defect prediction, dozens of supervised and unsupervised methods have been put forward and achieved good results in this field. One limiting factor of defect prediction is that the data size of defect data is not big, which restricts the scope of application with defect prediction models. In this study, we try to construct bigger defect datasets by merging available datasets with the same measurement dimension and check whether bigger data will bring better defect prediction performance with supervised and unsupervised models or not. The results of our experiment reveal that larger-scale dataset doesn’t bring improvements of both supervised and unsupervised classifiers.},
booktitle = {Web Information Systems and Applications: 16th International Conference, WISA 2019, Qingdao, China, September 20-22, 2019, Proceedings},
pages = {138–150},
numpages = {13},
keywords = {Defect prediction, Supervised, Classifier, Data size},
location = {Qingdao, China}
}

@inproceedings{10.1145/3191697.3213793,
author = {Jindal, Vasu},
title = {Towards an intelligent fault prediction code editor to improve software quality using deep learning},
year = {2018},
isbn = {9781450355131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3191697.3213793},
doi = {10.1145/3191697.3213793},
abstract = {Software quality assurance has become the pillar for success in software companies. High quality, low maintenance programs can be achieved if fault-prone modules can be identified early in the development lifecycle. In this paper, we propose a new intelligent Integrated Development Environment (IDE) which seamlessly allow programmers to test their code for faults using prior source code databases. Our IDE is built upon deep learning models for making recommendations. The editor also gives scores to programmers on their program design. We evaluate and validate our approach using famous NASA code repositories.},
booktitle = {Companion Proceedings of the 2nd International Conference on the Art, Science, and Engineering of Programming},
pages = {222–223},
numpages = {2},
keywords = {software quality, quality assurance, fault prediction, Deep learning},
location = {Nice, France},
series = {Programming '18}
}

@article{10.1007/s10664-020-09878-9,
author = {Bangash, Abdul Ali and Sahar, Hareem and Hindle, Abram and Ali, Karim},
title = {On the time-based conclusion stability of cross-project defect prediction models},
year = {2020},
issue_date = {Nov 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09878-9},
doi = {10.1007/s10664-020-09878-9},
abstract = {Researchers in empirical software engineering often make claims based on observable data such as defect reports. Unfortunately, in many cases, these claims are generalized beyond the data sets that have been evaluated. Will the researcher’s conclusions hold a year from now for the same software projects? Perhaps not. Recent studies show that in the area of Software Analytics, conclusions over different data sets are usually inconsistent. In this article, we empirically investigate whether conclusions in the area of cross-project defect prediction truly exhibit stability throughout time or not. Our investigation applies a time-aware evaluation approach where models are trained only on the past, and evaluations are executed only on the future. Through this time-aware evaluation, we show that depending on which time period we evaluate defect predictors, their performance, in terms of F-Score, the area under the curve (AUC), and Mathews Correlation Coefficient (MCC), varies and their results are not consistent. The next release of a product, which is significantly different from its prior release, may drastically change defect prediction performance. Therefore, without knowing about the conclusion stability, empirical software engineering researchers should limit their claims of performance within the contexts of evaluation, because broad claims about defect prediction performance might be contradicted by the next upcoming release of a product under analysis.},
journal = {Empirical Softw. Engg.},
month = nov,
pages = {5047–5083},
numpages = {37},
keywords = {Time-aware evaluation, Defect prediction, Conclusion stability}
}

@inproceedings{10.1109/IECON43393.2020.9254448,
author = {Ossig, Daniel L. and Kurzenberger, Kevin and Speidel, Simon A. and Henning, Kay-Uwe and Sawodny, Oliver},
title = {Sensor Fault Detection Using an Extended Kalman Filter and Machine Learning for a Vehicle Dynamics Controller},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON43393.2020.9254448},
doi = {10.1109/IECON43393.2020.9254448},
abstract = {This paper describes a new sensor fault detection approach for a vehicle dynamics controller. The detection problem is divided into two parts. First, a model-based observer is used to incorporate the knowledge of the system into the fault detection. Next, a data driven classification algorithm based on kalman filter performance metrics is used. This machine learning algorithm is trained using real vehicle data and, therefore, able to handle model uncertainties and disturbances inherently. Due to the usage of a nonlinear observer, the fault detection is suitable up to the limits of handling. The presented structure offers the possibility to use the same classification algorithm for different vehicles as the vehicles’ behavior is abstracted in the observer. Therefore, the need of extensive training data is reduced. This paper focuses on the development of features and gives a first proof of concept. The developed fault detection is validated with real car measurements.},
booktitle = {IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society},
pages = {361–366},
numpages = {6},
location = {Singapore, Singapore}
}

@article{10.1016/j.asoc.2016.08.002,
author = {ztrk, Muhammed Maruf and Zengin, Ahmet},
title = {How repeated data points affect bug prediction performance},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.08.002},
doi = {10.1016/j.asoc.2016.08.002},
abstract = {Graphical abstractDisplay Omitted HighlightsPresents a novel pre-processing algorithm for defect data sets.Discusses the effects of the use of low level metrics in bug prediction.Compares repeated data points industrial versus open-source projects.Provides tips to obtain better bug prediction results. In defect prediction studies, open-source and real-world defect data sets are frequently used. The quality of these data sets is one of the main factors affecting the validity of defect prediction methods. One of the issues is repeated data points in defect prediction data sets. The main goal of the paper is to explore how low-level metrics are derived. This paper also presents a cleansing algorithm that removes repeated data points from defect data sets. The method was applied on 20 data sets, including five open source sets, and area under the curve (AUC) and precision performance parameters have been improved by 4.05% and 6.7%, respectively. In addition, this work discusses how static code metrics should be used in bug prediction. The study provides tips to obtain better defect prediction results.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1051–1061},
numpages = {11},
keywords = {Software metrics, Repeated data, Bug prediction}
}

@article{10.1016/j.asoc.2016.04.032,
author = {Malhotra, Ruchika},
title = {An empirical framework for defect prediction using machine learning techniques with Android software},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.04.032},
doi = {10.1016/j.asoc.2016.04.032},
abstract = {Display Omitted Use of appropriate and large number data sets for comparing 18 ML techniques for defect prediction using object-oriented metrics.Effective performance of the predicted models assessed using appropriate performance measures.Reliability of the results evaluated using statistical test and post-hoc analysis.Validating the predicted models using inter-release validation on various releases of seven application packages of Android software. ContextSoftware defect prediction is important for identification of defect-prone parts of a software. Defect prediction models can be developed using software metrics in combination with defect data for predicting defective classes. Various studies have been conducted to find the relationship between software metrics and defect proneness, but there are few studies that statistically determine the effectiveness of the results. ObjectiveThe main objectives of the study are (i) comparison of the machine-learning techniques using data sets obtained from popular open source software (ii) use of appropriate performance measures for measuring the performance of defect prediction models (iii) use of statistical tests for effective comparison of machine-learning techniques and (iv) validation of models over different releases of data sets. MethodIn this study we use object-oriented metrics for predicting defective classes using 18 machine-learning techniques. The proposed framework has been applied to seven application packages of well known, widely used Android operating system viz. Contact, MMS, Bluetooth, Email, Calendar, Gallery2 and Telephony. The results are validated using 10-fold and inter-release validation methods. The reliability and significance of the results are evaluated using statistical test and post-hoc analysis. ResultsThe results show that the area under the curve measure for Nave Bayes, LogitBoost and Multilayer Perceptron is above 0.7 in most of the cases. The results also depict that the difference between the ML techniques is statistically significant. However, it is also proved that the Support Vector Machines based techniques such as Support Vector Machines and voted perceptron do not possess the predictive capability for predicting defects. ConclusionThe results confirm the predictive capability of various ML techniques for developing defect prediction models. The results also confirm the superiority of one ML technique over the other ML techniques. Thus, the software engineers can use the results obtained from this study in the early phases of the software development for identifying defect-prone classes of given software.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1034–1050},
numpages = {17},
keywords = {Statistical tests, Software defect proneness, Object-oriented metrics, Machine-learning, Inter-release validation}
}

@article{10.1155/2021/5558561,
author = {Shao, Yanli and Zhao, Jingru and Wang, Xingqi and Wu, Weiwei and Fang, Jinglong and Gao, Honghao},
title = {Research on Cross-Company Defect Prediction Method to Improve Software Security},
year = {2021},
issue_date = {2021},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2021},
issn = {1939-0114},
url = {https://doi.org/10.1155/2021/5558561},
doi = {10.1155/2021/5558561},
abstract = {As the scale and complexity of software increase, software security issues have become the focus of society. Software defect prediction (SDP) is an important means to assist developers in discovering and repairing potential defects that may endanger software security in advance and improving software security and reliability. Currently, cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) are widely studied to improve the defect prediction performance, but there are still problems such as inconsistent metrics and large differences in data distribution between source and target projects. Therefore, a new CCDP method based on metric matching and sample weight setting is proposed in this study. First, a clustering-based metric matching method is proposed. The multigranularity metric feature vector is extracted to unify the metric dimension while maximally retaining the information contained in the metrics. Then use metric clustering to eliminate metric redundancy and extract representative metrics through principal component analysis (PCA) to support one-to-one metric matching. This strategy not only solves the metric inconsistent and redundancy problem but also transforms the cross-company heterogeneous defect prediction problem into a homogeneous problem. Second, a sample weight setting method is proposed to transform the source data distribution. Wherein the statistical source sample frequency information is set as an impact factor to increase the weight of source samples that are more similar to the target samples, which improves the data distribution similarity between the source and target projects, thereby building a more accurate prediction model. Finally, after the above two-step processing, some classical machine learning methods are applied to build the prediction model, and 12 project datasets in NASA and PROMISE are used for performance comparison. Experimental results prove that the proposed method has superior prediction performance over other mainstream CCDP methods.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {19}
}

@inproceedings{10.1145/3379247.3379278,
author = {Ahmed, Md. Razu and Ali, Md. Asraf and Ahmed, Nasim and Zamal, Md. Fahad Bin and Shamrat, F.M. Javed Mehedi},
title = {The Impact of Software Fault Prediction in Real-World Application: An Automated Approach for Software Engineering},
year = {2020},
isbn = {9781450376730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379247.3379278},
doi = {10.1145/3379247.3379278},
abstract = {Software fault prediction and proneness has long been considered as a critical issue for the tech industry and software professionals. In the traditional techniques, it requires previous experience of faults or a faulty module while detecting the software faults inside an application. An automated software fault recovery models enable the software to significantly predict and recover software faults using machine learning techniques. Such ability of the feature makes the software to run more effectively and reduce the faults, time and cost. In this paper, we proposed a software defect predictive development models using machine learning techniques that can enable the software to continue its projected task. Moreover, we used different prominent evaluation benchmark to evaluate the model's performance such as ten-fold cross-validation techniques, precision, recall, specificity, f 1 measure, and accuracy. This study reports a significant classification performance of 98-100% using SVM on three defect datasets in terms of f1 measure. However, software practitioners and researchers can attain independent understanding from this study while selecting automated task for their intended application.},
booktitle = {Proceedings of 2020 6th International Conference on Computing and Data Engineering},
pages = {247–251},
numpages = {5},
keywords = {Software fault, Software engineering, Machine learning, Defect prediction},
location = {Sanya, China},
series = {ICCDE '20}
}

@article{10.1007/s10845-020-01591-0,
author = {Hsu, Chia-Yu and Liu, Wei-Chen},
title = {Multiple time-series convolutional neural network for fault detection and diagnosis and empirical study in semiconductor manufacturing},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {3},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-020-01591-0},
doi = {10.1007/s10845-020-01591-0},
abstract = {The development of information technology and process technology have been enhanced the rapid changes in high-tech products and smart manufacturing, specifications become more sophisticated. Large amount of sensors are installed to record equipment condition during the manufacturing process. In particular, the characteristics of sensor data are temporal. Most the existing approaches for time series classification are not applicable to adaptively extract the effective feature from a large number of sensor data, accurately detect the fault, and provide the assignable cause for fault diagnosis. This study aims to propose a multiple time-series convolutional neural network (MTS-CNN) model for fault detection and diagnosis in semiconductor manufacturing. This study incorporates data augmentation with sliding window to generate amounts of subsequences and thus to enhance the diversity and avoid over-fitting. The key features of equipment sensor can be learned automatically through stacked convolution-pooling layers. The importance of each sensor is also identified through the diagnostic layer in the proposed MTS-CNN. An empirical study from a wafer fabrication was conducted to validate the proposed MTS-CNN and compare the performance among the other multivariate time series classification methods. The experimental results demonstrate that the MTS-CNN can accurately detect the fault wafers with high accuracy, recall and precision, and outperforms than other existing multivariate time series classification methods. Through the output value of the diagnostic layer in MTS-CNN, we can identify the relationship between each fault and different sensors and provider valuable information to associate the excursion for fault diagnosis.},
journal = {J. Intell. Manuf.},
month = mar,
pages = {823–836},
numpages = {14},
keywords = {Smart manufacturing, Convolutional neural network, Deep learning, Time series classification, Fault detection and diagnosis}
}

@inproceedings{10.1007/978-3-030-87007-2_28,
author = {Kumar, Lov and Dastidar, Triyasha Ghosh and Murthy Neti, Lalitha Bhanu and Satapathy, Shashank Mouli and Misra, Sanjay and Kocher, Vipul and Padmanabhuni, Srinivas},
title = {Deep-Learning Approach with DeepXplore for Software Defect Severity Level Prediction},
year = {2021},
isbn = {978-3-030-87006-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87007-2_28},
doi = {10.1007/978-3-030-87007-2_28},
abstract = {Fixing the defects of earlier releases and working on fast and efficient fixing of those software defects is detrimental for the release of further versions. Bug tracking systems like Bugzilla get thousands of software defect reports every day. Manually handling those report to assign severity to the defects is not feasible. Earlier traditional Machine Learning methods have been used to predict the severity level from the defect description. This paper presents different deep learning models to predict defect severity level. Furthermore, the deep neural network was tested using a framework developed similar to that DeepXplore. Different word-embedding techniques, feature-selection techniques, sampling techniques and deep learning models are analyzed and compared for this study. In this paper, we have considered Descriptive statistics, Box-plot, and Significant tests to compare the developed models for defect severity level prediction. The three performance metrics used for testing the models are AUC, Accuracy and Neuron Coverage. This is a preliminary study on DNN testing on this dataset. Thus, the paper focuses on DeepXplore DNN testing technique. However further studies would be undertaken on comparative analysis of different DNN testing techniques on this dataset.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part VII},
pages = {398–410},
numpages = {13},
keywords = {Word embedding, Deep learning, Feature selection, Imbalance handling, Severity prediction},
location = {Cagliari, Italy}
}

@inproceedings{10.1145/3094243.3094254,
author = {Wang, Miaoyiquan and Tong, Weiguo and Liu, Shibo},
title = {Fault Detection for Power Line Based on Convolution Neural Network},
year = {2017},
isbn = {9781450352321},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3094243.3094254},
doi = {10.1145/3094243.3094254},
abstract = {In order to solve the problem of power line fault detection, we proposed to introduce convolutional neural network (CNN) into the field of power line fault detection. In this paper, we describe a novel detection method which combines the sliding window approach and the output map information. Our algorithm can be divide into three steps. The first step uses CNN combined with sliding window approach to make predictions of all part of input image and achieves the output map. In the second step, the output map is preprocessed to make it more conducive to localization. Finally, object detection is accomplished according to the information of the preprocessed output map. Experimental results show that our algorithm can effectively solve the problem of power line fault detection in complex background.},
booktitle = {Proceedings of the 2017 International Conference on Deep Learning Technologies},
pages = {95–101},
numpages = {7},
keywords = {Sliding window, Power line fault detection, Output map, Digital image processing, Deep learning, Convolutional neural network},
location = {Chengdu, China},
series = {ICDLT '17}
}

@inproceedings{10.1109/RAISE.2019.00016,
author = {Humphreys, Jack and Dam, Hoa Khanh},
title = {An explainable deep model for defect prediction},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/RAISE.2019.00016},
doi = {10.1109/RAISE.2019.00016},
abstract = {Self attention transformer encoders represent an effective method for sequence to class prediction tasks as they can disentangle long distance dependencies and have many regularising effects. We achieve results substantially better than state of the art in one such task, namely, defect prediction and with many added benefits. Existing techniques do not normalise for correlations that are inversely proportional to the usefulness of the prediction but do, in fact, go further, specifically exploiting these features which is tantamount to data leakage. Our model is end-to-end trainable and has the potential capability to explain its prediction. This explainability provides insights and potential causes of a model's decisions, the absence of which has stopped defect prediction from gaining any traction in industry.},
booktitle = {Proceedings of the 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
pages = {49–55},
numpages = {7},
keywords = {defect prediction, deep learning},
location = {Montreal, Quebec, Canada},
series = {RAISE '19}
}

@article{10.3233/KES-200029,
author = {Singh, Pradeep and Verma, Shrish},
title = {ACO based comprehensive model for software fault prediction},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {24},
number = {1},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-200029},
doi = {10.3233/KES-200029},
abstract = {The comprehensive models can be used for software quality modelling which involves prediction of low-quality modules using interpretable rules. Such comprehensive model can guide the design and testing team to focus on the poor quality modules, thereby, limited resources allocated for software quality inspection can be targeted only towards modules that are likely to be defective. Ant Colony Optimization (ACO) based learner is one potential way to obtain rules that can classify the software modules faulty and not faulty. This paper investigates ACO based mining approach with ROC based rule quality updation to constructs a rule-based software fault prediction model with useful metrics. We have also investigated the effect of feature selection on ACO based and other benchmark algorithms. We tested the proposed method on several publicly available software fault data sets. We compared the performance of ACO based learning with the results of three benchmark classifiers on the basis of area under the receiver operating characteristic curve. The evaluation of performance measure proves that the ACO based learner outperforms other benchmark techniques.},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {63–71},
numpages = {9},
keywords = {ACO, fault prediction, Software metric}
}

@article{10.1504/IJISTA.2016.076102,
author = {Rong, Xiaotao and Li, Feixiang and Cui, Zhihua},
title = {A model for software defect prediction using support vector machine based on CBA},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {15},
number = {1},
issn = {1740-8865},
url = {https://doi.org/10.1504/IJISTA.2016.076102},
doi = {10.1504/IJISTA.2016.076102},
abstract = {Software defection prediction is not only crucial for improving software quality, but also helpful for software test effort estimation. As is well-known, 80% of the fault happens in 20% of the modules. Therefore, we need to find out the most error prone modules accurately and correct them in time to save time, money, and energy. Support vector machine SVM is an advanced classification method that fits the defection classification. However, studies show that, the value of parameters of SVM model has a remarkable influence on its classification accuracy and the selection process lacks theory guidance that makes the SVM model uncertainty and low efficiency. In this paper, a CBA-SVM software defect prediction model is proposed, which take advantage of the non-linear computing ability of SVM model and optimisation capacity of bat algorithm with centroid strategy CBA. Through the experimental comparison with other models, CBA-SVM is proved to have a higher accuracy.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = apr,
pages = {19–34},
numpages = {16}
}

@article{10.1504/ijiei.2021.120322,
author = {Lakra, Kirti and Chug, Anuradha},
title = {Application of metaheuristic techniques in software quality prediction: a systematic mapping study},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {4},
issn = {1758-8715},
url = {https://doi.org/10.1504/ijiei.2021.120322},
doi = {10.1504/ijiei.2021.120322},
abstract = {This paper focuses on the systematic review of various metaheuristic techniques employed for analysing different software quality aspects, including fault proneness, defect anticipation, change proneness, maintainability prediction, and software reliability prediction. It is observed that machine learning algorithms are still popular models, but metaheuristic algorithms are also gaining popularity in the field of software quality measurement. This is due to the fact that metaheuristic algorithms are more efficient in solving real-world, search-based, and optimisation problems. Initially, 90 papers were considered and analysed for conducting this study from 2010 to 2020, and 55 studies were shortlisted based on predesigned quality evaluation standards. Resultantly, particle swarm optimisation (PSO), and genetic algorithms came out as the most prominently used metaheuristic techniques for developing software quality models in 36.3% and 27.2% of the shortlisted studies, respectively. The current review will benefit other researchers by providing an insight into the current trends in software quality domain.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {355–399},
numpages = {44},
keywords = {software quality improvement, software maintainability prediction, software reliability prediction, software change prediction, software defect prediction, software fault proneness, software quality, object-oriented metrics, metaheuristic techniques}
}

@inproceedings{10.1109/QSIC.2012.19,
author = {Wang, Jun and Shen, Beijun and Chen, Yuting},
title = {Compressed C4.5 Models for Software Defect Prediction},
year = {2012},
isbn = {9780769548333},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QSIC.2012.19},
doi = {10.1109/QSIC.2012.19},
abstract = {Defects in every software must be handled properly, and the number of defects directly reflects the quality of a software. In recent years, researchers have applied data mining and machine learning methods to predicting software defects. However, in their studies, the method in which the machine learning models are directly adopted may not be precise enough. Optimizing the machine learning models used in defects prediction will improve the prediction accuracy. In this paper, aiming at the characteristics of the metrics mined from the open source software, we proposed three new defect prediction models based on C4.5 model. The new models introduce the Spearman's rank correlation coefficient to the basis of choosing root node of the decision tree which makes the models better on defects prediction. In order to verify the effectiveness of the improved models, an experimental scheme is designed. In the experiment, we compared the prediction accuracies of the existing models and the improved models and the result showed that the improved models reduced the size of the decision tree by 49.91% on average and increased the prediction accuracy by 4.58% and 4.87% on two modules used in the experiment.},
booktitle = {Proceedings of the 2012 12th International Conference on Quality Software},
pages = {13–16},
numpages = {4},
keywords = {Software Repository, Defect Prediction, Decision Tree Learner, Data Mining},
series = {QSIC '12}
}

@article{10.1007/s10462-017-9563-5,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {A study on software fault prediction techniques},
year = {2019},
issue_date = {February  2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {2},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-017-9563-5},
doi = {10.1007/s10462-017-9563-5},
abstract = {Software fault prediction aims to identify fault-prone software modules by using some underlying properties of the software project before the actual testing process begins. It helps in obtaining desired software quality with optimized cost and effort. Initially, this paper provides an overview of the software fault prediction process. Next, different dimensions of software fault prediction process are explored and discussed. This review aims to help with the understanding of various elements associated with fault prediction process and to explore various issues involved in the software fault prediction. We search through various digital libraries and identify all the relevant papers published since 1993. The review of these papers are grouped into three classes: software metrics, fault prediction techniques, and data quality issues. For each of the class, taxonomical classification of different techniques and our observations have also been presented. The review and summarization in the tabular form are also given. At the end of the paper, the statistical analysis, observations, challenges, and future directions of software fault prediction have been discussed.},
journal = {Artif. Intell. Rev.},
month = feb,
pages = {255–327},
numpages = {73},
keywords = {Taxonomic classification, Software metrics, Software fault prediction, Software fault datasets, Fault prediction techniques}
}

@article{10.1007/s00521-019-04651-6,
author = {Dib, M. A. and Oliveira, N. J. and Marques, A. E. and Oliveira, M. C. and Fernandes, J. V. and Ribeiro, B. M. and Prates, P. A.},
title = {Single and ensemble classifiers for defect prediction in sheet metal forming under variability},
year = {2020},
issue_date = {Aug 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-019-04651-6},
doi = {10.1007/s00521-019-04651-6},
abstract = {This paper presents an approach, based on machine learning techniques, to predict the occurrence of defects in sheet metal forming processes, exposed to sources of scatter in the material properties and process parameters. An empirical analysis of performance of ML techniques is presented, considering both single learning and ensemble models. These are trained using data sets populated with numerical simulation results of two sheet metal forming processes: U-Channel and Square Cup. Data sets were built for three distinct steel sheets. A total of eleven input features, related to the mechanical properties, sheet thickness and process parameters, were considered; also, two types of defects (outputs) were analysed for each process. The sampling data were generated, assuming that the variability of each input feature is described by a normal distribution. For a given type of defect, most single classifiers show similar performances, regardless of the material. When comparing single learning and ensemble models, the latter can provide an efficient alternative. The fact that ensemble predictive models present relatively high performances, combined with the possibility of reconciling model bias and variance, offer a promising direction for its application in industrial environment.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {12335–12349},
numpages = {15},
keywords = {Sheet metal forming, Defect prediction, Ensemble learning, Machine learning}
}

@article{10.1002/smr.2172,
author = {Gong, Lina and Jiang, Shujuan and Jiang, Li},
title = {An improved transfer adaptive boosting approach for mixed‐project defect prediction},
year = {2019},
issue_date = {October 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {10},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2172},
doi = {10.1002/smr.2172},
abstract = {Software defect prediction (SDP) has been a very important research topic in software engineering, since it can provide high‐quality results when given sufficient historical data of the project. Unfortunately, there are not abundant data to bulid the defect prediction model at the beginning of a project. For this scenario, one possible solution is to use data from other projects in the same company. However, using these data practically would get poor performance because of different distributional characteristics among projects. Also, software has more non‐defective instances than defective instances that may cause a significant bias towards defective instances. Considering these two problems, we propose an improved transfer adaptive boosting (ITrAdaBoost) approach for being given a small number of labeled data in the testing project. In our approach, ITrAdaBoost can not only employ the Matthews correlation coefficient (MCC) as the measure instead of accuracy rate but also use the asymmetric misclassification costs for non‐defective and defective instances. Extensive experiments on 18 public projects from four datasets indicate that: (a) our approach significantly outperforms state‐of‐the‐art cross‐project defect prediction (CPDP) approaches, and (b) our approach can obtain comparable prediction performances in contrast with within project prediction results. Consequently, the proposed approach can build an effective prediction model with a small number of labeled instances for mixed‐project defect prediction (MPDP).For mixed‐project defect prediction, improved transfer adaptive boosting approach (ITrAdaBoost) can not only employ the Matthews correlation coefficient (MCC) as the measure instead of accuracy rate, but also use the asymmetric misclassification costs for nondefective and defective instances. Extensive experiments on 18 public projects from four datasets indicate that (a) our approach significantly outperforms state‐of‐the‐art cross‐project defect prediction (CPDP) approaches, and (b) our approach can obtain comparable prediction performances in contrast with within project prediction results.


image
image},
journal = {J. Softw. Evol. Process},
month = oct,
numpages = {23},
keywords = {transfer learning, software defect prediction, mixed‐project, cross‐project, class imbalance}
}

@inproceedings{10.1109/IRI.2019.00030,
author = {Reddivari, Sandeep and Raman, Jayalakshmi},
title = {Software Quality Prediction: An Investigation Based on Machine Learning},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IRI.2019.00030},
doi = {10.1109/IRI.2019.00030},
abstract = {Irrespective of the type of software system that is being developed, producing and delivering high-quality software within the specified time and budget is crucial for many software businesses. The software process model has a major impact on the quality of the overall system - the longer a defect remains in the system undetected, the harder it becomes to fix. However, predicting the quality of the software in the early phases would immensely assist developers in software maintenance and quality assurance activities, and to allocate effort and resources more efficiently. This paper presents an evaluation of eight machine learning techniques in the context of reliability and maintainability. Reliability is investigated as the number of defects in a system and the maintainability is analyzed as the number of changes made in the system. Software metrics are direct reflections of various characteristics of software and are used in our study as the major attributes for training the models for both defect and maintainability prediction. Among the eight different techniques we experimented with, Random Forest provided the best results with an AUC of over 0.8 during both defect and maintenance prediction.},
booktitle = {2019 IEEE 20th International Conference on Information Reuse and Integration for Data Science (IRI)},
pages = {115–122},
numpages = {8},
location = {Los Angeles, CA, USA}
}

@inproceedings{10.1145/3172871.3172872,
author = {Kumar, Lov and Sureka, Ashish},
title = {Feature Selection Techniques to Counter Class Imbalance Problem for Aging Related Bug Prediction: Aging Related Bug Prediction},
year = {2018},
isbn = {9781450363983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3172871.3172872},
doi = {10.1145/3172871.3172872},
abstract = {Aging-Related Bugs (ARBs) occur in long running systems due to error conditions caused because of accumulation of problems such as memory leakage or unreleased files and locks. Aging-Related Bugs are hard to discover during software testing and also challenging to replicate. Automatic identification and prediction of aging related fault-prone files and classes in an object oriented system can help the software quality assurance team to optimize their testing efforts. In this paper, we present a study on the application of static source code metrics and machine learning techniques to predict aging related bugs. We conduct a series of experiments on publicly available dataset from two large open-source software systems: Linux and MySQL. Class imbalance and high dimensionality are the two main technical challenges in building effective predictors for aging related bugs.We investigate the application of five different feature selection techniques (OneR, Information Gain, Gain Ratio, RELEIF and Symmetric Uncertainty) for dimensionality reduction and five different strategies (Random Under-sampling, Random Oversampling, SMOTE, SMOTEBoost and RUSBoost) to counter the effect of class imbalance in our proposed machine learning based solution approach. Experimental results reveal that the random under-sampling approach performs best followed by RUSBoost in-terms of the mean AUC metric. Statistical significance test demonstrates that there is a significant difference between the performance of the various feature selection techniques. Experimental results shows that Gain Ratio and RELEIF performs best in comparison to other strategies to address the class imbalance problem. We infer from the statistical significance test that there is no difference between the performances of the five different learning algorithms.},
booktitle = {Proceedings of the 11th Innovations in Software Engineering Conference},
articleno = {2},
numpages = {11},
keywords = {Source Code Metrics, Software Maintenance, Predictive Modeling, Machine Learning, Imbalance Learning, Feature Selection Techniques, Empirical Software Engineering, Aging Related Bugs},
location = {Hyderabad, India},
series = {ISEC '18}
}

@article{10.1016/j.asoc.2016.05.038,
author = {Serdar Bier, M. and Diri, Banu},
title = {Defect prediction for Cascading Style Sheets},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.05.038},
doi = {10.1016/j.asoc.2016.05.038},
abstract = {Graphical abstractDisplay Omitted Testing is a crucial activity in software development. However exhaustive testing of a given software is impossible in practice because projects have serious time and budget limitations. Therefore, software testing teams need guidance about which modules they should focus on. Defect prediction techniques are useful for this situation because they let testers to identify and focus on defect prone parts of software. These techniques are essential for software teams, because they help teams to efficiently allocate their precious resources in testing phase. Software defect prediction has been an active research area in recent years. Researchers in this field have been using different types of metrics in their prediction models. However, value of extracting static code metrics for style sheet languages has been ignored until now. User experience is a very important part of web applications and its mostly provided using Cascading Style Sheets (CSS). In this research, our aim is to improve defect prediction performance for web applications by utilizing metrics generated from CSS code. We generated datasets from four open source web applications to conduct our experiments. Defect prediction is then performed using three different well-known machine learning algorithms. The results revealed that static code metrics based defect prediction techniques can be performed effectively to improve quality of CSS code in web applications. Therefore we recommend utilizing domain-specific characteristics of applications in defect prediction as they result in significantly high prediction performance with low costs.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1078–1084},
numpages = {7},
keywords = {Web sites, Software quality, Software Metrics, Defect prediction}
}

@inproceedings{10.1145/3490725.3490739,
author = {Shi, Linlin and Yu, Pengfei and He, Shilie and Zhou, Zhenwei and Meng, Linghui and Liu, Junbin},
title = {Degradation Characteristics Analysis and Fault Prediction of Switching Power Supply Based on Data Mining},
year = {2022},
isbn = {9781450384247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490725.3490739},
doi = {10.1145/3490725.3490739},
abstract = {Fault prediction and health monitoring of DC-DC switching power supply plays an important role in the safe and reliable operation of power electronic equipment. In this paper, a long-term high temperature degradation test was carried out for DC-DC power supply, and the characteristic parameters related to device health, such as input current, input voltage, output current and output voltage, were collected during the test. Through data mining technology, we carry out data preprocessing, feature analysis, health index modeling and fault prediction analysis on the samples collected in the power supply test, so as to study the degradation and fault predictor of the power supply from the real power supply test degradation data. The research results of this paper have important engineering significance for the monitoring and health prediction of power supply.},
booktitle = {Proceedings of the 2021 4th International Conference on Machine Learning and Machine Intelligence},
pages = {89–98},
numpages = {10},
keywords = {feature analysis, Fault Prediction, Data Mining, DC-DC power supply},
location = {Hangzhou, China},
series = {MLMI '21}
}

@inproceedings{10.1145/2372233.2372250,
author = {Wang, Dandan and Wang, Qing and Hong, Zhenghua and Chen, Xichang and Zhang, Liwen and Yang, Ye},
title = {Incorporating qualitative and quantitative factors for software defect prediction},
year = {2012},
isbn = {9781450315098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2372233.2372250},
doi = {10.1145/2372233.2372250},
abstract = {Defect is an important quality attribute of software. Defect is injected in development process and depended on the maturity level of the processes. How many defects were detected is enough? In any software organization, effort estimation and defect prediction are big challenges. Predicting the number of defects in the early stage of software development life cycle will be more helpful for the organizations to estimate the quality of developed product and optimize the resources schedule. Especially in outsourcing organization, the early precise defect prediction can help them to monitor the supplier's process and establish the criteria to verify the outsourcing products. Chinese development bank (CDB) is such an outsourcing organization, who applied SAM process area of CMMI to manage their outsourcing projects. In this paper, we proposed a prediction mode, which incorporated the qualitative factors from COQUALMO and the quantitative data collected from 21 historic financial projects of CDB. Principal Component Analysis (PCA) method was adopted to analyze the inter-correlated factors, and the key factors were determined to simplify the proposed model. We also evaluated its performance and compared with the software defect introduction (DI) model of COQUALMO. The results show that 66.67% predicted results are better than DI model and 80.5% predicted results have AE which are less than 50 while 95.24% predicted results have AE which are less than 100.},
booktitle = {Proceedings of the 2nd International Workshop on Evidential Assessment of Software Technologies},
pages = {61–66},
numpages = {6},
keywords = {re (relative error), principal component analysis (pca), defect prediction, coqualmo, ae (absolute error)},
location = {Lund, Sweden},
series = {EAST '12}
}

@article{10.1016/j.compeleceng.2018.02.043,
author = {Choudhary, Garvit Rajesh and Kumar, Sandeep and Kumar, Kuldeep and Mishra, Alok and Catal, Cagatay},
title = {Empirical analysis of change metrics for software fault prediction},
year = {2018},
issue_date = {Apr 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {67},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2018.02.043},
doi = {10.1016/j.compeleceng.2018.02.043},
journal = {Comput. Electr. Eng.},
month = apr,
pages = {15–24},
numpages = {10},
keywords = {Defect prediction, Software quality, Metrics, Change log, Eclipse, Software fault prediction}
}

@article{10.1016/j.eswa.2009.12.056,
author = {Zheng, Jun},
title = {Cost-sensitive boosting neural networks for software defect prediction},
year = {2010},
issue_date = {June, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {6},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2009.12.056},
doi = {10.1016/j.eswa.2009.12.056},
abstract = {Software defect predictors which classify the software modules into defect-prone and not-defect-prone classes are effective tools to maintain the high quality of software products. The early prediction of defect-proneness of the modules can allow software developers to allocate the limited resources on those defect-prone modules such that high quality software can be produced on time and within budget. In the process of software defect prediction, the misclassification of defect-prone modules generally incurs much higher cost than the misclassification of not-defect-prone ones. Most of the previously developed predication models do not consider this cost issue. In this paper, three cost-sensitive boosting algorithms are studied to boost neural networks for software defect prediction. The first algorithm based on threshold-moving tries to move the classification threshold towards the not-fault-prone modules such that more fault-prone modules can be classified correctly. The other two weight-updating based algorithms incorporate the misclassification costs into the weight-update rule of boosting procedure such that the algorithms boost more weights on the samples associated with misclassified defect-prone modules. The performances of the three algorithms are evaluated by using four datasets from NASA projects in terms of a singular measure, the Normalized Expected Cost of Misclassification (NECM). The experimental results suggest that threshold-moving is the best choice to build cost-sensitive software defect prediction models with boosted neural networks among the three algorithms studied, especially for the datasets from projects developed by object-oriented language.},
journal = {Expert Syst. Appl.},
month = jun,
pages = {4537–4543},
numpages = {7},
keywords = {Software defect, Neural networks, Cost-sensitive, Adaboost}
}

@article{10.1016/j.is.2015.02.006,
author = {Siers, Michael J. and Islam, Md Zahidul},
title = {Software defect prediction using a cost sensitive decision forest and voting, and a potential solution to the class imbalance problem},
year = {2015},
issue_date = {July 2015},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {51},
number = {C},
issn = {0306-4379},
url = {https://doi.org/10.1016/j.is.2015.02.006},
doi = {10.1016/j.is.2015.02.006},
abstract = {Software development projects inevitably accumulate defects throughout the development process. Due to the high cost that defects can incur, careful consideration is crucial when predicting which sections of code are likely to contain defects. Classification algorithms used in machine learning can be used to create classifiers which can be used to predict defects. While traditional classification algorithms optimize for accuracy, cost-sensitive classification methods attempt to make predictions which incur the lowest classification cost. In this paper we propose a cost-sensitive classification technique called CSForest which is an ensemble of decision trees. We also propose a cost-sensitive voting technique called CSVoting in order to take advantage of the set of decision trees in minimizing the classification cost. We then investigate a potential solution to class imbalance within our decision forest algorithm. We empirically evaluate the proposed techniques comparing them with six (6) classifier algorithms on six (6) publicly available clean datasets that are commonly used in the research on software defect prediction. Our initial experimental results indicate a clear superiority of the proposed techniques over the existing ones. Author-HighlightsSDP is short for Software Defect Prediction.We show that there is not a clear winner in the studied existing methods for SDP*.A cost-sensitive decision forest and voting technique are proposed.The superiority of the proposed techniques is shown.A proposed framework for the forest algorithm for handling class imbalance.},
journal = {Inf. Syst.},
month = jul,
pages = {62–71},
numpages = {10},
keywords = {Software defect prediction, Forest voting, Decision forest, Cost-sensitive, Class imbalance}
}

@inproceedings{10.1109/ESEM.2017.48,
author = {Yan, Meng and Fang, Yicheng and Lo, David and Xia, Xin and Zhang, Xiaohong},
title = {File-level defect prediction: unsupervised vs. supervised models},
year = {2017},
isbn = {9781509040391},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ESEM.2017.48},
doi = {10.1109/ESEM.2017.48},
abstract = {Background: Software defect models can help software quality assurance teams to allocate testing or code review resources. A variety of techniques have been used to build defect prediction models, including supervised and unsupervised methods. Recently, Yang et al. [1] surprisingly find that unsupervised models can perform statistically significantly better than supervised models in effort-aware change-level defect prediction. However, little is known about relative performance of unsupervised and supervised models for effort-aware file-level defect prediction. Goal: Inspired by their work, we aim to investigate whether a similar finding holds in effort-aware file-level defect prediction. Method: We replicate Yang et al.'s study on PROMISE dataset with totally ten projects. We compare the effectiveness of unsupervised and supervised prediction models for effort-aware file-level defect prediction. Results: We find that the conclusion of Yang et al. [1] does not hold under within-project but holds under cross-project setting for file-level defect prediction. In addition, following the recommendations given by the best unsupervised model, developers needs to inspect statistically significantly more files than that of supervised models considering the same inspection effort (i.e., LOC). Conclusions: (a) Unsupervised models do not perform statistically significantly better than state-of-art supervised model under within-project setting, (b) Unsupervised models can perform statistically significantly better than state-of-art supervised model under cross-project setting, (c) We suggest that not only LOC but also number of files needed to be inspected should be considered when evaluating effort-aware file-level defect prediction models.},
booktitle = {Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {344–353},
numpages = {10},
keywords = {replication study, inspection effort, effort-aware defect prediction},
location = {Markham, Ontario, Canada},
series = {ESEM '17}
}

@inproceedings{10.1145/3465481.3465746,
author = {Nelson, Boel},
title = {Efficient Error Prediction for Differentially Private Algorithms},
year = {2021},
isbn = {9781450390514},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465481.3465746},
doi = {10.1145/3465481.3465746},
abstract = {Differential privacy is a strong mathematical notion of privacy. Still, a prominent challenge when using differential privacy in real data collection is understanding and counteracting the accuracy loss that differential privacy imposes. As such, the accuracy/privacy trade-off of differential privacy needs to be balanced on a case-by-case basis. Applications in the literature tend to focus solely on analytical accuracy bounds, not include data in error prediction, or use arbitrary settings to measure error empirically. To fill the gap in the literature, we propose a novel application of factor experiments to create data aware error predictions. Basically, factor experiments provide a systematic approach to conducting empirical experiments. To demonstrate our methodology in action, we conduct a case study where error is dependent on arbitrarily complex tree structures. We first construct a tool to simulate poll data. Next, we use our simulated data to construct a least squares model to predict error. Last, we show how to validate the model. Consequently, our contribution is a method for constructing error prediction models that are data aware.},
booktitle = {Proceedings of the 16th International Conference on Availability, Reliability and Security},
articleno = {26},
numpages = {12},
keywords = {accuracy prediction, data privacy, differential privacy, empirical evaluation, error prediction, factor experiments, prediction model},
location = {Vienna, Austria},
series = {ARES '21}
}

@article{10.1007/s10489-020-02026-2,
author = {Van Nguyen, Sinh and Tran, Ha Manh},
title = {An automated fault detection system for communication networks and distributed systems},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {8},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-02026-2},
doi = {10.1007/s10489-020-02026-2},
abstract = {Automating fault detection in communication networks and distributed systems is a challenging process that usually requires the involvement of supporting tools and the expertise of system operators. Automated event monitoring and correlating systems produce event data that is forwarded to system operators for analyzing error events and creating fault reports. Machine learning methods help not only analyzing event data more precisely but also forecasting possible error events by learning from existing faults. This study introduces an automated fault detection system that assists system operators in detecting and forecasting faults. This system is characterized by the capability of exploiting bug knowledge resources at various online repositories, log events and status parameters from the monitored system; and applying bug analysis and event filtering methods for evaluating events and forecasting faults. The system contains a fault data model to collect bug reports, a feature and semantic filtering method to correlate log events, and machine learning methods to evaluate the severity, priority and relation of log events and forecast the forthcoming critical faults of the monitored system. We have evaluated the prototyping implementation of the proposed system on a high performance computing cluster system and provided analysis with lessons learned.},
journal = {Applied Intelligence},
month = aug,
pages = {5405–5419},
numpages = {15},
keywords = {Bug tracking system, Random forest, Machine learning, Automation, Fault detection}
}

@inproceedings{10.1109/HASE.2016.13,
author = {Sawadpong, Puntitra and Allen, Edward B.},
title = {Software Defect Prediction Using Exception Handling Call Graphs: A Case Study},
year = {2016},
isbn = {9781467399135},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/HASE.2016.13},
doi = {10.1109/HASE.2016.13},
abstract = {The ability to predict which modules are fault-prone can assist in directing quality enhancement efforts to modules at risk. This is especially critical for high-assurance systems where software failures may have severe consequences. While the field of defect rediction based on software metrics is mature, no study has addressed the use of metrics for predicting faults related to exception handling. In this paper, we propose exception-based software metrics that are based on the structural attributes of exception handling call graphs. We empirically validate the proposed metrics through a case study of Hadoop Core using data mined from software repositories and defect reports. The results of our case study are comparable to the results of other software metric studies in the literature. We also show that our exception-based software metrics can be better predictors of fault-proneness of exception classes compared to conventional software metrics.},
booktitle = {Proceedings of the 2016 IEEE 17th International Symposium on High Assurance Systems Engineering (HASE)},
pages = {55–62},
numpages = {8},
series = {HASE '16}
}

@inproceedings{10.1109/IECON43393.2020.9254466,
author = {Wu, Bingjie and Cai, Wenjian and Zhang, Xin},
title = {A fault detection model for air handling units based on the machine learning algorithms},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON43393.2020.9254466},
doi = {10.1109/IECON43393.2020.9254466},
abstract = {A fault detection model for air handling units (AHU) is proposed in this study based on machine learning methods. The hyperparaters of the model is tuned by the grid search method. The training accuracy, test accuracy, recall, precision, and F1 score are evaluated for this model. The result demonstrates that the model is robust enough to detect the fault for AHU with test accuracy and F1 score of 99.58% and 99.51%, respectively.},
booktitle = {IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society},
pages = {4789–4793},
numpages = {5},
location = {Singapore, Singapore}
}

@article{10.1007/s11704-017-6015-y,
author = {Zhang, Yun and Lo, David and Xia, Xin and Sun, Jianling},
title = {Combined classifier for cross-project defect prediction: an extended empirical study},
year = {2018},
issue_date = {April     2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {12},
number = {2},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-017-6015-y},
doi = {10.1007/s11704-017-6015-y},
abstract = {To facilitate developers in effective allocation of their testing and debugging efforts, many software defect prediction techniques have been proposed in the literature. These techniques can be used to predict classes that are more likely to be buggy based on the past history of classes, methods, or certain other code elements. These techniques are effective provided that a sufficient amount of data is available to train a prediction model. However, sufficient training data are rarely available for new software projects. To resolve this problem, cross-project defect prediction, which transfers a prediction model trained using data from one project to another, was proposed and is regarded as a new challenge in the area of defect prediction. Thus far, only a few cross-project defect prediction techniques have been proposed. To advance the state of the art, in this study, we investigated seven composite algorithms that integrate multiple machine learning classifiers to improve cross-project defect prediction. To evaluate the performance of the composite algorithms, we performed experiments on 10 open-source software systems from the PROMISE repository, which contain a total of 5,305 instances labeled as defective or clean. We compared the composite algorithms with the combined defect predictor where logistic regression is used as the meta classification algorithm (CODEPLogistic), which is the most recent cross-project defect prediction algorithm in terms of two standard evaluation metrics: cost effectiveness and F-measure. Our experimental results show that several algorithms outperform CODEPLogistic: Maximum voting shows the best performance in terms of F-measure and its average F-measure is superior to that of CODEPLogistic by 36.88%. Bootstrap aggregation (BaggingJ48) shows the best performance in terms of cost effectiveness and its average cost effectiveness is superior to that of CODEPLogistic by 15.34%.},
journal = {Front. Comput. Sci.},
month = apr,
pages = {280–296},
numpages = {17},
keywords = {defect prediction, cross-project, classifier combination}
}

@inproceedings{10.1007/978-3-030-31726-3_42,
author = {Li, Juanjuan and Jing, Xiao-Yuan and Wu, Fei and Sun, Ying and Yang, Yongguang},
title = {A Cost-Sensitive Shared Hidden Layer Autoencoder for Cross-Project Defect Prediction},
year = {2019},
isbn = {978-3-030-31725-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31726-3_42},
doi = {10.1007/978-3-030-31726-3_42},
abstract = {Cross-project defect prediction means training a classifier model using the historical data of the other source project, and then testing whether the target project instance is defective or not. Since source and target projects have different data distributions, and data distribution difference will degrade the performance of classifier. Furthermore, the class imbalance of datasets increases the difficulty of classification. Therefore, a cost-sensitive shared hidden layer autoencoder (CSSHLA) method is proposed. CSSHLA learns a common feature representation between source and target projects by shared hidden layer autoencoder, and makes the different data distributions more similar. To solve the class imbalance problem, CSSHLA introduces a cost-sensitive factor to assign different importance weights to different instances. Experiments on 10 projects of PROMISE dataset show that CSSHLA improves the performance of cross-project defect prediction compared with baselines.},
booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part III},
pages = {491–502},
numpages = {12},
keywords = {Cross-project software defect prediction, Cost-sensitive learning, Shared hidden layer autoencoder},
location = {Xi'an, China}
}

@inproceedings{10.1145/2601248.2601294,
author = {Rodriguez, Daniel and Herraiz, Israel and Harrison, Rachel and Dolado, Javier and Riquelme, Jos\'{e} C.},
title = {Preliminary comparison of techniques for dealing with imbalance in software defect prediction},
year = {2014},
isbn = {9781450324762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2601248.2601294},
doi = {10.1145/2601248.2601294},
abstract = {Imbalanced data is a common problem in data mining when dealing with classification problems, where samples of a class vastly outnumber other classes. In this situation, many data mining algorithms generate poor models as they try to optimize the overall accuracy and perform badly in classes with very few samples. Software Engineering data in general and defect prediction datasets are not an exception and in this paper, we compare different approaches, namely sampling, cost-sensitive, ensemble and hybrid approaches to the problem of defect prediction with different datasets preprocessed differently. We have used the well-known NASA datasets curated by Shepperd et al. There are differences in the results depending on the characteristics of the dataset and the evaluation metrics, especially if duplicates and inconsistencies are removed as a preprocessing step.Further Results and replication package: http://www.cc.uah.es/drg/ease14},
booktitle = {Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {43},
numpages = {10},
keywords = {imbalanced data, defect prediction, data quality},
location = {London, England, United Kingdom},
series = {EASE '14}
}

@article{10.3233/JIFS-179459,
author = {Bashir, Kamal and Li, Tianrui and Yohannese, Chubato Wondaferaw and Yahaya, Mahama and Kahraman, Cengiz},
title = {SMOTEFRIS-INFFC: Handling the challenge of borderline and noisy examples in imbalanced learning for software defect prediction},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {38},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-179459},
doi = {10.3233/JIFS-179459},
abstract = {The object of Software Defect Prediction (SDP) is to identify modules that are prone to defect. This is achieved by training prediction models with datasets obtained by mining software historical depositories. When one acquires data through this approach, it often includes class imbalance which has an unequal class representation among their example. We hypothesize that the imbalance learning is not a problem in itself and decrease in performance is also influenced by other factors related to class distribution in the data. One of these is the existence of noisy and borderline examples. Thus, the objective of our research is to propose a novel preprocessing method using Synthetic Minority Over-Sampling Technique (SMOTE), Fuzzy-rough Instance Selection type II (FRIS-II) and Iterative Noise Filter based on the Fusion of Classifiers (INFFC) which can overcome these problems. The experimental results show that the new proposal significantly outperformed all the methods compared in this study.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {917–933},
numpages = {17},
keywords = {noise filtering, fuzzy rough set, data sampling, Software defect prediction}
}

@inproceedings{10.1007/978-3-030-85607-6_20,
author = {Ardito, Carmelo and Deldjoo, Yashar and Di Sciascio, Eugenio and Nazary, Fatemeh and Sapienza, Gianluca},
title = {ISCADA: Towards a Framework for&nbsp;Interpretable Fault Prediction in&nbsp;Smart Electrical Grids},
year = {2021},
isbn = {978-3-030-85606-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-85607-6_20},
doi = {10.1007/978-3-030-85607-6_20},
abstract = {This paper reports ongoing research for the definition of a data-driven self-healing system using machine learning (ML) techniques that can perform automatic and timely detection of fault types and locations. Specifically, the proposed method makes use of spectrogram-based CNN modeling of the 3-phase voltage signals. Furthermore, to keep human operators informed about why certain decisions were made, i.e., to facilitate the interpretability of the black-box ML model, we propose a novel explanation approach that highlight regions in the input spectrogram that contributed the most for the prediction task at hand (e.g., fault type or location) - or visual explanation.},
booktitle = {Human-Computer Interaction – INTERACT 2021: 18th IFIP TC 13 International Conference, Bari, Italy, August 30 – September 3, 2021, Proceedings, Part V},
pages = {270–274},
numpages = {5},
keywords = {Fault prediction, Interpretability, Self-healing system},
location = {Bari, Italy}
}

@article{10.1016/j.neucom.2019.06.029,
author = {Yang, Jing and Guo, Yingqing and Zhao, Wanli},
title = {Long short-term memory neural network based fault detection and isolation for electro-mechanical actuators},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {360},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.06.029},
doi = {10.1016/j.neucom.2019.06.029},
journal = {Neurocomput.},
month = sep,
pages = {85–96},
numpages = {12},
keywords = {Electro-mechanical actuators, Fault diagnosis and isolation, Neural network, Long short-term memory}
}

@inproceedings{10.1109/MSR.2017.46,
author = {Madeyski, Lech and Kawalerowicz, Marcin},
title = {Continuous defect prediction: the idea and a related dataset},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.46},
doi = {10.1109/MSR.2017.46},
abstract = {We would like to present the idea of our Continuous Defect Prediction (CDP) research and a related dataset that we created and share. Our dataset is currently a set of more than 11 million data rows, representing files involved in Continuous Integration (CI) builds, that synthesize the results of CI builds with data we mine from software repositories. Our dataset embraces 1265 software projects, 30,022 distinct commit authors and several software process metrics that in earlier research appeared to be useful in software defect prediction. In this particular dataset we use TravisTorrent as the source of CI data. TravisTorrent synthesizes commit level information from the Travis CI server and GitHub open-source projects repositories. We extend this data to a file change level and calculate the software process metrics that may be used, for example, as features to predict risky software changes that could break the build if committed to a repository with CI enabled.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {515–518},
numpages = {4},
keywords = {software repository, open science, mining software repositories, defect prediction, continuous defect prediction},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@article{10.4018/ijssci.2014040101,
author = {Mishra, Bharavi and Shukla, K.K.},
title = {Software Defect Prediction Based on GUHA Data Mining Procedure and Multi-Objective Pareto Efficient Rule Selection},
year = {2014},
issue_date = {April 2014},
publisher = {IGI Global},
address = {USA},
volume = {6},
number = {2},
issn = {1942-9045},
url = {https://doi.org/10.4018/ijssci.2014040101},
doi = {10.4018/ijssci.2014040101},
abstract = {Software defect prediction, if is effective, enables the developers to distribute their testing efforts efficiently and let them focus on defect prone modules. It would be very resource consuming to test all the modules while the defect lies in fraction of modules. Information about fault-proneness of classes and methods can be used to develop new strategies which can help mitigate the overall development cost and increase the customer satisfaction. Several machine learning strategies have been used in recent past to identify defective modules. These models are built using publicly available historical software defect data sets. Most of the proposed techniques are not able to deal with the class imbalance problem efficiently. Therefore, it is necessary to develop a prediction model which consists of small simple and comprehensible rules. Considering these facts, in this paper, the authors propose a novel defect prediction approach named GUHA based Classification Association Rule Mining algorithm G-CARM where "GUHA" stands for General Unary Hypothesis Automaton. G-CARM approach is primarily based on Classification Association Rule Mining, and deploys a two stage process involving attribute discretization, and rule generation using GUHA. GUHA is oldest yet very powerful method of pattern mining. The basic idea of GUHA procedure is to mine the interesting attribute patterns that indicate defect proneness. The new method has been compared against five other models reported in recent literature viz. Naive Bayes, Support Vector Machine, RIPPER, J48 and Nearest Neighbour classifier by using several measures, including AUC and probability of detection. The experimental results indicate that the prediction performance of G-CARM approach is better than other prediction approaches. The authors' approach achieved 76% mean recall and 83% mean precision for defective modules and 93% mean recall and 83% mean precision for non-defective modules on CM1, KC1, KC2 and Eclipse data sets. Further defect rule generation process often generates a large number of rules which require considerable efforts while using these rules as a defect predictor, hence, a rule sub-set selection process is also proposed to select best set of rules according to the requirements. Evolution criteria for defect prediction like sensitivity, specificity, precision often compete against each other. It is therefore, important to use multi-objective optimization algorithms for selecting prediction rules. In this paper the authors report prediction rules that are Pareto efficient in the sense that no further improvements in the rule set is possible without sacrificing some performance criteria. Non-Dominated Sorting Genetic Algorithm has been used to find Pareto front and defect prediction rules.},
journal = {Int. J. Softw. Sci. Comput. Intell.},
month = apr,
pages = {1–29},
numpages = {29},
keywords = {Pareto Optimality, General Unary Hypothesis Automaton GUHA, Fault Prediction, Defect Patterns, Data Mining}
}

@article{10.1007/s10796-013-9430-0,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan and Napolitano, Amri and Wald, Randall},
title = {A comparative study of iterative and non-iterative feature selection techniques for software defect prediction},
year = {2014},
issue_date = {November  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {5},
issn = {1387-3326},
url = {https://doi.org/10.1007/s10796-013-9430-0},
doi = {10.1007/s10796-013-9430-0},
abstract = {Two important problems which can affect the performance of classification models are high-dimensionality (an overabundance of independent features in the dataset) and imbalanced data (a skewed class distribution which creates at least one class with many fewer instances than other classes). To resolve these problems concurrently, we propose an iterative feature selection approach, which repeated applies data sampling (in order to address class imbalance) followed by feature selection (in order to address high-dimensionality), and finally we perform an aggregation step which combines the ranked feature lists from the separate iterations of sampling. This approach is designed to find a ranked feature list which is particularly effective on the more balanced dataset resulting from sampling while minimizing the risk of losing data through the sampling step and missing important features. To demonstrate this technique, we employ 18 different feature selection algorithms and Random Undersampling with two post-sampling class distributions. We also investigate the use of sampling and feature selection without the iterative step (e.g., using the ranked list from a single iteration, rather than combining the lists from multiple iterations), and compare these results from the version which uses iteration. Our study is carried out using three groups of datasets with different levels of class balance, all of which were collected from a real-world software system. All of our experiments use four different learners and one feature subset size. We find that our proposed iterative feature selection approach outperforms the non-iterative approach.},
journal = {Information Systems Frontiers},
month = nov,
pages = {801–822},
numpages = {22},
keywords = {Software defect prediction, Iterative feature selection, High dimensionality, Date sampling, Class imbalance}
}

@article{10.1007/s11219-019-09460-7,
author = {Qin, Fangyun and Wan, Xiaohui and Yin, Beibei},
title = {An empirical study of factors affecting cross-project aging-related bug prediction with TLAP},
year = {2020},
issue_date = {Mar 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-019-09460-7},
doi = {10.1007/s11219-019-09460-7},
abstract = {Software aging is a phenomenon in which long-running software systems show an increasing failure rate and/or progressive performance degradation. Due to their nature, Aging-Related Bugs (ARBs) are hard to discover during software testing and are also challenging to reproduce. Therefore, automatically predicting ARBs before software release can help developers reduce ARB impact or avoid ARBs. Many bug prediction approaches have been proposed, and most of them show effectiveness in within-project prediction settings. However, due to the low presence and reproducing difficulty of ARBs, it is usually hard to collect sufficient training data to build an accurate prediction model. A recent work proposed a method named Transfer Learning based Aging-related bug Prediction (TLAP) for performing cross-project ARB prediction. Although this method considerably improves cross-project ARB prediction performance, it has been observed that its prediction result is affected by several key factors, such as the normalization methods, kernel functions, and machine learning classifiers. Therefore, this paper presents the first empirical study to examine the impact of these factors on the effectiveness of cross-project ARB prediction in terms of single-factor pattern, bigram pattern, and triplet pattern and validates the results with the Scott-Knott test technique. We find that kernel functions and classifiers are key factors affecting the effectiveness of cross-project ARB prediction, while normalization methods do not show statistical influence. In addition, the order of values in three single-factor patterns is maintained in three bigram patterns and one triplet pattern to a large extent. Similarly, the order of values in the three bigram patterns is also maintained in the triplet pattern.},
journal = {Software Quality Journal},
month = mar,
pages = {107–134},
numpages = {28},
keywords = {Empirical study, Cross-project, Software aging, Aging-related bugs}
}

@article{10.1504/ijdats.2019.103754,
author = {Meti, Subhas A. and Sangam, V.G.},
title = {Enhanced auto associative neural network using feed forward neural network: an approach to improve performance of fault detection and analysis},
year = {2019},
issue_date = {2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {11},
number = {4},
issn = {1755-8050},
url = {https://doi.org/10.1504/ijdats.2019.103754},
doi = {10.1504/ijdats.2019.103754},
abstract = {Biosensors have played a significant role in many of present day's applications ranging from military applications to healthcare sectors. However, its practicality and robustness in its usage in real time scenario is still a matter of concern. Primarily issues such as prediction of sensor data, noise estimation and channel estimation and most importantly in fault detection and analysis. In this paper an enhancement is applied to the auto associative neural network (AANN) by considering the cascade feed forward propagation. The residual noise is also computed along with fault detection and analysis of the sensor data. An experimental result shows a significant reduction in the MSE as compared to conventional AANN. The regression based correlation coefficient has improved in the proposed method as compared to conventional AANN.},
journal = {Int. J. Data Anal. Tech. Strateg.},
month = jan,
pages = {291–309},
numpages = {18},
keywords = {residual noise, enhanced AANN, feed forward neural network, fault detection and analysis, WBAN}
}

@inproceedings{10.1145/3449365.3449384,
author = {Malhotra, Ruchika and Budhiraja, Anmol and Kumar Singh, Abhinav and Ghoshal, Ishani},
title = {A Novel Feature Selection Approach based on Binary Particle Swarm Optimization and Ensemble Learning for Heterogeneous Defect Prediction},
year = {2021},
isbn = {9781450388108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3449365.3449384},
doi = {10.1145/3449365.3449384},
abstract = {Software defect prediction is an integral part of the software development process. Defect prediction helps focus on the grey areas beforehand, thus saving the considerable amount of money that is otherwise wasted in finding and fixing the faults once the software is already in production. One of the popular areas of defect prediction in recent years is Heterogeneous Defect Prediction, which predicts defects in a target project using a source project with different metrics. Through our paper, we provide a novel feature selection based approach, En-BPSO, based on binary particle swarm optimization, coupled with majority voting ensemble classifier based fitness function for heterogeneous defect prediction. The datasets we are using are MORPH and SOFTLAB. The results show that the En-BPSO method provides the highest Friedman mean rank amongst all the feature selection methods used for comparison. En-BPSO technique also helps us dynamically determine the optimal number of features to build an accurate heterogeneous defect prediction model.},
booktitle = {Proceedings of the 2021 3rd Asia Pacific Information Technology Conference},
pages = {115–121},
numpages = {7},
keywords = {Heterogeneous Metrics, Feature Selection, Ensemble Learning, Defect Prediction, Binary Particle Swarm Optimization},
location = {Bangkok, Thailand},
series = {APIT '21}
}

@phdthesis{10.5555/AAI29262928,
author = {Li, Gang and Won-Jong, Kim, and Edgar, Sanchez-Sinencio,},
advisor = {G., Parlos, Alexander and Reza, Langari,},
title = {Fast Generation of Machine Learning Models in Model-Based Fault Detection Systems},
year = {2018},
isbn = {9798802710920},
publisher = {Texas A&amp;M University},
abstract = {In model-based fault detection, processed input and output time-series data are used to generate models and then perform on-line predictions. Many practical considerations in model-based fault detection systems rule out most of the available approaches in generating on-line predictive models. One approach that satisfies the needs of on-line predictive model generation is the piece-wise linear robust regression (PWLRR) method. The PWLRR requires too much data for initial training, it has limited ability to perform accurate predictions beyond the initial training region (extrapolation), it does not perform accurate predictions without significant follow-on or on-line training, and it constantly runs into blind spots losing track of the asset condition. The performance of a fault detection system based on the PWLRR suffers in many instances, mostly in the form of delayed detection, missed faults and/or false alarms. This work presents an alternative learning method to model generation that overcomes many of the existing disadvantages of the PWLRR approach. Gaussian process (GP) based regression, which exhibits good approximation properties with minimal training data points and has very good extrapolation properties, is selected as an alternate learning method in the fault detection system. The fraction of blind spots, number of data points in the training and validation sets, extent of extrapolation, average prediction error, true negatives (missed faults), false positives (false alarms), and detection time are all considered performance indicators when testing and comparing the model generation methods. Five (5) cases with artificial data and ten (10) cases with real world data from both staged experiments in the laboratory and fielded production sites are used to benchmark the performance of the GP approach, and compare it against the PWLRR approach. Empirical research results comparing GP to PWLRR demonstrate that for comparable training levels, less data is required to train a GP model and with fewer blind spots. Extrapolation by the GP model improves significantly. Among the real test cases with faults, GP results in 100% detection rate, while PWLRR results in 50 % detection rate. For the test cases where both approaches result in true positives, detection time is improved by roughly 2.5 times when using the GP. In test cases without faults, GP results in no false positives, while PWLRR results in three (3) false positives. The proposed method for training based on GP can generate models with less computational resources than the PWLRR and requires less human intervention. Further testing is needed to verify the performance of the proposed approach on data sets with a wider variety of statistical properties.},
note = {AAI29262928}
}

@inproceedings{10.1145/3127005.3127017,
author = {Osman, Haidar and Ghafari, Mohammad and Nierstrasz, Oscar and Lungu, Mircea},
title = {An Extensive Analysis of Efficient Bug Prediction Configurations},
year = {2017},
isbn = {9781450353052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127005.3127017},
doi = {10.1145/3127005.3127017},
abstract = {Background: Bug prediction helps developers steer maintenance activities towards the buggy parts of a software. There are many design aspects to a bug predictor, each of which has several options, i.e., software metrics, machine learning model, and response variable.Aims: These design decisions should be judiciously made because an improper choice in any of them might lead to wrong, misleading, or even useless results. We argue that bug prediction configurations are intertwined and thus need to be evaluated in their entirety, in contrast to the common practice in the field where each aspect is investigated in isolation.Method: We use a cost-aware evaluation scheme to evaluate 60 different bug prediction configuration combinations on five open source Java projects.Results: We find out that the best choices for building a cost-effective bug predictor are change metrics mixed with source code metrics as independent variables, Random Forest as the machine learning model, and the number of bugs as the response variable. Combining these configuration options results in the most efficient bug predictor across all subject systems.Conclusions: We demonstrate a strong evidence for the interplay among bug prediction configurations and provide concrete guidelines for researchers and practitioners on how to build and evaluate efficient bug predictors.},
booktitle = {Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {107–116},
numpages = {10},
keywords = {Bug Prediction, Effort-Aware Evaluation},
location = {Toronto, Canada},
series = {PROMISE}
}

@article{10.5555/3192182.3192194,
title = {An empirical approach for complexity reduction and fault prediction for software quality attribute},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {1–3},
issn = {1743-8195},
abstract = {Designing the high-quality software is a difficult one due to the high complexity and fault prone class. To reduce the complexity and predict the fault-prone class in the object orient software design proposed a new empirical approach. This proposed approach concentrates more on to increase the software quality in the object oriented programming structures. This technique will collect the dataset and metric values from CK-based metrics. And then complexity will be calculated based on the weighted approach. The fault prediction will be done, based on the low usage of the dataset and high complexity dataset. This helps to increase the software quality. In simulation section, the proposed approach has performed and analysed the parameters such as accuracy, fairness, recall, prediction rate and efficiency. The experimental results have shown that the proposed approach increases the prediction rate, accuracy and efficiency.},
journal = {Int. J. Bus. Intell. Data Min.},
month = jan,
pages = {177–187},
numpages = {11}
}

@inproceedings{10.1145/3486611.3491122,
author = {Kumar, Devanshu and Ding, Xianzhong and Du, Wan and Cerpa, Alberto},
title = {Building sensor fault detection and diagnostic system},
year = {2021},
isbn = {9781450391146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3486611.3491122},
doi = {10.1145/3486611.3491122},
abstract = {In this paper, we developed a Building Sensor Fault Detection and Diagnostics System. It consists of a smartphone application integrated with airflow and temperature sensors, to enable Facilities' crews to collect flow, supply, and zone temperatures from each zone with a simple walk-through. This data is then uploaded to a cloud for further analysis using machine learning algorithms trained to identify zones' faulty sensors based on comparisons with building data available from the Building Management Systems (BMS). We develop two different data-driven fault classifiers and compare our system with two state-of-the-art sensing fault schemes using the Receiver Operating Characteristic (ROC) curve, showing an improvement in the Area Under the ROC Curve (AUC) of 7.1% and 26.3%, and 12.9% and 55.1% in fault detection performance improvement for a 10% false positive rate.},
booktitle = {Proceedings of the 8th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {357–360},
numpages = {4},
keywords = {fault detection and diagnosis (FDD), building sensors},
location = {Coimbra, Portugal},
series = {BuildSys '21}
}

@article{10.1016/j.robot.2021.103876,
author = {Liao, Yiwen and Yeaser, Abdullah and Yang, Bin and Tung, James and Hashemi, Ehsan},
title = {Unsupervised fault detection and recovery for intelligent robotic rollators},
year = {2021},
issue_date = {Dec 2021},
publisher = {North-Holland Publishing Co.},
address = {NLD},
volume = {146},
number = {C},
issn = {0921-8890},
url = {https://doi.org/10.1016/j.robot.2021.103876},
doi = {10.1016/j.robot.2021.103876},
journal = {Robot. Auton. Syst.},
month = dec,
numpages = {10},
keywords = {Temporal finite differences, Assistive devices, Deep learning, Robotic rollators, Fault detection and recovery}
}

@inproceedings{10.1145/3319008.3319712,
author = {Amasaki, Sousuke and Yokogawa, Tomoyuki and Aman, Hirohisa},
title = {Towards Better Effort Estimation with Cross-Project Defect Prediction Approaches},
year = {2019},
isbn = {9781450371452},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3319008.3319712},
doi = {10.1145/3319008.3319712},
abstract = {This research aims to tackle a data shift problem of software effort estimation. Cross project defect prediction approaches were found to be helpful for the same problem of software defect prediction. We examined the CPDP approaches and explored its applicability and adaptability for the problem of software effort estimation.},
booktitle = {Proceedings of the 23rd International Conference on Evaluation and Assessment in Software Engineering},
pages = {357–360},
numpages = {4},
keywords = {effort estimation, cross-project defect prediction},
location = {Copenhagen, Denmark},
series = {EASE '19}
}

@article{10.1155/2020/8884786,
author = {Wang, Zuoxun and Xu, Liqiang and Rajagopal, Karthikeyan},
title = {Fault Detection of the Power System Based on the Chaotic Neural Network and Wavelet Transform},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1076-2787},
url = {https://doi.org/10.1155/2020/8884786},
doi = {10.1155/2020/8884786},
abstract = {The safety and stability of the power supply system are affected by some faults that often occur in power system. To solve this problem, a criterion algorithm based on the chaotic neural network (CNN) and a fault detection algorithm based on discrete wavelet transform (DWT) are proposed in this paper. MATLAB/Simulink is used to establish the system model to output fault signals and travelling wave signals. Db4 wavelet decomposes the travelling wave signals into detail signals and approximate signals, and these signals are combined with the two-terminal travelling wave location method to achieve fault location. And the wavelet detail coefficients are extracted to input to the proposed chaotic neural network. The results show that the criterion algorithm can effectively determine whether there are faults in the power system, the fault detection algorithm has the capabilities of locating the system faults accurately, and both algorithms are not affected by fault type, fault location, fault initial angle, and transition resistance.},
journal = {Complex.},
month = jan,
numpages = {15}
}

@inproceedings{10.1007/978-3-642-13318-3_3,
author = {Yan, Zhen and Chen, Xinyu and Guo, Ping},
title = {Software defect prediction using fuzzy support vector regression},
year = {2010},
isbn = {3642133177},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-13318-3_3},
doi = {10.1007/978-3-642-13318-3_3},
abstract = {Regression techniques have been applied to improve software quality by using software metrics to predict defect numbers in software modules This can help developers allocate limited developing resources to modules containing more defects In this paper, we propose a novel method of using Fuzzy Support Vector Regression (FSVR) in predicting software defect numbers Fuzzification input of regressor can handle unbalanced software metrics dataset Compared with the approach of support vector regression, the experiment results with the MIS and RSDIMU datasets indicate that FSVR can get lower mean squared error and higher accuracy of total number of defects for modules containing large number of defects.},
booktitle = {Proceedings of the 7th International Conference on Advances in Neural Networks - Volume Part II},
pages = {17–24},
numpages = {8},
keywords = {software metrics, software defect prediction, fuzzy support vector regression},
location = {Shanghai, China},
series = {ISNN'10}
}

@article{10.1002/smr.2234,
author = {Chen, Xiang and Mu, Yanzhou and Qu, Yubin and Ni, Chao and Liu, Meng and He, Tong and Liu, Shangqing},
title = {Do different cross‐project defect prediction methods identify the same defective modules?},
year = {2020},
issue_date = {May 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {32},
number = {5},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2234},
doi = {10.1002/smr.2234},
abstract = {Cross‐project defect prediction (CPDP) is needed when the target projects are new projects or the projects have less training data, since these projects do not have sufficient historical data to build high‐quality prediction models. The researchers have proposed many CPDP methods, and previous studies have conducted extensive comparisons on the performance of different CPDP methods. However, to the best of our knowledge, it remains unclear whether different CPDP methods can identify the same defective modules, and this issue has not been thoroughly explored. In this article, we select 12 state‐of‐the‐art CPDP methods, including eight supervised methods and four unsupervised methods. We first compare the performance of these methods in the same experiment settings on five widely used datasets (ie, NASA, SOFTLAB, PROMISE, AEEEM, and ReLink) and rank these methods via the Scott‐Knott test. Final results confirm the competitiveness of unsupervised methods. Then we perform diversity analysis on defective modules for these methods by using the McNemar test. Empirical results verify that different CPDP methods may lead to difference in the modules predicted as defective, especially when the comparison is performed between the supervised methods and unsupervised methods. Finally, we also find there exist a certain number of defective modules, which cannot be correctly identified by any of the CPDP methods or can be correctly identified by only one CPDP method. These findings can be utilized to design more effective methods to further improve the performance of&nbsp;CPDP.},
journal = {J. Softw. Evol. Process},
month = apr,
numpages = {24},
keywords = {software defect prediction, empirical study, diversity analysis, cross‐project defect prediction}
}

@inproceedings{10.1145/3345629.3351449,
author = {Jahanshahi, Hadi and Jothimani, Dhanya and Ba\c{s}ar, Ay\c{s}e and Cevik, Mucahit},
title = {Does chronology matter in JIT defect prediction? A Partial Replication Study},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3351449},
doi = {10.1145/3345629.3351449},
abstract = {BACKGROUND: Just-In-Time (JIT) models, unlike the traditional defect prediction models, detect the fix-inducing changes (or defect inducing changes). These models are designed based on the assumption that past code change properties are similar to future ones. However, as the system evolves, the expertise of developers and/or the complexity of the system also change.AIM: In this work, we aim to investigate the effect of code change properties on JIT models over time. We also study the impact of using recent data as well as all available data on the performance of JIT models. Further, we analyze the effect of weighted sampling on the performance of fix-inducing properties of JIT models. For this purpose, we used datasets from four open-source projects, namely Eclipse JDT, Mozilla, Eclipse Platform, and PostgreSQL.METHOD: We used five families of change code properties such as size, diffusion, history, experience, and purpose. We used Random Forest to train and test the JIT model and Brier Score (BS) and Area Under Curve (AUC) for performance measurement. We applied the Wilcoxon Signed Rank Test on the output to statistically validate whether the performance of JIT models improves using all the available data or the recent data.RESULTS: Our paper suggest that the predictive power of JIT models does not change by time. Furthermore, we observed that the chronology of data in JIT defect prediction models can be discarded by considering all the available data. On the other hand, the importance score of families of code change properties is found to oscillate over time.CONCLUSION: To mitigate the impact of the evolution of code change properties, it is recommended to use weighted sampling approach in which more emphasis is placed upon the changes occurring closer to the current time. Moreover, since properties such as "Expertise of the Developer" and "Size" evolve with the time, the models obtained from old data may exhibit different characteristics compared to those employing the newer dataset. Hence, practitioners should constantly retrain JIT models to include fresh data.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {90–99},
numpages = {10},
keywords = {Just-In-Time prediction, defect prediction, quality assurance, software engineering},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@article{10.1007/s10489-020-01935-6,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {An empirical study of ensemble techniques for software fault prediction},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {6},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-01935-6},
doi = {10.1007/s10489-020-01935-6},
abstract = {Previously, many researchers have performed analysis of various techniques for the software fault prediction (SFP). Oddly, the majority of such studies have shown the limited prediction capability and their performance for given software fault datasets was not persistent. In contrast to this, recently, ensemble techniques based SFP models have shown promising and improved results across different software fault datasets. However, many new as well as improved ensemble techniques have been introduced, which are not explored for SFP. Motivated by this, the paper performs an investigation on ensemble techniques for SFP. We empirically assess the performance of seven ensemble techniques namely, Dagging, Decorate, Grading, MultiBoostAB, RealAdaBoost, Rotation Forest, and Ensemble Selection. We believe that most of these ensemble techniques are not used before for SFP. We conduct a series of experiments on the benchmark fault datasets and use three distinct classification algorithms, namely, naive Bayes, logistic regression, and J48 (decision tree) as base learners to the ensemble techniques. Experimental analysis revealed that rotation forest with J48 as the base learner achieved the highest precision, recall, and G-mean 1 values of 0.995, 0.994, and 0.994, respectively and Decorate achieved the highest AUC value of 0.986. Further, results of statistical tests showed used ensemble techniques demonstrated a statistically significant difference in their performance among the used ones for SFP. Additionally, the cost-benefit analysis showed that SFP models based on used ensemble techniques might be helpful in saving software testing cost and effort for twenty out of twenty-eight used fault datasets.},
journal = {Applied Intelligence},
month = jun,
pages = {3615–3644},
numpages = {30},
keywords = {Empirical analysis, PROMISE data repository, Ensemble techniques, Software fault prediction}
}

@inproceedings{10.1109/ICMLA.2012.145,
author = {Gao, Kehan and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {A Hybrid Approach to Coping with High Dimensionality and Class Imbalance for Software Defect Prediction},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.145},
doi = {10.1109/ICMLA.2012.145},
abstract = {High dimensionality and class imbalance are the two main problems affecting many software defect prediction. In this paper, we propose a new technique, named SelectRUSBoost, which is a form of ensemble learning that in-corporates data sampling to alleviate class imbalance and feature selection to resolve high dimensionality. To evaluate the effectiveness of the new technique, we apply it to a group of datasets in the context of software defect prediction. We employ two classification learners and six feature selection techniques. We compare the technique to the approach where feature selection and data sampling are used together, as well as the case where feature selection is used alone (no sampling used at all). The experimental results demonstrate that the SelectRUSBoost technique is more effective in improving classification performance compared to the other approaches.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 02},
pages = {281–288},
numpages = {8},
keywords = {software defect prediction, high dimensionality, class imbalance},
series = {ICMLA '12}
}

@proceedings{10.1145/3340482,
title = {MaLTeSQuE 2019: Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tallinn, Estonia}
}

@article{10.1007/s11219-019-09468-z,
author = {Eni\c{s}er, Hasan Ferit and Sen, Alper},
title = {Virtualization of stateful services via machine learning},
year = {2020},
issue_date = {Mar 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-019-09468-z},
doi = {10.1007/s11219-019-09468-z},
abstract = {Today’s enterprise software systems are much more complicated than the past. Increasing numbers of dependent applications, heterogeneous technologies, and wide usage of Service-Oriented Architectures (SOA), where numerous services communicate with each other, makes testing of such systems challenging. For testing these software systems, the concept of service virtualization is gaining popularity. Service virtualization is an automated technique to mimic the behavior of a given real service. Services can be classified as stateless or stateful services. Many services are stateful in nature, yet virtualization of stateful services is harder than virtualization of stateless services. In this work, we introduce two novel stateful service virtualization approaches. We employ classification-based and sequence-to-sequence-based machine learning algorithms in developing our solutions. Classification is a supervised learning method where the task is assigning given inputs to corresponding classes. A sequence-to-sequence model is a deep neural network architecture where the input and the output are sequences. We demonstrate the validity of our approaches on three datasets. Our evaluation shows that we obtain 75 % to 81 % accuracy on subject datasets with classification based method. Our deep neural network-based solution achieves even better accuracy results ranging from 89 to 97 % on subject datasets. Our evaluation on training times of the mentioned techniques show that classification based technique significantly outperforms other methods.},
journal = {Software Quality Journal},
month = mar,
pages = {283–306},
numpages = {24},
keywords = {Machine learning, Service virtualization, Software testing}
}

@inproceedings{10.1145/2786805.2786814,
author = {Nam, Jaechang and Kim, Sunghun},
title = {Heterogeneous defect prediction},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786814},
doi = {10.1145/2786805.2786814},
abstract = {Software defect prediction is one of the most active research areas in software engineering. We can build a prediction model with defect data collected from a software project and predict defects in the same project, i.e. within-project defect prediction (WPDP). Researchers also proposed cross-project defect prediction (CPDP) to predict defects for new projects lacking in defect data by using prediction models built by other projects. In recent studies, CPDP is proved to be feasible. However, CPDP requires projects that have the same metric set, meaning the metric sets should be identical between projects. As a result, current techniques for CPDP are difficult to apply across projects with heterogeneous metric sets. To address the limitation, we propose heterogeneous defect prediction (HDP) to predict defects across projects with heterogeneous metric sets. Our HDP approach conducts metric selection and metric matching to build a prediction model between projects with heterogeneous metric sets. Our empirical study on 28 subjects shows that about 68% of predictions using our approach outperform or are comparable to WPDP with statistical significance.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {508–519},
numpages = {12},
keywords = {quality assurance, heterogeneous metrics, Defect prediction},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.1145/3439961.3439991,
author = {Rivero, Luis and Diniz, Jo\~{a}o and Silva, Giovanni and Borralho, Gabriel and Braz Junior, Geraldo and Paiva, Anselmo and Alves, Erika and Oliveira, Milton},
title = {Deployment of a Machine Learning System for Predicting Lawsuits Against Power Companies: Lessons Learned from an Agile Testing Experience for Improving Software Quality},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439991},
doi = {10.1145/3439961.3439991},
abstract = {The advances in Machine Learning (ML) require software organizations to evolve their development processes in order to improve the quality of ML systems. Within the software development process, the testing stage of an ML system is more critical, considering that it is necessary to add data validation, trained model quality evaluation, and model validation to traditional unit, integration tests and system tests. In this paper, we focus on reporting the lessons learned of using model testing and exploratory testing within the context of the agile development process of an ML system that predicts lawsuits proneness in energy supply companies. Through the development of the project, the SCRUM agile methodology was applied and activities related to the development of the ML model and the development of the end-user application were defined. After the testing process of the ML model, we managed to achieve 93.89 accuracy; 95.58 specificity; 88.84 sensitivity; and 87.09 precision. Furthermore, we focused on the quality of use of the application embedding the ML model, by carrying out exploratory testing. As a result, through several iterations, different types of defects were identified and corrected. Our lessons learned support software engineers willing to develop ML systems that consider both the ML model and the end-user application.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {30},
numpages = {10},
keywords = {and Tools, and Testing, Verification, Validation, Software Processes, Methods},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@article{10.1007/s10489-021-02346-x,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {Software fault prediction based on the dynamic selection of learning technique: findings from the eclipse project study},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {12},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-021-02346-x},
doi = {10.1007/s10489-021-02346-x},
abstract = {An effective software fault prediction (SFP) model could help developers in the quick and prompt detection of faults and thus help enhance the overall reliability and quality of the software project. Variations in the prediction performance of learning techniques for different software systems make it difficult to select a suitable learning technique for fault prediction modeling. The evaluation of previously presented SFP approaches has shown that single machine learning-based models failed to provide the best accuracy in any context, highlighting the need to use multiple techniques to build the SFP model. To solve this problem, we present and discuss a software fault prediction approach based on selecting the most appropriate learning techniques from a set of competitive and accurate learning techniques for building a fault prediction model. In work, we apply the discussed SFP approach for the five Eclipse project datasets and nine Object-oriented (OO) project datasets and report the findings of the experimental study. We have used different performance measures, i.e., AUC, accuracy, sensitivity, and specificity, to assess the discussed approach’s performance. Further, we have performed a cost-benefit analysis to evaluate the economic viability of the approach. Results showed that the presented approach predicted the software’s faults effectively for the used accuracy, AUC, sensitivity, and specificity measures with the highest achieved values of 0.816, 0.835, 0.98, and 0.903 for AUC, accuracy, sensitivity, and specificity, respectively. The cost-benefit analysis of the approach showed that it could help reduce the overall software testing cost.},
journal = {Applied Intelligence},
month = dec,
pages = {8945–8960},
numpages = {16},
keywords = {Machine learning techniques, Cost-benefit analysis, Dynamic selection, Eclipse project, Software fault prediction}
}

@phdthesis{10.5555/AAI28107980,
author = {Alqadi, Basma},
title = {Slice-Based Cognitive Complexity Metrics for Defect Prediction},
year = {2020},
isbn = {9798662545755},
publisher = {Kent State University},
address = {USA},
abstract = {Researchers have identified several quality metrics to predict defects, relying on different information however, these approaches lack metrics to estimate the effort of program understandability of system artifacts. Code that is understandable is often considered more maintainable. Programmers must have mental capacity for dealing with large workloads for short periods of time and must have cognitive mechanisms for locating the code relevant to a particular feature or variable. Program slicing is a technique that programmers use when scanning code for comprehension.In this dissertation, novel metrics to compute the cognitive complexity based on program slicing are introduced.  These metrics help identify code that is more likely to have defects due to being challenging to comprehension. The metrics include such measures as the total number of slices in a file, the size, the average number of identifiers, and the average spatial distance of a slice.  A scalable lightweight slicing tool is used to compute the necessary slicing data. A thorough empirical investigation into how cognitive complexity correlates with and predicts defects in the version histories of 10 datasets of 7 open source systems is performed. The results show that the increase of cognitive complexity significantly increases the number of defects in 94% of the cases. In a comparison study to metrics that have been shown to correlate with understandability and with defects, the addition of cognitive complexity metrics shows better prediction by up to 14% in F1, 16% in AUC, and 35% in R2.},
note = {AAI28107980}
}

@inproceedings{10.1145/3183440.3194992,
author = {Guo, Yuchen and Shepperd, Martin and Li, Ning},
title = {Bridging effort-aware prediction and strong classification: a just-in-time software defect prediction study},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3194992},
doi = {10.1145/3183440.3194992},
abstract = {Context: Most research into software defect prediction ignores the differing amount of effort entailed in searching for defects between software components. The result is sub-optimal solutions in terms of allocating testing resources. Recently effort-aware (EA) defect prediction has sought to redress this deficiency. However, there is a gap between previous classification research and EA prediction.Objective: We seek to transfer strong defect classification capability to efficient effort-aware software defect prediction.Method: We study the relationship between classification performance and the cost-effectiveness curve experimentally (using six open-source software data sets).Results: We observe extremely skewed distributions of change size which contributes to the lack of relationship between classification performance and the ability to find efficient test orderings for defect detection. Trimming allows all effort-aware approaches bridging high classification capability to efficient effort-aware performance.Conclusion: Effort distributions dominate effort-aware models. Trimming is a practical method to handle this problem.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {325–326},
numpages = {2},
keywords = {defect prediction, effort-aware, just-in-time, software},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1109/WCRE.2011.37,
author = {Tan, Xi and Peng, Xin and Pan, Sen and Zhao, Wenyun},
title = {Assessing Software Quality by Program Clustering and Defect Prediction},
year = {2011},
isbn = {9780769545820},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WCRE.2011.37},
doi = {10.1109/WCRE.2011.37},
abstract = {Many empirical studies have shown that defect prediction models built on product metrics can be used to assess the quality of software modules. So far, most methods proposed in this direction predict defects by class or file. In this paper, we propose a novel software defect prediction method based on functional clusters of programs to improve the performance, especially the effort-aware performance, of defect prediction. In the method, we use proper-grained and problem-oriented program clusters as the basic units of defect prediction. To evaluate the effectiveness of the method, we conducted an experimental study on Eclipse 3.0. We found that, comparing with class-based models, cluster-based prediction models can significantly improve the recall (from 31.6% to 99.2%) and precision (from 73.8% to 91.6%) of defect prediction. According to the effort-aware evaluation, the effort needed to review code to find half of the total defects can be reduced by 6% if using cluster-based prediction models.},
booktitle = {Proceedings of the 2011 18th Working Conference on Reverse Engineering},
pages = {244–248},
numpages = {5},
keywords = {software quality, program clustering, defect prediction},
series = {WCRE '11}
}

@article{10.1016/j.cie.2021.107632,
author = {Shim, Jaewoong and Cho, Sungzoon and Kum, Euiseok and Jeong, Suho},
title = {Adaptive fault detection framework for recipe transition in semiconductor manufacturing},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {161},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2021.107632},
doi = {10.1016/j.cie.2021.107632},
journal = {Comput. Ind. Eng.},
month = nov,
numpages = {7},
keywords = {Fault detection and classification model, Recipe transition, Sensor data, Domain adaptation, Semiconductor manufacturing}
}

@article{10.1016/j.eswa.2021.115492,
author = {Liu, Jie},
title = {A minority oversampling approach for fault detection with heterogeneous imbalanced data},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {184},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115492},
doi = {10.1016/j.eswa.2021.115492},
journal = {Expert Syst. Appl.},
month = dec,
numpages = {9},
keywords = {Minority oversampling, Feature heterogeneity, Imbalanced data, Fault detection}
}

@phdthesis{10.5555/AAI28498637,
author = {Khalil, Kasem Mohamed Ahmed and Ashok, Kumar, and Mohammad, Madani, and Michael, Totaro,},
advisor = {A, Bayoumi, Magdy},
title = {Fault Prediction and Self-Healing Paradigm for Intelligent Hardware Systems},
year = {2021},
isbn = {9798522907303},
publisher = {University of Louisiana at Lafayette},
abstract = {As the complexity of hardware systems grows, the failure rate, or the rate at which such systems produce faults, accelerates. Ideally, future hardware should heal faults before the faults can occur and impact a system adversely. Fault prediction is needed to identify a fault before it occurs, and this helps to heal the fault early to avoid losing data or missing some operation. Such systems, also referred to as intelligent hardware systems, are expected to revolutionize the way circuits and systems are designed, and it is the focus of this dissertation. An intelligent hardware system is expected to have mechanisms for self-healing and fault prediction. A novel mechanism for self-healing methods for Embryonic Hardware (EmHW), Network-on-Chip (NoC), and neural network is proposed. The proposed self-healing method is implemented in VHDL on Altera Arria 10 GX FPGA device. The area overhead of the proposed self-healing method for EmHW and NoC is 34% and 31%, respectively, with high reliability and the mean-time-to-failure that prove extended network age. The hardware fault prediction requires low-cost machine learning techniques. A hardware neural network optimization and reconfiguration is proposed for artificial neural networks, Long Short-Term Memory (LSTM), and Convolutional Neural Network (CNN). An Economic LSTM (ELSTM) is proposed, which saves 34% of the area and 35% of the power consumption compared to LSTM. Next, a novel Absolute Average Deviation (ADD) pooling method with very high accuracy for CNN is also. The AAD pooling achieves an accuracy of more than 98%. and has a modest 4%. It is synthesized using Synopsis in 45 nm technology and found to occupy an area of 244.466 nm2, and consume 0.31 mW of power. Two fault prediction methods are presented, and they are based on the proposed machine learning optimization methods. The proposed fault prediction methods are used for early transistor and architectural fault prediction for NoC and EmHW, using fast Fourier transform, Principal Component Analysis (PCA), Relative PCA (RPCA), ELSTM, and CNN. The proposed approaches are implemented using Tensorflow and FPGA device, and the result shows the proposed approach could predict a fault with the accuracy of more than 98%.},
note = {AAI28498637}
}

@article{10.1016/j.asoc.2019.03.051,
author = {Abdali, Ali and Mazlumi, Kazem and Noroozian, Reza},
title = {High-speed fault detection and location in DC microgrids systems using Multi-Criterion System and neural network},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {79},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2019.03.051},
doi = {10.1016/j.asoc.2019.03.051},
journal = {Appl. Soft Comput.},
month = jun,
pages = {341–353},
numpages = {13},
keywords = {Circuit breaker, LVDC microgrids, Neural network (NN), Multi-Criterion System (MCS), Fault location, Fault detection}
}

@inproceedings{10.1007/978-3-030-86970-0_30,
author = {Meyer, Angela},
title = {Early Fault Detection with Multi-target Neural Networks},
year = {2021},
isbn = {978-3-030-86969-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86970-0_30},
doi = {10.1007/978-3-030-86970-0_30},
abstract = {Wind power is seeing a strong growth around the world. At the same time, shrinking profit margins in the energy markets let wind farm managers explore options for cost reductions in the turbine operation and maintenance. Sensor-based condition monitoring facilitates remote diagnostics of turbine subsystems, enabling faster responses when unforeseen maintenance is required. Condition monitoring with data from the turbines’ supervisory control and data acquisition (SCADA) systems was proposed and SCADA-based fault detection and diagnosis approaches introduced based on single-task normal operation models of turbine state variables. As the number of SCADA channels has grown strongly, thousands of independent single-target models are in place today for monitoring a single turbine. Multi-target learning was recently proposed to limit the number of models. This study applied multi-target neural networks to the task of early fault detection in drive-train components. The accuracy and delay of detecting gear bearing faults were compared to state-of-the-art single-target approaches. We found that multi-target multi-layer perceptrons (MLPs) detected faults at least as early and in many cases earlier than single-target MLPs. The multi-target MLPs could detect faults up to several days earlier than the single-target models. This can deliver a significant advantage in the planning and performance of maintenance work. At the same time, the multi-target MLPs achieved the same level of prediction stability.},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part III},
pages = {429–437},
numpages = {9},
keywords = {Wind turbines, Normal behaviour models, Multi-target neural networks, Fault detection, Condition monitoring},
location = {Cagliari, Italy}
}

@article{10.1145/3386360,
author = {Liu, Mengyun and Xia, Lixue and Wang, Yu and Chakrabarty, Krishnendu},
title = {Algorithmic Fault Detection for RRAM-based Matrix Operations},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {3},
issn = {1084-4309},
url = {https://doi.org/10.1145/3386360},
doi = {10.1145/3386360},
abstract = {An RRAM-based computing system (RCS) provides an energy-efficient hardware implementation of vector-matrix multiplication for machine-learning hardware. However, it is vulnerable to faults due to the immature RRAM fabrication process. We propose an efficient fault tolerance method for RCS; the proposed method, referred to as extended-ABFT (X-ABFT), is inspired by algorithm-based fault tolerance (ABFT). We utilize row checksums and test-input vectors to extract signatures for fault detection and error correction. We present a solution to alleviate the overflow problem caused by the limited number of voltage levels for the test-input signals. Simulation results show that for a Hopfield classifier with faults in 5% of its RRAM cells, X-ABFT allows us to achieve nearly the same classification accuracy as in the fault-free case.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
articleno = {29},
numpages = {31},
keywords = {neural network, fault detection, RRAM}
}

@article{10.1145/3470006,
author = {Nikanjam, Amin and Braiek, Houssem Ben and Morovati, Mohammad Mehdi and Khomh, Foutse},
title = {Automatic Fault Detection for Deep Learning Programs Using Graph Transformations},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3470006},
doi = {10.1145/3470006},
abstract = {Nowadays, we are witnessing an increasing demand in both corporates and academia for exploiting Deep Learning (DL) to solve complex real-world problems. A DL program encodes the network structure of a desirable DL model and the process by which the model learns from the training dataset. Like any software, a DL program can be faulty, which implies substantial challenges of software quality assurance, especially in safety-critical domains. It is therefore crucial to equip DL development teams with efficient fault detection techniques and tools. In this article, we propose NeuraLint, a model-based fault detection approach for DL programs, using meta-modeling and graph transformations. First, we design a meta-model for DL programs that includes their base skeleton and fundamental properties. Then, we construct a graph-based verification process that covers 23 rules defined on top of the meta-model and implemented as graph transformations to detect faults and design inefficiencies in the generated models (i.e., instances of the meta-model). First, the proposed approach is evaluated by finding faults and design inefficiencies in 28 synthesized examples built from common problems reported in the literature. Then NeuraLint successfully finds 64 faults and design inefficiencies in 34 real-world DL programs extracted from Stack Overflow posts and GitHub repositories. The results show that NeuraLint effectively detects faults and design issues in both synthesized and real-world examples with a recall of 70.5% and a precision of 100%. Although the proposed meta-model is designed for feedforward neural networks, it can be extended to support other neural network architectures such as recurrent neural networks. Researchers can also expand our set of verification rules to cover more types of issues in DL programs.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {14},
numpages = {27},
keywords = {fault detection, deep learning, model-based verification, Graph transformations}
}

@article{10.1016/j.cageo.2019.104344,
author = {Cunha, Augusto and Pochet, Axelle and Lopes, H\'{e}lio and Gattass, Marcelo},
title = {Seismic fault detection in real data using transfer learning from a convolutional neural network pre-trained with synthetic seismic data},
year = {2020},
issue_date = {Feb 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {135},
number = {C},
issn = {0098-3004},
url = {https://doi.org/10.1016/j.cageo.2019.104344},
doi = {10.1016/j.cageo.2019.104344},
journal = {Comput. Geosci.},
month = feb,
numpages = {9},
keywords = {Seismic fault, Convolutional neural network, Transfer learning}
}

@inproceedings{10.1145/3377811.3380360,
author = {Li, Ke and Xiang, Zilin and Chen, Tao and Wang, Shuo and Tan, Kay Chen},
title = {Understanding the automated parameter optimization on transfer learning for cross-project defect prediction: an empirical study},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380360},
doi = {10.1145/3377811.3380360},
abstract = {Data-driven defect prediction has become increasingly important in software engineering process. Since it is not uncommon that data from a software project is insufficient for training a reliable defect prediction model, transfer learning that borrows data/konwledge from other projects to facilitate the model building at the current project, namely cross-project defect prediction (CPDP), is naturally plausible. Most CPDP techniques involve two major steps, i.e., transfer learning and classification, each of which has at least one parameter to be tuned to achieve their optimal performance. This practice fits well with the purpose of automated parameter optimization. However, there is a lack of thorough understanding about what are the impacts of automated parameter optimization on various CPDP techniques. In this paper, we present the first empirical study that looks into such impacts on 62 CPDP techniques, 13 of which are chosen from the existing CPDP literature while the other 49 ones have not been explored before. We build defect prediction models over 20 real-world software projects that are of different scales and characteristics. Our findings demonstrate that: (1) Automated parameter optimization substantially improves the defect prediction performance of 77% CPDP techniques with a manageable computational cost. Thus more efforts on this aspect are required in future CPDP studies. (2) Transfer learning is of ultimate importance in CPDP. Given a tight computational budget, it is more cost-effective to focus on optimizing the parameter configuration of transfer learning algorithms (3) The research on CPDP is far from mature where it is 'not difficult' to find a better alternative by making a combination of existing transfer learning and classification techniques. This finding provides important insights about the future design of CPDP techniques.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {566–577},
numpages = {12},
keywords = {automated parameter optimization, classification techniques, cross-project defect prediction, transfer learning},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1007/978-3-030-16142-2_17,
author = {Li, Heng-Yi and Li, Ming and Zhou, Zhi-Hua},
title = {Towards One Reusable Model for Various Software Defect Mining Tasks},
year = {2019},
isbn = {978-3-030-16141-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-16142-2_17},
doi = {10.1007/978-3-030-16142-2_17},
abstract = {Software defect mining is playing an important role in software quality assurance. Many deep neural network based models have been proposed for software defect mining tasks, and have pushed forward the state-of-the-art mining performance. These deep models usually require a huge amount of task-specific source code for training to capture the code functionality to mine the defects. But such requirement is often hard to be satisfied in practice. On the other hand, lots of free source code and corresponding textual explanations are publicly available in the open source software repositories, which is potentially useful in modeling code functionality. However, no previous studies ever leverage these resources to help defect mining tasks. In this paper, we propose a novel framework to learn one reusable deep model for code functional representation using the huge amount of publicly available task-free source code as well as their textual explanations. And then reuse it for various software defect mining tasks. Experimental results on three major defect mining tasks with real world datasets indicate that by reusing this model in specific tasks, the mining performance outperforms its counterpart that learns deep models from scratch, especially when the training data is insufficient.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 23rd Pacific-Asia Conference, PAKDD 2019, Macau, China, April 14-17, 2019, Proceedings, Part III},
pages = {212–224},
numpages = {13},
keywords = {Software defect mining, Machine learning, Model reuse},
location = {Macau, China}
}

@inproceedings{10.5555/3340730.3340750,
author = {Catolino, Gemma and Di Nucci, Dario and Ferrucci, Filomena},
title = {Cross-project just-in-time bug prediction for mobile apps: an empirical assessment},
year = {2019},
publisher = {IEEE Press},
abstract = {Bug Prediction is an activity aimed at identifying defect-prone source code entities that allows developers to focus testing efforts on specific areas of software systems. Recently, the research community proposed Just-in-Time (JIT) Bug Prediction with the goal of detecting bugs at commit-level. While this topic has been extensively investigated in the context of traditional systems, to the best of our knowledge, only a few preliminary studies assessed the performance of the technique in a mobile environment, by applying the metrics proposed by Kamei et al. in a within-project scenario. The results of these studies highlighted that there is still room for improvement. In this paper, we faced this problem to understand (i) which Kamei et al.'s metrics are useful in the mobile context, (ii) if different classifiers impact the performance of cross-project JIT bug prediction models and (iii) whether the application of ensemble techniques improves the capabilities of the models. To carry out the experiment, we first applied a feature selection technique, i.e., InfoGain, to filter relevant features and avoid models multicollinearity. Then, we assessed and compared the performance of four different well-known classifiers and four ensemble techniques. Our empirical study involved 14 apps and 42,543 commits extracted from the Commit Guru platform. The results show that Naive Bayes achieves the best performance with respect to the other classifiers and in some cases outperforms some well-known ensemble techniques.},
booktitle = {Proceedings of the 6th International Conference on Mobile Software Engineering and Systems},
pages = {99–110},
numpages = {12},
keywords = {metrics, empirical study, JIT bug prediction},
location = {Montreal, Quebec, Canada},
series = {MOBILESoft '19}
}

@inproceedings{10.1145/3340482.3342742,
author = {Borg, Markus and Svensson, Oscar and Berg, Kristian and Hansson, Daniel},
title = {SZZ unleashed: an open implementation of the SZZ algorithm - featuring example usage in a study of just-in-time bug prediction for the Jenkins project},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340482.3342742},
doi = {10.1145/3340482.3342742},
abstract = {Machine learning applications in software engineering often rely on detailed information about bugs. While issue trackers often contain information about when bugs were fixed, details about when they were introduced to the system are often absent. As a remedy, researchers often rely on the SZZ algorithm as a heuristic approach to identify bug-introducing software changes. Unfortunately, as reported in a recent systematic literature review, few researchers have made their SZZ implementations publicly available. Consequently, there is a risk that research effort is wasted as new projects based on SZZ output need to initially reimplement the approach. Furthermore, there is a risk that newly developed (closed source) SZZ implementations have not been properly tested, thus conducting research based on their output might introduce threats to validity. We present SZZ Unleashed, an open implementation of the SZZ algorithm for git repositories. This paper describes our implementation along with a usage example for the Jenkins project, and conclude with an illustrative study on just-in-time bug prediction. We hope to continue evolving SZZ Unleashed on GitHub, and warmly invite the community to contribute.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
pages = {7–12},
numpages = {6},
keywords = {mining software repositories, issue tracking, defect prediction, SZZ},
location = {Tallinn, Estonia},
series = {MaLTeSQuE 2019}
}

@inproceedings{10.1109/AIM.2017.8014159,
author = {Assaf, R. and Nefti-Meziani, S. and Scarf, P.},
title = {Unsupervised learning for improving fault detection in complex systems},
year = {2017},
isbn = {978-1-5090-5998-0},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/AIM.2017.8014159},
doi = {10.1109/AIM.2017.8014159},
abstract = {Complex mechatronic systems are becoming more widespread such as in industrial machinery and robotic systems. Detecting faults in such systems proves to be a challenging task due to the multitude of components that are interacting. In this paper, we demonstrate how we use an unsupervised learning technique to detect accelerated wear patterns in complex systems, where wear interactions between components are present. We use Gaussian Mixture Models (GMM), to uncover the intricate wear process that takes place when old worn out components are coupled with new healthy components. Then through a numerical simulation of a complex system, and experimental data gathered from a gearbox accelerated life testing platform, we demonstrate that this new-old component coupling leads to an accelerated rate of wear of the new components, and so they would have a lowered life expectancy that would jeopardize the reliability of the system. This approach shows that more fault prevention related information is gained if we take all interacting components into account when monitoring and modelling wear processes of complex systems. Such gained information could lead to more accurate Remaining Useful Lifetime (RUL) estimations and more robust fault prevention.},
booktitle = {2017 IEEE International Conference on Advanced Intelligent Mechatronics (AIM)},
pages = {1058–1064},
numpages = {7},
location = {Munich, Germany}
}

@article{10.1007/s10664-016-9468-y,
author = {Herbold, Steffen and Trautsch, Alexander and Grabowski, Jens},
title = {Global vs. local models for cross-project defect prediction},
year = {2017},
issue_date = {August    2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {4},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-016-9468-y},
doi = {10.1007/s10664-016-9468-y},
abstract = {Although researchers invested significant effort, the performance of defect prediction in a cross-project setting, i.e., with data that does not come from the same project, is still unsatisfactory. A recent proposal for the improvement of defect prediction is using local models. With local models, the available data is first clustered into homogeneous regions and afterwards separate classifiers are trained for each homogeneous region. Since the main problem of cross-project defect prediction is data heterogeneity, the idea of local models is promising. Therefore, we perform a conceptual replication of the previous studies on local models with a focus on cross-project defect prediction. In a large case study, we evaluate the performance of local models and investigate their advantages and drawbacks for cross-project predictions. To this aim, we also compare the performance with a global model and a transfer learning technique designed for cross-project defect predictions. Our findings show that local models make only a minor difference in comparison to global models and transfer learning for cross-project defect prediction. While these results are negative, they provide valuable knowledge about the limitations of local models and increase the validity of previously gained research results.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {1866–1902},
numpages = {37},
keywords = {Local models, Defect prediction, Cross-project}
}

@inproceedings{10.1007/978-3-030-38961-1_8,
author = {Sun, Yuanyuan and Xu, Lele and Guo, Lili and Li, Ye and Wang, Yongming},
title = {A Comparison Study of VAE and GAN for Software Fault Prediction},
year = {2019},
isbn = {978-3-030-38960-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38961-1_8},
doi = {10.1007/978-3-030-38961-1_8},
abstract = {Software fault is an unavoidable problem in software project. How to predict software fault to enhance safety and reliability of system is worth studying. In recent years, deep learning has been widely used in the fields of image, text and voice. However it is seldom applied in the field of software fault prediction. Considering the ability of deep learning, we select the deep learning techniques of VAE and GAN for software fault prediction and compare the performance of them. There is one salient feature of software fault data. The proportion of non-fault data is well above the proportion of fault data. Because of the imbalanced data, it is difficult to get high accuracy to predict software fault. As we known, VAE and GAN are able to generate synthetic samples that obey the distribution of real data. We try to take advantage of their power to generate new fault samples in order to improve the accuracy of software fault prediction. The architectures of VAE and GAN are designed to fit for the high dimensional software fault data. New software fault samples are generated to balance the software fault datasets in order to get better performance for software fault prediction. The models of VAE and GAN are trained on GPU TITAN X. SMOTE is also adopted in order to compare the performance with VAE and GAN. The results in the experiment show that VAE and GAN are useful techniques for software fault prediction and VAE has better performance than GAN on this issue.},
booktitle = {Algorithms and Architectures for Parallel Processing: 19th International Conference, ICA3PP 2019, Melbourne, VIC, Australia, December 9–11, 2019, Proceedings, Part II},
pages = {82–96},
numpages = {15},
keywords = {Software fault prediction, GAN, VAE, Deep learning},
location = {Melbourne, VIC, Australia}
}

@article{10.1007/s10664-019-09736-3,
author = {Kondo, Masanari and German, Daniel M. and Mizuno, Osamu and Choi, Eun-Hye},
title = {The impact of context metrics on just-in-time defect prediction},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09736-3},
doi = {10.1007/s10664-019-09736-3},
abstract = {Traditional just-in-time defect prediction approaches have been using changed lines of software to predict defective-changes in software development. However, they disregard information around the changed lines. Our main hypothesis is that such information has an impact on the likelihood that the change is defective. To take advantage of this information in defect prediction, we consider n-lines (n = 1,2,…) that precede and follow the changed lines (which we call context lines), and propose metrics that measure them, which we call “Context Metrics.” Specifically, these context metrics are defined as the number of words/keywords in the context lines. In a large-scale empirical study using six open source software projects, we compare the performance of using our context metrics, traditional code churn metrics (e.g., the number of modified subsystems), our extended context metrics which measure not only context lines but also changed lines, and combination metrics that use two extended context metrics at a prediction model for defect prediction. The results show that context metrics that consider the context lines of added-lines achieve the best median value in all cases in terms of a statistical test. Moreover, using few number of context lines is suitable for context metric that considers words, and using more number of context lines is suitable for context metric that considers keywords. Finally, the combination metrics of two extended context metrics significantly outperform all studied metrics in all studied projects w. r. t. the area under the receiver operation characteristic curve (AUC) and Matthews correlation coefficient (MCC).},
journal = {Empirical Softw. Engg.},
month = jan,
pages = {890–939},
numpages = {50},
keywords = {Code churn metrics, Indentation metrics, Changed lines, Context lines, Source code changes, Defect prediction, Just-in-time defect prediction}
}

@inproceedings{10.1145/2931037.2931039,
author = {Bowes, David and Hall, Tracy and Harman, Mark and Jia, Yue and Sarro, Federica and Wu, Fan},
title = {Mutation-aware fault prediction},
year = {2016},
isbn = {9781450343909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2931037.2931039},
doi = {10.1145/2931037.2931039},
abstract = {We introduce mutation-aware fault prediction, which leverages additional guidance from metrics constructed in terms of mutants and the test cases that cover and detect them. We report the results of 12 sets of experiments, applying 4 different predictive modelling techniques to 3 large real-world systems (both open and closed source). The results show that our proposal can significantly (p ≤ 0.05) improve fault prediction performance. Moreover, mutation-based metrics lie in the top 5% most frequently relied upon fault predictors in 10 of the 12 sets of experiments, and provide the majority of the top ten fault predictors in 9 of the 12 sets of experiments.},
booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
pages = {330–341},
numpages = {12},
keywords = {Software Metrics, Software Fault Prediction, Software Defect Prediction, Mutation Testing, Empirical Study},
location = {Saarbr\"{u}cken, Germany},
series = {ISSTA 2016}
}

@book{10.5555/3264684,
author = {Kumar, Sandeep and Rathore, Santosh Singh},
title = {Software Fault Prediction: A Road Map},
year = {2018},
isbn = {9789811087141},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {This book focuses on exploring the use of software fault prediction in building reliable and robust software systems. It is divided into the following chapters: Chapter 1 presents an introduction to the study and also introduces basic concepts of software fault prediction. Chapter 2 explains the generalized architecture of the software fault prediction process and discusses its various components. In turn, Chapter 3 provides detailed information on types of fault prediction models and discusses the latest literature on each model. Chapter 4 describes the software fault datasets and diverse issues concerning fault datasets when building fault prediction models. Chapter 5 presents a study evaluating different techniques on the basis of their performance for software fault prediction. Chapter 6 presents another study evaluating techniques for predicting the number of faults in the software modules. In closing, Chapter 7 provides a summary of the topics discussed. The book will be of immense benefit to all readers who are interested in starting research in this area. In addition, it offers experienced researchers a valuable overview of the latest work in this area.}
}

@inproceedings{10.1145/3412841.3442020,
author = {Hosseini, Seyedrebvar and Turhan, Burak},
title = {A comparison of similarity based instance selection methods for cross project defect prediction},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442020},
doi = {10.1145/3412841.3442020},
abstract = {Context: Previous studies have shown that training data instance selection based on nearest neighborhood (NN) information can lead to better performance in cross project defect prediction (CPDP) by reducing heterogeneity in training datasets. However, neighborhood calculation is computationally expensive and approximate methods such as Locality Sensitive Hashing (LSH) can be as effective as exact methods. Aim: We aim at comparing instance selection methods for CPDP, namely LSH, NN-filter, and Genetic Instance Selection (GIS). Method: We conduct experiments with five base learners, optimizing their hyper parameters, on 13 datasets from PROMISE repository in order to compare the performance of LSH with benchmark instance selection methods NN-Filter and GIS. Results: The statistical tests show six distinct groups for F-measure performance. The top two group contains only LSH and GIS benchmarks whereas the bottom two groups contain only NN-Filter variants. LSH and GIS favor recall more than precision. In fact, for precision performance only three significantly distinct groups are detected by the tests where the top group is comprised of NN-Filter variants only. Recall wise, 16 different groups are identified where the top three groups contain only LSH methods, four of the next six are GIS only and the bottom five contain only NN-Filter. Finally, NN-Filter benchmarks never outperform the LSH counterparts with the same base learner, tuned or non-tuned. Further, they never even belong to the same rank group, meaning that LSH is always significantly better than NN-Filter with the same learner and settings. Conclusions: The increase in performance and the decrease in computational overhead and runtime make LSH a promising approach. However, the performance of LSH is based on high recall and in environments where precision is considered more important NN-Filter should be considered.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1455–1464},
numpages = {10},
keywords = {approximate near neighbour, cross project defect prediction, instance selection, locality sensitive hashing, search based optimisation},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@article{10.1016/j.procs.2021.10.065,
author = {Gaber, Lamya and Hussein, Aziza I. and Moness, Mohammed},
title = {Fault Detection based on Deep Learning for Digital VLSI Circuits},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {194},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.10.065},
doi = {10.1016/j.procs.2021.10.065},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {122–131},
numpages = {10},
keywords = {Deep Learning, ML, Sparse Autoencoder, Design Debugging}
}

@article{10.1049/sfw2.12040,
author = {Zhao, Kunsong and Xu, Zhou and Yan, Meng and Xue, Lei and Li, Wei and Catolino, Gemma},
title = {A compositional model for effort‐aware Just‐In‐Time defect prediction on android apps},
year = {2021},
issue_date = {June 2022},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {16},
number = {3},
url = {https://doi.org/10.1049/sfw2.12040},
doi = {10.1049/sfw2.12040},
abstract = {Android apps have played important roles in daily life and work. To meet the new requirements from users, the apps encounter frequent updates, which involves a large quantity of code commits. Previous studies proposed to apply Just‐in‐Time (JIT) defect prediction for apps to timely identify whether the new code commits can introduce defects into apps, aiming to assure their quality. In general, high‐quality features are benefits for improving the classification performance. In addition, the number of defective commit instances is much fewer than that of clean ones, that is the defect data is class imbalanced. In this study, a novel compositional model, called KPIDL, is proposed to conduct the JIT defect prediction task for Android apps. More specifically, KPIDL first exploits a feature learning technique to preprocess original data for obtaining better feature representation, and then introduces a state‐of‐the‐art cost‐sensitive cross‐entropy loss function into the deep neural network to alleviate the class imbalance issue by considering the prior probability of the two types of classes. The experiments were conducted on a benchmark defect data consisting of 15 Android apps. The experimental results show that the proposed KPIDL model performs significantly better than 25 comparative methods in terms of two effort‐aware performance indicators in most cases.},
journal = {IET Software},
month = aug,
pages = {259–278},
numpages = {20},
keywords = {software quality, software performance evaluation, fault tolerance}
}

@article{10.5555/3197793.3197817,
author = {Shukla, Swapnil and Radhakrishnan, T. and Muthukumaran, K. and Neti, Lalita Bhanu},
title = {Multi-objective cross-version defect prediction},
year = {2018},
issue_date = {March     2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {6},
issn = {1432-7643},
abstract = {Defect prediction models help software project teams to spot defect-prone source files of software systems. Software project teams can prioritize and put up rigorous quality assurance (QA) activities on these predicted defect-prone files to minimize post-release defects so that quality software can be delivered. Cross-version defect prediction is building a prediction model from the previous version of a software project to predict defects in the current version. This is more practical than the other two ways of building models, i.e., cross-project prediction model and cross- validation prediction models, as previous version of same software project will have similar parameter distribution among files. In this paper, we formulate cross-version defect prediction problem as a multi-objective optimization problem with two objective functions: (a) maximizing recall by minimizing misclassification cost and (b) maximizing recall by minimizing cost of QA activities on defect prone files. The two multi-objective defect prediction models are compared with four traditional machine learning algorithms, namely logistic regression, na\"{\i}ve Bayes, decision tree and random forest. We have used 11 projects from the PROMISE repository consisting of a total of 41 different versions of these projects. Our findings show that multi-objective logistic regression is more cost-effective than single-objective algorithms.},
journal = {Soft Comput.},
month = mar,
pages = {1959–1980},
numpages = {22},
keywords = {Search-based software engineering, Multi-objective optimization, Misclassification cost, Cross-version defect prediction, Cost-effectiveness}
}

@article{10.1007/s11390-019-1959-z,
author = {Xu, Zhou and Pang, Shuai and Zhang, Tao and Luo, Xia-Pu and Liu, Jin and Tang, Yu-Tian and Yu, Xiao and Xue, Lei},
title = {Cross Project Defect Prediction via Balanced Distribution Adaptation Based Transfer Learning},
year = {2019},
issue_date = {Sep 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {5},
issn = {1000-9000},
url = {https://doi.org/10.1007/s11390-019-1959-z},
doi = {10.1007/s11390-019-1959-z},
abstract = {Defect prediction assists the rational allocation of testing resources by detecting the potentially defective software modules before releasing products. When a project has no historical labeled defect data, cross project defect prediction (CPDP) is an alternative technique for this scenario. CPDP utilizes labeled defect data of an external project to construct a classification model to predict the module labels of the current project. Transfer learning based CPDP methods are the current mainstream. In general, such methods aim to minimize the distribution differences between the data of the two projects. However, previous methods mainly focus on the marginal distribution difference but ignore the conditional distribution difference, which will lead to unsatisfactory performance. In this work, we use a novel balanced distribution adaptation (BDA) based transfer learning method to narrow this gap. BDA simultaneously considers the two kinds of distribution differences and adaptively assigns different weights to them. To evaluate the effectiveness of BDA for CPDP performance, we conduct experiments on 18 projects from four datasets using six indicators (i.e., F-measure, g-means, Balance, AUC, EARecall, and EAF-measure). Compared with 12 baseline methods, BDA achieves average improvements of 23.8%, 12.5%, 11.5%, 4.7%, 34.2%, and 33.7% in terms of the six indicators respectively over four datasets.},
journal = {J. Comput. Sci. Technol.},
month = sep,
pages = {1039–1062},
numpages = {24},
keywords = {effort-aware indicator, balancing distribution, transfer learning, cross-project defect prediction}
}

@inproceedings{10.1007/978-3-030-90539-2_25,
author = {Molan, Martin and Borghesi, Andrea and Beneventi, Francesco and Guarrasi, Massimiliano and Bartolini, Andrea},
title = {An Explainable Model for Fault Detection in HPC Systems},
year = {2021},
isbn = {978-3-030-90538-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-90539-2_25},
doi = {10.1007/978-3-030-90539-2_25},
abstract = {Large supercomputers are composed of numerous components that risk to break down or behave in unwanted manners. Identifying broken components is a daunting task for system administrators. Hence an automated tool would be a boon for the systems resiliency. The wealth of data available in a supercomputer can be used for this task. In this work we propose an approach to take advantage of holistic data centre monitoring, system administrator node status labeling and an explainable model for fault detection in supercomputing nodes. The proposed model aims at classifying the different states of the computing nodes thanks to the labeled data describing the supercomputer behaviour, data which is typically collected by system administrators but not integrated in holistic monitoring infrastructure for data center automation. In comparison the other method, the one proposed here is robust and provide explainable predictions. The model has been trained and validated on data gathered from a tier-0 supercomputer in production.},
booktitle = {High Performance Computing: ISC High Performance Digital 2021 International Workshops, Frankfurt Am Main, Germany, June 24 – July 2, 2021, Revised Selected Papers},
pages = {378–391},
numpages = {14},
keywords = {Fault detection, High performance computing, Machine learning}
}

@inproceedings{10.1007/978-3-030-62822-2_12,
author = {Zhou, Yangxi and Zhu, Yan and Chen, Liangyu},
title = {Software Defect-Proneness Prediction with Package Cohesion and Coupling Metrics Based on Complex Network Theory},
year = {2020},
isbn = {978-3-030-62821-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62822-2_12},
doi = {10.1007/978-3-030-62822-2_12},
abstract = {Driven by functionality requirements, software codes are increasingly inflated, and invocations between codes are frequent and random. This makes it difficult for programmers to be thoughtful when modifying code, increasing the risk of defects. In an object-oriented software system, packages take the role of a middle tier that aggregates classes and limits class access. However, as the software system evolves, the logic and correctness of packages are weakened. In this paper, we explore the relation between package metrics and object-oriented software defect-proneness. We use two metrics of package cohesion and coupling based on complex network theory to verify the impact of code structure on software quality. On six Java software systems, the experimental result shows that the cohesion and coupling metrics play a positive role in software defect prediction, and they can correctly and effectively evaluate package organization structure. Meanwhile, our study confirms that compliance with the design principle of high cohesion and low coupling can reduce the risk of software defect-proneness and improve software quality.},
booktitle = {Dependable Software Engineering. Theories, Tools, and Applications: 6th International Symposium, SETTA 2020, Guangzhou, China, November 24–27, 2020, Proceedings},
pages = {186–201},
numpages = {16},
keywords = {Cohesion and coupling metrics, Defect proneness, Software package},
location = {Guangzhou, China}
}

@article{10.1016/j.jss.2016.02.015,
author = {Rana, Rakesh and Staron, Miroslaw and Berger, Christian and Hansson, J\"{o}rgen and Nilsson, Martin and Meding, Wilhelm},
title = {Analyzing defect inflow distribution and applying Bayesian inference method for software defect prediction in large software projects},
year = {2016},
issue_date = {July 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {117},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.02.015},
doi = {10.1016/j.jss.2016.02.015},
abstract = {Defect inflow distribution of 14 large projects from industry &amp; OSS is analyzed.6 standard distributions are evaluated for their ability to fit the defect inflow.12 out of 14 projects defect inflow data was described best by beta distribution.Historical projects information is useful for early defect prediction using Bayesian inference method. Tracking and predicting quality and reliability is a major challenge in large and distributed software development projects. A number of standard distributions have been successfully used in reliability engineering theory and practice, common among these for modeling software defect inflow being exponential, Weibull, beta and Non-Homogeneous Poisson Process (NHPP). Although standard distribution models have been recognized in reliability engineering practice, their ability to fit defect data from proprietary and OSS software projects is not well understood. Lack of knowledge about underlying defect inflow distribution also leads to difficulty in applying Bayesian based inference methods for software defect prediction. In this paper we explore the defect inflow distribution of total of fourteen large software projects/release from two industrial domain and open source community. We evaluate six standard distributions for their ability to fit the defect inflow data and also assess which information criterion is practical for selecting the distribution with best fit. Our results show that beta distribution provides the best fit to the defect inflow data for all industrial projects as well as majority of OSS projects studied. In the paper we also evaluate how information about defect inflow distribution from historical projects is applied for modeling the prior beliefs/experience in Bayesian analysis which is useful for making software defect predictions early during the software project lifecycle.},
journal = {J. Syst. Softw.},
month = jul,
pages = {229–244},
numpages = {16},
keywords = {Software, SRGM, Defect Inflow}
}

@article{10.1007/s10515-019-00259-1,
author = {Li, Zhiqiang and Jing, Xiao-Yuan and Zhu, Xiaoke and Zhang, Hongyu and Xu, Baowen and Ying, Shi},
title = {Heterogeneous defect prediction with two-stage ensemble learning},
year = {2019},
issue_date = {Sep 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {3},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-019-00259-1},
doi = {10.1007/s10515-019-00259-1},
abstract = {Heterogeneous defect prediction (HDP) refers to predicting defect-prone software modules in one project (target) using heterogeneous data collected from other projects (source). Recently, several HDP methods have been proposed. However, these methods do not sufficiently incorporate the two characteristics of the defect data: (1) data could be linear inseparable, and (2) data could be highly imbalanced. These two data characteristics make it challenging to build an effective HDP model. In this paper, we propose a novel Two-Stage Ensemble Learning (TSEL) approach to HDP, which contains two stages: ensemble multi-kernel domain adaptation (EMDA) stage and ensemble data sampling (EDS) stage. In the EMDA stage, we develop an Ensemble Multiple Kernel Correlation Alignment (EMKCA) predictor, which combines the advantage of multiple kernel learning and domain adaptation techniques. In the EDS stage, we employ RESample with replacement (RES) technique to learn multiple different EMKCA predictors and use average ensemble to combine them together. These two stages create an ensemble of defect predictors. Extensive experiments on 30 public projects show that the proposed TSEL approach outperforms a range of competing methods. The improvement is 20.14–33.92% in AUC, 36.05–54.78% in f-measure, and 5.48–19.93% in balance, respectively.},
journal = {Automated Software Engg.},
month = sep,
pages = {599–651},
numpages = {53},
keywords = {Domain adaptation, Data sampling, Class imbalance, Multiple kernel learning, Linear inseparability, Two-stage ensemble learning, Heterogeneous defect prediction}
}

@article{10.3233/JIFS-18473,
author = {Malhotra, Ruchika and Sharma, Anjali},
title = {Empirical assessment of feature selection techniques in defect prediction models using web applications},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {36},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-18473},
doi = {10.3233/JIFS-18473},
abstract = {&nbsp;In order to minimize the over-fitting and related factors that are caused by the high dimensionality of the input data in software defect prediction, the attributes are often optimized using various feature selection techniques. However, the comparative performance of these selection techniques in combination with machine learning algorithms remains largely unexplored using web applications. In this work, we investigate the best possible combination of feature selection technique with machine learning algorithms, with the sample space chosen from open source Apache Click and Rave data sets. Our results are based on 945 defect prediction models derived from parametric, non-parametric and ensemble-based machine learning algorithms, for which the metrics are derived from the various filter and threshold-based ranking techniques. Friedman and Nemenyi post-hoc statistical tests are adopted to identify the performance difference of these models. We find that filter-based feature selection in combination with ensemble-based machine learning algorithms not only poise as the best strategy but also yields a maximum feature set redundancy by 94%, with little or no comprise on the performance index.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6567–6578},
numpages = {12},
keywords = {web application quality, machine learning, feature ranking, Feature selection}
}

@inproceedings{10.5555/1332044.1332090,
author = {Catal, Cagatay and Diri, Banu},
title = {Software defect prediction using artificial immune recognition system},
year = {2007},
publisher = {ACTA Press},
address = {USA},
abstract = {Predicting fault-prone modules for software development projects enables companies to reach high reliable systems and minimizes necessary budget, personnel and resource to be allocated to achieve this goal. Researchers have investigated various statistical techniques and machine learning algorithms until now but most of them applied their models to the different datasets which are not public or used different criteria to decide the best predictor model. Artificial Immune Recognition System is a supervised learning algorithm which has been proposed in 2001 for the classification problems and its performance for UCI datasets (University of California machine learning repository) is remarkable.In this paper, we propose a novel software defect prediction model by applying Artificial Immune Recognition System (AIRS) along with the Correlation-Based Feature Selection (CFS) technique. In order to evaluate the performance of the proposed model, we apply it to the five NASA public defect datasets and compute G-mean 1, G-mean 2 and F-measure values to discuss the effectiveness of the model. Experimental results show that AIRS has a great potential for software defect prediction and AIRS along with CFS technique provides relatively better prediction for large scale projects which consist of many modules.},
booktitle = {Proceedings of the 25th Conference on IASTED International Multi-Conference: Software Engineering},
pages = {285–290},
numpages = {6},
keywords = {artificial immune recognition system (AIRS) and correlation-based feature selection, immune systems, quality prediction, software defect prediction},
location = {Innsbruck, Austria},
series = {SE'07}
}

@inproceedings{10.1007/978-3-030-64580-9_27,
author = {Li, Huanghua and Deng, Zhidong and Zhang, Jianxin and Zhang, Zhen and Wang, Xiaozhao and Li, Yongbao and Li, Feng and Xie, Lizhong},
title = {A Deep Learning Based Fault Detection Method for Rocket Launcher Electrical System},
year = {2020},
isbn = {978-3-030-64579-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64580-9_27},
doi = {10.1007/978-3-030-64580-9_27},
abstract = {This paper proposes a fault detection method for a rocket launcher electrical system by using 1D convolutional neural network. Compared with the method based on analysis of mechanism model and the method based on knowledge, this end-to-end data-driven fault detection method, which only relies on the rich data generated during the running of the system, has the ability of automatic extraction of hierarchical features. The experimental results show that the 1D convolutional neural network designed in this paper achieves the accuracy of 98.66% in the practical fault detection for a rocket electrical system, which is improved by 29% and 13% higher than the traditional fully connected shallow neural network and support vector machine, respectively, which further verifies the feasibility and effectiveness of data-driven deep learning method in fault detection applications.},
booktitle = {Machine Learning, Optimization, and Data Science: 6th International Conference, LOD 2020, Siena, Italy, July 19–23, 2020, Revised Selected Papers, Part II},
pages = {316–325},
numpages = {10},
keywords = {Electrical system, Deep learning, Fault detection, Rocket launcher},
location = {Siena, Italy}
}

@inproceedings{10.1007/978-3-030-22808-8_23,
author = {Moloi, Katleho and Jordaan, Jaco and Hamam, Yskandar},
title = {Application of Machine Learning Based Technique for High Impedance Fault Detection in Power Distribution Network},
year = {2019},
isbn = {978-3-030-22807-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-22808-8_23},
doi = {10.1007/978-3-030-22808-8_23},
abstract = {High-impedance faults (HIFs) detection with high reliability has been a prominent challenge for protection engineers over the years. This is mainly because of the nature and characteristics this type of fault has. Although HIFs do not directly pose danger to the power system equipment, they pose a serious threat to the public and agricultural environment. In this paper, a technique which comprises of a signal decomposition technique, feature extraction, feature selection and fault classification is proposed. A practical experiment was conducted to validate the proposed method. The scheme is implemented in MATLAB and tested on the machine intelligence platform WEKA. The scheme was tested on different classifiers and showed impressive results for both simulations and practical cases.},
booktitle = {Advances in Neural Networks – ISNN 2019: 16th International Symposium on Neural Networks, ISNN 2019, Moscow, Russia, July 10–12, 2019, Proceedings, Part II},
pages = {222–231},
numpages = {10},
keywords = {Fault classification, Fault detection, Feature extraction, High impedance fault, Power system, Fault detection},
location = {Moscow, Russia}
}

@article{10.1016/j.eswa.2021.115477,
author = {Lee, Subin and Chang, Kyuchang and Baek, Jun-Geol},
title = {Incremental learning using generative-rehearsal strategy for fault detection and classification},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {184},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.115477},
doi = {10.1016/j.eswa.2021.115477},
journal = {Expert Syst. Appl.},
month = dec,
numpages = {10},
keywords = {Catastrophic forgetting, Class imbalance, Generative adversarial networks, Pseudorehearsal strategy, Incremental learning}
}

@inproceedings{10.1109/ICSE-C.2017.68,
author = {Loyola, Pablo and Matsuo, Yutaka},
title = {Learning graph representations for defect prediction},
year = {2017},
isbn = {9781538615898},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-C.2017.68},
doi = {10.1109/ICSE-C.2017.68},
abstract = {We propose to study the impact of the representation of the data in defect prediction models. For this study, we focus on the use of developer activity data, from which we structure dependency graphs. Then, instead of manually generating features, such as network metrics, we propose a model inspired in recent advances in Representation Learning which are able to automatically learn representations from graph data. These new representations are compared against manually crafted features for defect prediction in real world software projects.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering Companion},
pages = {265–267},
numpages = {3},
keywords = {representation learning, defect prediction},
location = {Buenos Aires, Argentina},
series = {ICSE-C '17}
}

@inproceedings{10.1007/978-3-030-33709-4_5,
author = {Tasnim Cynthia, Shamse and Rasul, Md. Golam and Ripon, Shamim},
title = {Effect of Feature Selection in Software Fault Detection},
year = {2019},
isbn = {978-3-030-33708-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33709-4_5},
doi = {10.1007/978-3-030-33709-4_5},
abstract = {The quality of software is enormously affected by the faults associated with it. Detection of faults at a proper stage in software development is a challenging task and plays a vital role in the quality of the software. Machine learning is, now a days, a commonly used technique for fault detection and prediction. However, the effectiveness of the fault detection mechanism is impacted by the number of attributes in the publicly available datasets. Feature selection is the process of selecting a subset of all the features that are most influential to the classification and it is a challenging task. This paper thoroughly investigates the effect of various feature selection techniques on software fault classification by using NASA’s some benchmark publicly available datasets. Various metrics are used to analyze the performance of the feature selection techniques. The experiment discovers that the most important and relevant features can be selected by the adopted feature selection techniques without sacrificing the performance of fault detection.},
booktitle = {Multi-Disciplinary Trends in Artificial Intelligence: 13th International Conference, MIWAI 2019, Kuala Lumpur, Malaysia, November 17–19, 2019, Proceedings},
pages = {52–63},
numpages = {12},
keywords = {Fault detection, Feature selection, Feature classification},
location = {Kuala Lumpur, Malaysia}
}

@article{10.1007/s10664-017-9516-2,
author = {Zhang, Feng and Keivanloo, Iman and Zou, Ying},
title = {Data Transformation in Cross-project Defect Prediction},
year = {2017},
issue_date = {December  2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-017-9516-2},
doi = {10.1007/s10664-017-9516-2},
abstract = {Software metrics rarely follow a normal distribution. Therefore, software metrics are usually transformed prior to building a defect prediction model. To the best of our knowledge, the impact that the transformation has on cross-project defect prediction models has not been thoroughly explored. A cross-project model is built from one project and applied on another project. In this study, we investigate if cross-project defect prediction is affected by applying different transformations (i.e., log and rank transformations, as well as the Box-Cox transformation). The Box-Cox transformation subsumes log and other power transformations (e.g., square root), but has not been studied in the defect prediction literature. We propose an approach, namely Multiple Transformations (MT), to utilize multiple transformations for cross-project defect prediction. We further propose an enhanced approach MT+ to use the parameter of the Box-Cox transformation to determine the most appropriate training project for each target project. Our experiments are conducted upon three publicly available data sets (i.e., AEEEM, ReLink, and PROMISE). Comparing to the random forest model built solely using the log transformation, our MT+ approach improves the F-measure by 7, 59 and 43% for the three data sets, respectively. As a summary, our major contributions are three-fold: 1) conduct an empirical study on the impact that data transformation has on cross-project defect prediction models; 2) propose an approach to utilize the various information retained by applying different transformation methods; and 3) propose an unsupervised approach to select the most appropriate training project for each target project.},
journal = {Empirical Softw. Engg.},
month = dec,
pages = {3186–3218},
numpages = {33},
keywords = {Software metrics, Defect prediction, Data transformation, Box-cox}
}

@article{10.1145/3468744.3468751,
author = {Pinzger, Martin and Giger, Emanuel and Gall, Harald C.},
title = {Comparing fine-grained source code changes and code churn for bug prediction - A retrospective},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0163-5948},
url = {https://doi.org/10.1145/3468744.3468751},
doi = {10.1145/3468744.3468751},
abstract = {More than two decades ago, researchers started to mine the data stored in software repositories to help software developers in making informed decisions for developing and testing software systems. Bug prediction was one of the most promising and popular research directions that uses the data stored in software repositories to predict the bug-proneness or number of bugs in source files. On that topic and as part of Emanuel's PhD studies, we submitted a paper with the title Comparing fine-grained source code changes and code churn for bug prediction [8] to the 8th Working Conference on Mining Software Engineering, held 2011 in beautiful Honolulu, Hawaii. Ten years later, it got selected as one of the finalists to receive the MSR 2021 Most Influential Paper Award. In the following, we provide a retrospective on our work, describing the road to publishing this paper, its impact in the field of bug prediction, and the road ahead.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jul,
pages = {21–23},
numpages = {3}
}

@inproceedings{10.1145/3239235.3239243,
author = {Tahir, Amjed and Bennin, Kwabena E. and MacDonell, Stephen G. and Marsland, Stephen},
title = {Revisiting the size effect in software fault prediction models},
year = {2018},
isbn = {9781450358231},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3239235.3239243},
doi = {10.1145/3239235.3239243},
abstract = {BACKGROUND: In object oriented (OO) software systems, class size has been acknowledged as having an indirect effect on the relationship between certain artifact characteristics, captured via metrics, and fault-proneness, and therefore it is recommended to control for size when designing fault prediction models.AIM: To use robust statistical methods to assess whether there is evidence of any true effect of class size on fault prediction models.METHOD: We examine the potential mediation and moderation effects of class size on the relationships between OO metrics and number of faults. We employ regression analysis and bootstrapping-based methods to investigate the mediation and moderation effects in two widely-used datasets comprising seventeen systems.RESULTS: We find no strong evidence of a significant mediation or moderation effect of class size on the relationships between OO metrics and faults. In particular, size appears to have a more significant mediation effect on CBO and Fan-out than other metrics, although the evidence is not consistent in all examined systems. On the other hand, size does appear to have a significant moderation effect on WMC and CBO in most of the systems examined. Again, the evidence provided is not consistent across all examined systemsCONCLUSION: We are unable to confirm if class size has a significant mediation or moderation effect on the relationships between OO metrics and the number of faults. We contend that class size does not fully explain the relationships between OO metrics and the number of faults, and it does not always affect the strength/magnitude of these relationships. We recommend that researchers consider the potential mediation and moderation effect of class size when building their prediction models, but this should be examined independently for each system.},
booktitle = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
articleno = {23},
numpages = {10},
keywords = {software quality, object-oriented metrics, moderation, mediation, fault prediction},
location = {Oulu, Finland},
series = {ESEM '18}
}

@inproceedings{10.1145/3194104.3194112,
author = {Di Nucci, Dario and Palomba, Fabio and De Lucia, Andrea},
title = {Evaluating the adaptive selection of classifiers for cross-project bug prediction},
year = {2018},
isbn = {9781450357234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194104.3194112},
doi = {10.1145/3194104.3194112},
abstract = {Bug prediction models are used to locate source code elements more likely to be defective. One of the key factors influencing their performances is related to the selection of a machine learning method (a.k.a., classifier) to use when discriminating buggy and non-buggy classes. Given the high complementarity of stand-alone classifiers, a recent trend is the definition of ensemble techniques, which try to effectively combine the predictions of different stand-alone machine learners. In a recent work we proposed ASCI, a technique that dynamically selects the right classifier to use based on the characteristics of the class on which the prediction has to be done. We tested it in a within-project scenario, showing its higher accuracy with respect to the Validation and Voting strategy. In this paper, we continue on the line of research, by (i) evaluating ASCI in a global and local cross-project setting and (ii) comparing its performances with those achieved by a stand-alone and an ensemble baselines, namely Naive Bayes and Validation and Voting, respectively. A key finding of our study shows that ASCI is able to perform better than the other techniques in the context of cross-project bug prediction. Moreover, despite local learning is not able to improve the performances of the corresponding models in most cases, it is able to improve the robustness of the models relying on ASCI.},
booktitle = {Proceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
pages = {48–54},
numpages = {7},
keywords = {ensemble classifiers, cross-project, bug prediction},
location = {Gothenburg, Sweden},
series = {RAISE '18}
}

@inproceedings{10.1007/978-3-030-16145-3_23,
author = {Zhang, Wenzhou and Li, Weiwei and Jia, Xiuyi},
title = {Effort-Aware Tri-Training for Semi-supervised Just-in-Time Defect Prediction},
year = {2019},
isbn = {978-3-030-16144-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-16145-3_23},
doi = {10.1007/978-3-030-16145-3_23},
abstract = {In recent years, just-in-time (JIT) defect prediction has gained considerable interest as it enables developers to identify risky changes at check-in time. Previous studies tried to conduct research from both supervised and unsupervised perspectives. Since the label of change is hard to acquire, it would be more desirable for applications if a prediction model doesn’t highly rely on the label information. However, the performance of the unsupervised models proposed by previous work isn’t good in terms of precision and F1 due to the lack of supervised information. To overcome this weakness, we try to study the JIT defect prediction from the semi-supervised perspective, which only requires a few labeled data for training. In this paper, we propose an Effort-Aware Tri-Training (EATT) semi-supervised model for JIT defect prediction based on sample selection. We compare EATT with the state-of-the-art supervised and unsupervised models with respect to different labeled rates. The experimental results on six open-source projects demonstrate that EATT performs better than existing supervised and unsupervised models for effort-aware JIT defect prediction.},
booktitle = {Advances in Knowledge Discovery and Data Mining: 23rd Pacific-Asia Conference, PAKDD 2019, Macau, China, April 14-17, 2019, Proceedings, Part II},
pages = {293–304},
numpages = {12},
keywords = {Defect prediction, Just-in-time, Tri-training, Effort-aware},
location = {Macau, China}
}

@phdthesis{10.5555/AAI29336887,
author = {Serai, Prashant and Michael, White, and DeLiang, Wang, and Rizwan, Ahmad,},
advisor = {Eric, Fosler-Lussier,},
title = {Speech Recognition Error Prediction Approaches with Applications to Spoken Language Understanding},
year = {2021},
isbn = {9798834082927},
publisher = {The Ohio State University},
abstract = {The last couple of decades have seen vast growth in the adoption of speech as an input modality, spread across a variety of tasks and devices. There has been corresponding rapid growth in the use of Automatic Speech Recognition (ASR) systems to transcribe the audio into text. ASR technology has advanced over time, however even today the best speech recognition systems still make errors, and even a single word error in recognizing an utterance can change the semantics or understanding of an utterance. The proliferation of automatic Natural Language Understanding (NLU) has also grown through the use of chatbots, machine translation, topic modeling, information retrieval, language modeling, and many more applications.Due to the natural style of speech, developers that incorporate NLU technology in their applications have increasingly felt a need to provide for the acceptance of speech input in replacement or in addition to typed text. A popular approach has been to utilize a cloud-based ASR service as a front-end to convert speech into text before feeding it to their text-based NLU back-end. Until developers deploy NLU systems in the spoken domain for long enough to collect adequate labeled data, they end up needing to rely on plain text data i.e., typed or otherwise devoid of ASR errors, to train their systems. When an NLU system trained on plain text is deployed under speech input, the presence of ASR errors changes the intended spoken text before it reaches the NLU system affecting downstream performance. Such a lack of ASR error examples in the plain text training data leads to a missed opportunity for NLU systems to become robust to the errorful input they may see at test-time. ASR error prediction is a technique to take plain text and predict the kinds of errors that may have occurred if that text were to have been spoken and transcribed by an ASR system. When plain text data is to be used to train systems for spoken language understanding or ASR, a proven strategy to reduce said mismatch and prevent degradations is to use ASR error prediction to turn plain text into simulated ASR output text.This work focuses on adapting the technology for ASR error prediction to modern ASR and spoken language understanding particularly for scenarios where a cloud-based/black box ASR system is used off-the-shelf in cascade with an NLU system to perform a downstream task; it is the first to build as well as evaluate error prediction models for cloud-based ASR services. It introduces end to end modeling approaches to improve error prediction, and provides techniques to leverage contextual word and phonetic level information within a single model. The contributions within this dissertation are shown to improve ASR error modeling and to help improve the performance of existing NLU systems under spoken input, whether or not they have access to real speech data in their training set, and at a variety of word error rate conditions.},
note = {AAI29336887}
}

@inbook{10.5555/1985688.1985695,
author = {Pu\l{}awski, \L{}ukasz},
title = {Software defect prediction based on source code metrics time series},
year = {2011},
isbn = {9783642183010},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Source code metrics have been proved to be reliable indicators of the vulnerability of the source code to defects. Typically, a source code unit with high value of a certain metric is considered to be badly structured and thus error-prone. However, analysis of source code change history shows that there are cases when source files with low values of metrics still turn out to be defective. Instead of introducing new metrics for such cases, I investigate the possibility of estimating the vulnerability of source code units to defects on the basis of the history of the values of selected well-known metrics. The experiments show that we can efficiently identify bad source code units just by looking at the history of metrics, coming from only a few revisions that precede the actual resolution of the defect.},
booktitle = {Transactions on Rough Sets XIII},
pages = {104–120},
numpages = {17}
}

@inproceedings{10.1109/IECON48115.2021.9589439,
author = {Pasqualotto, Dario and Navarro, Angela Navarro and Zigliotto, Mauro and Antonino-Daviu, Jose A. and Biot-Monterde, Vicente},
title = {Fault Detection in Soft-started Induction Motors using Convolutional Neural Network Enhanced by Data Augmentation Techniques},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON48115.2021.9589439},
doi = {10.1109/IECON48115.2021.9589439},
abstract = {Stray flux analysis is an interesting source of information for the diagnosis of Induction Motors (IMs). The widespread use of these motors in industry leads to a necessity of additional tools and methods for their predictive maintenance. On the other hand, soft-starters are increasingly used to reduce the high consumption of IMs at start-up. In this work, AI techniques based on convolutional neural networks are applied to detect rotor faults in soft-started motors. The objective is the automatic early detection of broken bars, avoiding the necessity of user intervention to interpret the obtained results. This work proves the potential of the methodology, including a successful set of experimental results.},
booktitle = {IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society},
pages = {1–6},
numpages = {6},
location = {Toronto, ON, Canada}
}

@article{10.1049/iet-sen.2019.0389,
author = {Sun, Ying and Jing, Xiao‐Yuan and Wu, Fei and Sun, Yanfei},
title = {Manifold embedded distribution adaptation for cross‐project defect prediction},
year = {2021},
issue_date = {December 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {14},
number = {7},
url = {https://doi.org/10.1049/iet-sen.2019.0389},
doi = {10.1049/iet-sen.2019.0389},
abstract = {Cross‐project defect prediction (CPDP) technology refers to the constructing prediction model to predict the instance label of the target project by utilising labelled data from an external project. The challenge of CPDP methods is the distribution difference between the data from different projects. Transfer learning can transfer the knowledge from the source domain to the target domain with the aim to minimise the domain difference between different domains. However, most existing methods reduce the distribution discrepancy in the original feature space, where the features are high‐dimensional and non‐linear, which makes it hard to reduce the distribution distance between different projects. Moreover, previous works mainly consider marginal distribution or conditional distribution difference. In this study, the authors proposed a manifold embedded distribution adaptation (MDA) approach to narrow the distribution gap in manifold feature subspace. MDA maps source and target project data to manifold subspace and then joint distribution adaptation of conditional and marginal distributions is performed on manifold subspace. To evaluate the effectiveness of MDA, the authors perform extensive experiments on 20 public projects with three indicators. The experiment results show that MDA improves the average performance, but the improvement is not statistically significant in comparison to HYDRA (one of the baselines).},
journal = {IET Software},
month = feb,
pages = {825–838},
numpages = {14},
keywords = {marginal distribution difference, conditional distribution difference, manifold embedded distribution adaptation approach, MDA, manifold feature subspace, joint distribution adaptation, public projects, transfer learning, distribution distance, distribution discrepancy, target domain, source domain, CPDP methods, cross‐project defect prediction, neural nets, program debugging, learning (artificial intelligence)}
}

@article{10.1016/j.jss.2017.06.070,
author = {Yu, Qiao and Jiang, Shujuan and Zhang, Yanmei},
title = {A feature matching and transfer approach for cross-company defect prediction},
year = {2017},
issue_date = {October 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {132},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2017.06.070},
doi = {10.1016/j.jss.2017.06.070},
abstract = {A feature matching algorithm is designed to address the heterogeneous features.A feature matching and transfer (FMT) approach for cross-company defect prediction.An empirical study is conducted on 16 datasets from NASA and PROMISE.The results show that FMT is effective for cross-company defect prediction. Software defect prediction has drawn much attention of researchers in software engineering. Traditional defect prediction methods aim to build the prediction model based on historical data. For a new project or a project with limited historical data, we cannot build a good prediction model. Therefore, researchers have proposed the cross-project defect prediction (CPDP) and cross-company defect prediction (CCDP) methods to share the historical data among different projects. However, the features of cross-company datasets are often heterogeneous, which may affect the feasibility of CCDP. To address the heterogeneous features of CCDP, this paper presents a feature matching and transfer (FMT) approach. First, we conduct feature selection for the source project and get the distribution curves of selected features. Similarly, we also get the distribution curves of all features in the target project. Second, according to the distance of different distribution curves, we design a feature matching algorithm to convert the heterogeneous features into the matched features. Finally, we can achieve feature transfer from the source project to the target project. All experiments are conducted on 16 datasets from NASA and PROMISE, and the results show that FMT is effective for CCDP.},
journal = {J. Syst. Softw.},
month = oct,
pages = {366–378},
numpages = {13},
keywords = {Software defect prediction, Heterogeneous features, Feature transfer, Feature matching}
}

@inproceedings{10.1145/3183399.3183402,
author = {Koch, Patrick and Schekotihin, Konstantin and Jannach, Dietmar and Hofer, Birgit and Wotawa, Franz and Schmitz, Thomas},
title = {Combining spreadsheet smells for improved fault prediction},
year = {2018},
isbn = {9781450356626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183399.3183402},
doi = {10.1145/3183399.3183402},
abstract = {Spreadsheets are commonly used in organizations as a programming tool for business-related calculations and decision making. Since faults in spreadsheets can have severe business impacts, a number of approaches from general software engineering have been applied to spreadsheets in recent years, among them the concept of code smells. Smells can in particular be used for the task of fault prediction. An analysis of existing spreadsheet smells, however, revealed that the predictive power of individual smells can be limited. In this work we therefore propose a machine learning based approach which combines the predictions of individual smells by using an AdaBoost ensemble classifier. Experiments on two public datasets containing real-world spreadsheet faults show significant improvements in terms of fault prediction accuracy.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {25–28},
numpages = {4},
keywords = {spreadsheet smells, spreadsheet QA, fault prediction},
location = {Gothenburg, Sweden},
series = {ICSE-NIER '18}
}

@inproceedings{10.5555/3463952.3464260,
author = {Youssef, Youssef Mahmoud},
title = {Inducing Rules about Distributed Robotic Systems for Fault Detection &amp; Diagnosis},
year = {2021},
isbn = {9781450383073},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {This paper presents an extended abstract for the PhD topic Inducing Rules about Distributed Robotic Systems for Fault Detection &amp; Diagnosis. The research focuses on developing novel methods for fault detection and diagnosis using explainable machine learning. The main field of application is distributed robotic systems. With current developments in distributed robot technology, the problem of detecting and diagnosing faults becomes more complex.},
booktitle = {Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1845–1847},
numpages = {3},
keywords = {explainable machine learning, fault detection &amp; diagnosis, inductive logic programming, robotics},
location = {Virtual Event, United Kingdom},
series = {AAMAS '21}
}

@inproceedings{10.1145/2979779.2979783,
author = {Maheshwari, Suchi and Agarwal, Sonali},
title = {Three-way decision based Defect Prediction for Object Oriented Software},
year = {2016},
isbn = {9781450342131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2979779.2979783},
doi = {10.1145/2979779.2979783},
abstract = {Early prediction of defective software module plays critical role in the software project development to reduce the overall development time, budgets and increases the customer satisfaction. The bug prediction based on two-way classification method classifies the software module as defective or non-defective. This method provides good accuracy measure but this metric is not sufficient in case if misclassification cost is concerned. Classifying the defective module as non-defective will lead to higher cost of entire software project at the end. In this study, three-way decision based classification method and Random Forest ensemble are used to predict the defect in Object Oriented Software to reduce the misclassification cost which will lead to avoid the cost overrun. The eclipse bug prediction dataset is used and experimental results show that the decision cost is reduced and accuracy is increased using our proposed method.},
booktitle = {Proceedings of the International Conference on Advances in Information Communication Technology &amp; Computing},
articleno = {4},
numpages = {6},
keywords = {Three-way decision, Software defect prediction, Random Forest, Na\"{\i}ve Bayes, Eclipse Bug Prediction dataset},
location = {Bikaner, India},
series = {AICTC '16}
}

@inproceedings{10.1145/3412841.3442027,
author = {Tsimpourlas, Foivos and Rajan, Ajitha and Allamanis, Miltiadis},
title = {Supervised learning over test executions as a test oracle},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442027},
doi = {10.1145/3412841.3442027},
abstract = {The challenge of automatically determining the correctness of test executions is referred to as the test oracle problem and is a key remaining issue for automated testing. The paper aims at solving the test oracle problem in a scalable and accurate way. To achieve this, we use supervised learning over test execution traces. We label a small fraction of the execution traces with their verdict of pass or fail. We use the labelled traces to train a neural network (NN) model to learn to distinguish runtime patterns for passing versus failing executions for a given program.We evaluate our approach using case studies from different application domains - 1. Module from Ethereum Blockchain, 2. Module from PyTorch deep learning framework, 3. Microsoft SEAL encryption library components and 4. Sed stream editor. We found the classification models for all subject programs resulted in high precision, recall and specificity, averaging to 89%, 88% and 92% respectively, while only training with an average 15% of the total traces. Our experiments show that the proposed NN model is promising as a test oracle and is able to learn runtime patterns to distinguish test executions for systems and tests from different application domains.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1521–1531},
numpages = {11},
keywords = {execution trace, neural networks, software testing, test oracle},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@article{10.1504/ijcsm.2021.117600,
author = {Hammad, Mustafa},
title = {Classifying defective software projects based on machine learning and complexity metrics},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {4},
issn = {1752-5055},
url = {https://doi.org/10.1504/ijcsm.2021.117600},
doi = {10.1504/ijcsm.2021.117600},
abstract = {Software defects can lead to software failures or errors at any time. Therefore, software developers and engineers spend a lot of time and effort in order to find possible defects. This paper proposes an automatic approach to predict software defects based on machine learning algorithms. A set of complexity measures values are used to train the classifier. Three public datasets were used to evaluate the ability of mining complexity measures for different software projects to predict possible defects. Experimental results showed that it is possible to min software complexity to build a defect prediction model with a high accuracy rate.},
journal = {Int. J. Comput. Sci. Math.},
month = jan,
pages = {401–412},
numpages = {11},
keywords = {support vector machine, SVM, decision trees, na\"{\i}ve Bayes, neural networks, complexity, machine learning, software metrics, defect prediction, software defects}
}

@inproceedings{10.1145/3380446.3430687,
author = {Fallon, Elias},
title = {Machine Learning in EDA: Opportunities and Challenges},
year = {2020},
isbn = {9781450375191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3380446.3430687},
doi = {10.1145/3380446.3430687},
abstract = {Electronic Design Automation software has delivered semiconductor design productivity improvements for decades. The next leap in productivity will come from the addition of machine learning techniques to the toolbox of computational software capabilities employed by EDA developers. Recent research and development into machine learning for EDA point to clear patterns for how it impacts EDA tools, flows, and design challenges. This research has also illustrated some of the challenges that will come with production deployment of machine learning techniques into EDA tools and flows. This talk will detail patterns observed in ML for EDA development, as well as discussing challenges with productization of ML for EDA developments and the opportunities that it presents for researchers.Biography: Elias Fallon is currently Engineering Group Director at Cadence Design Systems, a leading Electronic Design Automation company. He has been involved in EDA for more than 20 years from the founding of Neolinear, Inc, which was acquired by Cadence in 2004. Elias was co-Primary Investigator on the MAGESTIC project, funded by DARPA to investigate the application of Machine Learning to EDA for Package/PCB and Analog IC. Elias also leads an innovation incubation team within the Custom IC R&amp;D group as well as other traditional EDA product teams. Beyond his work developing electronic design automation tools, he has led software quality improvement initiatives within Cadence, partnering with the Carnegie Mellon Software Engineering Institute. Elias graduated from Carnegie Mellon University with an M.S. and B.S. in Electrical and Computer Engineering. Elias, his wife and two children live north of Pittsburgh, PA. https://www.linkedin.com/in/elias-fallon/},
booktitle = {Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD},
pages = {103},
numpages = {1},
keywords = {machine learning, electronic design automation},
location = {Virtual Event, Iceland},
series = {MLCAD '20}
}

@inproceedings{10.1109/QRS.2015.17,
author = {Qin, Fangyun and Zheng, Zheng and Bai, Chenggang and Qiao, Yu and Zhang, Zhenyu and Chen, Cheng},
title = {Cross-Project Aging Related Bug Prediction},
year = {2015},
isbn = {9781467379892},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QRS.2015.17},
doi = {10.1109/QRS.2015.17},
abstract = {In a long running system, software tends to encounter performance degradation and increasing failure rate during execution, which is called software aging. The bugs contributing to the phenomenon of software aging are defined as Aging Related Bugs (ARBs). Lots of manpower and economic costs will be saved if ARBs can be found in the testing phase. However, due to the low presence probability and reproducing difficulty of ARBs, it is usually hard to predict ARBs within a project. In this paper, we study whether and how ARBs can be located through cross-project prediction. We propose a transfer learning based aging related bug prediction approach (TLAP), which takes advantage of transfer learning to reduce the distribution difference between training sets and testing sets while preserving their data variance. Furthermore, in order to mitigate the severe class imbalance, class imbalance learning is conducted on the transferred latent space. Finally, we employ machine learning methods to handle the bug prediction tasks. The effectiveness of our approach is validated and evaluated by experiments on two real software systems. It indicates that after the processing of TLAP, the performance of ARB bug prediction can be dramatically improved.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Software Quality, Reliability and Security},
pages = {43–48},
numpages = {6},
keywords = {transfer learning, software aging, ross-project, bug prediction, aging related bug},
series = {QRS '15}
}

@article{10.1016/j.eswa.2021.114820,
author = {Bertolini, Massimo and Mezzogori, Davide and Neroni, Mattia and Zammori, Francesco},
title = {Machine Learning for industrial applications: A comprehensive literature review},
year = {2021},
issue_date = {Aug 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {175},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2021.114820},
doi = {10.1016/j.eswa.2021.114820},
journal = {Expert Syst. Appl.},
month = aug,
numpages = {29},
keywords = {Operation management, Machine Learning, Deep Learning, Industrial applications, Literature review}
}

@inproceedings{10.1109/ISCID.2014.140,
author = {Zhang, Kai and Du, Kai and Ju, Yongfeng},
title = {Algorithm of Railway Turnout Fault Detection Based on PNN Neural Network},
year = {2014},
isbn = {9781479970056},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISCID.2014.140},
doi = {10.1109/ISCID.2014.140},
abstract = {This paper presents a turnout fault detection algorithm based on PNN neural network. This algorithm summarized the typical turnout fault action current curves, established the mapping data sets between the action current curve and turnout fault types, used PNN neural network and BP neural network to train and test the mapping data sets of action current curve. Experimental results show that the turnout fault detection algorithm based on PNN neural network is better than BP neural network algorithm. It has higher precision and less parameter adjustment, easy to set up and so on.},
booktitle = {Proceedings of the 2014 Seventh International Symposium on Computational Intelligence and Design - Volume 01},
pages = {544–547},
numpages = {4},
keywords = {turnout, neural network, fault detection, action current curve},
series = {ISCID '14}
}

@book{10.5555/3239625,
author = {Prasad, K. S. N. and Rao, A. S. and Kumar, R.},
title = {Defect Prediction in Software Development &amp; Maintainence},
year = {2018},
isbn = {1543702422},
publisher = {PartridgeIndia},
address = {Gurgaon, IND},
abstract = {This book is a collection of taxonomy and review of contemporary model in the field of software development and maintenance. This book is basically the result of our passion toward the research of application of software engineering concepts. This work is derived from the need for accurate fault estimation in goals of quality programming and minimal maintenance overheads. State of art technologies have been discussed with respective experimental investigations and analysis. This work started out as a survey and then evolved according to our interest and proclivity into a work that emphasizes the aspects of software development. This book is intended to explain how the defect predictions are used to improve the quality of software development for easy analysis in a very simple way. It contains research that is useful to research scholars, engineers, and computing researchers.}
}

@article{10.1016/j.asoc.2014.11.023,
author = {Malhotra, Ruchika},
title = {A systematic review of machine learning techniques for software fault prediction},
year = {2015},
issue_date = {February 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {27},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2014.11.023},
doi = {10.1016/j.asoc.2014.11.023},
abstract = {Reviews studies from 1991-2013 to assess application of ML techniques for SFP.Identifies seven categories of the ML techniques.Identifies 64 studies to answer the established research questions.Selects primary studies according to the quality assessment of the studies.Systematic literature review performs the following:Summarize ML techniques for SFP models.Assess performance accuracy and capability of ML techniques for constructing SFP models.Provide comparison between the ML and statistical techniques.Provide comparison of performance accuracy of different ML techniques.Summarize the strength and weakness of the ML techniques.Provides future guidelines to software practitioners and researchers. BackgroundSoftware fault prediction is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. There are various machine learning techniques used in the past for predicting faults. MethodIn this study we perform a systematic review of studies from January 1991 to October 2013 in the literature that use the machine learning techniques for software fault prediction. We assess the performance capability of the machine learning techniques in existing research for software fault prediction. We also compare the performance of the machine learning techniques with the statistical techniques and other machine learning techniques. Further the strengths and weaknesses of machine learning techniques are summarized. ResultsIn this paper we have identified 64 primary studies and seven categories of the machine learning techniques. The results prove the prediction capability of the machine learning techniques for classifying module/class as fault prone or not fault prone. The models using the machine learning techniques for estimating software fault proneness outperform the traditional statistical models. ConclusionBased on the results obtained from the systematic review, we conclude that the machine learning techniques have the ability for predicting software fault proneness and can be used by software practitioners and researchers. However, the application of the machine learning techniques in software fault prediction is still limited and more number of studies should be carried out in order to obtain well formed and generalizable results. We provide future guidelines to practitioners and researchers based on the results obtained in this work.},
journal = {Appl. Soft Comput.},
month = feb,
pages = {504–518},
numpages = {15},
keywords = {Systematic literature review, Software fault proneness, Machine learning}
}

@article{10.1007/s00521-021-05919-6,
author = {Liu, Xing and Yu, Jianbo and Ye, Lyujiangnan},
title = {Residual attention convolutional autoencoder for feature learning and fault detection in nonlinear industrial processes},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {19},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05919-6},
doi = {10.1007/s00521-021-05919-6},
abstract = {Deep learning has been successfully applied in process monitoring in recent years due to its powerful feature extraction. However, these monitoring methods are difficult to extract intrinsic representations of the process data in complex nonlinear processes. A new deep neural network, residual attention convolutional autoencoder (RACAE) is proposed for process monitoring. The unsupervised learning method of RACAE can extract representative features from high-dimensional data, which can significantly improve process monitoring performance in nonlinear processes. RACAE effectively integrates convolution calculation with an autoencoder to perform effective feature extraction of multivariate data. Moreover, residual attention block is embedded in the autoencoder to select these key features and then reduce the feature dimension for detector. A new process monitoring model is proposed and two kinds of statistics are developed for fault detection. The effectiveness of RACAE in fault detection is evaluated through a numerical case and two benchmark processes. The convolutional autoencoder based on residual attention provides a new approach for feature learning and process monitoring of complex processes.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {12737–12753},
numpages = {17},
keywords = {Convolutional autoencoder, Fault detection, Deep learning, Nonlinear process}
}

@article{10.5555/3271870.3271879,
title = {Fault detection and isolation of asynchronous machine based on the probabilistic neural network},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {6},
number = {3–4},
issn = {1758-8715},
abstract = {In this paper, we propose three neural networks based methods for fault detection and isolation of asynchronous machine: a probabilistic neural network PNN, multi-layer perceptron MLP, and generalised regression neural network GRNN. To perform efficient diagnostic results the cross-validation procedure input data is partitioned into three sets: a training set, a validation set and a test set. The stator RMS values of three-phase voltages and currents are used as model inputs to identify the different types of faults and the normal operating mode. Efficiency of these three neural based methods is compared using a test set of 100 data.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {378–395},
numpages = {18}
}

@article{10.1109/TSE.2017.2659747,
author = {Di Nucci, Dario and Palomba, Fabio and De Rosa, Giuseppe and Bavota, Gabriele and Oliveto, Rocco and De Lucia, Andrea},
title = {A Developer Centered Bug Prediction Model},
year = {2018},
issue_date = {January 2018},
publisher = {IEEE Press},
volume = {44},
number = {1},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2017.2659747},
doi = {10.1109/TSE.2017.2659747},
abstract = {Several techniques have been proposed to accurately predict software defects. These techniques generally exploit characteristics of the code artefacts (e.g., size, complexity, etc.) and/or of the process adopted during their development and maintenance (e.g., the number of developers working on a component) to spot out components likely containing bugs. While these bug prediction models achieve good levels of accuracy, they mostly ignore the major role played by human-related factors in the introduction of bugs. Previous studies have demonstrated that focused developers are less prone to introduce defects than non-focused developers. According to this observation, software components changed by focused developers should also be less error prone than components changed by less focused developers. We capture this observation by measuring the scattering of changes performed by developers working on a component and use this information to build a bug prediction model. Such a model has been evaluated on 26 systems and compared with four competitive techniques. The achieved results show the superiority of our model, and its high complementarity with respect to predictors commonly used in the literature. Based on this result, we also show the results of a “hybrid” prediction model combining our predictors with the existing ones.},
journal = {IEEE Trans. Softw. Eng.},
month = jan,
pages = {5–24},
numpages = {20}
}

@inproceedings{10.1109/ICMLA.2009.18,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan},
title = {Feature Selection with Imbalanced Data for Software Defect Prediction},
year = {2009},
isbn = {9780769539263},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2009.18},
doi = {10.1109/ICMLA.2009.18},
abstract = {In this paper, we study the learning impact of data sampling followed by attribute selection on the classification models built with binary class imbalanced data within the scenario of software quality engineering. We use a wrapper-based attribute ranking technique to select a subset of attributes, and the random undersampling technique (RUS) on the majority class to alleviate the negative effects of imbalanced data on the prediction models. The datasets used in the empirical study were collected from numerous software projects. Five data preprocessing scenarios were explored in these experiments, including: (1) training on the original, unaltered fit dataset, (2) training on a sampled version of the fit dataset, (3) training on an unsampled version of the fit dataset using only the attributes chosen by feature selection based on the unsampled fit dataset, (4) training on an unsampled version of the fit dataset using only the attributes chosen by feature selection based on a sampled version of the fit dataset, and (5) training on a sampled version of the fit dataset using only the attributes chosen by feature selection based on the sampled version of the fit dataset. We compared the performances of the classification models constructed over these five different scenarios. The results demonstrate that the classification models constructed on the sampled fit data with or without feature selection (case 2 and case 5) significantly outperformed the classification models built with the other cases (unsampled fit data). Moreover, the two scenarios using sampled data (case 2 and case 5) showed very similar performances, but the subset of attributes (case 5) is only around 15% or 30% of the complete set of attributes (case 2).},
booktitle = {Proceedings of the 2009 International Conference on Machine Learning and Applications},
pages = {235–240},
numpages = {6},
keywords = {wrapper-based attribute ranking, software defect prediction, imbalanced data, feature selection},
series = {ICMLA '09}
}

@article{10.1016/j.cosrev.2020.100308,
author = {Mishra, Alok and Otaiwi, Ziadoon},
title = {DevOps and software quality: A systematic mapping},
year = {2020},
issue_date = {Nov 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {38},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2020.100308},
doi = {10.1016/j.cosrev.2020.100308},
journal = {Comput. Sci. Rev.},
month = nov,
numpages = {14},
keywords = {Systematic mapping, Measurement, Automation, Software quality, Software, Operations, Development, DevOps}
}

@inproceedings{10.1145/3338906.3341462,
author = {Caulo, Maria},
title = {A taxonomy of metrics for software fault prediction},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3341462},
doi = {10.1145/3338906.3341462},
abstract = {In the field of Software Fault Prediction (SFP), researchers exploit software metrics to build predictive models using machine learning and/or statistical techniques. SFP has existed for several decades and the number of metrics used has increased dramatically. Thus, the need for a taxonomy of metrics for SFP arises firstly to standardize the lexicon used in this field so that the communication among researchers is simplified and then to organize and systematically classify the used metrics. In this doctoral symposium paper, I present my ongoing work which aims not only to build such a taxonomy as comprehensive as possible, but also to provide a global understanding of the metrics for SFP in terms of detailed information: acronym(s), extended name, univocal description, granularity of the fault prediction (e.g., method and class), category, and research papers in which they were used.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1144–1147},
numpages = {4},
keywords = {taxonomy, software metrics, software fault prediction},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.1007/s00521-021-05776-3,
author = {Yan, Shifu and Yan, Xuefeng},
title = {Nonlinear quality-relevant process monitoring based on maximizing correlation neural network},
year = {2021},
issue_date = {Aug 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {16},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-05776-3},
doi = {10.1007/s00521-021-05776-3},
abstract = {Quality-relevant fault detection aims to reveal whether quality variables are affected when a fault is detected. For current industrial processes, kernel-based methods focus on the nonlinearity within process variables, which is insufficient for obtaining nonlinearities of quality variables. Alternatively, neural network is an option for nonlinear prediction. However, these models are driven by predictive errors on samples. For quality-relevant tasks, the key is to capture the trends of quality variables. Therefore, this study proposes a new model, namely, maximizing correlation neural network (MCNN), to predict the quality-relevant information intuitively. The MCNN is trained to maximize the linear correlation between quality variables and the combinations of nonlinear representations mapped by a multilayer feedforward network. As such, fault detection can be implemented in the quality-relevant and irrelevant subspaces on the basis of the deep most correlated representations of process variables. Considering that different variables have different sensitivities to quality at various locations due to their nonlinear relationship, fault backpropagation is designed in the MCNN to isolate the faulty variables on the basis of real-time faulty information. Finally, numerical example and Tennessee Eastman process are used to evaluate the proposed method, which exhibits a competitive performance.},
journal = {Neural Comput. Appl.},
month = aug,
pages = {10129–10139},
numpages = {11},
keywords = {Fault isolation, Fault detection, Quality-relevant, Neural network}
}

@inproceedings{10.1145/3345629.3345638,
author = {Amasaki, Sousuke and Yokogawa, Tomoyuki and Aman, Hirohisa},
title = {Applying Cross Project Defect Prediction Approaches to Cross-Company Effort Estimation},
year = {2019},
isbn = {9781450372336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345629.3345638},
doi = {10.1145/3345629.3345638},
abstract = {BACKGROUND: Prediction systems in software engineering often suffer from the shortage of suitable data within a project. A promising solution is transfer learning that utilizes data from outside the project. Many transfer learning approaches have been proposed for defect prediction known as cross-project defect prediction (CPDP). In contrast, a few approaches have been proposed for software effort estimation known as cross-company software effort estimation (CCSEE). Both CCSEE and CPDP are engaged in a similar problem, and a few CPDP approaches are applicable as CCSEE in actual. It is thus beneficial for improving CCSEE performance to examine how well CPDP approaches can perform as CCSEE approaches. AIMS: To explore how well CPDP approaches work as CCSEE approaches. METHOD: An empirical experiment was conducted for evaluating the performance of CPDP approaches in CCSEE. We examined 7 CPDP approaches which were selected due to the easiness of application. Those approaches were applied to 8 data sets, each of which consists of a few subsets from different domains. The estimation results were evaluated with a common performance measure called SA. RESULTS: there were several CPDP approaches which could improve the estimation accuracy though the degree of improvement was not large. CONCLUSIONS: A straight forward application of selected CPDP approaches did not bring a clear effect. CCSEE may need specific transfer learning approaches for more improvement.},
booktitle = {Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {76–79},
numpages = {4},
keywords = {cross-company effort estimation, cross-project defect prediction, transfer learning},
location = {Recife, Brazil},
series = {PROMISE'19}
}

@inproceedings{10.1145/3485730.3493455,
author = {Ahan, M. R. and Nambi, Akshay and Ganu, Tanuja and Nahata, Dhananjay and Kalyanaraman, Shivkumar},
title = {AI-assisted Cell-Level Fault Detection and Localization in Solar PV Electroluminescence Images},
year = {2021},
isbn = {9781450390972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485730.3493455},
doi = {10.1145/3485730.3493455},
abstract = {With the increasing adaption of solar energy worldwide, there is a huge interest to develop systems that help drive efficiency during manufacturing and ongoing operations. Due to various real-world conditions and processes, solar panels develop faults during their manufacturing and operations. The objective of this work is to build an End-to-End Fault Detection system to detect and localize faults in solar panels based on their Electroluminescence (EL) Imaging. Today, the majority of fault detection happens through manual inspection of EL images. To this end, we propose the design and implementation of an end-to-end system that firstly divides the solar panel into individual solar cells and then passes these cell images through a classification + detection pipeline for identifying the fault type and localizing the faults inside a cell. We propose a hybrid architecture that contains an ensemble of multiple CNN model architectures for classification and detection. The ensemble is capable of serving both - monocrystalline and polycrystalline solar panels. The proposed system significantly helps in increasing the efficiency of solar panels and reducing warranty and repair costs. We demonstrate the performance of the proposed system using an open EL image dataset with 95% of cell-level fault prediction accuracy and high recall. The proposed algorithms are applicable and can be extended for other solar applications that use RGB, EL, or thermal imaging techniques.},
booktitle = {Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems},
pages = {485–491},
numpages = {7},
keywords = {Fault Localization, Fault Detection, EL Imaging},
location = {Coimbra, Portugal},
series = {SenSys '21}
}

@article{10.1016/j.eswa.2020.114022,
author = {Rauber, Thomas Walter and da Silva Loca, Antonio Luiz and Boldt, Francisco de Assis and Rodrigues, Alexandre Loureiros and Varej\~{a}o, Fl\'{a}vio Miguel},
title = {An experimental methodology to evaluate machine learning methods for fault diagnosis based on vibration signals},
year = {2021},
issue_date = {Apr 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {167},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2020.114022},
doi = {10.1016/j.eswa.2020.114022},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {18},
keywords = {Machine learning, Pattern recognition, Classification, Performance criteria, CWRU bearing fault database, Fault detection}
}

@inproceedings{10.1007/978-3-030-98260-7_3,
author = {Dobossy, Barnab\'{a}s and Form\'{a}nek, Martin and Stastny, Petr and Sp\'{a}\v{c}il, Tom\'{a}\v{s}},
title = {Fault Detection and&nbsp;Identification on&nbsp;Pneumatic Production Machine},
year = {2021},
isbn = {978-3-030-98259-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-98260-7_3},
doi = {10.1007/978-3-030-98260-7_3},
abstract = {Pneumatic cylinders have become integral parts of today’s production machinery. In the age of just-in-time inventory system and with it the related production process, new, increased requirements were introduced. As a result, even the smallest fault in the system can lead to degradation in the product’s quality in addition to this it can cause unplanned downtime leading to delays in production, not to mention higher costs. The availability of cheap sensors, big data, and algorithms from the field of predictive maintenance made the aforementioned problem tractable.This paper examines whether signal-based condition indicators provide commercially viable and affordable basis for development of a health monitoring system for pneumatic actuator-based production machinery. The experiments and their results presented in this paper served two objectives. The first was to examine if faults on such equipment can be detected. The second was to identify the best combination of sensors, which are able to detect and identify fault with required accuracy. The evaluation of the sensors was not solely based on fault detection capabilities, but other practical aspects (price and durability of the sensors) were also taken into account.},
booktitle = {Modelling and Simulation  for Autonomous Systems: 8th International Conference, MESAS 2021, Virtual Event, October 13–14, 2021, Revised Selected Papers},
pages = {39–60},
numpages = {22},
keywords = {Production machinery, Pneumatic cylinder, Fault detection and isolation, Health monitoring}
}

@inproceedings{10.1145/2884781.2884857,
author = {Tantithamthavorn, Chakkrit and McIntosh, Shane and Hassan, Ahmed E. and Matsumoto, Kenichi},
title = {Automated parameter optimization of classification techniques for defect prediction models},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884857},
doi = {10.1145/2884781.2884857},
abstract = {Defect prediction models are classifiers that are trained to identify defect-prone software modules. Such classifiers have configurable parameters that control their characteristics (e.g., the number of trees in a random forest classifier). Recent studies show that these classifiers may underperform due to the use of suboptimal default parameter settings. However, it is impractical to assess all of the possible settings in the parameter spaces. In this paper, we investigate the performance of defect prediction models where Caret --- an automated parameter optimization technique --- has been applied. Through a case study of 18 datasets from systems that span both proprietary and open source domains, we find that (1) Caret improves the AUC performance of defect prediction models by as much as 40 percentage points; (2) Caret-optimized classifiers are at least as stable as (with 35% of them being more stable than) classifiers that are trained using the default settings; and (3) Caret increases the likelihood of producing a top-performing classifier by as much as 83%. Hence, we conclude that parameter settings can indeed have a large impact on the performance of defect prediction models, suggesting that researchers should experiment with the parameters of the classification techniques. Since automated parameter optimization techniques like Caret yield substantially benefits in terms of performance improvement and stability, while incurring a manageable additional computational cost, they should be included in future defect prediction studies.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {321–332},
numpages = {12},
keywords = {software defect prediction, parameter optimization, experimental design, classification techniques},
location = {Austin, Texas},
series = {ICSE '16}
}

@article{10.1007/s11227-018-2326-5,
author = {Kalsoom, Anum and Maqsood, Muazzam and Ghazanfar, Mustansar Ali and Aadil, Farhan and Rho, Seungmin},
title = {A dimensionality reduction-based efficient software fault prediction using Fisher linear discriminant analysis (FLDA)},
year = {2018},
issue_date = {Sep 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {74},
number = {9},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-018-2326-5},
doi = {10.1007/s11227-018-2326-5},
abstract = {Software quality is an important factor in the success of software companies. Traditional software quality assurance techniques face some serious limitations especially in terms of time and budget. This leads to increase in the use of machine learning classification techniques to predict software faults. Software fault prediction can help developers to uncover software problems in early stages of software life cycle. The extent to which these techniques can be generalized to different sizes of software, class imbalance problem, and identification of discriminative software metrics are the most critical challenges. In this paper, we have analyzed the performance of nine widely used machine learning classifiers--Bayes Net, NB, artificial neural network, support vector machines, K nearest neighbors, AdaBoost, Bagging, Zero R, and Random Forest for software fault prediction. Two standard sampling techniques--SMOTE and Resample with substitution are used to handle the class imbalance problem. We further used FLDA-based feature selection approach in combination with SMOTE and Resample to select most discriminative metrics. Then the top four classifiers based on performance are used for software fault prediction. The experimentation is carried out over 15 publically available datasets (small, medium and large) which are collected from PROMISE repository. The proposed Resample-FLDA method gives better performance as compared to existing methods in terms of precision, recall, f-measure and area under the curve.},
journal = {J. Supercomput.},
month = sep,
pages = {4568–4602},
numpages = {35},
keywords = {Software fault prediction, Robustness, Reliability, Fisher linear discriminant, Fault-tolerance}
}

@article{10.1007/s10664-018-9661-2,
author = {Huang, Qiao and Xia, Xin and Lo, David},
title = {Revisiting supervised and unsupervised models for effort-aware just-in-time defect prediction},
year = {2019},
issue_date = {Oct 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-018-9661-2},
doi = {10.1007/s10664-018-9661-2},
abstract = {Effort-aware just-in-time (JIT) defect prediction aims at finding more defective software changes with limited code inspection cost. Traditionally, supervised models have been used; however, they require sufficient labelled training data, which is difficult to obtain, especially for new projects. Recently, Yang et al. proposed an unsupervised model (i.e., LT) and applied it to projects with rich historical bug data. Interestingly, they reported that, under the same inspection cost (i.e., 20 percent of the total lines of code modified by all changes), it could find about 12% - 27% more defective changes than a state-of-the-art supervised model (i.e., EALR) when using different evaluation settings. This is surprising as supervised models that benefit from historical data are expected to perform better than unsupervised ones. Their finding suggests that previous studies on defect prediction had made a simple problem too complex. Considering the potential high impact of Yang et al.’s work, in this paper, we perform a replication study and present the following new findings: (1) Under the same inspection budget, LT requires developers to inspect a large number of changes necessitating many more context switches. (2) Although LT finds more defective changes, many highly ranked changes are false alarms. These initial false alarms may negatively impact practitioners’ patience and confidence. (3) LT does not outperform EALR when the harmonic mean of Recall and Precision (i.e., F1-score) is considered. Aside from highlighting the above findings, we propose a simple but improved supervised model called CBS+, which leverages the idea of both EALR and LT. We investigate the performance of CBS+ using three different evaluation settings, including time-wise cross-validation, 10-times 10-fold cross-validation and cross-project validation. When compared with EALR, CBS+ detects about 15% - 26% more defective changes, while keeping the number of context switches and initial false alarms close to those of EALR. When compared with LT, the number of defective changes detected by CBS+ is comparable to LT’s result, while CBS+ significantly reduces context switches and initial false alarms before first success. Finally, we discuss how to balance the tradeoff between the number of inspected defects and context switches, and present the implications of our findings for practitioners and researchers.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {2823–2862},
numpages = {40},
keywords = {Research bias, Evaluation metrics, Defect prediction}
}

@inproceedings{10.1007/978-3-642-01702-5_20,
author = {Ostrand, Thomas J. and Weyuker, Elaine J.},
title = {Progress in Automated Software Defect Prediction},
year = {2009},
isbn = {9783642017018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-01702-5_20},
doi = {10.1007/978-3-642-01702-5_20},
abstract = {We have designed and implemented a tool that predicts files most likely to have defects in a future release of a large software system. The tool builds a regression model based on the version and defect history of the system, and produces a list of the next release's most probable fault-prone files, sorted in decreasing order of the number of predicted defects. Testers can use this information to decide where to focus resources, and to help determine how much effort to allocate to various parts of the system. Developers can use the tool's output to help decide whether files should be rewritten rather than patched. A prototype version of the tool has been integrated with AT&amp;T's internal software change management system, providing seamless access to the system's version and defect information, and giving users a simple interface to the tool's output.},
booktitle = {Proceedings of the 4th International Haifa Verification Conference on Hardware and Software: Verification and Testing},
pages = {200–204},
numpages = {5},
keywords = {software fault prediction, negative binomial model, automated tool},
location = {Haifa, Israel},
series = {HVC '08}
}

@inproceedings{10.1145/2723742.2723754,
author = {Muthukumaran, K. and Rallapalli, Akhila and Murthy, N. L. Bhanu},
title = {Impact of Feature Selection Techniques on Bug Prediction Models},
year = {2015},
isbn = {9781450334327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723742.2723754},
doi = {10.1145/2723742.2723754},
abstract = {Several change metrics and source code metrics have been introduced and proved to be effective features in building bug prediction models. Researchers performed comparative studies of bug prediction models built using the individual metrics as well as combination of these metrics. In this paper, we investigate whether the prediction accuracy of bug prediction models is improved by applying feature selection techniques. We explore if there is one algorithm amongst ten popular feature selection algorithms that consistently fares better than others across sixteen bench marked open source projects. We also study whether the metrics in best feature subset are consistent across projects.},
booktitle = {Proceedings of the 8th India Software Engineering Conference},
pages = {120–129},
numpages = {10},
keywords = {Software Quality, Feature selection, Bug prediction},
location = {Bangalore, India},
series = {ISEC '15}
}

@article{10.1016/j.knosys.2021.107541,
author = {Pandey, Sushant Kumar and Tripathi, Anil Kumar},
title = {DNNAttention: A deep neural network and attention based architecture for cross project defect number prediction},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {233},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107541},
doi = {10.1016/j.knosys.2021.107541},
journal = {Know.-Based Syst.},
month = dec,
numpages = {30},
keywords = {Software defect number prediction, Long short term memory (LSTM), Attention layer, Deep neural network, Cross project defect prediction}
}

@article{10.1007/s10470-020-01732-8,
author = {Shokrolahi, Seyed Moslem and Karimiziarani, Mohammadsepehr},
title = {A deep network solution for intelligent fault detection in analog circuit},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {107},
number = {3},
issn = {0925-1030},
url = {https://doi.org/10.1007/s10470-020-01732-8},
doi = {10.1007/s10470-020-01732-8},
abstract = {Automatic fault diagnosis in analog electronic circuits is one of the interesting and important cases for researchers of this field that has gained substantial improvements in recent decades. Fault detection issue could be transferred into a classification problem. In this paper, a new fault detection method is proposed based on deep Convolution Neural Network (CNN). We used the real part of Power Spectrum Density (PSD) of faulty signals as the input images of CNN. The main reason for this is extracting microstructure features among signals by using PSD which result in a better discrimination amongst wide range of faults. Our method is evaluated by two benchmark circuits. The superior performance of our method is proved by simulation results and compared with other state of arts.},
journal = {Analog Integr. Circuits Signal Process.},
month = jun,
pages = {597–604},
numpages = {8},
keywords = {Power spectrum density, Feature extraction, CNN, Fault detection}
}

@inproceedings{10.1109/ICMLA.2012.226,
author = {Hall, Tracy and Bowes, David},
title = {The State of Machine Learning Methodology in Software Fault Prediction},
year = {2012},
isbn = {9780769549132},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2012.226},
doi = {10.1109/ICMLA.2012.226},
abstract = {The aim of this paper is to investigate the quality of methodology in software fault prediction studies using machine learning. Over two hundred studies of fault prediction have been published in the last 10 years. There is evidence to suggest that the quality of methodology used in some of these studies does not allow us to have confidence in the predictions reported by them. We evaluate the machine learning methodology used in 21 fault prediction studies. All of these studies use NASA data sets. We score each study from 1 to 10 in terms of the quality of their machine learning methodology (e.g. whether or not studies report randomising their cross validation folds). Only 10 out of the 21 studies scored 5 or more out of 10. Furthermore 1 study scored only 1 out of 10. When we plot these scores over time there is no evidence that the quality of machine learning methodology is better in recent studies. Our results suggest that there remains much to be done by both researchers and reviewers to improve the quality of machine learning methodology used in software fault prediction. We conclude that the results reported in some studies need to be treated with caution.},
booktitle = {Proceedings of the 2012 11th International Conference on Machine Learning and Applications - Volume 02},
pages = {308–313},
numpages = {6},
keywords = {software engineering, methodology, machine learning, fault prediction, experimental techniques},
series = {ICMLA '12}
}

@inproceedings{10.1145/3492547.3492608,
author = {Alsubhi, Sara R. and Laabidi, Kaouther and Hsairi, Lobna},
title = {Comparison of Several Artificial Neural Network Approaches for Fault Classification in Power Transmission Lines},
year = {2021},
isbn = {9781450390446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3492547.3492608},
doi = {10.1145/3492547.3492608},
abstract = {In this paper, we provide an application of multiple machine learning methods to classify the faults in power transmission lines. A dataset with different fault scenarios was obtained from a 735-kV transmission network using MATLAB and Simulink. After a proper data preprocessing and feature analysis, the fault classification was applied using three different artificial neural network architectures: backpropagation neural network, radial basis function neural network, and probabilistic neural network. We evaluated the effectiveness of the three models and obtained the accuracy of each model. The test results show that the three models are successfully able to classify the fault type. However, the probabilistic neural network model has the highest performance with the shortest prediction time.},
booktitle = {The 7th International Conference on Engineering &amp; MIS 2021},
articleno = {32},
numpages = {6},
keywords = {Radial Basis Function Neural Network, Probabilistic Neural Network, Power Distribution System., Fault Classification, Back Propagation Neural Network},
location = {Almaty, Kazakhstan},
series = {ICEMIS'21}
}

@inproceedings{10.1145/3196321.3196331,
author = {Xu, Zhou and Li, Shuai and Tang, Yutian and Luo, Xiapu and Zhang, Tao and Liu, Jin and Xu, Jun},
title = {Cross version defect prediction with representative data via sparse subset selection},
year = {2018},
isbn = {9781450357142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196321.3196331},
doi = {10.1145/3196321.3196331},
abstract = {Software defect prediction aims at detecting the defect-prone software modules by mining historical development data from software repositories. If such modules are identified at the early stage of the development, it can save large amounts of resources. Cross Version Defect Prediction (CVDP) is a practical scenario by training the classification model on the historical data of the prior version and then predicting the defect labels of modules of the current version. However, software development is a constantly-evolving process which leads to the data distribution differences across versions within the same project. The distribution differences will degrade the performance of the classification model. In this paper, we approach this issue by leveraging a state-of-the-art Dissimilarity-based Sparse Subset Selection (DS3) method. This method selects a representative module subset from the prior version based on the pairwise dissimilarities between the modules of two versions and assigns each module of the current version to one of the representative modules. These selected modules can well represent the modules of the current version, thus mitigating the distribution differences. We evaluate the effectiveness of DS3 for CVDP performance on total 40 cross-version pairs from 56 versions of 15 projects with three traditional and two effort-aware indicators. The extensive experiments show that DS3 outperforms three baseline methods, especially in terms of two effort-aware indicators.},
booktitle = {Proceedings of the 26th Conference on Program Comprehension},
pages = {132–143},
numpages = {12},
keywords = {cross version defect prediction, pairwise dissimilarities, representative data, sparse subset selection},
location = {Gothenburg, Sweden},
series = {ICPC '18}
}

@inproceedings{10.1109/MOBILESoft.2017.58,
author = {Catolino, Gemma},
title = {Just-in-time bug prediction in mobile applications: the domain matters!},
year = {2017},
isbn = {9781538626696},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MOBILESoft.2017.58},
doi = {10.1109/MOBILESoft.2017.58},
abstract = {Bug prediction allows developers to focus testing efforts on specific areas of software systems. While this topic has been extensively studied for traditional applications, investigations on mobile apps are still missing. In this paper we preliminarily study the effectiveness of a previously defined Just-In-Time bug prediction model applied on five mobile apps. Key results indicate the poor performance of the model and the need of further research on the topic.},
booktitle = {Proceedings of the 4th International Conference on Mobile Software Engineering and Systems},
pages = {201–202},
numpages = {2},
keywords = {mobile applications, metrics, bug prediction},
location = {Buenos Aires, Argentina},
series = {MOBILESoft '17}
}

@inproceedings{10.1145/3439961.3439971,
author = {Correia, Jo\~{a}o Lucas and Pereira, Juliana Alves and Mello, Rafael and Garcia, Alessandro and Fonseca, Baldoino and Ribeiro, M\'{a}rcio and Gheyi, Rohit and Kalinowski, Marcos and Cerqueira, Renato and Tiengo, Willy},
title = {Brazilian Data Scientists: Revealing their Challenges and Practices on Machine Learning Model Development},
year = {2021},
isbn = {9781450389235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3439961.3439971},
doi = {10.1145/3439961.3439971},
abstract = {Data scientists often develop machine learning models to solve a variety of problems in the industry and academy. To build these models, these professionals usually perform activities that are also performed in the traditional software development lifecycle, such as eliciting and implementing requirements. One might argue that data scientists could rely on the engineering of traditional software development to build machine learning models. However, machine learning development presents certain characteristics, which may raise challenges that lead to the need for adopting new practices. The literature lacks in characterizing this knowledge from the perspective of the data scientists. In this paper, we characterize challenges and practices addressing the engineering of machine learning models that deserve attention from the research community. To this end, we performed a qualitative study with eight data scientists across five different companies having different levels of experience in developing machine learning models. Our findings suggest that: (i) data processing and feature engineering are the most challenging stages in the development of machine learning models; (ii) it is essential synergy between data scientists and domain experts in most of stages; and (iii) the development of machine learning models lacks the support of a well-engineered process.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Software Quality},
articleno = {10},
numpages = {10},
keywords = {Software Engineering, Practitioner, Machine Learning, Empirical Study},
location = {S\~{a}o Lu\'{\i}s, Brazil},
series = {SBQS '20}
}

@article{10.1002/smr.2230,
author = {Ampatzoglou, Apostolos and Arcelli&nbsp;Fontana, Francesca and Palomba, Fabio and Walter, Bartosz},
title = {Introduction to the special issue on “Machine Learning Techniques for Software Quality Evaluation”},
year = {2019},
issue_date = {September 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {31},
number = {9},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2230},
doi = {10.1002/smr.2230},
journal = {J. Softw. Evol. Process},
month = oct,
numpages = {2}
}

@inproceedings{10.1145/2896839.2896843,
author = {Koroglu, Yavuz and Sen, Alper and Kutluay, Doruk and Bayraktar, Akin and Tosun, Yalcin and Cinar, Murat and Kaya, Hasan},
title = {Defect prediction on a legacy industrial software: a case study on software with few defects},
year = {2016},
isbn = {9781450341547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896839.2896843},
doi = {10.1145/2896839.2896843},
abstract = {Context: Building defect prediction models for software projects is helpful for reducing the effort in locating defects. In this paper, we share our experiences in building a defect prediction model for a large industrial software project. We extract product and process metrics to build models and show that we can build an accurate defect prediction model even when 4% of the software is defective.Objective: Our goal in this project is to integrate a defect predictor into the continuous integration (CI) cycle of a large software project and decrease the effort in testing.Method: We present our approach in the form of an experience report. Specifically, we collected data from seven older versions of the software project and used additional features to predict defects of current versions. We compared several classification techniques including Naive Bayes, Decision Trees, and Random Forest and resampled our training data to present the company with the most accurate defect predictor.Results: Our results indicate that we can focus testing efforts by guiding the test team to only 8% of the software where 53% of actual defects can be found. Our model has 90% accuracy.Conclusion: We produce a defect prediction model with high accuracy for a software with defect rate of 4%. Our model uses Random Forest, that which we show has more predictive power than Naive Bayes, Logistic Regression and Decision Trees in our case.},
booktitle = {Proceedings of the 4th International Workshop on Conducting Empirical Studies in Industry},
pages = {14–20},
numpages = {7},
keywords = {random forest, process metrics, feature selection, experience report, defect prediction},
location = {Austin, Texas},
series = {CESI '16}
}

@article{10.1109/TSMCC.2012.2226152,
author = {Sun, Zhongbin and Song, Qinbao and Zhu, Xiaoyan},
title = {Using Coding-Based Ensemble Learning to Improve Software Defect Prediction},
year = {2012},
issue_date = {November 2012},
publisher = {IEEE Press},
volume = {42},
number = {6},
issn = {1094-6977},
url = {https://doi.org/10.1109/TSMCC.2012.2226152},
doi = {10.1109/TSMCC.2012.2226152},
abstract = {Using classification methods to predict software defect proneness with static code attributes has attracted a great deal of attention. The class-imbalance characteristic of software defect data makes the prediction much difficult; thus, a number of methods have been employed to address this problem. However, these conventional methods, such as sampling, cost-sensitive learning, Bagging, and Boosting, could suffer from the loss of important information, unexpected mistakes, and overfitting because they alter the original data distribution. This paper presents a novel method that first converts the imbalanced binary-class data into balanced multiclass data and then builds a defect predictor on the multiclass data with a specific coding scheme. A thorough experiment with four different types of classification algorithms, three data coding schemes, and six conventional imbalance data-handling methods was conducted over the 14 NASA datasets. The experimental results show that the proposed method with a one-against-one coding scheme is averagely superior to the conventional methods.},
journal = {Trans. Sys. Man Cyber Part C},
month = nov,
pages = {1806–1817},
numpages = {12}
}

@inproceedings{10.1109/MSR.2017.20,
author = {Patil, Sangameshwar},
title = {Concept-based classification of software defect reports},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.20},
doi = {10.1109/MSR.2017.20},
abstract = {Automatic identification of the defect type from the textual description of a software defect can significantly speedup as well as improve the software defect management life-cycle. This has been recognized in the research community and multiple solutions based on supervised learning approach have been proposed in the recent literature. However, these approaches need significant amount of labeled training data for use in real-life projects.In this paper, we propose to use Explicit Semantic Analysis (ESA) to carry out concept-based classification of software defect reports. We compute the "semantic similarity" between the defect type labels and the defect report in a concept space spanned by Wikipedia articles and then, assign the defect type which has the highest similarity with the defect report. This approach helps us to circumvent the problem of dependence on labeled training data. Experimental results show that using concept-based classification is a promising approach for software defect classification to avoid the expensive process of creating labeled training data and yet get accuracy comparable to the traditional supervised learning approaches. To the best of our knowledge, this is the first use of Wikipedia and ESA for software defect classification problem.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {182–186},
numpages = {5},
keywords = {text data mining, software defect classification, mining software respositories, explicit semantic analysis},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1145/3183440.3195100,
author = {Su, Emily and Joshi, Sameer},
title = {Leveraging product relationships to generate candidate bugs for duplicate bug prediction},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3195100},
doi = {10.1145/3183440.3195100},
abstract = {Adaptive Bug Search (ABS) is a service developed by Oracle that uses machine learning to find potential duplicate bugs for a given input bug. ABS leverages the product and component relationships of existing duplicate bug pairs to limit the set of candidate bugs in which it searches for potential duplicates. In this paper, we discuss various approaches for selecting and refining the set of candidate bugs.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {210–211},
numpages = {2},
keywords = {duplicate bug prediction, human factors, machine learning},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/2245276.2231975,
author = {Banthia, Deepak and Gupta, Atul},
title = {Investigating fault prediction capabilities of five prediction models for software quality},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2245276.2231975},
doi = {10.1145/2245276.2231975},
abstract = {Predicting faults in software modules can lead to a high quality and more effective software development process to follow. However, the results of a fault prediction model have to be properly interpreted before incorporating them into any decision making. Most of the earlier studies have used the prediction accuracy as the main criteria to compare amongst competing fault prediction models. However, we show that besides accuracy, other criteria like number of false positives and false negatives can equally be important to choose a candidate model for fault prediction. We have used five NASA software data sets in our experiment. Our results suggest that the performance of Simple Logistic is better than the others on raw data sets whereas the performance of Neural Network was found to be better when we applied dimensionality reduction method on raw data sets. When we used data pre-processing techniques, the prediction accuracy of Random Forest was found to be better in both cases i.e. with and without dimensionality reduction but reliability of Simple Logistic was better than Random Forest because it had less number of fault negatives.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {1259–1261},
numpages = {3},
keywords = {quality assurance, fault prediction models, fault prediction, effort estimation, attribute selection},
location = {Trento, Italy},
series = {SAC '12}
}

@article{10.1007/s11219-014-9241-7,
author = {Madeyski, Lech and Jureczko, Marian},
title = {Which process metrics can significantly improve defect prediction models? An empirical study},
year = {2015},
issue_date = {September 2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {23},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-014-9241-7},
doi = {10.1007/s11219-014-9241-7},
abstract = {The knowledge about the software metrics which serve as defect indicators is vital for the efficient allocation of resources for quality assurance. It is the process metrics, although sometimes difficult to collect, which have recently become popular with regard to defect prediction. However, in order to identify rightly the process metrics which are actually worth collecting, we need the evidence validating their ability to improve the product metric-based defect prediction models. This paper presents an empirical evaluation in which several process metrics were investigated in order to identify the ones which significantly improve the defect prediction models based on product metrics. Data from a wide range of software projects (both, industrial and open source) were collected. The predictions of the models that use only product metrics (simple models) were compared with the predictions of the models which used product metrics, as well as one of the process metrics under scrutiny (advanced models). To decide whether the improvements were significant or not, statistical tests were performed and effect sizes were calculated. The advanced defect prediction models trained on a data set containing product metrics and additionally Number of Distinct Committers (NDC) were significantly better than the simple models without NDC, while the effect size was medium and the probability of superiority (PS) of the advanced models over simple ones was high (  $$p=.016$$ p = . 016 ,  $$r=-.29$$ r = - . 29 ,  $$hbox {PS}=.76$$ PS = . 76 ), which is a substantial finding useful in defect prediction. A similar result with slightly smaller PS was achieved by the advanced models trained on a data set containing product metrics and additionally all of the investigated process metrics (  $$p=.038$$ p = . 038 ,  $$r=-.29$$ r = - . 29 ,  $$hbox {PS}=.68$$ PS = . 68 ). The advanced models trained on a data set containing product metrics and additionally Number of Modified Lines (NML) were significantly better than the simple models without NML, but the effect size was small (  $$p=.038$$ p = . 038 ,  $$r=.06$$ r = . 06 ). Hence, it is reasonable to recommend the NDC process metric in building the defect prediction models.},
journal = {Software Quality Journal},
month = sep,
pages = {393–422},
numpages = {30},
keywords = {Software metrics, Software defect prediction, Product metrics, Process metrics, Defect prediction models}
}

@article{10.1007/s10462-020-09934-2,
author = {Abid, Anam and Khan, Muhammad Tahir and Iqbal, Javaid},
title = {A review on fault detection and diagnosis techniques: basics and beyond},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {54},
number = {5},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09934-2},
doi = {10.1007/s10462-020-09934-2},
abstract = {Safety and reliability are absolutely important for modern sophisticated systems and technologies. Therefore, malfunction monitoring capabilities are instilled in the system for detection of the incipient faults and anticipation of their impact on the future behavior of the system using fault diagnosis techniques. In particular, state-of-the-art applications rely on the quick and efficient treatment of malfunctions within the equipment/system, resulting in increased production and reduced downtimes. This paper presents developments within Fault Detection and Diagnosis (FDD) methods and reviews of research work in this area. The review presents both traditional model-based and relatively new signal processing-based FDD approaches, with a special consideration paid to artificial intelligence-based FDD methods. Typical steps involved in the design and development of automatic FDD system, including system knowledge representation, data-acquisition and signal processing, fault classification, and maintenance related decision actions, are systematically presented to outline the present status of FDD. Future research trends, challenges and prospective solutions are also highlighted.},
journal = {Artif. Intell. Rev.},
month = jun,
pages = {3639–3664},
numpages = {26},
keywords = {Signal processing, Industrial applications, Fault detection, Automatic fault diagnosis}
}

@inproceedings{10.1007/978-3-030-70866-5_3,
author = {Mohammedi, El-Heithem and Lavinal, Emmanuel and Fleury, Guillaume},
title = {Configuration Faults Detection in IP Virtual Private Networks Based on Machine Learning},
year = {2020},
isbn = {978-3-030-70865-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-70866-5_3},
doi = {10.1007/978-3-030-70866-5_3},
abstract = {Network incidents are largely due to configuration errors, particularly within network service providers who manage large complex networks. Such providers offer virtual private networks to their customers to interconnect their remote sites and provide Internet access. The growing demand for virtual private networks leads service providers to search for novel scalable approaches to locate incidents arising from configuration faults. In this paper, we propose a machine learning approach that aims to locate customer connectivity issues coming from configurations errors, in a BGP/MPLS IP virtual private network architecture. We feed the learning model with valid and faulty configuration data and train it using three algorithms: decision tree, random forest and multi-layer perceptron. Since failures can occur on several routers, we consider the learning problem as a supervised multi-label classification problem, where each customer router is represented by a unique label. We carry out our experiments on three network sizes containing different types of configuration errors. Results show that multi-layer perceptron has a better accuracy in detecting faults than the other algorithms, making it a potential candidate to validate offline network configurations before online deployment.},
booktitle = {Machine Learning for Networking: Third International Conference, MLN 2020, Paris, France, November 24–26, 2020, Revised Selected Papers},
pages = {40–56},
numpages = {17},
keywords = {BGP/MPLS networks, Virtual private networks, Machine learning, Configuration faults detection},
location = {Paris, France}
}

@article{10.3233/IDA-205504,
author = {Saifan, Ahmad A. and Lataifeh, Zainab},
title = {Privacy preserving defect prediction using generalization and entropy-based data reduction},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {25},
number = {6},
issn = {1088-467X},
url = {https://doi.org/10.3233/IDA-205504},
doi = {10.3233/IDA-205504},
abstract = {The software engineering community produces data that can be analyzed to enhance the quality of future software products, and data regarding software defects can be used by data scientists to create defect predictors. However, sharing such data raises privacy concerns, since sensitive software features are usually considered as business assets that should be protected in accordance with the law. Early research efforts on protecting the privacy of software data found that applying conventional data anonymization to mask sensitive attributes of software features degrades the quality of the shared data. In addition, data produced by such approaches is not immune to attacks such as inference and background knowledge attacks. This research proposes a new approach to share protected release of software defects data that can still be used in data science algorithms. We created a generalization (clustering)-based approach to anonymize sensitive software attributes. Tomek link and AllNN data reduction approaches were used to discard noisy records that may affect the usefulness of the shared data. The proposed approach considers diversity of sensitive attributes as an important factor to avoid inference and background knowledge attacks on the anonymized data, therefore data discarded is removed from both defective and non-defective records. We conducted experiments conducted on several benchmark software defect datasets, using both data quality and privacy measures to evaluate the proposed approach. Our findings showed that the proposed approach outperforms existing well-known techniques using accuracy and privacy measures.},
journal = {Intell. Data Anal.},
month = jan,
pages = {1369–1405},
numpages = {37}
}

@inproceedings{10.5555/1881763.1881787,
author = {Liu, Guang-Jie and Wang, Wen-Yong},
title = {Research an educational software defect prediction model based on SVM},
year = {2010},
isbn = {3642145329},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We must pay attention and find defects, defects through the prediction to quantify the quality management and quality in order to achieve this goal, requires an estimate of the various defect detection process. Software defects are the departure of software are products' anticipative function. This paper collecting the data of the software defects, then, using the SVM model the predictive values are gained analyzing the predictive results, software are organizations can improve software control measure software process and allocate testing resources effectively.},
booktitle = {Proceedings of the Entertainment for Education, and 5th International Conference on E-Learning and Games},
pages = {215–222},
numpages = {8},
keywords = {software lifecycle, software defect, educational software, SVM},
location = {Changchun, China},
series = {Edutainment'10}
}

@inproceedings{10.1007/978-3-030-77932-0_26,
author = {Saito, Yuto and Mohd Anuardi, Muhammad Nur Adilin and Matsubara, Ryota and Sugaya, Midori},
title = {Preliminary Analysis of Human Error Prediction Model by Using Biological Information},
year = {2021},
isbn = {978-3-030-77931-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-77932-0_26},
doi = {10.1007/978-3-030-77932-0_26},
abstract = {Increasing in aging population forced the society to act more than their limit. For instance, an action such as driving, where we need our mental concentration at most, could lead to serious accident from a simple mistake because of overwork. Therefore, it is crucial to prevent the accident. Many researchers focus on biological information to predict the error because human error always related to a person’s cognitive condition such as stress and discomfort. However, existing studies on the human error prediction model have not conducted a detailed analysis, and also have not considered individual differences. Therefore, the purpose of this study is to analyze the biological information immediately before and after the occurrence of human error in order to construct a prediction model for human error considering individual differences. In this study, we developed the Stroop task to be used as the mental workload and measured the subjects’ biological information. As a result, we proposed 10 [s] as the time intervals for before and after the consecutive of the occurrence of the human errors for better analysis. Besides, the biological information measured from all subjects suggested that pNN10 can be considered as the predictive indicator for human error occurrence. However, other biological information also expressed vary results where our next step needs to consider the individual differences by increasing the sample size. In addition, the logistic regression will be considered for machine learning to be used for the human error prediction model construction.},
booktitle = {Engineering Psychology and Cognitive Ergonomics: 18th International Conference, EPCE 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual Event, July 24–29, 2021, Proceedings},
pages = {324–335},
numpages = {12},
keywords = {Heart rate variability, Electroencephalography, Human error}
}

@inproceedings{10.1109/WORDS.2005.32,
author = {Challagulla, Venkata U. B. and Bastani, Farokh B. and Yen, I-Ling and Paul, Raymond A.},
title = {Empirical Assessment of Machine Learning based Software Defect Prediction Techniques},
year = {2005},
isbn = {0769523471},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/WORDS.2005.32},
doi = {10.1109/WORDS.2005.32},
abstract = {The wide-variety of real-time software systems, including telecontrol/telepresence systems, robotic systems, and mission planning systems, can entail dynamic code synthesis based on runtime mission-specific requirements and operating conditions. This necessitates the need for dynamic dependability assessment to ensure that these systems will perform as specified and will not fail in catastrophic ways. One approach in achieving this is to dynamically assess the modules in the synthesized code using software defect prediction techniques. Statistical models, such as Stepwise Multi-linear Regression models and multivariate models, and machine learning approaches, such as Artificial Neural Networks, Instance-based Reasoning, Bayesian-Belief Networks, Decision Trees, and Rule Inductions, have been investigated for predicting software quality. However, there is still no consensus about the best predictor model for software defects. In this paper, we evaluate different predictor models on four different real-time software defect data sets. The results show that a combination of 1R and Instance-based Learning along with the Consistencybased Subset Evaluation technique provides relatively better consistency in accuracy prediction compared to other models. The results also show that "size" and "complexity" metrics are not sufficient for accurately predicting real-time software defects.},
booktitle = {Proceedings of the 10th IEEE International Workshop on Object-Oriented Real-Time Dependable Systems},
pages = {263–270},
numpages = {8},
series = {WORDS '05}
}

@inproceedings{10.1109/ICMA.2018.8484590,
author = {Li, Ningning and Xue, Wei and Zhao, Songbo and Gao, Qiang and Li, Dahua and Xu, Liang},
title = {Application of Improved PSO-BP Neural Network in Fault Detection of Liquid-Propellant Rocket Engine},
year = {2018},
isbn = {978-1-5386-6074-4},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICMA.2018.8484590},
doi = {10.1109/ICMA.2018.8484590},
abstract = {Because liquid-propellant rocket engine (LRE) is working in complex environment, the reliability of some traditional fault detection methods is low due to the characteristics of limited fault samples, small samples, high coupling and nonlinear variation of the main engine. In order to improve the shortcomings of fault detection in traditional method, this paper presents a fault detection algorithm (PSO-BP) based on improved particle swarm optimization (PSO) algorithm and BP neural network. The structure of BP neural network is established, the collected samples are input into PSO algorithm to optimize, and the optimal BP parameters are found, and the fault detection model of the main engine is established. Finally, the established model is used to simulate the fault. The simulation results show that the proposed algorithm can improves the accuracy of fault detection in the health management of LRE and provides a guarantee for the market demand of commercial launch},
booktitle = {2018 IEEE International Conference on Mechatronics and Automation (ICMA)},
pages = {2025–2029},
numpages = {5},
location = {Changchun, Jilin, China}
}

@inproceedings{10.1109/ASE.2013.6693087,
author = {Jiang, Tian and Tan, Lin and Kim, Sunghun},
title = {Personalized defect prediction},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693087},
doi = {10.1109/ASE.2013.6693087},
abstract = {Many defect prediction techniques have been proposed. While they often take the author of the code into consideration, none of these techniques build a separate prediction model for each developer. Different developers have different coding styles, commit frequencies, and experience levels, causing different defect patterns. When the defects of different developers are combined, such differences are obscured, hurting prediction performance.This paper proposes personalized defect prediction--building a separate prediction model for each developer to predict software defects. As a proof of concept, we apply our personalized defect prediction to classify defects at the file change level. We evaluate our personalized change classification technique on six large software projects written in C and Java--the Linux kernel, PostgreSQL, Xorg, Eclipse, Lucene and Jackrabbit. Our personalized approach can discover up to 155 more bugs than the traditional change classification (210 versus 55) if developers inspect the top 20% lines of code that are predicted buggy. In addition, our approach improves the F1-score by 0.01-0.06 compared to the traditional change classification.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {279–289},
numpages = {11},
keywords = {software reliability, personalized defect prediction, machine learning, change classification},
location = {Silicon Valley, CA, USA},
series = {ASE '13}
}

@article{10.1155/2020/8858010,
author = {Shen, Zhidong and Chen, Si and Coppolino, Luigi},
title = {A Survey of Automatic Software Vulnerability Detection, Program Repair, and Defect Prediction Techniques},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1939-0114},
url = {https://doi.org/10.1155/2020/8858010},
doi = {10.1155/2020/8858010},
abstract = {Open source software has been widely used in various industries due to its openness and flexibility, but it also brings potential software security problems. Together with the large-scale increase in the number of software and the increase in complexity, the traditional manual methods to deal with these security issues are inefficient and cannot meet the current cyberspace security requirements. Therefore, it is an important research topic for researchers in the field of software security to develop more intelligent technologies to apply to potential security issues in software. The development of deep learning technology has brought new opportunities for the study of potential security issues in software, and researchers have successively proposed many automation methods. In this paper, these automation technologies are evaluated and analysed in detail from three aspects: software vulnerability detection, software program repair, and software defect prediction. At the same time, we point out some problems of these research methods, give corresponding solutions, and finally look forward to the application prospect of deep learning technology in automated software vulnerability detection, automated program repair, and automated defect prediction.},
journal = {Sec. and Commun. Netw.},
month = jan,
numpages = {16}
}

@article{10.1016/j.eswa.2019.113085,
author = {Pandey, Sushant Kumar and Mishra, Ravi Bhushan and Tripathi, Anil Kumar},
title = {BPDET: An effective software bug prediction model using deep representation and ensemble learning techniques},
year = {2020},
issue_date = {Apr 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {144},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.113085},
doi = {10.1016/j.eswa.2019.113085},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {22},
keywords = {Heterogeneous Ensemble learning technique, Staked denoising auto-encoder, Boosting, Deep representation, Software metrics, Classification technique, Software bug prediction}
}

@article{10.1016/j.asoc.2021.107319,
author = {Chen, Yang and Tong, Chudong and Ge, Yinghui and Lan, Ting},
title = {Fault detection based on auto-regressive extreme learning machine for nonlinear dynamic processes},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {106},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107319},
doi = {10.1016/j.asoc.2021.107319},
journal = {Appl. Soft Comput.},
month = jul,
numpages = {9},
keywords = {Fault detection, Dynamic process monitoring, Auto-regressive model, Extreme learning machine}
}

@inproceedings{10.1109/CEC45853.2021.9504804,
author = {Roberto Farah, Paulo and Mariani, Thain\'{a} and da Roza, Enrique A. and Silva, Rog\'{e}rio C. and Regina Vergilio, Silvia},
title = {Unsupervised Learning For Refactoring Pattern Detection},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC45853.2021.9504804},
doi = {10.1109/CEC45853.2021.9504804},
abstract = {Software refactoring changes the structure of a program without modifying its external behavior, generally intending to improve software quality attributes. However, refactoring is a complex activity and, many times, a composition of refactorings is necessary. Besides, some code elements are refactored similarly, considering the kind and frequency of refactorings applied. Works in the refactoring literature usually investigate the impact and understanding of an individual refactoring, neglecting that developers have to apply more than one refactoring operation to reach their goals. There is a lack of studies to identify and characterize refactoring patterns. To fulfill this gap, this work explores the use of unsupervised learning, particularly cluster analysis, to group elements (Java classes) that are refactored similarly in software repositories. We used a total of 1435 projects and applied the K-Means algorithm to group classes that received the same refactoring with the same frequency. We obtained a set of seven clusters. Then, the main refactoring compositions associated with each cluster are analyzed to identify the corresponding pattern. Each pattern is described and also characterized using a set of metrics. The great majority of refactoring compositions include only one kind of refactoring, applied with low frequency. If we consider compositions including more than one type of refactorings, combinations of Extract Superclass and Pull Up Method are the most frequent.},
booktitle = {2021 IEEE Congress on Evolutionary Computation (CEC)},
pages = {2377–2384},
numpages = {8},
location = {Krak\'{o}w, Poland}
}

@article{10.1007/s00521-018-3789-2,
author = {Silva, Sergio and Costa, Pyramo and Santana, Marcio and Leite, Daniel},
title = {Evolving neuro-fuzzy network for real-time high impedance fault detection and classification},
year = {2020},
issue_date = {Jun 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {12},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-018-3789-2},
doi = {10.1007/s00521-018-3789-2},
abstract = {This paper concerns the application of a neuro-fuzzy learning method based on data streams for high impedance fault (HIF) detection in medium-voltage power lines. A wavelet-packet-transform-based feature extraction method combined with a variation of evolving neuro-fuzzy network with fluctuating thresholds is considered for recognition of spatial–temporal patterns in the data. Wavelet families such as Haar, Symlet, Daubechie, Coiflet and Biorthogonal were investigated as a way to provide the most discriminative features for fault detection. The proposed evolving neuro-fuzzy classification model has shown to be particularly suitable for the problem because the HIF environment is subject to concept changes. Different from other statistical and intelligent approaches to the problem, the developed neuro-fuzzy model for HIF classification is not only parametrically, but also structurally adaptive to cope with nonstationarities and novelties. New neurons and connections are incrementally added to the neuro-fuzzy network when necessary for the identification of new patterns, such as faults and usual transients including sag, swell and spikes due to the switching of 3-phase capacitors and energization of transformers. Experimental evaluations compare the proposed classifier with other well-established computational intelligence methods, viz. multilayer perceptron neural network, learning vector quantization neural network and a support vector machine model. Results have shown that the evolving neuro-fuzzy system is effective and robust to changes. The system is able to maintain its detection and classification accuracy even in situations in which other classifiers exhibit a significant drop in accuracy due to gradual and abrupt changes of the fault patterns. Fuzzy rules are useful for interpretability purposes and help to enhance model credibility for decision making.},
journal = {Neural Comput. Appl.},
month = jun,
pages = {7597–7610},
numpages = {14},
keywords = {Fault detection, Power distribution system, Neuro-fuzzy, Evolving intelligence}
}

@article{10.1007/s10586-021-03282-8,
author = {Mustaqeem, Mohd. and Saqib, Mohd.},
title = {Principal component based support vector machine (PC-SVM): a hybrid technique for software defect detection},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {24},
number = {3},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-021-03282-8},
doi = {10.1007/s10586-021-03282-8},
abstract = {Defects are the major problems in the current situation and predicting them is also a difficult task. Researchers and scientists have developed many software defects prediction techniques to overcome this very helpful issue. But to some extend there is a need for an algorithm/method to predict defects with more accuracy, reduce time and space complexities. All the previous research conducted on the data without feature reduction lead to the curse of dimensionality. We brought up a machine learning hybrid approach by combining Principal component Analysis (PCA) and Support vector machines (SVM) to overcome the ongoing problem. We have employed PROMISE (CM1: 344 observations, KC1: 2109 observations) data from the directory of NASA to conduct our research. We split the dataset into training (CM1: 240 observations, KC1: 1476 observations) dataset and testing (CM1: 104 observations, KC1: 633 observations) datasets. Using PCA, we find the principal components for feature optimization which reduce the time complexity. Then, we applied SVM for classification due to very native qualities over traditional and conventional methods. We also employed the GridSearchCV method for hyperparameter tuning. In the proposed hybrid model we have found better accuracy (CM1: 95.2%, KC1: 86.6%) than other methods. The proposed model also presents higher evaluation in the terms of other criteria. As a limitation, the only problem with SVM is there is no probabilistic explanation for classification which may very rigid towards classifications. In the future, some other method may also introduce which can overcome this limitation and keep a soft probabilistic based margin for classification on the optimal hyperplane.},
journal = {Cluster Computing},
month = sep,
pages = {2581–2595},
numpages = {15},
keywords = {Software defects detection, PCA, SVM, Feature optimization, Classification, PROMISE dataset}
}

@article{10.1016/j.engappai.2009.10.001,
author = {Pendharkar, Parag C.},
title = {Exhaustive and heuristic search approaches for learning a software defect prediction model},
year = {2010},
issue_date = {February, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {23},
number = {1},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2009.10.001},
doi = {10.1016/j.engappai.2009.10.001},
abstract = {In this paper, we propose a software defect prediction model learning problem (SDPMLP) where a classification model selects appropriate relevant inputs, from a set of all available inputs, and learns the classification function. We show that the SDPMLP is a combinatorial optimization problem with factorial complexity, and propose two hybrid exhaustive search and probabilistic neural network (PNN), and simulated annealing (SA) and PNN procedures to solve it. For small size SDPMLP, exhaustive search PNN works well and provides an (all) optimal solution(s). However, for large size SDPMLP, the use of exhaustive search PNN approach is not pragmatic and only the SA-PNN allows us to solve the SDPMLP in a practical time limit. We compare the performance of our hybrid approaches with traditional classification algorithms and find that our hybrid approaches perform better than traditional classification algorithms.},
journal = {Eng. Appl. Artif. Intell.},
month = feb,
pages = {34–40},
numpages = {7},
keywords = {Software engineering, Simulated annealing, Probabilistic neural networks, Heuristics, Exhaustive search}
}

@inproceedings{10.1145/3128473.3128474,
author = {Pontes, A. and Siebra, C. and Bittencourt, M.},
title = {A Strategy for Functional Defect Prediction in Homogenous Datasets: A case study in the SIGAA academic system},
year = {2017},
isbn = {9781450353021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3128473.3128474},
doi = {10.1145/3128473.3128474},
abstract = {The optimization of test sequences is an important resource to improve the test efficiency of complex software systems. This optimization can be carried out by means of defect prediction techniques, which are able to identify modules with a higher chance to present problems, so that these modules can be first evaluated. The current literature brings some proposals of algorithms with high accuracy for defect prediction. However they present a poor generalization power, since problems of overfitting are hidden due to the nature of the evaluation methods that are used. The aim of this work is to propose a modelling strategy based on more homogeneous datasets to trainee defect prediction models aimed at functional bugs. The object of study for evaluation of our proposal is a complex system for academic management (SIGAA), which is used in several Brazilian universities. The application in successive versions of this system shows that our proposal is able to identify the best approach for defect prediction, which in fact indicates the most problematic modules, supporting in this way the construction of optimal test sequences.},
booktitle = {Proceedings of the 2nd Brazilian Symposium on Systematic and Automated Software Testing},
articleno = {1},
numpages = {10},
keywords = {test automation, software test, learning algorithms, Defect prediction},
location = {Fortaleza, Brazil},
series = {SAST '17}
}

@inproceedings{10.1145/3180155.3182520,
author = {Bennin, Kwabena E. and Keung, Jacky and Phannachitta, Passakorn and Monden, Akito and Mensah, Solomon},
title = {MAHAKIL: diversity based oversampling approach to alleviate the class imbalance issue in software defect prediction},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3182520},
doi = {10.1145/3180155.3182520},
abstract = {This study presents MAHAKIL, a novel and efficient synthetic over-sampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with five other sampling approaches using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant pf values than the other oversampling approaches, based on robust statistical tests.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {699},
numpages = {1},
keywords = {class imbalance learning, classification problems, data sampling methods, software defect prediction, synthetic sample generation},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1007/978-3-030-34885-4_28,
author = {Hussain, Muhammad Mubashir and Jadoon, Tariq and Awais, Mian M.},
title = {Induction Motor Inter-turn Short Circuit Fault Detection Using Efficient Feature Extraction for Machine Learning Based Fault Detectors},
year = {2019},
isbn = {978-3-030-34884-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-34885-4_28},
doi = {10.1007/978-3-030-34885-4_28},
abstract = {Inter-turn short circuit of the stator is one of the most common faults of an induction motor that degrades its performance and ultimately causes it to break down. To avoid unexpected breakdown, causing an industrial process to halt, it is desirable to continuously monitor the motor’s operation using an automated system that can differentiate normal from faulty operation. However, such automated systems usually require large datasets containing enough examples of normal and faulty characteristics of the motor to be able to detect abnormal behavior. The aim of this paper is to present some ways to extract such information or features from the available sensor signals data like motor currents, voltages and vibration, to enable a machine learning based fault detection system to discern normal operation from faulty operation with minimal training data.},
booktitle = {Artificial Intelligence XXXVI: 39th SGAI International Conference on Artificial Intelligence, AI 2019, Cambridge, UK, December 17–19, 2019, Proceedings},
pages = {362–378},
numpages = {17},
keywords = {Machine Learning (ML), Features, Stator inter-turn short circuit (ITSC) fault, Induction motors (IM)},
location = {Cambridge, United Kingdom}
}

@article{10.1007/s10470-014-0352-7,
author = {Jahangiri, Mahdieh and Razaghian, Farhad},
title = {Fault detection in analogue circuits using hybrid evolutionary algorithm and neural network},
year = {2014},
issue_date = {September 2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {80},
number = {3},
issn = {0925-1030},
url = {https://doi.org/10.1007/s10470-014-0352-7},
doi = {10.1007/s10470-014-0352-7},
abstract = {With the development of analog integrated circuits technology and due to the complexity, and various types of faults that occur in analog integrated circuits, fault detection is a new idea, has been studied in recent decades. In this paper a three amplifier state variable filter is used as circuit under test (CUT) and, a hybrid neural network is proposed for soft fault diagnosis of the CUT. Genetic algorithm (GA) has the powerful ability of searching the global optimal solution, and back propagation (BP) algorithm has the feature of rapid convergence on the local optima. The hybrid of two algorithm will improve the evolving speed of neural network. GA-BP scheme adopts GA to search the optimal combination of weights in the solution space, and then uses BP algorithm to obtain the accurate optimal solution quickly. Experiment results show that the proposed GA-BP scheme is more efficient and effective than BP algorithm.},
journal = {Analog Integr. Circuits Signal Process.},
month = sep,
pages = {551–556},
numpages = {6},
keywords = {Neural network, Genetic algorithm, Fault detection, Analog circuits}
}

@inproceedings{10.1109/ICMLA.2010.27,
author = {Wang, Huanjing and Khoshgoftaar, Taghi M. and Napolitano, Amri},
title = {A Comparative Study of Ensemble Feature Selection Techniques for Software Defect Prediction},
year = {2010},
isbn = {9780769543000},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2010.27},
doi = {10.1109/ICMLA.2010.27},
abstract = {Feature selection has become the essential step in many data mining applications. Using a single feature subset selection method may generate local optima. Ensembles of feature selection methods attempt to combine multiple feature selection methods instead of using a single one. We present a comprehensive empirical study examining 17 different ensembles of feature ranking techniques (rankers) including six commonly-used feature ranking techniques, the signal-to-noise filter technique, and 11 threshold-based feature ranking techniques. This study utilized 16 real-world software measurement data sets of different sizes and built 13,600 classification models. Experimental results indicate that ensembles of very few rankers are very effective and even better than ensembles of many or all rankers.},
booktitle = {Proceedings of the 2010 Ninth International Conference on Machine Learning and Applications},
pages = {135–140},
numpages = {6},
keywords = {feature ranking, ensembles, defect prediction},
series = {ICMLA '10}
}

@inproceedings{10.1145/2884781.2884804,
author = {Wang, Song and Liu, Taiyue and Tan, Lin},
title = {Automatically learning semantic features for defect prediction},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884804},
doi = {10.1145/2884781.2884804},
abstract = {Software defect prediction, which predicts defective code regions, can help developers find bugs and prioritize their testing efforts. To build accurate prediction models, previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs, and such a capability is needed for building accurate prediction models.To bridge the gap between programs' semantics and defect prediction features, this paper proposes to leverage a powerful representation-learning algorithm, deep learning, to learn semantic representation of programs automatically from source code. Specifically, we leverage Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs).Our evaluation on ten open source projects shows that our automatically learned semantic features significantly improve both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) compared to traditional features. Our semantic features improve WPDP on average by 14.7% in precision, 11.5% in recall, and 14.2% in F1. For CPDP, our semantic features based approach outperforms the state-of-the-art technique TCA+ with traditional features by 8.9% in F1.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {297–308},
numpages = {12},
location = {Austin, Texas},
series = {ICSE '16}
}

@article{10.1049/iet-sen.2018.5131,
author = {Qiu, Shaojian and Lu, Lu and Jiang, Siyu},
title = {Joint distribution matching model for distribution–adaptation‐based cross‐project defect prediction},
year = {2019},
issue_date = {October 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {13},
number = {5},
url = {https://doi.org/10.1049/iet-sen.2018.5131},
doi = {10.1049/iet-sen.2018.5131},
abstract = {Using classification methods to predict software defect is receiving a great deal of attention and most of the existing studies primarily conduct prediction under the within‐project setting. However, there usually had no or very limited labelled data to train an effective prediction model at an early phase of the software lifecycle. Thus, cross‐project defect prediction (CPDP) is proposed as an alternative solution, which is learning a defect predictor for a target project by using labelled data from a source project. Differing from previous CPDP methods that mainly apply instances selection and classifiers adjustment to improve the performance, in this study, the authors put forward a novel distribution–adaptation‐based CPDP approach, joint distribution matching (JDM). Specifically, JDM aims to minimise the joint distribution divergence between the source and target project to improve the CPDP performance. By constructing an adaptive weight vector for the instances of the source project, JDM can be effective and robust at reducing marginal distribution discrepancy and conditional distribution discrepancy simultaneously. Extensive experiments verify that JDM can outperform related distribution–adaptation‐based methods on 15 open‐source projects that are derived from two types of repositories.},
journal = {IET Software},
month = oct,
pages = {393–402},
numpages = {10},
keywords = {cross-project defect prediction, open-source projects, distribution–adaptation-based methods, conditional distribution discrepancy, marginal distribution discrepancy, adaptive weight vector, CPDP performance, joint distribution divergence, JDM, classifiers adjustment, instances selection, source project, target project, defect predictor, software lifecycle, effective prediction model, labelled data, within-project setting, software defect, classification methods, joint distribution matching model, vectors, learning (artificial intelligence), pattern classification}
}

@inproceedings{10.1007/978-3-030-58802-1_43,
author = {Oh, Jin Woo and Jeong, Jongpil},
title = {Bearing Fault Detection with a Deep Light Weight CNN},
year = {2020},
isbn = {978-3-030-58801-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58802-1_43},
doi = {10.1007/978-3-030-58802-1_43},
abstract = {Bearings are vital part of rotary machines. A failure of bearing has a negative impact on schedules, production operation and even human casualties. Therefore, in prior achieving fault detection and diagnosis (FDD) of bearing is ensuring the safety and reliable operation of rotating machinery systems. However, there are some challenges of the industrial FDD problems. Since according to a literature review, more than half of the broken machines are caused by bearing fault. Therefore, one of the important thing is time delay should be reduced for FDD. However, due to many learnable parameters in model and data of long sequence, both lead to time delay for FDD. Therefore, this paper proposes a deep Light Convolutional Neural Network (LCNN) using one dimensional convolution neural network for FDD.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part II},
pages = {604–612},
numpages = {9},
keywords = {Bearing, Fault diagnosis, Light, CNN, Data augmentation},
location = {Cagliari, Italy}
}

@article{10.1007/s10515-017-0220-7,
author = {Li, Zhiqiang and Jing, Xiao-Yuan and Wu, Fei and Zhu, Xiaoke and Xu, Baowen and Ying, Shi},
title = {Cost-sensitive transfer kernel canonical correlation analysis for heterogeneous defect prediction},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-017-0220-7},
doi = {10.1007/s10515-017-0220-7},
abstract = {Cross-project defect prediction (CPDP) refers to predicting defects in a target project using prediction models trained from historical data of other source projects. And CPDP in the scenario where source and target projects have different metric sets is called heterogeneous defect prediction (HDP). Recently, HDP has received much research interest. Existing HDP methods only consider the linear correlation relationship among the features (metrics) of the source and target projects, and such models are insufficient to evaluate nonlinear correlation relationship among the features. So these methods may suffer from the linearly inseparable problem in the linear feature space. Furthermore, existing HDP methods do not take the class imbalance problem into consideration. Unfortunately, the imbalanced nature of software defect datasets increases the learning difficulty for the predictors. In this paper, we propose a new cost-sensitive transfer kernel canonical correlation analysis (CTKCCA) approach for HDP. CTKCCA can not only make the data distributions of source and target projects much more similar in the nonlinear feature space, where the learned features have favorable separability, but also utilize the different misclassification costs for defective and defect-free classes to alleviate the class imbalance problem. We perform the Friedman test with Nemenyi's post-hoc statistical test and the Cliff's delta effect size test for the evaluation. Extensive experiments on 28 public projects from five data sources indicate that: (1) CTKCCA significantly performs better than the related CPDP methods; (2) CTKCCA performs better than the related state-of-the-art HDP methods.},
journal = {Automated Software Engg.},
month = jun,
pages = {201–245},
numpages = {45},
keywords = {Transfer learning, Kernel canonical correlation analysis, Heterogeneous defect prediction, Cost-sensitive learning, Class imbalance}
}

@article{10.5555/3271870.3271878,
title = {Software fault prediction using firefly algorithm},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {6},
number = {3–4},
issn = {1758-8715},
abstract = {The software fault prediction SFP literature has shown an immense growth of the research studies involving the artificial neural network ANN based fault prediction models. However, the default gradient descent back propagation neural networks BPNNs have a high risk of getting stuck in the local minima of the search space. A class of nature inspired computing methods overcomes this disadvantage of BPNNs and has helped ANNs to evolve into a class of adaptive ANN. In this work, we propose a hybrid SFP model built using firefly algorithm FA and artificial neural network ANN, along with an empirical comparison with GA and PSO based evolutionary methods in optimising the connection weights of ANN. Seven different datasets were involved and MSE and the confusion matrix parameters were used for performance evaluation. The results have shown that FA-ANN model has performed better than the genetic and particle swarm optimised ANN fault prediction models.},
journal = {Int. J. Intell. Eng. Inform.},
month = jan,
pages = {356–377},
numpages = {22}
}

@inproceedings{10.1109/ETFA.2017.8247619,
author = {Chadha, Gavneet Singh and Schwung, Andreas},
title = {Comparison of deep neural network architectures for fault detection in Tennessee Eastman process},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ETFA.2017.8247619},
doi = {10.1109/ETFA.2017.8247619},
abstract = {Process monitoring and fault diagnosis methods are used to detect abnormal events in industrial processes. Process breakdowns hinder the overall productivity of the system which makes the early detection of faults very critical. Due to the highly non-linear nature of modern industrial processes, deep neural networks with several layers of non-linear complex representations fit aptly for contemporary fault diagnosis. Although deep neural networks have found wide array of application areas such as image recognition and speech recognition, their effectiveness in fault detection has not been tested substantially. In this study, a comparison between two deep neural network architectures, namely Deep Stacking Networks and Sparse Stacked Autoencoders for fault detection from process data is presented. The Tennessee Eastman benchmark process is considered to test the effectiveness of these deep architectures. A detailed comparison between the two architectures is illustrated with different hyperparameters. The experiment results show that the Sparse Stacked Autoencoders model has superior average fault detection capability and is also more stable as it has less variation in fault detection rate.},
booktitle = {2017 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)},
pages = {1–8},
numpages = {8},
location = {Limassol, Cyprus}
}

@inproceedings{10.1109/ICICTA.2008.76,
author = {Yang, Weimin and Li, Longshu},
title = {A Rough Set Model for Software Defect Prediction},
year = {2008},
isbn = {9780769533575},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICICTA.2008.76},
doi = {10.1109/ICICTA.2008.76},
abstract = {High assurance software requires extensive and expensive assessment. Many software organizations frequently do not allocate enough resources for software quality. We research the defect detectors focusing on the data sets of software defect prediction. A rough set model is presented to deal with the attributes of data sets of software defect prediction in this paper. Appling this model to the most famous public domain data set created by the NASA's Metrics Data Program shows its splendid performance.},
booktitle = {Proceedings of the 2008 International Conference on Intelligent Computation Technology and Automation - Volume 01},
pages = {747–751},
numpages = {5},
series = {ICICTA '08}
}

@inproceedings{10.1145/3416508.3417118,
author = {Amasaki, Sousuke and Aman, Hirohisa and Yokogawa, Tomoyuki},
title = {An exploratory study on applicability of cross project defect prediction approaches to cross-company effort estimation},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417118},
doi = {10.1145/3416508.3417118},
abstract = {BACKGROUND: Research on software effort estimation has been active for decades, especially in developing effort estimation models. Effort estimation models need a dataset collected from completed projects similar to a project to be estimated. The similarity suffers from dataset shift, and cross-company software effort estimation (CCSEE) gets an attractive research topic. A recent study on the dataset shift problem examined the applicability and the effectiveness of cross-project defect prediction (CPDP) approaches. It was insufficient to bring a conclusion due to a limited number of examined approaches. AIMS: To investigate the characteristics of CPDP approaches that are applicable and effective for dataset shift problem in effort estimation. METHOD: We first reviewed the characteristics of 24 CPDP approaches to find applicable approaches. Next, we investigated their effectiveness in effort estimation performance with ten dataset configurations. RESULTS: 16 out of 24 CPDP approaches implemented in CrossPare framework were found to be applicable to CCSEE. However, only one approach could improve the effort estimation performance. Most of the others degraded it and were harmful. CONCLUSIONS: Most of the CPDP approaches we examined were helpless for CCSEE.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {71–80},
numpages = {10},
keywords = {cross-company effort estimation, cross-project defect prediction, empirical evaluation},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@article{10.1007/s11227-018-2711-0,
author = {Khan, Mohammad Azam and Kim, Yong-Hwa and Choo, Jaegul},
title = {Intelligent fault detection using raw vibration signals via dilated convolutional neural networks},
year = {2020},
issue_date = {Oct 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {10},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-018-2711-0},
doi = {10.1007/s11227-018-2711-0},
abstract = {Fault detection and diagnosis is critical to improve the reliability and availability in induction motors (IMs). Machine learning and deep learning techniques have been widely used in induction motor fault detection and diagnosis. In this paper, we propose a new deep learning model based on a dilated convolutional neural network (D-CNN) for detecting bearing faults in IMs. The proposed model works directly on raw vibration signals without any hand-crafted feature extraction process. Our model can incorporate global context without losing important local information by stacking dilated convolutions with an increasing width. Numerical results show that the proposed D-CNN is not only capable of classifying normal signals perfectly but also can achieve higher accuracy than conventional techniques under noisy environments.},
journal = {J. Supercomput.},
month = oct,
pages = {8086–8100},
numpages = {15},
keywords = {Convolutional neural networks, Deep neural networks, Vibration signals, Intelligent fault detection, Dilated convolution}
}

@article{10.3233/JIFS-201803,
author = {Chen, Yan and song, Huan-sheng and yang, Yan-ni and wang, Gang-feng},
title = {Fault detection in mixture production process based on wavelet packet and support vector machine},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {5},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-201803},
doi = {10.3233/JIFS-201803},
abstract = {Mixture production equipment is widely employed in road construction, and the quality of the produced mixture is the essential factor to ensure the quality of road construction. To detect the quality of the real-time produced mixture and solve the shortcomings of laboratory detection lag, a new fault detection method in the mixture production process is proposed, which is based on wavelet packet decomposition (WPD) and support vector machine (SVM). The proposed scheme includes feature extraction, feature selection, SVM classification, and optimization algorithm. During feature extraction, wavelet basis function is utilized to 4-layer decompose the aggregate and asphalt data mixed in real-time. The energy value calculated by wavelet packet coefficient is the extracted feature. During feature selection, a method combining the chi-square test and wrapper (CSW) is conducted to select the optimal feature subset from WPD features. Eventually, by adopting the optimal feature subset, SVM has been developed to classify various faults. Its parameters are optimized by differential evolution (DE) algorithm. In the test stage, multiple faults of different specifications of aggregates and asphalt are detected in the mixture production process. The results demonstrate that (1) accuracy produced by the CSW method with WPD features is 4.33% higher than the PCA method with statistical features; (2) SVM classification method optimized by DE algorithm brings an increase in recognition accuracy of identifying different types of mixture production faults produced by different equipment. Compared to other available methods, the proposed algorithm has a very outstanding detection performance.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {10235–10249},
numpages = {15},
keywords = {differential evolution (DE), support vector machine (SVM), wavelet packet decomposition (WPD) features, fault detection, Mixture production process}
}

@article{10.1007/s10664-014-9346-4,
author = {Ryu, Duksan and Choi, Okjoo and Baik, Jongmoon},
title = {Value-cognitive boosting with a support vector machine for cross-project defect prediction},
year = {2016},
issue_date = {February  2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-014-9346-4},
doi = {10.1007/s10664-014-9346-4},
abstract = {It is well-known that software defect prediction is one of the most important tasks for software quality improvement. The use of defect predictors allows test engineers to focus on defective modules. Thereby testing resources can be allocated effectively and the quality assurance costs can be reduced. For within-project defect prediction (WPDP), there should be sufficient data within a company to train any prediction model. Without such local data, cross-project defect prediction (CPDP) is feasible since it uses data collected from similar projects in other companies. Software defect datasets have the class imbalance problem increasing the difficulty for the learner to predict defects. In addition, the impact of imbalanced data on the real performance of models can be hidden by the performance measures chosen. We investigate if the class imbalance learning can be beneficial for CPDP. In our approach, the asymmetric misclassification cost and the similarity weights obtained from distributional characteristics are closely associated to guide the appropriate resampling mechanism. We performed the effect size A-statistics test to evaluate the magnitude of the improvement. For the statistical significant test, we used Wilcoxon rank-sum test. The experimental results show that our approach can provide higher prediction performance than both the existing CPDP technique and the existing class imbalance technique.},
journal = {Empirical Softw. Engg.},
month = feb,
pages = {43–71},
numpages = {29},
keywords = {Transfer learning, Cross-project defect prediction, Class imbalance, Boosting}
}

@article{10.1007/s11128-021-03292-w,
author = {Kheirandish, Davar and Haghparast, Majid and Reshadi, Midia and Hosseinzadeh, Mehdi},
title = {Efficient techniques for fault detection and location of multiple controlled Toffoli-based reversible circuit},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {20},
number = {11},
issn = {1570-0755},
url = {https://doi.org/10.1007/s11128-021-03292-w},
doi = {10.1007/s11128-021-03292-w},
abstract = {It is very important to detect and correct faults for ensuring the validity and reliability of these circuits. In this regard, a comparative study with related existing techniques is undertaken. Two techniques to achieve the testability of reversible circuits are introduced that have been improved in terms of quantum cost and fault coverage rate. Considering this aspect, the main focus of these techniques is on the efficient detection and location of faults with 100% accuracy. These techniques for fault detection in reversible circuit design, in addition to being able to produce the correct outputs, can also provide information for fault location that has already been done at a higher cost. Proposed approaches have been successfully tested for all types of SMGF, MMGF, PMGF, RGF, and SBF. In order to verify the functional correctness of the proposed scheme, it also has executed the testing over a reversible full adder circuit, and findings are checked. In the following, the proposed approach of reversible sequential circuits is presented for the first time so far. The cost metrics are evaluated for all the proposed designs and compared the estimated results against some existing design approaches of reversible circuits for better understanding.},
journal = {Quantum Information Processing},
month = nov,
numpages = {31},
keywords = {Cost metrics, Fault models, Test, Fault location, Fault detection, Reversible circuit}
}

@inproceedings{10.1145/3382025.3414976,
author = {Pereira, Juliana Alves and Martin, Hugo and Temple, Paul and Acher, Mathieu},
title = {Machine learning and configurable systems: a gentle introduction},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414976},
doi = {10.1145/3382025.3414976},
abstract = {The goal of this tutorial is to give a gentle introduction to how machine learning can be used to support software product line configuration. This is our second practical tutorial in this trending field. The tutorial is based on a systematic literature review and includes practical tasks (specialization, performance and bug prediction) on real-world systems (Linux, VaryLaTeX, x264). The material is designed for academics and practitioners with basic knowledge in software product lines and machine learning.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {40},
numpages = {1},
keywords = {software product lines, machine learning, configurable systems},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1145/3358528.3358594,
author = {Lu, Guo and Zhongqing, Yu and Jianqi, Yu and Chuang, Liu},
title = {Data Driven Induction Motor Condition Identification and Fault Prediction},
year = {2019},
isbn = {9781450371926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358528.3358594},
doi = {10.1145/3358528.3358594},
abstract = {With the development of technologies such as sensing and the scale of industrial production, the equipment data can be gathered massively. For induction motors, the health data can be collected is sufficient, but the fault data is not easy to obtain. Therefore, the focus of this paper was determined to identify motor operating conditions and predict possible faults based on motor health data. In this case, an induction motor condition model consisting of a state recognizer and adaptive thresholds was proposed. The health data was used for the training of the induction motor condition model, and an improved SOM-FCM Two-Layer clustering method was used to solve the problem of obtaining the motor data without label. Finally, the validity of the model and method was verified by normal motor variable load state identification and rotor broken motor fault prediction, and the accuracy of 97.5% and 90.2% was obtained respectively.},
booktitle = {Proceedings of the 2nd International Conference on Big Data Technologies},
pages = {221–229},
numpages = {9},
keywords = {Two-Layer clustering, Induction Motor, Fault Prediction, Data Driven, Condition Identification},
location = {Jinan, China},
series = {ICBDT '19}
}

@article{10.1007/s11063-013-9327-4,
author = {Obst, Oliver},
title = {Distributed Fault Detection in Sensor Networks using a Recurrent Neural Network},
year = {2014},
issue_date = {December  2014},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {40},
number = {3},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-013-9327-4},
doi = {10.1007/s11063-013-9327-4},
abstract = {In long-term deployments of sensor networks, monitoring the quality of gathered data is a critical issue. Over the time of deployment, sensors are exposed to harsh conditions, causing some of them to fail or to deliver less accurate data. If such a degradation remains undetected, the usefulness of a sensor network can be greatly reduced. We present an approach that learns spatio-temporal correlations between different sensors, and makes use of the learned model to detect anomalous sensors by using distributed computation and only local communication between nodes. We introduce SODESN, a distributed recurrent neural network architecture, and a learning method to train SODESN for fault detection in a distributed scenario. Our approach is evaluated using data from a real-world sensor-network deployment, and shows good results even with imperfect link qualities and a number of simultaneous faults.},
journal = {Neural Process. Lett.},
month = dec,
pages = {261–273},
numpages = {13},
keywords = {Sensor networks, Reservoir computing, Neural networks, Fault detection}
}

@inproceedings{10.1145/3324884.3415286,
author = {Perera, Anjana},
title = {Using defect prediction to improve the bug detection capability of search-based software testing},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3415286},
doi = {10.1145/3324884.3415286},
abstract = {Automated test generators, such as search based software testing (SBST) techniques, replace the tedious and expensive task of manually writing test cases. SBST techniques are effective at generating tests with high code coverage. However, is high code coverage sufficient to maximise the number of bugs found? We argue that SBST needs to be focused to search for test cases in defective areas rather in non-defective areas of the code in order to maximise the likelihood of discovering the bugs. Defect prediction algorithms give useful information about the bug-prone areas in software. Therefore, we formulate the objective of this thesis: Improve the bug detection capability of SBST by incorporating defect prediction information. To achieve this, we devise two research objectives, i.e., 1) Develop a novel approach (SBSTCL) that allocates time budget to classes based on the likelihood of classes being defective, and 2) Develop a novel strategy (SBSTML) to guide the underlying search algorithm (i.e., genetic algorithm) towards the defective areas in a class. Through empirical evaluation on 434 real reported bugs in the Defects4J dataset, we demonstrate that our novel approach, SBSTCL, is significantly more efficient than the state of the art SBST when they are given a tight time budget in a resource constrained environment.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1170–1174},
numpages = {5},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@article{10.1016/j.eswa.2015.03.013,
author = {\"{O}zt\"{u}rk, Muhammed Maruf and Cavusoglu, Unal and Zengin, Ahmet},
title = {A novel defect prediction method for web pages using k-means++},
year = {2015},
issue_date = {November 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {19},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.03.013},
doi = {10.1016/j.eswa.2015.03.013},
abstract = {Presents a novel defect clustering method.Shed new light to defect prediction methods.Depicts the prominence of k-means++ for software testing.Unveils the density of error rates of web elements. With the increase of the web software complexity, defect detection and prevention have become crucial processes in the software industry. Over the past decades, defect prediction research has reported encouraging results for reducing software product costs. Despite promising results, these researches have hardly been applied to web based systems using clustering algorithms. An appropriate implementation of the clustering in defect prediction may facilitate to estimate defects in a web page source code. One of the widely used clustering algorithms is k-means whose derived versions such as k-means++ show good performance on large-data sets. Here, we present a new defect clustering method using k-means++ for web page source codes. According to the experimental results, almost half of the defects are detected in the middle of web pages. k-means++ is significantly better than the other four clustering algorithms in three criteria on four data set. We also tested our method on four classifiers and the results have shown that after the clustering, Linear Discriminant Analysis is, in general, better than the other three classifiers.},
journal = {Expert Syst. Appl.},
month = nov,
pages = {6496–6506},
numpages = {11},
keywords = {k-means++, Software testing, Fault clustering, Defect prediction}
}

@article{10.1016/j.infsof.2008.04.008,
author = {Chang, Ching-Pao and Chu, Chih-Ping and Yeh, Yu-Fang},
title = {Integrating in-process software defect prediction with association mining to discover defect pattern},
year = {2009},
issue_date = {February, 2009},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {51},
number = {2},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2008.04.008},
doi = {10.1016/j.infsof.2008.04.008},
abstract = {Rather than detecting defects at an early stage to reduce their impact, defect prevention means that defects are prevented from occurring in advance. Causal analysis is a common approach to discover the causes of defects and take corrective actions. However, selecting defects to analyze among large amounts of reported defects is time consuming, and requires significant effort. To address this problem, this study proposes a defect prediction approach where the reported defects and performed actions are utilized to discover the patterns of actions which are likely to cause defects. The approach proposed in this study is adapted from the Action-Based Defect Prediction (ABDP), an approach uses the classification with decision tree technique to build a prediction model, and performs association rule mining on the records of actions and defects. An action is defined as a basic operation used to perform a software project, while a defect is defined as software flaws and can arise at any stage of the software process. The association rule mining finds the maximum rule set with specific minimum support and confidence and thus the discovered knowledge can be utilized to interpret the prediction models and software process behaviors. The discovered patterns then can be applied to predict the defects generated by the subsequent actions and take necessary corrective actions to avoid defects. The proposed defect prediction approach applies association rule mining to discover defect patterns, and multi-interval discretization to handle the continuous attributes of actions. The proposed approach is applied to a business project, giving excellent prediction results and revealing the efficiency of the proposed approach. The main benefit of using this approach is that the discovered defect patterns can be used to evaluate subsequent actions for in-process projects, and reduce variance of the reported data resulting from different projects. Additionally, the discovered patterns can be used in causal analysis to identify the causes of defects for software process improvement.},
journal = {Inf. Softw. Technol.},
month = feb,
pages = {375–384},
numpages = {10},
keywords = {Software defect prediction, Multi-interval discretization, Association rule}
}

@inproceedings{10.1109/CSMR.2013.43,
author = {Xia, Xin and Lo, David and Wang, Xinyu and Yang, Xiaohu and Li, Shanping and Sun, Jianling},
title = {A Comparative Study of Supervised Learning Algorithms for Re-opened Bug Prediction},
year = {2013},
isbn = {9780769549484},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CSMR.2013.43},
doi = {10.1109/CSMR.2013.43},
abstract = {Bug fixing is a time-consuming and costly job which is performed in the whole life cycle of software development and maintenance. For many systems, bugs are managed in bug management systems such as Bugzilla. Generally, the status of a typical bug report in Bugzilla changes from new to assigned, verified and closed. However, some bugs have to be reopened. Reopened bugs increase the software development and maintenance cost, increase the workload of bug fixers, and might even delay the future delivery of a software. Only a few studies investigate the phenomenon of reopened bug reports. In this paper, we evaluate the effectiveness of various supervised learning algorithms to predict if a bug report would be reopened. We choose 7 state-of-the-art classical supervised learning algorithm in machine learning literature, i.e., kNN, SVM, Simple Logistic, Bayesian Network, Decision Table, CART and LWL, and 3 ensemble learning algorithms, i.e., AdaBoost, Bagging and Random Forest, and evaluate their performance in predicting reopened bug reports. The experiment results show that among the 10 algorithms, Bagging and Decision Table (IDTM) achieve the best performance. They achieve accuracy scores of 92.91% and 92.80%, respectively, and reopened bug reports F-Measure scores of 0.735 and 0.732, respectively. These results improve the reopened bug reports F-Measure of the state-of-the-art approaches proposed by Shihab et al. by up to 23.53%.},
booktitle = {Proceedings of the 2013 17th European Conference on Software Maintenance and Reengineering},
pages = {331–334},
numpages = {4},
keywords = {supervised learning algorithms, reopened reports, comparative study, classification, bug reports},
series = {CSMR '13}
}

@inproceedings{10.1145/3127005.3127015,
author = {Amasaki, Sousuke},
title = {On Applicability of Cross-project Defect Prediction Method for Multi-Versions Projects},
year = {2017},
isbn = {9781450353052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127005.3127015},
doi = {10.1145/3127005.3127015},
abstract = {Context: Cross-project defect prediction (CPDP) research has been popular, and many CPDP methods have been proposed so far. As the straightforward use of Cross-project (CP) data was useless, those methods filter, weigh, and adapt CP data for a target project data. This idea would also be useful for a project having past defect data. Objective: To evaluate the applicability of CPDP methods for multi-versions projects. The evaluation focused on the relationship between the performance change and the proximity of older release data to a target project. Method: We conducted experiments that compared the predictive performance between using older version data with and without Nearest Neighbor (NN) filter, a classic CPDP method. Results: NN-filter could not make clear differences in predictive performance. Conclusions: NN-filter was not helpful for improving predictive performance with older release data.},
booktitle = {Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {93–96},
numpages = {4},
keywords = {Cross-Project, Defect Prediction, Experiment},
location = {Toronto, Canada},
series = {PROMISE}
}

@inproceedings{10.1145/3383219.3383243,
author = {Pham, Van and Lokan, Chris and Kasmarik, Kathryn},
title = {A Better Set of Object-Oriented Design Metrics for Within-Project Defect Prediction},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383243},
doi = {10.1145/3383219.3383243},
abstract = {Background: Using design metrics to predict fault-prone elements of a software design can help to focus attention on classes that need redesign and more extensive testing. However, some design metrics have been pointed out to be theoretically invalid, and the usefulness of some metrics is questioned.Aim: To identify a set of object-oriented metrics that are theoretically valid, and useful for identifying fault-prone classes in a design.Method: Drawing on four well-known sets of design metrics (CK, LK, MOOD and QMOOD), we propose a consolidated set of metrics that covers many aspects of object-oriented software design. We conduct two experiments, first using a single large system and then considering successive releases of that system, to compare the usefulness of the consolidated set with the other four sets for within-project prediction of fault-prone classes.Results: Both experiments suggest the consolidated set is effective at identifying fault-prone classes, outperforming the other metric sets (though at a cost of more false alarms).Conclusion: This paper adds to knowledge about the usefulness of existing sets of design metrics for within-project defect prediction, and identifies a consolidated set of metrics that is more effective than the existing sets at identifying fault-prone classes.},
booktitle = {Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering},
pages = {230–239},
numpages = {10},
keywords = {fault-proneness prediction, design metrics, Object-oriented software design},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1109/IECON.2019.8927129,
author = {Ra\c{c}\~{o}es, Hugo D. L. and Ferreira, Fernando J. T. E. and Pires, Jo\~{a}o M. and Dam\'{a}sio, Carlos V.},
title = {Application of Different Machine Learning Strategies for Current- and Vibration-based Motor Bearing Fault Detection in Induction Motors},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON.2019.8927129},
doi = {10.1109/IECON.2019.8927129},
abstract = {In this paper, the application of different machine learning strategies for current- and vibration-based detection of bearing faults in squirrel-cage induction motors is studied. This study compares several feature extraction strategies such as a statistical and spectral analysis of vibration, a statistical analysis of the Hilbert's Transform envelope of vibration, an analysis of the currents deviation to a perfect sinusoid and a statistical and spectral analysis of the Park's Vector Modulus, with its performances being evaluated with the Support Vector Machine, Artificial Neural Network, Random Forests and Extreme Gradient Boosting algorithms. A comparison of results obtained using sampling frequencies of 0.8 kHz, 1 kHz, 2 kHz, 5 kHz and 10 kHz and analysis periods between 20 ms and 100 ms is made and promising models are achieved even with the lowest sampling frequencies.},
booktitle = {IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society},
pages = {68–73},
numpages = {6},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/2851613.2851788,
author = {das D\^{o}res, Silvia N. and Alves, Luciano and Ruiz, Duncan D. and Barros, Rodrigo C.},
title = {A meta-learning framework for algorithm recommendation in software fault prediction},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851788},
doi = {10.1145/2851613.2851788},
abstract = {Software fault prediction is a significant part of software quality assurance and it is commonly used to detect faulty software modules based on software measurement data. Several machine learning based approaches have been proposed for generating predictive models from collected data, although none has become standard given the specificities of each software project. Hence, we believe that recommending the best algorithm for each project is much more important and useful than developing a single algorithm for being used in any project. For achieving that goal, we propose in this paper a novel framework for recommending machine learning algorithms that is capable of automatically identifying the most suitable algorithm according to the software project that is being considered. Our solution, namely SFP-MLF, makes use of the meta-learning paradigm in order to learn the best learner for a particular project. Results show that the SFP-MLF framework provides both the best single algorithm recommendation and also the best ranking recommendation for the software fault prediction problem.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1486–1491},
numpages = {6},
keywords = {algorithm recommendation, machine learning, meta-learning, software fault prediction, software quality},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1109/SMC52423.2021.9659069,
author = {Russo, Luigi and Sarda, Kisan and Glielmo, Luigi and Acernese, Antonio},
title = {Fault Detection and Diagnosis in Steel Industry: a One Class-Support Vector Machine Approach},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC52423.2021.9659069},
doi = {10.1109/SMC52423.2021.9659069},
abstract = {Complexity of manufacturing systems and variability in anomalous operations make fault detection and diagnosis in industrial systems a challenging task. In steel industries characterized by high temperatures and pressures, elevated production speeds, and intense throughput, the early diagnosis of an incoming fault is highly relevant for both safety and economic reasons. However, expensive preventive maintenance and early substitution of equipment are largely adopted, hence strongly limiting the availability of data related to fault events and the applicability of standard machine learning methods. In this work, we present a one class-support vector machine (OC-SVM) approach to early detect anomalies in steel making plants; we validate our method using production data gathered from a steel making industry placed in the South of Italy and compare performance with a multivariate statistical method recently designed for the fault detection of the same plant. The study revealed that OC-SVM outperforms the statistical method, and also is able to predict breakdowns.},
booktitle = {2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
pages = {2304–2309},
numpages = {6},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/3453688.3461750,
author = {Aramoon, Omid and Qu, Gang},
title = {Provably Accurate Memory Fault Detection Method for Deep Neural Networks},
year = {2021},
isbn = {9781450383936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3453688.3461750},
doi = {10.1145/3453688.3461750},
abstract = {Deep Neural Networks (DNNs) have been widely deployed in real-world systems, many of which have strict safety constraints. Soft errors on memory acceleration platforms for DNNs can degrade their inference accuracy and result in silent data corruption, which can have severe consequences in safety-critical applications. No doubt to say, efficient and effective techniques to detect and mitigate memory faults are needed. In this paper, we propose a novel methodology to diagnose the presence of faults in the memory of DNN accelerators. Our method queries the protected DNN with a set of specially crafted test cases that can accurately reveal if model parameters stored in the hardware are faulty. We provide a theoretical guarantee for the performance of our method and conduct systematic proof-of-concept experiments by simulating memory faults on computer vision models. Our empirical evaluations corroborate the effectiveness and efficiency of our approach. Detecting faults with our method requires simple decision-based access to the inference capability of the DNN, and does not require any additional functionality from the accelerator, which makes our method ideal for legacy systems.},
booktitle = {Proceedings of the 2021 Great Lakes Symposium on VLSI},
pages = {443–448},
numpages = {6},
keywords = {fault detection, neural networks},
location = {Virtual Event, USA},
series = {GLSVLSI '21}
}

@inproceedings{10.1145/3318216.3363305,
author = {Soualhia, Mbarka and Fu, Chunyan and Khomh, Foutse},
title = {Infrastructure fault detection and prediction in edge cloud environments},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363305},
doi = {10.1145/3318216.3363305},
abstract = {As an emerging 5G system component, edge cloud becomes one of the key enablers to provide services such us mission critical, IoT and content delivery applications. However, because of limited fail-over mechanisms in edge clouds, faults (e.g., CPU or HDD faults) are highly undesirable. When infrastructure faults occur in edge clouds, they can accumulate and propagate; leading to severe degradation of system and application performance. It is therefore crucial to identify these faults early on and mitigate them. In this paper, we propose a framework to detect and predict several faults at infrastructure-level of edge clouds using supervised machine learning and statistical techniques. The proposed framework is composed of three main components responsible for: (1) data pre-processing, (2) fault detection, and (3) fault prediction. The results show that the framework allows to timely detect and predict several faults online. For instance, using Support Vector Machine (SVM), Random Forest(RF) and Neural Network(NN)models, the framework is able to detect non-fatal CPU and HDD overload faults with an F1 score of more than 95%. For the prediction, the Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM) have comparable accuracy at 96.47% vs. 96.88% for CPU-overload fault and 85.52% vs. 88.73% for network fault.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {222–235},
numpages = {14},
location = {Arlington, Virginia},
series = {SEC '19}
}

@inproceedings{10.1145/2875913.2875922,
author = {Tang, Hao and Lan, Tian and Hao, Dan and Zhang, Lu},
title = {Enhancing Defect Prediction with Static Defect Analysis},
year = {2015},
isbn = {9781450336413},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2875913.2875922},
doi = {10.1145/2875913.2875922},
abstract = {In the software development process, how to develop better software at lower cost has been a major issue of concern. One way that helps is to find more defects as early as possible, on which defect prediction can provide effective guidance. The most popular defect prediction technique is to build defect prediction models based on machine learning. To improve the performance of defect prediction model, selecting appropriate features is critical. On the other hand, static analysis is usually used in defect detection. As static defect analyzers detects defects by matching some well-defined "defect patterns", its result is useful for locating defects. However, defect prediction and static defect analysis are supposed to be two parallel areas due to the differences in research motivation, solution and granularity.In this paper, we present a possible approach to improve the performance of defect prediction with the help of static analysis techniques. Specifically, we present to extract features based on defect patterns from static defect analyzers to improve the performance of defect prediction models. Based on this approach, we implemented a defect prediction tool and set up experiments to measure the effect of the features.},
booktitle = {Proceedings of the 7th Asia-Pacific Symposium on Internetware},
pages = {43–51},
numpages = {9},
keywords = {static defect analyzer, predictive model, machine learning, defect pattern, code feature, Defect},
location = {Wuhan, China},
series = {Internetware '15}
}

@article{10.1016/j.neunet.2016.01.003,
author = {Amozegar, M. and Khorasani, K.},
title = {An ensemble of dynamic neural network identifiers for fault detection and isolation of gas turbine engines},
year = {2016},
issue_date = {April 2016},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {76},
number = {C},
issn = {0893-6080},
url = {https://doi.org/10.1016/j.neunet.2016.01.003},
doi = {10.1016/j.neunet.2016.01.003},
abstract = {In this paper, a new approach for Fault Detection and Isolation (FDI) of gas turbine engines is proposed by developing an ensemble of dynamic neural network identifiers. For health monitoring of the gas turbine engine, its dynamics is first identified by constructing three separate or individual dynamic neural network architectures. Specifically, a dynamic multi-layer perceptron (MLP), a dynamic radial-basis function (RBF) neural network, and a dynamic support vector machine (SVM) are trained to individually identify and represent the gas turbine engine dynamics. Next, three ensemble-based techniques are developed to represent the gas turbine engine dynamics, namely, two heterogeneous ensemble models and one homogeneous ensemble model. It is first shown that all ensemble approaches do significantly improve the overall performance and accuracy of the developed system identification scheme when compared to each of the stand-alone solutions. The best selected stand-alone model (i.e., the dynamic RBF network) and the best selected ensemble architecture (i.e., the heterogeneous ensemble) in terms of their performances in achieving an accurate system identification are then selected for solving the FDI task. The required residual signals are generated by using both a single model-based solution and an ensemble-based solution under various gas turbine engine health conditions. Our extensive simulation studies demonstrate that the fault detection and isolation task achieved by using the residuals that are obtained from the dynamic ensemble scheme results in a significantly more accurate and reliable performance as illustrated through detailed quantitative confusion matrix analysis and comparative studies.},
journal = {Neural Netw.},
month = apr,
pages = {106–121},
numpages = {16},
keywords = {System identification, Gas turbine engines, Fault detection and isolation, Ensemble learning, Dynamic neural networks}
}

@inproceedings{10.1145/3340482.3342743,
author = {Foidl, Harald and Felderer, Michael},
title = {Risk-based data validation in machine learning-based software systems},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340482.3342743},
doi = {10.1145/3340482.3342743},
abstract = {Data validation is an essential requirement to ensure the reliability and quality of Machine Learning-based Software Systems. However, an exhaustive validation of all data fed to these systems (i.e. up to several thousand features) is practically unfeasible. In addition, there has been little discussion about methods that support software engineers of such systems in determining how thorough to validate each feature (i.e. data validation rigor). Therefore, this paper presents a conceptual data validation approach that prioritizes features based on their estimated risk of poor data quality. The risk of poor data quality is determined by the probability that a feature is of low data quality and the impact of this low (data) quality feature on the result of the machine learning model. Three criteria are presented to estimate the probability of low data quality (Data Source Quality, Data Smells, Data Pipeline Quality). To determine the impact of low (data) quality features, the importance of features according to the performance of the machine learning model (i.e. Feature Importance) is utilized. The presented approach provides decision support (i.e. data validation prioritization and rigor) for software engineers during the implementation of data validation techniques in the course of deploying a trained machine learning model and its software stack.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
pages = {13–18},
numpages = {6},
keywords = {Risk-based Testing, Machine Learning, Data Validation},
location = {Tallinn, Estonia},
series = {MaLTeSQuE 2019}
}

@article{10.1007/s10270-021-00913-x,
author = {Nguyen, Phuong T. and Di&nbsp;Rocco, Juri and Iovino, Ludovico and Di&nbsp;Ruscio, Davide and Pierantonio, Alfonso},
title = {Evaluation of a machine learning classifier for metamodels},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {6},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-021-00913-x},
doi = {10.1007/s10270-021-00913-x},
abstract = {Modeling is a ubiquitous activity in the process of software development. In recent years, such an activity has reached a high degree of intricacy, guided by the heterogeneity of the components, data sources, and tasks. The democratized use of models has led to the necessity for suitable machinery for mining modeling repositories. Among others, the classification of metamodels into independent categories facilitates personalized searches by boosting the visibility of metamodels. Nevertheless, the manual classification of metamodels is not only a tedious but also an error-prone task. According to our observation, misclassification is the norm which leads to a reduction in reachability as well as reusability of metamodels. Handling such complexity requires suitable tooling to leverage raw data into practical knowledge that can help modelers with their daily tasks. In our previous work, we proposed AURORA as a machine learning classifier for metamodel repositories. In this paper, we present a thorough evaluation of the system by taking into consideration different settings as well as evaluation metrics. More importantly, we improve the original AURORA tool by changing its internal design. Experimental results demonstrate that the proposed amendment is beneficial to the classification of metamodels. We also compared our approach with two baseline algorithms, namely gradient boosted decision tree and support vector machines. Eventually, we see that AURORA outperforms the baselines with respect to various quality metrics.},
journal = {Softw. Syst. Model.},
month = dec,
pages = {1797–1821},
numpages = {25},
keywords = {SVM, GBDT, Neural networks, Machine learning, Model-driven engineering}
}

@article{10.1016/j.neucom.2021.03.074,
author = {Feng, Yuan and Wang, Hexiang and Yang, Han and Wang, Fangbo},
title = {Time-continuous energy-conservation neural network for structural dynamics analysis},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {456},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2021.03.074},
doi = {10.1016/j.neucom.2021.03.074},
journal = {Neurocomput.},
month = oct,
pages = {450–460},
numpages = {11},
keywords = {Time-continuous, Energy-conservation, Structural dynamics, Neural network}
}

@inproceedings{10.5555/3507788.3507798,
author = {Khan, Md Asif and Azim, Akramul and Liscano, Ramiro and Smith, Kevin and Chang, Yee-Kang and Garcon, Sylvain and Tauseef, Qasim},
title = {Failure prediction using machine learning in IBM WebSphere liberty continuous integration environment},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {The growing complexity and dependencies of software have increased the importance of testing to ensure that frequent changes do not adversely affect existing functionality. Moreover, continuous integration comes with unique challenges associated with maintaining a stable build environment. Several studies have shown that the testing environment becomes more efficient with proper test case prioritization techniques. However, an application's dynamic behavior makes it challenging to derive test case prioritization techniques for achieving optimal results. With the advance of machine learning, the context of an application execution can be analyzed to select and prioritize test suites more efficiently.Test suite prioritization techniques aim to reorder test suites' execution to deliver high quality, maintainable software at lower costs to meet specific objectives such as revealing failures earlier. The state-of-the-art techniques on test prioritization in a continuous integration environment focus on relatively small, single-language, unit-tested projects. This paper compares and analyzes Machine learning-based test suite prioritization technique on two large-scale dataset collected from a continuous integration environment Google and IBM respectively. We optimize hyperparameters and report on experiments' findings by using different machine learning algorithms for test suite prioritization. Our optimized algorithms prioritize test suites with 93% accuracy on average and require 20% fewer test suites to detect 80% of the failures than the test suites prioritized randomly.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {63–72},
numpages = {10},
keywords = {test prioritization, machine learning, continuous integration, CI},
location = {Toronto, Canada},
series = {CASCON '21}
}

@article{10.1016/j.cogsys.2019.12.005,
author = {Kaliyar, Rohit Kumar and Goswami, Anurag and Narang, Pratik and Sinha, Soumendu},
title = {FNDNet – A deep convolutional neural network for fake news detection},
year = {2020},
issue_date = {Jun 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {61},
number = {C},
issn = {1389-0417},
url = {https://doi.org/10.1016/j.cogsys.2019.12.005},
doi = {10.1016/j.cogsys.2019.12.005},
journal = {Cogn. Syst. Res.},
month = jun,
pages = {32–44},
numpages = {13},
keywords = {Neural network, Deep learning, Machine learning, Social media, Fake news}
}

@article{10.1007/s10845-021-01810-2,
author = {Kim, Youngju and Lee, Hoyeop and Kim, Chang Ouk},
title = {A variational autoencoder for a semiconductor fault detection model robust to process drift due to incomplete maintenance},
year = {2021},
issue_date = {Feb 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {34},
number = {2},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01810-2},
doi = {10.1007/s10845-021-01810-2},
abstract = {In the semiconductor manufacturing field, few studies on fault detection (FD) models have considered process drift due to incomplete maintenance. Process drift refers to the shift in sensor measurements over time due to tool aging, and it leads to defective production when it is severe. Tool maintenance is conducted regularly to prevent defects. However, when it is performed improperly, tool aging accelerates, and the drift increases. In this paper, we propose an FD model robust to process drift by modeling process drift with a variational autoencoder (VAE). Because process drift is characterized by time-varying information, the proposed model encodes some time-varying information through separate hidden layers. By adopting a strategy that combines information separately encoded in a feature vector, the proposed model successfully models process drift. With actual chemical vapor deposition process data, we were able to generate many virtual datasets that incorporate process drift with various drift characteristics, such as patterns, degrees, and speeds. The proposed model outperformed four comparison FD methods on these datasets.},
journal = {J. Intell. Manuf.},
month = jul,
pages = {529–540},
numpages = {12},
keywords = {Deep learning, Variational autoencoder, Incomplete maintenance, Fault detection, Process drift}
}

@inproceedings{10.1145/3472674.3473978,
author = {De Stefano, Manuel and Pecorelli, Fabiano and Palomba, Fabio and De Lucia, Andrea},
title = {Comparing within- and cross-project machine learning algorithms for code smell detection},
year = {2021},
isbn = {9781450386258},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472674.3473978},
doi = {10.1145/3472674.3473978},
abstract = {Code smells represent a well-known problem in software engineering, since they are a notorious cause of loss of comprehensibility and maintainability. The most recent efforts in devising automatic machine learning-based code smell detection techniques have achieved unsatisfying results so far. This could be explained by the fact that all these approaches follow a within-project classification, i.e. training and test data are taken from the same source project, which combined with the imbalanced nature of the problem, produces datasets with a very low number of instances belonging to the minority class (i.e. smelly instances). In this paper, we propose a cross-project machine learning approach and compare its performance with a within-project alternative. The core idea is to use transfer learning to increase the overall number of smelly instances in the training datasets. Our results have shown that cross-project classification provides very similar performance with respect to within-project. Despite this finding does not yet provide a step forward in increasing the performance of ML techniques for code smell detection, it sets the basis for further investigations.},
booktitle = {Proceedings of the 5th International Workshop on Machine Learning Techniques for Software Quality Evolution},
pages = {1–6},
numpages = {6},
keywords = {Transfer Learning, Empirical Software Engineering, Code smells},
location = {Athens, Greece},
series = {MaLTESQuE 2021}
}

@inproceedings{10.1145/3443467.3443842,
author = {Zhou, Jian and Peng, Xueyan and Li, Long},
title = {Data-driven Key Features Selection for Fault Detection in a Complex System},
year = {2021},
isbn = {9781450387811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3443467.3443842},
doi = {10.1145/3443467.3443842},
abstract = {Fault detection is a difficult but important problem for a complex system. This paper presents a fault detection method based on data-driven key feature selection for the complex system abbreviated as FD-DKFS. By regarding the observable parameters as original features, FD-DKFS first finds the missing correlations among original features and constructs potentially useful features for fault detection. Next, FD-DKFS provides a filter feature selection method to find the best feature subset for fault detection. Then, these selected features are used to detect the fault in a certain complex system with conventional classifiers. Compared with the other methods, the results of the experiment show that the proposed method is more accurate for fault detection in the complex system.},
booktitle = {Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering},
pages = {717–722},
numpages = {6},
keywords = {Fault detection, complex system, feature construction, feature selection},
location = {Xiamen, China},
series = {EITCE '20}
}

@article{10.1155/2019/4825787,
author = {Rajamany, Gayatridevi and Srinivasan, Sekar and Rajamany, Krishnan and Natarajan, Ramesh K. and Lidozzi, Alessandro},
title = {Induction Motor Stator Interturn Short Circuit Fault Detection in Accordance with Line Current Sequence Components Using Artificial Neural Network},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {2090-0147},
url = {https://doi.org/10.1155/2019/4825787},
doi = {10.1155/2019/4825787},
abstract = {The intention of fault detection is to detect the fault at the beginning stage and shut off the machine immediately to avoid motor failure due to the large fault current. In this work, an online fault diagnosis of stator interturn fault of a three-phase induction motor based on the concept of symmetrical components is presented. A mathematical model of an induction motor with turn fault is developed to interpret machine performance under fault. A Simulink model of a three-phase induction motor with stator interturn fault is created for extraction of sequence components of current and voltage. The negative sequence current can provide a decisive and rapid monitoring technique to detect stator interturn short circuit fault of the induction motor. The per unit change in negative sequence current with positive sequence current is the main fault indicator which is imported to neural network architecture. The output of the feedforward backpropagation neural network classifies the short circuit fault level of stator winding.},
journal = {JECE},
month = jan,
numpages = {11}
}

@inproceedings{10.1145/3416505.3423562,
author = {Steinhauer, Martin and Palomba, Fabio},
title = {Speeding up the data extraction of machine learning approaches: a distributed framework},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423562},
doi = {10.1145/3416505.3423562},
abstract = {In the last decade, mining software repositories (MSR) has become one of the most important sources to feed machine learning models. Especially open-source projects on platforms like GitHub are providing a tremendous amount of data and make them easily accessible. Nevertheless, there is still a lack of standardized pipelines to extract data in an automated and fast way. Even though several frameworks and tools exist which can fulfill specific tasks or parts of the data extraction process, none of them allow neither building an automated mining pipeline nor the possibility for full parallelization. As a consequence, researchers interested in using mining software repositories to feed machine learning models are often forced to re-implement commonly used tasks leading to additional development time and libraries may not be integrated optimally.  This preliminary study aims to demonstrate current limitations of existing tools and Git itself which are threatening the prospects of standardization and parallelization. We also introduce the multi-dimensionality aspects of a Git repository and how they affect the computation time. Finally, as a proof of concept, we define an exemplary pipeline for predicting refactoring operations, assessing its performance. Finally, we discuss the limitations of the pipeline and further optimizations to be done.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {13–18},
numpages = {6},
keywords = {Mining Software Repositories, Machine Learning Pipelines, Distributed Mining},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@inproceedings{10.1145/2695664.2695959,
author = {Xuan, Xiao and Lo, David and Xia, Xin and Tian, Yuan},
title = {Evaluating defect prediction approaches using a massive set of metrics: an empirical study},
year = {2015},
isbn = {9781450331968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2695664.2695959},
doi = {10.1145/2695664.2695959},
abstract = {To evaluate the performance of a within-project defect prediction approach, people normally use precision, recall, and F-measure scores. However, in machine learning literature, there are a large number of evaluation metrics to evaluate the performance of an algorithm, (e.g., Matthews Correlation Coefficient, G-means, etc.), and these metrics evaluate an approach from different aspects. In this paper, we investigate the performance of within-project defect prediction approaches on a large number of evaluation metrics. We choose 6 state-of-the-art approaches including naive Bayes, decision tree, logistic regression, kNN, random forest and Bayesian network which are widely used in defect prediction literature. And we evaluate these 6 approaches on 14 evaluation metrics (e.g., G-mean, F-measure, balance, MCC, J-coefficient, and AUC). Our goal is to explore a practical and sophisticated way for evaluating the prediction approaches comprehensively. We evaluate the performance of defect prediction approaches on 10 defect datasets from PROMISE repository. The results show that Bayesian network achieves a noteworthy performance. It achieves the best recall, FN-R, G-mean1 and balance on 9 out of the 10 datasets, and F-measure and J-coefficient on 7 out of the 10 datasets.},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
pages = {1644–1647},
numpages = {4},
keywords = {machine learning, evaluation metric, defect prediction},
location = {Salamanca, Spain},
series = {SAC '15}
}

@article{10.1145/3453444,
author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
title = {Assuring the Machine Learning Lifecycle: Desiderata, Methods, and Challenges},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3453444},
doi = {10.1145/3453444},
abstract = {Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic, and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence, and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our article provides a comprehensive survey of the state of the art in the assurance of ML, i.e., in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle, i.e., of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The article begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {111},
numpages = {39},
keywords = {safety-critical systems, machine learning workflow, assurance evidence, assurance, Machine learning lifecycle}
}

@inproceedings{10.1145/2499393.2499395,
author = {Herbold, Steffen},
title = {Training data selection for cross-project defect prediction},
year = {2013},
isbn = {9781450320160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2499393.2499395},
doi = {10.1145/2499393.2499395},
abstract = {Software defect prediction has been a popular research topic in recent years and is considered as a means for the optimization of quality assurance activities. Defect prediction can be done in a within-project or a cross-project scenario. The within-project scenario produces results with a very high quality, but requires historic data of the project, which is often not available. For the cross-project prediction, the data availability is not an issue as data from other projects is readily available, e.g., in repositories like PROMISE. However, the quality of the defect prediction results is too low for practical use. Recent research showed that the selection of appropriate training data can improve the quality of cross-project defect predictions. In this paper, we propose distance-based strategies for the selection of training data based on distributional characteristics of the available data. We evaluate the proposed strategies in a large case study with 44 data sets obtained from 14 open source projects. Our results show that our training data selection strategy improves the achieved success rate of cross-project defect predictions significantly. However, the quality of the results still cannot compete with within-project defect prediction.},
booktitle = {Proceedings of the 9th International Conference on Predictive Models in Software Engineering},
articleno = {6},
numpages = {10},
keywords = {cross-project prediction, defect-prediction, machine learning},
location = {Baltimore, Maryland, USA},
series = {PROMISE '13}
}

@inproceedings{10.1007/978-3-642-39068-5_56,
author = {Nawaz, Javeria Muhammad and Arshad, Muhammad Zeeshan and Hong, Sang Jeen},
title = {Time series fault prediction in semiconductor equipment using recurrent neural network},
year = {2013},
isbn = {9783642390678},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-39068-5_56},
doi = {10.1007/978-3-642-39068-5_56},
abstract = {This paper presents a model of Elman recurrent neural network (ERNN) for time series fault prediction in semiconductor etch equipment. ERNN maintains a copy of previous state of the input in its context units, as well as the current state of the input. Derivative dynamic time warping (DDTW) method is also discussed for the synchronization of time series data set acquired from plasma etcher. For each parameter of the data, the best ERNN structure was selected and trained using Levenberg Marquardt to generate one-step-ahead prediction for 10 experimental runs. The faulty experimental runs were successfully distinguished from healthy experimental runs with one missed alarm out of ten experimental runs.},
booktitle = {Proceedings of the 10th International Conference on Advances in Neural Networks - Volume Part II},
pages = {463–472},
numpages = {10},
keywords = {time series prediction, recurrent neural network, derivative dynamic time warping},
location = {Dalian, China},
series = {ISNN'13}
}

@article{10.1007/s00542-019-04554-5,
author = {Kang, Jung-Min and Choi, Sung-Hyun and Park, Jung-wan and Park, Kyoung-Su},
title = {Position error prediction using hybrid recurrent neural network algorithm for improvement of pose accuracy of cable driven parallel robots},
year = {2020},
issue_date = {Jan 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {1},
issn = {0946-7076},
url = {https://doi.org/10.1007/s00542-019-04554-5},
doi = {10.1007/s00542-019-04554-5},
abstract = {Because cable-driven parallel robots (CDPRs) have lightweight moving parts, CDPRs have been used in various industrial applications requiring high speeds and accelerations. Especially, CDPRs with polymer cables can achieve higher accelerations and speeds compared to those with steel cables. However, they also have some disadvantages, such as a nonlinear creep, a hysteresis, and a short- and long-term recovery. Because these nonlinear characteristics, the accuracy of CDPRs gets worse and worse. In this study, we proposed a hybrid recurrent neural network (H-RNN) to predict nonlinear characteristics of the cable elongation and to solve the problems associated with CDPRs and apply the real-time control. In the algorithm, the long short-term memory (LSTM) algorithm was used to learn the characteristics of the low-frequency data, and the basic RNN learned the features of the high-frequency data. We also confirmed that the cut-off frequency was determined based on the non-operating frequency related to rest time. Also, it yielded more accurate results because the LSTM has a wider effective frequency range. Finally, the learning process was completed by combining these two algorithms. These results made it possible to predict position errors of CDPRs with high accuracy, in which error varies under both while operating and no operation conditions. The H-RNN had a lower root mean square error than both the optimal RNN and the optimal LSTM, so it was effective for controlling systems that have errors across a range of frequencies.},
journal = {Microsyst. Technol.},
month = jan,
pages = {209–218},
numpages = {10}
}

@article{10.1016/j.infsof.2013.05.002,
author = {Rodriguez, Daniel and Ruiz, Roberto and Riquelme, Jose C. and Harrison, Rachel},
title = {A study of subgroup discovery approaches for defect prediction},
year = {2013},
issue_date = {October, 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {10},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.05.002},
doi = {10.1016/j.infsof.2013.05.002},
abstract = {Context: Although many papers have been published on software defect prediction techniques, machine learning approaches have yet to be fully explored. Objective: In this paper we suggest using a descriptive approach for defect prediction rather than the precise classification techniques that are usually adopted. This allows us to characterise defective modules with simple rules that can easily be applied by practitioners and deliver a practical (or engineering) approach rather than a highly accurate result. Method: We describe two well-known subgroup discovery algorithms, the SD algorithm and the CN2-SD algorithm to obtain rules that identify defect prone modules. The empirical work is performed with publicly available datasets from the Promise repository and object-oriented metrics from an Eclipse repository related to defect prediction. Subgroup discovery algorithms mitigate against characteristics of datasets that hinder the applicability of classification algorithms and so remove the need for preprocessing techniques. Results: The results show that the generated rules can be used to guide testing effort in order to improve the quality of software development projects. Such rules can indicate metrics, their threshold values and relationships between metrics of defective modules. Conclusions: The induced rules are simple to use and easy to understand as they provide a description rather than a complete classification of the whole dataset. Thus this paper represents an engineering approach to defect prediction, i.e., an approach which is useful in practice, easily understandable and can be applied by practitioners.},
journal = {Inf. Softw. Technol.},
month = oct,
pages = {1810–1822},
numpages = {13},
keywords = {Subgroup discovery, Rules, Imbalanced datasets, Defect prediction}
}

@article{10.1016/j.asoc.2019.02.008,
author = {Juneja, Kapil},
title = {A fuzzy-filtered neuro-fuzzy framework for software fault prediction for inter-version and inter-project evaluation},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {77},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2019.02.008},
doi = {10.1016/j.asoc.2019.02.008},
journal = {Appl. Soft Comput.},
month = apr,
pages = {696–713},
numpages = {18},
keywords = {Fuzzy, Classification, Intra project, Inter project, Defect Prediction}
}

@inproceedings{10.23919/INM.2017.7987312,
author = {Ferreira, Vinicius C. and Carrano, Ricardo C. and Silva, Joacir O. and Albuquerque, C\'{e}lio V. N. and Muchaluat-Saade, D\'{e}bora C. and Passos, Diego},
title = {Fault detection and diagnosis for solar-powered Wireless Mesh Networks using machine learning},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/INM.2017.7987312},
doi = {10.23919/INM.2017.7987312},
abstract = {The inherent complexity of Wireless Mesh Networks (WMNs) makes management and configuration tasks difficult, specially for fault detection and diagnosis. In addition, manual inspections are extremely costly and require a highly skilled workforce, thus becoming impractical as the problem scales. To address this issue, this paper proposes a solution that makes use of machine learning techniques for automated fault detection and diagnosis (FDD) on solar-powered Wireless Mesh Networks (WMNs). We have used the Knowledge Discovery in Databases (KDD) methodology and a pre-defined dictionary of failures based on our previous experience with the deployment of WMNs. Thereafter, the problem was solved as a pattern classification problem. Several classification algorithms were evaluated, such as Naive Bayes, Support Vector Machine (SVM), Decision Table, k-Nearest Neighbors (k-NN) and C4.5. The SVM presented the best results, achieving a 90.59% overall accuracy during training and over 85% in validation tests.},
booktitle = {2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM)},
pages = {456–462},
numpages = {7},
location = {Lisbon, Portugal}
}

@article{10.1109/TSE.2008.35,
author = {Lessmann, Stefan and Baesens, Bart and Mues, Christophe and Pietsch, Swantje},
title = {Benchmarking Classification Models for Software Defect Prediction: A Proposed Framework and Novel Findings},
year = {2008},
issue_date = {July 2008},
publisher = {IEEE Press},
volume = {34},
number = {4},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2008.35},
doi = {10.1109/TSE.2008.35},
abstract = {Software defect prediction strives to improve software quality and testing efficiency by constructing predictive classification models from code attributes to enable a timely identification of fault-prone modules. Several classification models have been evaluated for this task. However, due to inconsistent findings regarding the superiority of one classifier over another and the usefulness of metric-based classification in general, more research is needed to improve convergence across studies and further advance confidence in experimental results. We consider three potential sources for bias: comparing classifiers over one or a small number of proprietary datasets, relying on accuracy indicators that are conceptually inappropriate for software defect prediction and cross-study comparisons, and finally, limited use of statisti-cal testing procedures to secure empirical findings. To remedy these problems, a framework for comparative software defect prediction experiments is proposed and applied in a large-scale empirical comparison of 22 classifiers over ten public domain datasets from the NASA Metrics Data repository. Our results indicate that the importance of the particu-lar classification algorithm may have been overestimated in previous research since no significant performance differ-ences could be detected among the top-17 classifiers.},
journal = {IEEE Trans. Softw. Eng.},
month = jul,
pages = {485–496},
numpages = {12},
keywords = {Statistical methods, Formal methods, Data mining, Complexity measures}
}

@inproceedings{10.1007/978-3-319-47955-2_19,
author = {Murillo-Morera, Juan and Castro-Herrera, Carlos and Arroyo, Javier and Fuentes-Fern\'{a}ndez, Rub\'{e}n},
title = {An Empirical Validation of Learning Schemes Using an Automated Genetic Defect Prediction Framework},
year = {2016},
isbn = {978-3-319-47954-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-47955-2_19},
doi = {10.1007/978-3-319-47955-2_19},
abstract = {Today, it is common for software projects to collect measurement data through development processes. With these data, defect prediction software can try to estimate the defect proneness of a software module, with the objective of assisting and guiding software practitioners. With timely and accurate defect predictions, practitioners can focus their limited testing resources on higher risk areas. This paper reports a benchmarking study that uses a genetic algorithm that automatically generates and compares different learning schemes (preprocessing + attribute selection + learning algorithms). Performance of the software development defect prediction models (using AUC, Area Under the Curve) was validated using NASA-MDP and PROMISE data sets. Twelve data sets from NASA-MDP (8) and PROMISE (4) projects were analyzed running a -fold cross-validation. We used a genetic algorithm to select the components of the learning schemes automatically, and to evaluate and report those with the best performance. In all, 864 learning schemes were studied. The most common learning schemes were: data preprocessors: Log and CoxBox + attribute selectors: Backward Elimination, BestFirst and LinearForwardSelection + learning algorithms: NaiveBayes, NaiveBayesSimple, SimpleLogistic, MultilayerPerceptron, Logistic, LogitBoost, BayesNet, and OneR. The genetic algorithm reported steady performance and runtime among data sets, according to statistical analysis.},
booktitle = {Advances in Artificial Intelligence - IBERAMIA 2016: 15th Ibero-American Conference on AI, San Jos\'{e}, Costa Rica, November 23-25, 2016, Proceedings},
pages = {222–234},
numpages = {13},
keywords = {Software quality, Fault prediction models, Genetic algorithms, Learning schemes, Learning algorithms, Machine learning},
location = {San Jos\'{e}, Costa Rica}
}

@inproceedings{10.1007/978-3-030-82136-4_25,
author = {Kerestely, Arpad and Baicoianu, Alexandra and Bocu, Razvan},
title = {A Research Study on Running Machine Learning Algorithms on Big Data with Spark},
year = {2021},
isbn = {978-3-030-82135-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-82136-4_25},
doi = {10.1007/978-3-030-82136-4_25},
abstract = {The design and implementation of proactive fault diagnosis systems concerning the bearings during their manufacturing process requires the selection of robust representation learning techniques, which belong to the broader scope of the machine learning techniques. Particular systems, such as those that are based on machine learning libraries like Scikit-learn, favor the actual processing of the data, while essentially disregarding relevant computational parameters, such as the speed of the data processing, or the consideration of scalability as an important design and implementation feature. This paper describes an integrated machine learning-based data analytics system, which processes the large amounts of data that are generated by the bearings manufacturing processes using a multinode cluster infrastructure. The data analytics system uses an optimally configured and deployed Spark environment. The proposed data analytics system is thoroughly assessed using a large dataset that stores real manufacturing data, which is generated by the respective bearings manufacturing processes. The performance assessment demonstrates that the described approach ensures the timely and scalable processing of the data. This achievement is relevant, as it exceeds the processing capabilities of significant existing data analytics systems.},
booktitle = {Knowledge Science, Engineering and Management: 14th International Conference, KSEM 2021, Tokyo, Japan, August 14–16, 2021, Proceedings, Part I},
pages = {307–318},
numpages = {12},
keywords = {Machine learning, Representation techniques, Fault detection, Spark, High performance computing, Big data},
location = {Tokyo, Japan}
}

@article{10.1016/j.asoc.2021.107638,
author = {Asgari, Sahar and Gupta, Rohit and Puri, Ishwar K. and Zheng, Rong},
title = {A data-driven approach to simultaneous fault detection and diagnosis in data centers},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {110},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107638},
doi = {10.1016/j.asoc.2021.107638},
journal = {Appl. Soft Comput.},
month = oct,
numpages = {17},
keywords = {Gray-box model, Time-series analysis, Classification, Fault diagnosis, Data center}
}

@inproceedings{10.1145/3452940.3453500,
author = {Hong, Xianli and Yang, Yongxia and Wang, Peng and Zhao, Yihan and Di, Ruohai and Dong, Mianmian},
title = {Fault Diagnosis Algorithm of Integrated Navigation Based on D-S Evidence Theory Fuses Neural Network},
year = {2021},
isbn = {9781450388665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452940.3453500},
doi = {10.1145/3452940.3453500},
abstract = {In the field of fault diagnosis technology of integrated navigation, traditional methods require high precision of system model, and the single neural network detection has the defects of misdiagnosis, missed diagnosis and large error rate. This paper presents a fault diagnosis method based on fusion neural network. The algorithm takes the error data as the input of neural network. Firstly, BP neural network and improved dynamic particle swarm optimization (PSO) BP neural network are used for fault diagnosis, then the detection results of these two neural networks are fused by D-S evidence theory, and finally verified by simulation. The experimental results show that the method can effectively reduce the error rate of fault detection and improve the accuracy and reliability of fault detection.},
booktitle = {Proceedings of the 3rd International Conference on Information Technologies and Electrical Engineering},
pages = {388–391},
numpages = {4},
keywords = {Neural Network, Integrated Navigation, Fault Detection, D-S Evidence Theory},
location = {Changde City, Hunan, China},
series = {ICITEE '20}
}

@article{10.1016/j.cie.2019.06.052,
author = {Chen, Chong and Liu, Ying and Kumar, Maneesh and Qin, Jian and Ren, Yunxia},
title = {Energy consumption modelling using deep learning embedded semi-supervised learning},
year = {2019},
issue_date = {Sep 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {135},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2019.06.052},
doi = {10.1016/j.cie.2019.06.052},
journal = {Comput. Ind. Eng.},
month = sep,
pages = {757–765},
numpages = {9},
keywords = {Data mining, Semi-supervised learning, Deep learning, Intelligent manufacturing, Energy modelling}
}

@inproceedings{10.1145/3331453.3360965,
author = {Chen, Shouhong and Kang, Huaiqiang and Ma, Jun and Guo, Ling and Hou, Xingna},
title = {Research on TSV Void Defects Based on Machine Learning},
year = {2019},
isbn = {9781450362948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331453.3360965},
doi = {10.1145/3331453.3360965},
abstract = {With the rapid development of 3D TSV (through silicon via) technology, it is particularly important to improve the yield for TSV fault detection. Aiming at TSV void defects, the paper adopts supervised machine learning method to train S parameters in TSV model with void faults, and carries out classification processing, then predicts the size of void faults through stimulus signal and S parameters. The results show that for spherical void defects detection, the classification accuracy of ELM (Extreme Learning Machine) algorithm and KNN (K-Nearest Neighbor) algorithm is above 85%, while for TSV cylindrical void defects detection, the classification accuracy of ELM algorithm is 96%.},
booktitle = {Proceedings of the 3rd International Conference on Computer Science and Application Engineering},
articleno = {75},
numpages = {4},
keywords = {TSV fault detection, Machine learning, Classification algorithm},
location = {Sanya, China},
series = {CSAE '19}
}

@inproceedings{10.1145/3422392.3422450,
author = {Neri, Hilmer R. and Travassos, Guilherme H.},
title = {Software Quality is Multidimensional: Let's play with Tensors},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422450},
doi = {10.1145/3422392.3422450},
abstract = {In the face of the dynamic nature of modern software systems, the quality of software products must be monitored and assured from different perspectives at the same time and throughout the development cycle. Although different characteristics and subcharacteristics can represent a software product quality, they have been historically studied and observed in a unidimensional way, which restricts the ability to observe the multiple relationships among quality characteristics. There is empirical evidence indicating the multidimensionality of this phenomenon. Therefore, an n-dimensional software quality base model is presented. The fundamentals of tensor algebra provide its basis, which explores the combination of different dimensions and relations of quality (internal, external, and in use) to suggest the level of quality of a software product. Preliminary results of its operationalization are presented to support this proposal.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {126–131},
numpages = {6},
keywords = {Empirical Software Engineering, Release Acceptance, Software Engineering, Software Metric and Measurement, Software Product Quality, Software Quality Model, Tensor},
location = {Natal, Brazil},
series = {SBES '20}
}

@inproceedings{10.1145/3194104.3194110,
author = {Young, Steven and Abdou, Tamer and Bener, Ayse},
title = {A replication study: just-in-time defect prediction with ensemble learning},
year = {2018},
isbn = {9781450357234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194104.3194110},
doi = {10.1145/3194104.3194110},
abstract = {Just-in-time defect prediction, which is also known as change-level defect prediction, can be used to efficiently allocate resources and manage project schedules in the software testing and debugging process. Just-in-time defect prediction can reduce the amount of code to review and simplify the assignment of developers to bug fixes. This paper reports a replicated experiment and an extension comparing the prediction of defect-prone changes using traditional machine learning techniques and ensemble learning. Using datasets from six open source projects, namely Bugzilla, Columba, JDT, Platform, Mozilla, and PostgreSQL we replicate the original approach to verify the results of the original experiment and use them as a basis for comparison for alternatives in the approach. Our results from the replicated experiment are consistent with the original. The original approach uses a combination of data preprocessing and a two-layer ensemble of decision trees. The first layer uses bagging to form multiple random forests. The second layer stacks the forests together with equal weights. Generalizing the approach to allow the use of any arbitrary set of classifiers in the ensemble, optimizing the weights of the classifiers, and allowing additional layers, we apply a new deep ensemble approach, called deep super learner, to test the depth of the original study. The deep super learner achieves statistically significantly better results than the original approach on five of the six projects in predicting defects as measured by F1 score.},
booktitle = {Proceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
pages = {42–47},
numpages = {6},
keywords = {defect prediction, deep learning},
location = {Gothenburg, Sweden},
series = {RAISE '18}
}

@article{10.1504/ijics.2020.105155,
author = {Pinto, Joey and Jain, Pooja and Kumar, Tapan},
title = {Fault prediction for distributed computing Hadoop clusters using real-time higher order differential inputs to SVM: Zedacross},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {12},
number = {2–3},
issn = {1744-1765},
url = {https://doi.org/10.1504/ijics.2020.105155},
doi = {10.1504/ijics.2020.105155},
abstract = {Hadoop distributed computing clusters are used worldwide for high-performance computations. Often various hardware and software faults occur, leading to both data and computation time losses. This paper proposes the usage of a fault prediction software called 'Zedacross' which uses machine learning principles combined with cluster monitoring tools. Firstly, the paper suggests a model that uses the resource usage statistics of a normally functioning Hadoop cluster to create a machine learning model that can then be used to predict and detect faults in real time. Secondly, the paper explains the novel idea of using higher order differentials as inputs to SVM for highly accurate fault predictions. Predictions of system faults by observing system resource usage statistics in real-time with minimum delay will play a vital role in deciding the need for job rescheduling tasks or even dynamic up-scaling of the cluster. To demonstrate the effectiveness of the design a Java utility was built to perform cluster fault monitoring. The results obtained after running the system on various test cases demonstrate that the proposed method is accurate and effective.},
journal = {Int. J. Inf. Comput. Secur.},
month = jan,
pages = {181–198},
numpages = {17},
keywords = {SVM, higher order differential, Hadoop, Ganglia, fault prediction}
}

@article{10.1007/s10619-021-07331-4,
author = {Srinivasan, R. and Subalalitha, C. N.},
title = {Sentimental analysis from imbalanced code-mixed data using machine learning approaches},
year = {2021},
issue_date = {Jun 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {41},
number = {1},
issn = {0926-8782},
url = {https://doi.org/10.1007/s10619-021-07331-4},
doi = {10.1007/s10619-021-07331-4},
abstract = {Knowledge discovery from various perspectives has become a crucial asset in almost all fields. Sentimental analysis is a classification task used to classify the sentence based on the meaning of their context. This paper addresses class imbalance problem which is one of the important issues in sentimental analysis. Not much works focused on sentimental analysis with imbalanced class label distribution. The paper also focusses on another aspect of the problem which involves a concept called “Code Mixing”. Code mixed data consists of text alternating between two or more languages. Class imbalance distribution is a commonly noted phenomenon in a code-mixed data. The existing works have focused more on analyzing the sentiments in a monolingual data but not in a code-mixed data. This paper addresses all these issues and comes up with a solution to analyze sentiments for a class imbalanced code-mixed data using sampling technique combined with levenshtein distance metrics. Furthermore, this paper compares the performances of various machine learning approaches namely, Random Forest Classifier, Logistic Regression, XGBoost classifier, Support Vector Machine and Na\"{\i}ve Bayes Classifier using F1- Score.},
journal = {Distrib. Parallel Databases},
month = mar,
pages = {37–52},
numpages = {16},
keywords = {Code-mixed data, Sentimental analysis, Imbalanced data, Machine learning, Sampling}
}

@article{10.5555/3057337.3057441,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {A decision tree logic based recommendation system to select software fault prediction techniques},
year = {2017},
issue_date = {March     2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {99},
number = {3},
issn = {0010-485X},
abstract = {Identifying a reliable fault prediction technique is the key requirement for building effective fault prediction model. It has been found that the performance of fault prediction techniques is highly dependent on the characteristics of the fault dataset. To mitigate this issue, researchers have evaluated and compared a plethora of fault prediction techniques by varying the context in terms of domain information, characteristics of input data, complexity, etc. However, the lack of an accepted benchmark makes it difficult to select fault prediction technique for a particular context of prediction. In this paper, we present a recommendation system that facilitates the selection of appropriate technique(s) to build fault prediction model. First, we have reviewed the literature to elicit the various characteristics of the fault dataset and the appropriateness of the machine learning and statistical techniques for the identified characteristics. Subsequently, we have formalized our findings and built a recommendation system that helps in the selection of fault prediction techniques. We performed an initial appraisal of our presented system and found that proposed recommendation system provides useful hints in the selection of the fault prediction techniques.},
journal = {Computing},
month = mar,
pages = {255–285},
numpages = {31},
keywords = {verification, requirements, metrics, etc.), Software fault prediction techniques, Software fault prediction, Recommendation system, Decision tree, 68N30 Mathematical aspects of software engineering (specification}
}

@inproceedings{10.1145/3460319.3464844,
author = {Dutta, Saikat and Selvam, Jeeva and Jain, Aryaman and Misailovic, Sasa},
title = {TERA: optimizing stochastic regression tests in machine learning projects},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464844},
doi = {10.1145/3460319.3464844},
abstract = {The stochastic nature of many Machine Learning (ML) algorithms makes testing of ML tools and libraries challenging. ML algorithms allow a developer to control their accuracy and run-time through a set of hyper-parameters, which are typically manually selected in tests. This choice is often too conservative and leads to slow test executions, thereby increasing the cost of regression testing.  We propose TERA, the first automated technique for reducing the cost of regression testing in Machine Learning tools and libraries(jointly referred to as projects) without making the tests more flaky. TERA solves the problem of exploring the trade-off space between execution time of the test and its flakiness as an instance of Stochastic Optimization over the space of algorithm hyper-parameters. TERA presents how to leverage statistical convergence-testing techniques to estimate the level of flakiness of the test for a specific choice of hyper-parameters during optimization.  We evaluate TERA on a corpus of 160 tests selected from 15 popular machine learning projects. Overall, TERA obtains a geo-mean speedup of 2.23x over the original tests, for the minimum passing probability threshold of 99%. We also show that the new tests did not reduce fault detection ability through a mutation study and a study on a set of 12 historical build failures in studied projects.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {413–426},
numpages = {14},
keywords = {Test Optimization, Software Testing, Machine Learning, Bayesian Optimization},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@inproceedings{10.1109/IROS51168.2021.9636741,
author = {Khalil, Abdelrahman and Al Janaideh, Mohammad},
title = {On Fault Classification in Connected Autonomous Vehicles Using Supervised Machine Learning},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IROS51168.2021.9636741},
doi = {10.1109/IROS51168.2021.9636741},
abstract = {Different health-monitoring techniques were considered in the literature to enhance the safety and stability of Connected Autonomous Vehicle (CAV) platoons. The health-monitoring processes include fault detection, localization, and mitigation. It is evident that mitigating these faults is faster and more reliable if the fault structure is known. To this end, we consider classifying the fault class using supervised machine learning. We first model a heterogeneous CAV platoon with three different common faults separately. These faults are bounded actuator disturbances (namely, engine bearing knock), False Data Injection (FDI) attack, and communication time delay. We consider two supervised machine learning classifiers, the first classifier determines whether the fault is bounded disturbances or communication delay, and the second classifier determines whether the disturbances are in the physical or cyber layer. We have compared four machine learning techniques for each classifier, Support Vector Machine (SVM), Naive Bayes (NB), Quadratic Discriminant (QD), and K-Nearest Neighbors (KNN). The classifiers are trained firstly on the simulation model, then are tested on a different set of observations and tested experimentally on a platoon of three autonomous robots. The highest accuracy was achieved by considering SVM for the first classifier and QD for the second classifier. The overall classification accuracy achieved is 96.8% for the simulation test and 92.1% for the experiment.},
booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
pages = {1198–1204},
numpages = {7},
location = {Prague, Czech Republic}
}

@article{10.1016/j.compeleceng.2014.08.011,
author = {Honggui, Han and Ying, Li and Junfei, Qiao},
title = {A fuzzy neural network approach for online fault detection in waste water treatment process},
year = {2014},
issue_date = {October 2014},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {40},
number = {7},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2014.08.011},
doi = {10.1016/j.compeleceng.2014.08.011},
abstract = {Display Omitted A fault detection system is proposed and tested.A FNN, using the adaptive computation algorithm, is applied to the predicting plant.This fault diagnosis method allows a quick revealing of the faults.The fault detection system owns more reliable diagnosis then the off-line methods. In this paper, an effective strategy for fault detection of sludge volume index (SVI) sensor is proposed and tested on an experimental hardware setup in waste water treatment process (WWTP). The main objective of this fault detection strategy is to design a system which consists of the online sensors, the SVI predicting plant and fault diagnosis method. The SVI predicting plant is designed utilizing a fuzzy neural network (FNN), which is trained by a historical set of data collected during fault-free operation of WWTP. The fault diagnosis method, based on the difference between the measured concentration values and FNN predictions, allows a quick revealing of the faults. Then this proposed fault detection method is applied to a real WWTP and compared with other approaches. Experimental results show that the proposed fault detection strategy can obtain the fault signals of the SVI sensor online.},
journal = {Comput. Electr. Eng.},
month = oct,
pages = {2216–2226},
numpages = {11},
keywords = {Waste water treatment process, Sludge volume index, Fuzzy neural network, Fault detection, Bulking sludge}
}

@article{10.1016/j.asoc.2016.04.009,
author = {Ryu, Duksan and Baik, Jongmoon},
title = {Effective multi-objective nave Bayes learning for cross-project defect prediction},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.04.009},
doi = {10.1016/j.asoc.2016.04.009},
abstract = {Display Omitted We propose novel multi-objective learning techniques considering the class imbalance context for cross-project defect prediction.The proposed approaches (i.e., MONB and MONBNN) show the better diversity compared to existing multi-objective prediction models.The proposed approaches show the similar prediction performance compared to within-project defect prediction models. Software defect prediction predicts fault-prone modules which will be tested thoroughly. Thereby, limited quality control resources can be allocated effectively on them. Without sufficient local data, defects can be predicted via cross-project defect prediction (CPDP) utilizing data from other projects to build a classifier. Software defect datasets have the class imbalance problem, indicating the defect class has much fewer instances than the non-defect class does. Unless defect instances are predicted correctly, software quality could be degraded. In this context, a classifier requires to provide high accuracy of the defect class without severely worsening the accuracy of the non-defect class. This class imbalance principle seamlessly connects to the purpose of the multi-objective (MO) optimization in that MO predictive models aim at balancing many of the competing objectives. In this paper, we target to identify effective multi-objective learning techniques under cross-project (CP) environments. Three objectives are devised considering the class imbalance context. The first objective is to maximize the probability of detection (PD). The second objective is to minimize the probability of false alarm (PF). The third objective is to maximize the overall performance (e.g., Balance). We propose novel MO naive Bayes learning techniques modeled by a Harmony Search meta-heuristic algorithm. Our approaches are compared with single-objective models, other existing MO models and within-project defect prediction models. The experimental results show that the proposed approaches are promising. As a result, they can be effectively applied to satisfy various prediction needs under CP settings.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1062–1077},
numpages = {16},
keywords = {Search-based software engineering, Multi-objective optimization, Harmony Search, Cross-project defect prediction, Class imbalance}
}

@inproceedings{10.1109/COMPSAC.2014.66,
author = {Liu, Shulong and Chen, Xiang and Liu, Wangshu and Chen, Jiaqiang and Gu, Qing and Chen, Daoxu},
title = {FECAR: A Feature Selection Framework for Software Defect Prediction},
year = {2014},
isbn = {9781479935758},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2014.66},
doi = {10.1109/COMPSAC.2014.66},
abstract = {Software defect prediction can classify new software entities into either buggy or clean. However the effectiveness of existing methods is influenced by irrelevant and redundant features. In this paper, we propose a new feature selection framework FECAR using Feature Clustering And feature Ranking. This framework firstly partitions original features into k clusters based on FF-Correlation measure. Then it selects relevant features from each cluster based on FC-Relevance measure. In empirical study, we choose Symmetric Uncertainty as FF-Correlation measure, and choose Information Gain, Chi-Square, and Relief as three different FC-Relevance measures. Based on some real projects Eclipse and NASA, we implemented our framework and performed empirical studies to investigate the redundancy rate and the performance of the trained defect predictors. Final results verify the effectiveness of our proposed framework and further provide a guideline for achieving cost-effective feature selection when using our framework.},
booktitle = {Proceedings of the 2014 IEEE 38th Annual Computer Software and Applications Conference},
pages = {426–435},
numpages = {10},
keywords = {Software Defect Prediction, Feature Selection, Feature Clustering, Feature Ranking},
series = {COMPSAC '14}
}

@inproceedings{10.1145/3428757.3429152,
author = {Philipp, Robert and Mladenow, Andreas and Strauss, Christine and V\"{o}lz, Alexander},
title = {Machine Learning as a Service: Challenges in Research and Applications},
year = {2021},
isbn = {9781450389228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3428757.3429152},
doi = {10.1145/3428757.3429152},
abstract = {This study aims to evaluate the current state of research with regards to Machine Learning as a Service (MLaaS) and to identify challenges and research fields of this novel topic. First, a literature review on a basket of eight leading journals was performed. We motivate this study by identifying a lack of studies in the field of MLaaS. The structured literature review was further extended to established scientific databases relevant in this field. We found 30 contributions on MLaaS. As a result of the analysis we grouped them into four key concepts: Platform, Applications; Performance Enhancements and Challenges. Three of the derived concepts are discussed in detail to identify future research areas and to reveal challenges in research as well as in applications.},
booktitle = {Proceedings of the 22nd International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {396–406},
numpages = {11},
keywords = {Machine Learning as a Service, Machine Learning Platform, Machine Learning, MLaaS, Machine Learning Services},
location = {Chiang Mai, Thailand},
series = {iiWAS '20}
}

@article{10.1016/j.infsof.2019.08.005,
author = {Bigonha, Mariza A.S. and Ferreira, Kecia and Souza, Priscila and Sousa, Bruno and Janu\'{a}rio, Marcela and Lima, Daniele},
title = {The usefulness of software metric thresholds for detection of bad smells and fault prediction},
year = {2019},
issue_date = {Nov 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {115},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.08.005},
doi = {10.1016/j.infsof.2019.08.005},
journal = {Inf. Softw. Technol.},
month = nov,
pages = {79–92},
numpages = {14},
keywords = {Fault prediction, Bad smell, Detection strategies, Thresholds, Software quality, Software metrics}
}

@article{10.1007/s10664-015-9396-2,
author = {Zhang, Feng and Mockus, Audris and Keivanloo, Iman and Zou, Ying},
title = {Towards building a universal defect prediction model with rank transformed predictors},
year = {2016},
issue_date = {October   2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9396-2},
doi = {10.1007/s10664-015-9396-2},
abstract = {Software defects can lead to undesired results. Correcting defects costs 50 % to 75 % of the total software development budgets. To predict defective files, a prediction model must be built with predictors (e.g., software metrics) obtained from either a project itself (within-project) or from other projects (cross-project). A universal defect prediction model that is built from a large set of diverse projects would relieve the need to build and tailor prediction models for an individual project. A formidable obstacle to build a universal model is the variations in the distribution of predictors among projects of diverse contexts (e.g., size and programming language). Hence, we propose to cluster projects based on the similarity of the distribution of predictors, and derive the rank transformations using quantiles of predictors for a cluster. We fit the universal model on the transformed data of 1,385 open source projects hosted on SourceForge and GoogleCode. The universal model obtains prediction performance comparable to the within-project models, yields similar results when applied on five external projects (one Apache and four Eclipse projects), and performs similarly among projects with different context factors. At last, we investigate what predictors should be included in the universal model. We expect that this work could form a basis for future work on building a universal model and would lead to software support tools that incorporate it into a regular development workflow.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {2107–2145},
numpages = {39},
keywords = {Universal defect prediction model, Software quality, Rank transformation, Large-scale, Defect prediction, Context factors}
}

@inproceedings{10.5555/3408352.3408656,
author = {Biasielli, Matteo and Cassano, Luca and Miele, Antonio},
title = {An approximation-based fault detection scheme for image processing applications},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Image processing applications expose an intrinsic resilience to faults. In this application field the classical Duplication with Comparison (DWC) scheme, where output images are discarded as soon as the two replicas' outputs differ for at least one pixel, may be over-conseravative. This paper introduces a novel lightweight fault detection scheme for image processing applications; i) it extends the DWC scheme by substituting one of the two exact replicas with a faster approximated one; and ii) it features a Neural Network-based checker designed to distinguish between usable and unusable images instead of faulty/unfaulty ones. The application of the hardening scheme on a case study has shown an execution time reduction from 27% to 34% w.r.t. the DWC, while guaranteeing a comparable fault detection capability.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {1331–1334},
numpages = {4},
keywords = {approximate computing, convolutional neural networks, fault detection, image processing},
location = {Grenoble, France},
series = {DATE '20}
}

@article{10.1109/TSE.2019.2892959,
author = {Qu, Yu and Zheng, Qinghua and Chi, Jianlei and Jin, Yangxu and He, Ancheng and Cui, Di and Zhang, Hengshan and Liu, Ting},
title = {Using K-core Decomposition on Class Dependency Networks to Improve Bug Prediction Model's Practical Performance},
year = {2021},
issue_date = {Feb. 2021},
publisher = {IEEE Press},
volume = {47},
number = {2},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2019.2892959},
doi = {10.1109/TSE.2019.2892959},
abstract = {In recent years, &lt;italic&gt;Complex Network&lt;/italic&gt; theory and graph algorithms have been proved to be effective in predicting software bugs. On the other hand, as a widely-used algorithm in Complex Network theory, &lt;italic&gt;k-core decomposition&lt;/italic&gt; has been used in software engineering domain to identify key classes. Intuitively, key classes are more likely to be buggy since they participate in more functions or have more interactions and dependencies. However, there is no existing research uses &lt;italic&gt;k&lt;/italic&gt;-core decomposition to analyze software bugs. To fill this gap, we first use &lt;italic&gt;k&lt;/italic&gt;-core decomposition on Class Dependency Networks to analyze software bug distribution from a new perspective. An interesting and widely existed tendency is observed: for classes in &lt;italic&gt;k&lt;/italic&gt;-cores with larger &lt;italic&gt;k&lt;/italic&gt; values, there is a stronger possibility for them to be buggy. Based on this observation, we then propose a simple but effective equation named as &lt;italic&gt;top-core&lt;/italic&gt; which improves the order of classes in the suspicious class list produced by effort-aware bug prediction models. Based on an empirical study on 18 open-source Java systems, we show that the bug prediction models’ performances are significantly improved in 85.2 percent experiments in the cross-validation scenario and in 80.95 percent experiments in the forward-release scenario, after using &lt;italic&gt;top-core&lt;/italic&gt;. The models’ average performances are improved by 11.5 and 12.6 percent, respectively. It is concluded that the proposed &lt;italic&gt;top-core&lt;/italic&gt; equation can help the testers or code reviewers locate the real bugs more quickly and easily in software bug prediction practices.},
journal = {IEEE Trans. Softw. Eng.},
month = feb,
pages = {348–366},
numpages = {19}
}

@article{10.1155/2021/6662932,
author = {Gupta, Mansi and Rajnish, Kumar and Bhattacharjee, Vandana and Gou, Jianping},
title = {Impact of Parameter Tuning for Optimizing Deep Neural Network Models for Predicting Software Faults},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1058-9244},
url = {https://doi.org/10.1155/2021/6662932},
doi = {10.1155/2021/6662932},
abstract = {Deep neural network models built by the appropriate design decisions are crucial to obtain the desired classifier performance. This is especially desired when predicting fault proneness of software modules. When correctly identified, this could help in reducing the testing cost by directing the efforts more towards the modules identified to be fault prone. To be able to build an efficient deep neural network model, it is important that the parameters such as number of hidden layers, number of nodes in each layer, and training details such as learning rate and regularization methods be investigated in detail. The objective of this paper is to show the importance of hyperparameter tuning in developing efficient deep neural network models for predicting fault proneness of software modules and to compare the results with other machine learning algorithms. It is shown that the proposed model outperforms the other algorithms in most cases.},
journal = {Sci. Program.},
month = jan,
numpages = {17}
}

@inproceedings{10.1109/SEAA.2008.52,
author = {Turhan, Burak and Kocak, Gozde and Bener, Ayse},
title = {Software Defect Prediction Using Call Graph Based Ranking (CGBR) Framework},
year = {2008},
isbn = {9780769532769},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAA.2008.52},
doi = {10.1109/SEAA.2008.52},
abstract = {Recent research on static code attribute (SCA) based defect prediction suggests that a performance ceiling has been achieved and this barrier can be exceeded by increasing the information content in data. In this research we propose static call graph based ranking (CGBR) framework, which can be applied to any defect prediction model based on SCA. In this framework, we model both intra module properties and inter module relations. Our results show that defect predictors using CGBR framework can detect the same number of defective modules, while yielding significantly lower false alarm rates. On industrial public data, we also show that using CGBR framework can improve testing efforts by 23%.},
booktitle = {Proceedings of the 2008 34th Euromicro Conference Software Engineering and Advanced Applications},
pages = {191–198},
numpages = {8},
keywords = {defect prediction, cost-benefit analysis, call graph},
series = {SEAA '08}
}

@inproceedings{10.1145/3183440.3195034,
author = {Rahman, Akond and Stallings, Jonathan and Williams, Laurie},
title = {Defect prediction metrics for infrastructure as code scripts in DevOps},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3195034},
doi = {10.1145/3183440.3195034},
abstract = {Use of infrastructure as code (IaC) scripts helps software teams manage their configuration and infrastructure automatically. Information technology (IT) organizations use IaC scripts to create and manage automated deployment pipelines to deliver services rapidly. IaC scripts can be defective, resulting in dire consequences, such as creating wide-scale service outages for end-users. Prediction of defective IaC scripts can help teams to mitigate defects in these scripts by prioritizing their inspection efforts. The goal of this paper is to help software practitioners in prioritizing their inspection efforts for infrastructure as code (IaC) scripts by proposing defect prediction model-related metrics. IaC scripts use domain specific languages (DSL) that are fundamentally different from object-oriented programming (OOP) languages. Hence, the OOP-based metrics that researchers used in defect prediction might not be applicable for IaC scripts. We apply Constructivist Grounded Theory (CGT) on defect-related commits mined from version control systems to identify metrics suitable for IaC scripts. By applying CGT, we identify 18 metrics. Of these metrics, 13 are related to IaC, for example, count of string occurrences in a script. Four of the identified metrics are related to churn, and one metric is lines of code.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {414–415},
numpages = {2},
keywords = {DevOps, continuous deployment, infrastructure as code, metrics},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3452383.3452391,
author = {Kuri, Mohit and Karre, Sai Anirudh and Reddy, Y. Raghu},
title = {Understanding Software Quality Metrics for Virtual Reality Products - A Mapping Study},
year = {2021},
isbn = {9781450390460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452383.3452391},
doi = {10.1145/3452383.3452391},
abstract = {Virtual Reality (VR) Software is becoming more mainstream in recent years. It has provided an opportunity for VR practitioners to explore new domains and deliver cutting edge products. The success of the VR products depends primarily on the product contextual relevance and qualities exhibited. However, it is unclear how VR practitioners curb software quality challenges and improve the essence of the VR product over every release. In this paper, we present a Systematic Mapping Study of the software quality metrics adopted by VR practitioners for assessing the quality of their VR products. The study showed that practitioners used unique metrics to measure the quality of their VR products in addition to adopting some of existing enterprise software metrics. Further, we consolidate these metrics into different themes that future practitioners may use for developing VR products.},
booktitle = {Proceedings of the 14th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {8},
numpages = {11},
keywords = {Industrial Practices, Metrics, Software Quality, Virtual Reality},
location = {Bhubaneswar, Odisha, India},
series = {ISEC '21}
}

@inproceedings{10.5555/3398761.3399015,
author = {Khalastchi, Eliahu and Kalech, Meir},
title = {Efficient Hybrid Fault Detection for Autonomous Robots},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The use of robots has increased significantly in the recent years; rapidly expending to numerous applications. Yet, these sophisticated and sometimes expensive machines are susceptible to faults that might endanger the robot or its surroundings (e.g., a crash of an Unmanned Aerial Vehicle (UAV)). To prevent such faults, the robot's operation needs to be monitored by Fault Detection (FD) algorithms. An autonomous robot, which is already engaged with heavy computational tasks, has to continuously apply FD on its own. Thus, the impact of a FD process on the robot's resources should be minimized. Unfortunately, the computational load of existing FD approaches, which may be very accurate, might be impractical for an autonomous robot. To solve this problem, we suggest to use a hybrid approach. A very efficient FD algorithm is applied continuously and is used to trigger a heavier, more accurate, FD approach that determines the occurrence of a fault. In this paper we focus on the efficient FD algorithm. We test the algorithm in several real-world and simulated domains and we show and discuss the promising results.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1884–1886},
numpages = {3},
keywords = {[rob] long-term (or lifelong) autonomy for robotic systems, [rob] failure recovery for robots},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@article{10.1145/3469029,
author = {Murshed, M. G. Sarwar and Murphy, Christopher and Hou, Daqing and Khan, Nazar and Ananthanarayanan, Ganesh and Hussain, Faraz},
title = {Machine Learning at the Network Edge: A Survey},
year = {2021},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3469029},
doi = {10.1145/3469029},
abstract = {Resource-constrained IoT devices, such as sensors and actuators, have become ubiquitous in recent years. This has led to the generation of large quantities of data in real-time, which is an appealing target for AI systems. However, deploying machine learning models on such end-devices is nearly impossible. A typical solution involves offloading data to external computing systems (such as cloud servers) for further processing but this worsens latency, leads to increased communication costs, and adds to privacy concerns. To address this issue, efforts have been made to place additional computing devices at the edge of the network, i.e., close to the IoT devices where the data is generated. Deploying machine learning systems on such edge computing devices alleviates the above issues by allowing computations to be performed close to the data sources. This survey describes major research efforts where machine learning systems have been deployed at the edge of computer networks, focusing on the operational aspects including compression techniques, tools, frameworks, and hardware used in successful applications of intelligent edge systems.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {170},
numpages = {37},
keywords = {distributed computing, embedded, deep learning, low-power, IoT, resource-constrained, machine learning, mobile edge computing, Edge intelligence}
}

@article{10.1016/j.future.2019.09.009,
author = {Lopes, F\'{a}bio and Agnelo, Jo\~{a}o and Teixeira, C\'{e}sar A. and Laranjeiro, Nuno and Bernardino, Jorge},
title = {Automating orthogonal defect classification using machine learning algorithms},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {102},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.09.009},
doi = {10.1016/j.future.2019.09.009},
journal = {Future Gener. Comput. Syst.},
month = jan,
pages = {932–947},
numpages = {16},
keywords = {Text classification, Machine learning, Orthogonal defect classification, Bug reports, Software defects}
}

@inproceedings{10.1007/978-3-030-68799-1_52,
author = {Devagekar, Somesh and Delforouzi, Ahmad and Pl\"{o}ger, Paul G.},
title = {Fault Detection in Uni-Directional Tape Production Using Image Processing},
year = {2021},
isbn = {978-3-030-68798-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-68799-1_52},
doi = {10.1007/978-3-030-68799-1_52},
abstract = {The quality of uni-directional tape in its production process is affected by environmental conditions like temperature and production speed. In this paper, computer vision algorithms on the scanned images are needed to be used in this context to detect and classify tape damages during the manufacturing procedure. We perform a comparative study among famous feature descriptors for fault candidate generation, then propose own features for fault detection. We investigate various machine learning techniques to find best model for the classification problem. The empirical results demonstrate the high performance of the proposed system and show preference of random forest and canny edges for classifier and feature generator respectively.},
booktitle = {Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10–15, 2021, Proceedings, Part IV},
pages = {719–732},
numpages = {14},
keywords = {Object detection, Machine-learning, Feature extraction, Quality control, Unidirectional thermoplastic composites}
}

@inproceedings{10.1145/2915970.2916007,
author = {Petri\'{c}, Jean and Bowes, David and Hall, Tracy and Christianson, Bruce and Baddoo, Nathan},
title = {The jinx on the NASA software defect data sets},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2916007},
doi = {10.1145/2915970.2916007},
abstract = {Background: The NASA datasets have previously been used extensively in studies of software defects. In 2013 Shepperd et al. presented an essential set of rules for removing erroneous data from the NASA datasets making this data more reliable to use.Objective: We have now found additional rules necessary for removing problematic data which were not identified by Shepperd et al.Results: In this paper, we demonstrate the level of erroneous data still present even after cleaning using Shepperd et al.'s rules and apply our new rules to remove this erroneous data.Conclusion: Even after systematic data cleaning of the NASA MDP datasets, we found new erroneous data. Data quality should always be explicitly considered by researchers before use.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {13},
numpages = {5},
keywords = {software defect prediction, machine learning, data quality},
location = {Limerick, Ireland},
series = {EASE '16}
}

@inproceedings{10.1109/IROS51168.2021.9636868,
author = {Gu, Haoyuan and Hu, Hanjiang and Wang, Hesheng and Chen, Weidong},
title = {Soft Manipulator Fault Detection and Identification Using ANC-based LSTM},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IROS51168.2021.9636868},
doi = {10.1109/IROS51168.2021.9636868},
abstract = {Timely fault detection and identification (FDI) of soft manipulators are critical in the design of surgical systems to improve reliability. However, due to the intrinsic compliance of soft manipulators, their end effectors vibrate during the dynamic control process, which introduces noise into the measured signals and makes FDI of soft manipulators challenging. This paper proposes a novel method to accomplish these tasks based on Long Short Term Memory (LSTM) recurrent neural network. Based on LSTM network, a new Attention-based Noise Compensation (ANC) module is proposed to enable the network to filter the noise merged with signals input in a self-supervision manner. Moreover, weighted cross entropy loss is introduced to balance the normal and faulty samples in the training set. Of the 9930 samples presented to the model, 9489 are correctly diagnosed in less than 1.0 second, which implies that the method can learn the spatial and temporal dependence of the signals and distinguish the healthy modes from the faulty ones. Finally, we compare the ANC-based method with the vanilla LSTM method and the state-of-art Bruin et al. method. From the comparison, we conclude that the ANC-based method proposed in this paper not only shortens the time cost of the FDI process but also suppresses the sensitivity of diagnosis results to noise. Source code, pre-trained models and dataset are available on https://github.com/IRMVLab/ANC-LSTM-fault-detection.},
booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
pages = {1702–1707},
numpages = {6},
location = {Prague, Czech Republic}
}

@inproceedings{10.1145/3421515.3421535,
author = {Yan, Jiawen and Zhang, Weiwen and Peng, Yuxiang},
title = {WASSKIL: An Oversampling Method for Fault Detection of Industrial Plants},
year = {2020},
isbn = {9781450388627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3421515.3421535},
doi = {10.1145/3421515.3421535},
abstract = {Class imbalance is a major issue when adopting machine learning algorithms to build a predictive model for fault detection of industrial plants in smart factories. In this paper, we propose a data oversampling method termed WASSKIL. WASSKIL is developed based on MAHAKIL that simulates the genetic breeding process, where Wasserstein distance is leveraged rather than Mahalanobis distance when partitioning two sets of data for oversampling. We evaluate the performance of WASSKIL over 5 industrial plants of PHM 2015 dataset, using raw features of sensors and statistical features of the dataset in time series. The results show that WASSKIL can outperform MAHAKIL under both raw features and statistical features. Consequently, our proposed oversampling method has the potential to tame class imbalance, which can be used for prognostics and health management in smart factories.},
booktitle = {Proceedings of the 2020 2nd Symposium on Signal Processing Systems},
pages = {107–112},
numpages = {6},
keywords = {oversampling, machine health modeling, fault detection, Class imbalance},
location = {Guangdong, China},
series = {SSPS '20}
}

@inproceedings{10.1145/3468264.3468614,
author = {Cito, J\"{u}rgen and Dillig, Isil and Kim, Seohyun and Murali, Vijayaraghavan and Chandra, Satish},
title = {Explaining mispredictions of machine learning models using rule induction},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468614},
doi = {10.1145/3468264.3468614},
abstract = {While machine learning (ML) models play an increasingly prevalent role in many software engineering tasks, their prediction accuracy is often problematic. When these models do mispredict, it can be very difficult to isolate the cause. In this paper, we propose a technique that aims to facilitate the debugging process of trained statistical models. Given an ML model and a labeled data set, our method produces an interpretable characterization of the data on which the model performs particularly poorly. The output of our technique can be useful for understanding limitations of the training data or the model itself; it can also be useful for ensembling if there are multiple models with different strengths. We evaluate our approach through case studies and illustrate how it can be used to improve the accuracy of predictive models used for software engineering tasks within Facebook.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {716–727},
numpages = {12},
keywords = {rule induction, machine learning, explainability},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1109/QRS.2015.14,
author = {Yang, Xinli and Lo, David and Xia, Xin and Zhang, Yun and Sun, Jianling},
title = {Deep Learning for Just-in-Time Defect Prediction},
year = {2015},
isbn = {9781467379892},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/QRS.2015.14},
doi = {10.1109/QRS.2015.14},
abstract = {Defect prediction is a very meaningful topic, particularly at change-level. Change-level defect prediction, which is also referred as just-in-time defect prediction, could not only ensure software quality in the development process, but also make the developers check and fix the defects in time. Nowadays, deep learning is a hot topic in the machine learning literature. Whether deep learning can be used to improve the performance of just-in-time defect prediction is still uninvestigated. In this paper, to bridge this research gap, we propose an approach Deeper which leverages deep learning techniques to predict defect-prone changes. We first build a set of expressive features from a set of initial change features by leveraging a deep belief network algorithm. Next, a machine learning classifier is built on the selected features. To evaluate the performance of our approach, we use datasets from six large open source projects, i.e., Bugzilla, Columba, JDT, Platform, Mozilla, and PostgreSQL, containing a total of 137,417 changes. We compare our approach with the approach proposed by Kamei et al. The experimental results show that on average across the 6 projects, Deeper could discover 32.22% more bugs than Kamei et al's approach (51.04% versus 18.82% on average). In addition, Deeper can achieve F1-scores of 0.22-0.63, which are statistically significantly higher than those of Kamei et al.'s approach on 4 out of the 6 projects.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Software Quality, Reliability and Security},
pages = {17–26},
numpages = {10},
keywords = {Just-In-Time Defect Prediction, Deep Learning, Deep Belief Network, Cost Effectiveness},
series = {QRS '15}
}

@article{10.1016/j.jss.2021.111031,
author = {Giray, G\"{o}rkem},
title = {A software engineering perspective on engineering machine learning systems: State of the art and challenges},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {180},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2021.111031},
doi = {10.1016/j.jss.2021.111031},
journal = {J. Syst. Softw.},
month = oct,
numpages = {35},
keywords = {Systematic literature review, Deep learning, Machine learning, Software process, Software development, Software engineering}
}

@inproceedings{10.1007/978-3-030-64881-7_16,
author = {Sharma, Arnab and Wehrheim, Heike},
title = {Automatic Fairness Testing of Machine Learning Models},
year = {2020},
isbn = {978-3-030-64880-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-64881-7_16},
doi = {10.1007/978-3-030-64881-7_16},
abstract = {In recent years, there has been an increased application of machine learning (ML) to decision making systems. This has prompted an urgent need for validating requirements on ML models. Fairness is one such requirement to be ensured in numerous application domains. It specifies a software as “learned” by an ML algorithm to not be biased in the sense of discriminating against some attributes (like gender or age), giving different decisions upon flipping the values of these attributes.In this work, we apply verification-based testing (VBT) to the fairness checking of ML models. Verification-based testing employs verification technology to generate test cases potentially violating the property under interest. For fairness testing, we additionally provide a specification language for the formalization of different fairness requirements. From the ML model under test and fairness specification VBT automatically generates test inputs specific to the specified fairness requirement. The empirical evaluation on several benchmark ML models shows verification-based testing to perform better than existing fairness testing techniques with respect to effectiveness.},
booktitle = {Testing Software and Systems: 32nd IFIP WG 6.1 International Conference, ICTSS 2020, Naples, Italy, December 9–11, 2020, Proceedings},
pages = {255–271},
numpages = {17},
keywords = {SMT solving, Machine learning testing, Fairness},
location = {Naples, Italy}
}

@inproceedings{10.1007/978-3-030-04212-7_46,
author = {Xue, Yangtao and Zhang, Li and Wang, Bangjun and Tang, Baige},
title = {Density-Induced Support Vector Data Description for Fault Detection on Tennessee Eastman Process},
year = {2018},
isbn = {978-3-030-04211-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-04212-7_46},
doi = {10.1007/978-3-030-04212-7_46},
abstract = {Fault detection can be taken as a behavior of detecting abnormal data in process data. Support vector data description (SVDD) has been successfully used for fault detection. Although density-induced support vector data description (D-SVDD) can give a better description of target data by introducing relative density degrees than SVDD, the problem of an additional parameter selection hinders the application of D-SVDD, which has a great influence on the performance of D-SVDD. This paper bounds this additional parameter for D-SVDD and applies D-SVDD to fault detection on TE process monitoring. Experiment shows D-SVDD is promising.},
booktitle = {Neural Information Processing: 25th International Conference, ICONIP 2018, Siem Reap, Cambodia, December 13-16, 2018, Proceedings, Part IV},
pages = {522–531},
numpages = {10},
keywords = {D-SVDD, Fault detection, TE process},
location = {Siem Reap, Cambodia}
}

@article{10.1007/s00500-020-05226-7,
author = {Khuat, Thanh Tung and Ruta, Dymitr and Gabrys, Bogdan},
title = {Hyperbox-based machine learning algorithms: a comprehensive survey},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {2},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05226-7},
doi = {10.1007/s00500-020-05226-7},
abstract = {With the rapid development of digital information, the data volume generated by humans and machines is growing exponentially. Along with this trend, machine learning algorithms have been formed and evolved continuously to discover new information and knowledge from different data sources. Learning algorithms using hyperboxes as fundamental representational and building blocks are a branch of machine learning methods. These algorithms have enormous potential for high scalability and online adaptation of predictors built using hyperbox data representations to the dynamically changing environments and streaming data. This paper aims to give a comprehensive survey of the literature on hyperbox-based machine learning models. In general, according to the architecture and characteristic features of the resulting models, the existing hyperbox-based learning algorithms may be grouped into three major categories: fuzzy min–max neural networks, hyperbox-based hybrid models and other algorithms based on hyperbox representations. Within each of these groups, this paper shows a brief description of the structure of models, associated learning algorithms and an analysis of their advantages and drawbacks. Main applications of these hyperbox-based models to the real-world problems are also described in this paper. Finally, we discuss some open problems and identify potential future research directions in this field.},
journal = {Soft Comput.},
month = jan,
pages = {1325–1363},
numpages = {39},
keywords = {Online learning, Clustering, Data classification, Hybrid classifiers, Fuzzy min–max neural network, Membership function, Hyperboxes}
}

@article{10.1016/j.cosrev.2020.100341,
author = {Kotsiopoulos, Thanasis and Sarigiannidis, Panagiotis and Ioannidis, Dimosthenis and Tzovaras, Dimitrios},
title = {Machine Learning and Deep Learning in smart manufacturing: The Smart Grid paradigm},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2020.100341},
doi = {10.1016/j.cosrev.2020.100341},
journal = {Comput. Sci. Rev.},
month = may,
numpages = {25},
keywords = {Smart Grid, Industrial AI, Deep Learning, Machine Learning, Industry 4.0}
}

@inproceedings{10.5555/1671248.1671311,
author = {Tosun, Ayse and Bener, Ayse},
title = {Reducing false alarms in software defect prediction by decision threshold optimization},
year = {2009},
isbn = {9781424448425},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {Software defect data has an imbalanced and highly skewed class distribution. The misclassification costs of two classes are not equal nor are known. It is critical to find the optimum bound, i.e. threshold, which would best separate defective and defect-free classes in software data. We have applied decision threshold optimization on Na\"{\i}ve Bayes classifier in order to find the optimum threshold for software defect data. ROC analyses show that decision threshold optimization significantly decreases false alarms (on the average by 11%) without changing probability of detection rates.},
booktitle = {Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
pages = {477–480},
numpages = {4},
series = {ESEM '09}
}

@inproceedings{10.1109/RAMS.2019.8768923,
author = {Cui, Can and Liu, Bin and Li, Guoqi},
title = {A Novel Feature Selection Method for Software Fault Prediction Model},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/RAMS.2019.8768923},
doi = {10.1109/RAMS.2019.8768923},
abstract = {Software fault prediction (SFP) is an active issue in software engineering (SE). At present, machine learning (ML) has been successfully applied to SFP classification problems. However, one of the challenges for building software fault prediction models (SFPM) is processing high dimensional datasets, which include many irrelevant and redundant features. To address this issue, feature selection techniques, mainly contain wrapper methods and filter methods, are used. In the paper, we report an empirical study aimed at providing a novel approach to select feature for SFP.},
booktitle = {2019 Annual Reliability and Maintainability Symposium (RAMS)},
pages = {1–6},
numpages = {6},
location = {Orlando, FL, USA}
}

@article{10.1109/MCOM.001.1900283,
author = {Huang, Huakun and Zhao, Lingjun and Huang, Huawei and Guo, Song},
title = {Machine Fault Detection for Intelligent Self-Driving Networks},
year = {2020},
issue_date = {January 2020},
publisher = {IEEE Press},
volume = {58},
number = {1},
issn = {0163-6804},
url = {https://doi.org/10.1109/MCOM.001.1900283},
doi = {10.1109/MCOM.001.1900283},
abstract = {To build the mechanism of a SelfDN is becoming an emerging direction for future IoT. The detection of device status, such as fault or normal, is a very fundamental module in SelfDN. In this article, we first review recent studies devoted to applying fault detection techniques in IoT networks. Taking the challenge of processing the real-valued IoT data into account, we propose a novel fault detection architecture for SelfDN. Under this architecture, we present an algorithm, named GBRBM-based deep neural network with auto-encoder (i.e., GBRBM-DAE) to transform the fault detection problem into a classification problem. The real-world trace-driven experimental results show that the proposed algorithm outperforms other popular machine learning algorithms, including linear discriminant analysis, support vector machine, pure deep neural network, and so on. Finally, we summarize some open issues of this study. We expect that this article will inspire successive studies on the related topics of SelfDN.},
journal = {Comm. Mag.},
month = jan,
pages = {40–46},
numpages = {7}
}

@inproceedings{10.1145/3340482.3342741,
author = {Nair, Aravind and Meinke, Karl and Eldh, Sigrid},
title = {Leveraging mutants for automatic prediction of metamorphic relations using machine learning},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340482.3342741},
doi = {10.1145/3340482.3342741},
abstract = {An oracle is used in software testing to derive the verdict (pass/fail) for a test case. Lack of precise test oracles is one of the major problems in software testing which can hinder judgements about quality. Metamorphic testing is an emerging technique which solves both the oracle problem and the test case generation problem by testing special forms of software requirements known as metamorphic requirements. However, manually deriving the metamorphic requirements for a given program requires a high level of domain expertise, is labor intensive and error prone. As an alternative, we consider the problem of automatic detection of metamorphic requirements using machine learning (ML). For this problem we can apply graph kernels and support vector machines (SVM). A significant problem for any ML approach is to obtain a large labeled training set of data (in this case programs) that generalises well. The main contribution of this paper is a general method to generate large volumes of synthetic training data which can improve ML assisted detection of metamorphic requirements. For training data synthesis we adopt mutation testing techniques. This research is the first to explore the area of data augmentation techniques for ML-based analysis of software code. We also have the goal to enhance black-box testing using white-box methodologies. Our results show that the mutants incorporated into the source code corpus not only efficiently scale the dataset size, but they can also improve the accuracy of classification models.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
pages = {1–6},
numpages = {6},
keywords = {Test Case Generation, Source Code Analysis, Mutation Testing, Metamorphic Testing, Machine Learning, Fault Identification, Data augmentation},
location = {Tallinn, Estonia},
series = {MaLTeSQuE 2019}
}

@inproceedings{10.1145/3364641.3364670,
author = {Amaral, Weldson and Rivero, Luis and Junior, Geraldo Braz and Viana, Davi},
title = {Using Machine Learning Technique for Effort Estimation in Software Development},
year = {2019},
isbn = {9781450372824},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3364641.3364670},
doi = {10.1145/3364641.3364670},
abstract = {Estimates in software projects aim to help practitioners predict more realistic values on software development, impacting the quality of software process activities regarding planning and execution. However, software companies have difficulties when carrying out estimations that represent adequately the real effort needed to execute the software project activities. Although, the literature presents techniques to estimate effort, this activity remains complex. Recently, Machine Learning (ML) techniques are been applied to solve this problem. Through ML techniques it is possible to use databases of finished projects (datasets) to help get more precisely estimations. This research aims to propose a methodology to estimate effort using a ML technique based on decision trees: XGBoost. To evaluate our methodology, we conducted tests with four datasets using two metrics: Mean Magnitude Relative Error and Prediction(25). The preliminary results show consistent results for this methodology for software effort estimation based on the employed metrics, which indicates that our methodology is promising. As further work, new datasets must be analyzed using our methodology, and also an approach using synthetic data to improve the ML training.},
booktitle = {Proceedings of the XVIII Brazilian Symposium on Software Quality},
pages = {240–245},
numpages = {6},
keywords = {Software Projects, Machine Learning, Effort estimation, Boosting},
location = {Fortaleza, Brazil},
series = {SBQS '19}
}

@inproceedings{10.1145/3193977.3193985,
author = {Hardin, Bonnie and Kanewala, Upulee},
title = {Using semi-supervised learning for predicting metamorphic relations},
year = {2018},
isbn = {9781450357296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3193977.3193985},
doi = {10.1145/3193977.3193985},
abstract = {Software testing is difficult to automate, especially in programs which have no oracle, or method of determining which output is correct. Metamorphic testing is a solution this problem. Metamorphic testing uses metamorphic relations to define test cases and expected outputs. A large amount of time is needed for a domain expert to determine which metamorphic relations can be used to test a given program. Metamorphic relation prediction removes this need for such an expert. We propose a method using semi-supervised machine learning to detect which metamorphic relations are applicable to a given code base. We compare this semi-supervised model with a supervised model, and show that the addition of unlabeled data improves the classification accuracy of the MR prediction model.},
booktitle = {Proceedings of the 3rd International Workshop on Metamorphic Testing},
pages = {14–17},
numpages = {4},
keywords = {semi-supervised learning, metamorphic testing, metamorphic relations, machine learning},
location = {Gothenburg, Sweden},
series = {MET '18}
}

@inproceedings{10.1007/978-3-030-79379-1_1,
author = {Meinke, Karl and Khosrowjerdi, Hojat},
title = {Use Case Testing: A Constrained Active Machine Learning Approach},
year = {2021},
isbn = {978-3-030-79378-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79379-1_1},
doi = {10.1007/978-3-030-79379-1_1},
abstract = {As a methodology for system design and testing, use cases are well-known and widely used. While current active machine learning (ML) algorithms can effectively automate unit testing, they do not scale up&nbsp;to use case testing of complex systems in an efficient way.We present a new parallel distributed processing (PDP) architecture for a constrained active machine learning (CAML) approach to use case testing. To exploit CAML we introduce a use case modeling language with: (i) compile-time constraints on query generation, and (ii) run-time constraints using dynamic constraint checking. We evaluate this approach by applying a prototype implementation of CAML to use case testing of simulated multi-vehicle autonomous driving scenarios.},
booktitle = {Tests and Proofs: 15th International Conference, TAP 2021, Held as Part of STAF 2021, Virtual Event, June 21–22, 2021, Proceedings},
pages = {3–21},
numpages = {19},
keywords = {Use case testing, Requirements testing, Model checking, Machine learning, Learning-based testing, Constraint solving, Autonomous driving}
}

@article{10.1007/s11219-020-09511-4,
author = {Moreno, Valent\'{\i}n and G\'{e}nova, Gonzalo and Parra, Eugenio and Fraga, Anabel},
title = {Application of machine learning techniques to the flexible assessment and improvement of requirements quality},
year = {2020},
issue_date = {Dec 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09511-4},
doi = {10.1007/s11219-020-09511-4},
abstract = {It is already common to compute quantitative metrics of requirements to assess their quality. However, the risk is to build assessment methods and tools that are both arbitrary and rigid in the parameterization and combination of metrics. Specifically, we show that a linear combination of metrics is insufficient to adequately compute a global measure of quality. In this work, we propose to develop a flexible method to assess and improve the quality of requirements that can be adapted to different contexts, projects, organizations, and quality standards, with a high degree of automation. The domain experts contribute with an initial set of requirements that they have classified according to their quality, and we extract their quality metrics. We then use machine learning techniques to emulate the implicit expert’s quality function. We provide also a procedure to suggest improvements in bad requirements. We compare the obtained rule-based classifiers with different machine learning algorithms, obtaining measurements of effectiveness around 85%. We show as well the appearance of the generated rules and how to interpret them. The method is tailorable to different contexts, different styles to write requirements, and different demands in quality. The whole process of inferring and applying the quality rules adapted to each organization is highly automated.},
journal = {Software Quality Journal},
month = dec,
pages = {1645–1674},
numpages = {30},
keywords = {Flexible assessment, Experts’ judgment, Automatic improvement, Automatic classification, Machine learning, Requirements quality}
}

@inproceedings{10.1145/2884781.2884839,
author = {Zhang, Feng and Zheng, Quan and Zou, Ying and Hassan, Ahmed E.},
title = {Cross-project defect prediction using a connectivity-based unsupervised classifier},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884839},
doi = {10.1145/2884781.2884839},
abstract = {Defect prediction on projects with limited historical data has attracted great interest from both researchers and practitioners. Cross-project defect prediction has been the main area of progress by reusing classifiers from other projects. However, existing approaches require some degree of homogeneity (e.g., a similar distribution of metric values) between the training projects and the target project. Satisfying the homogeneity requirement often requires significant effort (currently a very active area of research).An unsupervised classifier does not require any training data, therefore the heterogeneity challenge is no longer an issue. In this paper, we examine two types of unsupervised classifiers: a) distance-based classifiers (e.g., k-means); and b) connectivity-based classifiers. While distance-based unsupervised classifiers have been previously used in the defect prediction literature with disappointing performance, connectivity-based classifiers have never been explored before in our community.We compare the performance of unsupervised classifiers versus supervised classifiers using data from 26 projects from three publicly available datasets (i.e., AEEEM, NASA, and PROMISE). In the cross-project setting, our proposed connectivity-based classifier (via spectral clustering) ranks as one of the top classifiers among five widely-used supervised classifiers (i.e., random forest, naive Bayes, logistic regression, decision tree, and logistic model tree) and five unsupervised classifiers (i.e., k-means, partition around medoids, fuzzy C-means, neural-gas, and spectral clustering). In the within-project setting (i.e., models are built and applied on the same project), our spectral classifier ranks in the second tier, while only random forest ranks in the first tier. Hence, connectivity-based unsupervised classifiers offer a viable solution for cross and within project defect predictions.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {309–320},
numpages = {12},
keywords = {unsupervised, spectral clustering, heterogeneity, graph mining, defect prediction, cross-project},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3405962.3405994,
author = {Soller, Sebastian and Kranz, Matthias and Hoelzl, Gerold},
title = {Adaptive Error Prediction for Production Lines with Unknown Dependencies},
year = {2020},
isbn = {9781450375429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3405962.3405994},
doi = {10.1145/3405962.3405994},
abstract = {Forecasting or predicting errors can dramatically reduce the downtime of machines in industrial settings and even allow to take counteractions long before the error affects the production system. A forecast system to predict upcoming critical values for identical production lines under different environmental circumstances is proposed. We focus on errors that result in multiple erroneous work pieces. These error patterns need manual corrections by a machine controller. An analysis of the system observed gathered the information about the types of errors that are observable. 30% of errors are measurement errors or single faulty work-pieces which are not influenced by previous work-pieces and do not show any indication to preceding work-pieces. These errors do not need any type of action by the machine controller. 70% of the observed errors are continuous system deviations which lead to multiple erroneous work-pieces in order or a high percentage of erroneous work-pieces in an observed time frame.We observe multiple production lines which consist of identical machines and produce the same product type. For the forecast of errors, we use the ARIMA, Holt and Holt-Winter method. Each production line and product type combination showed different results for the different forecast methods. We implemented a dynamic system that automatically detects the seasonality and trend of the specific combination to assign a correct forecast method and model. For 40 combinations of production line and product type the holt-winter algorithm performed best for 14, the holt-winter without seasonal or trend component performed best for 13 combinations and the holt-winter with only a trend component performed best for 10 setups. 3 combinations did not have a distinct best method for all observed results. By selecting the correct forecast methods, we were able to boost the forecast accuracy for the overall system over each single forecast method.},
booktitle = {Proceedings of the 10th International Conference on Web Intelligence, Mining and Semantics},
pages = {227–234},
numpages = {8},
keywords = {time series forecast, seasonality analysis, real-time system, maintenance prediction, data mining},
location = {Biarritz, France},
series = {WIMS 2020}
}

@inproceedings{10.1109/CEC.2017.7969629,
author = {Ibarguren, Igor and P\'{e}rez, Jes\'{u}s M. and Mugerza, Javier and Rodriguez, Daniel and Harrison, Rachel},
title = {The Consolidated Tree Construction algorithm in imbalanced defect prediction datasets},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC.2017.7969629},
doi = {10.1109/CEC.2017.7969629},
abstract = {In this short paper, we compare well-known rule/tree classifiers in software defect prediction with the CTC decision tree classifier designed to deal with class imbalanced. It is well-known that most software defect prediction datasets are highly imbalance (non-defective instances outnumber defective ones). In this work, we focused only on tree/rule classifiers as these are capable of explaining the decision, i.e., describing the metrics and thresholds that make a module error prone. Furthermore, rules/decision trees provide the advantage that they are easily understood and applied by project managers and quality assurance personnel. The CTC algorithm was designed to cope with class imbalance and noisy datasets instead of using preprocessing techniques (oversampling or undersampling), ensembles or cost weights of misclassification. The experimental work was carried out using the NASA datasets and results showed that induced CTC decision trees performed better or similar to the rest of the rule/tree classifiers.},
booktitle = {2017 IEEE Congress on Evolutionary Computation (CEC)},
pages = {2656–2660},
numpages = {5},
location = {Donostia, San Sebasti\'{a}n, Spain}
}

@article{10.1145/3183339,
author = {Zhou, Yuming and Yang, Yibiao and Lu, Hongmin and Chen, Lin and Li, Yanhui and Zhao, Yangyang and Qian, Junyan and Xu, Baowen},
title = {How Far We Have Progressed in the Journey? An Examination of Cross-Project Defect Prediction},
year = {2018},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3183339},
doi = {10.1145/3183339},
abstract = {Background. Recent years have seen an increasing interest in cross-project defect prediction (CPDP), which aims to apply defect prediction models built on source projects to a target project. Currently, a variety of (complex) CPDP models have been proposed with a promising prediction performance.Problem. Most, if not all, of the existing CPDP models are not compared against those simple module size models that are easy to implement and have shown a good performance in defect prediction in the literature.Objective. We aim to investigate how far we have really progressed in the journey by comparing the performance in defect prediction between the existing CPDP models and simple module size models.Method. We first use module size in the target project to build two simple defect prediction models, ManualDown and ManualUp, which do not require any training data from source projects. ManualDown considers a larger module as more defect-prone, while ManualUp considers a smaller module as more defect-prone. Then, we take the following measures to ensure a fair comparison on the performance in defect prediction between the existing CPDP models and the simple module size models: using the same publicly available data sets, using the same performance indicators, and using the prediction performance reported in the original cross-project defect prediction studies.Result. The simple module size models have a prediction performance comparable or even superior to most of the existing CPDP models in the literature, including many newly proposed models.Conclusion. The results caution us that, if the prediction performance is the goal, the real progress in CPDP is not being achieved as it might have been envisaged. We hence recommend that future studies should include ManualDown/ManualUp as the baseline models for comparison when developing new CPDP models to predict defects in a complete target project.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {1},
numpages = {51},
keywords = {unsupervised, supervised, model, cross-project, Defect prediction}
}

@inproceedings{10.1109/ICMLA.2014.63,
author = {Coelho, Rodrigo A. and Guimar\~{a}es, Fabr\'{\i}cio dos R. N. and Esmin, Ahmed A. A.},
title = {Applying Swarm Ensemble Clustering Technique for Fault Prediction Using Software Metrics},
year = {2014},
isbn = {9781479974153},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICMLA.2014.63},
doi = {10.1109/ICMLA.2014.63},
abstract = {Number of defects remaining in a system provides an insight into the quality of the system. Defect detection systems predict defects by using software metrics and data mining techniques. Clustering analysis is adopted to build the software defect prediction models. Cluster ensembles have emerged as a prominent method for improving robustness, stability and accuracy of clustering solutions. The clustering ensembles combine multiple partitions generated by different clustering algorithms into a single clustering solution. In this paper, the clustering ensemble using Particle Swarm Optimization algorithm (PSO) solution is proposed to improve the prediction quality. An empirical study shows that the PSO can be a good choice to build defect prediction software models.},
booktitle = {Proceedings of the 2014 13th International Conference on Machine Learning and Applications},
pages = {356–361},
numpages = {6},
keywords = {Software defect prediction, Particle swarm optimization, Ensemble clustering, Cluster data},
series = {ICMLA '14}
}

@article{10.1145/3442181,
author = {Sabir, Bushra and Ullah, Faheem and Babar, M. Ali and Gaire, Raj},
title = {Machine Learning for Detecting Data Exfiltration: A Review},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442181},
doi = {10.1145/3442181},
abstract = {Context: Research at the intersection of cybersecurity, Machine Learning (ML), and Software Engineering (SE) has recently taken significant steps in proposing countermeasures for detecting sophisticated data exfiltration attacks. It is important to systematically review and synthesize the ML-based data exfiltration countermeasures for building a body of knowledge on this important topic. Objective: This article aims at systematically reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches, feature engineering techniques, evaluation datasets, and performance metrics used for these countermeasures. This review also aims at identifying gaps in research on ML-based data exfiltration countermeasures. Method: We used Systematic Literature Review (SLR) method to select and review 92 papers. Results: The review has enabled us to: (a) classify the ML approaches used in the countermeasures into data-driven, and behavior-driven approaches; (b) categorize features into six types: behavioral, content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance measures used by these studies. Conclusion: We conclude that: (i) The integration of data-driven and behavior-driven approaches should be explored; (ii) There is a need of developing high quality and large size evaluation datasets; (iii) Incremental ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial learning should be considered and explored during the development of countermeasures to avoid poisoning attacks; and (v) The use of automated feature engineering should be encouraged for efficiently detecting data exfiltration attacks.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {50},
numpages = {47},
keywords = {machine learning, data leakage, data breach, advanced persistent threat, Data exfiltration}
}

@article{10.1016/j.compeleceng.2021.107362,
author = {P, Gouthaman and Sankaranarayanan, Suresh},
title = {Prediction of Risk Percentage in Software Projects by Training Machine Learning Classifiers},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {94},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107362},
doi = {10.1016/j.compeleceng.2021.107362},
journal = {Comput. Electr. Eng.},
month = sep,
numpages = {9},
keywords = {Risk prediction, Machine learning, Incremental, Evolutionary, Waterfall, Agile, Software model}
}

@inproceedings{10.1145/3340482.3342744,
author = {Pecorelli, Fabiano and Di Nucci, Dario and De Roover, Coen and De Lucia, Andrea},
title = {On the role of data balancing for machine learning-based code smell detection},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340482.3342744},
doi = {10.1145/3340482.3342744},
abstract = {Code smells can compromise software quality in the long term by inducing technical debt. For this reason, many approaches aimed at identifying these design flaws have been proposed in the last decade. Most of them are based on heuristics in which a set of metrics (e.g., code metrics, process metrics) is used to detect smelly code components. However, these techniques suffer of subjective interpretation, low agreement between detectors, and threshold dependability. To overcome these limitations, previous work applied Machine Learning techniques that can learn from previous datasets without needing any threshold definition. However, more recent work has shown that Machine Learning is not always suitable for code smell detection due to the highly unbalanced nature of the problem. In this study we investigate several approaches able to mitigate data unbalancing issues to understand their impact on ML-based approaches for code smell detection. Our findings highlight a number of limitations and open issues with respect to the usage of data balancing in ML-based code smell detection.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
pages = {19–24},
numpages = {6},
keywords = {Machine Learning, Data Balancing, Code Smells},
location = {Tallinn, Estonia},
series = {MaLTeSQuE 2019}
}

@article{10.1016/j.cose.2021.102459,
author = {Zhao, Jinxiong and Guo, Sensen and Mu, Dejun},
title = {DouBiGRU-A: Software defect detection algorithm based on attention mechanism and double BiGRU},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier Advanced Technology Publications},
address = {GBR},
volume = {111},
number = {C},
issn = {0167-4048},
url = {https://doi.org/10.1016/j.cose.2021.102459},
doi = {10.1016/j.cose.2021.102459},
journal = {Comput. Secur.},
month = dec,
numpages = {10},
keywords = {Flawfinder, RATS, Vulnerability identification, Software defect detection, DouBiGRU-A}
}

@article{10.1016/j.jnca.2020.102576,
author = {Gu, Rentao and Yang, Zeyuan and Ji, Yuefeng},
title = {Machine learning for intelligent optical networks: A comprehensive survey},
year = {2020},
issue_date = {May 2020},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {157},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2020.102576},
doi = {10.1016/j.jnca.2020.102576},
journal = {J. Netw. Comput. Appl.},
month = may,
numpages = {22},
keywords = {Reinforcement learning, Neural networks, Optical performance monitoring, Resource management, Machine learning, Optical networks}
}

@inproceedings{10.5220/0005382803820387,
author = {Sari, Ozkan and Kalipsiz, Oya},
title = {Bug Prediction for an ATM Monitoring Software},
year = {2015},
isbn = {9789897580970},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
address = {Setubal, PRT},
url = {https://doi.org/10.5220/0005382803820387},
doi = {10.5220/0005382803820387},
abstract = {Software testing which is carried out for the elimination of the software defects is one of the significant activities to achieve software quality. However, testing each fragment of the software is impossible and defects still occur even after several detailed test activities. Therefore, there is a need for effective methods to detect bugs in software. It is possible to detect faulty portions of the code earlier by examining the characteristics of the code. Serving this purpose, bug prediction activities help to detect the presence of defects as early as possible in an automated fashion. As a part of the ongoing thesis study, an effective model is aimed to be developed in order to predict software entities having bugs. A public bug database and ATM monitoring software source code are used for the creation of the model and to find the performance of the study.},
booktitle = {Proceedings of the 17th International Conference on Enterprise Information Systems - Volume 2},
pages = {382–387},
numpages = {6},
keywords = {Software Metrics and Measurement, Software Engineering, Logistic Regression Analysis., Bug Prediction},
location = {Barcelona, Spain},
series = {ICEIS 2015}
}

@article{10.1007/s10766-021-00707-0,
author = {\"{O}z, I\c{s}\i{}l and Arslan, Sanem},
title = {Predicting the Soft Error Vulnerability of Parallel Applications Using Machine Learning},
year = {2021},
issue_date = {Jun 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {3},
issn = {0885-7458},
url = {https://doi.org/10.1007/s10766-021-00707-0},
doi = {10.1007/s10766-021-00707-0},
abstract = {With the widespread use of the multicore systems having smaller transistor sizes, soft errors become an important issue for parallel program execution. Fault injection is a prevalent method to quantify the soft error rates of the applications. However, it is very time consuming to perform detailed fault injection experiments. Therefore, prediction-based techniques have been proposed to evaluate the soft error vulnerability in a faster way. In this work, we present a soft error vulnerability prediction approach for parallel applications using machine learning algorithms. We define a set of features including thread communication, data sharing, parallel programming, and performance characteristics; and train our models based on three ML algorithms. This study uses the parallel programming features, as well as the combination of all features for the first time in vulnerability prediction of parallel programs. We propose two models for the soft error vulnerability prediction: (1) A regression model with rigorous feature selection analysis that estimates correct execution rates, (2) A novel classification model that predicts the vulnerability level of the target programs. We get maximum prediction accuracy rate of 73.2% for the regression-based model, and achieve 89% F-score for our classification model.},
journal = {Int. J. Parallel Program.},
month = jun,
pages = {410–439},
numpages = {30},
keywords = {Machine Learning, Parallel programming, Fault injection, Soft error analysis}
}

@inproceedings{10.1007/978-3-030-16670-0_12,
author = {Zhang, Yu and Hu, Ting and Liang, Xiaodong and Ali, Mohammad Zawad and Shabbir, Md. Nasmus Sakib Khan},
title = {Fault Detection and Classification for Induction Motors Using Genetic Programming},
year = {2019},
isbn = {978-3-030-16669-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-16670-0_12},
doi = {10.1007/978-3-030-16670-0_12},
abstract = {Induction motors are the workhorse in various industry sectors, and their accurate fault detection is essential to ensure reliable operation of critical industrial processes. Since various types of mechanical and electrical faults could occur, induction motor fault diagnosis can be interpreted as a multi-label classification problem. The current and vibration input data collected by monitoring a motor often require signal processing to extract features that can better characterize these waveforms. However, some extracted features may not be relevant to the classification, feature selection is thus necessary. Given such challenges, in recent years, machine learning methods, including decision trees and support vector machines, are increasingly applied to detect and classify induction motor faults. Genetic programming (GP), as a powerful automatic learning algorithm with its abilities of embedded feature selection and multi-label classification, has not been explored to solve this problem. In this paper, we propose a linear GP (LGP) algorithm to search predictive models for motor fault detection and classification. Our method is able to evolve multi-label classifiers with high accuracies using experimentally collected data in the lab by monitoring two induction motors. We also compare the results of the LGP algorithm to other commonly used machine learning algorithms, and are able to show its superior performance on both feature selection and classification.},
booktitle = {Genetic Programming: 22nd European Conference, EuroGP 2019, Held as Part of EvoStar 2019, Leipzig, Germany, April 24–26, 2019, Proceedings},
pages = {178–193},
numpages = {16},
keywords = {Genetic programming, Feature selection, Classification, Fault detection, Induction motor},
location = {Leipzig, Germany}
}

@inproceedings{10.1145/3410992.3411004,
author = {Mukhopadhyay, Sumona and Litoiu, Marin},
title = {Fault detection in sensors using single and multi-channel weighted convolutional neural networks},
year = {2020},
isbn = {9781450387583},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410992.3411004},
doi = {10.1145/3410992.3411004},
abstract = {The success of sensor based application depends on the availability of clean data and its fail safe operation. However, due to their inherent dynamical behavior, detecting faults in sensors can be challenging. To this end, we propose a signal processing and nonlinear dynamics based fault detection approach for learning the normal/abnormal states of sensors using machine learning. The characteristic traits in detecting faults are the textured images that are generated from the time series of sensor measurements. Our approach uses these textured images that capture the dynamical properties of the sensor systems along with spectrograms with weighted Convolutional Neural Networks (wCNNs). We first test our approach on a radar sensor system since identifying faults in such a system is difficult due to their inherent complex dynamics. An evaluation of the multi-channel wCNN model for radar fault detection shows its robustness to tolerate noise. The efficiency of our approach is validated on a real data set from a gearbox sensor system. Results demonstrate that the unique patterns from the image representation convey valuable information about the dynamical states of the sensor systems in improving fault detection.},
booktitle = {Proceedings of the 10th International Conference on the Internet of Things},
articleno = {4},
numpages = {8},
keywords = {weighted convolutional neural network, time series, symbolic signal processing, spectrogram},
location = {Malm\"{o}, Sweden},
series = {IoT '20}
}

@article{10.1007/s00158-020-02819-6,
author = {Wu, Rih-Teng and Liu, Ting-Wei and Jahanshahi, Mohammad R. and Semperlotti, Fabio},
title = {Design of one-dimensional acoustic metamaterials using machine learning and cell concatenation},
year = {2021},
issue_date = {May 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {63},
number = {5},
issn = {1615-147X},
url = {https://doi.org/10.1007/s00158-020-02819-6},
doi = {10.1007/s00158-020-02819-6},
abstract = {Metamaterial systems have opened new, unexpected, and exciting paths for the design of acoustic devices that only few years ago were considered completely out of reach. However, the development of an efficient design methodology still remains challenging due to highly intensive search in the design space required by the conventional optimization-based approaches. To address this issue, this study develops two machine learning (ML)-based approaches for the design of one-dimensional periodic and non-periodic metamaterial systems. For periodic metamaterials, a reinforcement learning (RL)-based approach is proposed to design a metamaterial that can achieve user-defined frequency band gaps. This RL-based approach surpasses conventional optimization-based methods in the reduction of computation cost when a near-optimal solution is acceptable. Leveraging the capability of exploration in RL, the proposed approach does not require any training datasets generation and therefore can be deployed for online metamaterial design. For non-periodic metamaterials, a neural network (NN)-based approach capable of learning the behavior of individual material units is presented. By assembling the NN representation of individual material units, a surrogate model of the whole metamaterial is employed to determine the properties of the resulting assembly. Interestingly, the proposed approach is capable of modeling different metamaterial assemblies satisfying user-defined properties while requiring only a one-time network training procedure. Also, the NN-based approach does not need a pre-defined number of material unit cells, and it works when the physical model of the unit cell is not well understood, or the situation where only the sensor measurements of the unit cell are available. The robustness of the proposed two approaches is validated through numerical simulations and design examples.},
journal = {Struct. Multidiscip. Optim.},
month = may,
pages = {2399–2423},
numpages = {25},
keywords = {Neural network, Reinforcement learning, Machine learning, Phononic crystal, Acoustic metamaterial}
}

@article{10.34768/amcs-2021-0003,
author = {Huang, Lei and Ren, Hao and Chai, Yi and Qu, Jianfeng},
title = {A fault detection method based on stacking the SAE-SRBM for nonstationary and stationary hybrid processes},
year = {2021},
issue_date = {Mar 2021},
publisher = {Walter de Gruyter &amp; Co.},
address = {USA},
volume = {31},
number = {1},
issn = {1641-876X},
url = {https://doi.org/10.34768/amcs-2021-0003},
doi = {10.34768/amcs-2021-0003},
abstract = {This paper proposes a fault detection method by extracting nonlinear features for nonstationary and stationary hybrid industrial processes. The method is mainly built on the basis of a sparse auto-encoder and a sparse restricted Boltzmann machine (SAE-SRBM), so as to take advantages of their adaptive extraction and fusion on strong nonlinear symptoms. In the present work, SAEs are employed to reconstruct inputs and accomplish feature extraction by unsupervised mode, and their outputs present a knotty problem of an unknown probability distribution. In order to solve it, SRBMs are naturally used to fuse these unknown probability distribution features by transforming them into energy characteristics. The contribution of this method is the capability of further mining and learning of nonlinear features without considering the nonstationary problem. Also, this paper introduces a method of constructing labeled and unlabeled training samples while maintaining time series features. Unlabeled samples can be adopted to train the part for feature extraction and fusion, while labeled samples can be used to train the classification part. Finally, a simulation on the Tennessee Eastman process is carried out to demonstrate the effectiveness and excellent performance on fault detection for nonstationary and stationary hybrid industrial processes.},
journal = {Int. J. Appl. Math. Comput. Sci.},
month = mar,
pages = {29–43},
numpages = {15},
keywords = {hybrid industrial processes, sparse restricted Boltzmann machine, sparse auto-encoder, fault detection}
}

@inproceedings{10.1145/1868328.1868350,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
title = {On the value of learning from defect dense components for software defect prediction},
year = {2010},
isbn = {9781450304047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868328.1868350},
doi = {10.1145/1868328.1868350},
abstract = {BACKGROUND: Defect predictors learned from static code measures can isolate code modules with a higher than usual probability of defects.AIMS: To improve those learners by focusing on the defect-rich portions of the training sets.METHOD: Defect data CM1, KC1, MC1, PC1, PC3 was separated into components. A subset of the projects (selected at random) were set aside for testing. Training sets were generated for a NaiveBayes classifier in two ways. In sample the dense treatment, the components with higher than the median number of defective modules were used for training. In the standard treatment, modules from any component were used for training. Both samples were run against the test set and evaluated using recall, probability of false alarm, and precision. In addition, under sampling and over sampling was performed on the defect data. Each method was repeated in a 10-by-10 cross-validation experiment.RESULTS: Prediction models learned from defect dense components out-performed standard method, under sampling, as well as over sampling. In statistical rankings based on recall, probability of false alarm, and precision, models learned from dense components won 4--5 times more often than any other method, and also lost the least amount of times.CONCLUSIONS: Given training data where most of the defects exist in small numbers of components, better defect predictors can be trained from the defect dense components.},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
articleno = {14},
numpages = {9},
keywords = {ceiling effect, defect dense components, defect prediction, sampling},
location = {Timi\c{s}oara, Romania},
series = {PROMISE '10}
}

@inproceedings{10.1109/SMC.2016.7844959,
author = {Qing Liu and Feng Zhang and Liu, Min and Shen, Weiming},
title = {A fault prediction method based on modified Genetic Algorithm using BP neural network algorithm},
year = {2016},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SMC.2016.7844959},
doi = {10.1109/SMC.2016.7844959},
abstract = {In order to improve fault forecasting model accuracy of back propagation neural network (BPNN), an improved prediction method of optimized BPNN based on Multilevel Genetic Algorithm (MGA) was proposed. We design new chromosome with multilevel structure, improve the encoding mode, fitness function and genetic operator. Which can optimizes the initial values of weights, thresholds and the structure of BPNN synchronously. Enhancing the ability of nonlinear learning and generalization of BPNN. Case study of continuous casting equipment verified that the proposed model with higher prediction accuracy is better than classical BPNN and GA-BPNN prediction method for fault prediction.},
booktitle = {2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
pages = {004614–004619},
numpages = {6},
location = {Budapest, Hungary}
}

@inproceedings{10.1145/3373509.3373558,
author = {Zhao, Xuan and Li, Yali and Wang, Shengjin},
title = {Face Quality Assessment via Semi-supervised Learning},
year = {2020},
isbn = {9781450376570},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373509.3373558},
doi = {10.1145/3373509.3373558},
abstract = {Face quality assessment, used for selecting a "good" subset from face images captured over multiple frames in uncontrolled conditions, plays a significant role in video-based face recognition. By removing the poor quality images, it can not only improve recognition performance but also reduce the computation cost. This paper proposes an end-to-end face quality assessment algorithm based on a semi-supervised learning framework. The contributions of the proposed method are threefold. (i) Making use of unlabeled data from target domain to fine-tune a neural network by a strategy of automatically updating labels. (ii) Combining prior knowledge with feature learning by using a set of characteristics as binary constraints. (iii) Proposing a light neural network model for training and predicting. Experiments demonstrate that our model can get much higher accuracy in face quality assessment task than the models trained with the same amount of labeled faces, meanwhile the complexity is lower. Experimental results also show that our method can improve the performance of face recognition by face selection.},
booktitle = {Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition},
pages = {288–293},
numpages = {6},
keywords = {semi-supervised learning, prior knowledge, light CNN, Face quality assessment},
location = {Beijing, China},
series = {ICCPR '19}
}

@inproceedings{10.1007/978-3-030-04780-1_26,
author = {Pal, Amrit and Kumar, Manish},
title = {Applying Big Data Intelligence for Real Time Machine Fault Prediction},
year = {2018},
isbn = {978-3-030-04779-5},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-04780-1_26},
doi = {10.1007/978-3-030-04780-1_26},
abstract = {Continuous use of mechanical systems requires precise maintenance. Automatic monitoring of such systems generates a large amount of data which require intelligent mining methods for processing and information extraction. The problem is to predict the faults generated with ball bearing which severely degrade operating conditions of machinery. We develop a distributed fault prediction model based on big data intelligence that extracts nine essential features from ball bearing dataset through distributed random forest. We also perform a rigorous simulation analysis of the proposed approach and the results ensure the accuracy/correctness of the method. Different types of fault classes are considered for prediction purpose and classification is done in a supervised distributed environment.},
booktitle = {Big Data Analytics: 6th International Conference, BDA 2018, Warangal, India, December 18–21, 2018, Proceedings},
pages = {376–391},
numpages = {16},
keywords = {Distributed environment, Random forest, Ball bearing, Fault prediction, Spark, Parallel processing, Decision tree},
location = {Warangal, India}
}

@article{10.1002/smr.2238,
author = {Naeem, Muhammad Rashid and Lin, Tao and Naeem, Hamad and Liu, Hailu},
title = {A machine learning approach for classification of equivalent mutants},
year = {2020},
issue_date = {May 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {32},
number = {5},
issn = {2047-7473},
url = {https://doi.org/10.1002/smr.2238},
doi = {10.1002/smr.2238},
abstract = {Mutation testing is a fault‐based technique to test the quality of test suites by inducing artificial syntactic faults or mutants in a source program. However, some mutants have the same semantics as original program and cannot be detected by any test suite input known as equivalent mutants. Equivalent mutant problem (EMP) is undecidable as it requires manual human effort to identify a mutant as equivalent or killable. The constraint‐based testing (CBT) theory suggests the use of mathematical constraints which can help reveal some equivalent mutants using mutant features. In this paper, we consider three metrics of CBT theory, ie, reachability, necessity, and sufficiency to extract feature constraints from mutant programs. Constraints are extracted using program dependency graphs. Other features such as degree of significance, semantic distance, and information entropy of mutants are also extracted to build a binary classification model. Machine learning algorithms such as Random Forest, GBT, and SVM are applied under two application scenarios (split‐project and cross‐project) on ten Java programs to predict equivalent mutants. The analysis of the study demonstrates that that the proposed techniques not only improves the efficiency of the equivalent mutant detection but also reduces the effort required to perform it with small accuracy loss.},
journal = {J. Softw. Evol. Process},
month = apr,
numpages = {32},
keywords = {static analysis, program semantics, mutation testing, machine learning, equivalent mutants}
}

@article{10.1016/j.compeleceng.2021.107574,
author = {Rajpoot, Vikram and Garg, Lalit and Alam, M. Zahid and Sangeeta and Parashar, Vivek and Tapashetti, Pratibhadevi and Arjariya, Tripti},
title = {Analysis of machine learning based LEACH robust routing in the Edge Computing systems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {96},
number = {PB},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2021.107574},
doi = {10.1016/j.compeleceng.2021.107574},
journal = {Comput. Electr. Eng.},
month = dec,
numpages = {17},
keywords = {Independent RNN, LEACH routing protocol, Data Fusion Method, Machine learning, Edge Computing, Wireless sensor networks}
}

@inproceedings{10.1145/2372251.2372285,
author = {Giger, Emanuel and D'Ambros, Marco and Pinzger, Martin and Gall, Harald C.},
title = {Method-level bug prediction},
year = {2012},
isbn = {9781450310567},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2372251.2372285},
doi = {10.1145/2372251.2372285},
abstract = {Researchers proposed a wide range of approaches to build effective bug prediction models that take into account multiple aspects of the software development process. Such models achieved good prediction performance, guiding developers towards those parts of their system where a large share of bugs can be expected. However, most of those approaches predict bugs on file-level. This often leaves developers with a considerable amount of effort to examine all methods of a file until a bug is located. This particular problem is reinforced by the fact that large files are typically predicted as the most bug-prone. In this paper, we present bug prediction models at the level of individual methods rather than at file-level. This increases the granularity of the prediction and thus reduces manual inspection efforts for developers. The models are based on change metrics and source code metrics that are typically used in bug prediction. Our experiments---performed on 21 Java open-source (sub-)systems---show that our prediction models reach a precision and recall of 84% and 88%, respectively. Furthermore, the results indicate that change metrics significantly outperform source code metrics.},
booktitle = {Proceedings of the ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {171–180},
numpages = {10},
keywords = {method-level bug prediction, fine-grained source code changes, code metrics},
location = {Lund, Sweden},
series = {ESEM '12}
}

@article{10.1016/j.jss.2019.110486,
author = {Barbez, Antoine and Khomh, Foutse and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l},
title = {A machine-learning based ensemble method for anti-patterns detection},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {161},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.110486},
doi = {10.1016/j.jss.2019.110486},
journal = {J. Syst. Softw.},
month = mar,
numpages = {11},
keywords = {Ensemble methods, Machine learning, Anti-patterns, Software quality}
}

@article{10.1016/j.procs.2021.08.087,
author = {Wachulec, Ma\l{}gorzata and Luckner, Marcin},
title = {Fault detection of jet engine heat sensor},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {192},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.08.087},
doi = {10.1016/j.procs.2021.08.087},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {844–852},
numpages = {9},
keywords = {sister engines, time series, anomaly detection, outlier detection, oil temperature sensor}
}

@article{10.1007/s00500-020-05480-9,
author = {Venkatesh, R. and Balasubramanian, C. and Kaliappan, M.},
title = {RETRACTED ARTICLE: Rainfall prediction using
         generative adversarial networks with convolution neural network},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {6},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05480-9},
doi = {10.1007/s00500-020-05480-9},
abstract = {In recent days, deep learning becomes a successful approach to solving
            complex problems and analyzing the huge volume of data. The proposed system developed a
            rainfall prediction system using generative adversarial networks to analyze rainfall
            data of India and predict the future rainfall. The proposed system used a GAN network in
            which long short-term memory (LSTM) network algorithm is used as a generator and
            convolution neural network model is used as a discriminator. LSTM is much suitable to
            predict time series data such as rainfall data. The experimental results reveal that the
            proposed system provides the predicted results with 99% of accuracy. Rainfall prediction
            helps farmers to cultivate their crops and improved their economy as well as country’s
            economy.},
journal = {Soft Comput.},
month = mar,
pages = {4725–4738},
numpages = {14},
keywords = {Convolution neural network, Deep learning, Generative adversarial networks, Long short-term memory networks}
}

@inproceedings{10.1145/3377816.3381734,
author = {Byun, Taejoon and Rayadurgam, Sanjai},
title = {Manifold for machine learning assurance},
year = {2020},
isbn = {9781450371261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377816.3381734},
doi = {10.1145/3377816.3381734},
abstract = {The increasing use of machine-learning (ML) enabled systems in critical tasks fuels the quest for novel verification and validation techniques yet grounded in accepted system assurance principles. In traditional system development, model-based techniques have been widely adopted, where the central premise is that abstract models of the required system provide a sound basis for judging its implementation. We posit an analogous approach for ML systems using an ML technique that extracts from the high-dimensional training data implicitly describing the required system, a low-dimensional underlying structure---a manifold. It is then harnessed for a range of quality assurance tasks such as test adequacy measurement, test input generation, and runtime monitoring of the target ML system. The approach is built on variational autoencoder, an unsupervised method for learning a pair of mutually near-inverse functions between a given high-dimensional dataset and a low-dimensional representation. Preliminary experiments establish that the proposed manifold-based approach, for test adequacy drives diversity in test data, for test generation yields fault-revealing yet realistic test cases, and for run-time monitoring provides an independent means to assess trustability of the target system's output.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {97–100},
numpages = {4},
keywords = {variational autoencoder, neural networks, machine learning testing},
location = {Seoul, South Korea},
series = {ICSE-NIER '20}
}

@inproceedings{10.1109/ASE.2009.76,
author = {Shivaji, Shivkumar and Jr., E. James Whitehead and Akella, Ram and Kim, Sunghun},
title = {Reducing Features to Improve Bug Prediction},
year = {2009},
isbn = {9780769538914},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ASE.2009.76},
doi = {10.1109/ASE.2009.76},
abstract = {Recently, machine learning classifiers have emerged as a way to predict the existence of a bug in a change made to a source code file. The classifier is first trained on software history data, and then used to predict bugs. Two drawbacks of existing classifier-based bug prediction are potentially insufficient accuracy for practical use, and use of a large number of features. These large numbers of features adversely impact scalability and accuracy of the approach. This paper proposes a feature selection technique applicable to classification-based bug prediction. This technique is applied to predict bugs in software changes, and performance of Naive Bayes and Support Vector Machine (SVM) classifiers is characterized.},
booktitle = {Proceedings of the 24th IEEE/ACM International Conference on Automated Software Engineering},
pages = {600–604},
numpages = {5},
keywords = {Reliability, Machine Learning, Feature Selection, Bug prediction},
series = {ASE '09}
}

@article{10.1002/stvr.1570,
author = {Canfora, Gerardo and Lucia, Andrea De and Penta, Massimiliano Di and Oliveto, Rocco and Panichella, Annibale and Panichella, Sebastiano},
title = {Defect prediction as a multiobjective optimization problem},
year = {2015},
issue_date = {June 2015},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {25},
number = {4},
issn = {0960-0833},
url = {https://doi.org/10.1002/stvr.1570},
doi = {10.1002/stvr.1570},
abstract = {In this paper, we formalize the defect-prediction problem as a multiobjective optimization problem. Specifically, we propose an approach, coined as multiobjective defect predictor MODEP, based on multiobjective forms of machine learning techniques-logistic regression and decision trees specifically-trained using a genetic algorithm. The multiobjective approach allows software engineers to choose predictors achieving a specific compromise between the number of likely defect-prone classes or the number of defects that the analysis would likely discover effectiveness, and lines of code to be analysed/tested which can be considered as a proxy of the cost of code inspection. Results of an empirical evaluation on 10 datasets from the PROMISE repository indicate the quantitative superiority of MODEP with respect to single-objective predictors, and with respect to trivial baseline ranking classes by size in ascending or descending order. Also, MODEP outperforms an alternative approach for cross-project prediction, based on local prediction upon clusters of similar classes. Copyright © 2015John Wiley &amp; Sons, Ltd.},
journal = {Softw. Test. Verif. Reliab.},
month = jun,
pages = {426–459},
numpages = {34},
keywords = {multiobjective optimization, defect prediction, cross-project defect prediction, cost-effectiveness}
}

@article{10.1016/j.asoc.2016.08.025,
author = {Erturk, Ezgi and Akcapinar Sezer, Ebru},
title = {Iterative software fault prediction with a hybrid approach},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2016.08.025},
doi = {10.1016/j.asoc.2016.08.025},
abstract = {Display Omitted To make software fault prediction (SFP) more beneficial, it should be into service at the beginning of the project.A novel prediction methodology based on existing methods (i.e. FIS, ANN) are proposed here.Version based development of software projects are considered to design an iterative prediction approach.Proposed methodology is developed as Eclipse plugin.Experiments show that proposed methodology gives promising results to use SFP in daily routine of software development phases. In this study, we consider a software fault prediction task that can assist a developer during the lifetime of a project. We aim to improve the performance of software fault prediction task while keeping it as applicable. Initial predictions are constructed by Fuzzy Inference Systems (FISs), whereas subsequent predictions are performed by data-driven methods. In this paper, an Artificial Neural Network and Adaptive Neuro Fuzzy Inference System are employed. We propose an iterative prediction model that begins with a FIS when no data are available for the software project and continues with a data-driven method when adequate data become available. To prove the usability of this iterative prediction approach, software fault prediction experiments are performed using expert knowledge for the initial version and information about previous versions for subsequent versions. The datasets employed in this paper comprise different versions of Ant, jEdit, Camel, Xalan, Log4j and Lucene projects from the PROMISE repository. The metrics of the models are common object-oriented metrics, such as coupling between objects, weighted methods per class and response for a class. The results of the models are evaluated according to the receiver operating characteristics with the area under the curve approach. The results indicate that the iterative software fault prediction is successful and can be transformed into a tool that can automatically locate fault-prone modules due to its well-organized information flow. We also implement the proposed methodology as a plugin for the Eclipse environment.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {1020–1033},
numpages = {14},
keywords = {Software fault prediction, Iterative prediction, Fuzzy inference systems, Artificial neural network, Adaptive neuro fuzzy inference system}
}

@article{10.1016/j.asoc.2013.09.024,
author = {Zhou, Jing and Guo, Aihuang and Celler, Branko and Su, Steven},
title = {Fault detection and identification spanning multiple processes by integrating PCA with neural network},
year = {2014},
issue_date = {January, 2014},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {14},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2013.09.024},
doi = {10.1016/j.asoc.2013.09.024},
abstract = {This paper proposes an effective fault detection and identification method for systems which perform in multiple processes. One such type of system investigated in this paper is COSMED K4b^2. K4b^2 is a standard portable electrical device designed to test pulmonary functions in various applications, such as athlete training, sports medicine and health monitoring. However, its actual sensor outputs and received data may be disturbed by Electromagnetic Interference (EMI), body artifacts, and device malfunctions/faults, which might cause misinterpretations of activities or statuses to people being monitored. Although some research is reported to detect faults in specific steady state, normal approach may yield false alarms in multi-processes applications. In this paper, a novel and comprehensive method, which merges statistical analysis and intelligent computational model, is proposed to detect and identify faults of K4b^2 during exercise monitoring. Firstly the principal component analysis (PCA) is utilized to acquire main features of measured data and then K-means is combined to cluster various processes for abnormalities detection. When faults are detected, a back propagation (BP) neural network is constructed to identify and isolate faults. The effectiveness and feasibility of the proposed model method is finally verified with experimental data.},
journal = {Appl. Soft Comput.},
month = jan,
pages = {4–11},
numpages = {8},
keywords = {Principal component analysis, Fault detection and identification, Exercising monitoring, BP neural network}
}

@article{10.1007/s10664-015-9400-x,
author = {Kamei, Yasutaka and Fukushima, Takafumi and Mcintosh, Shane and Yamashita, Kazuhiro and Ubayashi, Naoyasu and Hassan, Ahmed E.},
title = {Studying just-in-time defect prediction using cross-project models},
year = {2016},
issue_date = {October   2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9400-x},
doi = {10.1007/s10664-015-9400-x},
abstract = {Unlike traditional defect prediction models that identify defect-prone modules, Just-In-Time (JIT) defect prediction models identify defect-inducing changes. As such, JIT defect models can provide earlier feedback for developers, while design decisions are still fresh in their minds. Unfortunately, similar to traditional defect models, JIT models require a large amount of training data, which is not available when projects are in initial development phases. To address this limitation in traditional defect prediction, prior work has proposed cross-project models, i.e., models learned from other projects with sufficient history. However, cross-project models have not yet been explored in the context of JIT prediction. Therefore, in this study, we empirically evaluate the performance of JIT models in a cross-project context. Through an empirical study on 11 open source projects, we find that while JIT models rarely perform well in a cross-project context, their performance tends to improve when using approaches that: (1) select models trained using other projects that are similar to the testing project, (2) combine the data of several other projects to produce a larger pool of training data, and (3) combine the models of several other projects to produce an ensemble model. Our findings empirically confirm that JIT models learned using other projects are a viable solution for projects with limited historical data. However, JIT models tend to perform best in a cross-project context when the data used to learn them are carefully selected.},
journal = {Empirical Softw. Engg.},
month = oct,
pages = {2072–2106},
numpages = {35},
keywords = {Just-in-time prediction, Empirical study, Defect prediction}
}

@article{10.1155/2020/6688075,
author = {Naseem, Rashid and Khan, Bilal and Ahmad, Arshad and Almogren, Ahmad and Jabeen, Saima and Hayat, Bashir and Shah, Muhammad Arif and Uddin, M. Irfan},
title = {Investigating Tree Family Machine Learning Techniques for a Predictive System to Unveil Software Defects},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1076-2787},
url = {https://doi.org/10.1155/2020/6688075},
doi = {10.1155/2020/6688075},
abstract = {Software defects prediction at the initial period of the software development life cycle remains a critical and important assignment. Defect prediction and correctness leads to the assurance of the quality of software systems and has remained integral to study in the previous years. The quick forecast of imperfect or defective modules in software development can serve the development squad to use the existing assets competently and effectively to provide remarkable software products in a given short timeline. Hitherto, several researchers have industrialized defect prediction models by utilizing statistical and machine learning techniques that are operative and effective approaches to pinpoint the defective modules. Tree family machine learning techniques are well-thought-out to be one of the finest and ordinarily used supervised learning methods. In this study, different tree family machine learning techniques are employed for software defect prediction using ten benchmark datasets. These techniques include Credal Decision Tree (CDT), Cost-Sensitive Decision Forest (CS-Forest), Decision Stump (DS), Forest by Penalizing Attributes (Forest-PA), Hoeffding Tree (HT), Decision Tree (J48), Logistic Model Tree (LMT), Random Forest (RF), Random Tree (RT), and REP-Tree (REP-T). Performance of each technique is evaluated using different measures, i.e., mean absolute error (MAE), relative absolute error (RAE), root mean squared error (RMSE), root relative squared error (RRSE), specificity, precision, recall, F-measure (FM), G-measure (GM), Matthew’s correlation coefficient (MCC), and accuracy. The overall outcomes of this paper suggested RF technique by producing best results in terms of reducing error rates as well as increasing accuracy on five datasets, i.e., AR3, PC1, PC2, PC3, and PC4. The average accuracy achieved by RF is 90.2238%. The comprehensive outcomes of this study can be used as a reference point for other researchers. Any assertion concerning the enhancement in prediction through any new model, technique, or framework can be benchmarked and verified.},
journal = {Complex.},
month = jan,
numpages = {21}
}

@inproceedings{10.1109/ESEM.2017.50,
author = {Bennin, Kwabena Ebo and Keung, Jacky and Monden, Akito and Phannachitta, Passakorn and Mensah, Solomon},
title = {The significant effects of data sampling approaches on software defect prioritization and classification},
year = {2017},
isbn = {9781509040391},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ESEM.2017.50},
doi = {10.1109/ESEM.2017.50},
abstract = {Context: Recent studies have shown that performance of defect prediction models can be affected when data sampling approaches are applied to unbalanced training data for building defect prediction models. However, the magnitude (degree and power) of the effect of these sampling methods on the classification and prioritization performances of defect prediction models is still unknown. Goal: To investigate the statistical and practical significance of using resampled data for constructing defect prediction models. Method: We examine the practical effects of six data sampling methods on performances of five defect prediction models. The prediction performances of the models trained on default datasets (no sampling method) are compared with that of the models trained on resampled datasets (application of sampling methods). To decide whether the performance changes are significant or not, robust statistical tests are performed and effect sizes computed. Twenty releases of ten open source projects extracted from the PROMISE repository are considered and evaluated using the AUC, pd, pf and G-mean performance measures. Results: There are statistical significant differences and practical effects on the classification performance (pd, pf and G-mean) between models trained on resampled datasets and those trained on the default datasets. However, sampling methods have no statistical and practical effects on defect prioritization performance (AUC) with small or no effect values obtained from the models trained on the resampled datasets. Conclusions: Existing sampling methods can properly set the threshold between buggy and clean samples, while they cannot improve the prediction of defect-proneness itself. Sampling methods are highly recommended for defect classification purposes when all faulty modules are to be considered for testing.},
booktitle = {Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {364–373},
numpages = {10},
keywords = {statistical significance, sampling methods, imbalanced data, empirical software engineering, defect prediction},
location = {Markham, Ontario, Canada},
series = {ESEM '17}
}

@article{10.1007/s11219-021-09563-0,
author = {G\"{u}demann, Matthias and Mariani, Leonardo},
title = {Preface to the special issue on improving software quality through program analysis},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-021-09563-0},
doi = {10.1007/s11219-021-09563-0},
abstract = {This special issue is dedicated to the presentation of novel results in the scope of program analysis, verification, and testing of software to improve its quality. The papers included in the special issue present approaches that successfully combine model-based test case generation, reasoning about functional equivalence, data mining, classification, and the combination of abstraction with model-checking, to address real software applications in realistic settings.},
journal = {Software Quality Journal},
month = sep,
pages = {595–596},
numpages = {2}
}

@inproceedings{10.1145/2908812.2908938,
author = {Panichella, Annibale and Alexandru, Carol V. and Panichella, Sebastiano and Bacchelli, Alberto and Gall, Harald C.},
title = {A Search-based Training Algorithm for Cost-aware Defect Prediction},
year = {2016},
isbn = {9781450342063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2908812.2908938},
doi = {10.1145/2908812.2908938},
abstract = {Research has yielded approaches to predict future defects in software artifacts based on historical information, thus assisting companies in effectively allocating limited development resources and developers in reviewing each others' code changes. Developers are unlikely to devote the same effort to inspect each software artifact predicted to contain defects, since the effort varies with the artifacts' size (cost) and the number of defects it exhibits (effectiveness). We propose to use Genetic Algorithms (GAs) for training prediction models to maximize their cost-effectiveness. We evaluate the approach on two well-known models, Regression Tree and Generalized Linear Model, and predict defects between multiple releases of six open source projects. Our results show that regression models trained by GAs significantly outperform their traditional counterparts, improving the cost-effectiveness by up to 240%. Often the top 10% of predicted lines of code contain up to twice as many defects.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference 2016},
pages = {1077–1084},
numpages = {8},
keywords = {machine learning, genetic algorithm, defect prediction},
location = {Denver, Colorado, USA},
series = {GECCO '16}
}

@article{10.1007/s11063-021-10569-9,
author = {Feng, Naiqin and Geng, Xiuqin and Sun, Bin},
title = {Study on Neural Network Integration Method Based on Morphological Associative Memory Framework},
year = {2021},
issue_date = {Dec 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {6},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-021-10569-9},
doi = {10.1007/s11063-021-10569-9},
abstract = {In traditional neural network integration, people adopt Boosting, Bagging and other methods to integrate traditional neural networks. The integration is complex, time-consuming and laborious, difficult to popularize and apply. This paper is not a continuation of this method, but another integration which is called by us morphological neural network integration (MNNI) or morphological associative memory integration (MAMI). These networks used in MAMI are a network family, with 10 family members, unified in the morphological associative memory framework. Various morphological associative memory networks can be directly used as individual networks to learn and work separately, and then synthesize to draw conclusions. The results of some experiments show that this method is not only feasible in theory, but also effective in practice. It can avoid the complexity of traditional integration method, make the integration structure simple and clear, easy to operate, save time, and therefore is a method of neural network integration with research and application value. The contribution of this paper lies in that: (1) it proposed the concept and method of MNNI and, (2) verified the effectiveness of MNNI through experiments and, (3) it has the characteristics of simplicity, saving time and labor and cost, with a good application prospect and, (4) thus promoting the development of morphological neural networks in theory and practice.},
journal = {Neural Process. Lett.},
month = dec,
pages = {3915–3945},
numpages = {31},
keywords = {Traditional neural network, Neural network integration, Morphological neural network, Morphological associative memory integration, Morphological associative memory framework}
}

@article{10.1007/s00521-021-06531-4,
author = {Liu, Haochen and Zhao, Yifan and Zaporowska, Anna and Skaf, Zakwan},
title = {A machine learning-based clustering approach to diagnose multi-component degradation of aircraft fuel systems},
year = {2021},
issue_date = {Feb 2023},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {35},
number = {4},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-06531-4},
doi = {10.1007/s00521-021-06531-4},
abstract = {Accurate fault diagnosis and prognosis can significantly reduce maintenance costs, increase the safety and availability of engineering systems that have become increasingly complex. It has been observed that very limited researches have been reported on fault diagnosis where multi-component degradation are presented. This is essentially a challenging Complex Systems problem where features multiple components interacting simultaneously and nonlinearly with each other and its environment on multiple levels. Even the degradation of a single component can lead to a misidentification of the fault severity level. This paper introduces a new test rig to simulate the multi-component degradation of the aircraft fuel system. A machine learning-based data analytical approach based on the classification of clustering features from both time and frequency domains is proposed. The scope of this framework is the identification of the location and severity of not only the system fault but also the multi-component degradation. The results illustrate that (a) the fault can be detected with accuracy &gt; 99%; (b) the severity of fault can be identified with an accuracy of almost 100%; (c) the degradation level can be successfully identified with the R-square value &gt; 0.9.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {2973–2989},
numpages = {17},
keywords = {Multi-component degradation, Fault diagnosis, Clustering analysis, Fast Fourier transform}
}

@article{10.3233/JIFS-191627,
author = {Taimoor, Muhammad and Aijun, Li},
title = {Adaptive strategy for fault detection, isolation and reconstruction of aircraft actuators and sensors},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {38},
number = {4},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-191627},
doi = {10.3233/JIFS-191627},
abstract = {An online fault detection, isolation, and reconstruction strategy is proposed for actuators and sensors fault detection of an aircraft. For increasing the fault detection capabilities, the Extended Kalman Filter (EKF) is used for the weight updating parameters of multi-layer perceptron (MLP) neural network. The main purpose of using the EKF is to make the weight updating parameters of MLP adaptive in order to increase the fault detection, isolation and reconstruction preciseness, efficiency and rapidness compared to the conventional MLP where the fixed learning rate due to which it has slow response to faults occurrence. Because of the online adaptation of weighting parameters of MLP, the preciseness of the faults detection is increased. For testing and validation of the proposed strategy, the nonlinear dynamics of Boeing 747 100/200 are used. Results demonstrate that the proposed strategy has better accuracy and rapid response to fault detection compared to convention multi-layer perceptron neural network based faults detection schemes.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {4993–5012},
numpages = {20},
keywords = {nonlinear systems, neural networks, aircraft, fault detection and isolation, sensors, Actuators}
}

@inproceedings{10.1145/3368089.3417043,
author = {Ahmed, Md Sohel and Ishikawa, Fuyuki and Sugiyama, Mahito},
title = {Testing machine learning code using polyhedral region},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3417043},
doi = {10.1145/3368089.3417043},
abstract = {To date, although machine learning has been successful in various practical applications, generic methods of testing machine learning code have not been established yet. Here we present a new approach to test machine learning code using the possible input region obtained as a polyhedron. If an ML system generates different output for multiple input in the polyhedron, it is ensured that there exists a bug in the code. This property is known as one of theoretical fundamentals in statistical inference, for example, sparse regression models such as the lasso, and a wide range of machine learning algorithms satisfy this polyhedral condition, to which our testing procedure can be applied. We empirically show that the existence of bugs in lasso code can be effectively detected by our method in the mutation testing framework.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1533–1536},
numpages = {4},
keywords = {Testing, Polyhedral region, Mutation Analysis, Machine learning code, Lasso},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@phdthesis{10.5555/2520283,
author = {Shivaji, Shivkumar},
advisor = {Whitehead, E. James},
title = {Efficient bug prediction and fix suggestions},
year = {2013},
isbn = {9781303021435},
publisher = {University of California at Santa Cruz},
address = {USA},
abstract = {Bugs are a well known Achilles' heel of software development. In the last few years, machine learning techniques to combat software bugs have become popular. However, results of these techniques are not good enough for practical adoption. In addition, most techniques do not provide reasons for why a code change is a bug. Furthermore, suggestions to fix the bug would be greatly beneficial. An added bonus would be engaging humans to improve the bug and fix prediction process. In this dissertation, a step-by-step procedure which effectively predicts buggy code changes (Bug Prognosticator), produces bug fix suggestions (Fix Suggester), and utilizes human feedback is presented. Each of these steps can be used independently, but combining them allows more effective management of bugs. These techniques are tested on many open source and a large commercial project. Human feedback was used to understand and improve the performance of the techniques. Feedback was primarily gathered from industry participants in order to assess practical suitability. The Bug Prognosticator explores feature selection techniques and classifiers to improve results of code change bug prediction. The optimized Bug Prognosticator is able to achieve an average 97% precision and 70% recall when evaluated on eleven projects, ten open source and one commercial. The Fix Suggester uses the Bug Prognosticator and statistical analysis of keyword term frequencies to suggest unordered fix keywords to a code change predicted to be buggy. The suggestions are validated against actual bug fixes to confirm their utility. The Fix Suggester is able to achieve 46.9% precision and 38.9% recall on its predicted fix tokens. This is a reasonable start to the difficult problem of predicting the contents of a bug fix. To improve the efficiency of the Bug Prognosticator and the Fix Suggester, active learning is employed on willing human participants. Developers aid the Bug Prognosticator and the Fix Suggester on code changes that machines find hard to evaluate. The developer's feedback is used to enhance the performance of the Bug Prognosticator and the Fix Suggester. In addition, a user study is performed to gauge the utility of the Fix Suggester. The dissertation concludes with a discussion of future work and challenges faced by the techniques. Given the success of statistical defect prediction techniques, more industrial exposure would benefit researchers and software practitioners.},
note = {AAI3558011}
}

@article{10.1016/j.inffus.2019.12.001,
author = {Meng, Tong and Jing, Xuyang and Yan, Zheng and Pedrycz, Witold},
title = {A survey on machine learning for data fusion},
year = {2020},
issue_date = {May 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {57},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2019.12.001},
doi = {10.1016/j.inffus.2019.12.001},
journal = {Inf. Fusion},
month = may,
pages = {115–129},
numpages = {15},
keywords = {Fusion criteria, Fusion methods, Machine learning, Data fusion}
}

@article{10.4018/IJITSA.2021010104,
author = {Shatnawi, Raed and Mishra, Alok},
title = {An Empirical Study on Software Fault Prediction Using Product and Process Metrics},
year = {2021},
issue_date = {Jan 2021},
publisher = {IGI Global},
address = {USA},
volume = {14},
number = {1},
issn = {1935-570X},
url = {https://doi.org/10.4018/IJITSA.2021010104},
doi = {10.4018/IJITSA.2021010104},
abstract = {Product and process metrics are measured from the development and evolution of software. Metrics are indicators of software fault-proneness and advanced models using machine learning can be provided to the development team to select modules for further inspection. Most fault-proneness classifiers were built from product metrics. However, the inclusion of process metrics adds evolution as a factor to software quality. In this work, the authors propose a process metric measured from the evolution of software to predict fault-proneness in software models. The process metrics measures change-proneness of modules (classes and interfaces). Classifiers are trained and tested for five large open-source systems. Classifiers were built using product metrics alone and using a combination of product and the proposed process metric. The classifiers evaluation shows improvements whenever the process metrics were used. Evolution metrics are correlated with quality of software and helps in improving software quality prediction for future releases.},
journal = {Int. J. Inf. Technol. Syst. Appoach},
month = jan,
pages = {62–78},
numpages = {17},
keywords = {Software Fault, Product Metrics, Process Metrics, CK Metrics}
}

@article{10.1016/j.rcim.2015.11.006,
author = {Fernando, Heshan and Surgenor, Brian},
title = {An unsupervised artificial neural network versus a rule-based approach for fault detection and identification in an automated assembly machine},
year = {2017},
issue_date = {February 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {43},
number = {C},
issn = {0736-5845},
url = {https://doi.org/10.1016/j.rcim.2015.11.006},
doi = {10.1016/j.rcim.2015.11.006},
abstract = {Artificial neural networks (ANNs) are suitable for fault detection and identification (FDI) applications because of their pattern recognition abilities. In this study, an unsupervised ANN based on Adaptive Resonance Theory (ART) is tested for FDI on an automated O-ring assembly machine testbed, and its performance and practicality are compared to a conventional rule-based method. Three greyscale sensors and two redundant limit switches are used as cost-effective sensors to monitor the machine's assembly process. Sensor data are collected while the machine is operated under normal condition, as well as 10 fault conditions. Features are selected from the raw sensor data, and data sets are created for training and testing the ANN. The performance of the ANN for detecting and identifying known, unknown and multiple faults is evaluated; the performance is compared to a conventional rule-based method using the same data sets. Results show that the ART ANN is able to achieve excellent fault detection performance with minimal modeling requirements; however, the performance depends on careful tuning of its vigilance parameter. Although the rule-based system requires more effort to set up, it is judged to be more useful when unknown or multiple faults are present. The ART network creates new outputs for unknown and multiple fault conditions, but it does not give any more information as to what the new fault is. By contrast, the rule-based method is able to generate symptoms that clearly identify the unknown and multiple fault conditions. Thus, the rule-based method is judged to be the most feasible method for FDI applications.},
journal = {Robot. Comput.-Integr. Manuf.},
month = feb,
pages = {79–88},
numpages = {10},
keywords = {Fault identification, Fault detection, Assembly automation, Artificial neural networks}
}

@inproceedings{10.1145/3368089.3409723,
author = {She, Dongdong and Krishna, Rahul and Yan, Lu and Jana, Suman and Ray, Baishakhi},
title = {MTFuzz: fuzzing with a multi-task neural network},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409723},
doi = {10.1145/3368089.3409723},
abstract = {Fuzzing is a widely used technique for detecting software bugs and vulnerabilities. Most popular fuzzers generate new inputs using an evolutionary search to maximize code coverage. Essentially, these fuzzers start with a set of seed inputs, mutate them to generate new inputs, and identify the promising inputs using an evolutionary fitness function for further mutation.Despite their success, evolutionary fuzzers tend to get stuck in long sequences of unproductive mutations. In recent years, machine learning (ML) based mutation strategies have reported promising results. However, the existing ML-based fuzzers are limited by the lack of quality and diversity of the training data. As the input space of the target programs is high dimensional and sparse, it is prohibitively expensive to collect many diverse samples demonstrating successful and unsuccessful mutations to train the model.In this paper, we address these issues by using a Multi-Task Neural Network that can learn a compact embedding of the input space based on diverse training samples for multiple related tasks (i.e.,predicting for different types of coverage). The compact embedding can guide the mutation process by focusing most of the mutations on the parts of the embedding where the gradient is high. MTFuzz uncovers 11 previously unseen bugs and achieves an average of 2\texttimes{} more edge coverage compared with 5 state-of-the-art fuzzer on 10 real-world programs},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {737–749},
numpages = {13},
keywords = {Multi-task learning, Machine learning, Fuzzing},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/3472163.3472172,
author = {Wiese, Lena and Wiese, Ingmar and Lietz, Kristina},
title = {Software Quality Assessment of a Web Application for Biomedical Data Analysis},
year = {2021},
isbn = {9781450389914},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472163.3472172},
doi = {10.1145/3472163.3472172},
abstract = {Data Science as a multidisciplinary discipline has seen a massive transformation in the direction of operationalisation of analysis workflows. Yet it can be observed that such a workflow consists of potentially many diverse components: like modules in different programming languages, database backends, or web frontends. In order to achieve high efficiency and reproducibility of the analysis, a sufficiently high level of software engineering for the different components as well as an overall software architecture that integrates and automates the different components is needed. For the use case of gene expression analysis, from a software quality point of view we analyze a newly developed web application that allows user-friendly access to the underlying workflow.},
booktitle = {Proceedings of the 25th International Database Engineering &amp; Applications Symposium},
pages = {84–93},
numpages = {10},
keywords = {Web service, Software quality, Gene expression analysis, Data Science workflow},
location = {Montreal, QC, Canada},
series = {IDEAS '21}
}

@inproceedings{10.1145/3387906.3388618,
author = {Cruz, Daniel and Santana, Amanda and Figueiredo, Eduardo},
title = {Detecting bad smells with machine learning algorithms: an empirical study},
year = {2020},
isbn = {9781450379601},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387906.3388618},
doi = {10.1145/3387906.3388618},
abstract = {Bad smells are symptoms of bad design choices implemented on the source code. They are one of the key indicators of technical debts, specifically, design debt. To manage this kind of debt, it is important to be aware of bad smells and refactor them whenever possible. Therefore, several bad smell detection tools and techniques have been proposed over the years. These tools and techniques present different strategies to perform detections. More recently, machine learning algorithms have also been proposed to support bad smell detection. However, we lack empirical evidence on the accuracy and efficiency of these machine learning based techniques. In this paper, we present an evaluation of seven different machine learning algorithms on the task of detecting four types of bad smells. We also provide an analysis of the impact of software metrics for bad smell detection using a unified approach for interpreting the models' decisions. We found that with the right optimization, machine learning algorithms can achieve good performance (F1 score) for two bad smells: God Class (0.86) and Refused Parent Bequest (0.67). We also uncovered which metrics play fundamental roles for detecting each bad smell.},
booktitle = {Proceedings of the 3rd International Conference on Technical Debt},
pages = {31–40},
numpages = {10},
keywords = {software quality, software measurement, machine learning, empirical software engineering, bad smells detection},
location = {Seoul, Republic of Korea},
series = {TechDebt '20}
}

@article{10.1007/s00500-020-05197-9,
author = {Kamaraj, K. and Arvind, C. and Srihari, K.},
title = {A weight optimized artificial neural network for automated software test oracle},
year = {2020},
issue_date = {Sep 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {17},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05197-9},
doi = {10.1007/s00500-020-05197-9},
abstract = {Software testing has its main goal as designing new test case sets in a manner in which it is able to depict its maximum faults. As soon as these test cases have been designed, Oracle software provides a method in which the software has to behave for a particular test case given. Prioritization of such test cases with the execution of their components specifying inputs, their operation and their outcome will determine as to whether the application and their properties are working in the right manner. The prioritization methods are as follows: initial ordering, random ordering and finally reverse ordering that were based on fault detection abilities. For developing software applications, a test suite that was less commonly known as the suite for checking the validity of software was employed. The test suite contained a detailed set of instructions and goals for each test case collection based on the system and its configuration used during testing. Automating the generation of a test case and test oracle was researched in an extensive manner. From among the automated test oracle, the artificial neural network (ANN) was used extensively but with a high cost of computation. This work proposed a weight optimized ANN using stochastic diffusion search to find the optimal weights with a unique fitness function such that computational time is reduced and misclassification rate reduced.},
journal = {Soft Comput.},
month = sep,
pages = {13501–13511},
numpages = {11},
keywords = {Stochastic diffusion search, Test oracle, Test cases, Software testing, Soft computing, Neural science, Artificial neural network, Evolutionary algorithms}
}

@article{10.3103/S0147688221060046,
author = {Gibadullin, R. F. and Lekomtsev, D. V. and Perukhin, M. Y.},
title = {Analysis of Industrial Network Parameters Using Neural Network Processing},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {48},
number = {6},
issn = {0147-6882},
url = {https://doi.org/10.3103/S0147688221060046},
doi = {10.3103/S0147688221060046},
journal = {Sci. Tech. Inf. Process.},
month = dec,
pages = {446–451},
numpages = {6},
keywords = {data preprocessing, machine learning, artificial neural networks, network diagnostics, Industrial Ethernet, PROFINET}
}

@article{10.1007/s10664-011-9173-9,
author = {D'Ambros, Marco and Lanza, Michele and Robbes, Romain},
title = {Evaluating defect prediction approaches: a benchmark and an extensive comparison},
year = {2012},
issue_date = {August    2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4–5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-011-9173-9},
doi = {10.1007/s10664-011-9173-9},
abstract = {Reliably predicting software defects is one of the holy grails of software engineering. Researchers have devised and implemented a plethora of defect/bug prediction approaches varying in terms of accuracy, complexity and the input data they require. However, the absence of an established benchmark makes it hard, if not impossible, to compare approaches. We present a benchmark for defect prediction, in the form of a publicly available dataset consisting of several software systems, and provide an extensive comparison of well-known bug prediction approaches, together with novel approaches we devised. We evaluate the performance of the approaches using different performance indicators: classification of entities as defect-prone or not, ranking of the entities, with and without taking into account the effort to review an entity. We performed three sets of experiments aimed at (1) comparing the approaches across different systems, (2) testing whether the differences in performance are statistically significant, and (3) investigating the stability of approaches across different learners. Our results indicate that, while some approaches perform better than others in a statistically significant manner, external validity in defect prediction is still an open problem, as generalizing results to different contexts/learners proved to be a partially unsuccessful endeavor.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {531–577},
numpages = {47},
keywords = {Source code metrics, Defect prediction, Change metrics}
}

@inproceedings{10.1145/2528228.2528238,
author = {Muthukumaran, K. and Murthy, N. L. Bhanu and Reddy, G. Karthik and Aruna, M.},
title = {Comparative study on effectiveness of standard bug prediction approaches},
year = {2013},
isbn = {9781450323208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2528228.2528238},
doi = {10.1145/2528228.2528238},
abstract = {Bug prediction research has been evolving quite rapidly but its applicability to IT industry is far from reality. The efficacy of object oriented metrics in bug prediction has been investigated in this work by evaluating the performance of bug prediction models built with various combinations of these metrics. The module-order models have been built using object oriented metrics and the limitations of standard measures like recall in evaluating the performance of bug prediction models have been exposed.},
booktitle = {Proceedings of the 5th IBM Collaborative Academia Research Exchange Workshop},
articleno = {9},
numpages = {4},
keywords = {module-order model, classification, bug prediction},
location = {New Delhi, India},
series = {I-CARE '13}
}

@article{10.1007/s10664-015-9376-6,
author = {Herzig, Kim and Just, Sascha and Zeller, Andreas},
title = {The impact of tangled code changes on defect prediction models},
year = {2016},
issue_date = {April     2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-015-9376-6},
doi = {10.1007/s10664-015-9376-6},
abstract = {When interacting with source control management system, developers often commit unrelated or loosely related code changes in a single transaction. When analyzing version histories, such tangled changes will make all changes to all modules appear related, possibly compromising the resulting analyses through noise and bias. In an investigation of five open-source Java projects, we found between 7 % and 20 % of all bug fixes to consist of multiple tangled changes. Using a multi-predictor approach to untangle changes, we show that on average at least 16.6 % of all source files are incorrectly associated with bug reports. These incorrect bug file associations seem to not significantly impact models classifying source files to have at least one bug or no bugs. But our experiments show that untangling tangled code changes can result in more accurate regression bug prediction models when compared to models trained and tested on tangled bug datasets--in our experiments, the statistically significant accuracy improvements lies between 5 % and 200 %. We recommend better change organization to limit the impact of tangled changes.},
journal = {Empirical Softw. Engg.},
month = apr,
pages = {303–336},
numpages = {34},
keywords = {Untangling, Defect prediction, Data noise}
}

@article{10.1016/j.asoc.2019.105526,
author = {Yan, Shifu and Yan, Xuefeng},
title = {Design teacher and supervised dual stacked auto-encoders for quality-relevant fault detection in industrial process},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {81},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2019.105526},
doi = {10.1016/j.asoc.2019.105526},
journal = {Appl. Soft Comput.},
month = aug,
numpages = {8},
keywords = {Stacked auto-encoder, Quality-relevant, Fault detection, Deep neural network}
}

@article{10.4018/IJSI.2021070105,
author = {Jo, Jun-Hyuk and Lee, Jihyun and Jaffari, Aman and Kim, Eunmi},
title = {Fault Localization With Data Flow Information and an Artificial Neural Network},
year = {2021},
issue_date = {Jul 2021},
publisher = {IGI Global},
address = {USA},
volume = {9},
number = {3},
issn = {2166-7160},
url = {https://doi.org/10.4018/IJSI.2021070105},
doi = {10.4018/IJSI.2021070105},
abstract = {Fault localization is a technique for identifying the exact source code line with faults. It typically requires a lot of time and cost because, to locate the fault, a developer must track the execution of the failed program line by line. To reduce the fault localization efforts, many methods have been proposed. However, their localized suspicious code range is wide, and their fault localization effect is not high. To cope with this limitation, this paper computes the degree of fault suspiciousness of statements by using an artificial neural network and information of the executed test case, such as statement coverage, execution result, and definition-use pair. Compared to the approach that uses only statement coverage as input data for training an artificial neural network, the experiment results show higher accuracy in 15 types of faults out of 29 real fault types in the approach that the definition-use pair included.},
journal = {Int. J. Softw. Innov.},
month = jul,
pages = {66–78},
numpages = {13},
keywords = {Software Verification, Software Testing, Fault Suspiciousness, Fault Localization, Du-Pair, Definition-Use, Data Flow Coverage, Artificial Neural Network}
}

@article{10.1016/j.engappai.2019.04.010,
author = {Dong, Yiqun},
title = {Implementing Deep Learning for comprehensive aircraft icing and actuator/sensor fault detection/identification},
year = {2019},
issue_date = {Aug 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {83},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2019.04.010},
doi = {10.1016/j.engappai.2019.04.010},
journal = {Eng. Appl. Artif. Intell.},
month = aug,
pages = {28–44},
numpages = {17},
keywords = {Sensor fault detection, Icing detection and identification, Actuator fault detection and identification, Deep Learning}
}

@article{10.1016/j.neucom.2018.12.041,
author = {Plakias, Spyridon and Boutalis, Yiannis S.},
title = {Exploiting the generative adversarial framework for one-class multi-dimensional fault detection},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {332},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.12.041},
doi = {10.1016/j.neucom.2018.12.041},
journal = {Neurocomput.},
month = mar,
pages = {396–405},
numpages = {10},
keywords = {Generative Adversarial Networks, Fault detection, Anomaly detection, Deep learning}
}

@article{10.1007/s10723-021-09546-2,
author = {Zamani, Ghazal and Das, Olivia},
title = {Fault-Detection Managers: More May Not Be the Merrier: Fault-detection Managers: More may not be the merrier},
year = {2021},
issue_date = {Mar 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {19},
number = {1},
issn = {1570-7873},
url = {https://doi.org/10.1007/s10723-021-09546-2},
doi = {10.1007/s10723-021-09546-2},
abstract = {A fault management system contains managers that detect faults as well as initiate recovery actions. Such management systems often come in an architecture that is not only a distributed one but also decoupled from the applications. Although an arrangement like this promotes scalability, it unfortunately makes the recovery of applications dependent on the fault management system itself. This work introduces two novel equations to meet the performance objectives of applications. To this end, we first create an equation that estimates the maximum number of jobs to be handled by an application instance for meeting a given performance objective. This formula is then used by admission control mechanism to restrict the number of jobs (targeted for operational application instances) to be allowed to enter the system. Next, we create a second equation that computes the response time distribution of an application. Thereafter, we develop a simulation model that predicts the impact of the failure of four sample fault management architectures on application’s performance. Exploiting our equations, we compare the architectures in terms of three distinct ways of handling affected jobs when application instances fail—allow job loss; retry jobs resulting in overload; employ admission control to mitigate the overload. Our simulation results show that boosting the number of managers may not always be beneficial; rather, it could possibly be the interconnection topology (i.e. the layout of interconnects linking the architectural components) of the management architecture, together with the model parameter values that may sometimes have a bigger role to play in the application’s performance.},
journal = {J. Grid Comput.},
month = mar,
numpages = {19},
keywords = {Modeling, Fault management architecture, Job retry, Resource overload, Admission control, Model parameter values}
}

@article{10.1007/s11390-020-9668-1,
author = {Elmidaoui, Sara and Cheikhi, Laila and Idri, Ali and Abran, Alain},
title = {Machine Learning Techniques for Software Maintainability Prediction: Accuracy Analysis},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {35},
number = {5},
issn = {1000-9000},
url = {https://doi.org/10.1007/s11390-020-9668-1},
doi = {10.1007/s11390-020-9668-1},
abstract = {Maintaining software once implemented on the end-user side is laborious and, over its lifetime, is most often considerably more expensive than the initial software development. The prediction of software maintainability has emerged as an important research topic to address industry expectations for reducing costs, in particular, maintenance costs. Researchers and practitioners have been working on proposing and identifying a variety of techniques ranging from statistical to machine learning (ML) for better prediction of software maintainability. This review has been carried out to analyze the empirical evidence on the accuracy of software product maintainability prediction (SPMP) using ML techniques. This paper analyzes and discusses the findings of 77 selected studies published from 2000 to 2018 according to the following criteria: maintainability prediction techniques, validation methods, accuracy criteria, overall accuracy of ML techniques, and the techniques offering the best performance. The review process followed the well-known systematic review process. The results show that ML techniques are frequently used in predicting maintainability. In particular, artificial neural network (ANN), support vector machine/regression (SVM/R), regression &amp; decision trees (DT), and fuzzy &amp; neuro fuzzy (FNF) techniques are more accurate in terms of PRED and MMRE. The N-fold and leave-one-out cross-validation methods, and the MMRE and PRED accuracy criteria are frequently used in empirical studies. In general, ML techniques outperformed non-machine learning techniques, e.g., regression analysis (RA) techniques, while FNF outperformed SVM/R, DT, and ANN in most experiments. However, while many techniques were reported superior, no specific one can be identified as the best.},
journal = {J. Comput. Sci. Technol.},
month = oct,
pages = {1147–1174},
numpages = {28},
keywords = {maintainability prediction, machine learning technique, accuracy value, accuracy criterion}
}

@inproceedings{10.1145/3340482.3342746,
author = {Viuginov, Nickolay and Filchenkov, Andrey},
title = {A machine learning based automatic folding of dynamically typed languages},
year = {2019},
isbn = {9781450368551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340482.3342746},
doi = {10.1145/3340482.3342746},
abstract = {The popularity of dynamically typed languages has been growing strongly lately. Elegant syntax of such languages like javascript, python, PHP and ruby pays back when it comes to finding bugs in large codebases. The analysis is hindered by specific capabilities of dynamically typed languages, such as defining methods dynamically and evaluating string expressions. For finding bugs or investigating unfamiliar classes and libraries in modern IDEs and text editors features for folding unimportant code blocks are implemented. In this work, data on user foldings from real projects were collected and two classifiers were trained on their basis. The input to the classifier is a set of parameters describing the structure and syntax of the code block. These classifiers were subsequently used to identify unimportant code fragments. The implemented approach was tested on JavaScript and Python programs and compared with the best existing algorithm for automatic code folding.},
booktitle = {Proceedings of the 3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation},
pages = {31–36},
numpages = {6},
keywords = {Source code analysis, Python, JavaScript, Dynamically typed languages, Automatic Folding, Abstract Syntax tree},
location = {Tallinn, Estonia},
series = {MaLTeSQuE 2019}
}

@inproceedings{10.1145/3358331.3358376,
author = {Easttom, Chuck},
title = {A Methodological Approach to Weaponizing Machine Learning},
year = {2019},
isbn = {9781450372022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3358331.3358376},
doi = {10.1145/3358331.3358376},
abstract = {The current literature is replete with studies involving the use of machine learning algorithms for defensive security implementations. For example, machine learning has been utilized to enhance antivirus software and intrusion detection systems. The use of machine learning in defensive cybersecurity operations is well documented. However, there is a substantial gap in the literature on the offensive use of machine learning. Particularly, use of machine learning algorithms to enhance cyber warfare operations. Cyber components to modern conflicts, whether those conflicts are cyber or kinetic warfare, are a fact of the modern international political landscape. It is a natural progression to explore applications of machine learning to cyber warfare, particularly weaponized malware.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Advanced Manufacturing},
articleno = {45},
numpages = {5},
keywords = {weaponized malware, machine learning, cyber warfare, Weaponized malware},
location = {Dublin, Ireland},
series = {AIAM 2019}
}

@inproceedings{10.5555/2819009.2819026,
author = {Tan, Ming and Tan, Lin and Dara, Sashank and Mayeux, Caleb},
title = {Online defect prediction for imbalanced data},
year = {2015},
publisher = {IEEE Press},
abstract = {Many defect prediction techniques are proposed to improve software reliability. Change classification predicts defects at the change level, where a change is the modifications to one file in a commit. In this paper, we conduct the first study of applying change classification in practice.We identify two issues in the prediction process, both of which contribute to the low prediction performance. First, the data are imbalanced---there are much fewer buggy changes than clean changes. Second, the commonly used cross-validation approach is inappropriate for evaluating the performance of change classification. To address these challenges, we apply and adapt online change classification, resampling, and updatable classification techniques to improve the classification performance.We perform the improved change classification techniques on one proprietary and six open source projects. Our results show that these techniques improve the precision of change classification by 12.2-89.5% or 6.4--34.8 percentage points (pp.) on the seven projects. In addition, we integrate change classification in the development process of the proprietary project. We have learned the following lessons: 1) new solutions are needed to convince developers to use and believe prediction results, and prediction results need to be actionable, 2) new and improved classification algorithms are needed to explain the prediction results, and insensible and unactionable explanations need to be filtered or refined, and 3) new techniques are needed to improve the relatively low precision.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {99–108},
numpages = {10},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3368089.3418538,
author = {\v{C}egi\v{n}, J\'{a}n},
title = {Machine learning based test data generation for safety-critical software},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3418538},
doi = {10.1145/3368089.3418538},
abstract = {Unit testing focused on Modified Condition/Decision Coverage (MC/DC) criterion is essential in development safety-critical systems. However, design of test data that meets the MC/DC criterion currently needs detailed manual analysis of branching conditions in units under test by test engineers. Multiple state-of-art approaches exist with proven usage even in industrial projects. However, these approaches have multiple shortcomings, one of them being the Path explosion problem which has not been fully solved yet. Machine learning methods as meta-heuristic approximations can model behaviour of programs that are hard to test using traditional approaches, where the Path explosion problem does occur and thus could solve the limitations of the current state-of-art approaches. I believe, motivated by an ongoing collaboration with an industrial partner, that the machine learning methods could be combined with existing approaches to produce an approach suitable for testing of safety-critical projects.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1678–1681},
numpages = {4},
keywords = {unit testing, test data generation, machine learning, MC/DC criterion},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1145/2786805.2804429,
author = {Kim, Mijung and Nam, Jaechang and Yeon, Jaehyuk and Choi, Soonhwang and Kim, Sunghun},
title = {REMI: defect prediction for efficient API testing},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2804429},
doi = {10.1145/2786805.2804429},
abstract = {Quality assurance for common APIs is important since the the reliability of APIs affects the quality of other systems using the APIs. Testing is a common practice to ensure the quality of APIs, but it is a challenging and laborious task especially for industrial projects. Due to a large number of APIs with tight time constraints and limited resources, it is hard to write enough test cases for all APIs. To address these challenges, we present a novel technique, REMI that predicts high risk APIs in terms of producing potential bugs. REMI allows developers to write more test cases for the high risk APIs. We evaluate REMI on a real-world industrial project, Tizen-wearable, and apply REMI to the API development process at Samsung Electronics. Our evaluation results show that REMI predicts the bug-prone APIs with reasonable accuracy (0.681 f-measure on average). The results also show that applying REMI to the Tizen-wearable development process increases the number of bugs detected, and reduces the resources required for executing test cases.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {990–993},
numpages = {4},
keywords = {Quality Assurance, Defect Prediction, API Testing},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@inproceedings{10.5555/3432601.3432605,
author = {Krishnakumar, Sanjena and Abdou, Tamer},
title = {Towards interpretable and maintainable supervised learning using shapley values in arrhythmia},
year = {2020},
publisher = {IBM Corp.},
address = {USA},
abstract = {This paper investigates the application of a model-agnostic interpretability technique, Shapley Additive Explanations (SHAP), to understand and hence, enhance machine learning classification models using Shapley values in the prediction of arrhythmias1. Using the Arrhythmia dataset2, three different feature selection techniques, Information Gain (IG), Recursive Feature Elimination-Random Forest (RFE-RF), and AutoSpearman, were used to select features for machine learning models to predict the arrhythmia class. Four multi-class classification models, Na\"{\i}ve Bayes (NB), k-Nearest Neighbours (kNN), Random Forest (RF), and stacking heterogeneous ensemble (Ensemble) were built, evaluated, and compared. SHAP interpretation method was applied to find reliable explanations for the predictions of the classification models. Additionally, SHAP values were used to find `bellwether' instances to enhance the training of our models in order to improve their performances in the prediction of arrhythmia. The most stable and top-performing classification model was RF, followed by Ensemble in comparison to NB and kNN. SHAP provided robust and reliable explanations for the classification models. Furthermore, improving the training of our models with `bellwether' instances, found using SHAP values, enhanced the overall model performances in terms of accuracy, AUC, and F1 score. In conclusion, we recommend using SHAP value explanations as a robust and reliable method for local model-agnostic interpretability and to enhance machine learning models for arrhythmia prediction.},
booktitle = {Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering},
pages = {23–32},
numpages = {10},
keywords = {shapley value, multi-class classification, machine learning, local model-agnostic interpretation, healthcare, bellwether, arrhythmia, SHAP, LIME},
location = {Toronto, Ontario, Canada},
series = {CASCON '20}
}

@article{10.1016/j.aei.2021.101312,
author = {Xu, Yubo and Liu, Jie},
title = {High-speed train fault detection with unsupervised causality-based feature extraction methods},
year = {2021},
issue_date = {Aug 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2021.101312},
doi = {10.1016/j.aei.2021.101312},
journal = {Adv. Eng. Inform.},
month = aug,
numpages = {10},
keywords = {Directed acyclic graph, Anomaly detection, Feature extraction, Causality analysis, High-speed train}
}

@inproceedings{10.1109/ICSE43902.2021.00138,
author = {Wang, Song and Shrestha, Nishtha and Subburaman, Abarna Kucheri and Wang, Junjie and Wei, Moshi and Nagappan, Nachiappan},
title = {Automatic Unit Test Generation for Machine Learning Libraries: How Far Are We?},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00138},
doi = {10.1109/ICSE43902.2021.00138},
abstract = {Automatic unit test generation that explores the input space and produces effective test cases for given programs have been studied for decades. Many unit test generation tools that can help generate unit test cases with high structural coverage over a program have been examined. However, the fact that existing test generation tools are mainly evaluated on general software programs calls into question about its practical effectiveness and usefulness for machine learning libraries, which are statistically-orientated and have fundamentally different nature and construction from general software projects.In this paper, we set out to investigate the effectiveness of existing unit test generation techniques on machine learning libraries. To investigate this issue, we conducted an empirical study on five widely-used machine learning libraries with two popular unit test case generation tools, i.e., EVOSUITE and Randoop. We find that (1) most of the machine learning libraries do not maintain a high-quality unit test suite regarding commonly applied quality metrics such as code coverage (on average is 34.1%) and mutation score (on average is 21.3%), (2) unit test case generation tools, i.e., EVOSUITE and Randoop, lead to clear improvements in code coverage and mutation score, however, the improvement is limited, and (3) there exist common patterns in the uncovered code across the five machine learning libraries that can be used to improve unit test case generation tasks.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1548–1560},
numpages = {13},
keywords = {testing machine learning libraries, test case generation, Empirical software engineering},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1007/978-3-030-58811-3_65,
author = {Guveyi, Elcin and Aktas, Mehmet S. and Kalipsiz, Oya},
title = {Human Factor on Software Quality: A Systematic Literature Review},
year = {2020},
isbn = {978-3-030-58810-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58811-3_65},
doi = {10.1007/978-3-030-58811-3_65},
abstract = {Ensuring software quality is an important step towards a successful project. Since software development is a human-oriented process, it is possible to say that any factor affecting people will directly affect software quality and success. The aim of this study is to reveal which factors affect humans. For this purpose, we conducted a systematic literature review. We identified 80 related primary studies from the literature. We defined 7 research questions. For answering research questions, we extracted data from the primary studies. We researched human factors, methods for data collection and data analysis, publication types and years. Factors are grouped into 3 main groups: Personal factors, interpersonal factors, and organizational factors. The results show that personal factors are the most important category of human factors. It is seen that the most researched factors among personal factors are “experience” and “education”.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part IV},
pages = {918–930},
numpages = {13},
keywords = {Systematic literature review, Software quality, Human factor},
location = {Cagliari, Italy}
}

@inproceedings{10.1109/ITSC45102.2020.9294718,
author = {Guo, Zijian and Ye, Hao and Jiang, Ming and Sun, Xinya},
title = {An enhanced fault detection method for railway turnouts incorporating prior faulty information},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC45102.2020.9294718},
doi = {10.1109/ITSC45102.2020.9294718},
abstract = {Railway turnouts monitoring is critical for ensuring the safety of railway systems. Owing to the scarcity of faulty samples, many approaches focus on the fault detection of railway turnouts only using normal samples. However, although the faulty samples are insufficient, they can still provide useful information for fault detection. To improve the fault detection performance of railway turnouts, this paper proposes an enhanced fault detection method incorporating prior faulty information, which deals with the limitation of existing fault detection methods of turnouts that they fail to take insufficient faulty samples into account. In our method, a novel model which shares the architecture of deep autoencoders but has a different training objective is presented. By minimizing the difference between the averaged reconstruction error of normal samples and that of faulty samples, the proposed model enlarges the gap between the normal and faulty classes and making them more separable. The field data collected from a real high-speed railway in China is used to evaluate the proposed method, and a comparative study with several existing approaches is conducted. Experimental results show the effectiveness of the proposed method.},
booktitle = {2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
pages = {1–6},
numpages = {6},
location = {Rhodes}
}

@inproceedings{10.1145/3338906.3338961,
author = {Zhou, Xiang and Peng, Xin and Xie, Tao and Sun, Jun and Ji, Chao and Liu, Dewei and Xiang, Qilin and He, Chuan},
title = {Latent error prediction and fault localization for microservice applications by learning from system trace logs},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338961},
doi = {10.1145/3338906.3338961},
abstract = {In the production environment, a large part of microservice failures are related to the complex and dynamic interactions and runtime environments, such as those related to multiple instances, environmental configurations, and asynchronous interactions of microservices. Due to the complexity and dynamism of these failures, it is often hard to reproduce and diagnose them in testing environments. It is desirable yet still challenging that these failures can be detected and the faults can be located at runtime of the production environment to allow developers to resolve them efficiently. To address this challenge, in this paper, we propose MEPFL, an approach of latent error prediction and fault localization for microservice applications by learning from system trace logs. Based on a set of features defined on the system trace logs, MEPFL trains prediction models at both the trace level and the microservice level using the system trace logs collected from automatic executions of the target application and its faulty versions produced by fault injection. The prediction models thus can be used in the production environment to predict latent errors, faulty microservices, and fault types for trace instances captured at runtime. We implement MEPFL based on the infrastructure systems of container orchestrator and service mesh, and conduct a series of experimental studies with two opensource microservice applications (one of them being the largest open-source microservice application to our best knowledge). The results indicate that MEPFL can achieve high accuracy in intraapplication prediction of latent errors, faulty microservices, and fault types, and outperforms a state-of-the-art approach of failure diagnosis for distributed systems. The results also show that MEPFL can effectively predict latent errors caused by real-world fault cases.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {683–694},
numpages = {12},
keywords = {tracing, microservices, machine learning, fault localization, error prediction, debugging},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@phdthesis{10.5555/AAI28773561,
author = {Pan, Renjian and Krishnendu, Chakrabarty, and Yiran, Chen, and Hai, Li, and Qiang, Qiu,},
advisor = {Xin, Li,},
title = {Applying Machine Learning to Testing and Diagnosis of Integrated Systems},
year = {2021},
isbn = {9798780614135},
publisher = {Duke University},
address = {USA},
abstract = {The growing complexity of integrated boards and systems makes manufacturing test and diagnosis increasingly expensive. There is a pressing need to reduce test cost and to pinpoint the root causes of integrated systems in a more effective way. In light of machine learning, a number of intelligent test-cost reduction and root-cause analysis methods have been proposed. However, it remains extremely challenging to (i) reduce test cost for black-box testing for integrated systems, and (ii) pinpoint the root causes for integrated systems with little need on labeled test data from repair history. To tackle these challenges, we propose multiple machine-learning-based solutions for black-box test-cost reduction and unsupervised/semi-supervised root-cause analysis in this dissertation.For black-box test-cost reduction, we propose a novel test selection method based on a Bayesian network model. First, it is formulated as a constrained optimization problem. Next, a score-based algorithm is implemented to construct the Bayesian network for black-box tests. Finally, we propose a Bayesian index with the property of Markov blankets, and then an iterative test selection method is developed based on our proposed Bayesian index.For root-cause analysis, we first propose an unsupervised root-cause analysis method in which no repair history is needed. In the first stage, a decision-tree model is trained with system test information to cluster the data in a coarse-grained manner. In the second stage, frequent-pattern mining is applied to extract frequent patterns in each decision-tree node to precisely cluster the data so that each cluster represents only a small number of root causes. The proposed method can accommodate both numerical and categorical test items. A combination of the L-method, cross validation and Silhouette score enables us to automatically determine all hyper-parameters. Two industry case studies with system test data demonstrate that the proposed approach significantly outperforms the state-of-the-art unsupervised root-cause-analysis method.Utilizing transfer learning, we further improve the performance of unsupervised root-cause-analysis. A two-stage clustering method is first developed by exploiting model selection based on the concept of Silhouette score. Next, a data-selection method based on ensemble learning is proposed to transfer valuable information from a source product to improve the diagnosis accuracy on the target product with insufficient data. Two case studies based on industry designs demonstrate that the proposed approach significantly outperforms other state-of-the-art unsupervised root-cause-analysis methods.In addition, we propose a semi-supervised root-cause-analysis method with co-training, where only a small set of labeled data is required. Using random forest as the learning kernel, a co-training technique is proposed to leverage the unlabeled data by automatically pre-labeling a subset of them and retraining each decision tree. In addition, several novel techniques have been proposed to avoid over-fitting and determine hyper-parameters. Two case studies based on industrial designs demonstrate that the proposed approach significantly outperforms the state-of-the-art methods.In summary, this dissertation addresses the most difficult problems in testing and diagnosis of integrated systems with machine learning. A test selection method based on Bayesian networks reduces the test cost for black-box testing. With unsupervised learning, semi-supervised learning and transfer learning, we analysis root causes for integrated systems without much need on historical diagnosis information. The proposed approaches are expected to contribute to the semiconductor industry by effectively reducing the black-box test cost and efficiently diagnosing the integrated systems.},
note = {AAI28773561}
}

@article{10.3233/JIFS-181998,
author = {Jahan, Hosney and Feng, Ziliang and Mahmud, S.M. Hasan and Dong, Penglin},
title = {Version specific test case prioritization approach based on artificial neural network},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {36},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-181998},
doi = {10.3233/JIFS-181998},
abstract = {Regression testing involves validating a software system after modification to ensure that the previous bugs have been fixed and no new error has been raised. Finding faults early and increasing the fault detection rate are the main objectives of regression testing. A common technique involves re-executing the whole test suite, which is time consuming. Test case prioritization aims to schedule the test cases in an order that could achieve the regression testing goals early in the testing phase. Recently, machine learning techniques have been extensively used in regression testing to make it more effective and efficient. In this paper, we propose and investigate whether an Artificial Neural Network (ANN)-based approach can improve the version specific test case prioritization approach. The proposed approach utilizes the combination of test cases complexity information and software modification information with an ANN, for early detection of critical faults. Three new factors have been proposed, based on which an ANN is trained and finally it can automatically assign priorities to new test cases. The proposed approach is empirically evaluated with two software applications. Effectiveness metrics, such as fault detection rate, accuracy, precision, and recall are examined. The results suggest that the proposed approach is both effective and feasible.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6181–6194},
numpages = {14},
keywords = {fault detection capability, artificial neural network, test case prioritization, Regression testing}
}

@inproceedings{10.1007/978-3-030-55789-8_25,
author = {Saeed, Faisal and Paul, Anand and Rho, Seungmin},
title = {Faster R-CNN Based Fault Detection in Industrial Images},
year = {2020},
isbn = {978-3-030-55788-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-55789-8_25},
doi = {10.1007/978-3-030-55789-8_25},
abstract = {Industry 4.0 requires smart environment to find defects or faults in their products. A defective product in the market can impact negatively on the overall image of the industry. Thus, there is continuous struggle for industrial environment to reduce impulsive downtime, concert deprivation and safety risks. Defect detection in industrial products using the images is very hot topic in era of current research. Machine learning provides various solution but most of the time such solutions are not suitable for environment where product is on conveyor belt and traveling from one point to another. To detect fault using industrial images, we proposed a method which is based on Faster R-CNN which is suitable for smart environment as it can the product efficiently. We simulated our environment using python language and proposed model has almost 99% accuracy. To make our proposed scheme adaptable for the industry 4.0, we also developed an android application which make it easy to interact with the model and industry can train this model according to their needs. Android application is able to take pictures of defective product and feed it to model which improve accuracy and eventually reduces time identify defective product.},
booktitle = {Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices: 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020, Kitakyushu, Japan, September 22-25, 2020, Proceedings},
pages = {280–287},
numpages = {8},
keywords = {RPN, Fast R-CNN, Convolution neural networks, Fault identification, Defect detection, Industrial images},
location = {Kitakyushu, Japan}
}

@inproceedings{10.1109/ICSSP.2019.00025,
author = {Nistala, Padmalata and Nori, Kesav Vithal and Reddy, Raghu},
title = {Software quality models: a systematic mapping study},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSSP.2019.00025},
doi = {10.1109/ICSSP.2019.00025},
abstract = {Quality Models play a critical role in assuring quality and have evolved over 40+ years. They provide support for defining quality attributes, building and measuring the quality of the resulting product. Each quality model adopts a critical view on quality in terms of a set of model elements and relationships between them. This study aims to provide an overview of the state-of-the-art research on quality models with a focus on encompassing model elements and their support to architecting quality. The study was conducted using systematic mapping as the research methodology. A total of 238 primary papers were classified based on the type of research, standards usage, and publication trends. We identified that 17% (40) of papers belong to quality models. These 40 models were analyzed for the underlying meta-model elements and their support for a quality architecture using Bayer's reference architecture framework. The architecture phase mapping analysis shows that quality planning phase is 100% supported, quality assessment is 75% supported, quality documentation is included in 40% models and quality realization aspect is barely considered in 13% models. Quality realization happens through software processes and patterns, and it is necessary to evolve quality models and software process architectures that correlate quality definitions and quality realization mechanisms. Future research is expected in this direction.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {125–134},
numpages = {10},
keywords = {software quality, software process, reference architecture, quality realization, quality pattern, quality model, quality meta model, quality characteristic, quality architecture, product quality},
location = {Montreal, Quebec, Canada},
series = {ICSSP '19}
}

@article{10.1504/ijbis.2020.108650,
author = {Sarker, Kamal Uddin and Deraman, Aziz Bin and Hasan, Raza},
title = {Ontological practice for software quality control},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {34},
number = {3},
issn = {1746-0972},
url = {https://doi.org/10.1504/ijbis.2020.108650},
doi = {10.1504/ijbis.2020.108650},
abstract = {Recent statistical report on software project has been reflected the significant software project failure rate is existed till now. Failure can be partial, complete or compromising in functional or non-functional factors. The EBSPM public software project data repository has been analysed to reflect the relationship among cost, time, effective hours and functional points to identify eternal influencing factors. The literature review has identified the root causes of failure. Software quality control is a formal approach to make the project successful but until now ambiguous with the integration of quality factors. Our proposed ontology reduces the complexity of project management. This research has established the way of developing an ontology by including maximum quality factors. The way of collaborative working is included in the ontology to ensure formal, transparent, accountable and responsible manner. The ontology model is developed with descriptive logic and diagrams. Theoretical evaluation has been done at the end of the research based on the criteria of standardisation organisations.},
journal = {Int. J. Bus. Inf. Syst.},
month = jan,
pages = {355–372},
numpages = {17},
keywords = {descriptive logic, software quality control, ontology, project failure reasons, understanding project failure, software project failure rate}
}

@article{10.1007/s13748-020-00217-z,
author = {Sawaqed, Laith S. and Alrayes, Ayman M.},
title = {Bearing fault diagnostic using machine learning algorithms},
year = {2020},
issue_date = {Dec 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {9},
number = {4},
url = {https://doi.org/10.1007/s13748-020-00217-z},
doi = {10.1007/s13748-020-00217-z},
abstract = {This study aims to enhance the condition monitoring of external ball bearings using the raw data provided by Paderborn University which provided sufficient data for motor current signal MCS. Three classes of bearings have been used: healthy bearings, bearings with an inner race defect, and bearings with outer race defect. Online data at different operating conditions, bearings, and faults extent of artificial and real damages have been chosen to provide the generalization and robustness of the model. After proper preprocessing to the raw data of vibration and MCS, time, frequency, and time–frequency domain features have been extracted. Then, optimal features have been selected using genetic algorithm. Artificial neural network with optimized structure using genetic algorithm has been implemented. A comparison between the performance of vibration and motor current signal has been presented. Moreover, our results are compared to previous work by using the same raw data. Results showed the potential of motor current signal in bearing fault diagnosis with high classification accuracy. Moreover, the results showed the possibility to provide a promised diagnostic model that can diagnose bearings of real faults with different fault severities using MCS.},
journal = {Prog. in Artif. Intell.},
month = dec,
pages = {341–350},
numpages = {10},
keywords = {Genetic algorithm, Neural networks, Machine learning algorithm, Motor current signal, Vibration, Machine fault diagnostic, Bearing damage detection}
}

@inproceedings{10.1109/ICCAD51958.2021.9643459,
author = {Tseng, Hsiao-Yin and Chiu, I-Wei and Wu, Mu-Ting and Li, James Chien-Mo},
title = {Machine Learning-Based Test Pattern Generation for Neuromorphic Chips},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICCAD51958.2021.9643459},
doi = {10.1109/ICCAD51958.2021.9643459},
abstract = {The demand for neuromorphic chips has skyrocketed in recent years. Thus, efficient manufacturing testing becomes an issue. Conventional testing cannot be applied because some neuromorphic chips do not have scan chains. However, traditional functional testing for neuromorphic chips suffers from long test length and low fault coverage. In this work, we propose a machine learning-based test pattern generation technique with behavior fault models. We use the concept of adversarial attack to generate test patterns to improve the fault coverage of existing functional test patterns. The effectiveness of the proposed technique is demonstrated on two Spiking Neural Network models trained on MNIST. Compared to traditional functional testing, our proposed technique reduces test length by 566x to 8,824x and improves fault coverage by 8.1% to 86.3% on five fault models. Finally, we propose a methodology to solve the scalability issue for the synapse fault models, resulting in 25.7x run time reduction on test pattern generation for synapse faults.},
booktitle = {2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)},
pages = {1–7},
numpages = {7},
location = {Munich, Germany}
}

@inproceedings{10.1145/3341105.3374008,
author = {Zakurdaeva, Alla and Weiss, Michael and Muegge, Steven},
title = {Detecting architectural integrity violation patterns using machine learning},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3374008},
doi = {10.1145/3341105.3374008},
abstract = {Recent1 years have seen a surge of research into new ways of analyzing software quality. Specifically, a set of studies has been devoted to the impact the architectural relations among files have on system maintainability and file bug-proneness. The literature has proposed a set of rules for determining recurring architectural design flaws that occur in most complex systems, are associated with bugs, and thus incur high maintenance costs. In the present paper we advocate for using machine learning as the means of refining the approach and revealing new patterns of architectural integrity violations. Having trained a machine learning model on the combination of structural and historical information acquired from the Tiki open source project, we have been able to replicate three of the six known types of architectural violations and discover one new type, the Reverse Unstable Interface pattern. The implication of our study is that machine learning can provide valuable insights into the problem and discover novel patterns which would help software analysts to pinpoint specific architectural problems that may be the root causes of elevated bug- and change-proneness.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {1480–1487},
numpages = {8},
keywords = {software architecture, machine learning, hotspot patterns, bug-proneness, architectural flaws},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1007/978-3-030-58811-3_73,
author = {Siavvas, Miltiadis and Tsoukalas, Dimitrios and Marantos, Charalampos and Tsintzira, Angeliki-Agathi and Jankovic, Marija and Soudris, Dimitrios and Chatzigeorgiou, Alexander and Kehagias, Dionysios},
title = {The SDK4ED Platform for Embedded Software Quality Improvement - Preliminary Overview},
year = {2020},
isbn = {978-3-030-58810-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-58811-3_73},
doi = {10.1007/978-3-030-58811-3_73},
abstract = {Maintaining high level of quality with respect to important quality attributes is critical for the success of modern software applications. Hence, appropriate tooling is required to help developers and project managers monitor and optimize software quality throughout the overall Software Development Lifecycle (SDLC). Moreover, embedded software engineers and developers need support to manage complex interdependencies and inherent trade-offs between design and run-time qualities. To this end, in an attempt to address these issues, we are developing the SDK4ED Platform as part of the ongoing EU-funded SDK4ED project, a software quality system that enables the monitoring and optimization of software quality, with emphasis on embedded software. The purpose of this technical paper is to provide an overview of the SDK4ED Platform and present the main novel functionalities that have been implemented within the platform until today.},
booktitle = {Computational Science and Its Applications – ICCSA 2020: 20th International Conference, Cagliari, Italy, July 1–4, 2020, Proceedings, Part IV},
pages = {1035–1050},
numpages = {16},
keywords = {Verification and validation, Software quality},
location = {Cagliari, Italy}
}

@book{10.5555/3360164,
author = {Rathore, Santosh Singh and Kumar, Sandeep},
title = {Fault Prediction Modeling for the Prediction of Number of Software Faults},
year = {2019},
isbn = {9789811371301},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {This book addresses software faults—a critical issue that not only reduces the quality of software, but also increases their development costs. Various models for predicting the fault-proneness of software systems have been proposed; however, most of them provide inadequate information, limiting their effectiveness. This book focuses on the prediction of number of faults in software modules, and provides readers with essential insights into the generalized architecture, different techniques, and state-of-the art literature. In addition, it covers various software fault datasets and issues that crop up when predicting number of faults. A must-read for readers seeking a "one-stop" source of information on software fault prediction and recent research trends, the book will especially benefit those interested in pursuing research in this area. At the same time, it will provide experienced researchers with a valuable summary of the latest developments.}
}

@inproceedings{10.1145/1370750.1370759,
author = {Ratzinger, Jacek and Sigmund, Thomas and Gall, Harald C.},
title = {On the relation of refactorings and software defect prediction},
year = {2008},
isbn = {9781605580241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370750.1370759},
doi = {10.1145/1370750.1370759},
abstract = {This paper analyzes the influence of evolution activities such as refactoring on software defects. In a case study of five open source projects we used attributes of software evolution to predict defects in time periods of six months. We use versioning and issue tracking systems to extract 110 data mining features, which are separated into refactoring and non-refactoring related features. These features are used as input into classification algorithms that create prediction models for software defects. We found out that refactoring related features as well as non-refactoring related features lead to high quality prediction models. Additionally, we discovered that refactorings and defects have an inverse correlation: The number of software defects decreases, if the number of refactorings increased in the preceding time period. As a result, refactoring should be a significant part of both bug fixes and other evolutionary changes to reduce software defects.},
booktitle = {Proceedings of the 2008 International Working Conference on Mining Software Repositories},
pages = {35–38},
numpages = {4},
keywords = {software evolution, software analysis, mining},
location = {Leipzig, Germany},
series = {MSR '08}
}

@inproceedings{10.1145/3421537.3421546,
author = {Han, Seungmin and Oh, Jinwoo and Jeong, Jongpil},
title = {Bearing Fault Detection with Data Augmentation Based on 2-D CNN and 1-D CNN},
year = {2020},
isbn = {9781450375504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3421537.3421546},
doi = {10.1145/3421537.3421546},
abstract = {Bearings are one of the most essential parts of rotary machines. The failure of bearings can lead to significant financial loss as well as personal casualties. Therefore, bearing defect diagnosis is a very important research project. Recently, a lot of bearing defect diagnosis studies using deep learning methods have been conducted. However, there are some challenges to be addressed. In a real working condition, there is always much more normal data than fault data, so a data imbalance problem exists. To address this situation, data augmentation method which generates more training data from the original data, was used. This method was done by applying a geometric transformation so that the class label did not be changed. Therefore, in this paper, we compared the results of using and without data augmentation technique through 1-D CNN and 2-D CNN deep learning algorithm that are effective on time series data analysis and pattern recognition. Finally, we obtained better results when using data augmentation technique.},
booktitle = {Proceedings of the 2020 4th International Conference on Big Data and Internet of Things},
pages = {20–23},
numpages = {4},
keywords = {Fault Detection, Data Augmentation, 2-D CNN, 1-D CNN},
location = {Singapore, Singapore},
series = {BDIOT '20}
}

@inproceedings{10.5555/3291291.3291297,
author = {Nascimento, Nathalia and Alencar, Paulo and Lucena, Carlos and Cowan, Donald},
title = {A context-aware machine learning-based approach},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {It is known that training a general and versatile Machine Learning (ML)-based model is more cost-effective than training several specialized ML-models for different operating contexts. However, as the volume of training information grows, the higher the probability of producing biased results. Learning bias is a critical problem for many applications, such as those related to healthcare scenarios, environmental monitoring and air traffic control. In this paper, we compare the use of a general model that was trained using all contexts against a system that is composed of a set of specialized models that was trained for each particular operating context. For this purpose, we propose a local learning approach based on context-awareness, which involves: (i) anticipating, analyzing and representing context changes; (ii) training and finding machine learning models to maximize a given scoring function for each operating context; (iii) storing trained ML-based models and associating them with corresponding operating contexts; and (iv) deploying a system that is able to select the best-fit ML-based model at runtime based on the context. To illustrate our proposed approach, we reproduce two experiments: one that uses a neural network regression-based model to perform predictions and another one that uses an evolutionary neural network-based approach to make decisions. For each application, we compare the results of the general model, which was trained based on all contexts, against the results of our proposed approach. We show that our context-aware approach can improve results by alleviating bias with different ML tasks.},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {40–47},
numpages = {8},
keywords = {neural network, machine learning, learning bias, contextual modeling, context-awareness},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@article{10.1016/j.mejo.2021.105198,
author = {Abazyan, Suren and Melikyan, Vazgen},
title = {Enhanced pin-access prediction and design optimization with machine learning integration},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {116},
number = {C},
issn = {0026-2692},
url = {https://doi.org/10.1016/j.mejo.2021.105198},
doi = {10.1016/j.mejo.2021.105198},
journal = {Microelectron. J.},
month = oct,
numpages = {5},
keywords = {Prediction and optimization, Machine learning, Pin access}
}

@inproceedings{10.1109/IECON.2017.8216945,
author = {Gou, XiaoDong and Zhou, Xin and Pang, JiaWen and Yang, ShunKun},
title = {Medical software bug prediction based on static analysis},
year = {2017},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON.2017.8216945},
doi = {10.1109/IECON.2017.8216945},
abstract = {Monitoring and predicting the increasing or decreasing trend of bug number in a software is of great importance to both software developers and users. Accurate predicting of number of software bug will help developers make timely and correct decision. For software users, knowing the possible number of software bugs will enable them to take seasonable actions to cope with loss caused by possible software bugs. Medical software is vital to people's health, and therefore, the bug prediction of medical software is more important and essential than the ordinary software. To accomplish this goal, we present a method based on static analysis and correlation analysis to predict the bug number of medical image informatics software 3D Slicer and ITK. We obtain the complexity metrics through static analysis, then get the bug predicted value via correlation analysis between existing bug number and complexity metrics. The core idea of this paper is that the changes of software complexity metrics obtained by static analysis can reflect the changes of the bug number, and the predicted results prove the feasibility of this method. In addition, the method proposed in this paper is also applicable to other types of software other than medical software.},
booktitle = {IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society},
pages = {5460–5464},
numpages = {5},
location = {Beijing, China}
}

@article{10.1007/s00521-013-1429-4,
author = {Reyes, Javier and Vellasco, Marley and Tanscheit, Ricardo},
title = {Fault detection and measurements correction for multiple sensors using a modified autoassociative neural network},
year = {2014},
issue_date = {June      2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {7–8},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-013-1429-4},
doi = {10.1007/s00521-013-1429-4},
abstract = {Periodic manual calibrations ensure that an instrument will operate correctly for a given period of time, but they do not assure that a faulty instrument will remain calibrated for other periods. In addition, sometimes such calibrations are even unnecessary. In industrial plants, the analysis of signals provided by process monitoring sensors is a difficult task due to the high dimensionality of the data. A strategy for online monitoring and correction of multiple sensors measurements is therefore required. Thus, this work proposes the use of autoassociative neural networks, trained with a modified robust method, in an online monitoring system for fault detection and self-correction of measurements generated by a large number of sensors. Unlike the existing models, the proposed system aims at using only one neural network to reconstruct faulty sensor signals. The model is evaluated with the use of a database containing measurements collected by industrial sensors that monitor and are used in the control of an internal combustion engine installed in a mining truck. Results show that the proposed model is able to map and correct faulty sensor signals and achieve low error rates.},
journal = {Neural Comput. Appl.},
month = jun,
pages = {1929–1941},
numpages = {13},
keywords = {Signal monitoring system, Sensors, Fault detection, Calibration, Autoassociative neural networks}
}

@inproceedings{10.1145/3377811.3380384,
author = {Sotiropoulos, Thodoris and Mitropoulos, Dimitris and Spinellis, Diomidis},
title = {Practical fault detection in puppet programs},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380384},
doi = {10.1145/3377811.3380384},
abstract = {Puppet is a popular computer system configuration management tool. By providing abstractions that model system resources it allows administrators to set up computer systems in a reliable, predictable, and documented fashion. Its use suffers from two potential pitfalls. First, if ordering constraints are not correctly specified whenever a Puppet resource depends on another, the non-deterministic application of resources can lead to race conditions and consequent failures. Second, if a service is not tied to its resources (through the notification construct), the system may operate in a stale state whenever a resource gets modified. Such faults can degrade a computing infrastructure's availability and functionality.We have developed an approach that identifies these issues through the analysis of a Puppet program and its system call trace. Specifically, a formal model for traces allows us to capture the interactions of Puppet resources with the file system. By analyzing these interactions we identify (1) resources that are related to each other (e.g., operate on the same file), and (2) resources that should act as notifiers so that changes are correctly propagated. We then check the relationships from the trace's analysis against the program's dependency graph: a representation containing all the ordering constraints and notifications declared in the program. If a mismatch is detected, our system reports a potential fault.We have evaluated our method on a large set of popular Puppet modules, and discovered 92 previously unknown issues in 33 modules. Performance benchmarking shows that our approach can analyze in seconds real-world configurations with a magnitude measured in thousands of lines and millions of system calls.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {26–37},
numpages = {12},
keywords = {notifiers, ordering relationships, program analysis, puppet, system calls},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3195546.3206423,
author = {Hamou-Lhadj, Wahab and Nayrolles, Mathieu},
title = {A project on software defect prevention at commit-time: a success story of university-industry research collaboration},
year = {2018},
isbn = {9781450357449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3195546.3206423},
doi = {10.1145/3195546.3206423},
abstract = {In this talk, we describe a research collaboration project between Concordia University and Ubisoft. The project consists of investigating techniques for defect prevention at commit-time for increased software quality. The outcome of this project is a tool called CLEVER (Combining Levels of Bug Prevention and Resolution techniques) that uses machine learning to automatically detect coding defects as programmers write code. The main novelty of CLEVER is that it relies on code matching techniques to detect coding mistakes based on a database of historical code defects found in multiple related projects. The tool also proposes fixes based on known patterns.},
booktitle = {Proceedings of the 5th International Workshop on Software Engineering Research and Industrial Practice},
pages = {24–25},
numpages = {2},
keywords = {university-industry research project, software maintenance and evolution, machine learning, bug prevention at commit-time},
location = {Gothenburg, Sweden},
series = {SER&amp;IP '18}
}

@inproceedings{10.1109/IECON43393.2020.9254897,
author = {Li, Xuemeng and Chai, Wei and Liu, Tong and Qiao, Junfei},
title = {Fault detection of dissolved oxygen sensor in wastewater treatment plants},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON43393.2020.9254897},
doi = {10.1109/IECON43393.2020.9254897},
abstract = {In wastewater treatment processes, the monitoring of dissolved oxygen sensor is the key to ensure the quality of effluent. In this paper, a method for fault detection of dissolved oxygen sensor is proposed using set membership identification and radial basis function(RBF) neural network. The time series model of KLa5 is built by RBF neural network in virtue of its universal approximation ability. Considering the bounded modeling error, the set description of the output weights of the network is obtained by linear-in-parameters set membership identification algorithm. This built model can give a one-step prediction of the confidence interval of KLa5 under the fault-free case. If the real of KLa5 exceeds the predicted confidence interval, a failure of the dissolved oxygen sensor can be determined.},
booktitle = {IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society},
pages = {225–230},
numpages = {6},
location = {Singapore, Singapore}
}

@article{10.1145/2347696.2347709,
author = {Rashid, Ekbal and Patnayak, Srikanta and Bhattacherjee, Vandana},
title = {A survey in the area of machine learning and its application for software quality prediction},
year = {2012},
issue_date = {September 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2347696.2347709},
doi = {10.1145/2347696.2347709},
abstract = {This paper explores software quality improvement through early prediction of error patterns. It summarizes a variety of techniques for software quality prediction in the domain of software engineering. The objective of this research is to apply the various machine learning approaches, such as Case-Based Reasoning and Fuzzy logic, to predict software quality. The system predicts the error after accepting the values of certain parameters of the software. This paper advocates the use of case-based reasoning (i.e., CBR) to build a software quality prediction system with the help of human experts. The prediction is based on analogy. We have used different similarity measures to find the best method that increases reliability. This software is compiled using Turbo C++ 3.0 and hence it is very compact and standalone. It can be readily deployed on any configuration without affecting its performance.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {1–7},
numpages = {7},
keywords = {software quality, similarity, machine learning, function, erffort estimation, analogy, CBR}
}

@inproceedings{10.1145/2889160.2889256,
author = {Tantithamthavorn, Chakkrit},
title = {Towards a better understanding of the impact of experimental components on defect prediction modelling},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889256},
doi = {10.1145/2889160.2889256},
abstract = {Defect prediction models are used to pinpoint risky software modules and understand past pitfalls that lead to defective modules. The predictions and insights that are derived from defect prediction models may not be accurate and reliable if researchers do not consider the impact of experimental components (e.g., datasets, metrics, and classifiers) of defect prediction modelling. Therefore, a lack of awareness and practical guidelines from previous research can lead to invalid predictions and unreliable insights. In this thesis, we investigate the impact that experimental components have on the predictions and insights of defect prediction models. Through case studies of systems that span both proprietary and open-source domains, we find that (1) noise in defect datasets; (2) parameter settings of classification techniques; and (3) model validation techniques have a large impact on the predictions and insights of defect prediction models, suggesting that researchers should carefully select experimental components in order to produce more accurate and reliable defect prediction models.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {867–870},
numpages = {4},
keywords = {experimental components, defect prediction modelling},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3369583.3392672,
author = {Behera, Subhendu and Wan, Lipeng and Mueller, Frank and Wolf, Matthew and Klasky, Scott},
title = {Orchestrating Fault Prediction with Live Migration and Checkpointing},
year = {2020},
isbn = {9781450370523},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369583.3392672},
doi = {10.1145/3369583.3392672},
abstract = {Checkpoint/Restart (C/R) is widely used to provide fault tolerance on High-Performance Computing (HPC) systems. However, Parallel File System (PFS) overhead and failure uncertainty cause significant application overhead. This paper develops an adaptive multi-level C/R model that incorporates a failure prediction and analysis model, which orchestrates failure prediction, checkpointing, checkpoint frequency, and proactive live migration along with the additional benefit of Burst Buffers (BB). It effectively reduces the overheads due to failures, checkpointing, and recovery. Simulation results for the Summit supercomputer yield a reduction of ~20%-86% in application overhead due to BBs, orchestrated failure prediction, and migration. We also observe a ~29% decrease in checkpoint writes to BBs, which can increase the longevity of the BB storage devices.},
booktitle = {Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing},
pages = {167–171},
numpages = {5},
keywords = {proactive live migration, high performance computing, failure prediction, checkpoint/restart, burst buffers, I/O subsystem},
location = {Stockholm, Sweden},
series = {HPDC '20}
}

@inproceedings{10.1145/2597073.2597078,
author = {Zhang, Feng and Mockus, Audris and Keivanloo, Iman and Zou, Ying},
title = {Towards building a universal defect prediction model},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597078},
doi = {10.1145/2597073.2597078},
abstract = {To predict files with defects, a suitable prediction model must be built for a software project from either itself (within-project) or other projects (cross-project). A universal defect prediction model that is built from the entire set of diverse projects would relieve the need for building models for an individual project. A universal model could also be interpreted as a basic relationship between software metrics and defects. However, the variations in the distribution of predictors pose a formidable obstacle to build a universal model. Such variations exist among projects with different context factors (e.g., size and programming language). To overcome this challenge, we propose context-aware rank transformations for predictors. We cluster projects based on the similarity of the distribution of 26 predictors, and derive the rank transformations using quantiles of predictors for a cluster. We then fit the universal model on the transformed data of 1,398 open source projects hosted on SourceForge and GoogleCode. Adding context factors to the universal model improves the predictive power. The universal model obtains prediction performance comparable to the within-project models and yields similar results when applied on five external projects (one Apache and four Eclipse projects). These results suggest that a universal defect prediction model may be an achievable goal.},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {182–191},
numpages = {10},
keywords = {rank transformation, quality, large scale, defect prediction, defect, context factors, bug, Universal defect prediction model},
location = {Hyderabad, India},
series = {MSR 2014}
}

@article{10.2478/acss-2021-0010,
author = {Vincent, Olufunke Rebecca and Babalola, Yetunde Ebunoluwa and Sodiya, Adesina Simon and Adeniran, Olusola John},
title = {A Cognitive Rail Track Breakage Detection System Using Artificial Neural Network},
year = {2021},
issue_date = {Dec 2021},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {26},
number = {2},
issn = {2255-8691},
url = {https://doi.org/10.2478/acss-2021-0010},
doi = {10.2478/acss-2021-0010},
abstract = {Rail track breakages represent broken structures consisting of rail track on the railroad. The traditional methods for detecting this problem have proven unproductive. The safe operation of rail transportation needs to be frequently monitored because of the level of trust people have in it and to ensure adequate maintenance strategy and protection of human lives and properties. This paper presents an automatic deep learning method using an improved fully Convolutional Neural Network (FCN) model based on U-Net architecture to detect and segment cracks on rail track images. An approach to evaluating the extent of damage on rail tracks is also proposed to aid efficient rail track maintenance. The model performance is evaluated using precision, recall, F1-Score, and Mean Intersection over Union (MIoU). The results obtained from the extensive analysis show U-Net capability to extract meaningful features for accurate crack detection and segmentation.},
journal = {Appl. Comput. Syst.},
month = dec,
pages = {80–86},
numpages = {7},
keywords = {U-Net architecture, rail track breakage, fully convolutional neural network, Deep learning}
}

@article{10.1016/j.jss.2016.05.015,
author = {Chen, Tse-Hsun and Shang, Weiyi and Nagappan, Meiyappan and Hassan, Ahmed E. and Thomas, Stephen W.},
title = {Topic-based software defect explanation},
year = {2017},
issue_date = {July 2017},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {129},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2016.05.015},
doi = {10.1016/j.jss.2016.05.015},
abstract = {Some topics are more defect-prone than others.Defect-prone topics are likely to remain so over time.Our topic-based metrics provide additional defect explanatory to baseline metrics.Our metrics outperform state-of-the-art topic-based cohesion and coupling metrics. Researchers continue to propose metrics using measurable aspects of software systems to understand software quality. However, these metrics largely ignore the functionality, i.e., the conceptual concerns, of software systems. Such concerns are the technical concepts that reflect the systems business logic. For instance, while lines of code may be a good general measure for defects, a large file responsible for simple I/O tasks is likely to have fewer defects than a small file responsible for complicated compiler implementation details. In this paper, we study the effect of concerns on software quality. We use a statistical topic modeling approach to approximate software concerns as topics (related words in source code). We propose various metrics using these topics to help explain the file defect-proneness. Case studies on multiple versions of Firefox, Eclipse, Mylyn, and NetBeans show that (i) some topics are more defect-prone than others; (ii) defect-prone topics tend to remain so over time; (iii) our topic-based metrics provide additional explanatory power for software quality over existing structural and historical metrics; and (iv) our topic-based cohesion metric outperforms state-of-the-art topic-based cohesion and coupling metrics in terms of defect explanatory power, while being simpler to implement and more intuitive to interpret.},
journal = {J. Syst. Softw.},
month = jul,
pages = {79–106},
numpages = {28},
keywords = {Topic modeling, Metrics, LDA, Coupling, Cohesion, Code quality}
}

@inproceedings{10.1145/3387940.3391478,
author = {Sildatke, Michael and Karwanni, Hendrik and Kraft, Bodo and Schmidts, Oliver and Z\"{u}ndorf, Albert},
title = {Automated Software Quality Monitoring in Research Collaboration Projects},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391478},
doi = {10.1145/3387940.3391478},
abstract = {In collaborative research projects, both researchers and practitioners work together solving business-critical challenges. These projects often deal with ETL processes, in which humans extract information from non-machine-readable documents by hand. AI-based machine learning models can help to solve this problem.Since machine learning approaches are not deterministic, their quality of output may decrease over time. This fact leads to an overall quality loss of the application which embeds machine learning models. Hence, the software qualities in development and production may differ.Machine learning models are black boxes. That makes practitioners skeptical and increases the inhibition threshold for early productive use of research prototypes. Continuous monitoring of software quality in production offers an early response capability on quality loss and encourages the use of machine learning approaches. Furthermore, experts have to ensure that they integrate possible new inputs into the model training as quickly as possible.In this paper, we introduce an architecture pattern with a reference implementation that extends the concept of Metrics Driven Research Collaboration with an automated software quality monitoring in productive use and a possibility to auto-generate new test data coming from processed documents in production.Through automated monitoring of the software quality and auto-generated test data, this approach ensures that the software quality meets and keeps requested thresholds in productive use, even during further continuous deployment and changing input data.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {603–610},
numpages = {8},
keywords = {Software Architecture, Research Collaboration Management, Research Best Practices, Metrics, Lean Software Development},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/3416013.3426443,
author = {Almazrouei, Ebtesam and Gianini, Gabriele and Almoosa, Nawaf and Damiani, Ernesto},
title = {What can Machine Learning do for Radio Spectrum Management?},
year = {2020},
isbn = {9781450381208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416013.3426443},
doi = {10.1145/3416013.3426443},
abstract = {The opening of the unlicensed radio spectrum creates new opportunities and new challenges for communication technology that can be faced by Machine Learning techniques. In this work, we discuss the potential benefits and the challenges with reference to the recent research developments in this area. Applications go from channel estimation to Signal quality control, and from signal classification to action control. We survey Machine learning and Deep Learning algorithms with possible radio applications and highlight the corresponding challenges.},
booktitle = {Proceedings of the 16th ACM Symposium on QoS and Security for Wireless and Mobile Networks},
pages = {15–21},
numpages = {7},
keywords = {wireless communication, radio signals, machine learning},
location = {Alicante, Spain},
series = {Q2SWinet '20}
}

@phdthesis{10.5555/AAI28772454,
author = {Stewart, Michael Allen and J., Laszlo, Michael and Sumitra, Mukherjee,},
advisor = {J, Mitropoulos, Francisco},
title = {Increasing Software Reliability Using Mutation Testing and Machine Learning},
year = {2021},
isbn = {9798492722906},
publisher = {Nova Southeastern University},
abstract = {Mutation testing is a type of software testing proposed in the 1970s where program statements are deliberately changed to introduce simple errors so that test cases can be validated to determine if they can detect the errors. The goal of mutation testing was to reduce complex program errors by preventing the related simple errors. Test cases are executed against the mutant code to determine if one fails, detects the error and ensures the program is correct. One major issue with this type of testing was it became intensive computationally to generate and test all possible mutations for complex programs.This dissertation used machine learning for the selection of mutation operators that reduced the computational cost of testing and improved test suite effectiveness. The goals were to produce mutations that were more resistant to test cases, improve test case evaluation, validate then improve the test suite's effectiveness, realize cost reductions by generating fewer mutations for testing and improving software reliability by detecting more errors. To accomplish these goals, experiments were conducted using sample programs to determine how well the reinforcement learning based algorithm performed with one live mutation, multiple live mutations and no live mutations. The experiments, measured by mutation score, were used to update the algorithm and improved accuracy for predictions. The performance was then evaluated on multiple processor computers.One key result from this research was the development of a reinforcement algorithm to identify mutation operator combinations that resulted in live mutants. During experimentation, the reinforcement learning algorithm identified the optimal mutation operator selections for various programs and test suite scenarios, as well as determined that by using parallel processing and multiple cores the reinforcement learning process for mutation operator selection was practical. With reinforcement learning the mutation operators utilized were reduced by 50–100%. In conclusion, these improvements created a 'live' mutation testing process that evaluated various mutation operators and generated mutants to perform real-time mutation testing while dynamically prioritizing mutation operator recommendations. This has enhanced the software developer's ability to improve testing processes. The contributions of this paper's research supported the shift-left testing approach, where testing is performed earlier in the software development cycle when error resolution is less costly.},
note = {AAI28772454}
}

@article{10.1145/3445812,
author = {Jesus, Gon\c{c}alo and Casimiro, Ant\'{o}nio and Oliveira, Anabela},
title = {Using Machine Learning for Dependable Outlier Detection in Environmental Monitoring Systems},
year = {2021},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
issn = {2378-962X},
url = {https://doi.org/10.1145/3445812},
doi = {10.1145/3445812},
abstract = {Sensor platforms used in environmental monitoring applications are often subject to harsh environmental conditions while monitoring complex phenomena. Therefore, designing dependable monitoring systems is challenging given the external disturbances affecting sensor measurements. Even the apparently simple task of outlier detection in sensor data becomes a hard problem, amplified by the difficulty in distinguishing true data errors due to sensor faults from deviations due to natural phenomenon, which look like data errors. Existing solutions for runtime outlier detection typically assume that the physical processes can be accurately modeled, or that outliers consist in large deviations that are easily detected and filtered by appropriate thresholds. Other solutions assume that it is possible to deploy multiple sensors providing redundant data to support voting-based techniques. In this article, we propose a new methodology for dependable runtime detection of outliers in environmental monitoring systems, aiming to increase data quality by treating them. We propose the use of machine learning techniques to model each sensor behavior, exploiting the existence of correlated data provided by other related sensors. Using these models, along with knowledge of processed past measurements, it is possible to obtain accurate estimations of the observed environment parameters and build failure detectors that use these estimations. When a failure is detected, these estimations also allow one to correct the erroneous measurements and hence improve the overall data quality. Our methodology not only allows one to distinguish truly abnormal measurements from deviations due to complex natural phenomena, but also allows the quantification of each measurement quality, which is relevant from a dependability perspective.We apply the methodology to real datasets from a complex aquatic monitoring system, measuring temperature and salinity parameters, through which we illustrate the process for building the machine learning prediction models using a technique based on Artificial Neural Networks, denoted ANNODE (ANN Outlier Detection). From this application, we also observe the effectiveness of our ANNODE approach for accurate outlier detection in harsh environments. Then we validate these positive results by comparing ANNODE with state-of-the-art solutions for outlier detection. The results show that ANNODE improves existing solutions regarding accuracy of outlier detection.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = jul,
articleno = {29},
numpages = {30},
keywords = {outlier detection, neural networks, machine learning, data quality, aquatic monitoring, Dependability}
}

@inproceedings{10.1007/978-3-030-33607-3_12,
author = {Shepperd, Martin and Guo, Yuchen and Li, Ning and Arzoky, Mahir and Capiluppi, Andrea and Counsell, Steve and Destefanis, Giuseppe and Swift, Stephen and Tucker, Allan and Yousefi, Leila},
title = {The Prevalence of Errors in Machine Learning Experiments},
year = {2019},
isbn = {978-3-030-33606-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-33607-3_12},
doi = {10.1007/978-3-030-33607-3_12},
abstract = {Context: Conducting experiments is central to research machine learning research to benchmark, evaluate and compare learning algorithms. Consequently it is important we conduct reliable, trustworthy experiments.Objective: We investigate the incidence of errors in a sample of machine learning experiments in the domain of software defect prediction. Our focus is simple arithmetical and statistical errors.Method: We analyse 49 papers describing 2456 individual experimental results from a previously undertaken systematic review comparing supervised and unsupervised defect prediction classifiers. We extract the confusion matrices and test for relevant constraints, e.g., the marginal probabilities must sum to one. We also check for multiple statistical significance testing errors.Results: We find that a total of 22 out of 49 papers contain demonstrable errors. Of these 7 were statistical and 16 related to confusion matrix inconsistency (one paper contained both classes of error).Conclusions: Whilst some errors may be of a relatively trivial nature, e.g., transcription errors their presence does not engender confidence. We strongly urge researchers to follow open science principles so errors can be more easily be detected and corrected, thus as a community reduce this worryingly high error rate with our computational experiments.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2019: 20th International Conference, Manchester, UK, November 14–16, 2019, Proceedings, Part I},
pages = {102–109},
numpages = {8},
keywords = {Classifier, Computational experiment, Reliability, Error},
location = {Manchester, United Kingdom}
}

@article{10.1007/s10515-011-0091-2,
author = {Liparas, Dimitris and Angelis, Lefteris and Feldt, Robert},
title = {Applying the Mahalanobis-Taguchi strategy for software defect diagnosis},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0091-2},
doi = {10.1007/s10515-011-0091-2},
abstract = {The Mahalanobis-Taguchi (MT) strategy combines mathematical and statistical concepts like Mahalanobis distance, Gram-Schmidt orthogonalization and experimental designs to support diagnosis and decision-making based on multivariate data. The primary purpose is to develop a scale to measure the degree of abnormality of cases, compared to "normal" or "healthy" cases, i.e. a continuous scale from a set of binary classified cases. An optimal subset of variables for measuring abnormality is then selected and rules for future diagnosis are defined based on them and the measurement scale. This maps well to problems in software defect prediction based on a multivariate set of software metrics and attributes. In this paper, the MT strategy combined with a cluster analysis technique for determining the most appropriate training set, is described and applied to well-known datasets in order to evaluate the fault-proneness of software modules. The measurement scale resulting from the MT strategy is evaluated using ROC curves and shows that it is a promising technique for software defect diagnosis. It compares favorably to previously evaluated methods on a number of publically available data sets. The special characteristic of the MT strategy that it quantifies the level of abnormality can also stimulate and inform discussions with engineers and managers in different defect prediction situations.},
journal = {Automated Software Engg.},
month = jun,
pages = {141–165},
numpages = {25},
keywords = {Software testing, Software defect prediction, Mahalanobis-Taguchi strategy, Fault-proneness}
}

@article{10.1145/3408063,
author = {Xama, Nektar and Andraud, Martin and Gomez, Jhon and Esen, Baris and Dobbelaere, Wim and Vanhooren, Ronny and Coyette, Anthony and Gielen, Georges},
title = {Machine Learning-based Defect Coverage Boosting of Analog Circuits under Measurement Variations},
year = {2020},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {5},
issn = {1084-4309},
url = {https://doi.org/10.1145/3408063},
doi = {10.1145/3408063},
abstract = {Safety-critical and mission-critical systems, such as airplanes or (semi-)autonomous cars, are relying on an ever-increasing number of embedded integrated circuits. Consequently, there is a need for complete defect coverage during the testing of these circuits to guarantee their functionality in the field. In this context, reducing the escape rate of defects during production testing is crucial, and significant progress has been made to this end. However, production testing using automatic test equipment is subject to various measurement parasitic variations, which may have a negative impact on the testing procedure and therefore limit the final defect coverage. To tackle this issue, this article proposes an improved test flow targeting increased analog defect coverage, both at the system and block levels, by analyzing and improving the coverage of typical functional and structural tests under these measurement variations. To illustrate the flow, the technique of inserting a pseudo-random signal at available circuit nodes and applying machine learning techniques to its response is presented. A DC-DC converter, derived from an industrial product, is used as a case study to validate the flow. In short, results show that system-level tests for the converter suffer strongly from the measurement variations and are limited to just under 80% coverage, even when applying the proposed test flow. Block-level testing, however, can achieve only 70% fault coverage without improvements but is able to consistently achieve 98% of fault coverage at a cost of at most 2% yield loss with the proposed machine learning–based boosting technique.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = aug,
articleno = {47},
numpages = {27},
keywords = {test under measurements variations, Machine learning for test, AMS IC test}
}

@inproceedings{10.1145/3318299.3318345,
author = {Li, ZhanJun and Shao, Yan},
title = {A Survey of Feature Selection for Vulnerability Prediction Using Feature-based Machine Learning},
year = {2019},
isbn = {9781450366007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318299.3318345},
doi = {10.1145/3318299.3318345},
abstract = {This paper summarized the basic process of software vulnerability prediction using feature-based machine learning for the first time. In addition to sorting out the related types and basis of vulnerability features definition, the advantages and disadvantages of different methods are compared. Finally, this paper analyzed the difficulties and challenges in this research field, and put forward some suggestions for future work.},
booktitle = {Proceedings of the 2019 11th International Conference on Machine Learning and Computing},
pages = {36–42},
numpages = {7},
keywords = {machine learning, feature, Software vulnerability prediction},
location = {Zhuhai, China},
series = {ICMLC '19}
}

@article{10.1007/s10664-020-09881-0,
author = {Riccio, Vincenzo and Jahangirova, Gunel and Stocco, Andrea and Humbatova, Nargiz and Weiss, Michael and Tonella, Paolo},
title = {Testing machine learning based systems: a systematic mapping},
year = {2020},
issue_date = {Nov 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {6},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-020-09881-0},
doi = {10.1007/s10664-020-09881-0},
journal = {Empirical Softw. Engg.},
month = nov,
pages = {5193–5254},
numpages = {62},
keywords = {Machine learning, Software testing, Systematic review, Systematic mapping}
}

@inproceedings{10.1007/978-3-030-87013-3_3,
author = {Neto, Walter Lopes and de Morais Barroca Filho, Itamir},
title = {Failures Forecast in Monitoring Datacenter Infrastructure Through Machine Learning Techniques: A Systematic Review},
year = {2021},
isbn = {978-3-030-87012-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-87013-3_3},
doi = {10.1007/978-3-030-87013-3_3},
abstract = {With the trend of accelerating digital transformation processes, datacenters (DC) are gaining prominence as increasingly critical components for business success. Modern DC are complex systems. To maintain the operation with high efficiency and high availability, it is necessary to carry out detailed monitoring, which easily results in hundreds or thousands of items being monitored. Also, the large number of possible configurations is a challenge for monitoring and correcting failures on time. However, recent advances in the field of Artificial Intelligence (AI), especially in the area of Machine Learning (ML), have been generating unprecedented opportunities to improve the efficiency of the analysis of historical monitoring data, facilitating the recognition of patterns and enabling scenarios for early detection of failures. In this sense, significant research has been published discussing the applications of ML techniques in the context of DC monitoring. Based on this context, in this paper, we aim to present a systematic literature review (SLR) that helps to understand the current state and future trends of the application of ML techniques in DC monitoring, specifically those aimed at early fault detection. This SLR also aims to identify gaps for further investigations. As main results, we identified 51 papers reporting unique studies published in conferences and journals between 2009 and 2020. Most of the works (60%) were applied in supervised algorithms, in which the most used algorithm was the Random Forest (19,60%). The main types of data used were S.M.A.R.T attributes (14 papers) and log data (10 papers).},
booktitle = {Computational Science and Its Applications – ICCSA 2021: 21st International Conference, Cagliari, Italy, September 13–16, 2021, Proceedings, Part IX},
pages = {27–42},
numpages = {16},
keywords = {Systematic literature review, Data center, Monitoring, Machine learning},
location = {Cagliari, Italy}
}

@inproceedings{10.1109/IECON.2019.8927000,
author = {Vu, Hien Duc and Calderon, Edwin and Schweitzer, Patrick and Weber, Serge and Britsch, Nicolas},
title = {AC series arc fault detection with stacked autoencoders},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON.2019.8927000},
doi = {10.1109/IECON.2019.8927000},
abstract = {Series arc fault can occur in domestic electrical networks and lead to fire accidents. Many conventional detection algorithms based on time or frequency analysis have been published. Recently, machine learning technics have been adapted to the arc fault detection task and give promising results. However, the use of machine learning is frequently limited to the classification part. Manual feature extraction part which requires time and effort is always needed before obtaining the optimized features. In this paper, we used stacked autoencoders to replace the feature extraction part. The method presented can distinguish normal state and series arc fault with good accuracies.},
booktitle = {IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society},
pages = {4606–4609},
numpages = {4},
location = {Lisbon, Portugal}
}

@article{10.1016/j.inffus.2018.09.013,
author = {Praveen Kumar, D. and Amgoth, Tarachand and Annavarapu, Chandra Sekhara Rao},
title = {Machine learning algorithms for wireless sensor networks: A survey},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2018.09.013},
doi = {10.1016/j.inffus.2018.09.013},
journal = {Inf. Fusion},
month = sep,
pages = {1–25},
numpages = {25},
keywords = {Data aggregation, Network lifetime, Energy efficiency, Machine learning, Wireless sensor networks}
}

@inproceedings{10.1007/978-3-030-59851-8_18,
author = {Ozer, Gence and Netti, Alessio and Tafani, Daniele and Schulz, Martin},
title = {Characterizing HPC Performance Variation with Monitoring and Unsupervised Learning},
year = {2020},
isbn = {978-3-030-59850-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59851-8_18},
doi = {10.1007/978-3-030-59851-8_18},
abstract = {As HPC systems grow larger and more complex, characterizing the relationships between their different components and gaining insight on their behavior becomes difficult. In turn, this puts a burden on both system administrators and developers who aim at improving the efficiency and reliability of systems, algorithms and applications. Automated approaches capable of extracting a system’s behavior, as well as identifying anomalies and outliers, are necessary more than ever.In this work we discuss our exploratory study of Bayesian Gaussian mixture models, an unsupervised machine learning technique, to characterize the performance of an HPC system’s components, as well as to identify anomalies, based on sensor data. We propose an algorithmic framework for this purpose, implement it within the DCDB monitoring and operational data analytics system, and present several case studies carried out using data from a production HPC system.},
booktitle = {High Performance Computing: ISC High Performance 2020 International Workshops, Frankfurt, Germany, June 21–25, 2020, Revised Selected Papers},
pages = {280–292},
numpages = {13},
keywords = {Anomaly detection, Clustering, Operational data analytics, Monitoring, HPC systems},
location = {Frankfurt am Main, Germany}
}

@article{10.1016/j.knosys.2021.107386,
author = {Su, Kaige and Liu, Jianhua and Xiong, Hui},
title = {Hierarchical diagnosis of bearing faults using branch convolutional neural network considering noise interference and variable working conditions},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {230},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2021.107386},
doi = {10.1016/j.knosys.2021.107386},
journal = {Know.-Based Syst.},
month = oct,
numpages = {18},
keywords = {Variable working conditions, Noise interference, Intelligent bearing diagnosis, Hierarchical branch structure, Convolutional neural network}
}

@inproceedings{10.1145/2972958.2972964,
author = {Hosseini, Seyedrebvar and Turhan, Burak and M\"{a}ntyl\"{a}, Mika},
title = {Search Based Training Data Selection For Cross Project Defect Prediction},
year = {2016},
isbn = {9781450347723},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2972958.2972964},
doi = {10.1145/2972958.2972964},
abstract = {Context: Previous studies have shown that steered training data or dataset selection can lead to better performance for cross project defect prediction (CPDP). On the other hand, data quality is an issue to consider in CPDP.Aim: We aim at utilising the Nearest Neighbor (NN)-Filter, embedded in a genetic algorithm, for generating evolving training datasets to tackle CPDP, while accounting for potential noise in defect labels.Method: We propose a new search based training data (i.e., instance) selection approach for CPDP called GIS (Genetic Instance Selection) that looks for solutions to optimize a combined measure of F-Measure and GMean, on a validation set generated by (NN)-filter. The genetic operations consider the similarities in features and address possible noise in assigned defect labels. We use 13 datasets from PROMISE repository in order to compare the performance of GIS with benchmark CPDP methods, namely (NN)-filter and naive CPDP, as well as with within project defect prediction (WPDP).Results: Our results show that GIS is significantly better than (NN)-Filter in terms of F-Measure (p -- value ≪ 0.001, Cohen's d = 0.697) and GMean (p -- value ≪ 0.001, Cohen's d = 0.946). It also outperforms the naive CPDP approach in terms of F-Measure (p -- value ≪ 0.001, Cohen's d = 0.753) and GMean (p -- value ≪ 0.001, Cohen's d = 0.994). In addition, the performance of our approach is better than that of WPDP, again considering F-Measure (p -- value ≪ 0.001, Cohen's d = 0.227) and GMean (p -- value ≪ 0.001, Cohen's d = 0.595) values.Conclusions: We conclude that search based instance selection is a promising way to tackle CPDP. Especially, the performance comparison with the within project scenario encourages further investigation of our approach. However, the performance of GIS is based on high recall in the expense of low precision. Using different optimization goals, e.g. targeting high precision, would be a future direction to investigate.},
booktitle = {Proceedings of the The 12th International Conference on Predictive Models and Data Analytics in Software Engineering},
articleno = {3},
numpages = {10},
keywords = {Cross Project Defect Prediction, Genetic Algorithms, Instance Selection, Search Based Optimization, Training Data Selection},
location = {Ciudad Real, Spain},
series = {PROMISE 2016}
}

@inproceedings{10.1145/2025113.2025156,
author = {Lee, Taek and Nam, Jaechang and Han, DongGyun and Kim, Sunghun and In, Hoh Peter},
title = {Micro interaction metrics for defect prediction},
year = {2011},
isbn = {9781450304436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2025113.2025156},
doi = {10.1145/2025113.2025156},
abstract = {There is a common belief that developers' behavioral interaction patterns may affect software quality. However, widely used defect prediction metrics such as source code metrics, change churns, and the number of previous defects do not capture developers' direct interactions. We propose 56 novel micro interaction metrics (MIMs) that leverage developers' interaction information stored in the Mylyn data. Mylyn is an Eclipse plug-in, which captures developers' interactions such as file editing and selection events with time spent. To evaluate the performance of MIMs in defect prediction, we build defect prediction (classification and regression) models using MIMs, traditional metrics, and their combinations. Our experimental results show that MIMs significantly improve defect classification and regression accuracy.},
booktitle = {Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering},
pages = {311–321},
numpages = {11},
keywords = {mylyn, micro interaction metrics, defect prediction},
location = {Szeged, Hungary},
series = {ESEC/FSE '11}
}

@inproceedings{10.1007/978-3-030-79463-7_36,
author = {Kawalerowicz, Marcin and Madeyski, Lech},
title = {Jaskier: A Supporting Software Tool for&nbsp;Continuous Build Outcome Prediction Practice},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_36},
doi = {10.1007/978-3-030-79463-7_36},
abstract = {Continuous Defect Prediction (CDP) is an assisting software development practice that combines Software Defect Prediction (SDP) with machine learning aided modelling and continuous developer feedback. Jaskier is a set of software tools developed under the supervision and with the participation of the authors of the article that implements a lightweight version of CDP called Continuous Build Outcome Prediction (CBOP). CBOP uses classification to label the possible build results based on historical data and metrics derived from the software repository. This paper contains a detailed description of the tool that was already started to be used in the production environment of a real software project where the CBOP practice is being evaluated.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {426–438},
numpages = {13},
keywords = {Continuous integration, Software defect prediction},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1007/978-3-030-79463-7_40,
author = {Odyurt, Uraz and Sapra, Dolly and Pimentel, Andy D.},
title = {The Choice of AI Matters: Alternative Machine Learning Approaches for CPS Anomalies},
year = {2021},
isbn = {978-3-030-79462-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-79463-7_40},
doi = {10.1007/978-3-030-79463-7_40},
abstract = {We compare the pros and cons of two Artificial Intelligence (AI) solutions, addressing the anomaly detection and identification challenge in industrial Cyber-Physical Systems (CPS). We demonstrate how our current approach, Advanced DL, based on Convolutional Neural Networks (CNN) differs from a previous one, Classic ML. Though both workflows prove to result in highly accurate classification of anomalies, Classic ML is superior in this regard with 99.23% accuracy against 94.85%. This comes at a cost, as Classic ML requires total insight and expertise regarding the system under scrutiny and heavy amounts of feature engineering, while Advanced DL treats the data as a black box, minimising the effort. At the same time, we show that finding the best performing CNN model design is not trivial. We present a quantitative comparison of both workflows in terms of elapsed times for training, validation and preprocessing, alongside discussions on qualitative aspects. Such a comparison, involving analysis of workflows for the given use-case, is of independent interest. We find the choice of AI solution to be use-case dependent.},
booktitle = {Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26–29, 2021, Proceedings, Part II},
pages = {474–484},
numpages = {11},
keywords = {Industrial cyber-physical systems, Anomaly identification, Behavioural passports, Convolutional neural network, Machine learning},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1007/978-3-030-29400-7_1,
author = {Netti, Alessio and Kiziltan, Zeynep and Babaoglu, Ozalp and S\^{\i}rbu, Alina and Bartolini, Andrea and Borghesi, Andrea},
title = {Online Fault Classification in HPC Systems Through Machine Learning},
year = {2019},
isbn = {978-3-030-29399-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-29400-7_1},
doi = {10.1007/978-3-030-29400-7_1},
abstract = {As High-Performance Computing (HPC) systems strive towards the exascale goal, studies suggest that they will experience excessive failure rates. For this reason, detecting and classifying faults in HPC systems as they occur and initiating corrective actions before they can transform into failures will be essential for continued operation. In this paper, we propose a fault classification method for HPC systems based on machine learning that has been designed specifically to operate with live streamed data. We cast the problem and its solution within realistic operating constraints of online use. Our results show that almost perfect classification accuracy can be reached for different fault types with low computational overhead and minimal delay. We have based our study on a local dataset, which we make publicly available, that was acquired by injecting faults to an in-house experimental HPC system.},
booktitle = {Euro-Par 2019: Parallel Processing: 25th International Conference on Parallel and Distributed Computing, G\"{o}ttingen, Germany, August 26–30, 2019, Proceedings},
pages = {3–16},
numpages = {14},
keywords = {Machine learning, Fault detection, Monitoring, Resiliency, Exascale systems, High-performance computing},
location = {G\"{o}ttingen, Germany}
}

@article{10.1016/j.infsof.2021.106573,
author = {Zhang, Fanlong and Khoo, Siau-cheng},
title = {An empirical study on clone consistency prediction based on machine learning},
year = {2021},
issue_date = {Aug 2021},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {136},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2021.106573},
doi = {10.1016/j.infsof.2021.106573},
journal = {Inf. Softw. Technol.},
month = aug,
numpages = {16},
keywords = {Machine learning, Software maintenance, Clone consistency prediction, Clone consistent change, Code clones}
}

@inproceedings{10.1109/ICSME.2014.114,
author = {Shihab, Emad},
title = {Practical Software Quality Prediction},
year = {2014},
isbn = {9781479961467},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSME.2014.114},
doi = {10.1109/ICSME.2014.114},
abstract = {Software systems continue to play an increasingly important role in our daily lives, making the quality of software systems an extremely important issue. Therefore, a significant amount of recent research focused on the prioritization of software quality assurance efforts. One line of work that has been receiving an increasing amount of attention is Software Defect Prediction (SDP), where predictions are made to determine where future defects might appear. Our survey showed that in the past decade, more than 100 papers were published on SDP. Nevertheless, the practical adoption of SDP to date is limited. In this paper, we highlight the findings of our thesis, which identifies the challenges that hinder the adoption of SDP in practice. These challenges include the fact that the majority of SDP research rarely considers the impact of defects when performing their predictions, seldom provides guidance on how to use the SDP results, and is too reactive and defect-centric in nature. Therefore, we propose approaches that tackle these challenges. First, we present approaches that predict high-impact defects. Our approaches illustrate how SDP research can be tailored to consider the impact of defects when making their predictions. Second, we present approaches that simplify SDP models so they can be easily understood and illustrates how these simple models can be used to assist practitioners in prioritizing the creation of unit tests in large software systems. These approaches illustrate how SDP research can provide guidance to practitioners using SDP. Then, we argue that organizations are interested in proactive risk management, which covers more than just defects. For example, risky changes may not introduce defects but they could delay the release of projects. Therefore, we present an approach that predicts risky changes, illustrating how SDP can be more encompassing (i.e., by predicting risk, not only defects) and proactive (i.e., by predicting changes before they are incorporated into the code base).},
booktitle = {Proceedings of the 2014 IEEE International Conference on Software Maintenance and Evolution},
pages = {639–644},
numpages = {6},
keywords = {Software Quality, Software Defect Predcition, Risky Software Changes},
series = {ICSME '14}
}

@article{10.1504/ijiids.2020.109457,
author = {Anwar, Khalid and Siddiqui, Jamshed and Sohail, Shahab Saquib},
title = {Machine learning-based book recommender system: a survey and new perspectives},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {13},
number = {2–4},
issn = {1751-5858},
url = {https://doi.org/10.1504/ijiids.2020.109457},
doi = {10.1504/ijiids.2020.109457},
abstract = {The exponential growth of recommender systems research has drawn the attention of the scientific community recently. These systems are very useful in reducing information overload and providing users with the items of their need. The major areas where recommender systems have contributed significantly include e-commerce, online auction, and books and conference recommendation for academia and industrialists. Book recommender systems suggest books of interest to users according to their preferences and requirements. In this article, we have surveyed machine learning techniques which have been used in book recommender systems. Moreover, evaluation metrics applied to evaluate recommendation techniques is also studied. Six categories for book recommendation techniques have been identified and discussed which would enable the scientific community to lay a foundation of research in the concerned field. We have also proposed future perspectives to improve recommender system. We hope that researchers exploring recommendation technology in general and book recommendation in particular will be finding this work highly beneficial.},
journal = {Int. J. Intell. Inf. Database Syst.},
month = jan,
pages = {231–248},
numpages = {17},
keywords = {evaluation metrics, association rule mining, classification, machine learning, BRS, book recommender system}
}

@article{10.1007/s00500-021-05860-9,
author = {Liu, Haichao and Song, Xiaona and Zhang, Fagui},
title = {Fault diagnosis of new energy vehicles based on improved machine learning},
year = {2021},
issue_date = {Sep 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {18},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-021-05860-9},
doi = {10.1007/s00500-021-05860-9},
abstract = {The new energy vehicle system is in the initial stage of application, so the probability of fault is greater. Therefore, its reliability urgently needs to be improved. In order to improve the fault diagnosis effect of new energy vehicles, this paper proposes a fault diagnosis system of new energy vehicle electric drive system based on improved machine learning and also proposes several typical fault detection and diagnosis methods. Through the study of the operating characteristics and structural characteristics of the electric drive system and the analysis of the fault mechanism, this paper classifies the main faults of the electric drive system according to the self-test requirements of the electric drive system and the online diagnosis requirements and presents the self-test fault tree and online diagnosis fault tree of the electric drive system. In addition, this paper designs experiments to verify the performance of the system proposed by this paper, simulates the current common system fault conditions, and uses the system constructed in this paper to perform system fault diagnosis. The research results show that the performance of the fault diagnosis system for drive energy vehicles constructed in this paper is reliable.},
journal = {Soft Comput.},
month = sep,
pages = {12091–12106},
numpages = {16},
keywords = {Fault diagnosis, New energy vehicle, Improved algorithm, Machine learning}
}

@inproceedings{10.1145/3349341.3349460,
author = {Wang, Xiaojuan and Wang, Defu and Zhang, Yong and Jin, Lei and Song, Mei},
title = {Unsupervised Learning for Log Data Analysis Based on Behavior and Attribute Features},
year = {2019},
isbn = {9781450371506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3349341.3349460},
doi = {10.1145/3349341.3349460},
abstract = {In some special application environments, network fault can lead to loss of important information or even mission failures, resulting in unpredictable losses. Therefore, it has certain research significance and practical value to evaluate the network status and predict the possible faults before performing the key tasks. Based on the logs collected by the router board in the real network, this paper analyses the behavior type, attribute information and the corresponding status value, and detects the hidden fault or network attack, so as to provide early warning information for operators. We propose a deep neural network model utilizing Long Short-Term Memory (LSTM) to predict the current number of level-1 logs. By comparing the predicted number of level-1 logs, it can detect abnormal behavior such as a surge in the number of logs. What's more, we perform semantic analysis on attribute information to construct attribute syntax forest, which assists maintenance staff to monitor the system through key fingerprint information in the log. In addition, we adopt attribute information and status value to train the unsupervised learning algorithm models such as Isolation Forest, OneClassSVM and LocalOutlierFactor. What's more, this paper analyses the results to find out the causes of log surge, and to assist operators in subsequent maintenance of the system.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science},
pages = {510–518},
numpages = {9},
keywords = {Unsupervised Machine Learning, Network Fault, Log Analysis, LSTM},
location = {Wuhan, Hubei, China},
series = {AICS 2019}
}

@article{10.1155/2021/6612342,
author = {Li, Yao and Dourado, Ant\'{o}nio},
title = {A Fault Prediction and Cause Identification Approach in Complex Industrial Processes Based on Deep Learning},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/6612342},
doi = {10.1155/2021/6612342},
abstract = {Faults occurring in the production line can cause many losses. Predicting the fault events before they occur or identifying the causes can effectively reduce such losses. A modern production line can provide enough data to solve the problem. However, in the face of complex industrial processes, this problem will become very difficult depending on traditional methods. In this paper, we propose a new approach based on a deep learning (DL) algorithm to solve the problem. First, we regard these process data as a spatial sequence according to the production process, which is different from traditional time series data. Second, we improve the long short-term memory (LSTM) neural network in an encoder-decoder model to adapt to the branch structure, corresponding to the spatial sequence. Meanwhile, an attention mechanism (AM) algorithm is used in fault detection and cause identification. Third, instead of traditional biclassification, the output is defined as a sequence of fault types. The approach proposed in this article has two advantages. On the one hand, treating data as a spatial sequence rather than a time sequence can overcome multidimensional problems and improve prediction accuracy. On the other hand, in the trained neural network, the weight vectors generated by the AM algorithm can represent the correlation between faults and the input data. This correlation can help engineers identify the cause of faults. The proposed approach is compared with some well-developed fault diagnosing methods in the Tennessee Eastman process. Experimental results show that the approach has higher prediction accuracy, and the weight vector can accurately label the factors that cause faults.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {13}
}

@article{10.1007/s11704-020-9441-1,
author = {Sun, Xiaobing and Zhou, Tianchi and Wang, Rongcun and Duan, Yucong and Bo, Lili and Chang, Jianming},
title = {Experience report: investigating bug fixes in machine learning frameworks/libraries},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {15},
number = {6},
issn = {2095-2228},
url = {https://doi.org/10.1007/s11704-020-9441-1},
doi = {10.1007/s11704-020-9441-1},
abstract = {Machine learning (ML) techniques and algorithms have been successfully and widely used in various areas including software engineering tasks. Like other software projects, bugs are also common in ML projects and libraries. In order to more deeply understand the features related to bug fixing in ML projects, we conduct an empirical study with 939 bugs from five ML projects by manually examining the bug categories, fixing patterns, fixing scale, fixing duration, and types of maintenance. The results show that (1) there are commonly seven types of bugs in ML programs; (2) twelve fixing patterns are typically used to fix the bugs in ML programs; (3) 68.80% of the patches belong to micro-scale-fix and small-scale-fix; (4) 66.77% of the bugs in ML programs can be fixed within one month; (5) 45.90% of the bug fixes belong to corrective activity from the perspective of software maintenance. Moreover, we perform a questionnaire survey and send them to developers or users of ML projects to validate the results in our empirical study. The results of our empirical study are basically consistent with the feedback from developers. The findings from the empirical study provide useful guidance and insights for developers and users to effectively detect and fix bugs in ML projects.},
journal = {Front. Comput. Sci.},
month = dec,
numpages = {16},
keywords = {questionnaire survey, empirical study, machine learning project, bug fixing}
}

@article{10.1007/s10922-020-09512-5,
author = {Le, Duc C. and Zincir-Heywood, Nur},
title = {A Frontier: Dependable, Reliable and Secure Machine Learning for Network/System Management},
year = {2020},
issue_date = {Oct 2020},
publisher = {Plenum Press},
address = {USA},
volume = {28},
number = {4},
issn = {1064-7570},
url = {https://doi.org/10.1007/s10922-020-09512-5},
doi = {10.1007/s10922-020-09512-5},
abstract = {Modern networks and systems pose many challenges to traditional management approaches. Not only the number of devices and the volume of network traffic are increasing exponentially, but also new network protocols and technologies require new techniques and strategies for monitoring controlling and managing up and coming networks and systems. Moreover, machine learning has recently found its successful applications in many fields due to its capability to learn from data to automatically infer patterns for network analytics. Thus, the deployment of machine learning in network and system management has become imminent. This work provides a review of the applications of machine learning in network and system management. Based on this review, we aim to present the current opportunities and challenges in and highlight the need for dependable, reliable and secure machine learning for network and system management.},
journal = {J. Netw. Syst. Manage.},
month = oct,
pages = {827–849},
numpages = {23},
keywords = {Secure machine learning, Reliable and dependable machine learning, Network and system management}
}

@book{10.5555/2385865,
author = {Akalya, Devi C. and Surendiran, B. and Kannammal, K. E.},
title = {Software Fault Prediction: A Software Fault Prediction Model by Hybrid Feature Selection and Hybrid Classifier Approach},
year = {2012},
isbn = {3659144819},
publisher = {LAP Lambert Academic Publishing},
address = {Koln, DEU},
abstract = {Quality of the software is an important factor for any software company. Software fault prediction is a data mining process that helps to improve the quality. Data mining tools both open source and proprietary are available today. These bring lots of research works in this area. Software fault is the bug in the software that is identified only after its installation and it makes the software behave not in the expected way. Bug is there even after testing due to various constraints like cost, time. Prediction will help identify those fault prone areas and with that one can concentrate on those modules in future. Hybrid Feature Selection and Hybrid Classifier approach is a way to improve the software fault prediction accuracy. In Hybrid feature selection, irrelevant, redundant features are first filtered and this filtered feature set reduces the input feature set of wrapper. In Hybrid Classifier approach Linear Discriminant Analysis score is used as an additional feature for Neural Network classifier. These models give a better fault prediction accuracy.}
}

@inproceedings{10.1145/3196398.3196459,
author = {Bulmer, Tyson and Montgomery, Lloyd and Damian, Daniela},
title = {Predicting developers' IDE commands with machine learning},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196398.3196459},
doi = {10.1145/3196398.3196459},
abstract = {When a developer is writing code they are usually focused and in a state-of-mind which some refer to as flow. Breaking out of this flow can cause the developer to lose their train of thought and have to start their thought process from the beginning. This loss of thought can be caused by interruptions and sometimes slow IDE interactions. Predictive functionality has been harnessed in user applications to speed up load times, such as in Google Chrome's browser which has a feature called "Predicting Network Actions". This will pre-load web-pages that the user is most likely to click through. This mitigates the interruption that load times can introduce. In this paper we seek to make the first step towards predicting user commands in the IDE. Using the MSR 2018 Challenge Data of over 3000 developer session and over 10 million recorded events, we analyze and cleanse the data to be parsed into event series, which can then be used to train a variety of machine learning models, including a neural network, to predict user induced commands. Our highest performing model is able to obtain a 5 cross-fold validation prediction accuracy of 64%.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {82–85},
numpages = {4},
keywords = {IDE monitoring, developer commands, machine learning, neural network},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1109/ISSRE.2014.35,
author = {Lu, Huihua and Kocaguneli, Ekrem and Cukic, Bojan},
title = {Defect Prediction between Software Versions with Active Learning and Dimensionality Reduction},
year = {2014},
isbn = {9781479960330},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2014.35},
doi = {10.1109/ISSRE.2014.35},
abstract = {Accurate detection of defects prior to product release helps software engineers focus verification activities on defect prone modules, thus improving the effectiveness of software development. A common scenario is to use the defects from prior releases to build the prediction model for the upcoming release, typically through a supervised learning method. As software development is a dynamic process, fault characteristics in subsequent releases may vary. Therefore, supplementing the defect information from prior releases with limited information about the defects from the current release detected early seems to offer intuitive and practical benefits. We propose active learning as a way to automate the development of models which improve the performance of defect prediction between successive releases. Our results show that the integration of active learning with uncertainty sampling consistently outperforms the corresponding supervised learning approach. We further improve the prediction performance with feature compression techniques, where feature selection or dimensionality reduction is applied to defect data prior to active learning. We observe that dimensionality reduction techniques, particularly multidimensional scaling with random forest similarity, work better than feature selection due to their ability to identify and combine essential information in data set features. We present the improvements offered by this methodology through the prediction of defective modules in the three successive versions of Eclipse.},
booktitle = {Proceedings of the 2014 IEEE 25th International Symposium on Software Reliability Engineering},
pages = {312–322},
numpages = {11},
keywords = {Software defect prediction, Machine learning, Dimensionality reduction, Complexity measures, Active learning},
series = {ISSRE '14}
}

@article{10.1007/s10470-018-1362-7,
author = {Shokrolahi, Seyed Moslem and Kazempour, Alireza Tabrizi},
title = {A novel approach for fault detection of analog circuit by using improved EEMD},
year = {2019},
issue_date = {March     2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {98},
number = {3},
issn = {0925-1030},
url = {https://doi.org/10.1007/s10470-018-1362-7},
doi = {10.1007/s10470-018-1362-7},
abstract = {Fault detection and circuit testing consider as an important stage in production process. Fault detection is generally the last part of production process and after that the system is ready to use. Nowadays, controlling circuits and systems are widely used in control, communications, medical instruments and etc. the complexity of circuits are increased by growth of technology. Therefore, research and investigation on circuit fault detection is a challenging and non-ignorable issue. Many method has been presented in order to solve this problem. In this work methods based on signal processing and artificial intelligence will be used. Many of this methods such as wavelet transform, artificial neural networks, support vector machines, genetic algorithm and etc. were used in fault detection field. In this paper, a new method for the empirical mode decomposition of signals into independent IMF is presented, which results in extraction of discriminative features and better fault detection accuracy. The proposed method has been investigated and compared using two analog benchmark circuit. The results show a better performance of the proposed method.},
journal = {Analog Integr. Circuits Signal Process.},
month = mar,
pages = {527–534},
numpages = {8},
keywords = {Neural network, Feature extraction, Fault detection, Empirical mode decomposition}
}

@inproceedings{10.5555/2818754.2818850,
author = {Ghotra, Baljinder and McIntosh, Shane and Hassan, Ahmed E.},
title = {Revisiting the impact of classification techniques on the performance of defect prediction models},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Defect prediction models help software quality assurance teams to effectively allocate their limited resources to the most defect-prone software modules. A variety of classification techniques have been used to build defect prediction models ranging from simple (e.g., logistic regression) to advanced techniques (e.g., Multivariate Adaptive Regression Splines (MARS)). Surprisingly, recent research on the NASA dataset suggests that the performance of a defect prediction model is not significantly impacted by the classification technique that is used to train it. However, the dataset that is used in the prior study is both: (a) noisy, i.e., contains erroneous entries and (b) biased, i.e., only contains software developed in one setting. Hence, we set out to replicate this prior study in two experimental settings. First, we apply the replicated procedure to the same (known-to-be noisy) NASA dataset, where we derive similar results to the prior study, i.e., the impact that classification techniques have appear to be minimal. Next, we apply the replicated procedure to two new datasets: (a) the cleaned version of the NASA dataset and (b) the PROMISE dataset, which contains open source software developed in a variety of settings (e.g., Apache, GNU). The results in these new datasets show a clear, statistically distinct separation of groups of techniques, i.e., the choice of classification technique has an impact on the performance of defect prediction models. Indeed, contrary to earlier research, our results suggest that some classification techniques tend to produce defect prediction models that outperform others.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {789–800},
numpages = {12},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1109/AICCSA.2006.205110,
author = {Bibi, S. and Tsoumakas, G. and Stamelos, I. and Vlahvas, I.},
title = {Software Defect Prediction Using Regression via Classification},
year = {2006},
isbn = {1424402115},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/AICCSA.2006.205110},
doi = {10.1109/AICCSA.2006.205110},
booktitle = {Proceedings of the IEEE International Conference on Computer Systems and Applications},
pages = {330–336},
numpages = {7},
series = {AICCSA '06}
}

@inproceedings{10.23919/ICEMS50442.2020.9291033,
author = {Quabeck, Stefan and Shangguan, Wenbo and Scharfenstein, Daniel and De Doncker, Rik W.},
title = {Detection of Broken Rotor Bars in Induction Machines using Machine Learning Methods},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/ICEMS50442.2020.9291033},
doi = {10.23919/ICEMS50442.2020.9291033},
abstract = {Induction machines are used in a wide range of industrial applications due to their simplicity, ruggedness, and low cost. Despite their robustness, induction machines eventually fail at one point due to a variety of failure mechanisms. Many faults exhibit specific fault frequencies in the motor current spectrum, which allows for fault detection. Many classical fault detection methods have been developed for grid-connected machines with quasi-static operating points. In inverter-driven machines with a wide operating range, these methods cannot reliably detect and classify faults. Machine learning methods have been successfully used for various classification tasks. This work applies a combination of classical fault detection approaches with different fault classification algorithms to reliably detect induction machine faults over a wide operating range.The developed fault classification method is evaluated using steady-state measurements on an inverter-fed 5.5kW induction machine. The algorithm shows promising fault detection and classification capabilities and achieves an accuracy of 97.4%.},
booktitle = {2020 23rd International Conference on Electrical Machines and Systems (ICEMS)},
pages = {620–625},
numpages = {6},
location = {Hamamatsu}
}

@article{10.1007/s11042-018-6912-6,
author = {Singh, Rahul Dev and Mittal, Ajay and Bhatia, Rajesh K.},
title = {3D convolutional neural network for object recognition: a review},
year = {2019},
issue_date = {June      2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {78},
number = {12},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-018-6912-6},
doi = {10.1007/s11042-018-6912-6},
abstract = {Recognition of an object from an image or image sequences is an important task in computer vision. It is an important low-level image processing operation and plays a crucial role in many real-world applications. The challenges involved in object recognition are multi-model, multi-pose, complicated background, and depth variations. Recently developed methods have dealt with these challenges and have reported remarkable results for 3D objects. In this paper, a comprehensive overview of recent advances in 3D object recognition using Convolutional Neural Networks (CNN) has been presented. Along with the latest progress in 3D images, general overview of object recognition of 2D, 2.5D, and 3D images is presented.},
journal = {Multimedia Tools Appl.},
month = jun,
pages = {15951–15995},
numpages = {45},
keywords = {Supervised learning, Object recognition, Deep learning, Convolutional neural network, 3D images}
}

@inproceedings{10.1145/3387939.3388613,
author = {Scheerer, Max and Klamroth, Jonas and Reussner, Ralf and Beckert, Bernhard},
title = {Towards classes of architectural dependability assurance for machine-learning-based systems},
year = {2020},
isbn = {9781450379625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387939.3388613},
doi = {10.1145/3387939.3388613},
abstract = {Advances in Machine Learning (ML) have brought previously hard to handle problems within arm's reach. However, this power comes at the cost of unassured reliability and lacking transparency. Overcoming this drawback is very hard due to the probabilistic nature of ML. Current approaches mainly tackle this problem by developing more robust learning procedures. Such algorithmic approaches, however, are limited to certain types of uncertainties and cannot deal with all of them, e.g., hardware failure. This paper discusses how this problem can be addressed at architectural rather than algorithmic level to assess systems dependability properties in early development stages. Moreover, we argue that Self-Adaptive Systems (SAS) are more suited to safeguard ML w.r.t. various uncertainties. As a step towards this we propose classes of dependability in which ML-based systems may be categorized and discuss which and how assurances can be made for each class.},
booktitle = {Proceedings of the IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
pages = {31–37},
numpages = {7},
keywords = {software quality, machine learning, dependability, artificial intelligence, architectural-driven self-adaptation},
location = {Seoul, Republic of Korea},
series = {SEAMS '20}
}

@inproceedings{10.1109/COMPSAC.2015.58,
author = {Zhang, Yun and Lo, David and Xia, Xin and Sun, Jianling},
title = {An Empirical Study of Classifier Combination for Cross-Project Defect Prediction},
year = {2015},
isbn = {9781467365642},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/COMPSAC.2015.58},
doi = {10.1109/COMPSAC.2015.58},
abstract = {To help developers better allocate testing and debugging efforts, many software defect prediction techniques have been proposed in the literature. These techniques can be used to predict classes that are more likely to be buggy based on past history of buggy classes. These techniques work well as long as a sufficient amount of data is available to train a prediction model. However, there is rarely enough training data for new software projects. To deal with this problem, cross-project defect prediction, which transfers a prediction model trained using data from one project to another, has been proposed and is regarded as a new challenge for defect prediction. So far, only a few cross-project defect prediction techniques have been proposed. To advance the state-of-the-art, in this work, we investigate 7 composite algorithms, which integrate multiple machine learning classifiers, to improve cross-project defect prediction. To evaluate the performance of the composite algorithms, we perform experiments on 10 open source software systems from the PROMISE repository which contain a total of 5,305 instances labeled as defective or clean. We compare the composite algorithms with CODEP Logistic, which is the latest cross-project defect prediction algorithm proposed by Panichella et al., in terms of two standard evaluation metrics: cost effectiveness and F-measure. Our experiment results show that several algorithms outperform CODEP Logistic: Max performs the best in terms of F-measure and its average F-measure outperforms that of CODEP Logistic by 36.88%. Bagging J48 performs the best in terms of cost effectiveness and its average cost effectiveness outperforms that of CODEP Logistic by 15.34%.},
booktitle = {Proceedings of the 2015 IEEE 39th Annual Computer Software and Applications Conference - Volume 02},
pages = {264–269},
numpages = {6},
keywords = {Defect Prediction, Cross-Project, Classifier Combination},
series = {COMPSAC '15}
}

@article{10.1007/s11063-020-10319-3,
author = {Hu, Jiaojiao and Wang, Xiaofeng and Zhang, Ying and Zhang, Depeng and Zhang, Meng and Xue, Jianru},
title = {Time Series Prediction Method Based on Variant LSTM Recurrent Neural Network},
year = {2020},
issue_date = {Oct 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {52},
number = {2},
issn = {1370-4621},
url = {https://doi.org/10.1007/s11063-020-10319-3},
doi = {10.1007/s11063-020-10319-3},
abstract = {Time series prediction problems are a difficult type of predictive modeling problem. In this paper, we propose a time series prediction method based on a variant long short-term memory (LSTM) recurrent neural network. In the proposed method, we firstly improve the memory module of the LSTM recurrent neural network by merging its forget gate and input gate into one update gate, and using Sigmoid layer to control information update. Using improved LSTM recurrent neural network, we develop a time series prediction model. In the proposed model, the parameter migration method is used model update to ensure the model has good predictive ability after predicting multi-step sequences. Experimental results show, compared with several typical time series prediction models, the proposed method have better performance for long-sequence data prediction.},
journal = {Neural Process. Lett.},
month = oct,
pages = {1485–1500},
numpages = {16},
keywords = {Variant LSTM network, Recurrent neural network, Time series prediction, Deep learning}
}

@article{10.1007/s42979-021-00872-6,
author = {Sakhrawi, Zaineb and Sellami, Asma and Bouassida, Nadia},
title = {Software Enhancement Effort Prediction Using Machine-Learning Techniques: A Systematic Mapping Study},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {6},
url = {https://doi.org/10.1007/s42979-021-00872-6},
doi = {10.1007/s42979-021-00872-6},
abstract = {Accurate prediction of software enhancement effort is a key success in software project management. To increase the accuracy of estimates, several proposals used machine-learning (ML) techniques for predicting the software project effort. However, there is no clear evidence for determining which techniques to select for predicting more accurate effort within the context of enhancement projects. This paper aims to present a systematic mapping study (SMS) related to the use of ML techniques for predicting software enhancement effort (SEME). A SMS was performed by reviewing relevant papers from 1995 through 2020. We followed well-known guidelines. We selected 30 relevant studies; 19 from journals and 11 conferences proceedings through 4 search engines. Some of the key findings indicate that (1) there is relatively little activity in the area of SEME, (2) most of the successful studies cited focused on regression problems for enhancement maintenance effort prediction, (3) SEME is the dependent variable the most commonly used in software enhancement project planning, and the enhancement size (or the functional change size) is the most used independent variables, (4) several private datasets were used in the selected studies, and there is a growing demand for the use of commonly published datasets, and (5) only single models were employed for SEME prediction. Results indicate that much more work is needed to develop repositories in all prediction models. Based on the findings obtained in this SMS, estimators should be aware that SEME using ML techniques as part of non-algorithmic models demonstrated increased accuracy prediction over the algorithmic models. The use of ML techniques generally provides a reasonable accuracy when using the enhancement functional size as independent variables.},
journal = {SN Comput. Sci.},
month = sep,
numpages = {15},
keywords = {Machine learning (ML), Software enhancement effort (SEME) prediction, Functional change (FC), Systematic mapping study (SMS)}
}

@article{10.1007/s00521-020-05250-6,
author = {Zhao, Hailei},
title = {Futures price prediction of agricultural products based on machine learning},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {3},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05250-6},
doi = {10.1007/s00521-020-05250-6},
abstract = {Agricultural product futures are crucial to economic development, and the prediction of agricultural product futures prices has an important impact on the stability of the market economy. In order to improve the accuracy of agricultural product futures price prediction, based on machine learning algorithms, this study mainly uses machine learning methods to predict futures prices based on the analysis of fundamental factors affecting agricultural product futures prices. Moreover, in this study, wavelet analysis method is used to smooth the data and then build a model to process the hierarchical information after signal decomposition. In addition, this study conducts model validity studies through cases to draw comparative statistical diagrams to analyze the accuracy of model prediction data. The research shows that the model proposed in this paper has certain effects and can provide theoretical reference for subsequent related research.},
journal = {Neural Comput. Appl.},
month = feb,
pages = {837–850},
numpages = {14},
keywords = {Price prediction, Futures, Agricultural products, Machine learning}
}

@article{10.1007/s11042-017-4419-1,
author = {Singh, Sandip Kumar and Kumar, Sandeep and Dwivedi, J. P.},
title = {Compound fault prediction of rolling bearing using multimedia data},
year = {2017},
issue_date = {Sep 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {18},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-017-4419-1},
doi = {10.1007/s11042-017-4419-1},
abstract = {Catastrophic failure of mechanical systems due to faults occurring on rolling bearing is still a great challenge. These faults, which are of multiple type, are compounded in nature. Vibration analysis of multimedia signals is one of the most effective techniques for the health monitoring of these bearings. A compound fault signal usually consists of multiple characteristic signals and strong confusion noise, which makes it a tough task to separate weak fault signals from them. To resolve the compound fault diagnosis problem of rolling bearings byseparation of multimedia signals' (obtained from acoustic or acceleration sensors), ensemble empirical mode decomposition (EEMD) method along with some classifier (like independent component analysis (ICA) technique) has been used to some degree of success. But, they are not found capable of detecting difficult faults existing on small balls of the bearing. In order to solve this problem, we are going to propose a new method based on use of Combined Mode Functions (CMF) for selecting the intrinsic mode functions(IMFs) instead of the maximum cross correlation coefficient based EEMD technique, sandwiched with, Convolution Neural Networks (CNN), which are deep neural nets, used as fault classifiers. This composite CNN-CMF-EEMD methodovercomes the deficiencies of other approaches, such as the inability to learn the complex non-linear relationships in fault diagnosis issues and fine compound faults like those occurring on small balls of the bearing. The difficult compound faults can be separated effectively by executing CNN-CMF-EEMD method, which makes the fault features more easily extracted and more clearly identified. Experimental results reinforce the effectiveness of using CNN-CMF--EEMD technique for fine compound faults. A comparison of CNN-CMF-EEMD with Artificial Neural Networks (ANN) based ANN-CMF-EEMD shows the capability of CNN as a powerful classifier in the domain of compound fault features of rolling bearing.},
journal = {Multimedia Tools Appl.},
month = sep,
pages = {18771–18788},
numpages = {18},
keywords = {Multimedia signals, Intrinsic mode functions, Independent component analysis, Ensemble empirical mode distribution, Convolution neural network, Compound faults, Combined mode functions, Artificial neural networks}
}

@article{10.1016/j.automatica.2019.04.020,
author = {Shen, Ying and Wu, Zheng-Guang and Shi, Peng and Wen, Guanghui},
title = {Dissipativity based fault detection for 2D Markov jump systems with asynchronous modes},
year = {2019},
issue_date = {Aug 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {106},
number = {C},
issn = {0005-1098},
url = {https://doi.org/10.1016/j.automatica.2019.04.020},
doi = {10.1016/j.automatica.2019.04.020},
journal = {Automatica},
month = aug,
pages = {8–17},
numpages = {10},
keywords = {Markov jump system, 2D system, Dissipativity, Asynchronization, Fault detection}
}

@inproceedings{10.1007/978-3-642-02481-8_80,
author = {Santos, Igor and Nieves, Javier and Penya, Yoseba K. and Bringas, Pablo G.},
title = {Optimising Machine-Learning-Based Fault Prediction in Foundry Production},
year = {2009},
isbn = {9783642024801},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-02481-8_80},
doi = {10.1007/978-3-642-02481-8_80},
abstract = {Microshrinkages are known as probably the most difficult defects to avoid in high-precision foundry. The presence of this failure renders the casting invalid, with the subsequent cost increment. Modelling the foundry process as an expert knowledge cloud allows properly-trained machine learning algorithms to foresee the value of a certain variable, in this case the probability that a microshrinkage appears within a casting. Extending previous research that presented outstanding results with a Bayesian-network-based approach, we have adapted and tested an artificial neural network and the K-nearest neighbour algorithm for the same objective. Finally, we compare the obtained results and show that Bayesian networks are more suitable than the rest of the counterparts for the prediction of microshrinkages.},
booktitle = {Proceedings of the 10th International Work-Conference on Artificial Neural Networks: Part II: Distributed Computing, Artificial Intelligence, Bioinformatics, Soft Computing, and Ambient Assisted Living},
pages = {554–561},
numpages = {8},
keywords = {fault prediction, data mining, Machine learning},
location = {Salamanca, Spain},
series = {IWANN '09}
}

@inproceedings{10.1007/978-3-030-78612-0_41,
author = {Zhang, Xiaolong and Yang, Rengbo and Guo, Guangfeng and Zhang, Junxing},
title = {Sensor Failure Detection Based on Programmable Switch and Machine Learning},
year = {2021},
isbn = {978-3-030-78611-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-78612-0_41},
doi = {10.1007/978-3-030-78612-0_41},
abstract = {With the large-scale application of the Internet of Things, various sensors continue to produce new and various environmental data. Among them, there may be some failure data caused by environmental interference, device aging, etc., and these failure data are given to relevant scientific researchers and The Internet of Things system brings huge problems. We propose a new kind of Internet of Things nodes combined with programmable switches failure detection method. Different from the method proposed by the predecessors, we perform failure detection during the sensor data packet transmission. This method realizes the interaction between the programmable switch and the local controller. It can perform failure detection on a large amount of sensor data in real-time. Use the processing power of programmable switches to reduce the feature extraction time in machine learning algorithms. In this article, we reviewed the technical background of programmable switch The Internet of Things failure detection and explained its architecture. To prove the feasibility of the system, we implemented it on the bmv2 software switch. The prototype was verified through experiments, simulation evaluation was performed on the real data set, and the average time for the machine learning algorithm to classify each sensor data was 1.26&nbsp;ms.},
booktitle = {Artificial Intelligence and Security: 7th International Conference, ICAIS 2021, Dublin, Ireland, July 19–23, 2021, Proceedings, Part II},
pages = {514–525},
numpages = {12},
keywords = {Fault diagnosis, Fault detection, Software-defined networking, P4, Wireless sensor networks, Internet of Things},
location = {Dublin, Ireland}
}

@article{10.1007/s00500-018-3093-1,
author = {Yu, Xiao and Wu, Man and Jian, Yiheng and Bennin, Kwabena Ebo and Fu, Mandi and Ma, Chuanxiang},
title = {Cross-company defect prediction via semi-supervised clustering-based data filtering and MSTrA-based transfer learning},
year = {2018},
issue_date = {May       2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {10},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-018-3093-1},
doi = {10.1007/s00500-018-3093-1},
abstract = {Cross-company defect prediction (CCDP) is a practical way that trains a prediction model by exploiting one or multiple projects of a source company and then applies the model to a target company. Unfortunately, larger irrelevant cross-company (CC) data usually make it difficult to build a prediction model with high performance. On the other hand, brute force leveraging of CC data poorly related to within-company data may decrease the prediction model performance. To address such issues, we aim to provide an effective solution for CCDP. First, we propose a novel semi-supervised clustering-based data filtering method (i.e., SSDBSCAN filter) to filter out irrelevant CC data. Second, based on the filtered CC data, we for the first time introduce multi-source TrAdaBoost algorithm, an effective transfer learning method, into CCDP to import knowledge not from one but from multiple sources to avoid negative transfer. Experiments on 15 public datasets indicate that: (1) our proposed SSDBSCAN filter achieves better overall performance than compared data filtering methods; (2) our proposed CCDP approach achieves the best overall performance among all tested CCDP approaches; and (3) our proposed CCDP approach performs significantly better than with-company defect prediction models.},
journal = {Soft Comput.},
month = may,
pages = {3461–3472},
numpages = {12},
keywords = {Transfer learning, SSDBSCAN, Multi-source TrAdaBoost, Cross-company defect prediction}
}

@inproceedings{10.1007/978-3-030-55789-8_21,
author = {Schranz, Thomas and Schweiger, Gerald and Pabst, Siegfried and Wotawa, Franz},
title = {Machine Learning for Water Supply Supervision},
year = {2020},
isbn = {978-3-030-55788-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-55789-8_21},
doi = {10.1007/978-3-030-55789-8_21},
abstract = {In an industrial setting water supply systems can be complex. Constructing physical models for fault diagnosis or prediction requires extensive knowledge about the system’s components and characteristics. Through advances in embedded computing, consumption meter data is often readily available. This data can be used to construct black box models that describe system behavior and highlight irregularities such as leakages. In this paper we discuss the application of artificial intelligence to the task of identifying irregular consumption patterns. We describe and evaluate data models based on neural networks and decision trees that were used for consumption prediction in buildings at the Graz University of Technology.},
booktitle = {Trends in Artificial Intelligence Theory and Applications. Artificial Intelligence Practices: 33rd International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2020, Kitakyushu, Japan, September 22-25, 2020, Proceedings},
pages = {238–249},
numpages = {12},
keywords = {Data science, Fault diagnosis, Machine learning},
location = {Kitakyushu, Japan}
}

@inproceedings{10.1007/978-3-030-27615-7_16,
author = {de Souza, Matheus Maia and Netto, Jo\~{a}o Cesar and Galante, Renata},
title = {FFT-2PCA: A New Feature Extraction Method for Data-Based Fault Detection},
year = {2019},
isbn = {978-3-030-27614-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27615-7_16},
doi = {10.1007/978-3-030-27615-7_16},
abstract = {The industrial environment requires constant attention for faults on processes. This concern has central importance both for workers safety and process efficiency. Modern Process Automation Systems are capable of produce a large amount of data; upon this data, machine learning algorithms can be trained to detect faults. However, this data high complexity and dimensionality causes a decrease in these algorithms quality metrics. In this work, we introduce a new feature extraction method to improve the quality metrics of data-based fault detection. Our method uses a Fast Fourier Transform (FFT) to extract a temporal signature from the input data, to reduce the feature dimensionality generated by signature extraction, we apply a sequence of Principal Component Analysis (PCA). Then, the feature extraction output feeds a classification algorithm. We achieve an overall improvement of 17.4% on F1 metric for the ANN classifier. Also, due to intrinsic FFT characteristics, we verified a meaningful reduction in development time for data-based fault detection solution.},
booktitle = {Database and Expert Systems Applications: 30th International Conference, DEXA 2019, Linz, Austria, August 26–29, 2019, Proceedings, Part I},
pages = {215–224},
numpages = {10},
keywords = {Feature extraction, Fault detection, Tennessee Eastman process},
location = {Linz, Austria}
}

@inproceedings{10.1145/3422392.3422427,
author = {Oliveira, Daniel and Assun\c{c}\~{a}o, Wesley K. G. and Souza, Leonardo and Oizumi, Willian and Garcia, Alessandro and Fonseca, Baldoino},
title = {Applying Machine Learning to Customized Smell Detection: A Multi-Project Study},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422427},
doi = {10.1145/3422392.3422427},
abstract = {Code smells are considered symptoms of poor implementation choices, which may hamper the software maintainability. Hence, code smells should be detected as early as possible to avoid software quality degradation. Unfortunately, detecting code smells is not a trivial task. Some preliminary studies investigated and concluded that machine learning (ML) techniques are a promising way to better support smell detection. However, these techniques are hard to be customized to promote an early and accurate detection of specific smell types. Yet, ML techniques usually require numerous code examples to be trained (composing a relevant dataset) in order to achieve satisfactory accuracy. Unfortunately, such a dependency on a large validated dataset is impractical and leads to late detection of code smells. Thus, a prevailing challenge is the early customized detection of code smells taking into account the typical limited training data. In this direction, this paper reports a study in which we collected code smells, from ten active projects, that were actually refactored by developers, differently from studies that rely on code smells inferred by researchers. These smells were used for evaluating the accuracy regarding early detection of code smells by using seven ML techniques. Once we take into account such smells that were considered as important by developers, the ML techniques are able to customize the detection in order to focus on smells observed as relevant in the investigated systems. The results showed that all the analyzed techniques are sensitive to the type of smell and obtained good results for the majority of them, especially JRip and Random Forest. We also observe that the ML techniques did not need a high number of examples to reach their best accuracy results. This finding implies that ML techniques can be successfully used for early detection of smells without depending on the curation of a large dataset.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {233–242},
numpages = {10},
keywords = {code smell, code smell detection, software quality},
location = {Natal, Brazil},
series = {SBES '20}
}

@article{10.1016/j.infsof.2019.106214,
author = {Alsolai, Hadeel and Roper, Marc},
title = {A systematic literature review of machine learning techniques for software maintainability prediction},
year = {2020},
issue_date = {Mar 2020},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {119},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.106214},
doi = {10.1016/j.infsof.2019.106214},
journal = {Inf. Softw. Technol.},
month = mar,
numpages = {25},
keywords = {Dataset, Metric, Machine learning, Software maintainability prediction, Systematic literature review}
}

@inproceedings{10.1145/3324884.3416617,
author = {Li, Ke and Xiang, Zilin and Chen, Tao and Tan, Kay Chen},
title = {BiLO-CPDP: bi-level programming for automated model discovery in cross-project defect prediction},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416617},
doi = {10.1145/3324884.3416617},
abstract = {Cross-Project Defect Prediction (CPDP), which borrows data from similar projects by combining a transfer learner with a classifier, have emerged as a promising way to predict software defects when the available data about the target project is insufficient. However, developing such a model is challenge because it is difficult to determine the right combination of transfer learner and classifier along with their optimal hyper-parameter settings. In this paper, we propose a tool, dubbed BiLO-CPDP, which is the first of its kind to formulate the automated CPDP model discovery from the perspective of bi-level programming. In particular, the bi-level programming proceeds the optimization with two nested levels in a hierarchical manner. Specifically, the upper-level optimization routine is designed to search for the right combination of transfer learner and classifier while the nested lower-level optimization routine aims to optimize the corresponding hyper-parameter settings. To evaluate BiLO-CPDP, we conduct experiments on 20 projects to compare it with a total of 21 existing CPDP techniques, along with its single-level optimization variant and Auto-Sklearn, a state-of-the-art automated machine learning tool. Empirical results show that BiLO-CPDP champions better prediction performance than all other 21 existing CPDP techniques on 70% of the projects, while being overwhelmingly superior to Auto-Sklearn and its single-level optimization variant on all cases. Furthermore, the unique bi-level formalization in BiLO-CPDP also permits to allocate more budget to the upper-level, which significantly boosts the performance.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {573–584},
numpages = {12},
keywords = {automated parameter optimization, classification techniques, configurable software and tool, cross-project defect prediction, transfer learning},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@article{10.1016/j.scico.2021.102713,
author = {Jain, Shivani and Saha, Anju},
title = {Improving performance with hybrid feature selection and ensemble machine learning techniques for code smell detection},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {212},
number = {C},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2021.102713},
doi = {10.1016/j.scico.2021.102713},
journal = {Sci. Comput. Program.},
month = dec,
numpages = {34},
keywords = {Stacking, Hybrid feature selection, Ensemble machine learning, Machine learning, Code smell}
}

@article{10.1007/s10994-020-05872-w,
author = {Kuwajima, Hiroshi and Yasuoka, Hirotoshi and Nakae, Toshihiro},
title = {Engineering problems in machine learning systems},
year = {2020},
issue_date = {May 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {109},
number = {5},
issn = {0885-6125},
url = {https://doi.org/10.1007/s10994-020-05872-w},
doi = {10.1007/s10994-020-05872-w},
abstract = {Fatal accidents are a major issue hindering the wide acceptance of safety-critical systems that employ machine learning and deep learning models, such as automated driving vehicles. In order to use machine learning in a safety-critical system, it is necessary to demonstrate the safety and security of the system through engineering processes. However, thus far, no such widely accepted engineering concepts or frameworks have been established for these systems. The key to using a machine learning model in a deductively engineered system is decomposing the data-driven training of machine learning models into requirement, design, and verification, particularly for machine learning models used in safety-critical systems. Simultaneously, open problems and relevant technical fields are not organized in a manner that enables researchers to select a theme and work on it. In this study, we identify, classify, and explore the open problems in engineering (safety-critical) machine learning systems—that is, in terms of requirement, design, and verification of machine learning models and systems—as well as discuss related works and research directions, using automated driving vehicles as an example. Our results show that machine learning models are characterized by a lack of requirements specification, lack of design specification, lack of interpretability, and lack of robustness. We also perform a gap analysis on a conventional system quality standard SQuaRE with the characteristics of machine learning models to study quality models for machine learning systems. We find that a lack of requirements specification and lack of robustness have the greatest impact on conventional quality models.},
journal = {Mach. Learn.},
month = may,
pages = {1103–1126},
numpages = {24},
keywords = {Quality models, Automated driving, Safety critical systems, Systems engineering, Software engineering, Machine learning}
}

@inproceedings{10.1109/ISCID.2013.199,
author = {Xia, Ye and Yan, Guoying and Si, Qianran},
title = {A Study on the Significance of Software Metrics in Defect Prediction},
year = {2013},
isbn = {9780769550794},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISCID.2013.199},
doi = {10.1109/ISCID.2013.199},
abstract = {In the case of metrics-based software defect prediction, an intelligent selection of metrics plays an important role in improving the model performance. In this paper, we use different ways for feature selection and dimensionality reduction to determine the most important software metrics. Three different classifiers are utilized, namely Na\"{\i}ve Bayes, support vector machine and decision tree. On the publicly NASA data, a comparative experiment results show that instead of 22 or more metrics, less than 10 metrics can get better performance.},
booktitle = {Proceedings of the 2013 Sixth International Symposium on Computational Intelligence and Design - Volume 02},
pages = {343–346},
numpages = {4},
keywords = {software metric, feature selection, defect prediction, classifier},
series = {ISCID '13}
}

@inproceedings{10.1109/ICSE-NIER52604.2021.00022,
author = {Panichella, Annibale and Liem, Cynthia C. S.},
title = {What are we really testing in mutation testing for machine learning? a critical reflection},
year = {2021},
isbn = {9780738133249},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER52604.2021.00022},
doi = {10.1109/ICSE-NIER52604.2021.00022},
abstract = {Mutation testing is a well-established technique for assessing a test suite's quality by injecting artificial faults into production code. In recent years, mutation testing has been extended to machine learning (ML) systems, and deep learning (DL) in particular; researchers have proposed approaches, tools, and statistically sound heuristics to determine whether mutants in DL systems are killed or not. However, as we will argue in this work, questions can be raised to what extent currently used mutation testing techniques in DL are actually in line with the classical interpretation of mutation testing. We observe that ML model development resembles a test-driven development (TDD) process, in which a training algorithm ('programmer') generates a model (program) that fits the data points (test data) to labels (implicit assertions), up to a certain threshold. However, considering proposed mutation testing techniques for ML systems under this TDD metaphor, in current approaches, the distinction between production and test code is blurry, and the realism of mutation operators can be challenged. We also consider the fundamental hypotheses underlying classical mutation testing: the competent programmer hypothesis and coupling effect hypothesis. As we will illustrate, these hypotheses do not trivially translate to ML system development, and more conscious and explicit scoping and concept mapping will be needed to truly draw parallels. Based on our observations, we propose several action points for better alignment of mutation testing techniques for ML with paradigms and vocabularies of classical mutation testing.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {66–70},
numpages = {5},
keywords = {software testing, mutation testing, mutation operators, machine learning},
location = {Virtual Event, Spain},
series = {ICSE-NIER '21}
}

@article{10.1007/s11042-019-08206-8,
author = {Dornaika, F. and Elorza, A. and Wang, K. and Arganda-Carreras, I.},
title = {Image-based face beauty analysis via graph-based semi-supervised learning},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {79},
number = {3–4},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-019-08206-8},
doi = {10.1007/s11042-019-08206-8},
abstract = {Automatic facial beauty analysis has become an emerging research topic. Despite some achieved advances, current methods and systems suffer from at least two limitations. Firstly, many developed systems rely on the use of ad-hoc hand-crafted features that were designed for generic pattern recognition problems. Secondly, while Deep Convolutional Neural Nets (DCNN) have been recently demonstrated to be a promising area of research in statistical machine learning, their use for automatic face beauty analysis may not guarantee optimal performances due to the use of a limited amount of face images with beauty scores. In this paper, we attempt to overcome these two main limitations by jointly exploiting two tricks. First, instead of using hand-crafted face features we use deep features of a pre-trained DCNN able to generate a high-level representation of a face image. Second, we exploit manifold learning theory and deploy three graph-based semi-supervised learning methods in order to enrich model learning without the need of additional labeled face images. These schemes perform graph-based score propagation. The proposed schemes were tested on three public datasets for beauty analysis: SCUT-FBP, M2B, and SCUT-FBP5500. These experiments, as well as many comparisons with supervised schemes, show that the scheme coined Kernel Flexible Manifold Embedding compares favorably with many supervised schemes. They also show that its performances in terms of error prediction and Pearson Correlation are better than those reported for the used datasets.},
journal = {Multimedia Tools Appl.},
month = jan,
pages = {3005–3030},
numpages = {26},
keywords = {Deep face features, Graph-based label propagation, Semi-supervised learning, Image-based face beauty analysis}
}

@inproceedings{10.1145/3361242.3361243,
author = {Wang, Yuehuan and Li, Zenan and Xu, Jingwei and Yu, Ping and Ma, Xiaoxing},
title = {Fast Robustness Prediction for Deep Neural Network},
year = {2019},
isbn = {9781450377010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361242.3361243},
doi = {10.1145/3361242.3361243},
abstract = {Deep neural networks (DNNs) have achieved impressive performance in many difficult tasks. However, DNN models are essentially uninterpretable to humans, and unfortunately prone to adversarial attacks, which hinders their adoption in security and safety-critical scenarios. The robustness of a DNN model, which measures its stableness against adversarial attacks, becomes an important topic in both the machine learning and the software engineering communities. Analytical evaluation of DNN robustness is difficult due to the high-dimensionality of inputs, the huge amount of parameters, and the nonlinear network structure. In practice, the degree of robustness of DNNs is empirically approximated with adversarial searching, which is computationally expensive and cannot be applied in resource constrained settings such as embedded computing. In this paper, we propose to predict the robustness of a DNN model for each input with another DNN model, which takes the output of neurons of the former model as input. We train a regression model to encode the connections between output of the penultimate layer of a DNN model and its robustness. With this trained model, the robustness for an input can be predicted instantaneously. Experiments with MNIST and CIFAR10 datasets and LeNet, VGG and ResNet DNN models were conducted to evaluate the efficacy of the proposed approach. The results indicated that our approach achieved 0.05-0.21 mean absolute errors and significantly outperformed confidence and surprise adequacy-based approaches.},
booktitle = {Proceedings of the 11th Asia-Pacific Symposium on Internetware},
articleno = {11},
numpages = {10},
keywords = {Robustness, Prediction, Deep Neural Networks},
location = {Fukuoka, Japan},
series = {Internetware '19}
}

@inproceedings{10.1145/3379597.3387461,
author = {Chen, Yang and Santosa, Andrew E. and Yi, Ang Ming and Sharma, Abhishek and Sharma, Asankhaya and Lo, David},
title = {A Machine Learning Approach for Vulnerability Curation},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387461},
doi = {10.1145/3379597.3387461},
abstract = {Software composition analysis depends on database of open-source library vulerabilities, curated by security researchers using various sources, such as bug tracking systems, commits, and mailing lists. We report the design and implementation of a machine learning system to help the curation by by automatically predicting the vulnerability-relatedness of each data item. It supports a complete pipeline from data collection, model training and prediction, to the validation of new models before deployment. It is executed iteratively to generate better models as new input data become available. We use self-training to significantly and automatically increase the size of the training dataset, opportunistically maximizing the improvement in the models' quality at each iteration. We devised new deployment stability metric to evaluate the quality of the new models before deployment into production, which helped to discover an error. We experimentally evaluate the improvement in the performance of the models in one iteration, with 27.59% maximum PR AUC improvements. Ours is the first of such study across a variety of data sources. We discover that the addition of the features of the corresponding commits to the features of issues/pull requests improve the precision for the recall values that matter. We demonstrate the effectiveness of self-training alone, with 10.50% PR AUC improvement, and we discover that there is no uniform ordering of word2vec parameters sensitivity across data sources.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {32–42},
numpages = {11},
keywords = {self-training, open-source software, machine learning, classifiers ensemble, application security},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/3434581.3434619,
author = {Bao, Yang and Rui, Guosheng and Zhang, Song},
title = {A Unsupervised Learning System of Aeroengine Predictive Maintenance Based on Cluster Analysis},
year = {2020},
isbn = {9781450375764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3434581.3434619},
doi = {10.1145/3434581.3434619},
abstract = {In this paper, a new cluster analysis system of predictive maintenance is proposed. The aim is to perform predictive maintenance on aero-engines under unsupervised conditions and reduce the cost of traditional periodic maintenance. Using this system and the proposed maintenance strategy to verify the subset from C-MAPSS dataset, the results show that the system obtains 40% extra uptime than regular maintenance. Under the theoretical limit, up to 60% of extra uptime can be obtained. The results show that the system can effectively increase uptime and reduce costs, which is a good supplement to the existing predictive maintenance.},
booktitle = {Proceedings of the 2020 International Conference on Aviation Safety and Information Technology},
pages = {187–191},
numpages = {5},
keywords = {warning system, unsupervised learning, cluster analysis, Predictive maintenance},
location = {Weihai City, China},
series = {ICASIT 2020}
}

@inproceedings{10.1145/1985793.1985859,
author = {Kim, Sunghun and Zhang, Hongyu and Wu, Rongxin and Gong, Liang},
title = {Dealing with noise in defect prediction},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985859},
doi = {10.1145/1985793.1985859},
abstract = {Many software defect prediction models have been built using historical defect data obtained by mining software repositories (MSR). Recent studies have discovered that data so collected contain noises because current defect collection practices are based on optional bug fix keywords or bug report links in change logs. Automatically collected defect data based on the change logs could include noises.This paper proposes approaches to deal with the noise in defect data. First, we measure the impact of noise on defect prediction models and provide guidelines for acceptable noise level. We measure noise resistant ability of two well-known defect prediction algorithms and find that in general, for large defect datasets, adding FP (false positive) or FN (false negative) noises alone does not lead to substantial performance differences. However, the prediction performance decreases significantly when the dataset contains 20%-35% of both FP and FN noises. Second, we propose a noise detection and elimination algorithm to address this problem. Our empirical study shows that our algorithm can identify noisy instances with reasonable accuracy. In addition, after eliminating the noises using our algorithm, defect prediction accuracy is improved.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {481–490},
numpages = {10},
keywords = {noise resistance, defect prediction, data quality, buggy files, buggy changes},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@article{10.1007/s00607-021-01011-y,
author = {Gavel, Shashank and Charitha, Raghavraju and Biswas, Pialy and Raghuvanshi, Ajay Singh},
title = {A data fusion based data aggregation and sensing technique for fault detection in wireless sensor networks},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {103},
number = {11},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-021-01011-y},
doi = {10.1007/s00607-021-01011-y},
abstract = {Wireless Sensor Networks (WSNs) are networks formed using a large number of low-cost sensor nodes that have limited energy sources, limited processing capability, low storage capacity, and generate a large amount of sensed data with high temporal coherency. Due to high node density in sensor networks, the same data is sensed by many nodes, which results in data redundancy. The problem becomes worse if the redundant transmission contains both normal and faulty data. This creates the issue of differentiating between normal and faulty behavior. This redundancy can be eliminated by using data fusion based techniques. Data aggregation based data fusion is considered an important technique that can reduce the repetitive transmission of the sensed data and can improve the network lifetime. Hence for maintaining the reliability and longevity of the sensor network, in this article, we propose a novel combination of data aggregation based data fusion with effective fault detection by utilizing the properties of Grey Model (GM) and Kernel-based Extreme Learning Machine (KELM). Here, GM is utilized as a data fusion scheme that records the single datum pattern by rejecting the repetitive data received from the different sensor nodes. Trained KELM is utilized for effective detection of fault thus maintaining high confidentiality of the network. The proposed technique is trained and tested using the standard WSN datasets recorded from different laboratories. The simulation results show that the proposed technique can effectively reduce the repetitive transmission and can efficiently detect the fault in the network. The solved problems result in extending the lifetime of the network by taking the low computational time and fast speed.},
journal = {Computing},
month = nov,
pages = {2597–2618},
numpages = {22},
keywords = {68Uxx, 68Txx, 68Rxx, 68Qxx, Kernel extreme learning machine, Grey model, Wireless sensor networks, Data fusion, Fault detection}
}

@article{10.1016/j.asoc.2020.106113,
author = {Li, Han and Zhao, Wei and Zhang, Yuxi and Zio, Enrico},
title = {Remaining useful life prediction using multi-scale deep convolutional neural network},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {89},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2020.106113},
doi = {10.1016/j.asoc.2020.106113},
journal = {Appl. Soft Comput.},
month = apr,
numpages = {13},
keywords = {Deep learning, Multi-scale, Convolutional neural network, Remaining useful life}
}

@article{10.1016/j.eswa.2014.10.025,
author = {Erturk, Ezgi and Sezer, Ebru Akcapinar},
title = {A comparison of some soft computing methods for software fault prediction},
year = {2015},
issue_date = {March 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2014.10.025},
doi = {10.1016/j.eswa.2014.10.025},
abstract = {Software fault prediction is implemented with ANN, SVM and ANFIS.First ANFIS implementation is applied to solve fault prediction problem.Parameters are discussed in neuro fuzzy approach.Experiments show that the application of ANFIS to the software fault prediction problem is highly reasonable. The main expectation from reliable software is the minimization of the number of failures that occur when the program runs. Determining whether software modules are prone to fault is important because doing so assists in identifying modules that require refactoring or detailed testing. Software fault prediction is a discipline that predicts the fault proneness of future modules by using essential prediction metrics and historical fault data. This study presents the first application of the Adaptive Neuro Fuzzy Inference System (ANFIS) for the software fault prediction problem. Moreover, Artificial Neural Network (ANN) and Support Vector Machine (SVM) methods, which were experienced previously, are built to discuss the performance of ANFIS. Data used in this study are collected from the PROMISE Software Engineering Repository, and McCabe metrics are selected because they comprehensively address the programming effort. ROC-AUC is used as a performance measure. The results achieved were 0.7795, 0.8685, and 0.8573 for the SVM, ANN and ANFIS methods, respectively.},
journal = {Expert Syst. Appl.},
month = mar,
pages = {1872–1879},
numpages = {8},
keywords = {Support Vector Machines, Software fault prediction, McCabe metrics, Artificial Neural Networks, Adaptive neuro fuzzy systems}
}

@inproceedings{10.1145/3180155.3182542,
author = {Herbold, Steffen and Trautsch, Alexander and Grabowski, Jens},
title = {A comparative study to benchmark cross-project defect prediction approaches},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3182542},
doi = {10.1145/3180155.3182542},
abstract = {Cross-Project Defect Prediction (CPDP) as a means to focus quality assurance of software projects was under heavy investigation in recent years. However, within the current state-of-the-art it is unclear which of the many proposals performs best due to a lack of replication of results and diverse experiment setups that utilize different performance metrics and are based on different underlying data. Within this article [2, 3], we provide a benchmark for CPDP. Our benchmark replicates 24 CPDP approaches proposed by researchers between 2008 and 2015. Through our benchmark, we answer the following research questions:• RQ1: Which CPDP approaches perform best in terms of F-measure, G-measure, AUC, and MCC?• RQ2: Does any CPDP approach consistently fulfill the performance criteria for successful predictions postulated by Zimmermann et al. [4], i.e., have at least 0.75 recall, 0.75 precision, and 0.75 accuracy?• RQ3: What is the impact of using only larger products (&gt; 100 instances) with a certain balance (at least 5% defective instances and at least 5% non-defective instances) on the benchmark results?• RQ4: What is the impact of using a relatively small subset of a larger data set on the benchmark results?We identified 5 public data sets, which contain defect data about 86 software products that we used to answer these research question. The advantage of using multiple data sets was that we could increase the number of software products and, thereby, increase the external validity of our results. Moreover, we wanted to use multiple performance criteria for the evaluation of the CPDP approaches. Therefore, RQ1 ranks approaches not just using a single criterion, but using the four performance metrics AUC, F-measure, G-measure, and MCC. Existing approaches for the ranking of statistically different approaches neither account for software products from different data sets, nor multiple performance metrics. Therefore, we defined a new approach for the combination of separate rankings for the performance criteria and data sets, into one common ranking.Figure 1 depicts the results for RQ1. The results show that an approach proposed by Camargo Cruz and Ochimizu [1] performs best and even outperforms cross-validation. Moreover, our results show that only 6 of the 24 approaches outperform one of our baselines, i.e., using all data for training without any transfer learning. Regarding RQ2, we determined that predictions only seldomly achieve a high performance of 0.75 recall, precision, and accuracy. The best CPDP approaches only fulfill the criterion for 4 of the 86 products, i.e., 4.6% of the time. Thus, CPDP still has not reached a point where the performance of the results is sufficient for the application in practice.RQ3 and RQ4 were used to see if results are affected by subsetting data, as is often done for defect prediction experiments. For RQ3, i.e., using a large subset, we determined no difference between using all data and using the subset. For RQ4, i.e., using a small subset of of data, we found that there are statistically signifcant differences in reported performances of up to 5%. Thus, the use of small subsets should be avoided.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {1063},
numpages = {1},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{10.1016/j.knosys.2017.04.014,
author = {Arcelli Fontana, Francesca and Zanoni, Marco},
title = {Code smell severity classification using machine learning techniques},
year = {2017},
issue_date = {July 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {128},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2017.04.014},
doi = {10.1016/j.knosys.2017.04.014},
abstract = {Several code smells detection tools have been developed providing different results, because smells can be subjectively interpreted and hence detected in different ways. Machine learning techniques have been used for different topics in software engineering, e.g., design pattern detection, code smell detection, bug prediction, recommending systems. In this paper, we focus our attention on the classification of code smell severity through the use of machine learning techniques in different experiments. The severity of code smells is an important factor to take into consideration when reporting code smell detection results, since it allows the prioritization of refactoring efforts. In fact, code smells with high severity can be particularly large and complex, and create larger issues to the maintainability of software a system. In our experiments, we apply several machine learning models, spanning from multinomial classification to regression, plus a method to apply binary classifiers for ordinal classification. In fact, we model code smell severity as an ordinal variable. We take the baseline models from previous work, where we applied binary classification models for code smell detection with good results. We report and compare the performance of the models according to their accuracy and four different performance measures used for the evaluation of ordinal classification techniques. From our results, while the accuracy of the classification of severity is not high as in the binary classification of absence or presence of code smells, the ranking correlation of the actual and predicted severity for the best models reaches 0.880.96, measured through Spearmans .},
journal = {Know.-Based Syst.},
month = jul,
pages = {43–58},
numpages = {16},
keywords = {Refactoring prioritization, Ordinal classification, Machine learning, Code smells detection, Code smell severity}
}

@article{10.1007/s10470-021-01885-0,
author = {Lopes, Alba and Pereira, Monica},
title = {Fast DSE of reconfigurable accelerator systems via ensemble machine learning},
year = {2021},
issue_date = {Sep 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {108},
number = {3},
issn = {0925-1030},
url = {https://doi.org/10.1007/s10470-021-01885-0},
doi = {10.1007/s10470-021-01885-0},
abstract = {Reconfigurable hardware accelerators (RAs) attached to processors have become a frequent choice to meet the performance demand of current embedded applications. However, answering when the combination of general purpose processors (GPPs) and RAs can provide the expected performance at the additional area and energy cost demands an extensive design space exploration (DSE). Performing DSE through hardware synthesis is an extremely time-consuming and costly task. High-level simulations are a faster and simpler DSE method at the cost of accuracy loss. Even so, the use of high-level simulation does not allow simulating all design solutions and meeting time-to-market. In this scenario, machine learning (ML) has become a promising solution to provide robustness to the DSE of large hardware designs by predicting aspects such as performance and energy. A main challenge in the design of a high-accuracy predictor is to select one ML algorithm to encompass a wide range of applications. In this context, ensemble learning is a promising solution since it can use multiple models and combine their predictions. In this work we employ the use of ensemble methods to simplify and speed up the DSE of GPPs with RAs. In our investigation, we evaluate three ensemble methods, Random Forest, AdaBoosting and Gradient Boosting. We compare them to the most used regression algorithms found in literature to perform DSE of computer architectures. Results show an error prediction rate below 2% for some benchmarks when using ensemble methods and a throughput of more than 6000 predictions per second when using Gradient Boosting.},
journal = {Analog Integr. Circuits Signal Process.},
month = sep,
pages = {495–509},
numpages = {15},
keywords = {DSE, Reconfigurable accelerators, Ensemble learning}
}

@phdthesis{10.5555/AAI28256855,
author = {Wu, Baijun and Arun, Lakhotia, and Anthony, Maida, and Miao, Jin,},
advisor = {Sheng, Chen,},
title = {Using Machine Learning to Improve Programming Error Reporting},
year = {2020},
isbn = {9798519181839},
publisher = {University of Louisiana at Lafayette},
abstract = {The main purpose of this research is to explore applying machine learning to improve programming error reporting. In the first part of this dissertation, I present the empirical study about how type error were fixed and what students did. The investigation results demonstrate that current error debugging support is far from sufficient in practice, where the located error causes for more than 50% of type errors are incorrect and the corresponding change suggestions are ineffective. I provide a fundamental understanding of why existing error debuggers do not work well for nonstructural type errors. To address this issue, a machine learning-base type error debugger, Learnskell, is developed. The evaluations results show that Learnskell could locate the error causes for nonstructural type errors several times more accurate than the state-of-the-art tools. In the second part, I study how to precisely infer error specifications in C. Error specifications, which specify the value range that each function returns to indicate failures, are widely used to check and propagate errors for the sake of reliability and security. I propose a general method, MLPEx, that can automatically generate error specifications by analyzing only the source code. MLPEx utilizes the idea of transfer learning, and therefore requires zero manual efforts to label data during the learning process. Error specifications are useful to detect bugs. As one example, I present how the results of MLPEx can be used to find new error handling bugs in real-world projects.},
note = {AAI28256855}
}

@article{10.1016/j.eswa.2019.112906,
author = {Costa Silva, Guilherme and Carvalho, Eduardo E.O. and Caminhas, Walmir Matos},
title = {An artificial immune systems approach to Case-based Reasoning applied to fault detection and diagnosis},
year = {2020},
issue_date = {Feb 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {140},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.112906},
doi = {10.1016/j.eswa.2019.112906},
journal = {Expert Syst. Appl.},
month = feb,
numpages = {15},
keywords = {Direct current motor simulation, Fault detection, Antigen, Antibody, Artificial immune system, Case-based Reasoning}
}

@article{10.3233/JIFS-192158,
author = {Xie, Ying},
title = {Double-weighted neighborhood standardization method with applications to multimode-process fault detection},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {39},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-192158},
doi = {10.3233/JIFS-192158},
abstract = {As modern industrial processes often have multiple production modes, multimode-process monitoring has become an important issue. In multimode processes, the operating condition may often switch among different modes. As a result, popular process monitoring methods such as principal component analysis (PCA) and partial least squares (PLS) method should not be directly applied because they are based on a fundamental assumption that the process only has one stable operating condition. In this paper, a novel multimode-process data-standardization approach called double-weighted neighborhood standardization (DWNS) is proposed to solve the problem of multimode characteristics. This approach can transform multimode data into approximately single-mode data, which follow a Gaussian distribution. By analyzing a concrete example, this study indicates that the DWNS strategy is effective for multimode data preprocessing. Moreover, a novel fault detection method called DWNS-PCA is proposed for multimode processes. Finally, a numerical example and the penicillin fermentation process are used to test the validity and effectiveness of the DWNS-PCA. The results demonstrate that the proposed data-standardization method is suitable for multimode data, and the DWNS-PCA process monitoring method is effective for detecting faults in multimode processes.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {1243–1256},
numpages = {14},
keywords = {fault detection, principal component analysis, double-weighted neighborhood standardization, multimode process}
}

@article{10.1016/j.future.2019.04.017,
author = {Din, Ikram Ud and Guizani, Mohsen and Rodrigues, Joel J.P.C. and Hassan, Suhaidi and Korotaev, Valery V.},
title = {Machine learning in the Internet of Things: Designed techniques for smart cities},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {100},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.04.017},
doi = {10.1016/j.future.2019.04.017},
journal = {Future Gener. Comput. Syst.},
month = nov,
pages = {826–843},
numpages = {18},
keywords = {VANET, Smart grid, Medical, Machine learning, Internet of Things}
}

@inproceedings{10.1145/2639490.2639511,
author = {Mockus, Audris},
title = {Defect prediction and software risk},
year = {2014},
isbn = {9781450328982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2639490.2639511},
doi = {10.1145/2639490.2639511},
abstract = {Defect prediction has always fascinated researchers and practitioners. The promise of being able to predict the future and act to improve it is hard to resist. However, the operational data used in predictions are treacherous and the prediction is usually done outside the context of the actual development project, making it impossible to employ it for software quality measurement or improvement. Contextualizing, imputing missing observations, and correcting operational data related to defects is essential to gauge software quality. Such augmented data can then be used with domain- and project-specific considerations to assess risk posed by code, organization, or activities and to suggest risk-specific remediation activities.},
booktitle = {Proceedings of the 10th International Conference on Predictive Models in Software Engineering},
pages = {1},
numpages = {1},
location = {Turin, Italy},
series = {PROMISE '14}
}

@article{10.1007/s00521-020-05171-4,
author = {Yu, Jianbo and Zhang, Chengyi and Wang, Shijin},
title = {Multichannel one-dimensional convolutional neural network-based feature learning for fault diagnosis of industrial processes},
year = {2021},
issue_date = {Apr 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {8},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05171-4},
doi = {10.1007/s00521-020-05171-4},
abstract = {In industrial processes, the noise and high dimension of process signals usually affect the performance of those methods in fault detection and diagnosis. A predominant property of a fault diagnosis model is to extract effective features from process signals. Wavelet transform is capable of extracting multiscale information that provides effective fault features in time and frequency domain of process signals. In this paper, a new deep neural network (DNN), multichannel one-dimensional convolutional neural network (MC1-DCNN), is proposed to investigate feature learning from high-dimensional process signals. Wavelet transform is used to extract multiscale components with fault features from process signals. MC1-DCNN is able to learn discriminative time–frequency features from these multiscale process signals. Tennessee Eastman process and fed-batch fermentation penicillin process are adopted to verify performance of the proposed method. The experimental results demonstrate remarkable feature extraction and fault diagnosis performance of MC1-DCNN and show prosperous possibility of applying this method to industrial processes.},
journal = {Neural Comput. Appl.},
month = apr,
pages = {3085–3104},
numpages = {20},
keywords = {Feature learning, Convolutional neural network, Wavelet transform, Fault diagnosis, Industrial process}
}

@inproceedings{10.1145/3409501.3409543,
author = {Yan, Ziyue and Zong, Lu},
title = {Spatial Prediction of Housing Prices in Beijing Using Machine Learning Algorithms},
year = {2020},
isbn = {9781450375603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3409501.3409543},
doi = {10.1145/3409501.3409543},
abstract = {The real estate industry places key influence on almost every aspect of social economy given its great financing capacity and prolonged upstream and downstream industry chain. Therefore, predicting housing prices is regarded as an emerging topic in the recent decades. Hedonic Regression and Machine Learning Algorithms are two main methods in this field. This study aims to explore the important explanatory features and determine an accurate mechanism to implement spatial prediction of housing prices in Beijing by incorporating a list of machine learning techniques, including XGBoost, linear regression, Random Forest Regression, Ridge and Lasso Model, bagging and boosting, based on the housing price and features data in Beijing, China. Our result shows that compared to traditional hedonic method, machine learning methods demonstrate significant improvements on the accuracy of estimation despite that they are more time-costly. Moreover, it is found that XGBoost is the most accurate model in explaining and prediciting the spatial dynamics of housing prices in Beijing.},
booktitle = {Proceedings of the 2020 4th High Performance Computing and Cluster Technologies Conference &amp; 2020 3rd International Conference on Big Data and Artificial Intelligence},
pages = {64–71},
numpages = {8},
keywords = {Spatial Modeling, Prediction, Machine Learning Algorithms, Housing Price},
location = {Qingdao, China},
series = {HPCCT &amp; BDAI '20}
}

@mastersthesis{10.5555/AAI27837415,
author = {Kumar, Abhishek and Song, Myoungkyu and Hale, Matthew},
advisor = {Harvey, Siy,},
title = {Validating Machine Learning Applications with Metamorphic Testing},
year = {2020},
isbn = {9798662408258},
publisher = {University of Nebraska at Omaha},
abstract = {As machine learning applications have gone into mainstream use, it is increasingly important to find ways of assessing the reliability of their outputs. Unlike conventional software applications, there is no known approach for systematically testing machine learning applications. It is because of a lack of useful oracles due to the large input space for such applications. One of the most common uses of machine learning is image recognition. Robust image recognition needs to accurately identify images, even in the face of slight distortions to the image. Metamorphic testing is a promising approach for testing such applications. It makes use of successful test cases to generate additional test inputs. The main idea is that a small change in the input from a known test case should lead to a similarly small change (or no change) in the output. The changes to the test cases are constrained by metamorphic relations, which are defined as "expected relation among input and output of multiple executions of a program."In this study, we developed a metamorphic testing framework for testing the robustness of machine learning algorithms. We use a simple metamorphic relation: small changes in the input image should not lead to a different classification by the machine. We implemented five machine learning algorithms and trained them on the same dataset. We then apply a set of affine transformations to the test data to generate follow-up test data. We feed the follow-up test data to the algorithms and compare the output to the original outputs. We progressively increase the transformations to identify the ``breaking point" of the algorithms. Our results on three image databases indicate that machine learning algorithms are more sensitive to image shifting than other transformations such as rotation and shearing. Based on the results of the study, we provide recommendations to use our metamorphic properties to generate follow-up test cases for machine learning algorithms. Finally, we generated a new test dataset with these recommendations to assess the robustness of the algorithms. Within these recommended ranges, we find that deep learning algorithms like convolutional neural networks can outperform other algorithms.},
note = {AAI27837415}
}

@inproceedings{10.1007/978-3-030-41418-4_3,
author = {Nakajima, Shin},
title = {Distortion and Faults in Machine Learning Software},
year = {2019},
isbn = {978-3-030-41417-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-41418-4_3},
doi = {10.1007/978-3-030-41418-4_3},
abstract = {Machine learning software, deep neural networks (DNN) software in particular, discerns valuable information from a large dataset, a set of data, so as to synthesize approximate input-output relations. The outcomes of such DNN programs are dependent on the quality of both learning programs and datasets. However, the quality assurance of DNN software is difficult. The trained machine learning models, defining the functional behavior of the approximate relations, are unknown prior to its development, and the validation is conducted indirectly in terms of the prediction performance. This paper introduces a hypothesis that faults in DNN programs manifest themselves as distortions in trained machine learning models. Relative distortion degrees measured with appropriate observer functions may indicate that the programs have some hidden faults. The proposal is demonstrated with the cases of the MNIST dataset.},
booktitle = {Structured Object-Oriented Formal Language and Method: 9th International Workshop, SOFL+MSVL 2019, Shenzhen, China, November 5, 2019, Revised Selected Papers},
pages = {29–41},
numpages = {13},
location = {Shenzhen, China}
}

@inproceedings{10.1145/1985793.1985950,
author = {Nguyen, Tung Thanh and Nguyen, Tien N. and Phuong, Tu Minh},
title = {Topic-based defect prediction (NIER track)},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1985950},
doi = {10.1145/1985793.1985950},
abstract = {Defects are unavoidable in software development and fixing them is costly and resource-intensive. To build defect prediction models, researchers have investigated a number of factors related to the defect-proneness of source code, such as code complexity, change complexity, or socio-technical factors. In this paper, we propose a new approach that emphasizes on technical concerns/functionality of a system. In our approach, a software system is viewed as a collection of software artifacts that describe different technical concerns/-aspects. Those concerns are assumed to have different levels of defect-proneness, thus, cause different levels of defectproneness to the relevant software artifacts. We use topic modeling to measure the concerns in source code, and use them as the input for machine learning-based defect prediction models. Preliminary result on Eclipse JDT shows that the topic-based metrics have high correlation to the number of bugs (defect-proneness), and our topic-based defect prediction has better predictive performance than existing state-of-the-art approaches.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {932–935},
numpages = {4},
keywords = {topic modeling, defect prediction},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.1145/3458359.3458379,
author = {Guo, Pengwei and Ma, Xiaoping and Zhang, Wenmin and Gao, Fang and Liang, Meng and Shi, Hengliang},
title = {Study of Fault Detection of Bridge Crane Wheel based on Fourier Transform},
year = {2021},
isbn = {9781450389020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458359.3458379},
doi = {10.1145/3458359.3458379},
abstract = {The track condition of a bridge crane directly affects the production efficiency and life safety. Due to the limitation of harsh environment, the traditional detection methods include high altitude danger, difficult operation and low efficiency. In this paper, according to the on-line inspection of wheel track wear, the acoustic signal of electric converter is used to collect the sound signal. The method of failure detection based on power spectrum is proposed, and the BIF feature selection combined with Fisher criterion is used to select the best special collection, and the problem of many characteristics is solved. Finally, we use the two classification logic regression to achieve the mathematical modeling between the feature set and the wear volume, and use the H function as the basis of failure judgement. The results show that the failure probability value of the system is more than 0.8 when the wheel wear is serious and close to failure, which is approximately equal to the real value. It can provide a reliable basis for the detection of wheel track.},
booktitle = {Proceedings of the 2021 10th International Conference on Informatics, Environment, Energy and Applications},
pages = {23–27},
numpages = {5},
keywords = {Wheel, Sound Cumulative Power Spectrum, Fourier Transform, Fisher, Fault Detection},
location = {Xi'an, China},
series = {IEEA '21}
}

@phdthesis{10.5555/AAI30272676,
author = {Lee, Jangwon and Mario, Eden,},
advisor = {Peter, He, Q. and Jin, Wang, and Nedret, Billor, and Jesus, Flores-Cerrillo,},
title = {Hybrid Machine Learning Techniques for Manufacturing and Beyond},
year = {2021},
isbn = {9798371943002},
publisher = {Auburn University},
address = {USA},
abstract = {This dissertation presents research performed to develop a novel soft sensor, feature space process monitoring, and domain knowledge-based path analysis for manufacturing and healthcare industries.In recent years, as the Internet of Things (IoT) and data storage techniques (i.e., cloud service) have been evolved, large-scale data are available to various industries such as retail, healthcare, and manufacturing. With notable demonstrations from the world's largest companies, such as Google, Amazon, Facebook and Microsoft, that insights can be obtained from big data, many businesses and institutions have been utilizing their own big data for potentially making new inferences and solving challenging problems in data-driven ways. However, it is sometimes difficult to extract valuable information and gain insights from big data with rote application of machine learning (ML) since data collected from various sources may not be relevant and often contain noises. Without domain knowledge, the results from ML approaches can be incomplete, or even lead to misleading conclusions. Therefore, in this research I aim to demonstrate the limitations of pure data-driven ML techniques in several case studies that are relevant to manufacturing and healthcare, and then to address the limitations by developing solutions that systematically integrate domain knowledge with ML techniques.In the first part of this work (Chapter 2), I introduce a novel spectroscopy-based soft sensor which was developed by integrating a feature engineering approach – Statistics Pattern Analysis (SPA) – with a new feature selection approach – Consistency Enhanced Evolution for Variable Selection (CEEVS) – referred to as SPA-CEEVS. Based on the understanding of the spectral dataset that not all features contribute equally to the sample properties, a novel feature selection method, CEEVS, is proposed to identify truly relevant features that are associated with chemical functional group regions, leading to improved soft sensor performance and easier interpretation of results compared to the soft sensor based on the original spectroscopy data. SPA, one of the feature engineering methods, is embedded in the CEEVS algorithm to better capture the characteristics of spectra such as nonlinearity. SPA can also reduce the influence of spectral disturbance and background noise by extracting statistics and shape features from spectral data. To demonstrate the effectiveness of the proposed SPA-CEEVS method, comparison study of various variable selection methods and nonlinear models are conducted on several industrial near-infrared (NIR) spectral datasets.In the second part of this work (Chapter 3), I propose a data-driven feature space monitoring (FSM) approach that monitors periodic operations of pressure swing adsorption (PSA) processes. In FSM framework, features extracted from process variables are used to monitor the process operation, instead of raw process variables themselves. Domain knowledge of the PSA process helps to understand which features need to be generated and selected. In this work, I suggest a way of selecting features based on this domain knowledge. In addition, the FSM based fault detection method addresses challenges in monitoring periodic processes, such as unequal step and/or cycle time that requires trajectory alignment or synchronization for the traditional statistical process monitoring (SPM) methods. In this study, the k-nearest neighbor-based FSM (FSM-kNN) is developed for fault detection. The basic idea of FSM-kNN is that the distance between a faulty cycle and its neighboring training cycles (consisting of normal operation cycles) is greater than that between a normal cycle and its neighboring training cycles. In addition, a step-wise fault diagnosis is proposed to identify the root cause of faults when faults are detected. The proposed method not only shows superior fault detection performance compared to the conventional SPM methods for both simulated faults and real faults from an industrial PSA process, but also correctly identifies the root causes of the faults.In the third part of this work (Chapter 4), path analysis based on domain knowledge is proposed to examine if the hospitals specialized in certain diseases achieve better results in terms of costs and patient outcomes. With domain knowledge in healthcare industry, I formulate some hypotheses and construct paths. Pure data-driven ML approaches without hypotheses such as multiple linear regression and partial least square regression can lead to incomplete conclusion because they consider only one path among all the possible paths. However, the path analysis consists of all the possible paths where hospital specialization can affect the hospital performance so that the model can reveal full effects of hospital specialization. The comparison between the path analysis and the pure data-driven ML approaches suggests that domain knowledge can play a critical role in machine learning applications and should be incorporated whenever possible.},
note = {AAI30272676}
}

@article{10.1016/j.ins.2020.02.032,
author = {Song, Xiaona and Wang, Mi and Song, Shuai and Ning, Zhaoke},
title = {Space-sampling-based fault detection for nonlinear spatiotemporal dynamic systems with Markovian switching channel},
year = {2020},
issue_date = {May 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {520},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2020.02.032},
doi = {10.1016/j.ins.2020.02.032},
journal = {Inf. Sci.},
month = may,
pages = {400–415},
numpages = {16},
keywords = {Switching transmission channel, Space sampling, Piecewise measurements, Takagi–Sugeno fuzzy model, Fault detection}
}

@article{10.1145/3477025,
author = {Lee, Gyeongmin and Kim, Bongjun and Song, Seungbin and Kim, Changsu and Kim, Jong and Kim, Hanjun},
title = {Precise Correlation Extraction for IoT Fault Detection With Concurrent Activities},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3477025},
doi = {10.1145/3477025},
abstract = {In the Internet of Things (IoT) environment, detecting a faulty device is crucial to guarantee the reliable execution of IoT services. To detect a faulty device, existing schemes trace a series of events among IoT devices within a certain time window, extract correlations among them, and find a faulty device that violates the correlations. However, if a few users share the same IoT environment, since their concurrent activities make non-correlated devices react together in the same time window, the existing schemes fail to detect a faulty device without differentiating the concurrent activities. To correctly detect a faulty device in the multiple concurrent activities, this work proposes a new precise correlation extraction scheme, called PCoExtractor. Instead of using a time window, PCoExtractor continuously traces the events, removes unrelated device statuses that inconsistently react for the same activity, and constructs fine-grained correlations. Moreover, to increase the detection precision, this work newly defines a fine-grained correlation representation that reflects not only sensor values and functionalities of actuators but also their transitions and program states such as contexts. Compared to existing schemes, PCoExtractor detects and identifies 40.06% more faults for 4 IoT services with concurrent activities of 12 users while reducing 80.3% of detection and identification times.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = sep,
articleno = {94},
numpages = {21},
keywords = {compiler, anomaly detection, Internet of Things}
}

@article{10.1016/j.compeleceng.2019.04.011,
author = {G., Geetharamani and J., Arun Pandian},
title = {Identification of plant leaf diseases using a nine-layer deep convolutional neural network},
year = {2019},
issue_date = {Jun 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {76},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.04.011},
doi = {10.1016/j.compeleceng.2019.04.011},
journal = {Comput. Electr. Eng.},
month = jun,
pages = {323–338},
numpages = {16},
keywords = {Transfer learning, Training epoch, Mini batch, Machine learning, Leaf diseases identification, Image augmentation, Dropout, Deep learning, Deep convolutional neural networks, Artificial intelligence}
}

@inproceedings{10.23919/ICCAS52745.2021.9650037,
author = {Park, Jae-Hyeon and Chang, Dong Eui},
title = {Data-driven fault detection and isolation of system with only state measurements and control inputs using neural networks},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/ICCAS52745.2021.9650037},
doi = {10.23919/ICCAS52745.2021.9650037},
abstract = {With the advancement of neural network technology, many researchers are trying to find a clever way to apply neural network to a fault detection and isolation area for satisfactory and safer operations of the system. Some researchers detect system faults by combining a concrete model of the system with neural network, generating residuals by neural network, or training neural network with specific sensor signals of the system. In this article, we make a fault detection and isolation neural network algorithm that uses only inherent sensor measurements and control inputs of the system. This algorithm does not need a model of the system, residual generations, or additional sensors. We obtain sensor measurements and control inputs in a discrete-time manner, cut signals with a sliding window approach, and label data with one-hot vectors representing a normal or fault classes. We train our neural network model with the labeled training data. We give 2 neural network models: a stacked long short-term memory neural network and a multilayer perceptron. We test our algorithm with the quadrotor fault simulation and the real experiment. Our algorithm gives nice performance on a fault detection and isolation of the quadrotor.},
booktitle = {2021 21st International Conference on Control, Automation and Systems (ICCAS)},
pages = {108–112},
numpages = {5},
location = {Jeju, Korea, Republic of}
}

@inproceedings{10.1109/CEC48606.2020.9185555,
author = {Brester, Christina and Niska, Harri and Ciszek, Robert and Kolehmainen, Mikko},
title = {Weather-based Fault Prediction in Electricity Networks with Artificial Neural Networks},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CEC48606.2020.9185555},
doi = {10.1109/CEC48606.2020.9185555},
abstract = {Predicting weather-related outages in electricity networks is an important issue for distribution system operators. In this study, we apply a data-driven approach and train artificial neural networks to predict faults in the electricity network. In our experiments, we utilize the meteorological data and fault records collected for the period of1.1.2011-31.12.2013 in central Finland. Assuming that there might be long-term dependencies between weather conditions and faults in the network, we investigate simple recurrent neural networks, long short-term memory networks, and traditional multilayer perceptrons. Taking into account the meteorological observations preceding faults and varying this period from several hours to several days, we found that 6 hours prior to faults included the sufficient information to make accurate predictions. Also, there was no need in more complicated recurrent neural networks as multilayer perceptron was able to predict events with the large number of faults more accurately. Besides, while forecasting all types of faults and wind-related faults only, oversampling allowed the model to predict rare high peaks.},
booktitle = {2020 IEEE Congress on Evolutionary Computation (CEC)},
pages = {1–8},
numpages = {8},
location = {Glasgow, United Kingdom}
}

@inproceedings{10.1109/ACIT-CSI.2015.104,
author = {Kawata, Kazuya and Amasaki, Sousuke and Yokogawa, Tomoyuki},
title = {Improving Relevancy Filter Methods for Cross-Project Defect Prediction},
year = {2015},
isbn = {9781467396424},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ACIT-CSI.2015.104},
doi = {10.1109/ACIT-CSI.2015.104},
abstract = {Context: Cross-project defect prediction (CPDP)research has been popular. One of the techniques for CPDP isa relevancy filter which utilizes clustering algorithms to selecta useful subset of the cross-project data. Their performanceheavily relies on the quality of clustering, and using an advancedclustering algorithm instead of simple ones used in the past studiescan contribute to the performance improvement. Objective:To propose and examine a new relevancy filter method usingan advanced clustering method DBSCAN (Density-Based SpatialClustering). Method: We conducted an experiment that examinedthe predictive performance of the proposed method. Theexperiments compared three relevancy filter methods, namely,Burak-filter, Peters-filter, and the proposed method with 56project data and four prediction models. Results: The predictiveperformance measures supported the proposed method. It wasbetter than Burak-filter and Peters-filter in terms of AUC andg-measure. Conclusion: The proposed method achieved betterprediction than the conventional methods. The results suggestedthat exploring advanced clustering algorithms could contributeto cross-project defect prediction.},
booktitle = {Proceedings of the 2015 3rd International Conference on Applied Computing and Information Technology/2nd International Conference on Computational Science and Intelligence},
pages = {2–7},
numpages = {6},
series = {ACIT-CSI '15}
}

@inproceedings{10.5555/3049877.3049895,
author = {Mezouar, Mariam El and Zhang, Feng and Zou, Ying},
title = {Local versus global models for effort-aware defect prediction},
year = {2016},
publisher = {IBM Corp.},
address = {USA},
abstract = {Software entities (e.g., files or classes) do not have the same density of defects and therefore do not require the same amount of effort for inspection. With limited resources, it is critical to reveal as many defects as possible. To satisfy such need, effort-aware defect prediction models have been proposed. However, the performance of prediction models is commonly affected by a large amount of possible variability in the training data. Prior studies have inspected whether using a subset of the original training data (i.e., local models) could improve the performance of prediction models in the context of defect prediction and effort estimation in comparison with global models (i.e., trained on the whole dataset). However, no consensus has been reached and the comparison has not been performed in the context of effort-aware defect prediction.In this study, we compare local and global effort-aware defect prediction models using 15 projects from the widely used AEEEM and PROMISE datasets. We observe that although there is at least one local model that can outperform the global model, there always exists another local model that performs very poorly in all the projects. We further find that the poor performing local model is built on the subset of the training set with a low ratio of defective entities. By excluding such subset of the training set and building a local effort-aware model with the remaining training set, the local model usually underperforms the global model in 11 out of the 15 studied projects. A close inspection on the failure of local effort-aware models reveals that the major challenge comes from defective entities with small size (i.e., few lines of code), as such entities tend to be correctly predicted by the global model but missed by the local model. Further work should pay special attention to the small but defective entities.},
booktitle = {Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering},
pages = {178–187},
numpages = {10},
location = {Toronto, Ontario, Canada},
series = {CASCON '16}
}

@article{10.1016/j.cie.2021.107499,
author = {M\'{a}rquez-Vera, M.A. and Ramos-Velasco, L.E. and L\'{o}pez-Ortega, O. and Z\'{u}\~{n}iga-Pe\~{n}a, N.S. and Ramos-Fern\'{a}ndez, J.C. and Ortega-Mendoza, R.M.},
title = {Inverse fuzzy fault model for fault detection and isolation with least angle regression for variable selection},
year = {2021},
issue_date = {Sep 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {159},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2021.107499},
doi = {10.1016/j.cie.2021.107499},
journal = {Comput. Ind. Eng.},
month = sep,
numpages = {10},
keywords = {Wavelets, LARS, Fuzzy model, Fault isolation}
}

@inproceedings{10.1007/978-3-030-22808-8_27,
author = {Malla, Paul and Coburn, Will and Keegan, Kevin and Yu, Xiao-Hua},
title = {Power System Fault Detection and Classification Using Wavelet Transform and Artificial Neural Networks},
year = {2019},
isbn = {978-3-030-22807-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-22808-8_27},
doi = {10.1007/978-3-030-22808-8_27},
abstract = {Power system fault detection has been an import area of study for power distribution networks. The power transmission systems often operate in the kV range with significant current flowing through the lines. A single fault, even lasting for a fraction of a second, can cause huge losses and manufacturing downtime for industrial applications. In this research, we develop an approach to detect, classify, and localize different types of phase-to-ground and phase-to-phase faults in three-phase power transmission systems based on discrete wavelet transform (DWT) and artificial neural networks (ANN). The multi-resolution property of wavelet transform provides a suitable tool to analyze the irregular transient changes in voltage or current signals in the network when fault occurs. An artificial neural network is employed to discriminate the types of fault based on features extracted by DWT. Computer simulation results show that this method can effectively identify various faults in a typical three-phase transmission line in power grid.},
booktitle = {Advances in Neural Networks – ISNN 2019: 16th International Symposium on Neural Networks, ISNN 2019, Moscow, Russia, July 10–12, 2019, Proceedings, Part II},
pages = {266–272},
numpages = {7},
keywords = {Power systems, Fault detection, Fault classification, Wavelet transform, Artificial neural networks},
location = {Moscow, Russia}
}

@article{10.1007/s11219-008-9053-8,
author = {Kastro, Yomi and Bener, Ay\c{s}e Basar},
title = {A defect prediction method for software versioning},
year = {2008},
issue_date = {December  2008},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {16},
number = {4},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-008-9053-8},
doi = {10.1007/s11219-008-9053-8},
abstract = {New methodologies and tools have gradually made the life cycle for software development more human-independent. Much of the research in this field focuses on defect reduction, defect identification and defect prediction. Defect prediction is a relatively new research area that involves using various methods from artificial intelligence to data mining. Identifying and locating defects in software projects is a difficult task. Measuring software in a continuous and disciplined manner provides many advantages such as the accurate estimation of project costs and schedules as well as improving product and process qualities. This study aims to propose a model to predict the number of defects in the new version of a software product with respect to the previous stable version. The new version may contain changes related to a new feature or a modification in the algorithm or bug fixes. Our proposed model aims to predict the new defects introduced into the new version by analyzing the types of changes in an objective and formal manner as well as considering the lines of code (LOC) change. Defect predictors are helpful tools for both project managers and developers. Accurate predictors may help reducing test times and guide developers towards implementing higher quality codes. Our proposed model can aid software engineers in determining the stability of software before it goes on production. Furthermore, such a model may provide useful insight for understanding the effects of a feature, bug fix or change in the process of defect detection.},
journal = {Software Quality Journal},
month = dec,
pages = {543–562},
numpages = {20},
keywords = {Software defects, Neural networks, Defect prediction}
}

@article{10.1007/s10845-017-1380-9,
author = {Li, Zhe and Wang, Yi and Wang, Kesheng},
title = {A data-driven method based on deep belief networks for backlash error prediction in machining centers},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {31},
number = {7},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-017-1380-9},
doi = {10.1007/s10845-017-1380-9},
abstract = {Backlash error occurs in a machining center may lead to a series of changes in the geometry of the components and subsequently deteriorate the overall performance of the equipment. Due to the uncertainty of mechanical wear between kinematic pairs, it is challenging to predict backlash error through physical models directly. An alternative method is to leverage data-driven models to map the degradation. This paper proposes a data-driven method for backlash error predication through Deep Belief Network (DBN). The proposed method focuses on the assessment of both current and future geometric errors for backlash error prediction and subsequent maintenance in machining centers. During the process of prognosis, a DBN via stacking Restricted Boltzmann Machines is constructed for backlash error prediction. Energy-based models enable DBN to mine information hidden behind highly coupled inputs, which makes DBN a feasible method for fault diagnosis and prognosis when the target condition is beyond the historical data. In the experiment, to confirm the effectiveness of deep learning for backlash error prediction, similar popular regression methods, including Support Vector Machine Regression and Back Propagation Neural Network, are employed to present a comprehensive comparison in both diagnosis and prognosis. The experimental results show that the performances of all these regression methods are acceptable in the diagnostic stage. In the prognostic stage, DBN demonstrates its superiority and significantly outperforms the other models for backlash error prediction in machining centers.},
journal = {J. Intell. Manuf.},
month = oct,
pages = {1693–1705},
numpages = {13},
keywords = {Backlash error, Deep belief network, Data-driven method, Machining centers, Data mining}
}

@article{10.1134/S0005117921080014,
author = {Mukhachev, P. A. and Sadretdinov, T. R. and Pritykin, D. A. and Ivanov, A. B. and Solov’ev, S. V.},
title = {Modern Machine Learning Methods for Telemetry-Based Spacecraft Health Monitoring},
year = {2021},
issue_date = {Aug 2021},
publisher = {Plenum Press},
address = {USA},
volume = {82},
number = {8},
issn = {0005-1179},
url = {https://doi.org/10.1134/S0005117921080014},
doi = {10.1134/S0005117921080014},
journal = {Autom. Remote Control},
month = aug,
pages = {1293–1320},
numpages = {28},
keywords = {telemetry data, technical diagnostics, flight control, anomaly detection, data mining}
}

@inproceedings{10.1109/COASE.2019.8843086,
author = {He, Junjie and Wang, Junliang and Dai, Lu and Zhang, Jie and Bao, Jingsong},
title = {An Adaptive Interval Forecast CNN Model for Fault Detection Method},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/COASE.2019.8843086},
doi = {10.1109/COASE.2019.8843086},
abstract = {The machine fault detection (MFD) is critical for the safety operation of the petrochemical production. Aiming to automatically optimizing the pre-warning bounds of the control chart, an interval forecasting convolutional neural network (IFCNN) model has been proposed to forecast the warning interval of the signal with the raw dynamic data. Essentially, the IFCNN model is an improved convolutional neural network with dual output value to construct the warning interval directly and adaptively. To guide the model to learn the interval automatically during the model training, the loss function is customized to improve the fault detection accuracy. The proposed method is compared with the fixed threshold and the adaptive interval method with exponentially weighted moving average on a petrochemical equipment data set. The results indicated that the proposed method is of stronger robustness with lower failure rate in the fault detection of the petrochemical pump.},
booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
pages = {602–607},
numpages = {6},
location = {Vancouver, BC, Canada}
}

@inproceedings{10.1145/2818567.2818576,
author = {Gupta, Niketa and Panwar, Deepali and Sharma, Ashish},
title = {Modeling Structural Model for Defect Categories Based On Software Metrics for Categorical Defect Prediction},
year = {2015},
isbn = {9781450335522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2818567.2818576},
doi = {10.1145/2818567.2818576},
abstract = {Software Defect prediction is the pre-eminent area of software engineering which has witnessed huge importance over last decades. The identification of defects in the early stages of software development not only improve the quality of the software system but also reduce the time, cost and effort associated in maintaining the quality of software product. The quality of the software can be best assessed by software metrics. To evaluate the quality of the software, a number of software metrics have been proposed. Many research studies have been conducted to construct the prediction model that considers the CK (Chidamber and Kemerer) metrics suite and object oriented software metrics. For the prediction model development, consideration of interaction among the metrics is not a common practice. This paper presents the empirical evaluation in which several software metrics were investigated in order to identify the effective set of the metrics for each defect category which can significantly improve the defect prediction model made for each defect category. For each of the metrics, Pearson correlation coefficient with the number of defect categories were calculated and subsequently stepwise regression model is constructed for each defect category to predict the set of the metrics that are the good indicator of each defect category. We have proposed a novel approach for modelling the defects using structural equation modeling further which validates our work. Structural models were built for each defect category using structural equation modeling which claims that results are validated.},
booktitle = {Proceedings of the Sixth International Conference on Computer and Communication Technology 2015},
pages = {46–50},
numpages = {5},
keywords = {Structural Equation Modeling, Stepwise regression model, Software Metrics, Defect Prediction},
location = {Allahabad, India},
series = {ICCCT '15}
}

@article{10.1109/TSE.2010.90,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
title = {A General Software Defect-Proneness Prediction Framework},
year = {2011},
issue_date = {May 2011},
publisher = {IEEE Press},
volume = {37},
number = {3},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2010.90},
doi = {10.1109/TSE.2010.90},
abstract = {BACKGROUND—Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE—We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD—The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS—The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS—Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.},
journal = {IEEE Trans. Softw. Eng.},
month = may,
pages = {356–370},
numpages = {15},
keywords = {software defect-proneness prediction, scheme evaluation., machine learning, Software defect prediction}
}

@article{10.1016/j.compind.2019.02.001,
author = {Zhao, Dezun and Wang, Tianyang and Chu, Fulei},
title = {Deep convolutional neural network based planet bearing fault classification},
year = {2019},
issue_date = {May 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {107},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2019.02.001},
doi = {10.1016/j.compind.2019.02.001},
journal = {Comput. Ind.},
month = may,
pages = {59–66},
numpages = {8},
keywords = {Deep convolution neural network, Synchrosqueezing transform, Fault classification, Planet bearing}
}

@inproceedings{10.23919/ICEMS52562.2021.9634630,
author = {Kim, Si-Hwan and Kim, Sung-Hun and Byun, Hyung-Jun and Yi, Junsin and Won, Chung-Yuen},
title = {Interleaved DC-DC boost converter in DC distribution fault detection method using Artificial Neural Networks},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/ICEMS52562.2021.9634630},
doi = {10.23919/ICEMS52562.2021.9634630},
abstract = {This paper proposes a fault detection method of the interleaved bi-directional DC-DC boost converter using Artificial Neural Networks (ANN). In the proposed method, when open-switch faults occur, fault detection is performed using the gating signal and the inductor current slope. This method can compensate for the delay time, and detect the fault fast within 2-sampling time in real-time. Through the ANN, fault detection is possible without additional circuits or complex algorithms, and training data is composed of integers, errors can be reduced. The proposed method is verified by PSIM simulation.},
booktitle = {2021 24th International Conference on Electrical Machines and Systems (ICEMS)},
pages = {2318–2322},
numpages = {5},
location = {Gyeongju, Korea, Republic of}
}

@inproceedings{10.1145/3368089.3409671,
author = {Yan, Shenao and Tao, Guanhong and Liu, Xuwei and Zhai, Juan and Ma, Shiqing and Xu, Lei and Zhang, Xiangyu},
title = {Correlations between deep neural network model coverage criteria and model quality},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409671},
doi = {10.1145/3368089.3409671},
abstract = {Inspired by the great success of using code coverage as guidance in software testing, a lot of neural network coverage criteria have been proposed to guide testing of neural network models (e.g., model accuracy under adversarial attacks). However, while the monotonic relation between code coverage and software quality has been supported by many seminal studies in software engineering, it remains largely unclear whether similar monotonicity exists between neural network model coverage and model quality. This paper sets out to answer this question. Specifically, this paper studies the correlation between DNN model quality and coverage criteria, effects of coverage guided adversarial example generation compared with gradient decent based methods, effectiveness of coverage based retraining compared with existing adversarial training, and the internal relationships among coverage criteria.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {775–787},
numpages = {13},
keywords = {Software Testing, Deep Neural Networks},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.1109/MSR.2019.00052,
author = {Bangash, Abdul Ali and Sahar, Hareem and Chowdhury, Shaiful and Wong, Alexander William and Hindle, Abram and Ali, Karim},
title = {What do developers know about machine learning: a study of ML discussions on StackOverflow},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00052},
doi = {10.1109/MSR.2019.00052},
abstract = {Machine learning, a branch of Artificial Intelligence, is now popular in software engineering community and is successfully used for problems like bug prediction, and software development effort estimation. Developers' understanding of machine learning, however, is not clear, and we require investigation to understand what educators should focus on, and how different online programming discussion communities can be more helpful. We conduct a study on Stack Overflow (SO) machine learning related posts using the SOTorrent dataset. We found that some machine learning topics are significantly more discussed than others, and others need more attention. We also found that topic generation with Latent Dirichlet Allocation (LDA) can suggest more appropriate tags that can make a machine learning post more visible and thus can help in receiving immediate feedback from sites like SO.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {260–264},
numpages = {5},
keywords = {topic modeling, stackoverflow, machine learning},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1007/978-3-030-59003-1_26,
author = {Galli, Antonio and Moscato, Vincenzo and Sperl\'{\i}, Giancarlo and Santo, Aniello De},
title = {An Explainable Artificial Intelligence Methodology for Hard Disk Fault Prediction},
year = {2020},
isbn = {978-3-030-59002-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59003-1_26},
doi = {10.1007/978-3-030-59003-1_26},
abstract = {Failure rates of Hard Disk Drives (HDDs) are high and often due to a variety of different conditions. Thus, there is increasing demand for technologies dedicated to anticipating possible causes of failure, so to allow for preventive maintenance operations. In this paper, we propose a framework to predict HDD health status according to a long short-term memory (LSTM) model. We also employ eXplainable Artificial Intelligence (XAI) tools, to provide effective explanations of the model decisions, thus making the final results more useful to human decision-making processes. We extensively evaluate our approach on standard data-sets, proving its feasibility for real world applications.},
booktitle = {Database and Expert Systems Applications: 31st International Conference, DEXA 2020, Bratislava, Slovakia, September 14–17, 2020, Proceedings, Part I},
pages = {403–413},
numpages = {11},
keywords = {HDD maintenance, LSTMs, Explainable AI},
location = {Bratislava, Slovakia}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00049,
author = {Zhu, Junjie and Long, Teng and Memon, Atif},
title = {Automatically authoring regression tests for machine-learning based systems},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00049},
doi = {10.1109/ICSE-SEIP52600.2021.00049},
abstract = {Two key design characteristics of machine learning (ML) systems---their ever-improving nature, and learning-based emergent functional behavior---create a moving target, posing new challenges for authoring/maintaining functional regression tests. We identify four specific challenges and address them by developing a new general methodology to automatically author and maintain tests. In particular, we use the volume of production data to periodically refresh our large corpus of test inputs and expected outputs; we use perturbation of the data to obtain coverage-adequate tests; and we use clustering to help identify patterns of failures that are indicative of software bugs. We demonstrate our methodology on an ML-based context-aware Speller. Our coverage-adequate, approx. 1 million regression test cases, automatically authored and maintained for Speller (1) are virtually maintenance free, (2) detect a higher number of Speller failures than previous manually-curated tests, (3) have better coverage of previously unknown functional boundaries of the ML component, and (4) lend themselves to automatic failure triaging by clustering and prioritizing subcategories of tests with over-represented failures. We identify several systematic failure patterns which were due to previously undetected bugs in the Speller, e.g., (1) when the user misses the first letter in a short word, and (2) when the user mistakenly inserts a character in the last token of an address; these have since been fixed.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {374–383},
numpages = {10},
keywords = {spelling correction, ML-based testing, ML testing},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@article{10.1007/s11227-019-02993-5,
author = {Karthikeyan, S. and Vimala Devi, K. and Valarmathi, K.},
title = {RETRACTED ARTICLE: Design and implementation of CfoTS networks for industrial fault detection and correction mechanism},
year = {2020},
issue_date = {Aug 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {8},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-019-02993-5},
doi = {10.1007/s11227-019-02993-5},
abstract = {In the industry, large- and small-scale manufacturers and even original equipment manufacturers are facing a major problem in monitoring large data. Because the amount of data is increasing daily, detecting faults and the methodology of detecting faults are becoming increasingly complex, such that there are insufficient intelligent data-driven mechanisms for achieving a short response time and high accuracy. Intelligent systems utilizing the advantages of Internet of Things (IoT) are emerging; however, they still require innovation. To design an intelligent system for a fault detection system, we propose a new fog-based IoT framework called cognitive Fog of Things framework, for achieving improved industrial fault detection and correction. The proposed framework comprises fog area networks including sensor nodes, fogs, and machine learning algorithms for detection and prediction. The proposed network operates on message queue transportation telemetry and cognitive learning fogs. The proposed concept is developed in a real-time scenario using Raspberry Pi with different case studies for implementation and using various parameters such as different types of faults, time of computation, detection time, and accuracy.},
journal = {J. Supercomput.},
month = aug,
pages = {5763–5779},
numpages = {17},
keywords = {CfoTS, FAN, IoT, Machine learning algorithms, MQTT, Cognitive learning fogs}
}

@inproceedings{10.1109/ICTAI.2010.27,
author = {Khoshgoftaar, Taghi M. and Gao, Kehan and Seliya, Naeem},
title = {Attribute Selection and Imbalanced Data: Problems in Software Defect Prediction},
year = {2010},
isbn = {9780769542638},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICTAI.2010.27},
doi = {10.1109/ICTAI.2010.27},
abstract = {The data mining and machine learning community is often faced with two key problems: working with imbalanced data and selecting the best features for machine learning. This paper presents a process involving a feature selection technique for selecting the important attributes and a data sampling technique for addressing class imbalance. The application domain of this study is software engineering, more specifically, software quality prediction using classification models. When using feature selection and data sampling together, different scenarios should be considered. The four possible scenarios are: (1) feature selection based on original data, and modeling (defect prediction) based on original data; (2) feature selection based on original data, and modeling based on sampled data; (3) feature selection based on sampled data, and modeling based on original data; and (4) feature selection based on sampled data, and modeling based on sampled data. The research objective is to compare the software defect prediction performances of models based on the four scenarios. The case study consists of nine software measurement data sets obtained from the PROMISE software project repository. Empirical results suggest that feature selection based on sampled data performs significantly better than feature selection based on original data, and that defect prediction models perform similarly regardless of whether the training data was formed using sampled or original data.},
booktitle = {Proceedings of the 2010 22nd IEEE International Conference on Tools with Artificial Intelligence - Volume 01},
pages = {137–144},
numpages = {8},
keywords = {software measurements, feature selection, defect prediction, data sampling},
series = {ICTAI '10}
}

@article{10.2478/acss-2020-0017,
author = {Abramov, Kirill and Grundspenkis, Janis},
title = {Suitability Determination of Machine Learning Techniques for the Operational Quality Assessment of Geophysical Survey Results},
year = {2020},
issue_date = {Dec 2020},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {25},
number = {2},
issn = {2255-8691},
url = {https://doi.org/10.2478/acss-2020-0017},
doi = {10.2478/acss-2020-0017},
abstract = {Well logging, also known as a geophysical survey, is one of the main components of a nuclear fuel cycle. This survey follows directly after the drilling process, and the operational quality assessment of its results is a very serious problem. Any mistake in this survey can lead to the culling of the whole well. This paper examines the feasibility of applying machine learning techniques to quickly assess the well logging quality results. The studies were carried out by a reference well modelling for the selected uranium deposit of the Republic of Kazakhstan and further comparing it with the results of geophysical surveys recorded earlier. The parameters of the geophysical methods and the comparison rules for them were formulated after the reference well modelling process. The classification trees and the artificial neural networks were used during the research process and the results obtained for both methods were compared with each other. The results of this paper may be useful to the enterprises engaged in the geophysical well surveys and data processing obtained during the logging process.},
journal = {Appl. Comput. Syst.},
month = dec,
pages = {153–162},
numpages = {10},
keywords = {well logging, neural networks, machine learning, Classification trees}
}

@inproceedings{10.1145/3425174.3425226,
author = {Santos, Sebasti\~{a}o H. N. and da Silveira, Beatriz Nogueira Carvalho and Andrade, Stev\~{a}o A. and Delamaro, M\'{a}rcio and Souza, Simone R. S.},
title = {An Experimental Study on Applying Metamorphic Testing in Machine Learning Applications},
year = {2020},
isbn = {9781450387552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425174.3425226},
doi = {10.1145/3425174.3425226},
abstract = {Machine learning techniques have been successfully employed in various areas and, in particular, for the development of healthcare applications, aiming to support in more effective and faster diagnostics (such as cancer diagnosis). However, machine learning models may present uncertainties and errors. Errors in the training process, classification, and evaluation can generate incorrect results and, consequently, to wrong clinical decisions, reducing the professionals' confidence in the use of such techniques. Similar to other application domains, the quality should be guaranteed to produce more reliable models capable of assisting health professionals in their daily activities. Metamorphic testing can be an interesting option to validate machine learning applications. Using this testing approach is possible to define relationships that define changes to be made in the application's input data to identify faults. This paper presents an experimental study to evaluate the effectiveness of metamorphic testing to validate machine learning applications. A Machine learning application to verify breast cancer diagnostic was developed, using an available dataset composed of 569 samples whose data were taken from breast cancer images, and used as the software under test, in which the metamorphic testing was applied. The results indicate that metamorphic testing can be an alternative to support the validation of machine learning applications.},
booktitle = {Proceedings of the 5th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {98–106},
numpages = {9},
keywords = {Metamorphic Test, Machine Learning, Experimental Study},
location = {Natal, Brazil},
series = {SAST '20}
}

@inproceedings{10.1145/3021460.3021491,
author = {Malhotra, Ruchika},
title = {Software Quality Predictive Modeling: An Effective Assessment of Experimental Data},
year = {2017},
isbn = {9781450348560},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3021460.3021491},
doi = {10.1145/3021460.3021491},
abstract = {A major problem faced by software project managers is to develop good quality software products within tight schedules and budget constraints [1]. Predictive modeling, in the context of software engineering relates to construction of models for estimation of software quality attributes such as defect-proneness, maintainability and effort amongst others. For developing such models, software metrics act as predictor variables as they signify various design characteristics of a software such as coupling, cohesion, inheritance and polymorphism. A number of techniques such as statistical and machine learning are available for developing predictive models.However, conducting effective empirical studies, which develop successful predictive models, is not possible if proper research methodology and steps are not followed. This work introduces a successful stepwise procedure for efficient application of various techniques to predictive modeling. A number of research issues which are important to be addressed while conducting empirical studies such as data collection, validation method, use of statistical tests, use of an effective performance evaluator etc. are also discussed with the help of an example.The tutorial presents an overview of the research process and methodology followed in an empirical research [2]. All steps that are needed to perform an effective empirical study are described. The tutorial would demonstrate the research methodology with the help of an example based on a data set for defect prediction.In this work we focus on various research issues that are stated below:RQ1: Which repositories are available for extracting software engineering data?RQ2: What type of data pre-processing and feature selection techniques should be used before developing predictive models?RQ3: Which possible tools are freely available for mining and analysis of data for developing software quality predictive models?RQ4: Which techniques are available for developing software quality predictive models?RQ5: Which metrics should be used for performance evaluation for models developed for software?RQ6: Which statistical tests can be effectively used for hypothesis testing using search-based techniques?RQ7: How can we effectively use search-based techniques for predictive modeling?RQ8: What are possible fitness functions while using search-based techniques for predictive modeling?RQ9: How would researchers account for the stochastic nature of search-based techniques?The reasons for relevance of this study are manifold. Empirical validation of OO metrics is a critical research area in the present day scenario, with a large number of academicians and research practitioners working towards this direction to predict software quality attributes in the early phases of software development. Thus, we explore the various steps involved in development of an effective software quality predictive model using a modeling technique with an example data set. Performing successful empirical studies in software engineering is important for the following reasons:• To identify defective classes at the initial phases of software development so that more resources can be allocated to these classes to remove errors.• To analyze the metrics which are important for predicting software quality attributes and to use them as quality benchmarks so that the software process can be standardized and delivers effective products.• To efficiently plan testing, walkthroughs, reviews and inspection activities so that limited resources can be properly planned to provide good quality software.• To use and adapt different techniques (statistical, machine learning &amp; search-based) in predicting software quality attributes.• To analyze existing trends for software quality predictive modeling and suggest future directions for researchers.• To document the research methodology so that effective replicated studies can be performed with ease.},
booktitle = {Proceedings of the 10th Innovations in Software Engineering Conference},
pages = {215–216},
numpages = {2},
keywords = {Software quality predictive modeling, Search-based techniques, Object-oriented metrics, Empirical Validation},
location = {Jaipur, India},
series = {ISEC '17}
}

@article{10.1177/0037549718803716,
author = {Singh, Rajmeet and Bera, Tarun Kumar},
title = {Fault detection, isolation and reconfiguration of a bipedal-legged robot},
year = {2019},
issue_date = {Oct 2019},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
volume = {95},
number = {10},
issn = {0037-5497},
url = {https://doi.org/10.1177/0037549718803716},
doi = {10.1177/0037549718803716},
abstract = {This paper deals with the fault detection, isolation (FDI) and reconfiguration of the locomotion of a bipedal-legged robot. Initially, the planar model of the legged robot in the vertical plane is developed using a bond graph (BG) approach. Then, the planar BG model of the legged robot is extended to the three-dimensional legged robot. Two individual motors are used to actuate the prismatic leg of the robot for locomotion. The BG simulation provides results for straight walking based on an oscillating cylinder mechanism and the turning motion of the legged robot are discussed. The prototype model of the legged robot is also developed and experimentation is done for straight and inclined plane applications. Finally, an FDI technique for the three-dimensional model of a legged robot is developed for the generation of fault indicators (i.e., analytical redundancy relations; ARRs) in the presence of system failure. The ARRs are derived from the BG model of the legged robot during the occurrences of the fault. The experimental results are validated with the simulation results for FDI and reconfiguration when the robot manoeuvres in a U-shaped path. The real-time fault diagnosis and reconfiguration for locomotion of the legged robot is possible with this FDI approach.},
journal = {Simulation},
month = oct,
pages = {955–977},
numpages = {23},
keywords = {simulation, experiment, isolation and reconfiguration, fault detection, bond graph, oscillating cylinder mechanism, prismatic leg, Legged robot}
}

@article{10.1155/2021/6627588,
author = {Xie, Yuan and Zhao, Jisheng and Qiang, Baohua and Mi, Luzhong and Tang, Chenghua and Li, Longge and Xue, Xingsi},
title = {Attention Mechanism-Based CNN-LSTM Model for Wind Turbine Fault Prediction Using SSN Ontology Annotation},
year = {2021},
issue_date = {2021},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2021},
issn = {1530-8669},
url = {https://doi.org/10.1155/2021/6627588},
doi = {10.1155/2021/6627588},
abstract = {The traditional model for wind turbine fault prediction is not sensitive to the time sequence data and cannot mine the deep connection between the time series data, resulting in poor generalization ability of the model. To solve this problem, this paper proposes an attention mechanism-based CNN-LSTM model. The semantic sensor data annotated by SSN ontology is used as input data. Firstly, CNN extracts features to get high-level feature representation from input data. Then, the latent time sequence connection of features in different time periods is learned by LSTM. Finally, the output of LSTM is input into the attention mechanism module to obtain more fault-related target information, which improves the efficiency, accuracy, and generalization ability of the model. In addition, in the data preprocessing stage, the random forest algorithm analyzes the feature correlation degree of the data to get the features of high correlation degree with the wind turbine fault, which further improves the efficiency, accuracy, and generalization ability of the model. The model is validated on the icing fault dataset of No. 21 wind turbine and the yaw dataset of No. 4 wind turbine. The experimental results show that the proposed model has better efficiency, accuracy, and generalization ability than RNN, LSTM, and XGBoost.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {12}
}

@article{10.1016/j.neucom.2018.11.053,
author = {V. Utkin, Lev},
title = {An imprecise extension of SVM-based machine learning models},
year = {2019},
issue_date = {Feb 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {331},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.11.053},
doi = {10.1016/j.neucom.2018.11.053},
journal = {Neurocomput.},
month = feb,
pages = {18–32},
numpages = {15},
keywords = {Imprecise model, Interval-valued data, Regression, Classification, Duality, Support vector machine, Machine learning}
}

@inproceedings{10.1109/ASE.2019.00164,
author = {Zhang, Kevin},
title = {A machine learning based approach to identify SQL injection vulnerabilities},
year = {2020},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00164},
doi = {10.1109/ASE.2019.00164},
abstract = {This paper presents a machine learning classifier designed to identify SQL injection vulnerabilities in PHP code. Both classical and deep learning based machine learning algorithms were used to train and evaluate classifier models using input validation and sanitization features extracted from source code files. On ten-fold cross validations a model trained using Convolutional Neural Network(CNN) achieved the highest precision (95.4%), while a model based on Multilayer Perceptron (MLP) achieved the highest recall (63.7%) and the highest fmeasure (0.746).},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1286–1288},
numpages = {3},
keywords = {vulnerability, prediction model, deep learning, SQL injection},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3387940.3392694,
author = {Liu, Yelin and Liu, Yang and Chen, Tsong Yueh and Zhou, Zhi Quan},
title = {A Testing Tool for Machine Learning Applications},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3392694},
doi = {10.1145/3387940.3392694},
abstract = {We present the design of MTKeras, a generic metamorphic testing framework for machine learning, and demonstrate its effectiveness through case studies in image classification and sentiment analysis.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {386–387},
numpages = {2},
keywords = {oracle problem, neural network API, metamorphic relation pattern, Metamorphic testing, MTKeras, MR composition, Keras},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@article{10.1007/s11219-020-09508-z,
author = {Falcone, Yli\`{e}s and Mariani, Leonardo},
title = {Preface to the special section on improving software quality through formal methods},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-020-09508-z},
doi = {10.1007/s11219-020-09508-z},
journal = {Software Quality Journal},
month = jun,
pages = {693–694},
numpages = {2}
}

@article{10.1016/j.infsof.2013.02.009,
author = {Radjenovi\'{c}, Danijel and Heri\v{c}ko, Marjan and Torkar, Richard and \v{Z}ivkovi\v{c}, Ale\v{s}},
title = {Software fault prediction metrics},
year = {2013},
issue_date = {August 2013},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {55},
number = {8},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2013.02.009},
doi = {10.1016/j.infsof.2013.02.009},
abstract = {ContextSoftware metrics may be used in fault prediction models to improve software quality by predicting fault location. ObjectiveThis paper aims to identify software metrics and to assess their applicability in software fault prediction. We investigated the influence of context on metrics' selection and performance. MethodThis systematic literature review includes 106 papers published between 1991 and 2011. The selected papers are classified according to metrics and context properties. ResultsObject-oriented metrics (49%) were used nearly twice as often compared to traditional source code metrics (27%) or process metrics (24%). Chidamber and Kemerer's (CK) object-oriented metrics were most frequently used. According to the selected studies there are significant differences between the metrics used in fault prediction performance. Object-oriented and process metrics have been reported to be more successful in finding faults compared to traditional size and complexity metrics. Process metrics seem to be better at predicting post-release faults compared to any static code metrics. ConclusionMore studies should be performed on large industrial software systems to find metrics more relevant for the industry and to answer the question as to which metrics should be used in a given context.},
journal = {Inf. Softw. Technol.},
month = aug,
pages = {1397–1418},
numpages = {22},
keywords = {Systematic literature review, Software metric, Software fault prediction}
}

@article{10.1007/s10489-015-0694-6,
author = {Chebel-Morello, Brigitte and Malinowski, Simon and Senoussi, Hafida},
title = {Feature selection for fault detection systems: application to the Tennessee Eastman process},
year = {2016},
issue_date = {January   2016},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {44},
number = {1},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-015-0694-6},
doi = {10.1007/s10489-015-0694-6},
abstract = {In fault detection systems, a massive amount of data gathered from the life-cycle of equipment is often used to learn models or classifiers that aims at diagnosing different kinds of errors or failures. Among this huge quantity of information, some features (or sets of features) are more correlated with a kind of failure than another. The presence of irrelevant features might affect the performance of the classifier. To improve the performance of a detection system, feature selection is hence a key step. We propose in this paper an algorithm named STRASS, which aims at detecting relevant features for classification purposes. In certain cases, when there exists a strong correlation between some features and the associated class, conventional feature selection algorithms fail at selecting the most relevant features. In order to cope with this problem, STRASS algorithm uses k-way correlation between features and the class to select relevant features. To assess the performance of STRASS, we apply it on simulated data collected from the Tennessee Eastman chemical plant simulator. The Tennessee Eastman process (TEP) has been used in many fault detection studies and three specific faults are not well discriminated with conventional algorithms. The results obtained by STRASS are compared to those obtained with reference feature selection algorithms. We show that the features selected by STRASS always improve the performance of a classifier compared to the whole set of original features and that the obtained classification is better than with most of the other feature selection algorithms.},
journal = {Applied Intelligence},
month = jan,
pages = {111–122},
numpages = {12},
keywords = {Wrapper method, Feature selection, Fault detection, Contextual measure}
}

@article{10.1155/2016/1286318,
author = {Asghar, Furqan and Talha, Muhammad and Kim, Sung Ho},
title = {Neural Network Based Fault Detection and Diagnosis System for Three-Phase Inverter in Variable Speed Drive with Induction Motor},
year = {2016},
issue_date = {November  2016},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2016},
issn = {1687-5249},
url = {https://doi.org/10.1155/2016/1286318},
doi = {10.1155/2016/1286318},
abstract = {Recently, electrical drives generally associate inverter and induction machine. Therefore, inverter must be taken into consideration along with induction motor in order to provide a relevant and efficient diagnosis of these systems. Various faults in inverter may influence the system operation by unexpected maintenance, which increases the cost factor and reduces overall efficiency. In this paper, fault detection and diagnosis based on features extraction and neural network technique for three-phase inverter is presented. Basic purpose of this fault detection and diagnosis system is to detect single or multiple faults efficiently. Several features are extracted from the Clarke transformed output current and used in neural network as input for fault detection and diagnosis. Hence, some simulation study as well as hardware implementation and experimentation is carried out to verify the feasibility of the proposed scheme. Results show that the designed system not only detects faults easily, but also can effectively differentiate between multiple faults. These results prove the credibility and show the satisfactory performance of designed system. Results prove the supremacy of designed system over previous feature extraction fault systems as it can detect and diagnose faults in a single cycle as compared to previous multicycles detection with high accuracy.},
journal = {J. Control Sci. Eng.},
month = nov,
pages = {1}
}

@article{10.1007/s10462-020-09814-9,
author = {Gangavarapu, Tushaar and Jaidhar, C. D. and Chanduka, Bhabesh},
title = {Applicability of machine learning in spam and phishing email filtering: review and approaches},
year = {2020},
issue_date = {Oct 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {7},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-020-09814-9},
doi = {10.1007/s10462-020-09814-9},
abstract = {With the influx of technological advancements and the increased simplicity in communication, especially through emails, the upsurge in the volume of unsolicited bulk emails (UBEs) has become a severe threat to global security and economy. Spam emails not only waste users’ time, but also consume a lot of network bandwidth, and may also include malware as executable files. Alternatively, phishing emails falsely claim users’ personal information to facilitate identity theft and are comparatively more dangerous. Thus, there is an intrinsic need for the development of more robust and dependable UBE filters that facilitate automatic detection of such emails. There are several countermeasures to spam and phishing, including blacklisting and content-based filtering. However, in addition to content-based features, behavior-based features are well-suited in the detection of UBEs. Machine learning models are being extensively used by leading internet service providers like Yahoo, Gmail, and Outlook, to filter and classify UBEs successfully. There are far too many options to consider, owing to the need to facilitate UBE detection and the recent advances in this domain. In this paper, we aim at elucidating on the way of extracting email content and behavior-based features, what features are appropriate in the detection of UBEs, and the selection of the most discriminating feature set. Furthermore, to accurately handle the menace of UBEs, we facilitate an exhaustive comparative study using several state-of-the-art machine learning algorithms. Our proposed models resulted in an overall accuracy of 99% in the classification of UBEs. The text is accompanied by snippets of Python code, to enable the reader to implement the approaches elucidated in this paper.},
journal = {Artif. Intell. Rev.},
month = oct,
pages = {5019–5081},
numpages = {63},
keywords = {Spam, Python, Phishing, Machine learning, Feature engineering}
}

@article{10.1016/j.compag.2018.06.033,
author = {Lude\~{n}a-Choez, Jimmy and Choquehuanca-Zevallos, Juan J. and Mayhua-L\'{o}pez, Efra\'{\i}n},
title = {Sensor nodes fault detection for agricultural wireless sensor networks based on NMF},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {161},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2018.06.033},
doi = {10.1016/j.compag.2018.06.033},
journal = {Comput. Electron. Agric.},
month = jun,
pages = {214–224},
numpages = {11},
keywords = {Discrete Wavelet Transform (DWT), Principal Components Analysis (PCA), Non-Negative Matrix Factorization (NMF), Wireless Sensor Networks (WSN), Sensor nodes fault detection}
}

@article{10.1504/ijhpcn.2020.113779,
author = {Chouhan, Lokesh and Chauhan, Nancy and Mahapatra, Amitosh Swain and Agarwal, Vidushi},
title = {A survey on the applications of machine learning in wireless sensor networks},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {16},
number = {4},
issn = {1740-0562},
url = {https://doi.org/10.1504/ijhpcn.2020.113779},
doi = {10.1504/ijhpcn.2020.113779},
abstract = {With the dawn of the 21st century and the growth of fast, always available and low power networks, wireless sensor networks are being implemented in diverse use-cases. Wireless sensor networks are being deployed to observe, explore and control the physical world. Wireless sensor networks are generally deployed in dynamic environments. Sensor networks utilise machine learning techniques to avoid the unnecessary redesign of a wireless sensor network deployment for adapting to changing requirements. Machine learning is also used to maximise the security, efficiency, lifetime, and resource utilisation in such networks. In this paper, we present an extensive literature survey of various machine learning applications that are used or are in research to address the operational and non-operational challenges in wireless sensor networks.},
journal = {Int. J. High Perform. Comput. Netw.},
month = jan,
pages = {197–220},
numpages = {23},
keywords = {wireless sensor networks, security, machine learning, data aggregation, clustering}
}

@inproceedings{10.1007/978-3-030-73128-1_5,
author = {EzzatiKarami, Mahtab and Madhavji, Nazim H.},
title = {Automatically Classifying Non-functional Requirements with Feature Extraction and Supervised Machine Learning Techniques: A Research Preview},
year = {2021},
isbn = {978-3-030-73127-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-73128-1_5},
doi = {10.1007/978-3-030-73128-1_5},
abstract = {Context and Motivation: In large projects, extracting the relevant NFR-information as per the stakeholder’s responsibility and needs can be time-consuming and challenging. Question/Problem: Classification of NFRs is one way to mitigate this problem. However, because of the size and complexity of the SRS, the manual classification of NFRs is considered time-consuming, labour-intensive, and error-prone. An automated solution is needed that provides a reliable and efficient classification of NFRs. Principal ideas/results: Using natural language processing and supervised machine learning (SML) algorithms, we investigate feature extraction techniques (i.e., POS-tagging based, BoW, and TF-IDF) to assess their efficacy in automated classification, in conjunction with the SML algorithms (such as: SVM, SGD SVM, LR, DT, Bagging DT, Extra Tree, RF, GNB, MNB, and BNB). Contribution: The proposed combinations: (i) SVM with TF-IDF, (ii) LR with POS and BoW, and (iii) MNB with BoW, all achieve precision and recall values greater than 0.85, and process execution time of less than 0.1 s. Comparison with related work is favourable as is preliminary validation using an industry dataset.},
booktitle = {Requirements Engineering:  Foundation  for Software Quality: 27th International Working Conference, REFSQ 2021, Essen, Germany, April 12–15, 2021, Proceedings},
pages = {71–78},
numpages = {8},
keywords = {Non-functional requirements, Classification, Supervised Machine Learning, Feature extraction}
}

@article{10.1504/ijahuc.2020.106664,
author = {Masdari, Mohammad},
title = {Towards effective fault detection in heterogeneous wireless sensor networks},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {33},
number = {4},
issn = {1743-8225},
url = {https://doi.org/10.1504/ijahuc.2020.106664},
doi = {10.1504/ijahuc.2020.106664},
abstract = {Accurate detection of the faulty nodes and transmitting correct status data of a monitored environment is one of the crucial challenges in wireless sensor networks (WSNs). This paper puts forward a novel unsupervised faulty node detection algorithm to improve the detection accuracy of events in the 2D and 3D heterogeneous WSNs. In this approach, the current status of each node is predicted by using the ARIMA methods and factors such as distance and the common coverage ratio. Moreover, the node's status in the previous rounds is employed to weight the measured values of the neighbouring nodes. By using the proposed distributed algorithm, each sensor node can recognise its status with more accuracy, in the presence of transient faults and events like fire. Extensive simulations indicate the effectiveness of this algorithm in reducing the false positive problem and improving the detection accuracy in different scenarios considered for the 2D and 3D heterogeneous WSNs.},
journal = {Int. J. Ad Hoc Ubiquitous Comput.},
month = jan,
pages = {216–228},
numpages = {12},
keywords = {ARIMA, true negatives, false positives, voting, fault detection, heterogeneous, WSN, wireless sensor network}
}

@article{10.1016/j.jvcir.2019.102647,
author = {Wang, Yanhai and Li, Qingquan and Chen, Bo},
title = {Image classification towards transmission line fault detection via learning deep quality-aware fine-grained categorization},
year = {2019},
issue_date = {Oct 2019},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {64},
number = {C},
issn = {1047-3203},
url = {https://doi.org/10.1016/j.jvcir.2019.102647},
doi = {10.1016/j.jvcir.2019.102647},
journal = {J. Vis. Comun. Image Represent.},
month = oct,
numpages = {6},
keywords = {SVM, Fast R-CNN, Quality model, Fault recognition, Fine-grained categorization}
}

@inproceedings{10.1145/2393596.2393669,
author = {Rahman, Foyzur and Posnett, Daryl and Devanbu, Premkumar},
title = {Recalling the "imprecision" of cross-project defect prediction},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2393596.2393669},
doi = {10.1145/2393596.2393669},
abstract = {There has been a great deal of interest in defect prediction: using prediction models trained on historical data to help focus quality-control resources in ongoing development. Since most new projects don't have historical data, there is interest in cross-project prediction: using data from one project to predict defects in another. Sadly, results in this area have largely been disheartening. Most experiments in cross-project defect prediction report poor performance, using the standard measures of precision, recall and F-score. We argue that these IR-based measures, while broadly applicable, are not as well suited for the quality-control settings in which defect prediction models are used. Specifically, these measures are taken at specific threshold settings (typically thresholds of the predicted probability of defectiveness returned by a logistic regression model). However, in practice, software quality control processes choose from a range of time-and-cost vs quality tradeoffs: how many files shall we test? how many shall we inspect? Thus, we argue that measures based on a variety of tradeoffs, viz., 5%, 10% or 20% of files tested/inspected would be more suitable. We study cross-project defect prediction from this perspective. We find that cross-project prediction performance is no worse than within-project performance, and substantially better than random prediction!},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {61},
numpages = {11},
keywords = {inspection, fault prediction, empirical software engineering},
location = {Cary, North Carolina},
series = {FSE '12}
}

@inproceedings{10.1007/978-3-642-32639-4_21,
author = {Yang, Xiaoxing and Tang, Ke and Yao, Xin},
title = {A learning-to-rank algorithm for constructing defect prediction models},
year = {2012},
isbn = {9783642326387},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-32639-4_21},
doi = {10.1007/978-3-642-32639-4_21},
abstract = {This paper applies the learning-to-rank approach to software defect prediction. Ranking software modules in order of defect-proneness is important to ensure that testing resources are allocated efficiently. However, prediction models that are optimized for predicting explicitly the number of defects often fail to correctly predict rankings based on those defect numbers. We show in this paper that the model construction methods, which include the ranking performance measure in the objective function, perform better in predicting defect-proneness rankings of multiple modules. We present the experimental results, in which our method is compared against three other methods from the literature, using five publicly available data sets.},
booktitle = {Proceedings of the 13th International Conference on Intelligent Data Engineering and Automated Learning},
pages = {167–175},
numpages = {9},
keywords = {software defect prediction, learning-to-rank, differential evolution},
location = {Natal, Brazil},
series = {IDEAL'12}
}

@phdthesis{10.5555/AAI28492704,
author = {Ansarifar, Javad and Guiping, Hu, and William, Beavis, and Sotirios, Archontoulis, and Sigurdar, Olafsson,},
advisor = {Lizhi, Wang,},
title = {Machine Learning and Optimization Algorithms and Their Applications in Agriculture},
year = {2021},
isbn = {9798544277231},
publisher = {Iowa State University},
address = {USA},
abstract = {This dissertation is devoted to using machine learning and optimization algorithms to develop explainable machine learning and decision-making models and their applications in agriculture. This dissertation consists of four journal papers. The first three papers focus on formulating explainable machine learning, and the last one is about the decision-making model for the planting scheduling.The first paper proposes three new algorithms for multi-effect and multi-way epistases detection. Epistases refer to the phenomenon of genetic interactions that plays a significant role in many scientific discoveries such as the breeding process, case-and-control studies, and genome-wide association studies. Deciphering the exact genetic interactions is challenging because of the combinatorial nature of the problem. These three models are developed to detect the interaction between a binary representation of the genetic information so that one guaranteeing global optimality and the other two being local optimization-oriented heuristics. The computational performance of the proposed models were compared with several state-of-the-art methods using a yeast data set. In the second paper, a new explainable machine learning model named the interaction regression model is developed for crop yield prediction. Crop yield prediction is a challenging issue because of multitudinous variables, including genotype, environment, management, and complex interactions that affect crop yield performance explicitly or implicitly. We integrate the power of optimization, machine learning, and agronomic insight to develop this explainable model with three salient properties. First, by outperforming state-of-the-art predictive models, the proposed model achieves an error prediction of 8% or less in three Midwest states (Illinois, Indiana, and Iowa) in the US Corn Belt for both corn and soybean yield prediction. Second, it detects the environment by management interactions for corn and soybean that are insightful agronomically. Third, this model can quantify and break down the yield into contributions from weather, soil, management, and their interactions that allow agronomists to analyze the favorable and unfavorable yield factors.The third paper develops a new predictive framework that integrates random forest and an optimization-based model for G * E interaction detection to predict crosses' yield performance. In the plant breeding process, the yield performance plays a significant role in selecting more productive and adaptable parents to the changing environments. The proposed framework integrates a random forest with a combinatorial optimization-based interaction-detection model and attempts to combine their strengths. This model consists of three main components; a random forest model that captures complex non-linear relationships between input and output variables, an interaction detection model that captures interactions among hybrid, location, and weather variables, and another random forest model that utilizes the interactions to augment the prediction performance of the first random forest model. This model won the first place in the 2020 Syngenta crop challenge in analytics.The fourth paper concerns the planting time scheduling problem of different population seeds in the year-round breeding process so that there is a consistent harvest quantity. Although developing the breeding process and producing higher-quality crops ensures global food availability and security, they raise new logistical and productivity challenges for seed industries in the year-round breeding process due to the storage limitation. 2021 Syngenta crop challenge in analytics was launched to challenge participants to design an optimization model for the planting time scheduling of several population seeds so that weekly harvest quantity would be consistent at the lowest possible capacity. We address this problem with uncertainty weather information by developing a new hybrid framework that combines the weather time series model and optimization model to schedule the planting time. Comparison with actual planting time scheduling reveals that the developed models scheduled the seed population's planting time at the fewest number of weeks with a more consistent weekly harvest quantity.},
note = {AAI28492704}
}

@article{10.1016/j.compind.2021.103394,
author = {Dias, Andre Luis and Turcato, Afonso Celso and Sestito, Guilherme Serpa and Brandao, Dennis and Nicoletti, Rodrigo},
title = {A cloud-based condition monitoring system for fault detection in rotating machines using PROFINET process data},
year = {2021},
issue_date = {Apr 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {126},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2021.103394},
doi = {10.1016/j.compind.2021.103394},
journal = {Comput. Ind.},
month = apr,
numpages = {13},
keywords = {Cloud computing, PROFINET, Support vector machine, Feature Selection, Rotating machines, Condition monitoring}
}

@article{10.1016/j.aei.2019.100991,
author = {Jeong, Seongwoon and Ferguson, Max and Hou, Rui and Lynch, Jerome P. and Sohn, Hoon and Law, Kincho H.},
title = {Sensor data reconstruction using bidirectional recurrent neural network with application to bridge monitoring},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {42},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2019.100991},
doi = {10.1016/j.aei.2019.100991},
journal = {Adv. Eng. Inform.},
month = oct,
numpages = {14},
keywords = {Smart structure, Structural health monitoring, Machine learning, Bidirectional recurrent neural network, Artificial neural network, Sensor data reconstruction}
}

@inproceedings{10.1007/978-3-030-30391-4_7,
author = {Madhikermi, Manik and Malhi, Avleen Kaur and Fr\"{a}mling, Kary},
title = {Explainable Artificial Intelligence Based Heat Recycler Fault Detection in Air Handling Unit},
year = {2019},
isbn = {978-3-030-30390-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30391-4_7},
doi = {10.1007/978-3-030-30391-4_7},
abstract = {We are entering a new age of AI applications where machine learning is the core technology but machine learning models are generally non-intuitive, opaque and usually complicated for people to understand. The current AI applications inability to explain is decisions and actions to end users have limited its effectiveness. The explainable AI will enable the users to understand, accordingly trust and effectively manage the decisions made by machine learning models. The heat recycler’s fault detection in Air Handling Unit (AHU) has been explained with explainable artificial intelligence since the fault detection is particularly burdensome because the reason for its failure is mostly unknown and unique. The key requirement of such systems is the early diagnosis of such faults for its economic and functional efficiency. The machine learning models, Support Vector Machine and Neural Networks have been used for the diagnosis of the fault and explainable artificial intelligence has been used to explain the models’ behaviour.},
booktitle = {Explainable, Transparent Autonomous Agents and Multi-Agent Systems: First International Workshop, EXTRAAMAS 2019, Montreal, QC, Canada, May 13–14, 2019, Revised Selected Papers},
pages = {110–125},
numpages = {16},
keywords = {Neural networks, Support vector machine, Heat recycler unit, Explainable artificial intelligence},
location = {Montreal, QC, Canada}
}

@inproceedings{10.1109/MSR.2019.00019,
author = {Ahluwalia, Aalok and Falessi, Davide and Di Penta, Massimiliano},
title = {Snoring: a noise in defect prediction datasets},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00019},
doi = {10.1109/MSR.2019.00019},
abstract = {In order to develop and train defect prediction models, researchers rely on datasets in which a defect is often attributed to a release where the defect itself is discovered. However, in many circumstances, it can happen that a defect is only discovered several releases after its introduction. This might introduce a bias in the dataset, i.e., treating the intermediate releases as defect-free and the latter as defect-prone. We call this phenomenon as "sleeping defects". We call "snoring" the phenomenon where classes are affected by sleeping defects only, that would be treated as defect-free until the defect is discovered. In this paper we analyze, on data from 282 releases of six open source projects from the Apache ecosystem, the magnitude of the sleeping defects and of the snoring classes. Our results indicate that 1) on all projects, most of the defects in a project slept for more than 20% of the existing releases, and 2) in the majority of the projects the missing rate is more than 25% even if we remove the last 50% of releases.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {63–67},
numpages = {5},
keywords = {fix-inducing changes, defect prediction, dataset bias},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1109/CSE.2014.198,
author = {Ryu, Duksan and Choi, Okjoo and Baik, Jongmoon},
title = {Improving Prediction Robustness of VAB-SVM for Cross-Project Defect Prediction},
year = {2014},
isbn = {9781479979813},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CSE.2014.198},
doi = {10.1109/CSE.2014.198},
abstract = {Software defect prediction is important for improving software quality. Defect predictors allow software test engineers to focus on defective modules. Cross-Project Defect Prediction (CPDP) uses data from other companies to build defect predictors. However, outliers may lower prediction accuracy. In this study, we propose a transfer learning based model called VAB-SVM for CPDP robust in handling outliers. Notably, this method deals with the class imbalance problem which may decrease the prediction accuracy. Our proposed method computes similarity weights of the training data based on the test data. Such weights are applied to Boosting algorithm considering the class imbalance. VAB-SVM outperformed the previous research more than 10% and showed a sufficient robustness regardless of the ratio of outliers.},
booktitle = {Proceedings of the 2014 IEEE 17th International Conference on Computational Science and Engineering},
pages = {994–999},
numpages = {6},
keywords = {Transfer Learning, Outlier Detection, Cross-Project Defect Prediction, Boosting},
series = {CSE '14}
}

@article{10.1016/j.compag.2019.01.041,
author = {Kaya, Aydin and Keceli, Ali Seydi and Catal, Cagatay and Yalic, Hamdi Yalin and Temucin, Huseyin and Tekinerdogan, Bedir},
title = {Analysis of transfer learning for deep neural network based plant classification models},
year = {2019},
issue_date = {Mar 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {158},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2019.01.041},
doi = {10.1016/j.compag.2019.01.041},
journal = {Comput. Electron. Agric.},
month = mar,
pages = {20–29},
numpages = {10},
keywords = {Convolutional neural networks, Fine-tuning, Deep neural networks, Transfer learning, Plant classification}
}

@inproceedings{10.1109/MICAI.2008.38,
author = {Virk, Shafqat M. and Muhammad, Aslam and Martinez-Enriquez, A. M.},
title = {Fault Prediction Using Artificial Neural Network and Fuzzy Logic},
year = {2008},
isbn = {9780769534411},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/MICAI.2008.38},
doi = {10.1109/MICAI.2008.38},
abstract = {This paper studies different vehicle fault prediction techniques, using artificial neural network and fuzzy logic based model. With increasing demands for efficiency and product quality as well as progressing integration of automatic control systems in high-cost mechatronics and safety-critical processes, monitoring is necessary to detect and diagnose faults using symptoms and related data. However, beyond protective maintenance services, it is viable to integrate fault prediction services. Thus, we studied different parameters to model a fault prediction service. This service not only helps to predict faults but is also useful to take precautionary measures to avoid tangible and intangible losses.},
booktitle = {Proceedings of the 2008 Seventh Mexican International Conference on Artificial Intelligence},
pages = {149–154},
numpages = {6},
keywords = {Faults, Artificial Neural Network, Fuzzy Logic, Neuro-Fuzzy, Neuro-Neuro, Recurrent Neural Network, Back-propagation},
series = {MICAI '08}
}

@article{10.1016/j.eswa.2019.01.011,
author = {Ragab, Ahmed and El Koujok, Mohamed and Ghezzaz, Hakim and Amazouz, Mouloud and Ouali, Mohamed-Salah and Yacout, Soumaya},
title = {Deep understanding in industrial processes by complementing human expertise with interpretable patterns of machine learning},
year = {2019},
issue_date = {May 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {122},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2019.01.011},
doi = {10.1016/j.eswa.2019.01.011},
journal = {Expert Syst. Appl.},
month = may,
pages = {388–405},
numpages = {18},
keywords = {Causality analysis, Machine learning and pattern recognition, Fault tree analysis (FTA), Logical analysis of data (LAD), Fault detection and diagnosis (FDD)}
}

@inproceedings{10.1145/3395363.3404364,
author = {Guo, Zichen and Liu, Jiawei and He, Tieke and Li, Zhuoyang and Zhangzhu, Peitian},
title = {TauJud: test augmentation of machine learning in judicial documents},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3404364},
doi = {10.1145/3395363.3404364},
abstract = {The booming of big data makes the adoption of machine learning ubiquitous in the legal field. As we all know, a large amount of test data can better reflect the performance of the model, so the test data must be naturally expanded. In order to solve the high cost problem of labeling data in natural language processing, people in the industry have improved the performance of text classification tasks through simple data amplification techniques. However, the data amplification requirements in the judgment documents are interpretable and logical, as observed from CAIL2018 test data with over 200,000 judicial documents. Therefore, we have designed a test augmentation tool called TauJud specifically for generating more effective test data with uniform distribution over time and location for model evaluation and save time in marking data. The demo can be found at https://github.com/governormars/TauJud.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {549–552},
numpages = {4},
keywords = {Test Augmentation, Machine Learning, Judicial Documents},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@inproceedings{10.1109/ASE.2013.6693126,
author = {Scanniello, Giuseppe and Gravino, Carmine and Marcus, Andrian and Menzies, Tim},
title = {Class level fault prediction using software clustering},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2013.6693126},
doi = {10.1109/ASE.2013.6693126},
abstract = {Defect prediction approaches use software metrics and fault data to learn which software properties associate with faults in classes. Existing techniques predict fault-prone classes in the same release (intra) or in a subsequent releases (inter) of a subject software system. We propose an intra-release fault prediction technique, which learns from clusters of related classes, rather than from the entire system. Classes are clustered using structural information and fault prediction models are built using the properties of the classes in each cluster. We present an empirical investigation on data from 29 releases of eight open source software systems from the PROMISE repository, with predictors built using multivariate linear regression. The results indicate that the prediction models built on clusters outperform those built on all the classes of the system.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {640–645},
numpages = {6},
keywords = {software clustering, fault prediction, empirical study},
location = {Silicon Valley, CA, USA},
series = {ASE '13}
}

@inproceedings{10.1109/IECON48115.2021.9589586,
author = {Zheng, Xinlong and Han, Hua and Shi, Manling and Sun, Yao and Su, Mei and Wang, Hongfei},
title = {A Hierarchical Intelligent Fault Detection and Location Scheme for DC Ring Bus Microgrid},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON48115.2021.9589586},
doi = {10.1109/IECON48115.2021.9589586},
abstract = {A hierarchical fault detection and fault location framework consisting of two levels is proposed for DC ring bus microgrids. In the primary level, a decentralized fault detection scheme based on back propagation (BP) artificial neural network (ANN) and discrete wavelet transform (DWT) is proposed to classify the pole-to-pole (P-P) and pole-to-ground (P-G) faults under measuring noises and load disturbances only relying on the information needed by the local double closed-loop controller, and the diagnosis speed and reliability of system are guaranteed. In the secondary level, a distributed line fault location method is presented by synthesizing the detection results of local and neighbor DG units with low bandwidth communication, and the accuracy of line faults is improved greatly without the central controller and additional sensors. Several simulation cases are analyzed under various fault configurations such as load mutations, different fault types, fault locations and fault impedance. The effectiveness and feasibility of the proposed method are verified.},
booktitle = {IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society},
pages = {1–5},
numpages = {5},
location = {Toronto, ON, Canada}
}

@article{10.1145/3146389,
author = {Khalastchi, Eliahu and Kalech, Meir},
title = {On Fault Detection and Diagnosis in Robotic Systems},
year = {2018},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3146389},
doi = {10.1145/3146389},
abstract = {The use of robots in our daily lives is increasing. Different types of robots perform different tasks that are too dangerous or too dull to be done by humans. These sophisticated machines are susceptible to different types of faults. These faults have to be detected and diagnosed in time to allow recovery and continuous operation. The field of Fault Detection and Diagnosis (FDD) has been studied for many years. This research has given birth to many approaches and techniques that are applicable to different types of physical machines. Yet the domain of robotics poses unique requirements that are very challenging for traditional FDD approaches. The study of FDD for robotics is relatively new, and only few surveys were presented. These surveys have focused on traditional FDD approaches and how these approaches may broadly apply to a generic type of robot. Yet robotic systems can be identified by fundamental characteristics, which pose different constraints and requirements from FDD. In this article, we aim to provide the reader with useful insights regarding the use of FDD approaches that best suit the different characteristics of robotic systems. We elaborate on the advantages these approaches have and the challenges they must face. To meet this aim, we use two perspectives: (1) we elaborate on FDD from the perspective of the different characteristics a robotic system may have and give examples of successful FDD approaches, and (2) we elaborate on FDD from the perspective of the different FDD approaches and analyze the advantages and disadvantages of each approach with respect to robotic systems. Finally, we describe research opportunities for robotic systems’ FDD. With these three contributions, readers from the FDD research communities are introduced to FDD for robotic systems, and the robotics research community is introduced to the field of FDD.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {9},
numpages = {24},
keywords = {robots, fault diagnosis, Fault detection}
}

@article{10.1016/j.procs.2021.01.360,
author = {Glock, Anna-Christina},
title = {Explaining a Random Forest With the Difference of Two ARIMA Models in an Industrial Fault Detection Scenario},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {180},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.01.360},
doi = {10.1016/j.procs.2021.01.360},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {476–481},
numpages = {6},
keywords = {Fault Detection, surrogate model, Explainable AI, random forest, ARIMA}
}

@article{10.1016/j.aei.2021.101318,
author = {Lv, Yaqiong and Zhou, Qianwen and Li, Yifan and Li, Weidong},
title = {A predictive maintenance system for multi-granularity faults based on AdaBelief-BP neural network and fuzzy decision making},
year = {2021},
issue_date = {Aug 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {49},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2021.101318},
doi = {10.1016/j.aei.2021.101318},
journal = {Adv. Eng. Inform.},
month = aug,
numpages = {12},
keywords = {Fuzzy decision making, AdaBelief-BP NN, Predictive maintenance, Multi-granularity faults, Fault prediction}
}

@article{10.1016/j.procs.2015.02.154,
author = {Mahajan, Rohit and Gupta, Sunil Kumar and Bedi, Rajeev Kumar},
title = {Design of Software Fault Prediction Model Using BR Technique},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.154},
doi = {10.1016/j.procs.2015.02.154},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {849–858},
numpages = {10},
keywords = {public dataset ;, Neural network, Levenberg-Marquardt (LM)algorithm, Back Propagation (BPA) algorithm ;Bayesian Regularization(BR)algorithml}
}

@article{10.1007/s00521-020-04963-y,
author = {Chen, Fujiang},
title = {Safety evaluation method of hoisting machinery based on neural network},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {2},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04963-y},
doi = {10.1007/s00521-020-04963-y},
abstract = {Hoisting machinery as a material handling equipment, widely used in the national economy departments, in the national “safe, efficient, green and harmonious” under the application requirements, to improve the intrinsically safe hoisting machinery, a complex system, in this paper, the affecting the safe operation of the hoisting machinery hazards, summary and analysis based on the intrinsic safety theory and correlation analysis method, on the nature of the hoisting machinery safety assessment model is established. The theory of information entropy and fuzzy mathematics, the safety evaluation method of hoisting machinery based on neural network is studied. Through summarizing the hazard factor of hoisting machinery, lifting machinery design, manufacture, installation, alteration, use, and management and so on, this paper analyzes advantages and disadvantages of commonly used safety assessment or prediction method, based on the “human–environment” of safety evaluation of ideas, will influence of lifting machinery into the ontology equipment hazards, organizational security hazards, essence of safety culture and emergency fault handling of hazards. In the paper, two neural networks are used to predict the failure rate, and the accuracy of the two methods is compared. Firstly, BP neural network is optimized by genetic algorithm for prediction. BP neural network optimized by genetic algorithm is the most widely used neural network for prediction. Secondly, Elman neural network is used for prediction. Two neural networks are used to predict the failure rate, study the structural weight of neural network, obtain the prediction result graph and prediction error graph of neural network, and analyze the results, so as to judge the availability of using neural network method to predict the failure rate.},
journal = {Neural Comput. Appl.},
month = jan,
pages = {565–576},
numpages = {12},
keywords = {Safety evaluation, Fuzzy mathematics, The information entropy, Hoisting machinery, Neural network}
}

@inproceedings{10.1145/2491411.2491418,
author = {Rahman, Foyzur and Posnett, Daryl and Herraiz, Israel and Devanbu, Premkumar},
title = {Sample size vs. bias in defect prediction},
year = {2013},
isbn = {9781450322379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2491411.2491418},
doi = {10.1145/2491411.2491418},
abstract = {Most empirical disciplines promote the reuse and sharing of datasets, as it leads to greater possibility of replication. While this is increasingly the case in Empirical Software Engineering, some of the most popular bug-fix datasets are now known to be biased. This raises two significant concerns: first, that sample bias may lead to underperforming prediction models, and second, that the external validity of the studies based on biased datasets may be suspect. This issue has raised considerable consternation in the ESE literature in recent years. However, there is a confounding factor of these datasets that has not been examined carefully: size. Biased datasets are sampling only some of the data that could be sampled, and doing so in a biased fashion; but biased samples could be smaller, or larger. Smaller data sets in general provide less reliable bases for estimating models, and thus could lead to inferior model performance. In this setting, we ask the question, what affects performance more, bias, or size? We conduct a detailed, large-scale meta-analysis, using simulated datasets sampled with bias from a high-quality dataset which is relatively free of bias. Our results suggest that size always matters just as much bias direction, and in fact much more than bias direction when considering information-retrieval measures such as AUCROC and F-score. This indicates that at least for prediction models, even when dealing with sampling bias, simply finding larger samples can sometimes be sufficient. Our analysis also exposes the complexity of the bias issue, and raises further issues to be explored in the future.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
pages = {147–157},
numpages = {11},
keywords = {size, defect prediction, bias},
location = {Saint Petersburg, Russia},
series = {ESEC/FSE 2013}
}

@inproceedings{10.1109/ICSE43902.2021.00100,
author = {Velez, Miguel and Jamshidi, Pooyan and Siegmund, Norbert and Apel, Sven and K\"{a}stner, Christian},
title = {White-Box Analysis over Machine Learning: Modeling Performance of Configurable Systems},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00100},
doi = {10.1109/ICSE43902.2021.00100},
abstract = {Performance-influence models can help stakeholders understand how and where configuration options and their interactions influence the performance of a system. With this understanding, stakeholders can debug performance behavior and make deliberate configuration decisions. Current black-box techniques to build such models combine various sampling and learning strategies, resulting in tradeoffs between measurement effort, accuracy, and interpretability. We present Comprex, a white-box approach to build performance-influence models for configurable systems, combining insights of local measurements, dynamic taint analysis to track options in the implementation, compositionality, and compression of the configuration space, without relying on machine learning to extrapolate incomplete samples. Our evaluation on 4 widely-used, open-source projects demonstrates that Comprex builds similarly accurate performance-influence models to the most accurate and expensive black-box approach, but at a reduced cost and with additional benefits from interpretable and local models.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1072–1084},
numpages = {13},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.2478/cait-2020-0046,
author = {Bontchev, Boyan and Milanova, Emanuela},
title = {On the Usability of Object-Oriented Design Patterns for a Better Software Quality},
year = {2020},
issue_date = {Nov 2020},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {20},
number = {4},
issn = {1314-4081},
url = {https://doi.org/10.2478/cait-2020-0046},
doi = {10.2478/cait-2020-0046},
abstract = {Software design patterns incarnate expert knowledge distilled from the practical experience in object-oriented design, in a compact and reusable form. The article presents a quantitative study of the usability of the object-oriented software design patterns (known as Gang of Four patterns) applied for improving the testability, maintainability, extendibility, readability, reliability, and performance efficiency of software applications. We received 82 usable responses from software professionals in Bulgaria, with 65 of them addressing both the usability and recognition of each one of the Gang of Four patterns, together with their impact on important software quality characteristics. As well, we studied the approach of each software developer in choosing a particular design pattern to use in order to solve a problem. We found statistically significant differences between the most recognized and most useful patterns and between the most unrecognized and most useless patterns, split into creational, structural, and behavioral groups.},
journal = {Cybern. Inf. Technol.},
month = nov,
pages = {36–54},
numpages = {19},
keywords = {survey, software quality, usability, Design patterns}
}

@article{10.1016/j.patrec.2016.07.019,
author = {Martnez-Rego, David and Fontenla-Romero, Oscar and Alonso-Betanzos, Amparo and Principe, Jos C.},
title = {Fault detection via recurrence time statistics and one-class classification},
year = {2016},
issue_date = {December 2016},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {84},
number = {C},
issn = {0167-8655},
url = {https://doi.org/10.1016/j.patrec.2016.07.019},
doi = {10.1016/j.patrec.2016.07.019},
abstract = {A methodology for fault detection in rotating machinery is presented.An original one-class classifier based on extreme statistics (EVOC) is employed.One advantage of the method is a reduced number of hyperparameters to be adjusted.Another advantage is the use of only normal data of the machinery being monitored.The method shows higher classification accuracy than other state-of-the-art methods. Predictive maintenance has emerged as a fundamental practice to preserve production assets in many industrial environments. Of a wide set of approaches, vibration analysis is one of the most used for high-speed rotating machinery, especially when fault detection is to be automatic. Traditionally, this task has been studied as a classification problem using data extracted from the frequency domain. This approach, however, has two main limitations: (a) manufacture and mounting procedures can vary the vibration spectra of a machine, even when these share the same design; and (b) incipient fault signatures may be concealed in the frequency domain by noise and vibration from other parts of the system. For these reasons, the application of a classifier obtained for one machine to another machine is pointless, making early fault detection difficult. In this paper, a bearing fault detection problem is tackled using one-class classifiers and features extracted from vibration capture in the time domain using recurrence time statistics. We also describe a study of the behavior of the proposed method in real conditions. Our method shows high detection accuracy accompanied by a reduced number of false positives and negatives.},
journal = {Pattern Recogn. Lett.},
month = dec,
pages = {8–14},
numpages = {7},
keywords = {Vibration analysis, Recurrence time statistics, One-class classifiers, Machinery fault detection}
}

@inproceedings{10.1007/978-3-030-11389-6_15,
author = {Ma, Bin and Wang, Xiaoyu and Li, Bing and Shi, Yun-Qing},
title = {A Multiple Linear Regression Based High-Accuracy Error Prediction Algorithm for Reversible Data Hiding},
year = {2018},
isbn = {978-3-030-11388-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-11389-6_15},
doi = {10.1007/978-3-030-11389-6_15},
abstract = {In reversible data hiding, the higher embedding capacity and lower distortion are simultaneously expected. Hence, the precise and efficient error-prediction algorithm is essential and crucial. In this paper, a high-performance error-prediction method based on Multiple Linear Regression (MLR) algorithm is proposed to improve the performance of Reversible Data Hiding (RDH). The MLR matrix function that indicates the inner correlations between the pixels and their neighbors is established adaptively according to the consistency of pixels in local area of a natural image, and thus the targeted pixel is predicted accurately with the achieved MLR function that satisfies the consistency of the neighboring pixels. Compared with conventional methods that only predict the targeted pixel with fixed predictors through simple arithmetic combination of its surroundings pixel, the proposed method can provide a sparser prediction-error image for data embedding, and thus improves the performance of RDH. Experimental results have shown that the proposed method outperform the state-of-the-art error prediction algorithms.},
booktitle = {Digital Forensics and Watermarking: 17th International Workshop, IWDW 2018, Jeju Island, Korea, October 22-24, 2018, Proceedings},
pages = {195–205},
numpages = {11},
keywords = {Reversible data hiding, Error prediction, Multiple linear regression, Embedded capacity},
location = {Jeju Island, Korea (Republic of)}
}

@inproceedings{10.5555/2820690.2820697,
author = {Cavezza, Davide G. and Pietrantuono, Roberto and Russo, Stefano},
title = {Performance of defect prediction in rapidly evolving software},
year = {2015},
publisher = {IEEE Press},
abstract = {Defect prediction techniques allow spotting modules (or commits) likely to contain (introduce) a defect by training models with product or process metrics -- thus supporting testing, code integration, and release decisions. When applied to processes where software changes rapidly, conventional techniques might fail, as trained models are not thought to evolve along with the software.In this study, we analyze the performance of defect prediction in rapidly evolving software. Framed in a high commit frequency context, we set up an approach to continuously refine prediction models by using new commit data, and predict whether or not an attempted commit is going to introduce a bug. An experiment is set up on the Eclipse JDT software to assess the prediction ability trend. Results enable to leverage defect prediction potentials in modern development paradigms with short release cycle and high code variability.},
booktitle = {Proceedings of the Third International Workshop on Release Engineering},
pages = {8–11},
numpages = {4},
location = {Florence, Italy},
series = {RELENG '15}
}

@inproceedings{10.1145/3366194.3366276,
author = {Zhou, Jun and Zhang, Wenfeng and Sun, WeiZhao},
title = {Fault Diagnosis Method of Mechanical Equipment Based on Convolutional Neural Network},
year = {2019},
isbn = {9781450372985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366194.3366276},
doi = {10.1145/3366194.3366276},
abstract = {Mechanical equipment is becoming much larger, more precise and more autonomous in current industrial society. The mechanical equipment fault detection is entering the age of 'big data' for much more monitoring points and sampling rate. Traditional diagnosis methods based on "signal processing feature extraction + machine learning classification" require a large amount of signal processing technology and diagnostic experience and can no longer meet the requirements of mechanical 'big data'. To solve this problem, an important part bearing in mechanical equipment is taken as the research object, and a diagnosis method based on convolutional neural network is proposed. This method uses the vibration signal as the monitoring signal and uses the Fourier transform to generate the vibration signal spectrum picture as the input of the whole system. Using the powerful feature extraction capability of convolutional neural network can automatically complete fault feature extraction and fault identification. The results show that the proposed method is able to not only adaptively mine available fault characteristics from the data, but also obtain higher identification accuracy than the existing methods.},
booktitle = {Proceedings of the 2019 International Conference on Robotics, Intelligent Control and Artificial Intelligence},
pages = {459–465},
numpages = {7},
keywords = {Vibration signal, Feature extraction, Fault diagnosis, Deep learning, Convolutional neural network},
location = {Shanghai, China},
series = {RICAI '19}
}

@article{10.1016/j.asoc.2021.107244,
author = {Qasem, Sultan Noman and Mohammadzadeh, Ardashir},
title = {A deep learned type-2 fuzzy neural network: Singular value decomposition approach},
year = {2021},
issue_date = {Jul 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {105},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2021.107244},
doi = {10.1016/j.asoc.2021.107244},
journal = {Appl. Soft Comput.},
month = jul,
numpages = {10},
keywords = {Mittag-Leffler stability and uncertainty bounds type-reduction, Singular value decomposition, Deep learned, Type-2 fuzzy neural network}
}

@inproceedings{10.1145/3324884.3416621,
author = {Shen, Weijun and Li, Yanhui and Chen, Lin and Han, Yuanlei and Zhou, Yuming and Xu, Baowen},
title = {Multiple-boundary clustering and prioritization to promote neural network retraining},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3416621},
doi = {10.1145/3324884.3416621},
abstract = {With the increasing application of deep learning (DL) models in many safety-critical scenarios, effective and efficient DL testing techniques are much in demand to improve the quality of DL models. One of the major challenges is the data gap between the training data to construct the models and the testing data to evaluate them. To bridge the gap, testers aim to collect an effective subset of inputs from the testing contexts, with limited labeling effort, for retraining DL models.To assist the subset selection, we propose Multiple-Boundary Clustering and Prioritization (MCP), a technique to cluster test samples into the boundary areas of multiple boundaries for DL models and specify the priority to select samples evenly from all boundary areas, to make sure enough useful samples for each boundary reconstruction. To evaluate MCP, we conduct an extensive empirical study with three popular DL models and 33 simulated testing contexts. The experiment results show that, compared with state-of-the-art baseline methods, on effectiveness, our approach MCP has a significantly better performance by evaluating the improved quality of retrained DL models; on efficiency, MCP also has the advantages in time costs.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {410–422},
numpages = {13},
keywords = {deep learning, multiple-boundary, neural network, retraining, software testing},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1109/SEAA.2015.25,
author = {Amasaki, Sousuke and Kawata, Kazuya and Yokogawa, Tomoyuki},
title = {Improving Cross-Project Defect Prediction Methods with Data Simplification},
year = {2015},
isbn = {9781467375856},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAA.2015.25},
doi = {10.1109/SEAA.2015.25},
abstract = {Context: Cross-project defect prediction (CPDP) research has been popular and many CPDP methods were proposed. While these methods used cross-project data as is for their inputs, useless or noisy information in the cross-project data can cause the degradation of predictive and computation performance. Removing such information makes the cross-project data simple and it will affect the performance of CPDP methods. Objective: To identify and quantify the effects of the data simplification for CPDP methods. Method: We conducted experiments that compared the predictive performance between CPDP with and without the data simplification. We adopted a data simplification method based on an active learning method proposed for software effort estimation. The experiments adopted 44 versions of OSS projects, four prediction models, and two CPDP methods, namely, Burak-filter and cross-project selection. Results: The data simplification achieved significant improvement in predictive performance for the cross-project selection. It did not improve Burak-filter. Conclusion: The data simplification can be helpful for the cross-project selection in terms of predictive performance and size reduction of cross-project data.},
booktitle = {Proceedings of the 2015 41st Euromicro Conference on Software Engineering and Advanced Applications},
pages = {96–103},
numpages = {8},
keywords = {data simplification, cross-project defect prediction},
series = {SEAA '15}
}

@article{10.3233/JIFS-171947,
author = {Giap, Cu Nguyen and Son, Le Hoang and Chiclana, Francisco},
title = {Dynamic structural neural network},
year = {2018},
issue_date = {2018},
publisher = {IOS Press},
address = {NLD},
volume = {34},
number = {4},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-171947},
doi = {10.3233/JIFS-171947},
abstract = {Artificial neural network (ANN) has been well applied in pattern recognition, classification and machine learning thanks to its high performance. Most ANNs are designed by a static structure whose weights are trained during a learning process by supervised or unsupervised methods. These training methods require a set of initial weights values, which are normally randomly generated, with different initial sets of weight values leading to different convergent ANNs for the same training set. Dealing with these drawbacks, a trend of dynamic ANN was invoked in the past year. However, they are either too complex or far from practical applications such as in the pathology predictor in binary multi-input multi-output (MIMO) problems, when the role of a symptom is considered as an agent, a pathology predictor’s outcome is formed by action of active agents while other agents’ activities seem to be ignored or have mirror effects. In this paper, we propose a new dynamic structural ANN for MIMO problems based on the dependency graph, which gives clear cause and result relationships between inputs and outputs. The new ANN has the dynamic structure of hidden layer as a directed graph showing the relation between input, hidden and output nodes. The properties of the new dynamic structural ANN are experienced with a pathology problem and its learning methods’ performances are compared on a real well known dataset. The result shows that both approaches for structural learning process improve the quality of ANNs during learning iteration.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {2479–2490},
numpages = {12},
keywords = {medical diagnosis, greedy algorithm, Genetic algorithm, dynamic structure, binary multi-input multi-output problems, Artificial neural network}
}

@article{10.1016/j.procs.2021.01.171,
author = {Anastasi, Sara and Madonna, Marianna and Monica, Luigi},
title = {Implications of embedded artificial intelligence - machine learning on safety of machinery},
year = {2021},
issue_date = {2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {180},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2021.01.171},
doi = {10.1016/j.procs.2021.01.171},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {338–343},
numpages = {6},
keywords = {Machinery Directive, Machine Learning, Artificial Intelligence, Safety of machinery}
}

@inproceedings{10.1145/3471985.3472377,
author = {Park, Hayeon and Diane Cuebas, Rut and We, Kyoung-Soo and Hoon Kim, Sung and Lee, Chang-Gun},
title = {Oil Leakage Detection in Automobile Shock Absorber using Machine Learning Classifiers},
year = {2021},
isbn = {9781450387484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3471985.3472377},
doi = {10.1145/3471985.3472377},
abstract = {In this paper, we describe a lightweight and accurate fault diagnosis method that detects oil leakage in automobile shock absorbers. Our approach includes a machine learning classifier as its base. These classifiers are quick and maintain a low computational load that are suitable for the automotive environment where only low-performance Electronic Control Units (ECUs) are available. However, these classifiers do not produce sufficiently accurate results when raw sensor data is used as the input. To solve this issue, we have developed an approach that firstly includes sensor data selection, where only sensors that have a strong impact on accuracy are used as input. And secondly, this reduced input dataset undergoes preprocessing using Fast Fourier Transform (FFT) to further improve accuracy. Thus, our methodology produces an oil leakage detection methodology for automobile shock absorbers that addresses the limitations of fault detection in an automotive system by being both lightweight and accurate.},
booktitle = {2021 the 5th International Conference on Robotics, Control and Automation},
pages = {71–77},
numpages = {7},
location = {Seoul, Republic of Korea},
series = {ICRCA 2021}
}

@inproceedings{10.1145/3368089.3409737,
author = {Gaaloul, Khouloud and Menghi, Claudio and Nejati, Shiva and Briand, Lionel C. and Wolfe, David},
title = {Mining assumptions for software components using machine learning},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409737},
doi = {10.1145/3368089.3409737},
abstract = {Software verification approaches aim to check a software component under analysis for all possible environments. In reality, however, components are expected to operate within a larger system and are required to satisfy their requirements only when their inputs are constrained by environment assumptions. In this paper, we propose EPIcuRus, an approach to automatically synthesize environment assumptions for a component under analysis (i.e., conditions on the component inputs under which the component is guaranteed to satisfy its requirements). EPIcuRus combines search-based testing, machine learning and model checking. The core of EPIcuRus is a decision tree algorithm that infers environment assumptions from a set of test results including test cases and their verdicts. The test cases are generated using search-based testing, and the assumptions inferred by decision trees are validated through model checking. In order to improve the efficiency and effectiveness of the assumption generation process, we propose a novel test case generation technique, namely Important Features Boundary Test (IFBT), that guides the test generation based on the feedback produced by machine learning. We evaluated EPIcuRus by assessing its effectiveness in computing assumptions on a set of study subjects that include 18 requirements of four industrial models. We show that, for each of the 18 requirements, EPIcuRus was able to compute an assumption to ensure the satisfaction of that requirement, and further, ≈78% of these assumptions were computed in one hour.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {159–171},
numpages = {13},
keywords = {Search-based software testing, Model checking, Machine learning, Environment assumptions, Decision trees},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@article{10.1007/s11045-020-00727-y,
author = {Wang, Guopeng and Qin, Wen},
title = {Distributed finite frequency fault detection observer design for spatially interconnected time-delay systems with interconnected chains},
year = {2021},
issue_date = {Jan 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {32},
number = {1},
issn = {0923-6082},
url = {https://doi.org/10.1007/s11045-020-00727-y},
doi = {10.1007/s11045-020-00727-y},
abstract = {This paper proposes an H-/H∞ fault detection observer method for a class of spatially interconnected time-delay systems (SITSs) with interconnected chains in finite frequency domain. As one of the main contribution, a delay-dependent generalized Kalman–Yakubivich–Popov (GKYP) lemma for SITSs with interconnected chains is proposed. Based on the giving GKYP lemma, sufficient conditions for the existence of the observers to guarantee the fault sensitivity and disturbance robustness in finite frequency domain are presented. Finally, an example is provided to demonstrate the effectiveness of the proposed method.},
journal = {Multidimensional Syst. Signal Process.},
month = jan,
pages = {35–48},
numpages = {14},
keywords = {Spatially interconnected systems, Time-delay, Fault detection, Finite frequency}
}

@article{10.1007/s10664-011-9180-x,
author = {Ekanayake, Jayalath and Tappolet, Jonas and Gall, Harald C. and Bernstein, Abraham},
title = {Time variance and defect prediction in software projects},
year = {2012},
issue_date = {August    2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4–5},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-011-9180-x},
doi = {10.1007/s10664-011-9180-x},
abstract = {It is crucial for a software manager to know whether or not one can rely on a bug prediction model. A wrong prediction of the number or the location of future bugs can lead to problems in the achievement of a project's goals. In this paper we first verify the existence of variability in a bug prediction model's accuracy over time both visually and statistically. Furthermore, we explore the reasons for such a high variability over time, which includes periods of stability and variability of prediction quality, and formulate a decision procedure for evaluating prediction models before applying them. To exemplify our findings we use data from four open source projects and empirically identify various project features that influence the defect prediction quality. Specifically, we observed that a change in the number of authors editing a file and the number of defects fixed by them influence the prediction quality. Finally, we introduce an approach to estimate the accuracy of prediction models that helps a project manager decide when to rely on a prediction model. Our findings suggest that one should be aware of the periods of stability and variability of prediction quality and should use approaches such as ours to assess their models' accuracy in advance.},
journal = {Empirical Softw. Engg.},
month = aug,
pages = {348–389},
numpages = {42},
keywords = {Time variance, Mining software repository, Defect prediction, Decision tree learner, Concept drift}
}

@inproceedings{10.1109/ITSC.2019.8917295,
author = {Du, Heng and Li, Zhen and Chen, Ruijun and Yin, Zhuo and Fu, Zhe and Zhang, Qiang and Xiao, Xiao and Luo, Ming and Bao, Feng},
title = {Dynamic Time Warping and Spectral Clustering Based Fault Detection and Diagnosis of Railway Point Machines},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ITSC.2019.8917295},
doi = {10.1109/ITSC.2019.8917295},
abstract = {Point machine plays a very important role in the metro operation. Among these infrastructure failures in urban rail transit systems, the vast majority of them are triggered by railway point machines. Thus, fault detection and diagnosis should be well concerned to ensure traffic safety. In this paper, we propose to employ dynamic time warping and spectral clustering to handle this problem. Firstly, the dynamic time warping method is used to compare unequal sequences with phase-shifted shape. Secondly, the spectral clustering method is applied to deal with the classification problem without training steps. At last, simulation results demonstrate well performance of the proposed scheme.},
booktitle = {2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
pages = {595–600},
numpages = {6},
location = {Auckland, New Zealand}
}

@article{10.1007/s00521-020-04874-y,
author = {Adi, Erwin and Anwar, Adnan and Baig, Zubair and Zeadally, Sherali},
title = {Machine learning and data analytics for the IoT},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {20},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-04874-y},
doi = {10.1007/s00521-020-04874-y},
abstract = {The Internet of Things (IoT) applications have grown in exorbitant numbers, generating a large amount of data required for intelligent data processing. However, the varying IoT infrastructures (i.e., cloud, edge, fog) and the limitations of the IoT application layer protocols in transmitting/receiving messages become the barriers in creating intelligent IoT applications. These barriers prevent current intelligent IoT applications to adaptively learn from other IoT applications. In this paper, we critically review how IoT-generated data are processed for machine learning analysis and highlight the current challenges in furthering intelligent solutions in the IoT environment. Furthermore, we propose a framework to enable IoT applications to adaptively learn from other IoT applications and present a case study in how the framework can be applied to the real studies in the literature. Finally, we discuss the key factors that have an impact on future intelligent applications for the IoT.},
journal = {Neural Comput. Appl.},
month = oct,
pages = {16205–16233},
numpages = {29},
keywords = {Machine learning, Intelligent systems, Internet of Things, Cybersecurity}
}

@inproceedings{10.1145/3127005.3127013,
author = {Valdivia-Garcia, Harold and Nagappan, Meiyappan},
title = {The Characteristics of False-Negatives in File-level Fault Prediction},
year = {2017},
isbn = {9781450353052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127005.3127013},
doi = {10.1145/3127005.3127013},
abstract = {Over the years, a plethora of works has proposed more and more sophisticated machine learning techniques to improve fault prediction models. However, past studies using product metrics from closed-source projects, found a ceiling effect in the performance of fault prediction models. On the other hand, other studies have shown that process metrics are significantly better than product metrics for fault prediction. In our case study therefore we build models that include both product and process metrics taken together. We find that the ceiling effect found in prior studies exists even when we consider process metrics. We then qualitatively investigate the bug reports, source code files, and commit information for the bugs in the files that are false-negative in our fault prediction models trained using product and process metrics. Surprisingly, our qualitative analysis shows that bugs related to false-negative files and true-positive files are similar in terms of root causes, impact and affected components, and consequently such similarities might be exploited to enhance fault prediction models.},
booktitle = {Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {73–82},
numpages = {10},
keywords = {Code Metrics, Post-release Defects, Process Metrics},
location = {Toronto, Canada},
series = {PROMISE}
}

@inproceedings{10.1007/978-3-030-60799-9_10,
author = {Feng, Naiqin and Qin, Lijuan and Sun, Bin},
title = {A Cognitive Model of Morphological Neural Network},
year = {2020},
isbn = {978-3-030-60798-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-60799-9_10},
doi = {10.1007/978-3-030-60799-9_10},
abstract = {In this paper, a morphological neural network (MNN) cognitive tree model related to multi disciplines is proposed. The model has four layers: soil layer, primary layer, growth layer and presentation layer. Through the study of MNN at different levels, the cognitive function and mechanism of MNN are profoundly revealed, and the theoretical framework of MNN cognition is established. This paper can be seen as an example of multi-disciplinary crossover and fusion research, which not only helps to improve the understanding of MNN itself, but also brings some inspirations to promote the interdisciplinary research and coordinated development of computer science, artificial intelligence, neurobiology, cognitive psychology and so on.},
booktitle = {Intelligent Computing Theories and Application: 16th International Conference, ICIC 2020, Bari, Italy, October 2–5, 2020, Proceedings, Part I},
pages = {115–127},
numpages = {13},
keywords = {Crossover and fusion, Multiple disciplines, Cognitive model, Morphological neural network},
location = {Bari , Italy}
}

@article{10.1504/ijsnet.2020.104927,
author = {An, Haibo and Liang, Wei and Zhang, Yinlong and Tan, Jindong},
title = {Hidden Markov model based rotate vector reducer fault detection using acoustic emissions},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {32},
number = {2},
issn = {1748-1279},
url = {https://doi.org/10.1504/ijsnet.2020.104927},
doi = {10.1504/ijsnet.2020.104927},
abstract = {This paper proposes a hidden Markov model (HMM) based RV reducer fault detection using acoustic emission (AE) measurements. Compared with the conventional faults from the common rotating machinery (such as bearings and gears), faults from RV reducer are more complicated and undetectable due to its inherent inline and two-stage meshing structure. To this end, this work modifies the HMM model by taking into account not only the current observations and previous states, but the subsequent series of observations within posteriori probability framework. Through this way, the random and unknown disturbance could be suppressed. Besides, HMM is also applied to separate AE signal bulks within one cycle that has 39 subcycles. The proposed method has been evaluated on our collected AE signal dataset from the RV reducer in the industrial robotic platform. The experimental results and analysis validate the effectiveness and accuracy of our RV reducer fault detection model.},
journal = {Int. J. Sen. Netw.},
month = jan,
pages = {116–125},
numpages = {9},
keywords = {acoustic emission, AE, hidden Markov model, HMM, fault detection, rotate vector reducer, RV}
}

@article{10.1016/j.neucom.2019.04.006,
author = {Wang, Y. and Ye, H. and Zhang, T. and Zhang, H.},
title = {A data mining method based on unsupervised learning and spatiotemporal analysis for sheath current monitoring},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {352},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.04.006},
doi = {10.1016/j.neucom.2019.04.006},
journal = {Neurocomput.},
month = aug,
pages = {54–63},
numpages = {10},
keywords = {Spatiotemporal analysis, Unsupervised learning, Data mining, Sheath current monitoring}
}

@article{10.1016/j.neucom.2018.11.078,
author = {Liu, Junxiu and Huang, Yongchuang and Luo, Yuling and Harkin, Jim and McDaid, Liam},
title = {Bio-inspired fault detection circuits based on synapse and spiking neuron models},
year = {2019},
issue_date = {Feb 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {331},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.11.078},
doi = {10.1016/j.neucom.2018.11.078},
journal = {Neurocomput.},
month = feb,
pages = {473–482},
numpages = {10},
keywords = {Spiking neuron model, Memristive synapses, Memristor, Fault detection}
}

@article{10.5555/1991856.1991869,
author = {Jiang, Yuan and Li, Ming and Zhou, Zhi-Hua},
title = {Software defect detection with rocus},
year = {2011},
issue_date = {March 2011},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {2},
issn = {1000-9000},
abstract = {Software defect detection aims to automatically identify defective software modules for efficient software test in order to improve the quality of a software system. Although many machine learning methods have been successfully applied to the task, most of them fail to consider two practical yet important issues in software defect detection. First, it is rather difficult to collect a large amount of labeled training data for learning a well-performing model; second, in a software system there are usually much fewer defective modules than defect-free modules, so learning would have to be conducted over an imbalanced data set. In this paper, we address these two practical issues simultaneously by prcposing a novel semi-supervised learning approach named ROCUS. This method exploits the abundant unlabeled examples to improve the detection accuracy, as well as employs under-sampling to tackle the class-imbalance problem in the learning process. Experimental results of real-world software defect detection tasks show that ROCUS is effective for software defect cetection. Its performance is better than a semi-supervised learning method that ignores the class-imbalance nature of the task and a class-imbalance learning method that does not make effective use of unlabeled data.},
journal = {J. Comput. Sci. Technol.},
month = mar,
pages = {328–342},
numpages = {15},
keywords = {software defect detection, semi-supervised learning, machine learning, data mining, class-imbalance}
}

@inproceedings{10.1109/ICTAI.2011.155,
author = {Lounis, Hakim and Gayed, Tamer Fares and Boukadoum, Mounir},
title = {Machine-Learning Models for Software Quality: A Compromise between Performance and Intelligibility},
year = {2011},
isbn = {9780769545967},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICTAI.2011.155},
doi = {10.1109/ICTAI.2011.155},
abstract = {Building powerful machine-learning assessment models is an important achievement of empirical software engineering research, but it is not the only one. Intelligibility of such models is also needed, especially, in a domain, software engineering, where exploration and knowledge capture is still a challenge. Several algorithms, belonging to various machine-learning approaches, are selected and run on software data collected from medium size applications. Some of these approaches produce models with very high quantitative performances, others give interpretable, intelligible, and "glass-box" models that are very complementary. We consider that the integration of both, in automated decision-making systems for assessing software product quality, is desirable to reach a compromise between performance and intelligibility.},
booktitle = {Proceedings of the 2011  IEEE 23rd International Conference on Tools with Artificial Intelligence},
pages = {919–921},
numpages = {3},
keywords = {software product quality, reusability, metrics, maintainability, machine-learning, assessment models},
series = {ICTAI '11}
}

@inproceedings{10.1145/3468264.3468615,
author = {Dutta, Saikat and Shi, August and Misailovic, Sasa},
title = {FLEX: fixing flaky tests in machine learning projects by updating assertion bounds},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468615},
doi = {10.1145/3468264.3468615},
abstract = {Many machine learning (ML) algorithms are inherently random – multiple executions using the same inputs may produce slightly different results each time. Randomness impacts how developers write tests that check for end-to-end quality of their implementations of these ML algorithms. In particular, selecting the proper thresholds for comparing obtained quality metrics with the reference results is a non-intuitive task, which may lead to flaky test executions.  We present FLEX, the first tool for automatically fixing flaky tests due to algorithmic randomness in ML algorithms. FLEX fixes tests that use approximate assertions to compare actual and expected values that represent the quality of the outputs of ML algorithms. We present a technique for systematically identifying the acceptable bound between the actual and expected output quality that also minimizes flakiness. Our technique is based on the Peak Over Threshold method from statistical Extreme Value Theory, which estimates the tail distribution of the output values observed from several runs. Based on the tail distribution, FLEX updates the bound used in the test, or selects the number of test re-runs, based on a desired confidence level.  We evaluate FLEX on a corpus of 35 tests collected from the latest versions of 21 ML projects. Overall, FLEX identifies and proposes a fix for 28 tests. We sent 19 pull requests, each fixing one test, to the developers. So far, 9 have been accepted by the developers.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {603–614},
numpages = {12},
keywords = {Machine Learning, Flaky tests, Extreme Value Theory},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.5555/1260984.1261260,
author = {Fenton, Norman and Neil, Martin and Marsh, William and Hearty, Peter and Radlinski, Lukasz and Krause, Paul},
title = {Project Data Incorporating Qualitative Factors for Improved Software Defect Prediction},
year = {2007},
isbn = {0769528309},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {To make accurate predictions of attributes like defects found in complex software projects we need a rich set of process factors. We have developed a causal model that includes such process factors, both quantitative and qualitative. The factors in the model were identified as part of a major collaborative project. A challenge for such a model is getting the data needed to validate it. We present a dataset, elicited from 31 completed software projects in the consumer electronics industry, which we used for validation. The data were gathered using a questionnaire distributed to managers of recent projects. The dataset will be of interest to other researchers evaluating models with similar aims. We make both the dataset and causal model available for research use.},
booktitle = {Proceedings of the 29th International Conference on Software Engineering Workshops},
pages = {69},
series = {ICSEW '07}
}

@article{10.1007/s10515-021-00285-y,
author = {Goyal, Somya},
title = {Predicting the Defects using Stacked Ensemble Learner with Filtered Dataset},
year = {2021},
issue_date = {Nov 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-021-00285-y},
doi = {10.1007/s10515-021-00285-y},
abstract = {Software defect prediction is a crucial software project management activity to enhance the software quality. It aids the development team to forecast about which modules need extra attention for testing; which part of software is more prone to errors and faults; before the commencement of testing phase. It helps to reduce the testing cost and hence the overall development cost of the software. Though, it ensures in-time delivery of good quality end-product, but there is one major hinderance in making this prediction. This is the class imbalance issue in the training data. Data imbalance in class distribution adversely affects the performance of classifiers. This paper proposes a K-nearest neighbour (KNN) filtering-based data pre-processing technique for stacked ensemble classifier to handle class imbalance issue. First, nearest neighbour-based filtering is applied to filter out the overlapped data-points to reduce Imbalanced Ratio, then, the processed data with static code metrics is supplied to stacked ensemble for prediction. The stacking is achieved with five base classifiers namely Artificial Neural Network, Decision Tree, Na\"{\i}ve Bayes, K-nearest neighbour (KNN) and Support Vector Machine. A comparative analysis among 30 classifiers (5 data pre-processing techniques * 6 prediction techniques) is made. In the experiments, five public datasets from NASA repository namely CM1, JM1, KC1, KC2 and PC1 are used. In total 150 prediction models (5 data pre-processing techniques * 6 classification techniques * 5 datasets) are proposed and their performances are assessed in terms of measures namely Receiver Operator Curve, Area under the Curve and accuracy. The statistical analysis shows that proposed stacked ensemble classifier with KNN filtering performs best among all the predictors independent of datasets.},
journal = {Automated Software Engg.},
month = nov,
numpages = {81},
keywords = {ROC and AUC, Support vector machine, Nearest neighbour, Decision trees, Stacked ensembles, Artificial neural networks (ANN), Class imbalance, Data pre-processing, Defect prediction, Software quality}
}

@inproceedings{10.1145/3386164.3389078,
author = {Aljarallah, Sulaiman and Lock, Russell},
title = {A Comparison of Software Quality Characteristics and Software Sustainability Characteristics},
year = {2020},
isbn = {9781450376617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386164.3389078},
doi = {10.1145/3386164.3389078},
abstract = {Software sustainability has generated much interest in the software engineering field in recent times, and has been widely investigated across different fields and from different standpoints. The relationship between software quality and software sustainability is still an open question. In this study, a literature survey and comparison was conducted using three-phases, having as a starting point the comparison of basic models for software quality. A follow-up study, conducted at a more comprehensive level to cover both basic models and the most cited tailored models., Software sustainability literature is investigated to find the most frequent characteristics. Finally, data gathered from these studies and a comparison shows a similarity in the top level of these characteristics between software sustainability and software quality, and the emphasis on sustainability, maintainability and portability. The study suggests that ISO 25010 can be utilised by software sustainability. As a future work, the findings will be investigated empirically to support designing software sustainability framework identifying the most important criteria in the technical dimension.},
booktitle = {Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control},
articleno = {26},
numpages = {11},
keywords = {Software Sustainability Characteristics, Software Sustainability, Software Quality, Quality Models, Quality Characteristics},
location = {Amsterdam, Netherlands},
series = {ISCSIC 2019}
}

@article{10.4018/IJSSCI.2016070102,
author = {Rashid, Ekbal},
title = {R4 Model for Case-Based Reasoning and Its Application for Software Fault Prediction},
year = {2016},
issue_date = {July 2016},
publisher = {IGI Global},
address = {USA},
volume = {8},
number = {3},
issn = {1942-9045},
url = {https://doi.org/10.4018/IJSSCI.2016070102},
doi = {10.4018/IJSSCI.2016070102},
abstract = {Making R4 model effective and efficient I have introduced some new features, i.e., renovation of knowledgebase KBS and reducing the maintenance cost by removing the duplicate record from the KBS. Renovation of knowledgebase is the process of removing duplicate record stored in knowledgebase and adding world new problems along with world new solutions. This paper explores case-based reasoning and its applications for software quality improvement through early prediction of error patterns. It summarizes a variety of techniques for software quality prediction in the domain of software engineering. The system predicts the error level with respect to LOC and with respect to development time, and both affects the quality level. This paper also reviews four existing models of case-based reasoning CBR. The paper presents a work in which I have expanded our previous work Rashid et al., 2012. I have used different similarity measures to find the best method that increases reliability. The present work is also credited through introduction of some new terms like coefficient of efficiency, i.e., developer's ability.},
journal = {Int. J. Softw. Sci. Comput. Intell.},
month = jul,
pages = {19–38},
numpages = {20},
keywords = {Software Fault Prediction, Similarity Function, Reliability, Machine Learning, LOC, Development Time}
}

@inproceedings{10.1007/978-3-030-30949-7_28,
author = {Farooq, Basit and Bao, Jinsong},
title = {Machine Learning Method for Spinning Cyber-Physical Production System Subject to Condition Monitoring},
year = {2019},
isbn = {978-3-030-30948-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-30949-7_28},
doi = {10.1007/978-3-030-30949-7_28},
abstract = {Digitalization encapsulates the importance of machine condition monitoring which is subjected to predictive analytics for realizing significant improvements in the performance and reliability of rotating equipment i.e., spinning. This paper presents a machine learning approach for condition monitoring, based on a regularized deep neural network using automated diagnostics for spinning manufacturing. This article contributes a solution to find disturbances in a running system through real-time data sensing and signal to process via industrial internet of things. Because this controlled sensor network may comprise on different critical components of the same type of machines, therefore back propagation neural network based multi-sensor performance assessment and prediction strategy were developed for our system which worked as intelligent maintenance and diagnostic system. It is completely automatic requiring no manual extraction of handcrafted features.},
booktitle = {Cooperative Design, Visualization, and Engineering: 16th International Conference, CDVE 2019, Mallorca, Spain, October 6–9, 2019, Proceedings},
pages = {244–253},
numpages = {10},
keywords = {Spinning, Prognostics and health management, Machine learning, Condition monitoring, Cyber-physical production system},
location = {Mallorca, Spain}
}

@inproceedings{10.1145/3386164.3389105,
author = {Stephen, Nkyi and Feng, Yan Xue and Gershon, Rodor and Bonsu, Kusi Ankrah},
title = {Integrated Round Trip Path Dual Registers (RTPDR) Fault Detection},
year = {2020},
isbn = {9781450376617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386164.3389105},
doi = {10.1145/3386164.3389105},
abstract = {The numerous application of wireless sensor networks (WSNs) in every facet of today's world demands prompt detection and classification of faults. In this paper, an integrated round trip path dual registers (RTPDR) is presented which combines Round Trip Paths (RTP) and Dual Registers (DR) for detection and classification of node failure, node reboot and link failure diagnosis. Round trip path is adopted for nodes grouping and threshold monitoring. Detection and classification of faults are done by comparison of dual registers using each path traversed by a packet from the source node. Two different registers are kept and updated respectively depending on the path traversed by a packet to detect anomalous behaviors. The results from simulation in MATLAB demonstrates the proposed technique achieves better detection latency, false alarm rate and false positive rate when compared with existing protocols.},
booktitle = {Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control},
articleno = {22},
numpages = {6},
keywords = {Wireless Sensor Networks, Integrated Round Trip Path, Fault Detection, Etc, Component},
location = {Amsterdam, Netherlands},
series = {ISCSIC 2019}
}

@inproceedings{10.1007/978-3-030-38961-1_25,
author = {Zhang, Xiahao and Zhuang, Yi},
title = {A Fault Detection Algorithm for Cloud Computing Using QPSO-Based Weighted One-Class Support Vector Machine},
year = {2019},
isbn = {978-3-030-38960-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38961-1_25},
doi = {10.1007/978-3-030-38961-1_25},
abstract = {The complexity and diversity of cloud computing bring about cloud faults, which affect the quality of services. Existing fault detection methods suffer problems such as low efficiency and low accuracy. In order to improve the reliability of the cloud data center, a fault detection algorithm based on weighted one-class support vector machine (WOCSVM) is proposed to detect and identify the host faults in the cloud data center. Specifically, first, we conduct correlation analysis among monitoring metrics and select key ones for reducing the complexity. Second, for imbalanced monitoring dataset, one-class support vector machine is used to detect and identify host faults, and a weight allocation strategy is proposed to assign weights to the samples, which describes the importance of different sample points in order to improve detection accuracy on potential faults. Finally, for the purpose of increasing the accuracy further, the parameters are set via a parameter optimization algorithm based on quantum-behaved particle swarm optimization (QPSO). Furthermore, experiments by comprising with similar algorithms, demonstrate the superiority of our algorithm under different classification indicators.},
booktitle = {Algorithms and Architectures for Parallel Processing: 19th International Conference, ICA3PP 2019, Melbourne, VIC, Australia, December 9–11, 2019, Proceedings, Part II},
pages = {286–304},
numpages = {19},
keywords = {Quantum-behaved particle swarm optimization, One-class support vector machine, Mutual information, Fault detection, Cloud computing},
location = {Melbourne, VIC, Australia}
}

@inproceedings{10.1007/978-3-030-19945-6_15,
author = {Al Mamun, S. M. Abdullah and Beyaz, Mehmet},
title = {LSTM Recurrent Neural Network (RNN) for Anomaly Detection in Cellular Mobile Networks},
year = {2018},
isbn = {978-3-030-19944-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-19945-6_15},
doi = {10.1007/978-3-030-19945-6_15},
abstract = {Anomaly detection can show significant behavior changes in the cellular mobile network. It can explain much important missing information and which can be monitored using advanced AI (Artificial Intelligent) applications/tools. In this paper, we have proposed LSTM (Long Short-Term Memory) based RNN (Recurrent Neural Network) which can model a time series profile for LTE network based on cell KPI values. We have shown in this paper that the dynamic behavior of a single cell can be simplified using a combination of a set for neighbor cells. We can predict the profile and anomalous behavior using this method. According to the best of our knowledge this approach is applied here for the first time for cell level performance profile generation and anomaly detection. In a related work, they have proposed ensemble method to compare different KPIs and cell performance using machine learning algorithm. We have applied DNN (Deep Neural Network) to generate a profile on KPI features from historical data. It gave us deeper insight into how the cell is performing over time and can connect with the root causes or hidden fault of a major failure in the cellular network.},
booktitle = {Machine Learning for Networking: First International Conference, MLN 2018, Paris, France, November 27–29, 2018, Revised Selected Papers},
pages = {222–237},
numpages = {16},
keywords = {Anomaly detection, Deep Neural Network, Cell performance degradation, Recurrent Neural Network (RNN), Cell diagnostics},
location = {Paris, France}
}

@inproceedings{10.1109/I2MTC43012.2020.9128864,
author = {Yang, Jingli and Chang, Yongqi and Yang, Cheng and Liu, Yang},
title = {A Fault Prediction Method of Quartz Flexible Accelerometers Based on AGO-RVM},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/I2MTC43012.2020.9128864},
doi = {10.1109/I2MTC43012.2020.9128864},
abstract = {A novel fault prediction method for quartz flexible accelerometers of inertial navigation systems is presented. Firstly, accumulated generating operation (AGO) is conducted on the original data sequence of the scale factor stability to enhance its regularity. Then, relevance vector machine (RVM), which has good quality in terms of prediction precision and generalization, is applied to the data sequence achieved by AGO. Moreover, the RVM model is updated continuously by a metabolism mechanism to improve the adaptivity of the prediction method. The gray relational analysis (GRA) is adopted to decide whether to update the RVM model. The performance of the proposed method is verified by the accelerated life test, and the experimental results show it can achieve high accuracy on the fault prediction of quartz flexible accelerometers.},
booktitle = {2020 IEEE International Instrumentation and Measurement Technology Conference (I2MTC)},
pages = {1–6},
numpages = {6},
location = {Dubrovnik, Croatia}
}

@article{10.1145/3428205,
author = {Wang, Yu and Wang, Ke and Gao, Fengjuan and Wang, Linzhang},
title = {Learning semantic program embeddings with graph interval neural network},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {OOPSLA},
url = {https://doi.org/10.1145/3428205},
doi = {10.1145/3428205},
abstract = {Learning distributed representations of source code has been a challenging task for machine learning models. Earlier works treated programs as text so that natural language methods can be readily applied. Unfortunately, such approaches do not capitalize on the rich structural information possessed by source code. Of late, Graph Neural Network (GNN) was proposed to learn embeddings of programs from their graph representations. Due to the homogeneous (i.e. do not take advantage of the program-specific graph characteristics) and expensive (i.e. require heavy information exchange among nodes in the graph) message-passing procedure, GNN can suffer from precision issues, especially when dealing with programs rendered into large graphs. In this paper, we present a new graph neural architecture, called Graph Interval Neural Network (GINN), to tackle the weaknesses of the existing GNN. Unlike the standard GNN, GINN generalizes from a curated graph representation obtained through an abstraction method designed to aid models to learn. In particular, GINN focuses exclusively on intervals (generally manifested in looping construct) for mining the feature representation of a program, furthermore, GINN operates on a hierarchy of intervals for scaling the learning to large graphs.  We evaluate GINN for two popular downstream applications: variable misuse prediction and method name prediction. Results show in both cases GINN outperforms the state-of-the-art models by a comfortable margin. We have also created a neural bug detector based on GINN to catch null pointer deference bugs in Java code. While learning from the same 9,000 methods extracted from 64 projects, GINN-based bug detector significantly outperforms GNN-based bug detector on 13 unseen test projects. Next, we deploy our trained GINN-based bug detector and Facebook Infer, arguably the state-of-the-art static analysis tool, to scan the codebase of 20 highly starred projects on GitHub. Through our manual inspection, we confirm 38 bugs out of 102 warnings raised by GINN-based bug detector compared to 34 bugs out of 129 warnings for Facebook Infer. We have reported 38 bugs GINN caught to developers, among which 11 have been fixed and 12 have been confirmed (fix pending). GINN has shown to be a general, powerful deep neural network for learning precise, semantic program embeddings.},
journal = {Proc. ACM Program. Lang.},
month = nov,
articleno = {137},
numpages = {27},
keywords = {Program embeddings, Null pointer dereference detection, Intervals, Graph neural networks, Control-flow graphs}
}

@inproceedings{10.1007/978-3-319-25945-1_9,
author = {Altinger, Harald and Herbold, Steffen and Grabowski, Jens and Wotawa, Franz},
title = {Novel Insights on Cross Project Fault Prediction Applied to Automotive Software},
year = {2015},
isbn = {9783319259444},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-25945-1_9},
doi = {10.1007/978-3-319-25945-1_9},
abstract = {Defect prediction is a powerful tool that greatly helps focusing quality assurance efforts during development. In the case of the availability of fault data from a particular context, there are different ways of using such fault predictions in practice. Companies like Google, Bell Labs and Cisco make use of fault prediction, whereas its use within automotive industry has not yet gained a lot of attraction, although, modern cars require a huge amount of software to operate. In this paper, we want to contribute the adoption of fault prediction techniques for automotive software projects. Hereby we rely on a publicly available data set comprising fault data from three automotive software projects. When learning a fault prediction model from the data of one particular project, we achieve a remarkably high and nearly perfect prediction performance for the same project. However, when applying a cross-project prediction we obtain rather poor results. These results are rather surprising, because of the fact that the underlying projects are as similar as two distinct projects can possibly be within a certain application context. Therefore we investigate the reasons behind this observation through correlation and factor analyses techniques. We further report the obtained findings and discuss the consequences for future applications of Cross-Project Fault Prediction CPFP in the domain of automotive software.},
booktitle = {Proceedings of the 27th IFIP WG 6.1 International Conference on Testing Software and Systems - Volume 9447},
pages = {141–157},
numpages = {17},
keywords = {Project fault prediction, Principal component analysis, Cross project fault prediction, Automotive},
location = {Sharjah and Dubai, United Arab Emirates},
series = {ICTSS 2015}
}

@inproceedings{10.1145/2020390.2020405,
author = {Lu, Huihua and Cukic, Bojan and Culp, Mark},
title = {An iterative semi-supervised approach to software fault prediction},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020405},
doi = {10.1145/2020390.2020405},
abstract = {Background: Many statistical and machine learning techniques have been implemented to build predictive fault models. Traditional methods are based on supervised learning. Software metrics for a module and corresponding fault information, available from previous projects, are used to train a fault prediction model. This approach calls for a large size of training data set and enables the development of effective fault prediction models. In practice, data collection costs, the lack of data from earlier projects or product versions may make large fault prediction training data set unattainable. Small size of the training set that may be available from the current project is known to deteriorate the performance of the fault predictive model. In semi-supervised learning approaches, software modules with known or unknown fault content can be used for training.Aims: To implement and evaluate a semi-supervised learning approach in software fault prediction.Methods: We investigate an iterative semi-supervised approach to software quality prediction in which a base supervised learner is used within a semi-supervised application.Results: We varied the size of labeled software modules from 2% to 50% of all the modules in the project. After tracking the performance of each iteration in the semi-supervised algorithm, we observe that semi-supervised learning improves fault prediction if the number of initially labeled software modules exceeds 5%.Conclusion: The semi-supervised approach outperforms the corresponding supervised learning approach when both use random forest as base classification algorithm.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {15},
numpages = {10},
keywords = {fault prediction, semi-supervised learning},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@inproceedings{10.1007/978-3-030-73280-6_15,
author = {Lorente-Leyva, Leandro L. and Alemany, M. M. E. and Peluffo-Ord\'{o}\~{n}ez, Diego H. and Araujo, Roberth A.},
title = {Demand Forecasting for Textile Products Using Statistical Analysis and Machine Learning Algorithms},
year = {2021},
isbn = {978-3-030-73279-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-73280-6_15},
doi = {10.1007/978-3-030-73280-6_15},
abstract = {The generation of an accurate forecast model to estimate the future demand for textile products that favor decision-making around an organization's key processes is very important. The minimization of the model's uncertainty allows the generation of reliable results, which prevent the textile industry's economic commitment and improve the strategies adopted around production planning and decision making. That is why this work is focused on the demand forecasting for textile products through the application of artificial neural networks, from a statistical analysis of the time series and disaggregation in different time horizons through temporal hierarchies, to develop a more accurate forecast. With the results achieved, a comparison is made with statistical methods and machine learning algorithms, providing an environment where there is an adequate development of demand forecasting, improving accuracy and performance. Where all the variables that affect the productive environment of this sector under study are considered. Finally, as a result of the analysis, multilayer perceptron achieved better performance compared to conventional and machine learning algorithms. Featuring the best behavior and accuracy in demand forecasting of the analyzed textile products.},
booktitle = {Intelligent Information and Database Systems: 13th Asian Conference, ACIIDS 2021, Phuket, Thailand, April 7–10, 2021, Proceedings},
pages = {181–194},
numpages = {14},
keywords = {Temporal hierarchies, Artificial neural networks, Machine learning algorithms, Statistical analysis, Textile products, Demand forecasting},
location = {Phuket, Thailand}
}

@inproceedings{10.1007/978-3-030-38778-5_29,
author = {Shen, Yingshan and Liu, Weiwei and Wu, Qiumei and Chen, Ruiyang and Liu, Kui},
title = {Leveraging Neural Network for Online Learning Performance Prediction and Learning Suggestion},
year = {2019},
isbn = {978-3-030-38777-8},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-38778-5_29},
doi = {10.1007/978-3-030-38778-5_29},
abstract = {Learning performance analysis is such a research field that draws much attention from researchers though it has just been emerged in recent years. On the one hand, analyzing learning behaviors can help learners to choose their learning methods and allocate their study time in a more appropriate way. On the other hand, learning analysis can provide valuable feedbacks for teachers and administrators to improve teaching efficiency and quality. This paper studies and analyzes more than 640,000 learning data from the MOOC platform edX. A tree-based model along with an information gain measure is applied to identify the usefulness of data features. A back-propagation neural network model is further adopted to train data and achieve a prediction model of learning performance. In addition, a genetic algorithm calculates learning score conditions and return feedbacks as suggestions to learners. Experiment results demonstrate the effectiveness of the utilization of the methods in the predication of online learning performance.},
booktitle = {Emerging Technologies for Education: 4th International Symposium, SETE 2019, Held in Conjunction with ICWL 2019, Magdeburg, Germany, September 23–25, 2019, Revised Selected Papers},
pages = {267–279},
numpages = {13},
keywords = {Suggestion, Learning prediction, Genetic algorithm, Neural network},
location = {Magdeburg, Germany}
}

@article{10.1007/s11633-016-0967-5,
author = {Zhang, Yu and Bingham, Chris and Garlick, Mike and Gallimore, Michael},
title = {Applied fault detection and diagnosis for industrial gas turbine systems},
year = {2017},
issue_date = {Aug 2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {14},
number = {4},
issn = {1476-8186},
url = {https://doi.org/10.1007/s11633-016-0967-5},
doi = {10.1007/s11633-016-0967-5},
abstract = {The paper presents readily implementable approaches for fault detection and diagnosis (FDD) based on measurements from multiple sensor groups, for industrial systems. Specifically, the use of hierarchical clustering (HC) and self-organizing map neural networks (SOMNNs) are shown to provide robust and user-friendly tools for application to industrial gas turbine (IGT) systems. HC fingerprints are found for normal operation, and FDD is achieved by monitoring cluster changes occurring in the resulting dendrograms. Similarly, fingerprints of operational behaviour are also obtained using SOMNN based classification maps (CMs) that are initially determined during normal operation, and FDD is performed by detecting changes in their CMs. The proposed methods are shown to be capable of FDD from a large group of sensors that measure a variety of physical quantities. A key feature of the paper is the development of techniques to accommodate transient system operation, which can often lead to false-alarms being triggered when using traditional techniques if the monitoring algorithms are not first desensitized. Case studies showing the efficacy of the techniques for detecting sensor faults, bearing tilt pad wear and early stage pre-chamber burnout, are included. The presented techniques are now being applied operationally and monitoring IGTs in various regions of the world.},
journal = {Int. J. Autom. Comput.},
month = aug,
pages = {463–473},
numpages = {11},
keywords = {self-organizing map neural network, hierarchical clustering, Fault detection and diagnosis}
}

@inproceedings{10.1145/2791405.2791484,
author = {Gupta, Niketa and Singh, Deepali and Sharma, Ashish},
title = {Identifying Effective Software Metrics for Categorical Defect Prediction Using Structural Equation Modeling},
year = {2015},
isbn = {9781450333610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2791405.2791484},
doi = {10.1145/2791405.2791484},
abstract = {Software Defect prediction is the pre-eminent area of software engineering which has witnessed huge importance over last decades. The identification of defects in the early stages of software development improve the quality of the software system and reduce the effort in maintaining the quality of software product. Many research studies have been conducted to construct the prediction model that considers the CK metrics suite and object oriented software metrics. For the prediction model development, consideration of interaction among the metrics is not a common practice. This paper presents the empirical evaluation in which several software metrics were investigated in order to identify the effective set of the metrics for each defect category which can significantly improve the defect prediction model made for each defect category. For each of the metrics, Pearson correlation coefficient with the number of defect categories were calculated and subsequently stepwise regression model is constructed to predict the reduced set metrics for each defect category. We have proposed a novel approach for modeling the defects using structural equation modeling further which validates our work. Structural models were built for each defect category using structural equation modeling which claims that results are validated.},
booktitle = {Proceedings of the Third International Symposium on Women in Computing and Informatics},
pages = {59–65},
numpages = {7},
keywords = {Structural Equation Modeling, Stepwise regression model, Software Metrics, Defect Prediction},
location = {Kochi, India},
series = {WCI '15}
}

@article{10.1504/ijbidm.2020.109298,
author = {Shanmugam, C. and Sekaran, E. Chandira},
title = {Optimal region growing and multi-kernel SVM for fault detection in electrical equipments using infrared thermography images},
year = {2020},
issue_date = {2020},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {17},
number = {3},
issn = {1743-8195},
url = {https://doi.org/10.1504/ijbidm.2020.109298},
doi = {10.1504/ijbidm.2020.109298},
abstract = {Infrared thermography (IRT) has played an essential part in observing and examining thermal defects of electrical equipment without ending, which has vital enormity for the dependability of electrical recorded. This paper dissected the electrical parts are faulted or non-faulted with the help of segmentation and classification model. The features are calculated from the input thermal images and regions of interest (ROI) is segmented by utilising optimal region growing (ORG) technique and faults are classified using multi kernel support vector machine (MKSVM). In the tests, the classification performances from different input features are assessed. For enhancing the performance of the segmentation investigation optimisation procedure that is whale optimisation (WO) is used. Before classifying, the extracted electrical components are fused by using feature level fusion (FLF) procedure to fused vector in all images. These multi kernel classification performance indices, including sensitivity, specificity and accuracy are utilised to recognise the most appropriate input feature and the best arrangement of classifiers. The performance of SVM is contrasted with a neural network. The correlation comes about demonstrating that our technique can accomplish a superior performance with accuracy at 98.21%.},
journal = {Int. J. Bus. Intell. Data Min.},
month = jan,
pages = {329–348},
numpages = {19},
keywords = {classification and fault detection, optimisation, SVM, support vector machine, feature extraction, IRT, infrared thermography}
}

@inproceedings{10.1109/PROMISE.2007.11,
author = {Fenton, Norman and Neil, Martin and Marsh, William and Hearty, Peter and Radlinski, Lukasz and Krause, Paul},
title = {Project Data Incorporating Qualitative Factors for Improved Software Defect Prediction},
year = {2007},
isbn = {0769529542},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/PROMISE.2007.11},
doi = {10.1109/PROMISE.2007.11},
abstract = {To make accurate predictions of attributes like defects found in complex software projects we need a rich set of process factors. We have developed a causal model that includes such process factors, both quantitative and qualitative. The factors in the model were identified as part of a major collaborative project. A challenge for such a model is getting the data needed to validate it. We present a dataset, elicited from 31 completed software projects in the consumer electronics industry, which we used for validation. The data were gathered using a questionnaire distributed to managers of recent projects. The dataset will be of interest to other researchers evaluating models with similar aims. We make both the dataset and causal model available for research use.},
booktitle = {Proceedings of the Third International Workshop on Predictor Models in Software Engineering},
pages = {2},
series = {PROMISE '07}
}

@article{10.1007/s10836-021-05966-w,
author = {Wang, Qi and Ouyang, Yiming and Lu, Yingchun and Liang, Huaguo and Zhu, Dakai},
title = {Neural Network-based Online Fault Diagnosis in Wireless-NoC Systems},
year = {2021},
issue_date = {Aug 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {37},
number = {4},
issn = {0923-8174},
url = {https://doi.org/10.1007/s10836-021-05966-w},
doi = {10.1007/s10836-021-05966-w},
abstract = {The recent development of wireless Network-on-Chip (WiNoC) by introducing wireless interface in traditional wired NoC has significantly increased the performance of NoC systems with higher bandwidth and low latency on-chip communication. However, the integration of more components (e.g., antenna and transceiver) on the chip also increases system complexity and makes it more susceptible to various failures. In this paper, we propose a run-time fault diagnosis mechanism based on neural network (NN) techniques, where both fully-connected (FC) and convolutional neural networks (CNN) are considered. For NoC with 2-D mesh topology that incorporates both wired and wireless interfaces, the FC and CNN neural networks for fault diagnosis and detection are presented. The NN models can be trained offline with collected traffic data from partially failed NoC with various faulty components. Then, at run-time, the NN models can be deployed on certain tiles in the NoC to detect and locate the faulty components using the run-time traffic data. Based on simulated traffic data, we have evaluated the proposed NN-based mechanism under different fault scenarios (e.g., type, location and number of faulty components). The results show that, CNN models outperform FC neural networks with higher fault diagnosis rates. CNN can successfully identify up to 81.2% faults when there is only one faulty component on the NoC with different traffic patterns. The accuracy decreases when there are more faulty components and higher traffic loads.},
journal = {J. Electron. Test.},
month = aug,
pages = {545–559},
numpages = {15},
keywords = {Artificial neural network, Fault diagnosis, Wireless network on Chip}
}

@article{10.1007/s11277-017-5224-x,
author = {Wu, Yu-Chen and Feng, Jun-Wen},
title = {Development and Application of Artificial Neural Network},
year = {2018},
issue_date = {Sep 2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {102},
number = {2},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-5224-x},
doi = {10.1007/s11277-017-5224-x},
abstract = {Artificial neural network is a very important part in the new industry of artificial intelligence. In China, there are many researches on artificial neural network and artificial intelligence are developing rapidly. Therefore, this paper reviews and summarizes artificial neural network, and hopes that readers can get a deeper understanding of artificial neural network. This paper first reviews the development history of artificial neural network and its related theory, and introduces four major characteristics of artificial neural network, such as the non-linear, non-limitative, non-qualitative and non-convex. Then it emphatically analyzes its application in information, medicine, economy, control, transportation and psychology. Finally, the future development trend of artificial neural network is prospected and summarized.},
journal = {Wirel. Pers. Commun.},
month = sep,
pages = {1645–1656},
numpages = {12},
keywords = {Future development trend, Development history, Artificial neural network, Application status analysis}
}

@article{10.1016/j.compag.2021.106382,
author = {Maldaner, Leonardo Felipe and Molin, Jos\'{e} Paulo and Canata, Tatiana Fernanda and Martello, Maur\'{\i}cio},
title = {A system for plant detection using sensor fusion approach based on machine learning model},
year = {2021},
issue_date = {Oct 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {189},
number = {C},
issn = {0168-1699},
url = {https://doi.org/10.1016/j.compag.2021.106382},
doi = {10.1016/j.compag.2021.106382},
journal = {Comput. Electron. Agric.},
month = oct,
numpages = {11},
keywords = {Data fusion, Ultrasonic sensor, Optic sensor, Machine learning, Sugarcane, Precision agriculture}
}

@article{10.1109/TSE.2012.43,
author = {Shivaji, Shivkumar and Whitehead, E. James and Akella, Ram and Kim, Sunghun},
title = {Reducing Features to Improve Code Change-Based Bug Prediction},
year = {2013},
issue_date = {April 2013},
publisher = {IEEE Press},
volume = {39},
number = {4},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2012.43},
doi = {10.1109/TSE.2012.43},
abstract = {Machine learning classifiers have recently emerged as a way to predict the introduction of bugs in changes made to source code files. The classifier is first trained on software history, and then used to predict if an impending change causes a bug. Drawbacks of existing classifier-based bug prediction techniques are insufficient performance for practical use and slow prediction times due to a large number of machine learned features. This paper investigates multiple feature selection techniques that are generally applicable to classification-based bug prediction methods. The techniques discard less important features until optimal classification performance is reached. The total number of features used for training is substantially reduced, often to less than 10 percent of the original. The performance of Naive Bayes and Support Vector Machine (SVM) classifiers when using this technique is characterized on 11 software projects. Naive Bayes using feature selection provides significant improvement in buggy F-measure (21 percent improvement) over prior change classification bug prediction results (by the second and fourth authors [28]). The SVM's improvement in buggy F-measure is 9 percent. Interestingly, an analysis of performance for varying numbers of features shows that strong performance is achieved at even 1 percent of the original number of features.},
journal = {IEEE Trans. Softw. Eng.},
month = apr,
pages = {552–569},
numpages = {18}
}

@article{10.3233/JIFS-191689,
author = {Kadian, Ratika and Kumar, Satish},
title = {Renyi’s-Tsallis fuzzy divergence measure and its applications to pattern recognition and fault detection},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {39},
number = {1},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-191689},
doi = {10.3233/JIFS-191689},
abstract = {In this communication, we have characterized the sum of two general measures associated with two distributions with discrete random variables as well as fuzzy sets. One of these measures is logarithmic, while other contains the power of variables, named as joint representation of Renyi’s-Tsallis divergence measure which implies that the proposed measure is equal to the constant time the sum of Renyi’s and Tsallis divergence measure. Besides the validation of the proposed measures, some of its major properties are also discussed for probability distributions and fuzzy sets. The performance of the proposed measure is contrasted with other existing measures in the literature. Some illustrative examples are solved in the context of pattern recognition and fault detection problem which demonstrate the practicality and adequacy of measure between fuzzy sets.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {731–752},
numpages = {22},
keywords = {26D15, 94A24, 94A15, fault detection, pattern recognition, fuzzy divergence measure, fuzzy set, convex function, Renyi’s-Tsallis divergence measure}
}

@inproceedings{10.1109/IECON.2019.8927552,
author = {Islam, Md Moinul and Sanjeevikumar, P. and Pedersen, John K. and Brice, Charles W.},
title = {Advanced Digital Signal Processing Based Transmission Line Fault Detection and Classification},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON.2019.8927552},
doi = {10.1109/IECON.2019.8927552},
abstract = {This paper proposes a new algorithm to detect and classify faults in electric power transmission line. The method is developed based on advanced digital signal processing (DSP) and time-frequency distribution (TFD) technique. Since it shows suitable properties to extract time-varying signature of non-stationary signals and high-frequency transients introduced by typical power quality (PQ) disturbances in electric power systems. The proposed method first separates fault disturbance component from the steady-state signal, and represents it in time-frequency domain. Thereby for feature extraction to single out faults from other common electric PQ disturbances such as voltage sags and oscillatory transients. Once fault is detected, TFD-based new index Instantaneous Fault Disturbance Ratio (IFDR), which provides energy information of fault disturbance compared to steady-state signal, is utilized to classify different types of faults. The analysis results show that the proposed method is able to classify faults successfully by setting up thresholds obtained via IFDR index for different types of faults. In this work, different types of fault signals are generated using PSCAD/EMTDC simulation software. Further, fault signal data are imported into MATLAB for post processing, and time-frequency analysis using Signal Processing Toolbox in MATLAB.},
booktitle = {IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society},
pages = {4991–4996},
numpages = {6},
location = {Lisbon, Portugal}
}

@article{10.3233/JIFS-189306,
author = {Shan, Xianming and Liu, Huixin and Liu, Yefeng and Li, Xiaolong},
title = {Research on fault tolerant control system based on optimized neural network algorithm},
year = {2020},
issue_date = {2020},
publisher = {IOS Press},
address = {NLD},
volume = {39},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-189306},
doi = {10.3233/JIFS-189306},
abstract = {Due to the strict personnel control measures in COVID-19 epidemic, the control system cannot be maintained and managed manually. This puts forward higher requirements for the accuracy of its fault-tolerant performance. The control system plays an increasingly important role in the rapid development of industrial production. When the sensor in the system fails, the system will become unstable. Therefore, it is necessary to accurately and quickly diagnose the faults of the system sensors and maintain the system in time. This paper takes the control system as the object to carry out the fault diagnosis and fault-tolerant control research of its sensors. A network model of wavelet neural network is proposed, and an improved genetic algorithm is used to optimize the weights and thresholds of the neural network model to avoid the deficiencies of traditional neural network algorithms. For the depth sensor of a certain system, an online fault diagnosis scheme based on RBF (Radial Basis Function) neural network and genetic algorithm optimized neural network was designed. The disturbance fault, “stuck” fault, drift fault and oscillation fault of the depth sensor are simulated. Simulation experiments show that both online fault diagnosis schemes can accurately identify sensor faults and the genetic algorithm optimized neural network is superior to RBF neural network in both recognition accuracy and training time under the influence of COVID-19.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {9073–9083},
numpages = {11},
keywords = {genetic algorithm optimization, neural network, fault-tolerant control, COVID-19, Fault diagnosis}
}

@article{10.1007/s10291-021-01181-4,
author = {Sun, Rui and Wang, Junhui and Cheng, Qi and Mao, Yi and Ochieng, Washington Yotto},
title = {A new IMU-aided multiple GNSS fault detection and exclusion algorithm for integrated navigation in urban environments},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {4},
issn = {1080-5370},
url = {https://doi.org/10.1007/s10291-021-01181-4},
doi = {10.1007/s10291-021-01181-4},
abstract = {The performance of Global Navigation Satellite Systems (GNSS) and Inertial Measurement Unit (IMU) integrated navigation systems can be severely degraded in urban environments due to the non-line-of-sight (NLOS) signals and multipath effects of GNSS measurements. A GNSS data quality control algorithm with effective Fault Detection and Exclusion (FDE) is therefore required for high accuracy integrated system-based positioning. Traditional GNSS FDE algorithms are designed for a single failure at a time. In urban, environments affected by NLOS and multipath effects; however, there is increased potential for multiple simultaneous failures. We present a new pseudo range comparison-based algorithm for the dynamic detection and exclusion of multiple failures in an effort to improve GNSS/IMU integrated positioning in urban areas. A FDE scheme with a sliding window and a detector in parallel is proposed by using IMU data and GNSS pseudo range measurements, which allows accurate detection of multiple simultaneous faults of different satellites for real-time GNSS measurement quality control. Experimental results of land vehicle GNSS/IMU integrated positioning accuracy in terms of 3D Root Mean Square Error are 5.39&nbsp;m and 12.22&nbsp;m, respectively, for two cases in mid and deep urban canyons. These correspond to improvements of 14.7% and 22.7% over the cases without fault exclusion.},
journal = {GPS Solut.},
month = oct,
numpages = {17},
keywords = {Fault detection and exclusion, Urban positioning, IMU, GNSS}
}

@inproceedings{10.1109/SEAA.2014.44,
author = {Trillo, Erminio and Tognotta, Giuseppe Galli and Scanniello, Giuseppe},
title = {Clustering for Fault Prediction with CLUFFP},
year = {2014},
isbn = {9781479957958},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/SEAA.2014.44},
doi = {10.1109/SEAA.2014.44},
abstract = {In this tool demonstration paper, we present CLUFFP (Clustering For Fault Prediction) an Eclipse plug-in to group source code classes. The clustering approach implemented in our Eclipse plug-in has been successfully applied in the context of fault prediction of object oriented software systems.},
booktitle = {Proceedings of the 2014 40th EUROMICRO Conference on Software Engineering and Advanced Applications},
pages = {406–407},
numpages = {2},
keywords = {Maintenance, Fault Prediction, Clustering},
series = {SEAA '14}
}

@article{10.3233/JIFS-202241,
author = {Liu, Jianyong and Cai, Yanhua and Zhang, Qinjian and Zhang, Haifeng and He, Hu and Gao, Xiaodong and Ding, Liantong},
title = {Thermal error analysis of tauren EDM machine tool based on FCM fuzzy clustering and RBF neural network},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {41},
number = {6},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-202241},
doi = {10.3233/JIFS-202241},
abstract = {A method that combines temperature field detection, adaptive FCM (Fuzzy c-means) clustering algorithm and RBF (Radial basis function network) neural network model is proposed. This method is used to analyze the thermal error of the spindle reference point of the tauren EDM (Electro-discharge machining) machine tool. The thermal imager is used to obtain the temperature field distribution of the machine tool while the machine tool simulates actual operating conditions. Based on this, the arrangement of temperature measurement points is determined, and the temperature data of the corresponding measurement points are got by temperature sensors. In actual engineering, too many temperature measurement points can cause problems such as too high cost, too much wiring. And normal processing can be affected. In order to establish that the thermal error prediction model of the machine tool spindle reference point can meet the actual engineering needs, the adaptive FCM clustering algorithm is used to optimize the temperature measurement points. While collecting the temperatures of the optimized temperature measurement points, the displacement sensors are used to detect the thermal deformation data in X, Y, Z directions of the spindle reference position. Based on the test data, the RBF neural network thermal errors prediction model of the machine tool spindle reference point is established. Then, the test results are used to verify the accuracy of the thermal errors analysis model. The research method in this paper provides a system solution for thermal error analysis of the tauren EDM machine tool. And this builds a foundation for real-time compensation of the machine tool’s thermal errors.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {6003–6014},
numpages = {12},
keywords = {thermal errors, RBF neural network model, adaptive fuzzy clustering algorithm, The tauren EDM machine tool}
}

@inproceedings{10.5555/2819009.2819025,
author = {Caglayan, Bora and Turhan, Burak and Bener, Ayse and Habayeb, Mayy and Miransky, Andriy and Cialini, Enzo},
title = {Merits of organizational metrics in defect prediction: an industrial replication},
year = {2015},
publisher = {IEEE Press},
abstract = {Defect prediction models presented in the literature lack generalization unless the original study can be replicated using new datasets and in different organizational settings. Practitioners can also benefit from replicating studies in their own environment by gaining insights and comparing their findings with those reported. In this work, we replicated an earlier study in order to investigate the merits of organizational metrics in building defect prediction models for large-scale enterprise software. We mined the organizational, code complexity, code churn and pre-release bug metrics of that large scale software and built defect prediction models for each metric set. In the original study, organizational metrics were found to achieve the highest performance. In our case, models based on organizational metrics performed better than models based on churn metrics but were outperformed by pre-release metric models. Further, we verified four individual organisational metrics as indicators for defects. We conclude that the performance of different metric sets in building defect prediction models depends on the project's characteristics and the targeted prediction level. Our replication of earlier research enabled assessing the validity and limitations of organisational metrics in a different context.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {89–98},
numpages = {10},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1609/aaai.v33i01.33019446,
author = {Elmishali, Amir and Stern, Roni and Kalech, Meir},
title = {DeBGUer: a tool for bug prediction and diagnosis},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33019446},
doi = {10.1609/aaai.v33i01.33019446},
abstract = {In this paper, we present the DeBGUer tool, a web-based tool for prediction and isolation of software bugs. DeBGUer is a partial implementation of the Learn, Diagnose, and Plan (LDP) paradigm, which is a recently introduced paradigm for integrating Artificial Intelligence (AI) in the software bug detection and correction process. In LDP, a diagnosis (DX) algorithm is used to suggest possible explanations – diagnoses – for an observed bug. If needed, a test planning algorithm is subsequently used to suggest further testing. Both diagnosis and test planning algorithms consider a fault prediction model, which associates each software component (e.g., class or method) with the likelihood that it contains a bug. DeBGUer implements the first two components of LDP, bug prediction (Learn) and bug diagnosis (Diagnose). It provides an easy-to-use web interface, and has been successfully tested on 12 projects.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {1161},
numpages = {6},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{10.1145/2889160.2889265,
author = {Salman, Iflaah},
title = {Cognitive biases in software quality and testing},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2889160.2889265},
doi = {10.1145/2889160.2889265},
abstract = {Humans are an integral entity for performing software quality and testing activities. The quality is compromised when human-thought process deviates from the laws of rational thinking, referred to as cognitive biases. The work carried out so far from this perspective in software quality and testing is very scarce and is limited to one cognitive bias only. This work aims to explore the phenomenon of cognitive biases in software quality and testing in more detail. Furthermore, investigating the factors that exist in an organisational context and that trigger the biases, which in turn deteriorate the quality of software, is also the focus of this work. Acquiring the knowledge of cognitive biases and the triggering factors will help in circumventing them, thus improving software quality.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {823–826},
numpages = {4},
keywords = {software testing, software quality, software psychology, human factors, cognitive bias},
location = {Austin, Texas},
series = {ICSE '16}
}

@article{10.1007/s10586-019-02917-1,
author = {Mohammed, Bashir and Awan, Irfan and Ugail, Hassan and Younas, Muhammad},
title = {Failure prediction using machine learning in a virtualised HPC system and application},
year = {2019},
issue_date = {Mar 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-019-02917-1},
doi = {10.1007/s10586-019-02917-1},
abstract = {Failure is an increasingly important issue in high performance computing and cloud systems. As large-scale systems continue to grow in scale and complexity, mitigating the impact of failure and providing accurate predictions with sufficient lead time remains a challenging research problem. Traditional existing fault-tolerance strategies such as regular check-pointing and replication are not adequate because of the emerging complexities of high performance computing systems. This necessitates the importance of having an effective as well as proactive failure management approach in place aimed at minimizing the effect of failure within the system. With the advent of machine learning techniques, the ability to learn from past information to predict future pattern of behaviours makes it possible to predict potential system failure more accurately. Thus, in this paper, we explore the predictive abilities of machine learning by applying a number of algorithms to improve the accuracy of failure prediction. We have developed a failure prediction model using time series and machine learning, and performed comparison based tests on the prediction accuracy. The primary algorithms we considered are the support vector machine (SVM), random forest (RF), k-nearest neighbors (KNN), classification and regression trees (CART) and linear discriminant analysis (LDA). Experimental results indicates that the average prediction accuracy of our model using SVM when predicting failure is 90% accurate and effective compared to other algorithms. This finding implies that our method can effectively predict all possible future system and application failures within the system.},
journal = {Cluster Computing},
month = jun,
pages = {471–485},
numpages = {15},
keywords = {Machine learning, High performance computing, Failure, Cloud computing}
}

@inproceedings{10.1109/ICSE-SEIP52600.2021.00034,
author = {Lwakatare, Lucy Ellen and R\r{a}nge, Ellinor and Crnkovic, Ivica and Bosch, Jan},
title = {On the experiences of adopting automated data validation in an industrial machine learning project},
year = {2021},
isbn = {9780738146690},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP52600.2021.00034},
doi = {10.1109/ICSE-SEIP52600.2021.00034},
abstract = {Background: Data errors are a common challenge in machine learning (ML) projects and generally cause significant performance degradation in ML-enabled software systems. To ensure early detection of erroneous data and avoid training ML models using bad data, research and industrial practice suggest incorporating a data validation process and tool in ML system development process.Aim: The study investigates the adoption of a data validation process and tool in industrial ML projects. The data validation process demands significant engineering resources for tool development and maintenance. Thus, it is important to identify the best practices for their adoption especially by development teams that are in the early phases of deploying ML-enabled software systems.Method: Action research was conducted at a large-software intensive organization in telecommunications, specifically within the analytics R&amp;D organization for an ML use case of classifying faults from returned hardware telecommunication devices.Results: Based on the evaluation results and learning from our action research, we identified three best practices, three benefits, and two barriers to adopting the data validation process and tool in ML projects. We also propose a data validation framework (DVF) for systematizing the adoption of a data validation process.Conclusions: The results show that adopting a data validation process and tool in ML projects is an effective approach of testing ML-enabled software systems. It requires having an overview of the level of data (feature, dataset, cross-dataset, data stream) at which certain data quality tests can be applied.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice},
pages = {248–257},
numpages = {10},
keywords = {software engineering, machine learning, data validation, data quality, data errors},
location = {Virtual Event, Spain},
series = {ICSE-SEIP '21}
}

@article{10.1109/TSE.2013.6,
author = {Peters, Fayola and Menzies, Tim and Gong, Liang and Zhang, Hongyu},
title = {Balancing Privacy and Utility in Cross-Company Defect Prediction},
year = {2013},
issue_date = {August 2013},
publisher = {IEEE Press},
volume = {39},
number = {8},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2013.6},
doi = {10.1109/TSE.2013.6},
abstract = {Background: Cross-company defect prediction (CCDP) is a field of study where an organization lacking enough local data can use data from other organizations for building defect predictors. To support CCDP, data must be shared. Such shared data must be privatized, but that privatization could severely damage the utility of the data. Aim: To enable effective defect prediction from shared data while preserving privacy. Method: We explore privatization algorithms that maintain class boundaries in a dataset. CLIFF is an instance pruner that deletes irrelevant examples. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. CLIFF+MORPH are tested in a CCDP study among 10 defect datasets from the PROMISE data repository. Results: We find: 1) The CLIFFed+MORPHed algorithms provide more privacy than the state-of-the-art privacy algorithms; 2) in terms of utility measured by defect prediction, we find that CLIFF+MORPH performs significantly better. Conclusions: For the OO defect data studied here, data can be privatized and shared without a significant degradation in utility. To the best of our knowledge, this is the first published result where privatization does not compromise defect prediction.},
journal = {IEEE Trans. Softw. Eng.},
month = aug,
pages = {1054–1068},
numpages = {15},
keywords = {defect prediction, classification, Testing, Statistics, Software, Sociology, Search problems, Privacy, Genetic algorithms, Arrays}
}

@article{10.1007/s10462-016-9535-1,
author = {Li, Hui and Wang, Xuesong and Ding, Shifei},
title = {Research and development of neural network ensembles: a survey},
year = {2018},
issue_date = {April     2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {49},
number = {4},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-016-9535-1},
doi = {10.1007/s10462-016-9535-1},
abstract = {A Neural Network Ensemble (NNE) combines the outputs of several individually trained neural networks in order to improve generalization performance. This article summarizes different approaches on the development and the latest studies on NNE. The introduction of the basic principles of NNE is followed by detailed descriptions of individual neural network generation method, conclusion generation method and fusion based on granular computing and NNE. In addition, for each of these methods we provide a short taxonomy in terms of their relevant characteristics, and analyze several of NNE applications, classic algorithms and contributions on various fields.},
journal = {Artif. Intell. Rev.},
month = apr,
pages = {455–479},
numpages = {25},
keywords = {Neural network ensemble (NNE), Granular computing (GrC), Artificial neural networks (ANNs)}
}

@article{10.1007/s11334-015-0258-2,
author = {Abdi, Yousef and Parsa, Saeed and Seyfari, Yousef},
title = {A hybrid one-class rule learning approach based on swarm intelligence for software fault prediction},
year = {2015},
issue_date = {December  2015},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {11},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-015-0258-2},
doi = {10.1007/s11334-015-0258-2},
abstract = {Software testing is a fundamental activity in the software development process aimed to determine the quality of software. To reduce the effort and cost of this process, defect prediction methods can be used to determine fault-prone software modules through software metrics to focus testing activities on them. Because of model interpretation and easily used by programmers and testers some recent studies presented classification rules to make prediction models. This study presents a rule-based prediction approach based on kernel k-means clustering algorithm and Distance based Multi-objective Particle Swarm Optimization (DSMOPSO). Because of discrete search space, we modified this algorithm and named it DSMOPSO-D. We prevent best global rules to dominate local rules by dividing the search space with kernel k-means algorithm and by taking different approaches for imbalanced and balanced clusters, we solved imbalanced data set problem. The presented model performance was evaluated by four publicly available data sets from the PROMISE repository and compared with other machine learning and rule learning algorithms. The obtained results demonstrate that our model presents very good performance, especially in large data sets.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {289–301},
numpages = {13},
keywords = {Multi-objective particle swarm optimization, Kernel k-means, Imbalanced data sets, Fault prediction, DSMOPSO-D, Classification rules}
}

@inproceedings{10.1145/3324884.3415295,
author = {Khanan, Chaiyakarn and Luewichana, Worawit and Pruktharathikoon, Krissakorn and Jiarpakdee, Jirayus and Tantithamthavorn, Chakkrit and Choetkiertikul, Morakot and Ragkhitwetsagul, Chaiyong and Sunetnanta, Thanwadee},
title = {JITBot: an explainable just-in-time defect prediction bot},
year = {2021},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3324884.3415295},
doi = {10.1145/3324884.3415295},
abstract = {Just-In-Time (JIT) defect prediction is a classification model that is trained using historical data to predict bug-introducing changes. However, recent studies raised concerns related to the explainability of the predictions of many software analytics applications (i.e., practitioners do not understand why commits are risky and how to improve them). In addition, the adoption of Just-In-Time defect prediction is still limited due to a lack of integration into CI/CD pipelines and modern software development platforms (e.g., GitHub). In this paper, we present an explainable Just-In-Time defect prediction framework to automatically generate feedback to developers by providing the riskiness of each commit, explaining why such commit is risky, and suggesting risk mitigation plans. The proposed framework is integrated into the GitHub CI/CD pipeline as a GitHub application to continuously monitor and analyse a stream of commits in many GitHub repositories. Finally, we discuss the usage scenarios and their implications to practitioners. The VDO demonstration is available at https://jitbot-tool.github.io/},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1336–1339},
numpages = {4},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/3395363.3397366,
author = {Dutta, Saikat and Shi, August and Choudhary, Rutvik and Zhang, Zhekun and Jain, Aryaman and Misailovic, Sasa},
title = {Detecting flaky tests in probabilistic and machine learning applications},
year = {2020},
isbn = {9781450380089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395363.3397366},
doi = {10.1145/3395363.3397366},
abstract = {Probabilistic programming systems and machine learning frameworks like Pyro, PyMC3, TensorFlow, and PyTorch provide scalable and efficient primitives for inference and training. However, such operations are non-deterministic. Hence, it is challenging for developers to write tests for applications that depend on such frameworks, often resulting in flaky tests – tests which fail non-deterministically when run on the same version of code.  In this paper, we conduct the first extensive study of flaky tests in this domain. In particular, we study the projects that depend on four frameworks: Pyro, PyMC3, TensorFlow-Probability, and PyTorch. We identify 75 bug reports/commits that deal with flaky tests, and we categorize the common causes and fixes for them. This study provides developers with useful insights on dealing with flaky tests in this domain.  Motivated by our study, we develop a technique, FLASH, to systematically detect flaky tests due to assertions passing and failing in different runs on the same code. These assertions fail due to differences in the sequence of random numbers in different runs of the same test. FLASH exposes such failures, and our evaluation on 20 projects results in 11 previously-unknown flaky tests that we reported to developers.},
booktitle = {Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {211–224},
numpages = {14},
keywords = {Randomness, Probabilistic Programming, Non-Determinism, Machine Learning, Flaky tests},
location = {Virtual Event, USA},
series = {ISSTA 2020}
}

@inproceedings{10.5555/2348229.2348269,
author = {Nyanteh, Yaw and Srivastava, Sanjeev and Edrington, Chris and Cartes, David},
title = {Real time implementation of PSO for artificial neural network fault detection},
year = {2011},
isbn = {9781617829512},
publisher = {Society for Modeling &amp; Simulation International},
address = {Vista, CA},
abstract = {In this paper, ANN weights are trained to distinguish short-circuit winding faults from loading transients in a Permanent Magnet Synchronous Machine (PMSM) using offline and online implementation of Particle Swarm Optimization PSO. The detection technique presented is based on ANN weight configuration using PSO to improve speed of convergence. Online reconfiguration of monitoring systems can enable more responsive and accurate fault detection systems.},
booktitle = {Proceedings of the 2011 Grand Challenges on Modeling and Simulation Conference},
pages = {277–284},
numpages = {8},
keywords = {real time, artificial neural network, PSO, PMSM},
location = {Hague, Netherlands},
series = {GCMS '11}
}

@article{10.1016/j.vehcom.2019.100198,
author = {Song, Hyun Min and Woo, Jiyoung and Kim, Huy Kang},
title = {In-vehicle network intrusion detection using deep convolutional neural network},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {21},
number = {C},
issn = {2214-2096},
url = {https://doi.org/10.1016/j.vehcom.2019.100198},
doi = {10.1016/j.vehcom.2019.100198},
journal = {Veh. Commun.},
month = jan,
numpages = {13},
keywords = {Convolutional neural network (CNN), Intrusion detection, Controller area network (CAN), In-vehicle network}
}

@article{10.1145/3311950,
author = {Djenouri, Djamel and Laidi, Roufaida and Djenouri, Youcef and Balasingham, Ilangko},
title = {Machine Learning for Smart Building Applications: Review and Taxonomy},
year = {2019},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3311950},
doi = {10.1145/3311950},
abstract = {The use of machine learning (ML) in smart building applications is reviewed in this article. We split existing solutions into two main classes: occupant-centric versus energy/devices-centric. The first class groups solutions that use ML for aspects related to the occupants, including (1) occupancy estimation and identification, (2) activity recognition, and (3) estimating preferences and behavior. The second class groups solutions that use ML to estimate aspects related either to energy or devices. They are divided into three categories: (1) energy profiling and demand estimation, (2) appliances profiling and fault detection, and (3) inference on sensors. Solutions in each category are presented, discussed, and compared; open perspectives and research trends are discussed as well. Compared to related state-of-the-art survey papers, the contribution herein is to provide a comprehensive and holistic review from the ML perspectives rather than architectural and technical aspects of existing building management systems. This is by considering all types of ML tools, buildings, and several categories of applications, and by structuring the taxonomy accordingly. The article ends with a summary discussion of the presented works, with focus on lessons learned, challenges, open and future directions of research in this field.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {24},
numpages = {36},
keywords = {smart cities, Smart buildings, Internet of Things}
}

@inproceedings{10.1007/978-3-030-31332-6_33,
author = {Salazar-D’antonio, Diego and Meneses-Casas, Nohora and Forero, Manuel G. and L\'{o}pez-Santos, Oswaldo},
title = {Automatic Fault Detection in a Cascaded Transformer Multilevel Inverter Using Pattern Recognition Techniques},
year = {2019},
isbn = {978-3-030-31331-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-31332-6_33},
doi = {10.1007/978-3-030-31332-6_33},
abstract = {Cascade transformer multilevel inverters (CT-MLI) are DC–AC converters used in medium and high power applications to provide standardized AC output. Despite their numerous advantages and robustness, these devices are highly susceptible to fault events because of their high amount of components. Therefore, early failure detection enables turning off the power system avoiding the propagation of the fault to the connected loads. Beyond that, converter operation can be reconfigured to tolerate the fault and activate a fail flag facilitating the subsequent corrective maintenance. The techniques proposed so far required several sensors, which is not practical. Therefore, in this study, we propose an automatic fault detection algorithm for cascade multilevel inverters based on pattern recognition, that only requires a sensor located at the output of the inverter. Naive Bayes, decision tree, nearest neighbor, and support vector machine were tested as classifiers using cross validation. The proposed method showed high detection accuracy when all the obtained descriptors were employed, being the K-NN the classifier showing superior performance. Furthermore, an evaluation was developed to determine the minimum number of descriptors required for the effective operation of the detection system, reducing the computational cost and simplifying its implementation. The method was validated by using simulation results obtained from a multilevel inverter circuit model.},
booktitle = {Pattern Recognition and Image Analysis: 9th Iberian Conference, IbPRIA 2019, Madrid, Spain, July 1–4, 2019, Proceedings, Part I},
pages = {378–385},
numpages = {8},
keywords = {Power electronics, Multilevel inverter, Switching pattern, Pattern recognition, Machine learning, Automatic fault detection},
location = {Madrid, Spain}
}

@inproceedings{10.1145/3371425.3371463,
author = {Liu, Chunyan and Qian, Xiaohong},
title = {Health assessment of EMU based on convolutional neural network},
year = {2019},
isbn = {9781450376334},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3371425.3371463},
doi = {10.1145/3371425.3371463},
abstract = {This paper proposed a novel intelligent fault diagnosis method to automatically identify different health status of EMU (Electric Multiple Units). A health assessment model was established by collecting the temperature data of gear box, axle box and traction motor, and the state of the EMU health assessment was set out. Firstly, the collected temperature data were processed by means of batch estimation theory based on mean finger; then, CNN (Convolutional Neural Network) was constructed according to fault categories. Finally, characteristic parameters were utilized as input of CNN, after fault analysis and safety assessment, the fault category was put at the end of the model. This method greatly improved the feature learning ability and enabled better diagnosis performance. The proposed health assessment model was evaluated through experiments using Tensorflow. Experimental results and comprehensive comparison analysis with respect to the traditional CNN had demonstrated the superiority of the proposed method.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence, Information Processing and Cloud Computing},
articleno = {15},
numpages = {5},
keywords = {health assessment, electric multiple units, convolutional neural network},
location = {Sanya, China},
series = {AIIPCC '19}
}

@inproceedings{10.23919/ICEMS50442.2020.9290831,
author = {Ehya, Hossein and Skreien, Tarjei Nesb\o{} and Nysveen, Arne and Nilssen, Robert},
title = {The Noise Effects on Signal Processors Used for Fault Detection Purpose},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/ICEMS50442.2020.9290831},
doi = {10.23919/ICEMS50442.2020.9290831},
abstract = {Signal Processing plays a crucial role in addressing failures in electrical machines. Experimental data are never perfect due to the intrusion of undesirable fluctuations unrelated to the investigated phenomenon, so-called noise. Noise has disturbing effects on the measurement data, and in the same way, could diminish or mask the fault patterns in feature extraction using different signal processors. In this paper, fault detection in a custom made 100 kVA synchronous generator under an inter-turn short circuit fault is studied by using measurements of the air gap magnetic field. Signal processing tools like a Fast Fourier Transform (FFT), Short Time Fourier Transform (STFT), Discrete Wavelet Transform (DWT), Continuous Wavelet Transform (CWT), and Time Series Data Mining (TSDM) are used to diagnose the faults with a central focus on noise impacts on processed data. Moreover, some useful methods are presented for hardware noise rejection.},
booktitle = {2020 23rd International Conference on Electrical Machines and Systems (ICEMS)},
pages = {183–188},
numpages = {6},
location = {Hamamatsu}
}

@inproceedings{10.1109/ICST.2013.38,
author = {Canfora, Gerardo and De Lucia, Andrea and Di Penta, Massimiliano and Oliveto, Rocco and Panichella, Annibale and Panichella, Sebastiano},
title = {Multi-objective Cross-Project Defect Prediction},
year = {2013},
isbn = {9780769549682},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICST.2013.38},
doi = {10.1109/ICST.2013.38},
abstract = {Cross-project defect prediction is very appealing because (i) it allows predicting defects in projects for which the availability of data is limited, and (ii) it allows producing generalizable prediction models. However, existing research suggests that cross-project prediction is particularly challenging and, due to heterogeneity of projects, prediction accuracy is not always very good. This paper proposes a novel, multi-objective approach for cross-project defect prediction, based on a multi-objective logistic regression model built using a genetic algorithm. Instead of providing the software engineer with a single predictive model, the multi-objective approach allows software engineers to choose predictors achieving a compromise between number of likely defect-prone artifacts (effectiveness) and LOC to be analyzed/tested (which can be considered as a proxy of the cost of code inspection). Results of an empirical evaluation on 10 datasets from the Promise repository indicate the superiority and the usefulness of the multi-objective approach with respect to single-objective predictors. Also, the proposed approach outperforms an alternative approach for cross-project prediction, based on local prediction upon clusters of similar classes.},
booktitle = {Proceedings of the 2013 IEEE Sixth International Conference on Software Testing, Verification and Validation},
pages = {252–261},
numpages = {10},
keywords = {search-based software engineering, multi-objective optimization, Cross-project defect prediction},
series = {ICST '13}
}

@article{10.1007/s10515-011-0090-3,
author = {He, Zhimin and Shu, Fengdi and Yang, Ye and Li, Mingshu and Wang, Qing},
title = {An investigation on the feasibility of cross-project defect prediction},
year = {2012},
issue_date = {June      2012},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {19},
number = {2},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-011-0090-3},
doi = {10.1007/s10515-011-0090-3},
abstract = {Software defect prediction helps to optimize testing resources allocation by identifying defect-prone modules prior to testing. Most existing models build their prediction capability based on a set of historical data, presumably from the same or similar project settings as those under prediction. However, such historical data is not always available in practice. One potential way of predicting defects in projects without historical data is to learn predictors from data of other projects. This paper investigates defect predictions in the cross-project context focusing on the selection of training data. We conduct three large-scale experiments on 34 data sets obtained from 10 open source projects. Major conclusions from our experiments include: (1) in the best cases, training data from other projects can provide better prediction results than training data from the same project; (2) the prediction results obtained using training data from other projects meet our criteria for acceptance on the average level, defects in 18 out of 34 cases were predicted at a Recall greater than 70% and a Precision greater than 50%; (3) results of cross-project defect predictions are related with the distributional characteristics of data sets which are valuable for training data selection. We further propose an approach to automatically select suitable training data for projects without historical data. Prediction results provided by the training data selected by using our approach are comparable with those provided by training data from the same project.},
journal = {Automated Software Engg.},
month = jun,
pages = {167–199},
numpages = {33},
keywords = {Training data, Machine learning, Defect prediction, Data characteristics, Cross-project}
}

@article{10.1145/3398020,
author = {Qian, Bin and Su, Jie and Wen, Zhenyu and Jha, Devki Nandan and Li, Yinhao and Guan, Yu and Puthal, Deepak and James, Philip and Yang, Renyu and Zomaya, Albert Y. and Rana, Omer and Wang, Lizhe and Koutny, Maciej and Ranjan, Rajiv},
title = {Orchestrating the Development Lifecycle of Machine Learning-based IoT Applications: A Taxonomy and Survey},
year = {2020},
issue_date = {July 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3398020},
doi = {10.1145/3398020},
abstract = {Machine Learning (ML) and Internet of Things (IoT) are complementary advances: ML techniques unlock the potential of IoT with intelligence, and IoT applications increasingly feed data collected by sensors into ML models, thereby employing results to improve their business processes and services. Hence, orchestrating ML pipelines that encompass model training and implication involved in the holistic development lifecycle of an IoT application often leads to complex system integration. This article provides a comprehensive and systematic survey of the development lifecycle of ML-based IoT applications. We outline the core roadmap and taxonomy and subsequently assess and compare existing standard techniques used at individual stages.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {82},
numpages = {47},
keywords = {orchestration, machine learning, deep learning, IoT}
}

@article{10.1016/j.ins.2019.11.010,
author = {Li, Shih-Yu and Gu, Kai-Ren},
title = {A smart fault-detection approach with feature production and extraction processes},
year = {2020},
issue_date = {Mar 2020},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {513},
number = {C},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2019.11.010},
doi = {10.1016/j.ins.2019.11.010},
journal = {Inf. Sci.},
month = mar,
pages = {553–564},
numpages = {12},
keywords = {Smart machine, Chaotic mapping strategy, Feature production}
}

@article{10.1007/s11219-017-9383-5,
author = {Mariani, Leonardo and Hao, Dan and Subramanyan, Rajesh and Zhu, Hong},
title = {The central role of test automation in software quality assurance},
year = {2017},
issue_date = {September 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-017-9383-5},
doi = {10.1007/s11219-017-9383-5},
journal = {Software Quality Journal},
month = sep,
pages = {797–802},
numpages = {6}
}

@inproceedings{10.1145/3388818.3388823,
author = {Zhang, Yuchong and Fjeld, Morten},
title = {Condition Monitoring for Confined Industrial Process Based on Infrared Images by Using Deep Neural Network and Variants},
year = {2020},
isbn = {9781450376952},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3388818.3388823},
doi = {10.1145/3388818.3388823},
abstract = {Some industrial processes take place in confined settings only observable by sensors, e.g. infrared (IR) cameras. Drying processes take place while a material is transported by means of a conveyor through a "black box" equipped with internal IR cameras. While such sensors deliver data at high rates, this is beyond what human operators can analyze and calls for automation. Inspired by numerous implementations monitoring techniques that analyse IR images using deep learning, this paper shows how they can be applied to the confined microwave drying of porous foams, with benchmarking their effectiveness at condition monitoring to conduct fault detection. Convolutional neural networks, derived transfer learning, and deep residual neural network methods are already regarded as cutting-edge and are studied here, using a set of conventional approaches for comparative evaluation. Our comparison shows that state-of-the-art deep learning techniques significantly benefit condition monitoring, providing an increase in fault finding accuracy of up to 48% over conventional methods. Nevertheless, we also found that derived transfer learning and deep residual network techniques do not in our case yield increased performance over normal convolutional neural networks.},
booktitle = {Proceedings of the 2020 2nd International Conference on Image, Video and Signal Processing},
pages = {99–106},
numpages = {8},
keywords = {neural networks, fault detection, deep learning, confined industrial process, Condition monitoring},
location = {Singapore, Singapore},
series = {IVSP '20}
}

@article{10.5555/ios.INF1241,
author = {Jove, Esteban and Casteleiro-Roca, Jos\'{e}-Luis and Quinti\'{a}n, H\'{e}ctor and M\'{e}ndez-P\'{e}rez, Juan-Albino and Calvo-Rolle, Jos\'{e} Luis},
title = {Virtual Sensor for Fault Detection, Isolation and Data Recovery for Bicomponent Mixing Machine Monitoring},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {30},
number = {4},
issn = {0868-4952},
abstract = {The present research shows the implementation of a virtual sensor for fault detection with the feature of recovering data. The proposal was implemented over a bicomponent mixing machine used for the wind generator blades manufacture based on carbon fiber. The virtual sensor is necessary due to permanent problems with wrong sensor measurements. The solution proposed uses an intelligent model able to predict the sensor measurements, which are compared with the measured value. If this value belongs to a specified range, it is valid. Otherwise, the prediction replaces the read value. The process fault detection feature has been added to the proposal, based on consecutive erroneous readings, obtaining satisfactory results.},
journal = {Informatica},
month = jan,
pages = {671–687},
numpages = {17},
keywords = {FDR, FDD, recovery, fault detection, virtual sensor}
}

@inproceedings{10.1145/3322640.3326706,
author = {Lauritsen, Marc and Steenhuis, Quinten},
title = {Substantive Legal Software Quality: A Gathering Storm?},
year = {2019},
isbn = {9781450367547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3322640.3326706},
doi = {10.1145/3322640.3326706},
abstract = {Readily available interactive programs dispense substantive legal guidance, often including bespoke documents. These are found across a wide spectrum of commercial and non-commercial contexts. Consumers are coming to rely on them as alternatives to expensive lawyer services. Yet their quality is uneven and difficult to assess. We are in danger of serious harm being done to unwitting users. How can we avoid an epidemic of artificial misinformation, systematic inaccuracy, and mechanical malpractice? This paper reviews how those dangers play out in real-world application contexts and explores ways in which the AI &amp; Law community might help address them.},
booktitle = {Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law},
pages = {52–62},
numpages = {11},
location = {Montreal, QC, Canada},
series = {ICAIL '19}
}

@article{10.1016/j.neucom.2019.07.037,
author = {Zhang, Jingting and Yuan, Chengzhi and Stegagno, Paolo and Zeng, Wei and Wang, Cong},
title = {Small fault detection from discrete-time closed-loop control using fault dynamics residuals},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {365},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.07.037},
doi = {10.1016/j.neucom.2019.07.037},
journal = {Neurocomput.},
month = nov,
pages = {239–248},
numpages = {10},
keywords = {Neural networks, Deterministic learning, Fault dynamics residuals, Small fault detection}
}

@inproceedings{10.1145/3469951.3469966,
author = {Ye, Zhou},
title = {Integration of Machine Learning with MEC for Intelligent Applications},
year = {2021},
isbn = {9781450390040},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469951.3469966},
doi = {10.1145/3469951.3469966},
booktitle = {Proceedings of the 2021 3rd International Conference on Image Processing and Machine Vision},
pages = {82–87},
numpages = {6},
keywords = {Mobile Computing, Machine learning, Intelligent Applications, Edge Computing, Best Offloading Decision},
location = {Hong Kong, China},
series = {IPMV '21}
}

@article{10.1007/s10845-014-0950-3,
author = {Seera, Manjeevan and Lim, Chee Peng and Loo, Chu Kiong},
title = {Motor fault detection and diagnosis using a hybrid FMM-CART model with online learning},
year = {2016},
issue_date = {December  2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {27},
number = {6},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-014-0950-3},
doi = {10.1007/s10845-014-0950-3},
abstract = {In this paper, a hybrid online learning model that combines the fuzzy min---max (FMM) neural network and the Classification and Regression Tree (CART) for motor fault detection and diagnosis tasks is described. The hybrid model, known as FMM-CART, incorporates the advantages of both FMM and CART for undertaking data classification (with FMM) and rule extraction (with CART) problems. In particular, the CART model is enhanced with an importance predictor-based feature selection measure. To evaluate the effectiveness of the proposed online FMM-CART model, a series of experiments using publicly available data sets containing motor bearing faults is first conducted. The results (primarily prediction accuracy and model complexity) are analyzed and compared with those reported in the literature. Then, an experimental study on detecting imbalanced voltage supply of an induction motor using a laboratory-scale test rig is performed. In addition to producing accurate results, a set of rules in the form of a decision tree is extracted from FMM-CART to provide explanations for its predictions. The results positively demonstrate the usefulness of FMM-CART with online learning capabilities in tackling real-world motor fault detection and diagnosis tasks.},
journal = {J. Intell. Manuf.},
month = dec,
pages = {1273–1285},
numpages = {13},
keywords = {Induction motor, Fuzzy min---max neural network, Fault detection and diagnosis, Classification and regression tree}
}

@article{10.1007/s11277-017-4361-6,
author = {Yue, Yinggao and Li, Jianqing and Fan, Hehong and Qin, Qin and Gu, Le and Du, Li},
title = {Fault Prediction Based on the Kernel Function for Ribbon Wireless Sensor Networks},
year = {2017},
issue_date = {Dec 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {97},
number = {3},
issn = {0929-6212},
url = {https://doi.org/10.1007/s11277-017-4361-6},
doi = {10.1007/s11277-017-4361-6},
abstract = {There exist several applications of wireless sensor networks in which the reliable operation can be crucial. Fault prediction is a critical problem in reliability theory for ribbon wireless sensor networks (RWSNs). Accurate fault prediction can effectively improve the availability of the WSNs system. In this paper, we evaluated the network performance for RWSNs, studied the basic theory of kernel functions, proposed a new failure prediction method based on kernel function, and selected the radial basis function as kernel function failure prediction models from two aspects of node hardware failures and network failures for fault prediction. Theoretical evidence and experimental results have shown that the proposed algorithmic prediction method has higher accuracy of 12 and 15% than that of GRNN and PNN respectively. Finally, we provided extensive numerical results to demonstrate the usage and efficiency of the proposed algorithms and complement our theoretical analysis.},
journal = {Wirel. Pers. Commun.},
month = dec,
pages = {3277–3292},
numpages = {16},
keywords = {Ribbon wireless sensor networks, Reliability, Kernel function, Fault prediction}
}

@article{10.1007/s00521-019-04617-8,
author = {Hadjicharalambous, Myrianthi and Polycarpou, Marios M. and Panayiotou, Christos G.},
title = {Neural network-based construction of online prediction intervals},
year = {2020},
issue_date = {Jun 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {11},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-019-04617-8},
doi = {10.1007/s00521-019-04617-8},
abstract = {With the emergence of online learning systems which generate ever-growing amounts of data, quantifying the uncertainty in predictions regarding the system’s operation is becoming increasingly more important. Prediction intervals offer a powerful tool for assessing prediction uncertainty in artificial neural network applications; nevertheless, little work has been conducted on constructing prediction intervals for online learning applications. In this work, we propose a hybrid approach which employs artificial neural networks to directly estimate prediction intervals for both batch and online approximation scenarios. The aim of the approach is to provide high-quality prediction intervals, combining high coverage probability for future observations with small and thus informative interval widths. Compared with three popular methods for offline construction of prediction intervals, the proposed approach demonstrates a strong capacity for reliably representing prediction uncertainty in real-world regression applications. The approach is extended to adaptive approximation, whereby four online learning schemes are proposed to iteratively update prediction intervals based on recent measurements, requiring a reduced computational cost compared to offline approximation. The four online prediction intervals methods are compared over two synthetic and one real-world regression datasets, whereby data arrive in a sequential manner. Our results suggest the potential of an online learning scheme relying on a human-like memory mechanism, to construct high-quality online prediction intervals, capable of adapting to dynamic changes in data patterns. The proposed method is associated with low computational cost—an attractive feature for online learning applications requiring real-time performance.},
journal = {Neural Comput. Appl.},
month = jun,
pages = {6715–6733},
numpages = {19},
keywords = {Adaptive approximation, Error bounds, Online learning, Prediction intervals}
}

@article{10.1007/s00500-016-2284-x,
author = {Rathore, Santosh S. and Kumar, Sandeep},
title = {An empirical study of some software fault prediction techniques for the number of faults prediction},
year = {2017},
issue_date = {December  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {24},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-016-2284-x},
doi = {10.1007/s00500-016-2284-x},
abstract = {During the software development process, prediction of the number of faults in software modules can be more helpful instead of predicting the modules being faulty or non-faulty. Such an approach may help in more focused software testing process and may enhance the reliability of the software system. Most of the earlier works on software fault prediction have used classification techniques for classifying software modules into faulty or non-faulty categories. The techniques such as Poisson regression, negative binomial regression, genetic programming, decision tree regression, and multilayer perceptron can be used for the prediction of the number of faults. In this paper, we present an experimental study to evaluate and compare the capability of six fault prediction techniques such as genetic programming, multilayer perceptron, linear regression, decision tree regression, zero-inflated Poisson regression, and negative binomial regression for the prediction of number of faults. The experimental investigation is carried out for eighteen software project datasets collected from the PROMISE data repository. The results of the investigation are evaluated using average absolute error, average relative error, measure of completeness, and prediction at level l measures. We also perform Kruskal---Wallis test and Dunn's multiple comparison test to compare the relative performance of the considered fault prediction techniques.},
journal = {Soft Comput.},
month = dec,
pages = {7417–7434},
numpages = {18},
keywords = {Zero-inflated Poisson regression, Software fault prediction, Multilayer perceptron, Kruskal---Wallis test, Genetic programming, Dunn's multiple comparison test}
}

@inproceedings{10.1145/3297280.3297411,
author = {Leotta, Maurizio and Olianas, Dario and Ricca, Filippo and Noceti, Nicoletta},
title = {How do implementation bugs affect the results of machine learning algorithms?},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297411},
doi = {10.1145/3297280.3297411},
abstract = {Applications based on Machine learning (ML) are growing in popularity in a multitude of different contexts such as medicine, bioinformatics, and finance. However, there is a lack of established approaches and strategies able to assure the reliability of this category of software. This has a big impact since nowadays our society relies on (potentially) unreliable applications that could cause, in extreme cases, catastrophic events (e.g., loss of life due to a wrong diagnosis of an ML-based cancer classifier).In this paper, as a preliminary step towards providing a solution to this big problem, we used automatic mutations to mimic realistic bugs in the code of two machine learning algorithms, Multilayer Perceptron and Logistic Regression, with the goal of studying the impact of implementation bugs on their behaviours.Unexpectedly, our experiments show that about 2/3 of the injected bugs are silent since they does not influence the results of the algorithms, while the bugs emerge as runtime errors, exceptions, or modified accuracy of the predictions only in the remaining cases. Moreover, we also discovered that about 1% of the bugs are extremely dangerous since they drastically affect the quality of the prediction only in rare cases and with specific datasets increasing the possibility of going unnoticed.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1304–1313},
numpages = {10},
keywords = {Oracle problem, accuracy, bug, machine learning, software quality assurance, testing},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@article{10.1016/j.csi.2017.02.003,
title = {An empirical analysis of the effectiveness of software metrics and fault prediction model for identifying faulty classes},
year = {2017},
issue_date = {August 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {53},
number = {C},
issn = {0920-5489},
url = {https://doi.org/10.1016/j.csi.2017.02.003},
doi = {10.1016/j.csi.2017.02.003},
abstract = {Software fault prediction models are used to predict faulty modules at the very early stage of software development life cycle. Predicting fault proneness using source code metrics is an area that has attracted several researchers' attention. The performance of a model to assess fault proneness depends on the source code metrics which are considered as the input for the model. In this work, we have proposed a framework to validate the source code metrics and identify a suitable set of source code metrics with the aim to reduce irrelevant features and improve the performance of the fault prediction model. Initially, we applied a t-test analysis and univariate logistic regression analysis to each source code metric to evaluate their potential for predicting fault proneness. Next, we performed a correlation analysis and multivariate linear regression stepwise forward selection to find the right set of source code metrics for fault prediction. The obtained set of source code metrics are considered as the input to develop a fault prediction model using a neural network with five different training algorithms and three different ensemble methods. The effectiveness of the developed fault prediction models are evaluated using a proposed cost evaluation framework. We performed experiments on fifty six Open Source Java projects. The experimental results reveal that the model developed by considering the selected set of source code metrics using the suggested source code metrics validation framework as the input achieves better results compared to all other metrics. The experimental results also demonstrate that the fault prediction model is best suitable for projects with faulty classes less than the threshold value depending on fault identification efficiency (low 48.89%, median- 39.26%, and high 27.86%). HighlightsFault prediction improve the effectiveness of software quality assurance activities.This paper focus on building an effective fault prediction tool.Fault prediction model using ANN and ensemble methods.We perform experiments on 56 Open Source Java projects.Fault prediction model is best suitable for projects with faulty classes less than the threshold value.},
journal = {Comput. Stand. Interfaces},
month = aug,
pages = {1–32},
numpages = {32}
}

@inproceedings{10.1109/ICICIC.2007.308,
author = {Li, Bin and Zhang, Wei-guo and Ning, Dong-fang and Yin, Wei},
title = {Fault Prediction System Based on Neural Network Model},
year = {2007},
isbn = {0769528821},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICICIC.2007.308},
doi = {10.1109/ICICIC.2007.308},
abstract = {In the fault diagnosis of the plane steering surface, exact fault prediction is very important for the security of the aircraft. According to design requirement of the plane steering surface fault prediction system, the application of neural network technique is plane fault prediction is presented, and the algorithm based on the neural network model in the prediction system is given. Considering the advantage of neural network technique, the neural network and the fault prediction technique with expert are combined to form a fault prediction system. Finally, taking the steering surface of plane as an example to realize fault prediction, the result proves that the forecast model and algorithm based on the neural network are feasible.},
booktitle = {Proceedings of the Second International Conference on Innovative Computing, Informatio and Control},
pages = {496},
series = {ICICIC '07}
}

@article{10.1504/IJKEDM.2013.059319,
author = {Chaturvedi, K. K. and Singh, V. B.},
title = {Bug prediction using entropy-based measures},
year = {2013},
issue_date = {February 2013},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {2},
number = {4},
issn = {1755-2087},
url = {https://doi.org/10.1504/IJKEDM.2013.059319},
doi = {10.1504/IJKEDM.2013.059319},
abstract = {In the available literature, researchers have proposed and implemented a plethora of bug prediction approaches, which vary in terms of accuracy, complexity and the input data they require, but very few of them has predicted the number of bugs in the software based on the entropy or the complexity of code changes. To use the entropy of code change as a bug predictor, firstly, the history of complexity metric HCM defined with different decay weight and decay models were assigned to it Hassan, 2009. But, they did not propose any method to find out the value of decay rate/factor. In this paper, we proposed a new weight to HCM, a method to find out the value of decay rate/factor and proposed some novel decay-based methods. We have applied simple linear regression SLR and support vector regression SVR to predict the bugs based on existing and proposed methods of HCM. We have also studied the performance of different complexity of code changes entropy-based bug prediction approaches on the basis of various performance measures using four subsystems of Mozilla project. We found that decay models for SVR show better results in comparison with SLR.},
journal = {Int. J. Knowl. Eng. Data Min.},
month = feb,
pages = {266–291},
numpages = {26}
}

@article{10.1177/1094342019852127,
author = {Dongarra, Jack and Tourancheau, Bernard and Deelman, Ewa and Mandal, Anirban and Jiang, Ming and Sakellariou, Rizos},
title = {The role of machine learning in scientific workflows},
year = {2019},
issue_date = {Nov 2019},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {33},
number = {6},
issn = {1094-3420},
url = {https://doi.org/10.1177/1094342019852127},
doi = {10.1177/1094342019852127},
abstract = {Machine learning (ML) is being applied in a number of everyday contexts from image recognition, to natural language processing, to autonomous vehicles, to product recommendation. In the science realm, ML is being used for medical diagnosis, new materials development, smart agriculture, DNA classification, and many others. In this article, we describe the opportunities of using ML in the area of scientific workflow management. Scientific workflows are key to today’s computational science, enabling the definition and execution of complex applications in heterogeneous and often distributed environments. We describe the challenges of composing and executing scientific workflows and identify opportunities for applying ML techniques to meet these challenges by enhancing the current workflow management system capabilities. We foresee that as the ML field progresses, the automation provided by workflow management systems will greatly increase and result in significant improvements in scientific productivity.},
journal = {Int. J. High Perform. Comput. Appl.},
month = nov,
pages = {1128–1139},
numpages = {12},
keywords = {workflow composition, anomaly detection, workflow systems, machine learning, Scientific workflows}
}

@inproceedings{10.1007/978-3-030-62365-4_45,
author = {Jove, Esteban and Casteleiro-Roca, Jos\'{e}-Luis and Quinti\'{a}n, H\'{e}ctor and Zayas-Gato, Francisco and Calvo-Rolle, Jos\'{e} Luis},
title = {A Fault Detection System for Power Cells During Capacity Confirmation Test Through a Global One-Class Classifier},
year = {2020},
isbn = {978-3-030-62364-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-62365-4_45},
doi = {10.1007/978-3-030-62365-4_45},
abstract = {Power cells have presented an increasing popularity during last decades due to its importance in electric mobility, electronic devices and energy management systems. The international expansion of green policies to promote electric cars and renewable energies, has resulted in the need of ensuring their quality and reliability performance. In this context, detecting any early deviation from the correct operation must be addressed. Hence, this work is focused on the fault detection in a Lithium Iron Phosphate – LiFePO4 (LFP) cell. This is achieved by means of different one-class techniques, whose performance is assessed through artificially generated anomalies. After analysing the behaviour of each tested technique, the chosen classifier presents a successful performance.},
booktitle = {Intelligent Data Engineering and Automated Learning – IDEAL 2020: 21st International Conference, Guimaraes, Portugal, November 4–6, 2020, Proceedings, Part II},
pages = {477–484},
numpages = {8},
keywords = {Power cell, Fault detection, Anomaly detection, One-class},
location = {Guimaraes, Portugal}
}

@article{10.1016/j.neucom.2019.01.025,
author = {Xu, Chen and Zhao, Shunyi and Liu, Fei},
title = {Sensor fault detection and diagnosis in the presence of outliers},
year = {2019},
issue_date = {Jul 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {349},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.01.025},
doi = {10.1016/j.neucom.2019.01.025},
journal = {Neurocomput.},
month = jul,
pages = {156–163},
numpages = {8},
keywords = {Variational Bayesian inference, Unknown noise statistics, t-distribution, Sensor fault detection and diagnosis}
}

@article{10.1007/s10009-020-00577-w,
author = {Usman, Muhammad and Wang, Wenxi and Wang, Kaiyuan and Yelen, Cagdas and Dini, Nima and Khurshid, Sarfraz},
title = {A study of learning likely data structure properties using machine learning models},
year = {2020},
issue_date = {Oct 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {22},
number = {5},
issn = {1433-2779},
url = {https://doi.org/10.1007/s10009-020-00577-w},
doi = {10.1007/s10009-020-00577-w},
abstract = {Data structure properties are important for many testing and analysis tasks. For example, model checkers use these properties to find program faults. These properties are often written manually which can be error prone and lead to false alarms. This paper presents the results of controlled experiments performed using existing machine learning (ML) models on various data structures. These data structures are dynamic and reside on the program heap. We use ten data structure subjects and ten ML models to evaluate the learnability of data structure properties. The study reveals five key findings. One, most of the ML models perform well in learning data structure properties, but some of the ML models such as quadratic discriminant analysis and Gaussian naive Bayes are not suitable for learning data structure properties. Two, most of the ML models have high performance even when trained on just 1% of data samples. Three, certain data structure properties such as binary heap and red black tree are more learnable than others. Four, there are no significant differences between the learnability of varied-size (i.e., up to a certain size) and fixed-size data structures. Five, there can be significant differences in performance based on the encoding used. These findings show that using machine learning models to learn data structure properties is very promising. We believe that these properties, once learned, can be used to provide a run-time check to see whether a program state at a particular point satisfies the learned property. Learned properties can also be employed in the future to automate static and dynamic analysis, which would enhance software testing and verification techniques.},
journal = {Int. J. Softw. Tools Technol. Transf.},
month = oct,
pages = {601–615},
numpages = {15},
keywords = {Learnability, Korat, Machine learning, Data structure invariants}
}

@article{10.1007/s00521-016-2437-y,
author = {Chatterjee, S. and Nigam, S. and Roy, A.},
title = {Software fault prediction using neuro-fuzzy network and evolutionary learning approach},
year = {2017},
issue_date = {January   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {28},
number = {1},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-016-2437-y},
doi = {10.1007/s00521-016-2437-y},
abstract = {In the real world, a great deal of information is provided by human experts that normally do not conform to the rules of physics, but describe the complicated systems by a set of incomplete or vague statements. The need of conducting uncertainty analysis in software reliability for the large and complex system is demanding. For large complex systems made up of many components, the uncertainty of each individual parameter amplifies the uncertainty of the total system reliability. In this paper, to overcome with the problem of uncertainty in software development process and environment, a neuro-fuzzy modeling has been proposed for software fault prediction. The training of the proposed neuro-fuzzy model has been done with genetic algorithm and back-propagation learning algorithm. The proposed model has been validated using some real software failure data. The efficiency of the two learning algorithms has been compared with various fuzzy and statistical time series-based forecasting algorithms on the basis of their prediction ability.},
journal = {Neural Comput. Appl.},
month = jan,
pages = {1221–1231},
numpages = {11},
keywords = {Software reliability, Genetic algorithm, Fuzzy neural network, Faults}
}

@article{10.1016/j.sysarc.2021.102298,
author = {Fern\'{a}ndez, Javier and Perez, Jon and Agirre, Irune and Allende, Imanol and Abella, Jaume and Cazorla, Francisco J.},
title = {Towards functional safety compliance of matrix–matrix multiplication for machine learning-based autonomous systems},
year = {2021},
issue_date = {Dec 2021},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {121},
number = {C},
issn = {1383-7621},
url = {https://doi.org/10.1016/j.sysarc.2021.102298},
doi = {10.1016/j.sysarc.2021.102298},
journal = {J. Syst. Archit.},
month = dec,
numpages = {14},
keywords = {Error detection, Functional safety, Machine learning}
}

@article{10.1007/s00034-019-01327-3,
author = {Song, Shiyu and Hu, Jun and Chen, Dongyan and Chen, Weilu and Wu, Zhihui},
title = {An Event-Triggered Approach to Robust Fault Detection for Nonlinear Uncertain Markovian Jump Systems with Time-Varying Delays},
year = {2020},
issue_date = {Jul 2020},
publisher = {Birkhauser Boston Inc.},
address = {USA},
volume = {39},
number = {7},
issn = {0278-081X},
url = {https://doi.org/10.1007/s00034-019-01327-3},
doi = {10.1007/s00034-019-01327-3},
abstract = {In this paper, the problem of robust fault detection is investigated for nonlinear uncertain Markovian jump systems subject to time-varying delays, Lipschitz nonlinearities and parameter uncertainties under the event-triggered protocol. The event-triggered mechanism is introduced to adjust the transmission frequency of the data sent to the remote module. An event-based fault detection method is presented to guarantee the sensitivity of residual to fault and the attenuation of the effect from the disturbance on the residual. In this way, the considered fault detection problem is solvable by testifying the feasibility of H∞ filtering problem. By constructing the mode-dependent Lyapunov functional, new sufficient criteria are derived in terms of the linear matrix inequality technique, which insures the stochastic stability with prescribed performance for addressed MJSs. In the end, a numerical example is exploited and the validity of newly presented event-based fault detection method is shown.},
journal = {Circuits Syst. Signal Process.},
month = jul,
pages = {3445–3469},
numpages = {25},
keywords = {Parameter uncertainties, Time delays, Event-triggered mechanism, Markovian jump systems, Fault detection}
}

@inproceedings{10.1145/3393527.3393535,
author = {Hong, Cheng and Huang, Zhicong and Lu, Wen-jie and Qu, Hunter and Ma, Li and Dahl, Morten and Mancuso, Jason},
title = {Privacy-preserving collaborative machine learning on genomic data using TensorFlow},
year = {2020},
isbn = {9781450375344},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3393527.3393535},
doi = {10.1145/3393527.3393535},
abstract = {Machine learning (ML) methods have been widely used in genomic studies. However, genomic data are often held by different stakeholders (e.g. hospitals, universities, and healthcare companies) who consider the data as sensitive information, even though they desire to collaborate. To address this issue, recent works have proposed solutions using Secure Multi-party Computation (MPC), which train on the decentralized data in a way that the participants could learn nothing from each other beyond the final trained model.We design and implement several MPC-friendly ML primitives, including class weight adjustment and parallelizable approximation of activation function. In addition, we develop the solution as an extension to TF Encrypted [7], enabling us to quickly experiment with enhancements of both machine learning techniques and cryptographic protocols while leveraging the advantages of TensorFlow's optimizations. Our implementation compares favorably with state-of-the-art methods, winning first place in Track IV of the iDASH2019 secure genome analysis competition.1},
booktitle = {Proceedings of the ACM Turing Celebration Conference - China},
pages = {39–44},
numpages = {6},
keywords = {secure multi-party computation, machine learning, GWAS studies},
location = {Hefei, China},
series = {ACM TURC '20}
}

@article{10.1016/j.sigpro.2019.107410,
author = {Zhang, Xiaoxia and Delpha, Claude and Diallo, Demba},
title = {Incipient fault detection and estimation based on Jensen–Shannon divergence in a data-driven approach},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {169},
number = {C},
issn = {0165-1684},
url = {https://doi.org/10.1016/j.sigpro.2019.107410},
doi = {10.1016/j.sigpro.2019.107410},
journal = {Signal Process.},
month = apr,
numpages = {12},
keywords = {Principal component analysis, Data-driven process, Jensen Shannon Divergence, Fault detection and estimation, Incipient fault}
}

@article{10.1016/j.inffus.2018.10.005,
author = {Diez-Olivan, Alberto and Del Ser, Javier and Galar, Diego and Sierra, Basilio},
title = {Data fusion and machine learning for industrial prognosis: Trends and perspectives towards Industry 4.0},
year = {2019},
issue_date = {Oct 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {50},
number = {C},
issn = {1566-2535},
url = {https://doi.org/10.1016/j.inffus.2018.10.005},
doi = {10.1016/j.inffus.2018.10.005},
journal = {Inf. Fusion},
month = oct,
pages = {92–111},
numpages = {20},
keywords = {VCM, SVMs, SOM-MQE, SBM, SARMA, RNN, RBM, PoF, PCA, LOF, LAD, KDE, kNN, HMM, GRNN, GRBMs, GMM, FPCA, FFT, EWMA, EM, DWT, DBN, BPNN, ANNs, ANFIS, Industry 4.0, Machine learning, Data fusion, Data-driven prognosis}
}

@article{10.1007/s10845-021-01752-9,
author = {Sun, Yanning and Qin, Wei and Zhuang, Zilong and Xu, Hongwei},
title = {An adaptive fault detection and root-cause analysis scheme for complex industrial processes using moving window KPCA and information geometric causal inference},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {7},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01752-9},
doi = {10.1007/s10845-021-01752-9},
abstract = {In recent years, fault detection and diagnosis for industrial processes have been rapidly developed to minimize costs and maximize efficiency by taking advantages of cheap sensors and microprocessors, data analysis and artificial intelligence methods. However, due to the nonlinear and dynamic characteristics of industrial process data, the accuracy and efficiency of fault detection and diagnosis methods have always been an urgent problem in industry and academia. Therefore, this study proposes an adaptive fault detection and root-cause analysis scheme for complex industrial processes using moving window kernel principle component analysis (KPCA) and information geometric causal inference (IGCI). The proposed scheme has three main contributions. Firstly, a research scheme combining moving window KPCA with adaptive threshold is presented to handle the nonlinear and dynamic characteristics of complex industrial processes. Then, the multiobjective evolutionary algorithm is employed to select the optimal hyperparameters for fault detection, which not only avoids the blindness of hyperparameters selection, but also maximize model accuracy. Finally, the IGCI-based fault root-cause analysis method can help field operators to take corrective measures in time to resume the normal process. The proposed scheme is tested by the Tennessee Eastman platform. Its results show that this scheme has a good performance in reducing the faulty false alarms and missed detection rates and locating fault root-cause.},
journal = {J. Intell. Manuf.},
month = oct,
pages = {2007–2021},
numpages = {15},
keywords = {Causal inference, Multiobjective evolutionary algorithm, Moving window KPCA, Root-cause analysis, Fault detection}
}

@article{10.1016/j.cie.2020.106376,
author = {Apsemidis, Anastasios and Psarakis, Stelios and Moguerza, Javier M.},
title = {A review of machine learning kernel methods in statistical process monitoring},
year = {2020},
issue_date = {Apr 2020},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {142},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2020.106376},
doi = {10.1016/j.cie.2020.106376},
journal = {Comput. Ind. Eng.},
month = apr,
numpages = {12},
keywords = {Machine learning, Multivariate control charts, Statistical process monitoring, Support vector machines, Kernel methods}
}

@article{10.1002/acs.3105,
author = {Abid, Walid and Krifa, Abdelkader and Liouane, Noureddine},
title = {Neural observer‐based small fault detection and isolation for uncertain nonlinear systems},
year = {2020},
issue_date = {May 2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {34},
number = {5},
issn = {0890-6327},
url = {https://doi.org/10.1002/acs.3105},
doi = {10.1002/acs.3105},
abstract = {Small faults (some weak faults with a tiny magnitude) are difficult to detect and may cause severe problems leading to degrading the system performance. This paper proposes an approach to estimate, detect, and isolate small faults in uncertain nonlinear systems subjected to model uncertainties, disturbances, and measurement noise. A robust observer is developed to alleviate the lack of full state measurement. Using the estimated state, a dynamical radial basis function neural networks observer is designed in form of LMI problem to accurately learn the function of the inseparable mixture between modeling uncertainty and the small fault. By exploiting the knowledge obtained by the learning phase, a bank of observers is constructed for both normal and fault modes. A set of residues is achieved by filtering the differences between the outputs of the bank of observers and the monitored system output. Due to the noise dampening characteristics of the filters and according to the smallest residual principle, the small faults can be detected and isolated successfully. Finally, rigorous analysis is performed to characterize the detection and isolation capabilities of the proposed scheme. Simulation results are used to prove the efficacy and merits of the proposed approach.},
journal = {Int. J. Adapt. Control Signal Process.},
month = may,
pages = {677–702},
numpages = {26},
keywords = {small faults, nonlinear observers, learning systems, filtering, fault detection and isolation}
}

@article{10.1007/s11219-015-9297-z,
author = {Tosun, Ayse and Bener, Ayse Basar and Akbarinasaji, Shirin},
title = {A systematic literature review on the applications of Bayesian networks to predict software quality},
year = {2017},
issue_date = {March     2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-015-9297-z},
doi = {10.1007/s11219-015-9297-z},
abstract = {Bayesian networks (BN) have been used for decision making in software engineering for many years. In other fields such as bioinformatics, BNs are rigorously evaluated in terms of the techniques that are used to build the network structure and to learn the parameters. We extend our prior mapping study to investigate the extent to which contextual and methodological details regarding BN construction are reported in the studies. We conduct a systematic literature review on the applications of BNs to predict software quality. We focus on more detailed questions regarding (1) dataset characteristics, (2) techniques used for parameter learning, (3) techniques used for structure learning, (4) use of tools, and (5) model validation techniques. Results on ten primary studies show that BNs are mostly built based on expert knowledge, i.e. structure and prior distributions are defined by experts, whereas authors benefit from BN tools and quantitative data to validate their models. In most of the papers, authors do not clearly explain their justification for choosing a specific technique, and they do not compare their proposed BNs with other machine learning approaches. There is also a lack of consensus on the performance measures to validate the proposed BNs. Compared to other domains, the use of BNs is still very limited and current publications do not report enough details to replicate the studies. We propose a framework that provides a set of guidelines for reporting the essential contextual and methodological details of BNs. We believe such a framework would be useful to replicate and extend the work on BNs.},
journal = {Software Quality Journal},
month = mar,
pages = {273–305},
numpages = {33},
keywords = {Systematic literature review, Software reliability prediction, Software quality, Bayesian network, Applications of AI}
}

@inproceedings{10.5555/3507788.3507810,
author = {Korlepara, Piyush and Grigoriou, Marios and Kontogiannis, Kostas and Brealey, Chris and Giammaria, Alberto},
title = {Combining domain expert knowledge and machine learning for the identification of error prone files},
year = {2021},
publisher = {IBM Corp.},
address = {USA},
abstract = {Identifying as early as possible fault prone modules in order to facilitate continuous delivery in large software systems, has been an area where significant attention has been paid over the past few years. Recent efforts consider source code metrics and process metrics for training machine learning models to predict whether a software source code file is fault prone or not. In such prediction frameworks the accuracy of the trained model relies heavily on the features selected and the profiles of the metrics used for training the model which are unique to each system. Furthermore, these models act as black-boxes, where the end-user does not know how a specific prediction was reached. In this paper, we propose an approach which allows for domain expert knowledge to be combined with machine learning in order to yield fault-proneness prediction models that both exhibit high levels of recall and at the same time are able to provide explanations to the developers as to how and why these predictions were reached. For this paper we apply two rule-based inferencing techniques namely, Fuzzy reasoning, and Markov Logic Networks. The main contribution of this work is that it allows for expert developers to identify in the form of if-then rules domain logic that pertains to the fault-proneness of a source code file in the specific system being analysed. Results obtained from 19 open source systens indicate that MLNs perform better than Fuzzy Logic models and that project-customized rules achieve better results than generic rules. Furthermore, results indicate that its possible to compile a common set of rules that yields consistently acceptable results across different projects.},
booktitle = {Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering},
pages = {153–162},
numpages = {10},
keywords = {software repositories, process metrics, fault-proneness prediction, continuous software engineering},
location = {Toronto, Canada},
series = {CASCON '21}
}

@article{10.1145/3394112,
author = {Chen, Junjie and Wu, Zhuo and Wang, Zan and You, Hanmo and Zhang, Lingming and Yan, Ming},
title = {Practical Accuracy Estimation for Efficient Deep Neural Network Testing},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3394112},
doi = {10.1145/3394112},
abstract = {Deep neural network (DNN) has become increasingly popular and DNN testing is very critical to guarantee the correctness of DNN, i.e., the accuracy of DNN in this work. However, DNN testing suffers from a serious efficiency problem, i.e., it is costly to label each test input to know the DNN accuracy for the testing set, since labeling each test input involves multiple persons (even with domain-specific knowledge) in a manual way and the testing set is large-scale. To relieve this problem, we propose a novel and practical approach, called PACE (which is short for Practical ACcuracy Estimation), which selects a small set of test inputs that can precisely estimate the accuracy of the whole testing set. In this way, the labeling costs can be largely reduced by just labeling this small set of selected test inputs. Besides achieving a precise accuracy estimation, to make PACE more practical it is also required that it is interpretable, deterministic, and as efficient as possible. Therefore, PACE first incorporates clustering to interpretably divide test inputs with different testing capabilities (i.e., testing different functionalities of a DNN model) into different groups. Then, PACE utilizes the MMD-critic algorithm, a state-of-the-art example-based explanation algorithm, to select prototypes (i.e., the most representative test inputs) from each group, according to the group sizes, which can reduce the impact of noise due to clustering. Meanwhile, PACE also borrows the idea of adaptive random testing to select test inputs from the minority space (i.e., the test inputs that are not clustered into any group) to achieve great diversity under the required number of test inputs. The two parallel selection processes (i.e., selection from both groups and the minority space) compose the final small set of selected test inputs. We conducted an extensive study to evaluate the performance of PACE based on a comprehensive benchmark (i.e., 24 pairs of DNN models and testing sets) by considering different types of models (i.e., classification and regression models, high-accuracy and low-accuracy models, and CNN and RNN models) and different types of test inputs (i.e., original, mutated, and automatically generated test inputs). The results demonstrate that PACE is able to precisely estimate the accuracy of the whole testing set with only 1.181%∼2.302% deviations, on average, significantly outperforming the state-of-the-art approaches.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = oct,
articleno = {30},
numpages = {35},
keywords = {test optimization, test input selection, labeling, Deep neural network testing}
}

@article{10.1007/s00607-019-00781-w,
author = {Renga, Daniela and Apiletti, Daniele and Giordano, Danilo and Nisi, Matteo and Huang, Tao and Zhang, Yang and Mellia, Marco and Baralis, Elena},
title = {Data-driven exploratory models of an electric distribution network for fault prediction and diagnosis},
year = {2020},
issue_date = {May 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {102},
number = {5},
issn = {0010-485X},
url = {https://doi.org/10.1007/s00607-019-00781-w},
doi = {10.1007/s00607-019-00781-w},
abstract = {Data-driven models are becoming of fundamental importance in electric distribution networks to enable predictive maintenance, to perform effective diagnosis and to reduce related expenditures, with the final goal of improving the electric service efficiency and reliability to the benefit of both the citizens and the grid operators themselves. This paper considers a dataset collected over 6 years in a real-world medium-voltage distribution network by the Supervisory Control And Data Acquisition (SCADA) system. A transparent, exploratory, and exhaustive data-mining workflow, based on data characterisation, time-windowing, association rule mining, and associative classification is proposed and experimentally evaluated to automatically identify correlations and build a prognostic–diagnostic model from the SCADA events occurring before and after specific service interruptions, i.e., network faults. Our results, evaluated by both data-driven quality metrics and domain expert interpretations, highlight the capability to assess the limited predictive capability of the SCADA events for medium-voltage distribution networks, while their effective exploitation for diagnostic purposes is promising.},
journal = {Computing},
month = may,
pages = {1199–1211},
numpages = {13},
keywords = {68T04, Associative classification, Data mining, Medium Voltage distribution networks, Fault diagnosis, Predictive maintenance, Smart grid}
}

@inproceedings{10.1145/2020390.2020406,
author = {Paikari, Elham and Sun, Bo and Ruhe, Guenther and Livani, Emadoddin},
title = {Customization support for CBR-based defect prediction},
year = {2011},
isbn = {9781450307093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020390.2020406},
doi = {10.1145/2020390.2020406},
abstract = {Background: The prediction performance of a case-based reasoning (CBR) model is influenced by the combination of the following parameters: (i) similarity function, (ii) number of nearest neighbor cases, (iii) weighting technique used for attributes, and (iv) solution algorithm. Each combination of the above parameters is considered as an instantiation of the general CBR-based prediction method. The selection of an instantiation for a new data set with specific characteristics (such as size, defect density and language) is called customization of the general CBR method.Aims: For the purpose of defect prediction, we approach the question which combinations of parameters works best at which situation. Three more specific questions were studied:(RQ1) Does one size fit all? Is one instantiation always the best?(RQ2) If not, which individual and combined parameter settings occur most frequently in generating the best prediction results?(RQ3) Are there context-specific rules to support the customization?Method: In total, 120 different CBR instantiations were created and applied to 11 data sets from the PROMISE repository. Predictions were evaluated in terms of their mean magnitude of relative error (MMRE) and percentage Pred(α) of objects fulfilling a prediction quality level α. For the third research question, dependency network analysis was performed.Results: Most frequent parameter options for CBR instantiations were neural network based sensitivity analysis (as the weighting technique), un-weighted average (as the solution algorithm), and maximum number of nearest neighbors (as the number of nearest neighbors). Using dependency network analysis, a set of recommendations for customization was provided.Conclusion: An approach to support customization is provided. It was confirmed that application of context-specific rules across groups of similar data sets is risky and produces poor results.},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering},
articleno = {16},
numpages = {10},
keywords = {case-based reasoning, customization, defect prediction, dependency network analysis, instantiation},
location = {Banff, Alberta, Canada},
series = {Promise '11}
}

@inproceedings{10.1145/2811411.2811544,
author = {Siebra, Clauirton A. and Mello, Michael A. B.},
title = {The importance of replications in software engineering: a case study in defect prediction},
year = {2015},
isbn = {9781450337380},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811411.2811544},
doi = {10.1145/2811411.2811544},
abstract = {Prediction of defects in software is an important investigation area in software engineering, since such technique is able to return indications of parts of the code that are prone to contain problems. Thus, test teams can optimize the allocation of their resources by directing them to modules that are more defect-prone. The use of supervised learning is one of the approaches to support the design of prediction models. However, the erroneous use of training datasets can lead to poor models and, consequently, false results regarding accuracy. This work replicates important experiments of the area and shows how they could provide reliable results via the use of simple techniques of pre-processing. Based on the results, we discuss the importance of replications as method to find problems in current results and how this method is being motivated inside the software engineering area.},
booktitle = {Proceedings of the 2015 Conference on Research in Adaptive and Convergent Systems},
pages = {376–381},
numpages = {6},
keywords = {supervised learning, replication, defect prediction},
location = {Prague, Czech Republic},
series = {RACS '15}
}

@inproceedings{10.5555/2487085.2487161,
author = {Peters, Fayola and Menzies, Tim and Marcus, Andrian},
title = {Better cross company defect prediction},
year = {2013},
isbn = {9781467329361},
publisher = {IEEE Press},
abstract = {How can we find data for quality prediction? Early in the life cycle, projects may lack the data needed to build such predictors. Prior work assumed that relevant training data was found nearest to the local project. But is this the best approach?  This paper introduces the Peters filter which is based on the following conjecture: When local data is scarce, more information exists in other projects. Accordingly, this filter selects training data via the structure of other projects.  To assess the performance of the Peters filter, we compare it with two other approaches for quality prediction. Within- company learning and cross-company learning with the Burak filter (the state-of-the-art relevancy filter). This paper finds that: 1) within-company predictors are weak for small data-sets; 2) the Peters filter+cross-company builds better predictors than both within-company and the Burak filter+cross-company; and 3) the Peters filter builds 64% more useful predictors than both within- company and the Burak filter+cross-company approaches. Hence, we recommend the Peters filter for cross-company learning.},
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
pages = {409–418},
numpages = {10},
location = {San Francisco, CA, USA},
series = {MSR '13}
}

@article{10.1016/j.eswa.2017.03.058,
author = {Khalastchi, Eliahu and Kalech, Meir and Rokach, Lior},
title = {A hybrid approach for improving unsupervised fault detection for robotic systems},
year = {2017},
issue_date = {September 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {81},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2017.03.058},
doi = {10.1016/j.eswa.2017.03.058},
abstract = {From unsupervised to supervised learning a fault detection model (for robots).Insights to why and when it becomes more accurate.Theoretical analysis and a prediction tool.Empirical results on 3 real-world domains that back these insights. The use of robots in our daily lives is increasing. As we rely more on robots, thus it becomes more important for us that the robots will continue on with their mission successfully. Unfortunately, these sophisticated, and sometimes very expensive, machines are susceptible to different kinds of faults. It becomes important to apply a Fault Detection (FD) mechanism which is suitable for the domain of robots. Two important requirements of such a mechanism are: high accuracy and low computational-load during operation (online). Supervised learning can potentially produce very accurate FD models, and if the learning takes place offline then the online computational-load can be reduced. Yet, the domain of robots is characterized with the absence of labeled data (e.g., faulty, normal) required by supervised approaches, and consequently, unsupervised approaches are being used. In this paper we propose a hybrid approach - an unsupervised approach can label a data set, with a low degree of inaccuracy, and then the labeled data set is used offline by a supervised approach to produce an online FD model. Now, we are faced with a choice should we use the unsupervised or the hybrid fault detector? Seemingly, there is no way to validate the choice due to the absence of (a priori) labeled data. In this paper we give an insight to why, and a tool to predict when, the hybrid approach is more accurate. In particular, the main impacts of our work are (1) we theoretically analyze the conditions under which the hybrid approach is expected to be more accurate. (2) Our theoretical findings are backed with empirical analysis. We use data sets of three different robotic domains: a high fidelity flight simulator, a laboratory robot, and a commercial Unmanned Arial Vehicle (UAV). (3) We analyze how different unsupervised FD approaches are improved by the hybrid technique and (4) how well this improvement fits our prediction tool. The significance of the hybrid approach and the prediction tool is the potential benefit to expert and intelligent systems in which labeled data is absent or expensive to create.},
journal = {Expert Syst. Appl.},
month = sep,
pages = {372–383},
numpages = {12},
keywords = {Unsupervised, Robotic systems, Fault detection}
}

@article{10.1109/TSE.2016.2584050,
author = {Tantithamthavorn, Chakkrit and McIntosh, Shane and Hassan, Ahmed E. and Matsumoto, Kenichi},
title = {An Empirical Comparison of Model Validation Techniques for Defect Prediction Models},
year = {2017},
issue_date = {January 2017},
publisher = {IEEE Press},
volume = {43},
number = {1},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2016.2584050},
doi = {10.1109/TSE.2016.2584050},
abstract = {Defect prediction models help software quality assurance teams to allocate their limited resources to the most defect-prone modules. Model validation techniques, such as  $k$ -fold cross-validation, use historical data to estimate how well a model will perform in the future. However, little is known about how accurate the estimates of model validation techniques tend to be. In this paper, we investigate the bias and variance of model validation techniques in the domain of defect prediction. Analysis of 101 public defect datasets suggests that 77 percent of them are highly susceptible to producing unstable results– - selecting an appropriate model validation technique is a critical experimental design choice. Based on an analysis of 256 studies in the defect prediction literature, we select the 12 most commonly adopted model validation techniques for evaluation. Through a case study of 18 systems, we find that single-repetition holdout validation tends to produce estimates with 46-229 percent more bias and 53-863 percent more variance than the top-ranked model validation techniques. On the other hand, out-of-sample bootstrap validation yields the best balance between the bias and variance of estimates in the context of our study. Therefore, we recommend that future defect prediction studies avoid single-repetition holdout validation, and instead, use out-of-sample bootstrap validation.},
journal = {IEEE Trans. Softw. Eng.},
month = jan,
pages = {1–18},
numpages = {18}
}

@article{10.1007/s10515-010-0069-5,
author = {Menzies, Tim and Milton, Zach and Turhan, Burak and Cukic, Bojan and Jiang, Yue and Bener, Ay\c{s}e},
title = {Defect prediction from static code features: current results, limitations, new approaches},
year = {2010},
issue_date = {December  2010},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {17},
number = {4},
issn = {0928-8910},
url = {https://doi.org/10.1007/s10515-010-0069-5},
doi = {10.1007/s10515-010-0069-5},
abstract = {Building quality software is expensive and software quality assurance (QA) budgets are limited. Data miners can learn defect predictors from static code features which can be used to control QA resources; e.g. to focus on the parts of the code predicted to be more defective.Recent results show that better data mining technology is not leading to better defect predictors. We hypothesize that we have reached the limits of the standard learning goal of maximizing area under the curve (AUC) of the probability of false alarms and probability of detection "AUC(pd, pf)"; i.e. the area under the curve of a probability of false alarm versus probability of detection.Accordingly, we explore changing the standard goal. Learners that maximize "AUC(effort, pd)" find the smallest set of modules that contain the most errors. WHICH is a meta-learner framework that can be quickly customized to different goals. When customized to AUC(effort, pd), WHICH out-performs all the data mining methods studied here. More importantly, measured in terms of this new goal, certain widely used learners perform much worse than simple manual methods.Hence, we advise against the indiscriminate use of learners. Learners must be chosen and customized to the goal at hand. With the right architecture (e.g. WHICH), tuning a learner to specific local business goals can be a simple task.},
journal = {Automated Software Engg.},
month = dec,
pages = {375–407},
numpages = {33},
keywords = {WHICH, Static code features, Defect prediction}
}

@book{10.5555/3035850,
author = {Mahfuz, Abu Sayed},
title = {Software Quality Assurance: Integrating Testing, Security, and Audit},
year = {2016},
isbn = {1498735533},
publisher = {Auerbach Publications},
address = {USA},
abstract = {Software Quality Assurance: Integrating Testing, Security, and Audit focuses on the importance of software quality and security. It defines various types of testing, recognizes factors that propose value to software quality, and provides theoretical and real-world scenarios that offer value and contribute quality to projects and applications. The practical synopsis on common testing tools helps readers who are in testing jobs or those interested in pursuing careers as testers. It also helps test leaders, test managers, and others who are involved in planning, estimating, executing, and maintaining software. The book is divided into four sections: The first section addresses the basic concepts of software quality, validation and verification, and audits. It covers the major areas of software management, software life cycle, and life cycle processes. The second section is about testing. It discusses test plans and strategy and introduces a step-by-step test design process along with a sample test case. It also examines what a tester or test lead needs to do before and during test execution and how to report after completing the test execution. The third section deals with security breaches and defects that may occur. It discusses documentation and classification of incidences as well as how to handle an occurrence. The fourth and final section provides examples of security issues along with a security policy document and addresses the planning aspects of an information audit. This section also discusses the definition, measurement, and metrics of reliability based on standards and quality metrics methodology CMM models. It discusses the ISO 15504 standard, CMMs, PSP, and TSP and includes an appendix containing a software process improvement sample document.}
}

@inproceedings{10.1109/ETFA.2018.8502604,
author = {Ar\'{e}valo, Fernando and Rernenter\'{\i}a, Juan and Schwung, Andreas},
title = {Fault Detection Assessment Architectures based on Classification Methods and Information Fusion},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ETFA.2018.8502604},
doi = {10.1109/ETFA.2018.8502604},
abstract = {Classifiers based on machine learning are popular in literature, in order to support predictive maintenance of machinery. Depending on the process data, one classifier can assess target classes better than others. It often happens that the classifiers complement each other. A fusion strategy is needed in order to exploit the strength of each classifier. This paper presents fault detection assessment architectures based on information fusion and classification methods. It proposes the use of information fusion methods and different architectures, in order to improve the overall result of the fault detection assessment. Dempster-Shafer and Yager rules of combination are used to fuse the classification method predictions. The rules of combination improve the results by complementing the classifiers performance. A comparison between centralized and decentralized architectures is presented. The results show that the information fusion using decentralized architectures improves the overall performance of the fault detection assessment.},
booktitle = {2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA)},
pages = {1343–1350},
numpages = {8},
location = {Torino, Italy}
}

@article{10.1016/j.future.2020.10.009,
author = {Zhang, Dehua and Lou, Sha},
title = {The application research of neural network and BP algorithm in stock price pattern classification and prediction},
year = {2021},
issue_date = {Feb 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {115},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2020.10.009},
doi = {10.1016/j.future.2020.10.009},
journal = {Future Gener. Comput. Syst.},
month = feb,
pages = {872–879},
numpages = {8},
keywords = {Neural network, BP algorithm, Stock price prediction, Stock price pattern classification}
}

@article{10.1007/s42979-019-0004-1,
author = {Tran, Ha Manh and Le, Son Thanh and Nguyen, Sinh Van and Ho, Phong Thanh},
title = {An Analysis of Software Bug Reports Using Machine Learning Techniques},
year = {2019},
issue_date = {Jan 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {1},
url = {https://doi.org/10.1007/s42979-019-0004-1},
doi = {10.1007/s42979-019-0004-1},
abstract = {Bug tracking systems manage bug reports for assuring the quality of software products. A bug report (alsoreferred as trouble, problem, ticket or defect) contains several features for problem management and resolution purposes. Severity and priority are two essential features of a bug report that define the effect level and fixing order of the bug. Determining these features is challenging and depends heavily on human being, e.g., software developers or system operators, especially for assessing a large number of error and warning events occurring on software products or network services. This study first proposes a comparison of machine learning techniques for assessing severity and priority for software bug reports and then chooses an approach of using optimal decision trees, or random forest, for further investigation. This approach aims at constructing multiple decision trees based on the subsets of the existing bug dataset and features, and then selecting the best decision trees to assess the severity and priority of new bugs. The approach can be applied for detecting and forecasting faults in large, complex communication networks and distributed systems today. We have presented the applicability of random forest for bug report analysis and performed several experiments on software bug datasets obtained from open source bug tracking systems. Random forest yields an average accuracy score of 0.75 that can be sufficient for assisting system operators in determining these features. We have provided some analysis of the experimental results.},
journal = {SN Comput. Sci.},
month = jun,
numpages = {11},
keywords = {Software bug report, Data analytics, Machine learning, Fault management, Network fault detection}
}

@inproceedings{10.5555/2025816.2025859,
author = {Abreu, Rui and Gonzalez-Sanchez, Alberto and Van Gemund, Arjan J. C.},
title = {A diagnostic reasoning approach to defect prediction},
year = {2011},
isbn = {9783642218262},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {During software testing, defect prediction approaches measure current reliability status, forecasting future program failures, and provide information on how many defects need to be removed before shipping. Existing approaches often require faults to be detected and identified as a new one, before a model-based trend can be fitted. While during regression testing failures may frequently occur, it is not evident which are related to new faults. Consequently, reliability growth trending can only be performed in sync with fault identification and repair, which is often performed in between regression test cycles. In this paper we present a dynamic, reasoning approach to estimate the number of defects in the system early in the process of regression testing. Our approach, coined Dracon, is based on Bayesian fault diagnosis over abstractions of program traces (also known as program spectra). Experimental results show that Dracon systematically estimates the exact number of (injected) defects, provided sufficient tests cases are available. Furthermore, we also propose a simple, analytic performance model to assess the influence of failed test cases in the estimation. We observe that our empirical findings are in agreement with the model.},
booktitle = {Proceedings of the 24th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems Conference on Modern Approaches in Applied Intelligence - Volume Part II},
pages = {416–425},
numpages = {10},
keywords = {program spectra, diagnosis, defect prediction, bayes},
location = {Syracuse, NY},
series = {IEA/AIE'11}
}

@article{10.1007/s10489-020-02118-z,
author = {Yang, Chunsheng and Gu, Wen and Ito, Takayuki and Yang, Xiaohua},
title = {Machine learning-based consensus decision-making support for crowd-scale deliberation},
year = {2021},
issue_date = {Jul 2021},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {51},
number = {7},
issn = {0924-669X},
url = {https://doi.org/10.1007/s10489-020-02118-z},
doi = {10.1007/s10489-020-02118-z},
abstract = {With the rapid development of Internet, the online discussion system or social democratic system has become an important and effective vehicle for group decision-making support since it can continue collecting the opinions from the public at anytime. To reach a consensus in crowd-scale deliberation, the existing online discussion systems require an experienced human facilitator to navigate and guild the discussion. When human facilitator performs the required facilitation there are several issues such as heavy burden on decision-making, the 24/7 online facilitation, bias on the social issues, etc. To address these issues it is necessary and inevitable to explore intelligent facilitation. For this purpose, we propose a novel machine learning-based method for smart facilitation, in particular the intelligent consensus decision-making support (CDMS) for crowd-scale deliberation. After presenting an overview of the crowd-scale deliberation and the COLLAGREE, the paper details the proposed approach, a machine learning-based framework for CDMS in crowd-scale deliberation. To validate the developed methods the offline evaluation experiments were conducted with the online discussion platform, COLLAGREE. The preliminary experimental results obtained from offline validation demonstrated the feasibility and usefulness of the developed machine learning-based methods for CDMS.},
journal = {Applied Intelligence},
month = jul,
pages = {4762–4773},
numpages = {12},
keywords = {Online discussion systems, Facilitation, Consensus decision-making support (CDMS), Case-based reasoning, Machine learning algorithms, Crowd deliberation}
}

@phdthesis{10.5555/AAI28744987,
author = {Rahimilarki, Reihane},
advisor = {Zhiwei, Gao, and Nanlin, Jin,},
title = {Fault Diagnosis for Wind Turbine Systems by Using Neural Network and Deep Learning Techniques},
year = {2021},
isbn = {9798535579221},
publisher = {University of Northumbria at Newcastle (United Kingdom)},
abstract = {Concerning the fact that the number of wind turbines is increasing worldwide, it seems necessary to implement monitoring systems. To respond to this demand, this PhD thesis studies different fault diagnosis techniques in order to improve the reliability and reduce maintenance costs. Based on the fact that a considerable amount of data is stored via SCADA in every industry nowadays, the methods developed on historical data (called data-driven methods) can be very beneficial.By analyzing the historical data, the changing trends of a nonlinear dynamics, such as a wind turbine, can be predicted. Moreover, by applying suitable approaches, one can distinguish different faults based on the output of the system.The first part in this research reviews a neural network identification method by decoupling linear and nonlinear parts of a wind turbine model. As for the linear part, a Luenberger observer is designed, while for the nonlinear part, a neural network observer is proposed. By having an identification model for a wind turbine system, residual-based fault detection is studied.The second part in this research proposes a novel neuro-robust fault estimation method to deal with the occurred faults on actuators or sensors. The challenge in this method is environmental disturbances and sensor noises. To overcome these problems and simultaneously estimate the faults and the states, an augmented system is proposed in different scenarios of actuator faults or sensor faults. Then, a neural network updating rule is calculated along with the robust performance index to fully achieve this goal. The stability of the augmented system is guaranteed by having a Lyapunov function and input-to-state stability criteria.The third and final part in this research studies different structures of Convolutional Neural Networks for the problem of fault classification in a wind turbine.As working with time-series signals is challenging in deep learning classification, a pre-processing analysis is applied to prepare the data of system outputs for the input of the model.Each proposed method is applied to a 4.8 MW wind turbine benchmark and obtained results are illustrated and discussed to validate the accuracy and performance of the approach.},
note = {AAI28744987}
}

@article{10.1007/s11219-018-9406-x,
author = {Mendes, Emilia and Winkler, Dietmar},
title = {Special issue on "software quality in software-intensive systems"},
year = {2018},
issue_date = {June      2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {26},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-018-9406-x},
doi = {10.1007/s11219-018-9406-x},
journal = {Software Quality Journal},
month = jun,
pages = {657–660},
numpages = {4}
}

@article{10.1504/ijbis.2021.115366,
author = {Cerqueira, Marcelo Gomes De and Silva, Paulo Caetano Da},
title = {A survey of XBRL adoption impact on financial software development processes and software quality},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {37},
number = {2},
issn = {1746-0972},
url = {https://doi.org/10.1504/ijbis.2021.115366},
doi = {10.1504/ijbis.2021.115366},
abstract = {XBRL technology is currently used by several government institutions and companies around the world. The literature includes many papers related to the uses and benefits of XBRL in the areas of finance and accounting. However, there is a research gap on its benefits to software engineering. This paper seeks to identify the XBRL impacts on financial software development processes and software quality factors. Identifying such impacts may help software development companies better understand the advantages related to XBRL use and increase the adoption in other companies. This, in turn, may contribute to software quality improvement, facilitating the implementation of better financial software development frameworks in organisations.},
journal = {Int. J. Bus. Inf. Syst.},
month = jan,
pages = {263–286},
numpages = {23},
keywords = {software engineering, software quality factors, software process, financial software development, XBRL, extensible business reporting language}
}

@article{10.1016/j.neucom.2018.09.092,
author = {Pinto, Tiago and Morais, Hugo and Corchado, Juan Manuel},
title = {Adaptive entropy-based learning with dynamic artificial neural network},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {338},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.09.092},
doi = {10.1016/j.neucom.2018.09.092},
journal = {Neurocomput.},
month = apr,
pages = {432–440},
numpages = {9},
keywords = {Machine learning, Information theory, Forecasting, Entropy, Electricity market prices, Artificial Neural Networks}
}

@inproceedings{10.1145/3266003.3266004,
author = {de Santiago, Valdivino Alexandre and da Silva, Leoni Augusto Romain and de Andrade Neto, Pedro Ribeiro},
title = {Testing Environmental Models supported by Machine Learning},
year = {2018},
isbn = {9781450365550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3266003.3266004},
doi = {10.1145/3266003.3266004},
abstract = {In this paper we present a new methodology, DaOBML, to test environmental models whose outputs are complex artifacts such as images (maps) or plots. Our approach suggests several test data generation techniques (Combinatorial Interaction Testing, Model-Based Testing, Random Testing) and digital image processing methods to drive the creation of Knowledge Bases (KBs). Considering such KBs and Machine Learning (ML) algorithms, a test oracle assigns the verdicts of new test data. Our methodology is supported by a tool and we applied it to models developed via the TerraME product. A controlled experiment was carried out and we conclude that Random Testing is the most feasible test data generation approach for developing the KBs, Artificial Neural Networks present the best performance out of six ML algorithms, and the larger the KB, in terms of size, the better.},
booktitle = {Proceedings of the III Brazilian Symposium on Systematic and Automated Software Testing},
pages = {3–12},
numpages = {10},
keywords = {Random Testing, Model-Based Testing, Machine Learning, Environmental Modeling, Empirical Software Engineering, Digital Image Processing, Combinatorial Interaction Testing},
location = {SAO CARLOS, Brazil},
series = {SAST '18}
}

@article{10.1007/s00779-019-01348-4,
author = {Kim, Eun and Huh, Duck-Haing and Kim, Seokhoon},
title = {Knowledge-based power monitoring and fault prediction system for smart factories},
year = {2019},
issue_date = {Apr 2022},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {26},
number = {2},
issn = {1617-4909},
url = {https://doi.org/10.1007/s00779-019-01348-4},
doi = {10.1007/s00779-019-01348-4},
abstract = {With the recent spread of the 4th Industrial Revolution, the intellectualization of industry is progressing rapidly. In particular, companies in various field are interested in converting existing factories into smart factory, and the number of cases where the smart factory template is applied is increasing. In this paper, we design and implement an IoT-based power monitoring and data collection system that enables monitoring of power consumption as well as the detection of abnormal power consumption in a smart factory. The system consists of power measurement devices, data analysis servers, and knowledge-based web and smartphone applications. The power measurement device uses IoT sensors to measure power consumption and sends collected data to the server. The server analyzes the data collected from the device using R and exploits the analysis results to provide predictions about the failure of equipment and facilities in the smart factory. From this point of view, we can expect improvement in not only cost-efficiency but also product quality.},
journal = {Personal Ubiquitous Comput.},
month = dec,
pages = {307–318},
numpages = {12},
keywords = {Prediction, Failure detection, Power monitoring, Smart factory}
}

@article{10.1016/j.future.2019.11.042,
author = {Loreti, Daniela and Lippi, Marco and Torroni, Paolo},
title = {Parallelizing Machine Learning as a service for the end-user},
year = {2020},
issue_date = {Apr 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {105},
number = {C},
issn = {0167-739X},
url = {https://doi.org/10.1016/j.future.2019.11.042},
doi = {10.1016/j.future.2019.11.042},
journal = {Future Gener. Comput. Syst.},
month = apr,
pages = {275–286},
numpages = {12},
keywords = {MapReduce, Parallelization, Machine Learning as a service}
}

@article{10.1016/j.procs.2019.04.091,
author = {Xenakis, Apostolos and Karageorgos, Anthony and Lallas, Efthimios and Chis, Adriana E. and Gonz\'{a}lez-V\'{e}lez, Horacio},
title = {Towards Distributed IoT/Cloud based Fault Detection and Maintenance in Industrial Automation},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {151},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.04.091},
doi = {10.1016/j.procs.2019.04.091},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {683–690},
numpages = {8},
keywords = {ADMM Optimisation, Industrial Automation, Fault Detection, Industrial Internet of Things}
}

@inproceedings{10.1145/3338906.3342484,
author = {Moghadam, Mahshid Helali},
title = {Machine learning-assisted performance testing},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3342484},
doi = {10.1145/3338906.3342484},
abstract = {Automated testing activities like automated test case generation imply a reduction in human effort and cost, with the potential to impact the test coverage positively. If the optimal policy, i.e., the course of actions adopted, for performing the intended test activity could be learnt by the testing system, i.e., a smart tester agent, then the learnt policy could be reused in analogous situations which leads to even more efficiency in terms of required efforts. Performance testing under stress execution conditions, i.e., stress testing, which involves providing extreme test conditions to find the performance breaking points, remains a challenge, particularly for complex software systems. Some common approaches for generating stress test conditions are based on source code or system model analysis, or use-case based design approaches. However, source code or precise system models might not be easily available for testing. Moreover, drawing a precise performance model is often difficult, particularly for complex systems. In this research, I have used model-free reinforcement learning to build a self-adaptive autonomous stress testing framework which is able to learn the optimal policy for stress test case generation without having a model of the system under test. The conducted experimental analysis shows that the proposed smart framework is able to generate the stress test conditions for different software systems efficiently and adaptively without access to performance models.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1187–1189},
numpages = {3},
keywords = {Test case generation, Stress testing, Reinforcement learning, Performance testing, Autonomous testing},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@article{10.5555/3292849.3292858,
title = {A hybrid approach to improve the quality of software fault prediction using Na\"{\i}ve Bayes and k-NN classification algorithm with ensemble method},
year = {2018},
issue_date = {January 2018},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {17},
number = {4},
issn = {1740-8865},
abstract = {This paper considers an improvisation in software fault prediction research area using supervised classification algorithms and it mainly focuses to increase the performance of fault prediction. In this paper, we propose a hybrid prediction model using Na\"{\i}ve Bayes and k-nearest neighbour classification algorithm with vote ensemble method; in short it called as hNK. The goal of this model is to predict the best classification algorithm for software fault prediction based on the metrics and attributes of datasets. In the work, we have applied training sets and testing sets in hNK model with ensemble vote and we proposed the model to identify a suitable classification algorithm for fault prediction based on the accuracy and precision. We have achieved better results using hNK model for classifying supervised algorithms with different dataset.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {483–496},
numpages = {14}
}

@article{10.1007/s11334-017-0294-1,
author = {Pandey, Nitish and Sanyal, Debarshi Kumar and Hudait, Abir and Sen, Amitava},
title = {Automated classification of software issue reports using machine learning techniques: an empirical study},
year = {2017},
issue_date = {December  2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {13},
number = {4},
issn = {1614-5046},
url = {https://doi.org/10.1007/s11334-017-0294-1},
doi = {10.1007/s11334-017-0294-1},
abstract = {Software developers, testers and customers routinely submit issue reports to software issue trackers to record the problems they face in using a software. The issues are then directed to appropriate experts for analysis and fixing. However, submitters often misclassify an improvement request as a bug and vice versa. This costs valuable developer time. Hence automated classification of the submitted reports would be of great practical utility. In this paper, we analyze how machine learning techniques may be used to perform this task. We apply different classification algorithms, namely naive Bayes, linear discriminant analysis, k-nearest neighbors, support vector machine (SVM) with various kernels, decision tree and random forest separately to classify the reports from three open-source projects. We evaluate their performance in terms of F-measure, average accuracy and weighted average F-measure. Our experiments show that random forests perform best, while SVM with certain kernels also achieve high performance.},
journal = {Innov. Syst. Softw. Eng.},
month = dec,
pages = {279–297},
numpages = {19},
keywords = {Random forest, Machine learning, F-measure, Bug classification, Accuracy}
}

@inproceedings{10.1145/3474376.3487281,
author = {Liu, Wenye and Chang, Chip-Hong},
title = {A Forward Error Compensation Approach for Fault Resilient Deep Neural Network Accelerator Design},
year = {2021},
isbn = {9781450386623},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474376.3487281},
doi = {10.1145/3474376.3487281},
abstract = {Deep learning accelerator is a key enabler of a variety of safety-critical applications such as self-driving car and video surveillance. However, recently reported hardware-oriented attack vectors, e.g., fault injection attacks, have extended the threats on deployed deep neural network (DNN) systems beyond the software attack boundary by input data perturbation. Existing fault mitigation schemes including data masking, zeroing-on-error and circuit level time-borrowing techniques exploit the noise-tolerance of neural network models to resist random and sparse errors. Such noise tolerant-based schemes are not sufficiently effective to suppress intensive transient errors if a DNN accelerator is blasted with malicious and deliberate faults. In this paper, we conduct comprehensive investigations on reported resilient designs and propose a more robust countermeasure to fault injection attacks. The proposed design utilizes shadow flip flops for error detection and lightweight circuit for timely error correction. Our forward error compensation scheme rectifies the incorrect partial sum of the multiply-accumulation operation by estimating the difference between the correct and error-inflicted computation. The difference is added back to the final accumulated result at a later cycle without stalling the execution pipeline. We implemented our proposed design and the existing fault-mitigation schemes on the same Intel FPGA-based DNN accelerator to demonstrate its substantially enhanced resiliency against deliberate fault attacks on two popular DNN models, ResNet50 and VGG16, trained with ImageNet.},
booktitle = {Proceedings of the 5th Workshop on Attacks and Solutions in Hardware Security},
pages = {41–50},
numpages = {10},
keywords = {hardware security, fault injection attack, deep neural network accelerator},
location = {Virtual Event, Republic of Korea},
series = {ASHES '21}
}

@inproceedings{10.1145/3452383.3452400,
author = {Misra, Janardan and Podder, Sanjay},
title = {Association of Defect Log Suitability for Machine Learning with Performance: An Experience Report},
year = {2021},
isbn = {9781450390460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452383.3452400},
doi = {10.1145/3452383.3452400},
abstract = {Machine learning (ML) based solutions utilizing textual details in defect logs have been shown to enable automation of defect management process and make it cost effective. In this work, we assess effectiveness of apriori manual analysis of the suitability of applying ML to problems encountered during defect management process. We consider problems of mapping defects to service engineers and business processes for designing experiments. Experimental analysis on these problems using multiple defect logs from practice reveals that a systematic analysis of the defect log data by project experts can provide approximate indication of the eventual performance of the ML model even before they are actually built. We discuss practical significance of the conclusions for designing ML based solutions in-practice.},
booktitle = {Proceedings of the 14th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {17},
numpages = {5},
keywords = {Assignee Recommendation, Business Process Mapping, Defect Management Life-Cycle, Machine Learning Suitability, Mining Defect Repositories, Text Analysis},
location = {Bhubaneswar, Odisha, India},
series = {ISEC '21}
}

@article{10.1007/s00521-021-06228-8,
author = {Kumbhar, Surajkumar G. and Desavale, R. G. and Dharwadkar, Nagaraj V.},
title = {Fault size diagnosis of rolling element bearing using artificial neural network and dimension theory},
year = {2021},
issue_date = {Dec 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {23},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-021-06228-8},
doi = {10.1007/s00521-021-06228-8},
abstract = {Failure of roller bearings can cause downtime or a complete shutdown of rotating machines. Therefore, a well-timed detection of bearing defects must be performed. Modern condition monitoring demands simple but effective bearing failure diagnosis by integrating dynamic models with intelligence techniques. This paper presents an integration of Dimensional Analysis (DA) and Artificial Neural Network (ANN) to diagnose the size of the bearing faults. The vibration responses of artificially damaged bearings using Electrode Discharge Machining are collected using Fast Fourier Techniques on a developed rotor-bearing test rig. Two-performance indicators, actual error, and performance of error are used to evaluate the accuracy of models. The simplicity of the DA model and the performance of the ANN model predicting with 5.49% actual error and 97.79 performance of error band enhanced the accuracy of diagnosis compared to the experimental results. Moreover, ANN has shown good performance over experimental results and DA.},
journal = {Neural Comput. Appl.},
month = dec,
pages = {16079–16093},
numpages = {15},
keywords = {Dimension analysis, Artificial neural network, Fault size classification, Fault diagnosis}
}

@inproceedings{10.1109/ICMA.2019.8816600,
author = {Ellefsen, Andr\'{e} Listou and Cheng, Xu and Holmeset, Finn Tore and \AE{}s\o{}y, Vilmar and Zhang, Houxiang and Ushakov, Sergey},
title = {Automatic Fault Detection for Marine Diesel Engine Degradation in Autonomous Ferry Crossing Operation},
year = {2019},
isbn = {978-1-7281-1698-3},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICMA.2019.8816600},
doi = {10.1109/ICMA.2019.8816600},
abstract = {The maritime industry generally anticipates having semi-autonomous ferries in commercial use on the west coast of Norway by the end of this decade. In order to schedule maintenance operations of critical components in a secure and cost-effective manner, a reliable prognostics and health management system is essential during autonomous operations. Any remaining useful life prediction obtained from such system should depend on an automatic fault detection algorithm. In this study, an unsupervised reconstruction-based fault detection algorithm is used to predict faults automatically in a simulated autonomous ferry crossing operation. The benefits of the algorithm are confirmed on data sets of real-operational data from a marine diesel engine collected from a hybrid power lab. During the ferry crossing operation, the engine is subjected to drastic changes in operational loads. This increases the difficulty of the algorithm to detect faults with high accuracy. Thus, to support the algorithm, three different feature selection processes on the input data is compared. The results suggest that the algorithm achieves the highest prediction accuracy when the input data is subjected to feature selection based on sensitivity analysis.},
booktitle = {2019 IEEE International Conference on Mechatronics and Automation (ICMA)},
pages = {2195–2200},
numpages = {6},
location = {Tianjin, China}
}

@article{10.1155/2021/6805151,
author = {Alsamhi, Saeed H. and Almalki, Faris A. and Al-Dois, Hatem and Ben Othman, Soufiene and Hassan, Jahan and Hawbani, Ammar and Sahal, Radyah and Lee, Brian and Saleh, Hager and Khalil, Ahmed Mostafa},
title = {Machine Learning for Smart Environments in B5G Networks: Connectivity and QoS},
year = {2021},
issue_date = {2021},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2021},
issn = {1687-5265},
url = {https://doi.org/10.1155/2021/6805151},
doi = {10.1155/2021/6805151},
abstract = {The number of Internet of Things (IoT) devices to be connected via the Internet is overgrowing. The heterogeneity and complexity of the IoT in terms of dynamism and uncertainty complicate this landscape dramatically and introduce vulnerabilities. Intelligent management of IoT is required to maintain connectivity, improve Quality of Service (QoS), and reduce energy consumption in real time within dynamic environments. Machine Learning (ML) plays a pivotal role in QoS enhancement, connectivity, and provisioning of smart applications. Therefore, this survey focuses on the use of ML for enhancing IoT applications. We also provide an in-depth overview of the variety of IoT applications that can be enhanced using ML, such as smart cities, smart homes, and smart healthcare. For each application, we introduce the advantages of using ML. Finally, we shed light on ML challenges for future IoT research, and we review the current literature based on existing works.},
journal = {Intell. Neuroscience},
month = jan,
numpages = {23}
}

@article{10.1016/j.procs.2019.04.094,
author = {Pinto, Riccardo and Cerquitelli, Tania},
title = {Robot fault detection and remaining life estimation for predictive maintenance},
year = {2019},
issue_date = {2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {151},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2019.04.094},
doi = {10.1016/j.procs.2019.04.094},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {709–716},
numpages = {8},
keywords = {robot fault forecasting, data analytics, machine learning, Industry 4.0}
}

@inproceedings{10.1145/3382494.3410681,
author = {Serban, Alex and van der Blom, Koen and Hoos, Holger and Visser, Joost},
title = {Adoption and Effects of Software Engineering Best Practices in Machine Learning},
year = {2020},
isbn = {9781450375801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382494.3410681},
doi = {10.1145/3382494.3410681},
abstract = {Background. The increasing reliance on applications with machine learning (ML) components calls for mature engineering techniques that ensure these are built in a robust and future-proof manner.Aim. We aim to empirically determine the state of the art in how teams develop, deploy and maintain software with ML components.Method. We mined both academic and grey literature and identified 29 engineering best practices for ML applications. We conducted a survey among 313 practitioners to determine the degree of adoption for these practices and to validate their perceived effects. Using the survey responses, we quantified practice adoption, differentiated along demographic characteristics, such as geography or team size. We also tested correlations and investigated linear and non-linear relationships between practices and their perceived effect using various statistical models.Results. Our findings indicate, for example, that larger teams tend to adopt more practices, and that traditional software engineering practices tend to have lower adoption than ML specific practices. Also, the statistical models can accurately predict perceived effects such as agility, software quality and traceability, from the degree of adoption for specific sets of practices. Combining practice adoption rates with practice importance, as revealed by statistical models, we identify practices that are important but have low adoption, as well as practices that are widely adopted but are less important for the effects we studied.Conclusion. Overall, our survey and the analysis of responses received provide a quantitative basis for assessment and step-wise improvement of practice adoption by ML teams.},
booktitle = {Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {3},
numpages = {12},
keywords = {survey, machine learning engineering, best practices},
location = {Bari, Italy},
series = {ESEM '20}
}

@article{10.1016/j.eswa.2017.05.020,
author = {Oliveira, Jos Carlos M. and Pontes, Karen V. and Sartori, Isabel and Embiruu, Marcelo},
title = {Fault Detection and Diagnosis in dynamic systems using Weightless Neural Networks},
year = {2017},
issue_date = {October 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {84},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2017.05.020},
doi = {10.1016/j.eswa.2017.05.020},
abstract = {Weightless Neural Networks for Fault Detection and Diagnosis in dynamic systems.Several methods for data pre-processing (input patterns mapping) are evaluated.Attributes selection per class to pre-processing multivariate data.The importance of counting and bleaching in classification is shown.Successful Fault Detection and Diagnosis systems with accuracies around 99%. This work examines Fault Detection and Diagnosis (FDD) based on Weightless Neural Networks (WNN) with applications in univariate and multivariate dynamic systems. WNN use neurons based on RAM (Random Access Memory) devices. These networks use fast and flexible learning algorithms, which provide accurate and consistent results, without the need for residual generation or network retraining, and therefore they have great potential use for pattern recognition and classification (Ludermir, Carvalho, Braga, de Souto, 1999). The proposed system firstly executes the selection of attributes (in the multivariable case) and does the time series mapping of the data. In the intermediate stage, the WNN performs the detection and diagnosis per class. The network outputs are then passed through a clustering filter in the final stage of the system, if a diagnosis per fault groups is necessary. The system was tested with two case studies: one was an actual application for the temperature monitoring of a sales gas compressor in a natural gas processing unit; and the other one uses simulated data for an industrial plant, known in the literature as Tennessee Eastman Process. The results show the efficiency of the proposed systems for FDD with classification accuracies of up to 98.78% and 99.47% for the respective applications.},
journal = {Expert Syst. Appl.},
month = oct,
pages = {200–219},
numpages = {20},
keywords = {yOutput of the weightless neural net with value equal to a class label, xtInput pattern x in instant t, xInput pattern for the system, wInput pattern for the weightless neural net, tPertinence degree of the attribute i for the input pattern xt, tDeviation attribute i in relation to the current input pattern xt, tAttribute n of the input pattern xt, rRAM number of a discriminator, qPhase in which the RAM node is runing: learning or test, pNumber of bits of the vector of inputs for the RAM, pInput RAM node, nt(Dhf)Training in the class discriminator with the highest number of patterns, nDimensionality of input vectors for the used application, maxSecond highest score obtained by one of the discriminators of the WiSARD net, kQuantity of discriminators in the WiSARD net, kNNk-Nearest Neighbour, hHorizon of the processed time window, f(x)Function that defines approximately the limits for the classes considered, dai, dTerminal containing required output value, cValue that represents the importance of the attribute i for class c, cAttribute position i in class c, atInput atttribute in instant t, an, aiAverage attribute of the t values of the processed series for attribute i, ai, ahOriginal series attribute in period h, WiSARDWilkes-Stonham-Aleksander Recognition Device, Weightless Neural Networks, WNNWeightless Neural Network, WAdjustment coefficient belonging to the interval 0<w<1, vi,="" time="" series,="" ttotal="" population,="" tptrue="" positive,="" tprtrue="" positive="" rate,="" tntrue="" negative,="" tnrtrue="" negative="" teptennessee="" eastman="" process,="" states="" with="" systematic="" deviations="" in="" relation="" to="" the="" normal="" operation="" value,="" standard="" deviation="" of="" t="" values="" processed="" spcspecificity,="" spcamsmultiscale="" pca="" similarity="" factor,="" spasuccessive="" projections="" algorithm,="" sgcsale="" gas="" compressor,="" sessimple="" exponential="" smoothing,="" ri,="" rewpunreward="" punishment,="" recireward="" for="" attribute="" i,="" reagents="" used="" tep,="" rpireward="" and="" punishment="" ramrandom="" access="" memories,="" qdaquadratic="" discriminant="" analysis,="" punipunishment="" possible="" conventional="" bleaching,="" pmaxmaximum="" score="" obtained="" by="" one="" discriminators="" wisard="" net,="" petrobraspetrleo="" brasileiro="" s.a.,="" pwpattern="" wisard,="" pprevalence,="" ppvpositive="" predictive="" plspartial="" least="" squares,="" pimsplant="" information="" management="" system,="" p2,="" nstate="" sensor="" operation,="" npvnegative="" ngpunatural="" processing="" unit,="" ncnumber="" classes,="" natotal="" number="" attributes="" data="" set,="" mtsmultivariate="" mspcamulti-scale="" principal="" component="" mkmarkedness,="" mccmatthews="" correlation="" coefficient,="" lrnegative="" likelihood="" ratio,="" lr+positive="" ldalinear="" ivector="" inputs="" ram,="" htahigh="" temperature="" alarm,="" hhtahigh="" high="" gh,="" gagenetic="" fjfault="" pattern="" type="" j,="" final="" products="" fault="" detection="" diagnosis,="" fprfalse="" fpfalse="" forfalse="" omission="" fnrfalse="" fnfalse="" fdrfalse="" discovery="" fddfault="" fcmfuzzy="" c-means,="" fbyproduct="" generated="" f1f1="" score,="" ehvalue="" series="" adjusted="" period="" h,="" eh-1value="" h1,="" e,="" disckdiscriminator="" k,="" dordiagnostic="" odds="" d1d2,="" d,="" cwconfidence="" level="" net="" recognition="" a="" w,="" c[i]memory="" position="" accesssed="" vector="" cwcounting="" cpcondition="" cncondition="" negatives,="" brazil,="" bmbookmaker="" informedness,="" binert="" bastate="" bahia,="" b6state="" broken="" instrument="" readings="" oscillating="" around="" near="" 200c,="" b5state="" 0c,="" b4state="" partially="" b3state="" reduced="" background="" scale="" (0c),="" b2state="" binary="" oscillation="" between="" 0="" b1state="" on="" top="" (200c),="" arithmetic="" mean="" annartificial="" neural="" anfisadaptive="" neuro-fuzzy="" inference="" accaccuracy,="" ac}="" }<="" div="">
  </w<1,>

@article{10.1007/s00034-020-01572-x,
author = {Srimani, Supriyo and Parai, Manas and Ghosh, Kasturi and Rahaman, Hafizur},
title = {A Statistical Approach of Analog Circuit Fault Detection Utilizing Kolmogorov–Smirnov Test Method},
year = {2021},
issue_date = {May 2021},
publisher = {Birkhauser Boston Inc.},
address = {USA},
volume = {40},
number = {5},
issn = {0278-081X},
url = {https://doi.org/10.1007/s00034-020-01572-x},
doi = {10.1007/s00034-020-01572-x},
abstract = {This work presents a testing technique based on ‘Kolmogorov–Smirnov’ (K–S) test for detection of parametric faults in analog circuits. The proposed method is a time-domain signal processing technique that compares the statistical similarity in terms of ‘Empirical Cumulative Distribution Function’ (ECDF) of the outputs of the circuit when the input of the circuit is a random analog signal. ‘Multivariate Adaptive Regression Splines’ (MARS) technique is used to map the tolerances of functional metrics to the components of the circuit under test (CUT). Two benchmark circuits, i.e., second-order Sallen–Key band-pass filter and weakly nonlinear cascade amplifier are tested to validate the proposed fault detection technique. The proposed statistical approach with the use of random analog signal as input excitation results reduction of complexity for designing input test signal and increases fault coverage in the analog circuit testing. The proposed method is testified experimentally for Sallen–Key band-pass filter. The experimental results are in good agreement with the simulated results.},
journal = {Circuits Syst. Signal Process.},
month = may,
pages = {2091–2113},
numpages = {23},
keywords = {Component tolerance, Multivariate Adaptive Regression Splines (MARS), Kolmogorov–Smirnov test (K–S test), Parametric fault}
}

@inproceedings{10.1145/3234804.3234817,
author = {Nazari, Zahra and Yu, Seong-Mi and Kang, Dongshik and Kawachi, Yousuke},
title = {Comparative Study of Outlier Detection Algorithms for Machine Learning},
year = {2018},
isbn = {9781450364737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234804.3234817},
doi = {10.1145/3234804.3234817},
abstract = {Outliers are unusual data points which are inconsistent with other observations. Human error, mechanical faults, fraudulent behavior, instrument error, and changes in the environment are some reasons to arise outliers. Several types of outlier detection algorithms are developed and a number of surveys and overviews are performed to distinguish their advantages and disadvantages. Multivariate outlier detection algorithms are widely used among other types, therefore we concentrate on this type. In this work a comparison between effects of multivariate outlier detection algorithms on machine learning problems is performed. For this purpose, three multivariate outlier detection algorithms namely distance based, statistical based and clustering based are evaluated. Benchmark datasets of Heart disease, Breast cancer and Liver disorder are used for the experiments. To identify the effectiveness of mentioned algorithms, the above datasets are classified by Support Vector Machines (SVM) before and after outlier detection. Finally a comparative review is performed to distinguish the advantages and disadvantages of each algorithm and their respective effects on accuracy of SVM classifiers.},
booktitle = {Proceedings of the 2018 2nd International Conference on Deep Learning Technologies},
pages = {47–51},
numpages = {5},
keywords = {Support Vector Machines, Outlier Detection, Machine Learning},
location = {Chongqing, China},
series = {ICDLT '18}
}

@article{10.1504/ijics.2021.114711,
author = {Saraf, Iqra and Shrivastava, A.K. and Iqbal, Javaid},
title = {Effort-based fault detection and correction modelling for multi release of software},
year = {2021},
issue_date = {2021},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {14},
number = {3–4},
issn = {1744-1765},
url = {https://doi.org/10.1504/ijics.2021.114711},
doi = {10.1504/ijics.2021.114711},
abstract = {Most works on SRGMs in a unified multi release approach has been done using calendar time. Not much heed is given to consumption pattern of various testing resources. Due to stiff market rivalry, developers need to develop latest versions of software in multiple releases. Apart from being beneficial, it also turns to be challengeable as revision in the code creates hindrances in updating the software. Testers may find it difficult to rectify a detected fault resulting in imperfect debugging or error generation. Testing phase is affected by many factors which may change at any time, a concept called as change point. In this work, we propose detection and correction-based general scheme for modelling multi-release of software under the realistic environment of imperfect debugging, error generation, change point and testing effort. Parameter estimation has been done on Tandem data and SRGMs have been ranked using distance-based approach.},
journal = {Int. J. Inf. Comput. Secur.},
month = jan,
pages = {354–379},
numpages = {25},
keywords = {DBA, distance-based approach, multi release, nonlinear regression, TEF, testing effort function, NHPP, non-homogenous Poisson process, SRGM, software reliability growth model, MVF, mean value function, imperfect debugging}
}

@article{10.1007/s10270-020-00856-9,
author = {Pilarski, Sebastian and Staniszewski, Martin and Bryan, Matthew and Villeneuve, Frederic and Varr\'{o}, D\'{a}niel},
title = {Predictions-on-chip: model-based training and automated deployment of machine learning models at runtime: For multi-disciplinary design and operation of gas turbines},
year = {2021},
issue_date = {Jun 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {20},
number = {3},
issn = {1619-1366},
url = {https://doi.org/10.1007/s10270-020-00856-9},
doi = {10.1007/s10270-020-00856-9},
abstract = {The design of gas turbines is a challenging area of cyber-physical systems where complex model-based simulations across multiple disciplines (e.g., performance, aerothermal) drive the design process. As a result, a continuously increasing amount of data is derived during system design. Finding new insights in such data by exploiting various machine learning (ML) techniques is a promising industrial trend since better predictions based on real data result in substantial product quality improvements and cost reduction. This paper presents a method that generates data from multi-paradigm simulation tools, develops and trains ML models for prediction, and deploys such prediction models into an active control system operating at runtime with limited computational power. We explore the replacement of existing traditional prediction modules with ML counterparts with different architectures. We validate the effectiveness of various ML models in the context of three (real) gas turbine bearings using over 150,000 data points for training, validation, and testing. We introduce code generation techniques for automated deployment of neural network models to industrial off-the-shelf programmable logic controllers.},
journal = {Softw. Syst. Model.},
month = jun,
pages = {685–709},
numpages = {25},
keywords = {Gas turbine engines, Code generation, Automated deployment, Neural networks, Machine learning, Prediction-at-runtime}
}

@article{10.3233/JIFS-189587,
author = {Wen, Bor-Jiunn and Lin, Yung-Sheng and Tu, Hsing-Min and Hsieh, Cheng-Chang and Hsieh, Wen-Hsiang},
title = {Health-diagnosis of electromechanical system with a principal-component bayesian neural network algorithm},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {4},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-189587},
doi = {10.3233/JIFS-189587},
abstract = {This study proposes a cloud tele-measurement technique on an electromechanical system, and uses a neural network algorithm based on principal-component analysis (PCA) to quickly diagnose its performance. Three vibration, three temperature, electrical voltage, and current sensors were mounted on the electromechanical system, and the external braking device was used to provide different load-states to simulate the operating states of the motor under different conditions. Moreover, a single-chip multiprocessor was used through the sensor to instantly measure the various load-state simulations of the motor. The operating states of the electromechanical system were classified as normal, abnormal, and required-to-be-turned-off states using a principal-component Bayesian neural network algorithm (PBNNA), to enable their quick diagnosis. Furthermore, PBNNA successfully reduces the dimensionality of the multivariate dataset for rapid analysis of the electromechanical system’s performance. The accuracy rates of health-diagnosis based on the Bayesian neural network algorithm and PBNNA models were obtained as 97.7% and 98%, respectively. Finally, the single-chip multiprocessor based on PBNNA is used to automatically upload the measurement and analysis results of the electromechanical system to the cloud website server. The establishment of this model system can optimize prediction judgment and decision-making based on the damage situation to achieve the goals of intelligence and optimization of factory reconstruction.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {7671–7680},
numpages = {10},
keywords = {Tele-measurement, electromechanical system, principal-component bayesian neural network algorithm, health-diagnosis, cloud website server}
}

@inproceedings{10.1109/ICSE-Companion52605.2021.00066,
author = {Wan, Chengcheng and Liu, Shicheng and Hoffmann, Henry and Maire, Michael and Lu, Shan},
title = {A replication of are machine learning cloud APIs used correctly},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion52605.2021.00066},
doi = {10.1109/ICSE-Companion52605.2021.00066},
abstract = {This artifact aims to provide benchmark suite, data, and script used in our study "Are Machine Learning Cloud APIs Used Correctly?". We collected a suite of 360 non-trivial applications that use ML cloud APIs for manual study. We also developed checkers and tool to detect and fix API mis-uses. We hope this artifact can motivate and help future research to further tackle ML API mis-uses. All related data are available online.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings},
pages = {158–159},
numpages = {2},
location = {Virtual Event, Spain},
series = {ICSE '21}
}

@article{10.1007/s11390-020-0323-7,
author = {Mhawish, Mohammad Y. and Gupta, Manjari},
title = {Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics},
year = {2020},
issue_date = {Nov 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {35},
number = {6},
issn = {1000-9000},
url = {https://doi.org/10.1007/s11390-020-0323-7},
doi = {10.1007/s11390-020-0323-7},
abstract = {Code smell detection is essential to improve software quality, enhancing software maintainability, and decrease the risk of faults and failures in the software system. In this paper, we proposed a code smell prediction approach based on machine learning techniques and software metrics. The local interpretable model-agnostic explanations (LIME) algorithm was further used to explain the machine learning model’s predictions and interpretability. The datasets obtained from Fontana et al. were reformed and used to build binary-label and multi-label datasets. The results of 10-fold cross-validation show that the performance of tree-based algorithms (mainly Random Forest) is higher compared with kernel-based and network-based algorithms. The genetic algorithm based feature selection methods enhance the accuracy of these machine learning algorithms by selecting the most relevant features in each dataset. Moreover, the parameter optimization techniques based on the grid search algorithm significantly enhance the accuracy of all these algorithms. Finally, machine learning techniques have high potential in predicting the code smells, which contribute to detect these smells and enhance the software’s quality.},
journal = {J. Comput. Sci. Technol.},
month = nov,
pages = {1428–1445},
numpages = {18},
keywords = {parameter optimization, prediction explanation, feature selection, code smell detection, code smell}
}

@article{10.1007/s00521-019-04644-5,
author = {Huang, Jui-Chan and Ko, Kuo-Min and Shu, Ming-Hung and Hsu, Bi-Min},
title = {Application and comparison of several machine learning algorithms and their integration models in regression problems},
year = {2020},
issue_date = {May 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {10},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-019-04644-5},
doi = {10.1007/s00521-019-04644-5},
abstract = {With the rapid development of machine learning technology, as a regression problem that helps people to find the law from the massive data to achieve the prediction effect, more and more people pay attention. Data prediction has become an important part of people’s daily life. Currently, the technology is widely used in many fields such as weather forecasting, medical diagnosis and financial forecasting. Therefore, the research of machine learning algorithms in regression problems is a research hotspot in the field of machine learning in recent years. However, real-world regression problems often have very complex internal and external factors, and various machine learning algorithms have different effects on scalability and predictive performance. In order to better study the application effect of machine learning algorithm in regression problem, this paper mainly adopts three common machine learning algorithms: BP neural network, extreme learning machine and support vector machine. Then, by comparing the effects of the single model and integrated model of these machine learning algorithms in the application of regression problems, the advantages and disadvantages of each machine learning algorithm are studied. Finally, the performance of each machine learning algorithm in regression prediction is verified by simulation experiments on four different data sets. The results show that the research on several machine learning algorithms and their integration models has certain feasibility and rationality.},
journal = {Neural Comput. Appl.},
month = may,
pages = {5461–5469},
numpages = {9},
keywords = {Support vector machine, Extreme learning machine, BP neural network, Regression problem, Machine learning}
}

@article{10.1007/s11219-012-9180-0,
author = {\c{C}al\i{}kl\i{}, G\"{u}l and Bener, Ay\c{s}e Ba\c{s}ar},
title = {Influence of confirmation biases of developers on software quality: an empirical study},
year = {2013},
issue_date = {June      2013},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {21},
number = {2},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-012-9180-0},
doi = {10.1007/s11219-012-9180-0},
abstract = {The thought processes of people have a significant impact on software quality, as software is designed, developed and tested by people. Cognitive biases, which are defined as patterned deviations of human thought from the laws of logic and mathematics, are a likely cause of software defects. However, there is little empirical evidence to date to substantiate this assertion. In this research, we focus on a specific cognitive bias, confirmation bias, which is defined as the tendency of people to seek evidence that verifies a hypothesis rather than seeking evidence to falsify a hypothesis. Due to this confirmation bias, developers tend to perform unit tests to make their program work rather than to break their code. Therefore, confirmation bias is believed to be one of the factors that lead to an increased software defect density. In this research, we present a metric scheme that explores the impact of developers' confirmation bias on software defect density. In order to estimate the effectiveness of our metric scheme in the quantification of confirmation bias within the context of software development, we performed an empirical study that addressed the prediction of the defective parts of software. In our empirical study, we used confirmation bias metrics on five datasets obtained from two companies. Our results provide empirical evidence that human thought processes and cognitive aspects deserve further investigation to improve decision making in software development for effective process management and resource allocation.},
journal = {Software Quality Journal},
month = jun,
pages = {377–416},
numpages = {40},
keywords = {Software psychology, Human factors, Defect prediction, Confirmation bias}
}

@inproceedings{10.1145/3443467.3443805,
author = {Lv, XiaoLi and Ni, HongXia},
title = {Smart Fault Detection and Monitoring of Power Line by Drones},
year = {2021},
isbn = {9781450387811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3443467.3443805},
doi = {10.1145/3443467.3443805},
abstract = {In this paper, we introduce a novel automatic power line inspection system based on automatic vision. This system uses UAV inspection as the main inspection method, optical images as the main data source, and deep learning as the backbone of data analysis. To facilitate the implementation of the system, we solve three major challenges of deep learning in vision-based power line inspection: (i) lack of training data; (ii) class imbalance; (iii) detection of small parts and faults. First, we create four medium-sized datasets for training component detection and classification models. Next, we apply a series of effective data enhancement techniques to balance the unbalanced classes. Finally, we propose a multi-stage component detection and classification method based on a single-shot multi-box detector and a deep residual network to detect small components and faults. The results show that the proposed system can quickly and accurately detect common failures of power line components, including the lack of a top cover, cracks on the rod and cross arm, woodpecker damage to the rod, and rot on the cross arm. Field tests show that our system has broad prospects in the Smart monitoring and inspection of power line components and the valuable addition of smart grids.},
booktitle = {Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering},
pages = {501–505},
numpages = {5},
keywords = {Drones, Smart monitoring, deep learning, power line inspection, smart grids, vision-based power line inspection},
location = {Xiamen, China},
series = {EITCE '20}
}

@article{10.1016/j.neucom.2019.09.075,
author = {Zhou, Bingqian and Gu, Xingsheng},
title = {Multi-block statistics local kernel principal component analysis algorithm and its application in nonlinear process fault detection},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {376},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.09.075},
doi = {10.1016/j.neucom.2019.09.075},
journal = {Neurocomput.},
month = feb,
pages = {222–231},
numpages = {10},
keywords = {Fault detection, Bayesian strategy analysis, Statistics pattern analysis, Local KPCA, Multi-block}
}

@article{10.1177/1094342016684006,
author = {Altenbernd, Mirco and G\"{o}ddeke, Dominik},
title = {Soft fault detection and correction for multigrid},
year = {2018},
issue_date = {11 2018},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {32},
number = {6},
issn = {1094-3420},
url = {https://doi.org/10.1177/1094342016684006},
doi = {10.1177/1094342016684006},
abstract = {We introduce a novel algorithm-based fault-tolerance scheme to detect and repair soft transient faults silent data corruption, bitflips in multigrid solvers: by applying the full approximation scheme FAS variant of multigrid to linear systems, we prove invariants that enable fault detection and correction, and ultimately lead to a black-box protection of the smoothing stage. A statistical analysis for a wide range of prototypical problems demonstrates the efficiency of our approach, especially compared with full checksum protection. In particular, the overhead of our new method is negligible in the fault-free case, since we only employ readily available quantities.},
journal = {Int. J. High Perform. Comput. Appl.},
month = nov,
pages = {897–912},
numpages = {16},
keywords = {robust multigrid, robust iterative solvers, resilience, high-performance computing, Fault tolerance}
}

@article{10.1016/j.neucom.2016.09.076,
author = {Yan, Ke and Ji, Zhiwei and Shen, Wen},
title = {Online fault detection methods for chillers combining extended kalman filter and recursive one-class SVM},
year = {2017},
issue_date = {March 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {228},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2016.09.076},
doi = {10.1016/j.neucom.2016.09.076},
abstract = {Automatic, accurate and online fault detection of heating ventilation air conditioning (HVAC) subsystems, such as chillers, is highly demanded in building management system (BMS) to prevent energy waste and high maintenance cost. However, most fault detection techniques require rich faulty training data which is usually unavailable. In this study, a novel hybrid method is proposed to detect faults for chiller subsystems without any faulty training data available, i.e. by training the normal data only. A hybrid feature selection algorithm is applied to the chiller dataset collected by ASHRAE project 1043-RP to select the most significant feature variables. An online classification framework is introduced by combining an Extended Kalman Filter (EKF) model and a recursive one-class support vector machine (ROSVM). Experiment results show that the proposing algorithm detects typical chiller faults with high accuracy rates and requires less feature variables compared to existing works.},
journal = {Neurocomput.},
month = mar,
pages = {205–212},
numpages = {8},
keywords = {One-class support vector machine, Fault detection, Extended kalman filter, Chiller}
}

@inproceedings{10.1109/RELENG.2015.12,
author = {Cavezza, Davide Giacomo and Pietrantuono, Roberto and Russo, Stefano},
title = {Performance of Defect Prediction in Rapidly Evolving Software},
year = {2015},
isbn = {9781467370707},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/RELENG.2015.12},
doi = {10.1109/RELENG.2015.12},
abstract = {Defect prediction techniques allow spotting modules (or commits) likely to contain (introduce) a defect by training models with product or process metrics--thus supporting testing, code integration, and release decisions. When applied to processes where software changes rapidly, conventional techniques might fail, as trained models are not thought to evolve along with the software. In this study, we analyze the performance of defect prediction in rapidly evolving software. Framed in a high commit frequency context, we set up an approach to continuously refine prediction models by using new commit data, and predict whether or not an attempted commit is going to introduce a bug. An experiment is set up on the Eclipse JDT software to assess the prediction ability trend. Results enable to leverage defect prediction potentials in modern development paradigms with short release cycle and high code variability.},
booktitle = {Proceedings of the 2015 IEEE/ACM 3rd International Workshop on Release Engineering},
pages = {8–11},
numpages = {4},
series = {RELENG '15}
}

@inproceedings{10.1145/3482909.3482911,
author = {Santos, Sebasti\~{a}o and Silveira, Beatriz and Durelli, Vinicius and Durelli, Rafael and Souza, Simone and Delamaro, Marcio},
title = {On Using Decision Tree Coverage Criteria forTesting Machine Learning Models},
year = {2021},
isbn = {9781450385039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3482909.3482911},
doi = {10.1145/3482909.3482911},
abstract = {Over the past decade, there has been a growing interest in applying machine learning (ML) to address a myriad of tasks. Owing to this interest, the adoption of ML-based systems has gone mainstream. However, this widespread adoption of ML-based systems poses new challenges for software testers that must improve the quality and reliability of these ML-based solutions. To cope with the challenges of testing ML-based systems, we propose novel test adequacy criteria based on decision tree models. Differently from the traditional approach to testing ML models, which relies on manual collection and labelling of data, our criteria leverage the internal structure of decision tree models to guide the selection of test inputs. Thus, we introduce decision tree coverage (DTC) and boundary value analysis (BVA) as approaches to systematically guide the creation of effective test data that exercises key structural elements of a given decision tree model. To evaluate these criteria, we carried out an experiment using 12 datasets. We measured the effectiveness of test inputs in terms of the difference in model’s behavior between the test input and the training data. The experiment results indicate that our testing criteria can be used to guide the generation of effective test data.},
booktitle = {Proceedings of the 6th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {1–9},
numpages = {9},
keywords = {Testing Criterion, Software Testing, Decision Tree},
location = {Joinville, Brazil},
series = {SAST '21}
}

@inproceedings{10.1109/ISSRE.2014.21,
author = {Herzig, Kim},
title = {Using Pre-Release Test Failures to Build Early Post-Release Defect Prediction Models},
year = {2014},
isbn = {9781479960330},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ISSRE.2014.21},
doi = {10.1109/ISSRE.2014.21},
abstract = {Software quality is one of the most pressing concerns for nearly all software developing companies. At the same time, software companies also seek to shorten their release cycles to meet market demands while maintaining their product quality. Identifying problematic code areas becomes more and more important. Defect prediction models became popular in recent years and many different code and process metrics have been studied. There has been minimal effort relating test executions during development with defect likelihood. This is surprising as test executions capture the stability and quality of a program during the development process. This paper presents an exploratory study investigating whether test execution metrics, e.g. Test failure bursts, can be used as software quality indicators and used to build pre- and post-release defects prediction models. We show that test metrics collected during Windows 8 development can be used to build pre- and post-release defect prediction models early in the development process of a software product. Test metrics outperform pre-release defect counts when predicting post-release defects.},
booktitle = {Proceedings of the 2014 IEEE 25th International Symposium on Software Reliability Engineering},
pages = {300–311},
numpages = {12},
keywords = {software testing, measurement, development process, defect prediction},
series = {ISSRE '14}
}

@inproceedings{10.1109/EUROMICRO.2006.56,
author = {Ceylan, Evren and Kutlubay, F. Onur and Bener, Ayse B.},
title = {Software Defect Identification Using Machine Learning Techniques},
year = {2006},
isbn = {0769525946},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/EUROMICRO.2006.56},
doi = {10.1109/EUROMICRO.2006.56},
abstract = {Software engineering is a tedious job that includes people, tight deadlines and limited budgets. Delivering what customer wants involves minimizing the defects in the programs. Hence, it is important to establish quality measures early on in the project life cycle. The main objective of this research is to analyze problems in software code and propose a model that will help catching those problems earlier in the project life cycle. Our proposed model uses machine learning methods. Principal Component Analysis is used for dimensionality reduction, and Decision Tree, Multi Layer Perceptron and Radial Basis Functions are used for defect prediction. The experiments in this research are carried out with different software metric datasets that are obtained from real-life projects of three big software companies in Turkey. We can say that, the improved method that we proposed brings out satisfactory results in terms of defect prediction.},
booktitle = {Proceedings of the 32nd EUROMICRO Conference on Software Engineering and Advanced Applications},
pages = {240–247},
numpages = {8},
series = {EUROMICRO '06}
}

@article{10.1007/s40595-013-0008-z,
author = {Abaei, Golnoush and Selamat, Ali},
title = {A survey on software fault detection based on different prediction approaches},
year = {2014},
issue_date = {May       2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {1},
number = {2},
issn = {2196-8888},
url = {https://doi.org/10.1007/s40595-013-0008-z},
doi = {10.1007/s40595-013-0008-z},
abstract = {One of the software engineering interests is quality assurance activities such as testing, verification and validation, fault tolerance and fault prediction. When any company does not have sufficient budget and time for testing the entire application, a project manager can use some fault prediction algorithms to identify the parts of the system that are more defect prone. There are so many prediction approaches in the field of software engineering such as test effort, security and cost prediction. Since most of them do not have a stable model, software fault prediction has been studied in this paper based on different machine learning techniques such as decision trees, decision tables, random forest, neural network, Na\"{\i}ve Bayes and distinctive classifiers of artificial immune systems (AISs) such as artificial immune recognition system, CLONALG and Immunos. We use four public NASA datasets to perform our experiment. These datasets are different in size and number of defective data. Distinct parameters such as method-level metrics and two feature selection approaches which are principal component analysis and correlation based feature selection are used to evaluate the finest performance among the others. According to this study, random forest provides the best prediction performance for large data sets and Na\"{\i}ve Bayes is a trustable algorithm for small data sets even when one of the feature selection techniques is applied. Immunos99 performs well among AIS classifiers when feature selection technique is applied, and AIRSParallel performs better without any feature selection techniques. The performance evaluation has been done based on three different metrics such as area under receiver operating characteristic curve, probability of detection and probability of false alarm. These three evaluation metrics could give the reliable prediction criteria together.},
journal = {Vietnam J. of Computer Science},
month = may,
pages = {79–95},
numpages = {17},
keywords = {Software fault prediction, Random forest, Machine learning, CSCA, Artificial immune system, AISParallel}
}

@inproceedings{10.1109/IECON43393.2020.9254467,
author = {Luan, Yu and Zhou, Jianxun and Zhang, Duanjin},
title = {Fault Detection for Delta Operator Systems with Multi-packet Transmission and Limited Communication},
year = {2020},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON43393.2020.9254467},
doi = {10.1109/IECON43393.2020.9254467},
abstract = {In this paper, the fault detection problem for a multi-packet transmission network control system with limited communication and random delay is studied. The communication sequence method is introduced to deal with the limited communication problems in the system, and a multi-packet transmission is equivalent to a Markov jump process. A fault detection filter based on delta domain is established for the system model to generate the residual signal. The residual and fault signals are further used to generate the residual error so that the fault signal can be detected intuitively. Through linear matrix inequality (LMI) method and Lyapunov-Krasinskii stability theory, the designed H&lt;inf&gt;∞&lt;/inf&gt; fault detection filter’s stability conditions are gained. Finally, a numerical simulation example is shown to demonstrate the availability of the proposed method.},
booktitle = {IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society},
pages = {213–218},
numpages = {6},
location = {Singapore, Singapore}
}

@article{10.1002/asjc.1872,
author = {Wang, Guoliang and Gao, Xiangzhou and Miao, Xin and Cao, Yumeng},
title = {Fault Detection for Discrete‐Time Uncertain Systems with Polytopic Uncertainties: A Markov Approach},
year = {2019},
issue_date = {January 2019},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {21},
number = {1},
issn = {1561-8625},
url = {https://doi.org/10.1002/asjc.1872},
doi = {10.1002/asjc.1872},
abstract = {In this paper, the fault detection problem for a class of discrete‐time polytopic uncertain systems is studied. Different from the traditional methods dealing with polytopic uncertainties, not only its values but also the probability distributions are considered. First of all, the above process about polytopic uncertainty is described by applying a Markov process. Then, the original system with polytopic uncertainties becomes to be a Markovian jump system (MJS) without any uncertainty. Accordingly, the fault detection problem is transformed to be a similar one but considered for an MJS. Particularly, the fault detection and isolation (FDI) filter is constructed to be mode‐dependent and also said to be polytope‐dependent. Since more information of uncertainty is considered, it is claimed that the obtained results are less conservative. Finally, a practical example is used to show the effectiveness and superiority of the proposed methods.},
journal = {Asian J. Control},
month = feb,
pages = {277–288},
numpages = {12},
keywords = {linear matrix inequalities (LMI), H∞ filter, fault detection and isolation, Markov jump systems, Polytopic uncertain systems}
}

@inproceedings{10.5555/2040660.2040688,
author = {Wahyudin, Dindin and Ramler, Rudolf and Biffl, Stefan},
title = {A framework for defect prediction in specific software project contexts},
year = {2008},
isbn = {9783642223853},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Software defect prediction has drawn the attention of many researchers in empirical software engineering and software maintenance due to its importance in providing quality estimates and to identify the needs for improvement from project management perspective. However, most defect prediction studies seem valid primarily in a particular context and little concern is given on how to find out which prediction model is well suited for a given project context. In this paper we present a framework for conducting software defect prediction as aid for the project manager in the context of a particular project or organization. The framework has been aligned with practitioners' requirements and is supported by our findings from a systematical literature review on software defect prediction. We provide a guide to the body of existing studies on defect prediction by mapping the results of the systematic literature review to the framework.},
booktitle = {Proceedings of the Third IFIP TC 2 Central and East European Conference on Software Engineering Techniques},
pages = {261–274},
numpages = {14},
keywords = {systematical literature review, software defect prediction, metric-based defect prediction},
location = {Brno, Czech Republic},
series = {CEE-SET'08}
}

@article{10.1016/j.asoc.2007.06.002,
author = {Rajakarunakaran, S. and Venkumar, P. and Devaraj, D. and Rao, K. Surya Prakasa},
title = {Artificial neural network approach for fault detection in rotary system},
year = {2008},
issue_date = {January, 2008},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {8},
number = {1},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2007.06.002},
doi = {10.1016/j.asoc.2007.06.002},
abstract = {The detection and diagnosis of faults in technical systems are of great practical significance and paramount importance for the safe operation of the plant. An early detection of faults may help to avoid product deterioration, performance degradation, major damage to the machinery itself and damage to human health or even loss of lives. The centrifugal pumping rotary system is considered for this research. This paper presents the development of artificial neural network-based model for the fault detection of centrifugal pumping system. The fault detection model is developed by using two different artificial neural network approaches, namely feed forward network with back propagation algorithm and binary adaptive resonance network (ART1). The training and testing data required are developed for the neural network model that were generated at different operating conditions, including fault condition of the system by real-time simulation through experimental model. The performance of the developed back propagation and ART1 model were tested for a total of seven categories of faults in the centrifugal pumping system. The results are compared and the conclusions are presented.},
journal = {Appl. Soft Comput.},
month = jan,
pages = {740–748},
numpages = {9},
keywords = {Rotary system, Neural networks, Fault detection, Back propagation, Adaptive resonance theory}
}

@article{10.1007/s11554-019-00891-w,
author = {Ma, Bin and Wang, Xiaoyu and Li, Qi and Li, Bing and Li, Jian and Wang, Chunpeng and Shi, Yunqing},
title = {Adaptive error prediction method based on multiple linear regression for reversible data hiding},
year = {2019},
issue_date = {August    2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {16},
number = {4},
issn = {1861-8200},
url = {https://doi.org/10.1007/s11554-019-00891-w},
doi = {10.1007/s11554-019-00891-w},
abstract = {To improve the prediction accuracy, this paper proposes an adaptive error prediction method based on multiple linear regression (MLR) algorithm. The MLR matrix function that indicates the inner correlations between the pixels and their neighbors is established adaptively according to the consistency of pixels in local area of a natural image, and thus the objected pixel is predicted accurately with the achieved MLR function that denotes the consistency of the neighboring pixels. Compared with the conventional methods that predict the objected pixel with fixed predictors through simple arithmetic combination of its surroundings pixel, the proposed method can provide a comparatively spare prediction-error image for data embedding, and thus can improve the performance of reversible data hiding. Experimental results show that the proposed method outperforms most state-of-the-art error prediction algorithms.},
journal = {J. Real-Time Image Process.},
month = aug,
pages = {821–834},
numpages = {14},
keywords = {Reversible data hiding (RDH), Prediction accuracy, Multiple linear regression (MLR), Adaptive}
}

@inproceedings{10.1007/978-3-319-92639-1_15,
author = {Alaiz-Moret\'{o}n, H\'{e}ctor and Casteleiro-Roca, Jos\'{e} Luis and Robles, Laura Fern\'{a}ndez and Jove, Esteban and Castej\'{o}n-Limas, Manuel and Calvo-Rolle, Jos\'{e} Luis},
title = {Sensor Fault Detection and Recovery Methodology for a Geothermal Heat Exchanger},
year = {2018},
isbn = {978-3-319-92638-4},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-319-92639-1_15},
doi = {10.1007/978-3-319-92639-1_15},
abstract = {This research addresses a sensor fault detection and recovery methodology oriented to a real system as can be a geothermal heat exchanger installed as part of the heat pump installation at a bioclimatic house. The main aim is to stablish the procedure to detect the anomaly over a sensor and recover the value when it occurs. Therefore, some experiments applying a Multi-layer Perceptron (MLP) regressor, as modelling technique, have been made with satisfactory results in general terms. The correct election of the input variables is critical to get a robust model, specially, those features based on the sensor values on the previous state.},
booktitle = {Hybrid Artificial Intelligent Systems: 13th International Conference, HAIS 2018, Oviedo, Spain, June 20-22, 2018, Proceedings},
pages = {171–184},
numpages = {14},
keywords = {MLP, Fault detection, Recovery, Heat exchanger, Heat pump, Geothermal exchanger},
location = {Oviedo, Spain}
}

@article{10.1007/s00521-018-3911-5,
author = {Mohd Amiruddin, Ahmad Azharuddin Azhari and Zabiri, Haslinda and Taqvi, Syed Ali Ammar and Tufa, Lemma Dendena},
title = {Neural network applications in fault diagnosis and detection: an overview of implementations in engineering-related systems},
year = {2020},
issue_date = {Jan 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {2},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-018-3911-5},
doi = {10.1007/s00521-018-3911-5},
abstract = {The use of artificial neural networks (ANN) in fault detection analysis is widespread. This paper aims to provide an overview on its application in the field of fault identification and diagnosis (FID), as well as the guiding elements behind their successful implementations in engineering-related applications. In most of the reviewed studies, the ANN architecture of choice for FID problem-solving is the multilayer perceptron (MLP). This is likely due to its simplicity, flexibility, and established usage. Its use managed to find footing in a variety of fields in engineering very early on, even before the technology was as polished as it is today. Recurrent neural networks, while having overall stronger potential for solving dynamic problems, are only suggested for use after a simpler implementation in MLP was attempted. Across various ANN applications in FID, it is observed that preprocessing of the inputs is extremely important in obtaining the proper features for use in training the network, particularly when signal analysis is involved. Normalization is practically a standard for ANN use, and likely many other decision-based learning methods due to its ease of use and high impact on speed of convergence. A simple demonstration of ANN’s ease of use in solving a unique FID problem was also shown.},
journal = {Neural Comput. Appl.},
month = jan,
pages = {447–472},
numpages = {26},
keywords = {Data preprocessing, Engineering application, Fault diagnosis, Fault detection, Artificial neural network}
}

@inproceedings{10.1109/ICELMACH.2018.8506796,
author = {Sakaidani, Yo and Kondo, Minoru},
title = {Bearing Fault Detection for Railway Traction Motors Through Leakage Current},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICELMACH.2018.8506796},
doi = {10.1109/ICELMACH.2018.8506796},
abstract = {Many researches on detecting machinery faults in the early stage are being conducted for the purpose of preventing failure and reducing maintenance effort simultaneously. In this paper, a bearing fault detection method for a railway traction motor through leakage currents is proposed. The proposed detection method combines octave band analysis and machine learning. The abnormality simulation experiments with an inner race fault bearing are conducted and the effectiveness of the proposed method is verified. From the experiments, it is confirmed that the proposed method can detect failures of railway traction system well at specific conditions and leakage currents have potentials to be used for a bearing fault detection.},
booktitle = {2018 XIII International Conference on Electrical Machines (ICEM)},
pages = {1768–1774},
numpages = {7},
location = {Alexandroupoli, Greece}
}

@inproceedings{10.1109/CSSS.2012.121,
author = {Miao, Xudong and Lu, Yansheng and Dai, Yao},
title = {Method of Military Software Quality Evaluation Based on Multi-agent Fuzzy Neural Network},
year = {2012},
isbn = {9780769547190},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CSSS.2012.121},
doi = {10.1109/CSSS.2012.121},
abstract = {In allusion to the characteristic of military software, constructs multi-Agent fuzzy neural network military software evaluation system which based on Web environment. Discusses multi-Agent communication and message mechanism, designs military software evaluation metrics system and studies self-adjustability fuzzy neural network quality evaluation model. This method can obviously improve the synchronism, efficiency, scientific and objective.},
booktitle = {Proceedings of the 2012  International Conference on Computer Science and Service System},
pages = {459–462},
numpages = {4},
keywords = {quality evaluation, multi-Agent, military software, fuzzy neural network, Metrics system},
series = {CSSS '12}
}

@article{10.1016/j.engappai.2017.09.008,
author = {Wang, Hong-Qiao and Cai, Yan-Ning and Fu, Guang-Yuan and Wu, Ming and Wei, Zhen-Hua},
title = {Data-driven fault prediction and anomaly measurement for complex systems using support vector probability density estimation},
year = {2018},
issue_date = {January 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {67},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2017.09.008},
doi = {10.1016/j.engappai.2017.09.008},
abstract = {To quantitatively monitor the state of complex system, a data-driven fault prediction and anomaly degree measurement method based on probability density estimation is studied in this paper. First, an anomaly index is introduced and defined to measure the anomaly degree of samples. Then By improving the form of constraint condition, a single slack factor multiple kernel support vector machine probability density estimation model is presented. As a result, the scale of object function and the solution number are all reduced, and the computational efficiency of the presented model is greatly enhanced. On the other hand, as the introduction of multiple kernel functions, a multiple kernel matrix with better data mapping performance is obtained, which can well solve the composite probability density estimation for uncoupled data. The simulation test shows that the presented model has higher estimation precision and speed. The experiments on complex system fault prediction also show that the systems anomaly degree can be quantitatively and accurately measured by the anomaly index gained from the prediction results, which can effectively improve the fault prediction precision and increase the prediction advances.},
journal = {Eng. Appl. Artif. Intell.},
month = jan,
pages = {1–13},
numpages = {13},
keywords = {Support vector machine, Probability density estimation, Fault prediction, Data-driven, Anomaly degree measurement}
}

@inproceedings{10.1109/ASE.2015.56,
author = {Nam, Jaechang and Kim, Sunghun},
title = {CLAMI: defect prediction on unlabeled datasets},
year = {2015},
isbn = {9781509000241},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2015.56},
doi = {10.1109/ASE.2015.56},
abstract = {Defect prediction on new projects or projects with limited historical data is an interesting problem in software engineering. This is largely because it is difficult to collect defect information to label a dataset for training a prediction model. Cross-project defect prediction (CPDP) has tried to address this problem by reusing prediction models built by other projects that have enough historical data. However, CPDP does not always build a strong prediction model because of the different distributions among datasets. Approaches for defect prediction on unlabeled datasets have also tried to address the problem by adopting unsupervised learning but it has one major limitation, the necessity for manual effort.In this study, we propose novel approaches, CLA and CLAMI, that show the potential for defect prediction on unlabeled datasets in an automated manner without need for manual effort. The key idea of the CLA and CLAMI approaches is to label an unlabeled dataset by using the magnitude of metric values. In our empirical study on seven open-source projects, the CLAMI approach led to the promising prediction performances, 0.636 and 0.723 in average f-measure and AUC, that are comparable to those of defect prediction based on supervised learning.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering},
pages = {452–463},
numpages = {12},
location = {Lincoln, Nebraska},
series = {ASE '15}
}

@article{10.1007/s00500-020-05348-y,
author = {EL Mazgualdi, Choumicha and Masrour, Tawfik and El Hassani, Ibtissam and Khdoudi, Abdelmoula},
title = {Machine learning for KPIs prediction: a case study of the overall equipment effectiveness within the automotive industry},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {25},
number = {4},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-020-05348-y},
doi = {10.1007/s00500-020-05348-y},
abstract = {Key performance indicators are tools for management, decision support and forecasting; they reflect the strategy and vision of the company in terms of objectives and allow to always staying in step with the expectations of the stakeholders. Accurate forecasting of the indicators allows decisions to be reoriented to ensure performance optimization while reducing both cost and effort. This paper aims to apply different machine learning methods, namely support vector regression, optimized support vector regression (using genetic algorithm), random forest, extreme gradient boosting and deep learning to predict the overall equipment effectiveness as a case study. We will make use of several configurations of the listed models in order to provide a wide field of comparison. The data used to train our models were provided by an automotive cable production industry. The result shows that the configuration in which we used cross-validation technique, and we performed a duly splitting of data, provides predictor models with the better performances.},
journal = {Soft Comput.},
month = feb,
pages = {2891–2909},
numpages = {19},
keywords = {Improvement, Prediction, Overall equipment effectiveness, Key performance indicators, Machine learning}
}

@inproceedings{10.1007/978-3-030-86475-0_15,
author = {Azimi, Shelernaz and Pahl, Claus},
title = {The Effect of IoT Data Completeness and Correctness on Explainable Machine Learning Models},
year = {2021},
isbn = {978-3-030-86474-3},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-86475-0_15},
doi = {10.1007/978-3-030-86475-0_15},
abstract = {Many systems in the Edge Cloud, the Internet-of-Things or Cyber-Physical Systems are built for processing data, which is delivered from sensors and devices, transported, processed and consumed locally by actuators. This, given the regularly high volume of data, permits Artificial Intelligence (AI) strategies like Machine Learning (ML) to be used to generate the application and management functions needed. The quality of both source data and machine learning model is here unavoidably of high significance, yet has not been explored sufficiently as an explicit connection of the ML model quality that are created through ML procedures to the quality of data that the model functions consume in their construction. Here, we investigated the link between input data quality for ML function construction and the quality of these functions in data-driven software systems towards explainable model construction through an experimental approach with IoT Data using decision trees. We have 3 objectives in this research: 1. Search for indicators that influence data quality such as correctness and completeness and model construction factors on accuracy, precision and recall. 2. Estimate the impact of variations in model construction and data quality. 3. Identify change patterns that can be attributed to specific input changes.},
booktitle = {Database and Expert Systems Applications: 32nd International Conference, DEXA 2021, Virtual Event, September 27–30, 2021, Proceedings, Part II},
pages = {151–160},
numpages = {10},
keywords = {Explainable AI, Data quality, IoT systems, Machine learning, Data correctness, Data completeness, Decision trees}
}

@inproceedings{10.1109/ICSE43902.2021.00033,
author = {Tang, Yiming and Khatchadourian, Raffi and Bagherzadeh, Mehdi and Singh, Rhia and Stewart, Ajani and Raja, Anita},
title = {An Empirical Study of Refactorings and Technical Debt in Machine Learning Systems},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00033},
doi = {10.1109/ICSE43902.2021.00033},
abstract = {Machine Learning (ML), including Deep Learning (DL), systems, i.e., those with ML capabilities, are pervasive in today's data-driven society. Such systems are complex; they are comprised of ML models and many subsystems that support learning processes. As with other complex systems, ML systems are prone to classic technical debt issues, especially when such systems are long-lived, but they also exhibit debt specific to these systems. Unfortunately, there is a gap of knowledge in how ML systems actually evolve and are maintained. In this paper, we fill this gap by studying refactorings, i.e., source-to-source semantics-preserving program transformations, performed in real-world, open-source software, and the technical debt issues they alleviate. We analyzed 26 projects, consisting of 4.2 MLOC, along with 327 manually examined code patches. The results indicate that developers refactor these systems for a variety of reasons, both specific and tangential to ML, some refactorings correspond to established technical debt categories, while others do not, and code duplication is a major crosscutting theme that particularly involved ML configuration and model code, which was also the most refactored. We also introduce 14 and 7 new ML-specific refactorings and technical debt categories, respectively, and put forth several recommendations, best practices, and anti-patterns. The results can potentially assist practitioners, tool developers, and educators in facilitating long-term ML system usefulness.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {238–250},
numpages = {13},
keywords = {technical debt, software repository mining, refactoring, machine learning systems, empirical studies},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1016/j.eswa.2017.05.079,
author = {Manco, Giuseppe and Ritacco, Ettore and Rullo, Pasquale and Gallucci, Lorenzo and Astill, Will and Kimber, Dianne and Antonelli, Marco},
title = {Fault detection and explanation through big data analysis on sensor streams},
year = {2017},
issue_date = {November 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {87},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2017.05.079},
doi = {10.1016/j.eswa.2017.05.079},
abstract = {Analysis of event-based monitoring of complex systems for predictive maintenance.An unsupervised technique for early detection of faults from diagnostic data.A method for characterizing failures and distinguish them from normal behavior. Fault prediction is an important topic for the industry as, by providing effective methods for predictive maintenance, allows companies to perform important time and cost savings. In this paper we describe an application developed to predict and explain door failures on metro trains. To this end, the aim was twofold: first, devising prediction techniques capable of early detecting door failures from diagnostic data; second, describing failures in terms of properties distinguishing them from normal behavior. Data pre-processing was a complex task aimed at overcoming a number of issues with the dataset, like size, sparsity, bias, burst effect and trust. Since failure premonitory signals did not share common patterns, but were only characterized as non-normal device signals, fault prediction was performed by using outlier detection. Fault explanation was finally achieved by exhibiting device features showing abnormal values. An experimental evaluation was performed to assess the quality of the proposed approach. Results show that high-degree outliers are effective indicators of incipient failures. Also, explanation in terms of abnormal feature values (responsible for outlierness) seems to be quite expressive.There are some aspects in the proposed approach that deserve particular attention. We introduce a general framework for the failure detection problem based on an abstract model of diagnostic data, along with a formal problem statement. They both provide the basis for the definition of an effective data pre-processing technique where the behavior of a device, in a given time frame, is summarized through a number of suitable statistics. This approach strongly mitigates the issues related to data errors/noise, thus enabling to perform an effective outlier detection. All this, in our view, provides the grounds of a general methodology for advanced prognostic systems.},
journal = {Expert Syst. Appl.},
month = nov,
pages = {141–156},
numpages = {16},
keywords = {Sensor data, Outlier explanation, Fault detection, Big data, Anomaly detection}
}

@article{10.1007/s10462-019-09760-1,
author = {Hassanien, Aboul Ella and Darwish, Ashraf and Abdelghafar, Sara},
title = {Machine learning in telemetry data mining of space mission: basics, challenging and future directions},
year = {2020},
issue_date = {Jun 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {53},
number = {5},
issn = {0269-2821},
url = {https://doi.org/10.1007/s10462-019-09760-1},
doi = {10.1007/s10462-019-09760-1},
abstract = {The development of an intelligent artificial satellite health monitoring system is a key issue in aerospace engineering that determines satellite health status and failure using telemetry data. The modern design of data mining and machine learning technologies allows the use of satellite telemetry data and the mining of integrated information to produce an advanced health monitoring system. This paper reviews the current status and presents a framework of necessary processes on data mining to solving various problems in telemetry data such as error detection, prediction, summarization, and visualization of large quantities, and help them understand the health status of the satellite and detect the symptoms of anomalies. Machine learning technologies that include neural networks, fuzzy sets, rough sets, support vector machines, Naive Bayesian, swarm optimization, and deep learning are also presented. Also, this paper reviews a wide range of existing satellite health monitoring solutions and discusses them in the framework of remote data mining techniques. In addition, we are discussing the analysis of space debris flow analysis and the prediction of low earth orbit collision based on our orbital Petri nets model. Challenges to be addressed and future directions of research are identified and an extensive bibliography is also included.},
journal = {Artif. Intell. Rev.},
month = jun,
pages = {3201–3230},
numpages = {30},
keywords = {Aerospace engineering, Debris, Deep learning, Machine learning, Satellite ground control operations, Satellite health monitoring, Satellite telemetry data mining}
}

@inproceedings{10.1007/978-3-030-59854-9_1,
author = {Smirni, Evgenia},
title = {Machine Learning for Reliability Analysis of Large Scale Systems},
year = {2020},
isbn = {978-3-030-59853-2},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-59854-9_1},
doi = {10.1007/978-3-030-59854-9_1},
abstract = {As distributed systems dramatically grow in terms of scale, complexity, and usage, understanding the hidden interactions among system and workload properties becomes an exceedingly difficult task. Machine learning models for prediction of system behavior (and analysis) are increasingly popular but their effectiveness in answering what and why is not always the most favorable. In this talk I will present two reliability analysis studies from two large, distributed systems: one that looks into GPGPU error prediction at the Titan, a large scale high-performance-computing system at ORNL, and one that analyzes the failure characteristics of solid state drives at a Google data center and hard disk drives at the Backblaze data center. Both studies illustrate the difficulty of untangling complex interactions of workload characteristics that lead to failures and of identifying failure root causes from monitored symptoms. Nevertheless, this difficulty can occasionally manifest in spectacular results where failure prediction can be dramatically accurate.},
booktitle = {Quantitative Evaluation of Systems: 17th International Conference, QEST 2020, Vienna, Austria, August 31 – September 3, 2020, Proceedings},
pages = {3–7},
numpages = {5},
keywords = {HDDs, SSDs, GPUs, Reliability, Storage systems, HPC, Data centers},
location = {Vienna, Austria}
}

@article{10.1504/IJDATS.2016.075971,
author = {Erturk, Ezgi and Sezer, Ebru Akcapinar},
title = {Software fault prediction using Mamdani type fuzzy inference system},
year = {2016},
issue_date = {April 2016},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {8},
number = {1},
issn = {1755-8050},
url = {https://doi.org/10.1504/IJDATS.2016.075971},
doi = {10.1504/IJDATS.2016.075971},
abstract = {High quality software requires the occurrence of minimum number of failures while software runs. Software fault prediction is the determining whether software modules are prone to fault or not. Identification of the modules or code segments which need detailed testing, editing or, reorganising can be possible with the help of software fault prediction systems. In literature, many studies present models for software fault prediction using some soft computing methods which use training/testing phases. As a result, they require historical data to build models. In this study, to eliminate this drawback, Mamdani type fuzzy inference system FIS is applied for the software fault prediction problem. Several FIS models are produced and assessed with ROC-AUC as performance measure. The results achieved are ranging between 0.7138 and 0.7304; they are encouraging us to try FIS with the different software metrics and data to demonstrate general FIS performance on this problem.},
journal = {Int. J. Data Anal. Tech. Strateg.},
month = apr,
pages = {14–28},
numpages = {15}
}

@article{10.1016/j.compeleceng.2017.06.016,
author = {Zhou, Yaoming and Wu, Kan and Meng, Zhijun and Tian, Mingjun},
title = {Fault detection of aircraft based on support vector domain description},
year = {2017},
issue_date = {July 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {61},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2017.06.016},
doi = {10.1016/j.compeleceng.2017.06.016},
abstract = {The classification accuracy is improved by 5.52% after using the genetic algorithm.The fault detection time of the Support Vector Domain Description (SVDD) algorithm is always pre-emptive when compared to the red line shutdown system, which is superior to the Back Propagation algorithm.The SVDD algorithm based on the modified kernel function can significantly increase the separability between categories.The method of drawing the SVDD model boundary based on equal loss involves smaller risks compared to other cutting planes and minimizes the losses caused by classifications. To realize intelligent fault detection of aircraft lacking fault samples, a novel fault detection algorithm for aircraft based on Support Vector Domain Description (SVDD) is proposed. The Genetic Algorithm (GA), threshold scaling factor, rapid anomaly detection, modifying kernel function and SVDD model boundary based on equal loss are introduced to the fault detection algorithm. The empirical analyses show that the method has good fault detection ability. The classification accuracy is improved by 5.52% after using the GA. The fault detection time of the SVDD algorithm is improved by 0.4 seconds on average when compared to the red line shutdown system. The accurate classification rate is enhanced by 0.0225, and the number of support vectors is reduced by 1 after adopting the modified kernel function. The fault detection algorithm in this paper provides novel intelligent fault detection technology for aircraft. Display Omitted},
journal = {Comput. Electr. Eng.},
month = jul,
pages = {80–94},
numpages = {15},
keywords = {Support vector domain description, Modifying kernel function, Fault detection, Aircraft}
}

@article{10.1016/j.micpro.2020.103071,
author = {Meckel, Simon and Schuessler, Tim and Jaisawal, Pravin Kumar and Yang, Jie-Uei and Obermaisser, Roman},
title = {Generation of a diagnosis model for hybrid-electric vehicles using machine learning},
year = {2020},
issue_date = {Jun 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {75},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2020.103071},
doi = {10.1016/j.micpro.2020.103071},
journal = {Microprocess. Microsyst.},
month = jun,
numpages = {15},
keywords = {System level online-diagnosis, Active diagnosis, Machine learning, Artificial neural network, Real-time}
}

@inproceedings{10.1109/IECON.2019.8926891,
author = {Amirat, Yassine and Elbouchikhi, Elhoussin and Zhou, Zhibin and Benbouzid, Mohamed and Feld, Gilles},
title = {Variational Mode Decomposition-based Notch Filter for Bearing Fault Detection},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON.2019.8926891},
doi = {10.1109/IECON.2019.8926891},
abstract = {This work presents a variational mode decomposition (VMD) based detector for bearing fault in electrical machines. Its performance is compared to that of the ensemble empirical mode decomposition (EEMD) based. A notch filter based Pearson correlation was developed and used to extract the dominant mode. Experimental results showed that the VMD outperformed in terms of statistical features. As a result, the VMD-based notch filter could be a promising methodology for bearing fault detection and degradation prediction.},
booktitle = {IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society},
pages = {6028–6033},
numpages = {6},
location = {Lisbon, Portugal}
}

@inproceedings{10.5555/3154690.3154728,
author = {Mahdisoltani, Farzaneh and Stefanovici, Ioan and Schroeder, Bianca},
title = {Improving storage system reliability with proactive error prediction},
year = {2017},
isbn = {9781931971386},
publisher = {USENIX Association},
address = {USA},
abstract = {This paper proposes the use of machine learning techniques to make storage systems more reliable in the face of sector errors. Sector errors are partial drive failures, where individual sectors on a drive become unavailable, and occur at a high rate in both hard disk drives and solid state drives. The data in the affected sectors can only be recovered through redundancy in the system (e.g. another drive in the same RAID) and is lost if the error is encountered while the system operates in degraded mode, e.g. during RAID reconstruction.In this paper, we explore a range of different machine learning techniques and show that sector errors can be predicted ahead of time with high accuracy. Prediction is robust, even when only little training data or only training data for a different drive model is available. We also discuss a number of possible use cases for improving storage system reliability through the use of sector error predictors. We evaluate one such use case in detail: We show that the mean time to detecting errors (and hence the window of vulnerability to data loss) can be greatly reduced by adapting the speed of a scrubber based on error predictions.},
booktitle = {Proceedings of the 2017 USENIX Conference on Usenix Annual Technical Conference},
pages = {391–402},
numpages = {12},
location = {Santa Clara, CA, USA},
series = {USENIX ATC '17}
}

@article{10.1145/3462329,
author = {Masadeh, Mahmoud and Elderhalli, Yassmeen and Hasan, Osman and Tahar, Sofiene},
title = {A Quality-assured Approximate Hardware Accelerators–based on Machine Learning and Dynamic Partial Reconfiguration},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/3462329},
doi = {10.1145/3462329},
abstract = {Machine learning is widely used these days to extract meaningful information out of the Zettabytes of sensors data collected daily. All applications require analyzing and understanding the data to identify trends, e.g., surveillance, exhibit some error tolerance. Approximate computing has emerged as an energy-efficient design paradigm aiming to take advantage of the intrinsic error resilience in a wide set of error-tolerant applications. Thus, inexact results could reduce power consumption, delay, area, and execution time. To increase the energy-efficiency of machine learning on FPGA, we consider approximation at the hardware level, e.g., approximate multipliers. However, errors in approximate computing heavily depend on the application, the applied inputs, and user preferences. However, dynamic partial reconfiguration has been introduced, as a key differentiating capability in recent FPGAs, to significantly reduce design area, power consumption, and reconfiguration time by adaptively changing a selective part of the FPGA design without interrupting the remaining system. Thus, integrating “Dynamic Partial Reconfiguration” (DPR) with “Approximate Computing” (AC) will significantly ameliorate the efficiency of FPGA-based design approximation. In this article, we propose hardware-efficient quality-controlled approximate accelerators, which are suitable to be implemented in FPGA-based machine learning algorithms as well as any error-resilient applications. Experimental results using three case studies of image blending, audio blending, and image filtering applications demonstrate that the proposed adaptive approximate accelerator satisfies the required quality with an accuracy of 81.82%, 80.4%, and 89.4%, respectively. On average, the partial bitstream was found to be 28.6 smaller than the full bitstream.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = aug,
articleno = {57},
numpages = {19},
keywords = {FPGA, adaptive design, dynamic partial reconfiguration, input-aware approximation, decision tree, approximate hardware accelerator, Approximate computing}
}

@article{10.1155/2014/230382,
author = {Yadav, Anamika and Dash, Yajnaseni},
title = {An overview of transmission line protection by artificial neural network: fault detection, fault classification, fault location, and fault direction discrimination},
year = {2015},
issue_date = {January 2014},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2014},
issn = {1687-7594},
url = {https://doi.org/10.1155/2014/230382},
doi = {10.1155/2014/230382},
abstract = {Contemporary power systems are associated with serious issues of faults on high voltage transmission lines. Instant isolation of fault is necessary to maintain the system stability. Protective relay utilizes current and voltage signals to detect, classify, and locate the fault in transmission line. A trip signal will be sent by the relay to a circuit breaker with the purpose of disconnecting the faulted line from the rest of the system in case of a disturbance for maintaining the stability of the remaining healthy system. This paper focuses on the studies of fault detection, fault classification, fault location, fault phase selection, and fault direction discrimination by using artificial neural networks approach. Artificial neural networks are valuable for power system applications as they can be trained with offline data. Efforts have been made in this study to incorporate and review approximately all important techniques and philosophies of transmission line protection reported in the literature till June 2014. This comprehensive and exhaustive survey will reduce the difficulty of new researchers to evaluate different ANN based techniques with a set of references of all concerned contributions.},
journal = {Adv. Artif. Neu. Sys.},
month = jan,
articleno = {12},
numpages = {1}
}

@article{10.1186/s13673-019-0175-8,
author = {Ramotsoela, Daniel T. and Hancke, Gerhard P. and Abu-Mahfouz, Adnan M.},
title = {Attack detection in water distribution systems using machine learning},
year = {2019},
issue_date = {Dec 2019},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {9},
number = {1},
issn = {2192-1962},
url = {https://doi.org/10.1186/s13673-019-0175-8},
doi = {10.1186/s13673-019-0175-8},
abstract = {The threat to critical water system infrastructure has increased in recent years as is evident from the increasing number of reported attacks against these systems. Preventative security mechanisms are often not enough to keep attackers out so a second layer of security in the form of intrusion detection is paramount in order to limit the damage of successful attacks. In this paper several traditional anomaly detection techniques are evaluated in the context of attack detection in water distribution systems. These algorithms were centrally trained on the entire feature space and compared to multi-stage detection 
techniques that were designed to isolate both local and global anomalies. A novel ensemble technique that combines density-based and parametric algorithms was also developed and tested in the application environment. The traditional techniques had comparable results to the multi-stage systems and when used in conjunction with a local anomaly detector the performances of these algorithms were greatly improved. The developed ensemble technique also had promising results outperforming the density-based techniques and having comparable results to the parametric algorithms.},
journal = {Hum.-Centric Comput. Inf. Sci.},
month = dec,
articleno = {175},
numpages = {22},
keywords = {Water monitoring, System security, Machine learning, Cyber-physical systems, Critical infrastructure, Anomaly detection}
}

@article{10.1109/TCBB.2018.2880234,
author = {Bahadorinejad, Arghavan and Imani, Mahdi and Braga-Neto, Ulisses M.},
title = {Adaptive Particle Filtering for Fault Detection in Partially-Observed Boolean Dynamical Systems},
year = {2020},
issue_date = {July-Aug. 2020},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {17},
number = {4},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2018.2880234},
doi = {10.1109/TCBB.2018.2880234},
abstract = {We propose a novel methodology for fault detection and diagnosis in partially-observed Boolean dynamical systems (POBDS). These are stochastic, highly nonlinear, and derivativeless systems, rendering difficult the application of classical fault detection and diagnosis methods. The methodology comprises two main approaches. The first addresses the case when the normal mode of operation is known but not the fault modes. It applies an innovations filter (IF) to detect deviations from the nominal normal mode of operation. The second approach is applicable when the set of possible fault models is finite and known, in which case we employ a multiple model adaptive estimation (MMAE) approach based on a likelihood-ratio (LR) statistic. Unknown system parameters are estimated by an adaptive expectation-maximization (EM) algorithm. Particle filtering techniques are used to reduce the computational complexity in the case of systems with large state-spaces. The efficacy of the proposed methodology is demonstrated by numerical experiments with a large gene regulatory network (GRN) with stuck-at faults observed through a single noisy time series of RNA-seq gene expression measurements.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = aug,
pages = {1105–1114},
numpages = {10}
}

@article{10.1023/A:1024424811345,
author = {Khoshgoftaar, Taghi M. and Seliya, Naeem},
title = {Fault Prediction Modeling for Software Quality Estimation: Comparing Commonly Used Techniques},
year = {2003},
issue_date = {September 2003},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {8},
number = {3},
issn = {1382-3256},
url = {https://doi.org/10.1023/A:1024424811345},
doi = {10.1023/A:1024424811345},
abstract = {High-assurance and complex mission-critical software systems are heavily dependent on reliability of their underlying software applications. An early software fault prediction is a proven technique in achieving high software reliability. Prediction models based on software metrics can predict number of faults in software modules. Timely predictions of such models can be used to direct cost-effective quality enhancement efforts to modules that are likely to have a high number of faults. We evaluate the predictive performance of six commonly used fault prediction techniques: CART-LS (least squares), CART-LAD (least absolute deviation), S-PLUS, multiple linear regression, artificial neural networks, and case-based reasoning. The case study consists of software metrics collected over four releases of a very large telecommunications system. Performance metrics, average absolute and average relative errors, are utilized to gauge the accuracy of different prediction models. Models were built using both, original software metrics (RAW) and their principle components (PCA). Two-way ANOVA randomized-complete block design models with two blocking variables are designed with average absolute and average relative errors as response variables. System release and the model type (RAW or PCA) form the blocking variables and the prediction technique is treated as a factor. Using multiple-pairwise comparisons, the performance order of prediction models is determined. We observe that for both average absolute and average relative errors, the CART-LAD model performs the best while the S-PLUS model is ranked sixth.},
journal = {Empirical Softw. Engg.},
month = sep,
pages = {255–283},
numpages = {29},
keywords = {software metrics, neural networks, multiple linear regression, fault prediction, case-based reasoning, Software quality prediction, S-PLUS, CART}
}

@article{10.1007/s11219-019-09472-3,
author = {Li, J . Jenny and Ulrich, Andreas and Bai, Xiaoying and Bertolino, Antonia},
title = {Advances in test automation for software with special focus on artificial intelligence and machine learning},
year = {2020},
issue_date = {Mar 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {1},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-019-09472-3},
doi = {10.1007/s11219-019-09472-3},
journal = {Software Quality Journal},
month = mar,
pages = {245–248},
numpages = {4}
}

@article{10.1016/j.infsof.2019.01.008,
author = {Meqdadi, Omar and Alhindawi, Nouh and Alsakran, Jamal and Saifan, Ahmad and Migdadi, Hatim},
title = {Mining software repositories for adaptive change commits using machine learning techniques},
year = {2019},
issue_date = {May 2019},
publisher = {Butterworth-Heinemann},
address = {USA},
volume = {109},
number = {C},
issn = {0950-5849},
url = {https://doi.org/10.1016/j.infsof.2019.01.008},
doi = {10.1016/j.infsof.2019.01.008},
journal = {Inf. Softw. Technol.},
month = may,
pages = {80–91},
numpages = {12},
keywords = {Machine learning, Maintenance classification, Commit types, Adaptive maintenance, Code change metrics}
}

@inproceedings{10.1145/2786805.2786813,
author = {Jing, Xiaoyuan and Wu, Fei and Dong, Xiwei and Qi, Fumin and Xu, Baowen},
title = {Heterogeneous cross-company defect prediction by unified metric representation and CCA-based transfer learning},
year = {2015},
isbn = {9781450336758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2786805.2786813},
doi = {10.1145/2786805.2786813},
abstract = {Cross-company defect prediction (CCDP) learns a prediction model by using training data from one or multiple projects of a source company and then applies the model to the target company data. Existing CCDP methods are based on the assumption that the data of source and target companies should have the same software metrics. However, for CCDP, the source and target company data is usually heterogeneous, namely the metrics used and the size of metric set are different in the data of two companies. We call CCDP in this scenario as heterogeneous CCDP (HCCDP) task. In this paper, we aim to provide an effective solution for HCCDP. We propose a unified metric representation (UMR) for the data of source and target companies. The UMR consists of three types of metrics, i.e., the common metrics of the source and target companies, source-company specific metrics and target-company specific metrics. To construct UMR for source company data, the target-company specific metrics are set as zeros, while for UMR of the target company data, the source-company specific metrics are set as zeros. Based on the unified metric representation, we for the first time introduce canonical correlation analysis (CCA), an effective transfer learning method, into CCDP to make the data distributions of source and target companies similar. Experiments on 14 public heterogeneous datasets from four companies indicate that: 1) for HCCDP with partially different metrics, our approach significantly outperforms state-of-the-art CCDP methods; 2) for HCCDP with totally different metrics, our approach obtains comparable prediction performances in contrast with within-project prediction results. The proposed approach is effective for HCCDP.},
booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
pages = {496–507},
numpages = {12},
keywords = {unified metric representation, company-specific metrics, common metrics, canonical correlation analysis (CCA), Heterogeneous cross-company defect prediction (HCCDP)},
location = {Bergamo, Italy},
series = {ESEC/FSE 2015}
}

@article{10.1016/j.compind.2021.103489,
author = {Farahani, Hossein Shahabadi and Fatehi, Alireza and Nadali, Alireza and Shoorehdeli, Mahdi Aliyari},
title = {Domain Adversarial Neural Network Regression to design transferable soft sensor in a power plant},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {132},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2021.103489},
doi = {10.1016/j.compind.2021.103489},
journal = {Comput. Ind.},
month = nov,
numpages = {10},
keywords = {Transferable soft-sensors, Intelligent condition monitoring, Adversarial neural networks, Transfer learning}
}

@inproceedings{10.1145/3387940.3391490,
author = {Liem, Cynthia C. S. and Panichella, Annibale},
title = {Oracle Issues in Machine Learning and Where to Find Them},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3391490},
doi = {10.1145/3387940.3391490},
abstract = {The rise in popularity of machine learning (ML), and deep learning in particular, has both led to optimism about achievements of artificial intelligence, as well as concerns about possible weaknesses and vulnerabilities of ML pipelines. Within the software engineering community, this has led to a considerable body of work on ML testing techniques, including white- and black-box testing for ML models. This means the oracle problem needs to be addressed. For supervised ML applications, oracle information is indeed available in the form of dataset 'ground truth', that encodes input data with corresponding desired output labels. However, while ground truth forms a gold standard, there still is no guarantee it is truly correct. Indeed, syntactic, semantic, and conceptual framing issues in the oracle may negatively affect the ML system's integrity. While syntactic issues may automatically be verified and corrected, the higher-level issues traditionally need human judgment and manual analysis. In this paper, we employ two heuristics based on information entropy and semantic analysis on well-known computer vision models and benchmark data from ImageNet. The heuristics are used to semi-automatically uncover potential higher-level issues in (i) the label taxonomy used to define the ground truth oracle (labels), and (ii) data encoding and representation. In doing this, beyond existing ML testing efforts, we illustrate the need for software engineering strategies that especially target and assess the oracle.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {483–488},
numpages = {6},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1109/ETFA.2018.8502608,
author = {Yan, Weili and Zhou, Jun-Hong},
title = {Early Fault Detection of Aircraft Components Using Flight Sensor Data},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ETFA.2018.8502608},
doi = {10.1109/ETFA.2018.8502608},
abstract = {In this paper, a classification-based anomaly detection model is proposed to detect the aircraft component fault by exploring the historical flight sensor data. Detection of the aircraft component fault is formulated as a classification problem. Firstly, several sensors relevant to the fault are selected using statistical analysis. Secondly, flight phase-based statistical features are extracted using the selected sensors. Thirdly, several important features are selected using correlation analysis with the flight label. Finally, the random forest algorithm is applied to build the fault classification model based on the selected features. Experimental results show the proposed method can detect the component fault earlier than or as early as the current aircraft alarming system.},
booktitle = {2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA)},
pages = {1337–1342},
numpages = {6},
location = {Torino, Italy}
}

@inproceedings{10.1145/3427477.3429462,
author = {Jian, Sirui and Ishida, Shigemi and Arakawa, Yutaka},
title = {Initial Attempt on Wi-Fi CSI Based Vibration Sensing for Factory Equipment Fault Detection},
year = {2021},
isbn = {9781450381840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427477.3429462},
doi = {10.1145/3427477.3429462},
abstract = {Wi-Fi signal based detection is widely implemented in indoor action detection because of its low-cost and easy implementation. But it is still rarely used in equipment vibration detection. Moreover, it is hard to detect multiple targets where we need to monitor multiple equipments’ vibration state such as in the factory environment. In this paper, we propose a wireless based vibration sensing method using Wi-Fi for factory equipment fault detection. First, we use CSI amplitude data to distinguish sensing target equipments. Then, we apply an anomaly detection method to detect faulty machine operation. We conducted initial experiments to validate the feasibility of our proposed fault detection method. The experimental results show that our method detected abnormal situations with an accuracy of 100%, while 10% of normal situations were mistakenly recognized as abnormal.},
booktitle = {Adjunct Proceedings of the 2021 International Conference on Distributed Computing and Networking},
pages = {163–168},
numpages = {6},
keywords = {vibration sensing, commodity Wi-Fi, anomaly detection., Channel state information (CSI)},
location = {Nara, Japan},
series = {ICDCN '21}
}

@inproceedings{10.1109/IECON.2019.8926924,
author = {Singh Chadha, Gavneet and Krishnamoorthy, Monica and Schwung, Andreas},
title = {Time Series based Fault Detection in Industrial Processes using Convolutional Neural Networks},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/IECON.2019.8926924},
doi = {10.1109/IECON.2019.8926924},
abstract = {The constant and rapid rise in the field of Industrial Internet of Things has enabled the manufacturing and process industries to have access to large amounts of process data. This process data can be effectively analyzed to identify the faults in the system thereby facilitating in avoiding critical process breakdowns. Deep neural networks with their inherent ability to model complex non-linear representations, have been proven to fit well for contemporary fault detection. This work proposes a Time Series based approach to fault detection in the benchmark Tennessee Eastman process making use of the temporal dependencies within the process data. Since standard Feed Forward Neural Networks (FFNN) are not capable of learning these temporal dependencies, a novel approach using Convolutional Neural Networks (CNN) with its architectural and algorithmic variants is proposed. The experimental results show comparatively superior performance of the proposed CNN based models with the standard FFNN for fault detection. Also the different hyperpaprameters which effect the time series classification task are highlighted.},
booktitle = {IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society},
pages = {173–178},
numpages = {6},
location = {Lisbon, Portugal}
}

@book{10.5555/2911053,
author = {Mistrik, Ivan and Soley, Richard M. and Ali, Nour and Grundy, John and Tekinerdogan, Bedir},
title = {Software Quality Assurance: In Large Scale and Complex Software-intensive Systems},
year = {2015},
isbn = {0128023015},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st},
abstract = {Software Quality Assurance in Large Scale and Complex Software-intensive Systems presents novel and high-quality research related approaches that relate the quality of software architecture to system requirements, system architecture and enterprise-architecture, or software testing. Modern software has become complex and adaptable due to the emergence of globalization and new software technologies, devices and networks. These changes challenge both traditional software quality assurance techniques and software engineers to ensure software quality when building today (and tomorrows) adaptive, context-sensitive, and highly diverse applications. This edited volume presents state of the art techniques, methodologies, tools, best practices and guidelines for software quality assurance and offers guidance for future software engineering research and practice. Each contributed chapter considers the practical application of the topic through case studies, experiments, empirical validation, or systematic comparisons with other approaches already in practice. Topics of interest include, but are not limited, to: quality attributes of system/software architectures; aligning enterprise, system, and software architecture from the point of view of total quality; design decisions and their influence on the quality of system/software architecture; methods and processes for evaluating architecture quality; quality assessment of legacy systems and third party applications; lessons learned and empirical validation of theories and frameworks on architectural quality; empirical validation and testing for assessing architecture quality.Focused on quality assurance at all levels of software design and developmentCovers domain-specific software quality assurance issues e.g. for cloud, mobile, security, context-sensitive, mash-up and autonomic systemsExplains likely trade-offs from design decisions in the context of complex software system engineering and quality assuranceIncludes practical case studies of software quality assurance for complex, adaptive and context-critical systems}
}

@inproceedings{10.1109/ICSM.2015.7332470,
author = {Di Nucci, Dario and Palomba, Fabio and Siravo, Sandro and Bavota, Gabriele and Oliveto, Rocco and De Lucia, Andrea},
title = {On the role of developer's scattered changes in bug prediction},
year = {2015},
isbn = {9781467375320},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSM.2015.7332470},
doi = {10.1109/ICSM.2015.7332470},
abstract = {The importance of human-related factors in the introduction of bugs has recently been the subject of a number of empirical studies. However, such factors have not been captured yet in bug prediction models which simply exploit product metrics or process metrics based on the number and type of changes or on the number of developers working on a software component. Previous studies have demonstrated that focused developers are less prone to introduce defects than non focused developers. According to this observation, software components changed by focused developers should also be less error prone than software components changed by less focused developers. In this paper we capture this observation by measuring the structural and semantic scattering of changes performed by the developers working on a software component and use these two measures to build a bug prediction model. Such a model has been evaluated on five open source systems and compared with two competitive prediction models: the first exploits the number of developers working on a code component in a given time period as predictor, while the second is based on the concept of code change entropy. The achieved results show the superiority of our model with respect to the two competitive approaches, and the complementarity of the defined scattering measures with respect to standard predictors commonly used in the literature.},
booktitle = {Proceedings of the 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
pages = {241–250},
numpages = {10},
series = {ICSME '15}
}

@inproceedings{10.23919/ICEMS52562.2021.9634588,
author = {Xue, Shaopeng and Yang, Ming and Huang, Xu and Xu, Dianguo},
title = {Bearing Fault Detection Using Multipoint Optimal Minimum Entropy Deconvolution Adjusted of Motor Speed},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.23919/ICEMS52562.2021.9634588},
doi = {10.23919/ICEMS52562.2021.9634588},
abstract = {Fault diagnosis of bearings is of great significance to the development of various industries. Traditional permanent magnet synchronous motor bearing fault diagnosis technology mainly extracts fault characteristics from vibration and current signals. However, due to the need for acceleration sensors or oscilloscopes, these methods are costly and challenging to monitor in real-time. This paper aims at the above problems to propose a bearing fault diagnosis scheme based on speed signal and multi-point optimal minimum entropy deconvolution. U sing the periodicity of the characteristic fault signal, MOMEDA is used to extract the bearing fault characteristic in the signal, and the signal-to-noise ratio of the speed signal is improved. Compared with the traditional fault diagnosis scheme based on current signal and MED, the diagnosis scheme proposed in this paper can reduce the diagnosis cost and improve the diagnosis speed. The simulation signal verifies the effectiveness of this method. Experimental research on bearing faults shows that the diagnosis scheme based on speed signal and MOMEDA can detect bearing faults well.},
booktitle = {2021 24th International Conference on Electrical Machines and Systems (ICEMS)},
pages = {2191–2195},
numpages = {5},
location = {Gyeongju, Korea, Republic of}
}

@article{10.3233/JIFS-201965,
author = {Guo, Yiming and Zhang, Hui and Xia, Zhijie and Dong, Chang and Zhang, Zhisheng and Zhou, Yifan and Sun, Han},
title = {An improved deep convolution neural network for predicting the remaining useful life of rolling bearings},
year = {2021},
issue_date = {2021},
publisher = {IOS Press},
address = {NLD},
volume = {40},
number = {3},
issn = {1064-1246},
url = {https://doi.org/10.3233/JIFS-201965},
doi = {10.3233/JIFS-201965},
abstract = {The rolling bearing is the crucial component in the rotating machinery. The degradation process monitoring and remaining useful life prediction of the bearing are necessary for the condition-based maintenance. The commonly used deep learning methods use the raw or processed time domain data as the input. However, the feature extracted by these approaches is insufficient and incomprehensive. To tackle this problem, this paper proposed an improved Deep Convolution Neural Network with the dual-channel input from the time and frequency domain in parallel. The proposed methodology consists of two stages: the incipient failure identification and the degradation process fitting. To verify the effectiveness of the method, the IEEE PHM 2012 dataset is adopted to compare the proposed method and other commonly used approaches. The results show that the improved Deep Convolution Neural Network can effectively describe the degradation process for the rolling bearing.},
journal = {J. Intell. Fuzzy Syst.},
month = jan,
pages = {5743–5751},
numpages = {9},
keywords = {dual-channel input, remaining useful life prediction, Deep Convolution Neural Network, Rolling bearing}
}

@article{10.1007/s11219-007-9013-8,
author = {Seliya, Naeem and Khoshgoftaar, Taghi M.},
title = {Software quality estimation with limited fault data: a semi-supervised learning perspective},
year = {2007},
issue_date = {September 2007},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {15},
number = {3},
issn = {0963-9314},
url = {https://doi.org/10.1007/s11219-007-9013-8},
doi = {10.1007/s11219-007-9013-8},
abstract = {We addresses the important problem of software quality analysis when there is limited software fault or fault-proneness data. A software quality model is typically trained using software measurement and fault data obtained from a previous release or similar project. Such an approach assumes that fault data is available for all the training modules. Various issues in software development may limit the availability of fault-proneness data for all the training modules. Consequently, the available labeled training dataset is such that the trained software quality model may not provide predictions. More specifically, the small set of modules with known fault-proneness labels is not sufficient for capturing the software quality trends of the project. We investigate semi-supervised learning with the Expectation Maximization (EM) algorithm for software quality estimation with limited fault-proneness data. The hypothesis is that knowledge stored in software attributes of the unlabeled program modules will aid in improving software quality estimation. Software data collected from a large NASA software project is used during the semi-supervised learning process. The software quality model is evaluated with multiple test datasets collected from other NASA software projects. Compared to software quality models trained only with the available set of labeled program modules, the EM-based semi-supervised learning scheme improves generalization performance of the software quality models.},
journal = {Software Quality Journal},
month = sep,
pages = {327–344},
numpages = {18},
keywords = {Unlabeled data, Software quality estimation, Software metrics, Semi-supervised learning, Expectation maximization}
}

@inproceedings{10.1109/CA.2014.22,
author = {Han, Wanjiang and Jiang, Heyang and Li, Weijian and Li, Ye},
title = {A Summary of Software Defect Model},
year = {2014},
isbn = {9781479982066},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CA.2014.22},
doi = {10.1109/CA.2014.22},
abstract = {Effective detection of software defects is an important activity of software development process. In this paper, we give a summary about residual defect prediction technologies, and propose an approach to predict residual defects for ERP project, which applies defect distribution model. Experiment results show that this approach can effectively improve the accuracy of defect prediction.},
booktitle = {Proceedings of the 2014 7th International Conference on Control and Automation},
pages = {64–67},
numpages = {4},
series = {CA '14}
}

@article{10.1016/j.jss.2019.03.027,
author = {Xu, Zhou and Li, Shuai and Luo, Xiapu and Liu, Jin and Zhang, Tao and Tang, Yutian and Xu, Jun and Yuan, Peipei and Keung, Jacky},
title = {TSTSS: A two-stage training subset selection framework for cross version defect prediction},
year = {2019},
issue_date = {Aug 2019},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {154},
number = {C},
issn = {0164-1212},
url = {https://doi.org/10.1016/j.jss.2019.03.027},
doi = {10.1016/j.jss.2019.03.027},
journal = {J. Syst. Softw.},
month = aug,
pages = {59–78},
numpages = {20},
keywords = {99-00, 00–01, Weighted extreme learning machine, Training subset selection, Spare modeling, Cross version defect prediction}
}

@article{10.1109/MS.2016.156,
author = {Lanza, Michele and Mocci, Andrea and Ponzanelli, Luca},
title = {The Tragedy of Defect Prediction, Prince of Empirical Software Engineering Research},
year = {2016},
issue_date = {November 2016},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {33},
number = {6},
issn = {0740-7459},
url = {https://doi.org/10.1109/MS.2016.156},
doi = {10.1109/MS.2016.156},
abstract = {If measured by the number of published papers, defect prediction has become an important research field over the past decade, with many researchers continuously proposing novel approaches to predict defects in software systems. However, most of these approaches have had a noticeable lack of impact on industrial practice. This lack of impact is because something is intrinsically wrong in how defect prediction approaches are evaluated.},
journal = {IEEE Softw.},
month = nov,
pages = {102–105},
numpages = {4}
}

@article{10.1155/2020/5424236,
author = {Wang, Xiaolong and Tang, Guiji and He, Yuling and Bueno, \'{A}tila},
title = {Application of RSSD-OCYCBD Strategy in Enhanced Fault Detection of Rolling Bearing},
year = {2020},
issue_date = {2020},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {2020},
issn = {1076-2787},
url = {https://doi.org/10.1155/2020/5424236},
doi = {10.1155/2020/5424236},
abstract = {The defect characteristics of rolling bearing are difficult to excavate at the incipient injury phase; in order to effectively solve this issue, an original strategy fusing recursive singular spectrum decomposition (RSSD) with optimized cyclostationary blind deconvolution (OCYCBD) is put forward to achieve fault characteristic enhanced detection. In this diagnosis strategy, the data-driven RSSD method without predetermined component number is proposed. In addition, a new morphological difference operation entropy (MDOE) indicator, which takes advantage of morphological transformation and Shannon entropy, is developed for confirming the influencing parameters of cyclostationary blind deconvolution (CYCBD). During the process of fault detection, RSSD is firstly adopted to preprocess the original signal, and the most sensitive singular spectrum component (SSC) is selected by the envelope spectrum peak (ESP) indicator. Then, the grid search algorithm is adopted to precisely confirm the optimal parameters and OCYCBD is further performed as a postprocessing technology on the most sensitive component to suppress the residual interferences and amplify the fault signatures. Finally, the enhanced fault detection of rolling bearing is able to achieve by analyzing the envelope spectrum of deconvolution signal. The feasibility of the proposed strategy is verified by the simulated and the measured signals, respectively, and its superiority is also demonstrated through several comparison methods. The results manifest this novel strategy has praisable advantages on weak characteristic extraction and intensification.},
journal = {Complex.},
month = jan,
numpages = {24}
}

@article{10.1016/j.asoc.2017.03.031,
author = {Costa Silva, Guilherme and Caminhas, Walmir Matos and Palhares, Reinaldo Martinez},
title = {Artificial immune systems applied to fault detection and isolation},
year = {2017},
issue_date = {August 2017},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {57},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2017.03.031},
doi = {10.1016/j.asoc.2017.03.031},
abstract = {Graphical abstractDisplay Omitted HighlightsWe review some approaches inspired on infectious nonself and danger models.Novel immune-inspired algorithms tend to rely more on expert knowledge.Reviewed approaches can be applied to a fault detection benchmark.Experimental results show fault detection with no false alarms.A fault isolation mechanism can be provided from class ambiguity measurements. This paper aims to document the application of a new generation of artificial immune systems (AIS) in fault detection and isolation problems. These kind of algorithms are able to explore normal and anomalous behavior evidences, however, they may often require a more explicit prior knowledge provided by experts, usually difficult to obtain in some practical cases. Thus, many immune inspired approaches applied to fault detection and isolation (FDI) in the literature are based on negative selection algorithms. Considering these points, this work presents a review on three AIS approaches. Once reviewed and contextualized, the evaluated techniques are properly adjusted considering their main parameters and ways of processing data, and then, applied to a case study of fault detection and isolation in order to provide a performance analysis of these techniques, according to their applicability to these problems.},
journal = {Appl. Soft Comput.},
month = aug,
pages = {118–131},
numpages = {14},
keywords = {Infectious nonself model, Fault detection and isolation, Danger model, Artificial immune systems, Anomaly detection}
}

@inproceedings{10.1145/1868328.1868336,
author = {Mende, Thilo},
title = {Replication of defect prediction studies: problems, pitfalls and recommendations},
year = {2010},
isbn = {9781450304047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868328.1868336},
doi = {10.1145/1868328.1868336},
abstract = {Background: The main goal of the PROMISE repository is to enable reproducible, and thus verifiable or refutable research. Over time, plenty of data sets became available, especially for defect prediction problems.Aims: In this study, we investigate possible problems and pitfalls that occur during replication. This information can be used for future replication studies, and serve as a guideline for researchers reporting novel results.Method: We replicate two recent defect prediction studies comparing different data sets and learning algorithms, and report missing information and problems.Results: Even with access to the original data sets, replicating previous studies may not lead to the exact same results. The choice of evaluation procedures, performance measures and presentation has a large influence on the reproducibility. Additionally, we show that trivial and random models can be used to identify overly optimistic evaluation measures.Conclusions: The best way to conduct easily reproducible studies is to share all associated artifacts, e.g. scripts and programs used. When this is not an option, our results can be used to simplify the replication task for other researchers.},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
articleno = {5},
numpages = {10},
keywords = {defect prediction model, replication},
location = {Timi\c{s}oara, Romania},
series = {PROMISE '10}
}

@inproceedings{10.1145/3357419.3357452,
author = {Maria, Mykoniati and Lambrinoudakis, Konstantinos},
title = {Fault Prediction Model for Node Selection Function of Mobile Networks},
year = {2019},
isbn = {9781450371889},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357419.3357452},
doi = {10.1145/3357419.3357452},
abstract = {Survivability is a critical property that any network system should emerge. A survivable system is a system that achieves its critical services to perform, over an acceptable quality level of service in a timely manner, even if the system is under attack failure or disaster. Usually, mobile networked systems (2G, 3G, 4G, 5G) contain a certain number of different nodes each of which performs certain signaling as part of a larger service, provided to, or requested from, end users. Nowadays, there is much research on how telecommunication mobile systems, should be designed to include self-organization mechanisms like self-monitoring, self-configuration, and self-healing, to automatically perform network management activities. These system capabilities should also be used for ensuring system services' survivability or reliability against any failure. The main objectives of the current paper, for providing a service fault management system, are the following two. The first one is to provide a service fault monitoring system that has the ability of self-diagnosis, and the second one is to provide a self-organization ability for the mobile network by always choosing the best alternative path for a critical service, while the system is degrading to different levels of Quality of Service, until it becomes unavailable. These two objectives constitute key survivability principles.},
booktitle = {Proceedings of the 9th International Conference on Information Communication and Management},
pages = {153–159},
numpages = {7},
keywords = {DPMO, Survivability, mobile networks, predictive analytics, regression, reliability, robustness, selection function},
location = {Prague, Czech Republic},
series = {ICICM '19}
}

@inproceedings{10.1145/3387168.3390519,
author = {Demircan, Merve and Kasnako\u{g}lu, Co\c{s}ku},
title = {Aileron Locking Fault Detection Based on Extended Kalman Filter for UAV},
year = {2020},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387168.3390519},
doi = {10.1145/3387168.3390519},
abstract = {This paper presents application of Nonlinear Extended Kalman Filter for aileron actuator locking scenario in Unmanned Aerial Vehicles and estimation of states to make comparison between sensor results and estimation results. At first, nonlinear state space system of UAV is formulated. Then, three faulty scenarios including three faulty aileron actuators locking and one nominal scenario is formed. After that, Extended Kalman Filter is applied to estimate the roll rate state at the same time with measurements. Finally, measurement and filter estimations for the roll rate state outcomes are commented. The system is modelled in MATLAB/Simulink. The performances of the method have been commented using simulation results.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {53},
numpages = {6},
keywords = {UAV, Kalman Filters, Flight Control Systems, Fault Detection, Extended Kalman Filters, Actuator Lock},
location = {Vancouver, BC, Canada},
series = {ICVISP 2019}
}

@article{10.1016/j.jnca.2016.10.019,
author = {Muhammed, Thaha and Shaikh, Riaz Ahmed},
title = {An analysis of fault detection strategies in wireless sensor networks},
year = {2017},
issue_date = {January 2017},
publisher = {Academic Press Ltd.},
address = {GBR},
volume = {78},
number = {C},
issn = {1084-8045},
url = {https://doi.org/10.1016/j.jnca.2016.10.019},
doi = {10.1016/j.jnca.2016.10.019},
abstract = {Wireless sensor networks have emerged as a key technology which is used in many safety critical applications. The sensors in wireless sensor network have to be deployed in hostile, harsh and unattended environments for long periods of time. This creates a great challenge in providing a good quality of service. This results in introductions of faults, sensor failures, communication failures and changes in topology. Hence, efficient fault detection techniques are required for good quality of service. In this article, we survey various fault detection techniques and provide a new taxonomy to integrate new fault detection techniques. We perform a qualitative comparison of the latest fault detection algorithms. From a qualitative analysis, we select a list of techniques that are analyzed quantitatively. We also discuss the shortcomings, advantages and future research directions for fault detection in wireless sensor networks.},
journal = {J. Netw. Comput. Appl.},
month = jan,
pages = {267–287},
numpages = {21},
keywords = {Wireless sensor networks, Taxonomy, Faults, Fault-detection, 23-557}
}

@article{10.1016/j.cie.2017.08.035,
author = {Li, Shuai and Zhou, Xiaofeng and Pan, Fucheng and Shi, Haibo and Li, Kaituo and Wang, Zhongwei},
title = {Correlated and weakly correlated fault detection based on variable division and ICA},
year = {2017},
issue_date = {Oct 2017},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {112},
number = {C},
issn = {0360-8352},
url = {https://doi.org/10.1016/j.cie.2017.08.035},
doi = {10.1016/j.cie.2017.08.035},
journal = {Comput. Ind. Eng.},
month = oct,
pages = {320–335},
numpages = {16},
keywords = {Independent component analysis, Correlated and weakly correlated variables, Variable division, Monitoring, Fault detection}
}

@article{10.1109/32.815326,
author = {Fenton, Norman E. and Neil, Martin},
title = {A Critique of Software Defect Prediction Models},
year = {1999},
issue_date = {September 1999},
publisher = {IEEE Press},
volume = {25},
number = {5},
issn = {0098-5589},
url = {https://doi.org/10.1109/32.815326},
doi = {10.1109/32.815326},
abstract = {Many organizations want to predict the number of defects (faults) in software systems, before they are deployed, to gauge the likely delivered quality and maintenance effort. To help in this numerous software metrics and statistical models have been developed, with a correspondingly large literature. We provide a critical review of this literature and the state-of-the-art. Most of the wide range of prediction models use size and complexity metrics to predict defects. Others are based on testing data, the "quality" of the development process, or take a multivariate approach. The authors of the models have often made heroic contributions to a subject otherwise bereft of empirical studies. However, there are a number of serious theoretical and practical problems in many studies. The models are weak because of their inability to cope with the, as yet, unknown relationship between defects and failures. There are fundamental statistical and data quality problems that undermine model validity. More significantly many prediction models tend to model only part of the underlying problem and seriously misspecify it. To illustrate these points the "Goldilock's Conjecture," that there is an optimum module size, is used to show the considerable problems inherent in current defect prediction approaches. Careful and considered analysis of past and new results shows that the conjecture lacks support and that some models are misleading. We recommend holistic models for software defect prediction, using Bayesian Belief Networks, as alternative approaches to the single-issue models used at present. We also argue for research into a theory of "software decomposition" in order to test hypotheses about defect introduction and help construct a better science of software engineering.},
journal = {IEEE Trans. Softw. Eng.},
month = sep,
pages = {675–689},
numpages = {15},
keywords = {fault-density, defects, complexity metrics, Software faults and failures, Bayesian Belief Networks.}
}

@article{10.1016/j.engappai.2018.05.009,
author = {Siegel, Joshua E. and Pratt, Shane and Sun, Yongbin and Sarma, Sanjay E.},
title = {Real-time Deep Neural Networks for internet-enabled arc-fault detection},
year = {2018},
issue_date = {Sep 2018},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {74},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2018.05.009},
doi = {10.1016/j.engappai.2018.05.009},
journal = {Eng. Appl. Artif. Intell.},
month = sep,
pages = {35–42},
numpages = {8},
keywords = {Real-time, Arc fault detection, Distributed sensing, Embedded intelligence, Ambient intelligence, Intelligent infrastructure, Emerging applications and technology}
}

@inproceedings{10.1145/2811681.2817757,
author = {Yusop, Nor Shahida Mohamad},
title = {Understanding Usability Defect Reporting in Software Defect Repositories},
year = {2015},
isbn = {9781450337960},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2811681.2817757},
doi = {10.1145/2811681.2817757},
abstract = {Software defect management is a critical component of good software engineering practice. The information reported about a defect is a key element to ensure defects are rectified effectively. However, based on research, reporting usability defects using an existing defect tracking system (DTS) is impractical. This is due to text-centric design and lack of features to support usability attributes. In addition, not all defects can be explained textually; especially defects that involve interface redesign. Another aspect to consider is that the reporters describe usability defects based on their usability knowledge and the information available at the time the defects are found. Defects stored in a DTS in a universal format. Therefore, when reporting usability defects there are some possibilities: the data may not be relevant or irrelevant, useful or not useful, or may even be beyond the reporter's knowledge. This makes it impossible to submit a high quality defect report. To address these issues, I propose a custom defect template that can adjust defect form according to whom, when and how the defect is found. In this way, it will provide flexibility to the reporters to record data based on their expertise and knowledge.},
booktitle = {Proceedings of the ASWEC 2015 24th Australasian Software Engineering Conference},
pages = {134–137},
numpages = {4},
keywords = {software testing, defect reporting tools, Usability defect reporting},
location = {Adelaide, SA, Australia},
series = {ASWEC ' 15 Vol. II}
}

@inproceedings{10.1145/3377713.3377753,
author = {Lu, Qiwei and Cheng, Jinpei and Guo, Dianlin and Su, Mengmeng and Wu, Xuewei and Ru, Tao},
title = {Binary Classification Model Based on Machine Learning Algorithm for the Short-Circuit Detection in Power System},
year = {2020},
isbn = {9781450372619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377713.3377753},
doi = {10.1145/3377713.3377753},
abstract = {Short circuit faults usually occur in the damaged insulation lines or line connections, which will cause serious accidents such as fires and explosions. As the power supply distance increases, accuracy of short-circuit fault detection is insufficient and the process is tedious with the traditional analysis method. In order to solve the problems above, the short-circuit fault detection is classified into the two classification problems while the machine learning method is used. The data of the normal state and short circuit fault state are obtained by the short-circuit simulation experiment. Extract four features from time domain, including the average current and so on. By training support vector machine (SVM) using the different combinations of extraction features above, the model is obtained. The accuracy of classification of the test data set by the model is high. The results show that the short-circuit fault detection method based on machine learning is more accurate and robust than traditional analysis methods.},
booktitle = {Proceedings of the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence},
pages = {271–275},
numpages = {5},
keywords = {normalization, feature extraction, feature analysis, Short-circuit detection},
location = {Sanya, China},
series = {ACAI '19}
}

@article{10.1504/IJIIDS.2015.070825,
author = {Abaei, Golnoush and Mashinchi, M. Reza and Selamat, Ali},
title = {Software fault prediction using BP-based crisp artificial neural networks},
year = {2015},
issue_date = {July 2015},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {9},
number = {1},
issn = {1751-5858},
url = {https://doi.org/10.1504/IJIIDS.2015.070825},
doi = {10.1504/IJIIDS.2015.070825},
abstract = {Early fault detection for software reduces the cost of developments. Fault level can be predicted through learning mechanisms. Conventionally, precise metrics measure the fault level and crisp artificial neural networks CANNs perform the learning. However, the performance of CANNs depends on complexities of data and learning algorithm. This paper considers these two complexities to predict the fault level of software. We apply the principle component analysis PCA to reduce the dimensionality of data, and employ the correlation-based feature selection CFS to select the best features. CANNs, then, predict the fault level of software using back propagation BP algorithm as a learning mechanism. To investigate the performance of BP-based CANNs, we analyse varieties of dimensionality reduction. The results reveal the superiority of PCA to CFS in terms of accuracy.},
journal = {Int. J. Intell. Inf. Database Syst.},
month = jul,
pages = {15–31},
numpages = {17}
}

@article{10.1016/j.ins.2010.04.019,
author = {Peng, Yi and Wang, Guoxun and Wang, Honggang},
title = {User preferences based software defect detection algorithms selection using MCDM},
year = {2012},
issue_date = {May, 2012},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {191},
issn = {0020-0255},
url = {https://doi.org/10.1016/j.ins.2010.04.019},
doi = {10.1016/j.ins.2010.04.019},
abstract = {A variety of classification algorithms for software defect detection have been developed over the years. How to select an appropriate classifier for a given task is an important issue in Data mining and knowledge discovery (DMKD). Many studies have compared different types of classification algorithms and the performances of these algorithms may vary using different performance measures and under different circumstances. Since the algorithm selection task needs to examine several criteria, such as accuracy, computational time, and misclassification rate, it can be modeled as a multiple criteria decision making (MCDM) problem. The goal of this paper is to use a set of MCDM methods to rank classification algorithms, with empirical results based on the software defect detection datasets. Since the preferences of the decision maker (DM) play an important role in algorithm evaluation and selection, this paper involved the DM during the ranking procedure by assigning user weights to the performance measures. Four MCDM methods are examined using 38 classification algorithms and 13 evaluation criteria over 10 public-domain software defect datasets. The results indicate that the boosting of CART and the boosting of C4.5 decision tree are ranked as the most appropriate algorithms for software defect datasets. Though the MCDM methods provide some conflicting results for the selected software defect datasets, they agree on most top-ranked classification algorithms.},
journal = {Inf. Sci.},
month = may,
pages = {3–13},
numpages = {11},
keywords = {Software defect detection, Multi-criteria decision making (MCDM), Knowledge-driven data mining, Classification algorithm, Algorithm selection}
}

@article{10.5555/3319304.3319313,
title = {Survey on techniques of fault detection-rookies vantage point},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {1–2},
issn = {1740-8865},
abstract = {Cutting edge frameworks are turning out to be exceedingly configurable to fulfil the shifting requirements of clients and clients. Programming invention offerings are consequently turning into a typical pattern in programming improvement to decrease cost by empowering deliberate, expansive scale reuse. A few shortcomings may be uncovered just if a specific mix of components is chosen in the conveyed items. Yet, testing all mixes is typically not possible by and by, because of their to a great degree extensive numeral. Combinatorial testing is a method to produce littler test suites for which all mixes of t elements are ensured to be tried. In this research work, we display a few hypotheses depicting the likelihood of irregular testing to recognise connection blames and contrast the outcomes with combinatorial testing. For instance, an irregular testing turns out to be considerably more viable as the quantity of elements increments and focalises toward equivalent adequacy with combinatorial testing. Be that as it may, when imperatives are available among elements, then irregular testing can passage subjectively more awful than combinatorial testing. Subsequently, with a specific end goal to have a reasonable effect, future research ought to concentrate on combinatorial testing.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {133–141},
numpages = {9}
}

@article{10.1007/s00500-016-2316-6,
author = {Chinna Gounder Dhanajayan, Rajaganapathy and Appavu Pillai, Subramani},
title = {SLMBC: spiral life cycle model-based Bayesian classification technique for efficient software fault prediction and classification},
year = {2017},
issue_date = {January   2017},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {21},
number = {2},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-016-2316-6},
doi = {10.1007/s00500-016-2316-6},
abstract = {Software fault prediction and classification plays a vital role in the software development process for assuring high quality and reliability of the software product. Earlier prediction of the fault-prone software modules enables timely correction of the faults and delivery of reliable product. Generally, the fuzzy logic, decision tree and neural networks are deployed for fault prediction. But these techniques suffer due to low accuracy and inconsistency. To overcome these issues, this paper proposes a spiral life cycle model-based Bayesian classification technique for efficient software fault prediction and classification. In this process, initially the dependent and independent software modules are identified. The spiral life cycle model is used for testing the software modules in each life cycle of the software development process. Bayesian classification is applied to classify the software modules as faulty module and non-faulty module, by using the probability distribution models. Robust similarity-aware clustering algorithm performs clustering of the faulty and non-faulty software modules based on the similarity measure of the features in the dataset. From the experimental results, it is observed that the proposed method enables accurate prediction and classification of the faulty modules. The proposed technique achieves higher accuracy, precision, recall, probability of detection, F-measure and lower error rate than the existing techniques. The misclassification rate of the proposed technique is found to be lower than the existing techniques. Hence, the reliability of the software development process can be improved.},
journal = {Soft Comput.},
month = jan,
pages = {403–415},
numpages = {13},
keywords = {Spiral life cycle model-based Bayesian classification technique (SLMBC), Spiral life cycle model, Software development, Segregate fault prediction algorithm, Robust similarity-aware clustering (RSC) algorithm, Bayesian classification}
}

@inproceedings{10.1145/3429889.3429895,
author = {Zhao, Hanqing and Han, Bo and Li, Chen},
title = {Text classification of Diseases Treated by Traditional Chinese Medicine Prescription based on machine learning},
year = {2020},
isbn = {9781450388603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3429889.3429895},
doi = {10.1145/3429889.3429895},
abstract = {OBJECTIVE: To explore the application of machine learning in th e identification of diseases treated by traditional Chinese medicine prescriptions. METHODS: Based on the composition of the text document of Chinese medicine prescriptions, the prescriptions were divided into cough, headache and diarrhea. THUTCT were introduced to establish and train two machine learning text classification models, LibSVM and LibLinear, and the prescriptions to be deter mined were put into the model for classification and prediction. R ESULTS: The Precision rate of LibSVM model and Liblinear mod el were 0.7283 and 0.6690. Seven prescriptions were classified an d predicted, and the results were in line with expectations. CONCLUSION: THUCTC has good universality for the content of TCM prescriptions, high classification accuracy and fast testing speed, which is suitable for the text classification and discrimination research of TCM prescriptions for diseases.},
booktitle = {Proceedings of the 1st International Symposium on Artificial Intelligence in Medical Sciences},
pages = {28–32},
numpages = {5},
keywords = {Text Classification, TCM Informatization, Machine Learning, Formulaology of TCM, Big Data},
location = {Beijing, China},
series = {ISAIMS '20}
}

@article{10.1007/s10664-019-09735-4,
author = {Brindescu, Caius and Ahmed, Iftekhar and Jensen, Carlos and Sarma, Anita},
title = {An empirical investigation into merge conflicts and their effect on software quality},
year = {2020},
issue_date = {Jan 2020},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {25},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-019-09735-4},
doi = {10.1007/s10664-019-09735-4},
abstract = {Merge conflicts are known to cause extra effort for developers, but little is known about their effect on software. While some research has been done, many questions remain. To better understand merge conflicts and their impact we performed an empirical study about the types, frequency, and impact of merge conflicts, where impact is measured in terms of bug fixing commits associated with conflicts. We analyzed 143 open source projects and found that almost 1 in 5 merges cause conflicts. In 75.23% of these cases, a developer needed to reflect on the program logic to resolve it. We also found that the code associated with a merge conflict is twice as likely to have a bug. When the code associated with merge conflicts require manual intervention, the code is 26\texttimes{} more likely to have a bug.},
journal = {Empirical Softw. Engg.},
month = jan,
pages = {562–590},
numpages = {29},
keywords = {Mining software repositories, Empirical study, Software quality, Merge conflicts, Software merging, Version control}
}

@article{10.1145/3343440,
author = {Kaur, Harsurinder and Pannu, Husanbir Singh and Malhi, Avleen Kaur},
title = {A Systematic Review on Imbalanced Data Challenges in Machine Learning: Applications and Solutions},
year = {2019},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3343440},
doi = {10.1145/3343440},
abstract = {In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {79},
numpages = {36},
keywords = {sampling, machine learning, data analysis, Data imbalance}
}

@article{10.1007/s10845-021-01762-7,
author = {El Koujok, Mohamed and Ghezzaz, Hakim and Amazouz, Mouloud},
title = {Energy inefficiency diagnosis in industrial process through one-class machine learning techniques},
year = {2021},
issue_date = {Oct 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {32},
number = {7},
issn = {0956-5515},
url = {https://doi.org/10.1007/s10845-021-01762-7},
doi = {10.1007/s10845-021-01762-7},
abstract = {In the era of Industry 4.0, the ease of access to precise measurements in real-time and the existence of machine-learning (ML) techniques will play a vital role in building practical tools to isolate inefficiencies in energy-intensive processes. This paper aims at developing an abnormal event diagnosis (AED) tool based on ML techniques for monitoring the operation of industrial processes. This tool makes it easier for operators to accomplish their tasks and to make quick and accurate decisions to ensure highly efficient processes. One of the most popular ML techniques for AED is the multivariate statistical control (MSC) method; it only requires the dataset of the normal operating conditions (NOC) to detect and identify the variables that contribute to abnormal events (AEs). Despite the popularity of MSC, it is challenging to select the appropriate method for detecting and isolating all possible abnormalities a complex industrial process can experience. To address this limitation and improve efficiency, we have developed a generic methodology that integrates different ML techniques into a unified multiagent based approach, the selected ML techniques are supposed to be built using only the normal operating condition. For the sake of demonstration, we chose a combination of two ML methods: principal component analysis and k-nearest neighbors (k-NN). The k-NN was integrated into the proposed multiagent to take into account the nonlinearity and multimodality that frequently occur in industrial processes. In addition, we modified a k-NN method proposed in the literature to reduce computation time during real-time detection and isolation. Finally, the proposed methodology was successfully validated to monitor the energy efficiency of a reboiler located in a thermomechanical pulp mill.},
journal = {J. Intell. Manuf.},
month = oct,
pages = {2043–2060},
numpages = {18},
keywords = {Decision support systems, Multiagent approach, Augmented intelligence, Machine-learning techniques, Abnormal event diagnosis, Industrial and process efficiency}
}

@article{10.1016/j.engappai.2015.11.005,
author = {Fontes, Cristiano Hora and Pereira, Otac\'{\i}lio},
title = {Pattern recognition in multivariate time series - A case study applied to fault detection in a gas turbine},
year = {2016},
issue_date = {March 2016},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {49},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2015.11.005},
doi = {10.1016/j.engappai.2015.11.005},
abstract = {Advances in information technology, together with the evolution of systems in control, automation and instrumentation have enabled the recovery, storage and manipulation of a large amount of data from industrial plants. This development has motivated the advancement of research in fault detection, especially based on process history data. Although a large amount of work has been conducted in recent years on the diagnostics of gas turbines, few of them present the use of clustering approaches applied to multivariate time series, adopting PCA similarity factor (SPCA) in order to detect and/or prevent failures. This paper presents a comprehensive method for pattern recognition associated to fault prediction in gas turbines using time series mining techniques. Algorithms comprising appropriate similarity metrics, subsequence matching and fuzzy clustering were applied on data extracted from a Plant Information Management System (PIMS) represented by multivariate time series. A real case study comprising the fault detection in a gas turbine was investigated. The results suggest the existence of a safe way to start the turbine that can be useful to support the development of a dynamic system for monitoring and predicting the probability of failure and for decision-making at operational level. Real case study comprising the fault detection in a gas turbine.Comprehensive method for pattern recognition associated to fault prediction in gas turbines.Results show the efficiency of the proposed approach for decision-making at operational level.The whole three step method presented is flexible and portable.An extended version of the FCM algorithm suitable for the clustering of multivariate time series is applied.},
journal = {Eng. Appl. Artif. Intell.},
month = mar,
pages = {10–18},
numpages = {9},
keywords = {Multivariate time series, Gas turbines, Fault detection, Data mining, Clustering}
}

@article{10.5555/3319290.3319303,
title = {Support vector machine based fault detection and diagnosis for HVAC systems},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {1–2},
issn = {1740-8865},
abstract = {Various faults occurred in the heating, ventilation and airconditioning HVAC systems usually lead to more energy consumption and worse thermal comfort inevitably. This paper presents a feasible and valid solution of HVAC fault detection and diagnosis FDD problem based on statistical machine learning technology. It learns the consistent nature of different types of faults of HVAC operation based on support vector machine SVM, and then identify types of fault in all subsystems using the statistical relationships between groups of measurements. In order to speed up the learning process, principle component analysis PCA has been applied to compress the training data. Our approach models the dynamical sub-systems and sequence data in HVAC system. The learnt models can then be used for automatic fault detection and diagnosis. The approach has been tested on commercial HVAC systems. It had successfully detected and identified a number of typical AHU faults.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {204–222},
numpages = {19}
}

@article{10.1007/s10586-018-1795-x,
author = {Zhu, Wei and Wei, Yingsan and Xiao, Huan},
title = {Fault diagnosis of neural network classified signal fractal feature based on SVM},
year = {2019},
issue_date = {Mar 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {22},
number = {2},
issn = {1386-7857},
url = {https://doi.org/10.1007/s10586-018-1795-x},
doi = {10.1007/s10586-018-1795-x},
abstract = {The fault diagnosis method based on neural network has many defects, such as complicated network, long training time and slow convergence speed. The particle swarm optimization and neural network integration fault diagnosis methods are proposed to improve the fault diagnosis capability. Firstly, the heuristic global optimization capability of particle swarm optimization is used to optimize the neural network connection weights; then the transformer fault samples are trained and tested by using non-linear processing capacity of neural network. The test results show that such algorithm can effectively avoid unstable neural network, easily falling into local minimum and lower diagnostic accuracy etc. and can effectively increase the convergence speed and fault diagnosis efficiency compared with traditional fault diagnosis method.},
journal = {Cluster Computing},
month = mar,
pages = {4249–4254},
numpages = {6},
keywords = {Transformer, Fault diagnosis, Neural network, Particle swarm optimization}
}

@article{10.1016/j.procs.2015.02.041,
author = {Dhanalaxmi, B. and Naidu, G. Apparao and Anuradha, K.},
title = {Adaptive PSO Based Association Rule Mining Technique for Software Defect Classification Using ANN},
year = {2015},
issue_date = {2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {46},
number = {C},
issn = {1877-0509},
url = {https://doi.org/10.1016/j.procs.2015.02.041},
doi = {10.1016/j.procs.2015.02.041},
journal = {Procedia Comput. Sci.},
month = jan,
pages = {432–442},
numpages = {11},
keywords = {Defect prevention., Software testing, Artificial neural network, Adaptive particle swarm optimization algorithm, Association rule mining}
}

@inproceedings{10.5555/3199700.3199718,
author = {Liu, Yannan and Wei, Lingxiao and Luo, Bo and Xu, Qiang},
title = {Fault injection attack on deep neural network},
year = {2017},
publisher = {IEEE Press},
abstract = {Deep neural network (DNN), being able to effectively learn from a training set and provide highly accurate classification results, has become the de-facto technique used in many mission-critical systems. The security of DNN itself is therefore of great concern. In this paper, we investigate the impact of fault injection attacks on DNN, wherein attackers try to misclassify a specified input pattern into an adversarial class by modifying the parameters used in DNN via fault injection. We propose two kinds of fault injection attacks to achieve this objective. Without considering stealthiness of the attack, single bias attack (SBA) only requires to modify one parameter in DNN for misclassification, based on the observation that the outputs of DNN may linearly depend on some parameters. Gradient descent attack (GDA) takes stealthiness into consideration. By controlling the amount of modification to DNN parameters, GDA is able to minimize the fault injection impact on input patterns other than the specified one. Experimental results demonstrate the effectiveness and efficiency of the proposed attacks.},
booktitle = {Proceedings of the 36th International Conference on Computer-Aided Design},
pages = {131–138},
numpages = {8},
keywords = {neural network, misclassification, fault injection},
location = {Irvine, California},
series = {ICCAD '17}
}

@article{10.2478/acss-2021-0003,
author = {undefinedikiforova, Oksana and Zabiniako, Vitaly and Kornienko, Jurijs and Gasparovi\v{c}a-Asundefinedte, Madara and Siliundefineda, Amanda},
title = {Mapping of Source and Target Data for Application to Machine Learning Driven Discovery of IS Usability Problems},
year = {2021},
issue_date = {May 2021},
publisher = {Walter de Gruyter GmbH},
address = {Berlin, DEU},
volume = {26},
number = {1},
issn = {2255-8691},
url = {https://doi.org/10.2478/acss-2021-0003},
doi = {10.2478/acss-2021-0003},
abstract = {Improving IS (Information System) end-user experience is one of the most important tasks in the analysis of end-users behaviour, evaluation and identification of its improvement potential. However, the application of Machine Learning methods for the UX (User Experience) usability and effic iency improvement is not widely researched. In the context of the usability analysis, the information about behaviour of end-users could be used as an input, while in the output data the focus should be made on non-trivial or difficult attention-grabbing events and scenarios. The goal of this paper is to identify which data potentially can serve as an input for Machine Learning methods (and accordingly graph theory, transformation methods, etc.), to define dependency between these data and desired output, which can help to apply Machine Learning / graph algorithms to user activity records.},
journal = {Appl. Comput. Syst.},
month = may,
pages = {22–30},
numpages = {9},
keywords = {User Experience (UX), Machine Learning, IS usability, Data mapping}
}

@article{10.1016/j.knosys.2019.03.008,
author = {Li, Xiangju and Feng, Shi and Wang, Daling and Zhang, Yifei},
title = {Context-aware emotion cause analysis with multi-attention-based neural network},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {174},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2019.03.008},
doi = {10.1016/j.knosys.2019.03.008},
journal = {Know.-Based Syst.},
month = jun,
pages = {205–218},
numpages = {14},
keywords = {Interaction, Context, Neural network, Multi-attention mechanism, Emotion cause analysis}
}

@article{10.5555/3319304.3319317,
title = {Support vector machine based fault detection and diagnosis for HVAC systems},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {1–2},
issn = {1740-8865},
abstract = {Various faults occurred in the heating, ventilation and airconditioning HVAC systems usually lead to more energy consumption and worse thermal comfort inevitably. This paper presents a feasible and valid solution of HVAC fault detection and diagnosis FDD problem based on statistical machine learning technology. It learns the consistent nature of different types of faults of HVAC operation based on support vector machine SVM, and then identify types of fault in all subsystems using the statistical relationships between groups of measurements. In order to speed up the learning process, principle component analysis PCA has been applied to compress the training data. Our approach models the dynamical sub-systems and sequence data in HVAC system. The learnt models can then be used for automatic fault detection and diagnosis. The approach has been tested on commercial HVAC systems. It had successfully detected and identified a number of typical AHU faults.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {204–222},
numpages = {19}
}

@article{10.1016/j.neucom.2019.01.054,
author = {Li, Yang and Lu, Ningyun and Wang, Xiuli and Jiang, Bin},
title = {Islanding fault detection based on data-driven approach with active developed reactive power variation},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {337},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.01.054},
doi = {10.1016/j.neucom.2019.01.054},
journal = {Neurocomput.},
month = apr,
pages = {97–109},
numpages = {13},
keywords = {Data-driven islanding detection method, Logic operation, K-means cluster, False alarm, Pseudo islanding phenomenon (PIP)}
}

@article{10.1016/j.eswa.2009.10.041,
author = {Ghate, Vilas N. and Dudul, Sanjay V.},
title = {Optimal MLP neural network classifier for fault detection of three phase induction motor},
year = {2010},
issue_date = {April, 2010},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {37},
number = {4},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2009.10.041},
doi = {10.1016/j.eswa.2009.10.041},
abstract = {Induction motors are critical components in commercially available equipments and industrial processes due to cost effective and robust performance. Under various operating stresses, motors deteriorate their conditions which result into various faults. Early detection and diagnosis of these faults are desirable for online condition assessment, product quality assurance and improved operational efficiency. From the related work reported so far it is observed that researchers used vibration analysis, harmonics present in stator current, chemical analysis, electromagnetic analysis, etc. As these approaches are complex in view of the requirement of precise measurement and mathematical modeling. As compared to analytical methods, AI based schemes are more efficient and accurate. In this paper optimal MLP NN based classifier is proposed for fault detection which is inexpensive, reliable, and noninvasive by employing more readily available information such as stator current. Detailed design procedure for MLP and SOM NN models is given for which simple statistical parameters are used as input feature space and Principal Component Analysis is used for reduction of input dimensionality. Robustness of classifier to noise is verified on unseen data by introducing controlled Gaussian and Uniform noise in input and output.},
journal = {Expert Syst. Appl.},
month = apr,
pages = {3468–3481},
numpages = {14},
keywords = {SOM, PCA, MLP, Induction motor, Fault detection}
}

@article{10.1145/3477016,
author = {Hosseini, Fateme S. and Meng, Fanruo and Yang, Chengmo and Wen, Wujie and Cammarota, Rosario},
title = {Tolerating Defects in Low-Power Neural Network Accelerators Via Retraining-Free Weight Approximation},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3477016},
doi = {10.1145/3477016},
abstract = {Hardware accelerators are essential to the accommodation of ever-increasing Deep Neural Network (DNN) workloads on the resource-constrained embedded devices. While accelerators facilitate fast and energy-efficient DNN operations, their accuracy is threatened by faults in their on-chip and off-chip memories, where millions of DNN weights are held. The use of emerging Non-Volatile Memories (NVM) further exposes DNN accelerators to a non-negligible rate of permanent defects due to immature fabrication, limited endurance, and aging. To tolerate defects in NVM-based DNN accelerators, previous work either requires extra redundancy in hardware or performs defect-aware retraining, imposing significant overhead. In comparison, this paper proposes a set of algorithms that exploit the flexibility in setting the fault-free bits in weight memory to effectively approximate weight values, so as to mitigate defect-induced accuracy drop. These algorithms can be applied as a one-step solution when loading the weights to embedded devices. They only require trivial hardware support and impose negligible run-time overhead. Experiments on popular DNN models show that the proposed techniques successfully boost inference accuracy even in the face of elevated defect rates in the weight memory.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = sep,
articleno = {85},
numpages = {21},
keywords = {approximation, memory faults, reliability, defect tolerance, Neural network accelerator}
}

@inproceedings{10.1145/3266237.3266273,
author = {Braga, Rony\'{e}rison and Neto, Pedro Santos and Rab\^{e}lo, Ricardo and Santiago, Jos\'{e} and Souza, Matheus},
title = {A machine learning approach to generate test oracles},
year = {2018},
isbn = {9781450365031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3266237.3266273},
doi = {10.1145/3266237.3266273},
abstract = {One of the essential activities for quality assurance in software development is the software testing. Studies report that Software Testing is one of the most costly activities in the development process, can reach up to 50 percent of its total cost. One of the great challenges of conducting software testing is related to the automation of a mechanism known as "test oracle". This work presents an approach based on machine learning (ML) for automation of the test oracle mechanism in software. The approach uses historical usage data from an application captured by inserting a capture component into the application under test. These data go through a Knowledge Discovery in Database step and are then used for training to generate an oracle suitable for the application under test. Four experiments were executed with web applications to evaluate the proposed approach. The first and second experiments were performed with a fictitious application, with faults inserted randomly in the first experiment, inserted by a developer in the second one and inserted by mutation tests in third one. The fourth experiment was carried out with a large real application in order to assure the results of the preliminary experiments. The experiments presented indications of the suitability of the approach to the solution of the problem.},
booktitle = {Proceedings of the XXXII Brazilian Symposium on Software Engineering},
pages = {142–151},
numpages = {10},
keywords = {testing automation, test oracle, machine learning},
location = {Sao Carlos, Brazil},
series = {SBES '18}
}

@article{10.1007/s11227-017-2053-3,
author = {Bui, Dinh-Mao and Huynh-The, Thien and Lee, Sungyoung},
title = {Early fault detection in IaaS cloud computing based on fuzzy logic and prediction technique},
year = {2018},
issue_date = {November  2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {74},
number = {11},
issn = {0920-8542},
url = {https://doi.org/10.1007/s11227-017-2053-3},
doi = {10.1007/s11227-017-2053-3},
abstract = {Availability is one of the most important requirements in production system. Keeping a persistent level of high availability in the Infrastructure-as-a-Service (IaaS) cloud computing is a challenge due to the complexity of service providing. By definition, the availability can be maintained by coupling with the fault tolerance approaches. Recently, many fault tolerance methods have been developed, but few of them adequately consider the fault detection aspect, which is critical to issue the appropriate recovery actions just in time. In this paper, based on a rigorous analysis on the nature of failures, we would like to introduce a method to early identify the faults occurring in the IaaS system. By engaging fuzzy logic algorithm and prediction technique, the proposed approach can provide better performance in terms of accuracy and reaction rate, which subsequently enhances the system reliability.},
journal = {J. Supercomput.},
month = nov,
pages = {5730–5745},
numpages = {16},
keywords = {Prediction technique, IaaS cloud computing, Fuzzy logic, Fault detection, Approximate reasoning}
}

@article{10.1007/s00521-017-3295-y,
author = {Mishra, Debani Prasad and Ray, Papia},
title = {Fault detection, location and classification of a transmission line},
year = {2018},
issue_date = {September 2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {30},
number = {5},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-017-3295-y},
doi = {10.1007/s00521-017-3295-y},
abstract = {Transient stability is very important in power system. Large disturbances like fault in a transmission line are a concern which needs to be disconnected as quickly as possible in order to restore the transient stability. Faulty current and voltage signals are used for location, detection and classification of faults in a transmission network. Relay detects an abnormal signal, and then the circuit breaker disconnects the unhealthy transmission line from the rest of the health system. This paper discusses various signal processing techniques, impedance-based measurement method, travelling wave phenomenon-based method, artificial intelligence-based method and some special technique for the detection, location and classification of various faults in a transmission network. In this survey, paper signifies all method and techniques till August 2017. This compact and effective survey helps the researcher to understand different techniques and methods.},
journal = {Neural Comput. Appl.},
month = sep,
pages = {1377–1424},
numpages = {48},
keywords = {Transmission line, Signal processing technique, Location, Detection, Classification, Artificial intelligence}
}

@inproceedings{10.1145/3185089.3185152,
author = {Li, Boshu and Wu, Wenjun and Hu, Zhenhui},
title = {Evaluation of Software Quality for Competition-based Software Crowdsourcing Projects},
year = {2018},
isbn = {9781450354141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185089.3185152},
doi = {10.1145/3185089.3185152},
abstract = {Crowdsourcing-based Software Development (CSSD) performs as: many software practitioners use their own experience and technology to participate software development related tasks, through the open platform such as TopCoder. Crowdsourcing software quality issue has caught some researchers' attention, but it is still far from enough, and no work has been done on evaluating crowdsourcing software projects from a macro point of view. In the paper, we apply traditional quality evaluation practice and theory into the evaluation of crowdsourcing-based software quality by proper modification. The main contributions of this paper are: evaluate TopCoder software quality from the perspective of Project Rating and Project Effort respectively, and explore their aggregation strategies. In order to explore the relationship between them, we introduce the definition of quality assurance effort. We believe the final project rating indicator and quality assurance effort can help a project manager to make reasonable decisions on crowdsourcing-based software development tasks.},
booktitle = {Proceedings of the 2018 7th International Conference on Software and Computer Applications},
pages = {102–109},
numpages = {8},
keywords = {TopCoder, Software Quality, Software Competition, Quality Assurance Effort, Project Rating, Project Effort, Crowdsourcing-based Software Development},
location = {Kuantan, Malaysia},
series = {ICSCA '18}
}

@article{10.3233/KES-190421,
author = {Panigrahi, Rasmita and Kuanar, Sanjay K. and Kumar, Lov and Padhy, Neelamadhab and Satapathy, Suresh Chandra},
title = {Software reusability metrics prediction and cost estimation by using machine learning algorithms},
year = {2019},
issue_date = {2019},
publisher = {IOS Press},
address = {NLD},
volume = {23},
number = {4},
issn = {1327-2314},
url = {https://doi.org/10.3233/KES-190421},
doi = {10.3233/KES-190421},
abstract = {In this research, a highly robust and efficient software design optimization model has been proposed for object-oriented programming based software solutions while considering the importance of quality and reliability. Due to a piece of information that software component reusability has allowed cost and time-efficient software design. The software reusability metrics prediction and cost estimation play a vital role in the software industry. Software quality prediction is an important feature that can be achieved a novel machine learning approach. It is a process of gathering and analyzing recurring patterns in software metrics. Machine learning techniques play a crucial role in intelligent decision making and proactive forecasting. This paper focuses on analyzing software reusability and cost estimation metrics by providing the data set. In the present world software, cost estimation and reusability prediction problem has been resolved using various newly developed methods. This paper emphasizes to solve the novel machine learning algorithms as well as improved Output layer self-connection recurrent neural networks (OLSRNN) with kernel fuzzy c-means clustering (KFCM). The investigational results confirmed the competence of the proposed method for solving software reusability and cost estimation.},
journal = {Int. J. Know.-Based Intell. Eng. Syst.},
month = jan,
pages = {317–328},
numpages = {12},
keywords = {software cost estimation, machine learning techniques, software reusability metrics, Object-Oriented Metrics}
}

@article{10.1016/j.micpro.2021.104359,
author = {Li, Yanfei and Geng, Tong and Li, Ang and Yu, Huimin},
title = {BCNN: Binary complex neural network},
year = {2021},
issue_date = {Nov 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {87},
number = {C},
issn = {0141-9331},
url = {https://doi.org/10.1016/j.micpro.2021.104359},
doi = {10.1016/j.micpro.2021.104359},
journal = {Microprocess. Microsyst.},
month = nov,
numpages = {10},
keywords = {Complex number, Smart edges, Complex neural networks, Binarized network networks}
}

@article{10.1016/j.eswa.2020.114176,
author = {AlOmar, Eman Abdullah and Peruma, Anthony and Mkaouer, Mohamed Wiem and Newman, Christian and Ouni, Ali and Kessentini, Marouane},
title = {How we refactor and how we document it? On the use of supervised machine learning algorithms to classify refactoring documentation},
year = {2021},
issue_date = {Apr 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {167},
number = {C},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2020.114176},
doi = {10.1016/j.eswa.2020.114176},
journal = {Expert Syst. Appl.},
month = apr,
numpages = {26},
keywords = {Machine learning, Software engineering, Software quality, Refactoring}
}

@article{10.5555/3319290.3319299,
title = {Survey on techniques of fault detection-rookies vantage point},
year = {2019},
issue_date = {January 2019},
publisher = {Inderscience Publishers},
address = {Geneva 15, CHE},
volume = {18},
number = {1–2},
issn = {1740-8865},
abstract = {Cutting edge frameworks are turning out to be exceedingly configurable to fulfil the shifting requirements of clients and clients. Programming invention offerings are consequently turning into a typical pattern in programming improvement to decrease cost by empowering deliberate, expansive scale reuse. A few shortcomings may be uncovered just if a specific mix of components is chosen in the conveyed items. Yet, testing all mixes is typically not possible by and by, because of their to a great degree extensive numeral. Combinatorial testing is a method to produce littler test suites for which all mixes of t elements are ensured to be tried. In this research work, we display a few hypotheses depicting the likelihood of irregular testing to recognise connection blames and contrast the outcomes with combinatorial testing. For instance, an irregular testing turns out to be considerably more viable as the quantity of elements increments and focalises toward equivalent adequacy with combinatorial testing. Be that as it may, when imperatives are available among elements, then irregular testing can passage subjectively more awful than combinatorial testing. Subsequently, with a specific end goal to have a reasonable effect, future research ought to concentrate on combinatorial testing.},
journal = {Int. J. Intell. Syst. Technol. Appl.},
month = jan,
pages = {133–141},
numpages = {9}
}

@article{10.1155/2018/4349795,
author = {Cheng, Yong and Liu, Qiuyue and Wang, Jun and Wan, Shaohua and Umer, Tariq and Wu, Huaming},
title = {Distributed Fault Detection for Wireless Sensor Networks Based on Support Vector Regression},
year = {2018},
issue_date = {2018},
publisher = {John Wiley and Sons Ltd.},
address = {GBR},
volume = {2018},
issn = {1530-8669},
url = {https://doi.org/10.1155/2018/4349795},
doi = {10.1155/2018/4349795},
abstract = {Because the existing approaches for diagnosing sensor networks lead to low precision and high complexity, a new fault detection mechanism based on support vector regression and neighbor coordination is proposed in this work. According to the redundant information about meteorological elements collected by a multisensor, a fault prediction model is built using a support vector regression algorithm, and it achieves residual sequences. Then, the node status is identified by mutual testing among reliable neighbor nodes. Simulations show that when the sensor fault probability in wireless sensor networks is 40%, the detection accuracy of the proposed algorithm is over 87%, and the false alarm ratio is below 7%. The detection accuracy is increased by up to 13%, in contrast to other algorithms. This algorithm not only reduces the communication to sensor nodes but also has a high detection accuracy and a low false alarm ratio. The proposed algorithm is suitable for fault detection in meteorological sensor networks with low node densities and high failure ratios.},
journal = {Wirel. Commun. Mob. Comput.},
month = jan,
numpages = {8}
}

@article{10.1007/s11042-016-3981-2,
author = {Zhai, Yongjie and Wang, Di and Zhang, Muliu and Wang, Jiarong and Guo, Feng},
title = {Fault detection of insulator based on saliency and adaptive morphology},
year = {2017},
issue_date = {May       2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {76},
number = {9},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-016-3981-2},
doi = {10.1007/s11042-016-3981-2},
abstract = {We study the problem of glass insulator fault detection from image in this work. It is a challenging task as no reliable electromagnetism cues are available. Since the characteristics of insulator fault are not clear and the positions of the insulator fault are uncertain. Previous efforts have been focusing on insulator classification and the insulator location. Recently, there is mounting evidence that saliency detection are setting new records for various vision applications. On the other hand, considering the particularly structure of insulator, fault detection can be naturally enhanced by morphology problem. Therefore, we in this paper present a saliency and adaptive morphological based insulator fault detection algorithm, aiming to jointly explore the capacity of saliency and morphology. Specifically, we propose an adaptive learning scheme which learns the saliency and morphology in a unified adaptive framework. According to the experiment, we can process most of the circumstances with 92 % accuracy in 0.5 second on average, which suits the Unmanned Aerial Vehicle (UAV) patrol device well.},
journal = {Multimedia Tools Appl.},
month = may,
pages = {12051–12064},
numpages = {14},
keywords = {Saliency, Glass insulator, Fault detection, Adaptive morphological}
}

@article{10.1016/j.engappai.2015.07.020,
author = {Atoui, Mohamed Amine and Verron, Sylvain and Kobi, Abdessamad},
title = {Fault detection with Conditional Gaussian Network},
year = {2015},
issue_date = {October 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {45},
number = {C},
issn = {0952-1976},
url = {https://doi.org/10.1016/j.engappai.2015.07.020},
doi = {10.1016/j.engappai.2015.07.020},
abstract = {The main interest of this paper is to illustrate a new representation of the Principal Component Analysis (PCA) for fault detection under a Conditional Gaussian Network (CGN), a special case of Bayesian networks. PCA and its associated quadratic statistics such as T2 and SPE are integrated under a sole CGN. The proposed framework projects a new observation into an orthogonal space and gives probabilities on the state of the system. It could do so even when some data in the sample test are missing. This paper also gives the probabilities thresholds to use in order to match quadratic statistics decisions. The proposed network is validated and compared to the standard PCA scheme for fault detection on the Tennessee Eastman Process and the Hot Forming Process.},
journal = {Eng. Appl. Artif. Intell.},
month = oct,
pages = {473–481},
numpages = {9},
keywords = {Tennessee Eastman Process, Statistical inference, PCA, Hot Forming Process, Fault detection, Conditional Gaussian Networks}
}

@article{10.1002/acs.2931,
author = {Kallas, Maya and Mourot, Gilles and Maquin, Didier and Ragot, Jos\'{e}},
title = {Data‐driven approach for fault detection and isolation in nonlinear system},
year = {2018},
issue_date = {November 2018},
publisher = {John Wiley &amp; Sons, Inc.},
address = {USA},
volume = {32},
number = {11},
issn = {0890-6327},
url = {https://doi.org/10.1002/acs.2931},
doi = {10.1002/acs.2931},
abstract = {System diagnosis has been of a great interest for all aspects of industrial processes more precisely to gain in quality. It is based essentially on the analysis of the links between the variables of a system and more precisely on the changes of the relations between these variables, which testify to the presence of faults or anomalies. For that purpose, data modeling is the process of finding a mathematical expression that provides a good fit between given finite sample values of the independent variables and the associated values of the dependent variables of the process.The aim of this paper is to detect and, above all, localize faults affecting a system with nonlinear behavior, when its model is not known a priori. An important part of the presentation is dedicated to the construction of fault indicators capable of locating faults, ie, recognizing the input or output of a system affected by a fault. The first part of this paper is devoted to how to predict the output of a nonlinear behavior system. The second part proposes a way for the detection and isolation of measurement faults based on the proposed prediction model. The relevance of the proposed technique, for modeling and system diagnosis, is illustrated on a simulated example in the context of SIMO and MIMO systems.},
journal = {Int. J. Adapt. Control Signal Process.},
month = nov,
pages = {1569–1590},
numpages = {22},
keywords = {nonlinear systems, kernel, fault isolation, fault detection, data‐driven approach}
}

@article{10.1007/s11265-019-01463-8,
author = {Gao, Shengyao and Wang, Xueren and Miao, Xuhong and Su, Changwei and Li, Yibin},
title = {ASM1D-GAN: An Intelligent Fault Diagnosis Method Based on Assembled 1D Convolutional Neural Network and Generative Adversarial Networks},
year = {2019},
issue_date = {Oct 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {91},
number = {10},
issn = {1939-8018},
url = {https://doi.org/10.1007/s11265-019-01463-8},
doi = {10.1007/s11265-019-01463-8},
abstract = {For the past few years, In the research of intelligent monitoring of industrial equipment, deep learning is becoming a method that get the widespread concern of researchers. In general, the collection of a great quantity of typical data that has been labeled makes the deep learning approach a great success. However, it is often limited by real fault data samples, and the generalization ability of the established model is poor. A novel fault diagnostic method that we assemble data generation and fault diagnosis called ASM1D-GAN is proposed to address these problems. This method is composed of 1D convolutional neural network, Generative Adversarial Networks (GANs), and fault classifier. We assemble the data generation and fault diagnosis procedures together. Through a new antagonistic machine learning mechanism, the ASM1D-GAN model is optimized, so as to achieve higher sample quality and fault mode classification ability. This novel method can extract fault features from natural fault samples and generate effective new ones. The experimental results demonstrate the effective fault feature generation ability and the superior fault diagnostic ability of the proposed method.},
journal = {J. Signal Process. Syst.},
month = oct,
pages = {1237–1247},
numpages = {11},
keywords = {Artificial intelligence, Fault diagnosis, 1D convolutional neural network, Generative Adversarial Networks}
}

@article{10.1016/j.eswa.2015.01.023,
author = {Braida, Filipe and Mello, Carlos E. and Pasinato, Marden B. and Zimbr\~{a}o, Geraldo},
title = {Transforming collaborative filtering into supervised learning},
year = {2015},
issue_date = {June 2015},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {42},
number = {10},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2015.01.023},
doi = {10.1016/j.eswa.2015.01.023},
abstract = {We propose an transformation from CF problem to typical supervised learning.The proposed transformation is straightforward and domain-independent.Our transformation greatly outperforms classical collaborative filtering techniques. Collaborative Filtering (CF) is a well-known approach for Recommender Systems (RS). This approach extrapolates rating predictions from ratings given by user on items, which are represented by a user-item matrix filled with a rating r i , j given by an user i on an item j. Therefore, CF has been confined to this data structure relying mostly on adaptations of supervised learning methods to deal with rating predictions and matrix decomposition schemes to complete unfilled positions of the rating matrix. Although there have been proposals to apply Machine Learning (ML) to RS, these works had to transform the rating matrix into the typical Supervised Learning (SL) data set, i.e., a set of pairwise tuples ( x , y ) , where y is the correspondent class (the rating) of the instance x R k . So far, the proposed transformations were thoroughly crafted using the domain information. However, in many applications this kind of information can be incomplete, uncertain or stated in ways that are not machine-readable. Even when it is available, its usage can be very complex requiring specialists to craft the transformation. In this context, this work proposes a domain-independent transformation from the rating matrix representation to a supervised learning dataset that enables SL methods to be fully explored in RS. In addition, our transformation is said to be straightforward, in the sense that, it is an automatic process that any lay person can perform requiring no domain specialist. Our experiments have proven that our transformation, combined with SL methods, have greatly outperformed classical CF methods.},
journal = {Expert Syst. Appl.},
month = jun,
pages = {4733–4742},
numpages = {10},
keywords = {Supervised learning, Recommender system, Dimensionality reduction, Collaborative filtering}
}

@inproceedings{10.1145/3094243.3094245,
author = {Pang, Yulei and Xue, Xiaozhen and Wang, Huaying},
title = {Predicting Vulnerable Software Components through Deep Neural Network},
year = {2017},
isbn = {9781450352321},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3094243.3094245},
doi = {10.1145/3094243.3094245},
abstract = {Vulnerabilities need to be detected and removed from software. Although previous studies demonstrated the usefulness of employing prediction techniques in deciding about vulnerabilities of software components, the improvement of effectiveness of these prediction techniques is still a grand challenging research question. This paper employed a technique based on a deep neural network with rectifier linear units trained with stochastic gradient descent method and batch normalization, for predicting vulnerable software components. The features are defined as continuous sequences of tokens in source code files. Besides, a statistical feature selection algorithm is then employed to reduce the feature and search space. We evaluated the proposed technique based on some Java Android applications, and the results demonstrated that the proposed technique could predict vulnerable classes, i.e., software components, with high precision, accuracy and recall.},
booktitle = {Proceedings of the 2017 International Conference on Deep Learning Technologies},
pages = {6–10},
numpages = {5},
keywords = {vulnerability prediction, neural network, deep learning, Android},
location = {Chengdu, China},
series = {ICDLT '17}
}

@inproceedings{10.1145/3379310.3379327,
author = {Alqadri, Yuki and Budiardjo, Eko K. and Ferdinansyah, Alex and Rokhman, Mokhammad F.},
title = {The CMMI-Dev Implementation Factors for Software Quality Improvement: A Case of XYZ Corporation},
year = {2020},
isbn = {9781450376853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379310.3379327},
doi = {10.1145/3379310.3379327},
abstract = {Refer to CMMI-Institute Appraisal result, there are 6 (six) companies in Indonesia that have achieved CMMI-Dev v1.3 maturity level 3, one of them is XYZ Corporation. Initially, XYZ Corporation has set a target to achieve CMMI-Dev level 2. As advised by the consultant, XYZ Corporation has a possibility to achieve level 3 by completing several parts of level 3 requirements that had not been met yet. XYZ Corporation faced a significant problem in progress implementation, particularly in documents standardization. This is due to each division has a different document format. XYZ Corporation also needs to improve its current processes that are still in ongoing phase of improvement process to achieve better standardized. This research aims to find out "The factors that affects the success of CMMI-Dev implementation based on its Current Conditions of XYZ Corporation". The approach of this research in finding the factors that influence the implementation of CMMI-Dev by means Qualitative and Quantitative approach. A qualitative method, by means of questionnaires, is used to prioritize the main factor. A quantitative method is used to get ranking of the factors that affecting successfulness of CMMI-Dev implementation in which has been validated by questionnaire's results. This research finding expects that the factors could be applied by other companies which desire to implement CMMI-Dev.},
booktitle = {Proceedings of the 2020 2nd Asia Pacific Information Technology Conference},
pages = {34–40},
numpages = {7},
keywords = {Software Quality Management (SQM), Software Process Improvement (SPI), CMMI-Dev},
location = {Bali Island, Indonesia},
series = {APIT '20}
}

@inproceedings{10.1145/2597073.2597075,
author = {Fukushima, Takafumi and Kamei, Yasutaka and McIntosh, Shane and Yamashita, Kazuhiro and Ubayashi, Naoyasu},
title = {An empirical study of just-in-time defect prediction using cross-project models},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2597073.2597075},
doi = {10.1145/2597073.2597075},
abstract = {Prior research suggests that predicting defect-inducing changes, i.e., Just-In-Time (JIT) defect prediction is a more practical alternative to traditional defect prediction techniques, providing immediate feedback while design decisions are still fresh in the minds of developers. Unfortunately, similar to traditional defect prediction models, JIT models require a large amount of training data, which is not available when projects are in initial development phases. To address this flaw in traditional defect prediction, prior work has proposed cross-project models, i.e., models learned from older projects with sufficient history. However, cross-project models have not yet been explored in the context of JIT prediction. Therefore, in this study, we empirically evaluate the performance of JIT cross-project models. Through a case study on 11 open source projects, we find that in a JIT cross-project context: (1) high performance within-project models rarely perform well; (2) models trained on projects that have similar correlations between predictor and dependent variables often perform well; and (3) ensemble learning techniques that leverage historical data from several other projects (e.g., voting experts) often perform well. Our findings empirically confirm that JIT cross-project models learned using other projects are a viable solution for projects with little historical data. However, JIT cross-project models perform best when the data used to learn them is carefully selected.},
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {172–181},
numpages = {10},
keywords = {software quality, Empirical study},
location = {Hyderabad, India},
series = {MSR 2014}
}

@article{10.1016/j.jpdc.2013.10.010,
author = {Aupy, Guillaume and Robert, Yves and Vivien, Fr\'{e}d\'{e}ric and Zaidouni, Dounia},
title = {Checkpointing algorithms and fault prediction},
year = {2014},
issue_date = {February, 2014},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {74},
number = {2},
issn = {0743-7315},
url = {https://doi.org/10.1016/j.jpdc.2013.10.010},
doi = {10.1016/j.jpdc.2013.10.010},
abstract = {This paper deals with the impact of fault prediction techniques on checkpointing strategies. We extend the classical first-order analysis of Young and Daly in the presence of a fault prediction system, characterized by its recall and its precision. In this framework, we provide optimal algorithms to decide whether and when to take predictions into account, and we derive the optimal value of the checkpointing period. These results allow us to analytically assess the key parameters that impact the performance of fault predictors at very large scale.},
journal = {J. Parallel Distrib. Comput.},
month = feb,
pages = {2048–2064},
numpages = {17},
keywords = {Resilience, Prediction, Fault-tolerance, Exascale, Checkpoint, Algorithms}
}

@inproceedings{10.1145/3460319.3464829,
author = {Liu, Zixi and Feng, Yang and Chen, Zhenyu},
title = {DialTest: automated testing for recurrent-neural-network-driven dialogue systems},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464829},
doi = {10.1145/3460319.3464829},
abstract = {With the tremendous advancement of recurrent neural networks(RNN), dialogue systems have achieved significant development. Many RNN-driven dialogue systems, such as Siri, Google Home, and Alexa, have been deployed to assist various tasks. However, accompanying this outstanding performance, RNN-driven dialogue systems, which are essentially a kind of software, could also produce erroneous behaviors and result in massive losses. Meanwhile, the complexity and intractability of RNN models that power the dialogue systems make their testing challenging. In this paper, we design and implement DialTest, the first RNN-driven dialogue system testing tool. DialTest employs a series of transformation operators to make realistic changes on seed data while preserving their oracle information properly. To improve the efficiency of detecting faults, DialTest further adopts Gini impurity to guide the test generation process. We conduct extensive experiments to validate DialTest. We first experiment it on two fundamental tasks, i.e., intent detection and slot filling, of natural language understanding. The experiment results show that DialTest can effectively detect hundreds of erroneous behaviors for different RNN-driven natural language understanding (NLU) modules of dialogue systems and improve their accuracy via retraining with the generated data. Further, we conduct a case study on an industrial dialogue system to investigate the performance of DialTest under the real usage scenario. The study shows DialTest can detect errors and improve the robustness of RNN-driven dialogue systems effectively.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {115–126},
numpages = {12},
keywords = {dialog system testing, deep learning testing, automated testing},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@article{10.1007/s11265-019-01461-w,
author = {Wang, Daichao and Guo, Qingwen and Song, Yan and Gao, Shengyao and Li, Yibin},
title = {Application of Multiscale Learning Neural Network Based on CNN in Bearing Fault Diagnosis},
year = {2019},
issue_date = {Oct 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {91},
number = {10},
issn = {1939-8018},
url = {https://doi.org/10.1007/s11265-019-01461-w},
doi = {10.1007/s11265-019-01461-w},
abstract = {With the application of intelligent manufacturing becoming more and more widely, the losses caused by mechanical faults of equipment increase. Identifying and troubleshooting faults in an early stage are important. The process of traditional data-driven fault diagnosis method includes data acquisition, fault classification, and feature extraction, in which classification accuracy is directly affected by the result of feature extraction. As a common deep learning method in image recognition, the convolutional neural network (CNN) demonstrates good performance in fault diagnosis. CNN can adaptively extract features from original signals and eliminate the effect of conventional handcrafted features. In this study, a multiscale learning neural network that contains one-dimension (1D) and two-dimension (2D) convolution channels is proposed. The network can learn the local correlation of adjacent and nonadjacent intervals in periodic signals, such as vibration data. The Paderborn data set is came into use to demonstrate the classification accuracy of the method which is brought forward, which includes three conditions of healthy, outer ring (OR) damage and inner ring (IR) damage. The classification accuracy of the method which is put forward is up to 98.58%. The same dataset was applied to test the classification accuracy of support vector machine (SVM) for comparison. And the proposed multiscale learning neural network demonstrates considerable improvements.},
journal = {J. Signal Process. Syst.},
month = oct,
pages = {1205–1217},
numpages = {13},
keywords = {Multiscale learning neural network, Fault diagnosis, Convolutional neural network, Data-driven}
}

@phdthesis{10.5555/1237392,
author = {Kim, Sunghun},
advisor = {Whitehead, E. James},
title = {Adaptive bug prediction by analyzing project history},
year = {2006},
isbn = {9780542837180},
publisher = {University of California at Santa Cruz},
address = {USA},
abstract = {Finding and fixing software bugs is difficult, and many developers put significant effort into finding and fixing them. A project's software change history records the change that introduces a bug and the change that subsequently fixes it. This bug-introducing and bug-fix experience can be used to predict future bugs. This dissertation presents two bug prediction algorithms that adaptively analyze a project's change history: bug cache and change classification. The basic assumption of the bug cache approach is that the bugs do not occur in isolation, but rather in a burst of several related bugs. The bug cache exploits this locality by caching locations that are likely to have bugs. By consulting the bug cache, a developer can detect locations likely to be fault prone. This is useful for prioritizing verification and validation resources on the most bug prone files, functions, or methods. An evaluation of seven open source projects with more than 200,000 revisions shows that the bug cache selects 10% of the source code files; these files account for 73%--95% of future bugs. The change classification approach learns from previous buggy change patterns using two machine learning algorithms, Na\"{\i}ve Bayes and Support Vector Machine. After training on buggy change patterns, it predicts new unknown changes as either buggy or clean. As soon as changes are made, developers can use the predicted information to inspect the new changes, which are an average of 20 lines of code. After training on 12 open source projects, the change classification approach can, on average, classify buggy changes with 78% accuracy and 65% buggy change recall. By leveraging project history and learning the unique bug patterns of each project, both approaches can be used to find locations of bugs. This information can be used to increase software quality and reduce software development cost.},
note = {AAI3229992}
}

@inproceedings{10.1145/2590748.2590755,
author = {Rathore, Santosh Singh and Gupta, Atul},
title = {A comparative study of feature-ranking and feature-subset selection techniques for improved fault prediction},
year = {2014},
isbn = {9781450327763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2590748.2590755},
doi = {10.1145/2590748.2590755},
abstract = {The quality of a fault prediction model depends on the software metrics that are used to build the prediction model. Feature selection represents a process of selecting a subset of relevant features that may lead to build improved prediction models. Feature selection techniques can be broadly categorized into two subcategories: feature-ranking and feature-subset selection. In this paper, we present a comparative investigation of seven feature-ranking techniques and eight feature-subset selection techniques for improved fault prediction. The performance of these feature selection techniques is evaluated using two popular machine-learning classifiers: Naive Bayes and Random Forest, over fourteen software project's fault-datasets obtained from the PROMISE data repository. The performances were measured using F-measure and AUC values. Our results demonstrated that feature-ranking techniques produced better results compared to feature-subset selection techniques. Among, the feature-ranking techniques used in the study, InfoGain and PCA techniques provided the best performance over all the datasets, while for feature-subset selection techniques ClassifierSubsetEval and Logistic Regression produced better results against their peers.},
booktitle = {Proceedings of the 7th India Software Engineering Conference},
articleno = {7},
numpages = {10},
keywords = {wrappers, software metrics, filters, feature-ranking, feature selection, fault prediction},
location = {Chennai, India},
series = {ISEC '14}
}

@article{10.1155/2020/9898546,
author = {Chen, Jiusheng and Xu, Xingkai and Zhang, Xiaoyu and Lam, James},
title = {Fault Detection for Turbine Engine Disk Based on Adaptive Weighted One-Class Support Vector Machine},
year = {2020},
issue_date = {2020},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2020},
issn = {2090-0147},
url = {https://doi.org/10.1155/2020/9898546},
doi = {10.1155/2020/9898546},
abstract = {Fault detection for turbine engine components is becoming increasingly important for the efficient running of commercial aircraft. Recently, the support vector machine (SVM) with kernel function is the most popular technique for monitoring nonlinear processes, which can better handle the nonlinear representation of fault detection of turbine engine disk. In this paper, an adaptive weighted one-class SVM-based fault detection method coupled with incremental and decremental strategy is proposed, which can efficiently solve the time series data stream drifting problem. To update the efficient training of the fault detection model, the incremental strategy based on the new incoming data and support vectors is proposed. The weight of the training sample is updated by the variations of the decision boundaries. Meanwhile, to increase the calculating speed of the fault detection model and reduce the redundant data, the decremental strategy based on the k-nearest neighbor (KNN) is adopted. Based on time series data stream, numerical simulations are conducted and the results validated the superiority of the proposed approach in terms of both the detection performance and robustness.},
journal = {JECE},
month = jan,
numpages = {10}
}

@article{10.1109/TSE.2012.20,
author = {Dejaeger, Karel and Verbraken, Thomas and Baesens, Bart},
title = {Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers},
year = {2013},
issue_date = {February 2013},
publisher = {IEEE Press},
volume = {39},
number = {2},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2012.20},
doi = {10.1109/TSE.2012.20},
abstract = {Software testing is a crucial activity during software development and fault prediction models assist practitioners herein by providing an upfront identification of faulty software code by drawing upon the machine learning literature. While especially the Naive Bayes classifier is often applied in this regard, citing predictive performance and comprehensibility as its major strengths, a number of alternative Bayesian algorithms that boost the possibility of constructing simpler networks with fewer nodes and arcs remain unexplored. This study contributes to the literature by considering 15 different Bayesian Network (BN) classifiers and comparing them to other popular machine learning techniques. Furthermore, the applicability of the Markov blanket principle for feature selection, which is a natural extension to BN theory, is investigated. The results, both in terms of the AUC and the recently introduced H-measure, are rigorously tested using the statistical framework of Dem\v{s}ar. It is concluded that simple and comprehensible networks with less nodes can be constructed using BN classifiers other than the Naive Bayes classifier. Furthermore, it is found that the aspects of comprehensibility and predictive performance need to be balanced out, and also the development context is an item which should be taken into account during model selection.},
journal = {IEEE Trans. Softw. Eng.},
month = feb,
pages = {237–257},
numpages = {21},
keywords = {comprehensibility, classification, Software fault prediction, Software, Probability distribution, Predictive models, Measurement, Machine learning, Capability maturity model, Bayesian networks, Bayesian methods}
}

@inproceedings{10.1109/ACT.2009.212,
author = {Singh, Pradeep and Verma, Shirish},
title = {An Investigation of the Effect of Discretization on Defect Prediction Using Static Measures},
year = {2010},
isbn = {9780769539157},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ACT.2009.212},
doi = {10.1109/ACT.2009.212},
abstract = {Software repositories with defect logs are main resource for defect prediction. In recent years, researchers have used the vast amount of data that is contained by software repositories to predict the location of defect in the code that caused problems. In this paper we evaluate the effectiveness of software fault prediction with Naive-Bayes classifiers and J48 classifier by integrating with supervised discretization algorithm developed by Fayyad and Irani. Public datasets from the promise repository have been explored for this purpose. The repository contains software metric data and error data at the function/method level. Our experiment shows that integration of discretization method improves the software fault prediction accuracy when integrated with Naive-Bayes and J48 classifiers},
booktitle = {Proceedings of the 2009 International Conference on Advances in Computing, Control, and Telecommunication Technologies},
pages = {837–839},
numpages = {3},
keywords = {Software metrics, Machine learning, Defect prediction},
series = {ACT '09}
}

@article{10.1016/j.asoc.2015.08.036,
author = {Gil, P. and Santos, F. and Palma, L. and Cardoso, A.},
title = {Recursive subspace system identification for parametric fault detection in nonlinear systems},
year = {2015},
issue_date = {December 2015},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {37},
number = {C},
issn = {1568-4946},
url = {https://doi.org/10.1016/j.asoc.2015.08.036},
doi = {10.1016/j.asoc.2015.08.036},
abstract = {Graphical abstractDisplay Omitted HighlightsEigenstructure based fault detection for nonlinear systems.Recursive subspace based system identification techniques.Two linear models updated in parallel.Local eigenvalues residuals as symptoms. This work addresses the problem of detecting parametric faults in nonlinear dynamic systems by extending an eigenstructure based technique to a nonlinear context. Two local state-space models are updated online based on a recursive subspace system identification technique. One of the models relies on input-output real-time data collected from the plant, while the other is updated using data generated by a neural network predictor, describing the nonlinear plant behaviour in fault-free conditions. Parametric faults symptoms are generated based on eigenvalues residuals associated with two linear state-space model approximators. The feasibility and effectiveness of the proposed framework are demonstrated through two case studies.},
journal = {Appl. Soft Comput.},
month = dec,
pages = {444–455},
numpages = {12},
keywords = {Subspace system identification, Recursive estimation, Parametric fault, Model-based fault detection, Feedforward neural network}
}

@phdthesis{10.5555/AAI28022522,
author = {Islam, Md Johirul and Ciardo, Gianfranco and Prabhu, Gurpur and Tian, Jin and Sharma, Anuj},
advisor = {Hridesh, Rajan,},
title = {Towards Understanding the Challenges Faced by Machine Learning Software Developers and Enabling Automated Solutions},
year = {2020},
isbn = {9798672106496},
publisher = {Iowa State University},
address = {USA},
abstract = {Modern software systems are increasingly including machine learning (ML) as an integral component. However, we do not yet understand the difficulties faced by software developers when learning about ML libraries and using them within their systems. To fill that gap this thesis reports on a detailed (manual) examination of 3,243 highly-rated Q&amp;A posts related to ten ML libraries, namely Tensorflow, Keras, scikitlearn, Weka, Caffe, Theano, MLlib, Torch, Mahout, and H2O, on Stack Overflow, a popular online technical Q&amp;A forum. Our findings reveal the urgent need for software engineering (SE) research in this area.The second part of the thesis particularly focuses on understanding the Deep Neural Network (DNN) bug characteristics. We study 2,716 high-quality posts from Stack Overflow and 500 bug fix commits from Github about five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand the types of bugs, their root causes and impacts, bug-prone stage of deep learning pipeline as well as whether there are some common antipatterns found in this buggy software.While exploring the bug characteristics, our findings imply that repairing software that uses DNNs is one such unmistakable SE need where automated tools could be beneficial; however, we do not fully understand challenges to repairing and patterns that are utilized when manually repairing DNNs. So, the third part of this thesis presents a comprehensive study of bug fix patterns to address these questions. We have studied 415 repairs from Stack Overflow and 555 repairs from Github for five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand challenges in repairs and bug repair patterns. Our key findings reveal that DNN bug fix patterns are distinctive compared to traditional bug fix patterns and the most common bug fix patterns are fixing data dimension and neural network connectivity.Finally, we propose an automatic technique to detect ML Application Programming Interface (API) misuses. We started with an empirical study to understand ML API misuses. Our study shows that ML API misuse is prevalent and distinct compared to non-ML API misuses. Inspired by these findings, we contributed Amimla (Api Misuse In Machine Learning Apis) an approach and a tool for ML API misuse detection. Amimla relies on several technical innovations. First, we proposed an abstract representation of ML pipelines to use in misuse detection. Second, we proposed an abstract representation of neural networks for deep learning related APIs. Third, we have developed a representation strategy for constraints on ML APIs. Finally, we have developed a misuse detection strategy for both single and multi-APIs. Our experimental evaluation shows that Amimla achieves a high average accuracy of ∼80% on two benchmarks of misuses from Stack Overflow and Github.},
note = {AAI28022522}
}

@article{10.1007/s11042-019-07847-z,
author = {Chellamuthu, Shanmugam and Sekaran, E. Chandira},
title = {RETRACTED ARTICLE: Fault detection in electrical equipment’s images by using optimal features with deep learning classifier},
year = {2019},
issue_date = {Oct 2019},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {78},
number = {19},
issn = {1380-7501},
url = {https://doi.org/10.1007/s11042-019-07847-z},
doi = {10.1007/s11042-019-07847-z},
abstract = {Infrared imaging frameworks have been broadly utilized as a part of the military and civil fields, for example, target recognition, fault diagnosis, fire identification, and medical analysis. Evaluating and monitoring the electrical parts is necessary to analyze the thermal fault at the beginning period. The paper presents the IRT electrical images for diagnosing and classifying the faults by the feature extraction and classification process. At first, IRT segmented switch image (highly temperature zone) is considered, followed by the feature extraction procedure is applied where the images are selected based on the optimal features. The optimal features are accomplished by the inspired optimization algorithm i.e. Opposition based Dragonfly Algorithm (ODA). It chose the best features for the unproblematic classification process. With the intention of classifying the segmented portion as faulty and non-faulty IRT, an approach Deep Neural Network (DNN) is presented. On the basis of the optimal weight attained from learning algorithm, categorize the faulty electrical image easily. The results show that the proposed work accomplishes maximum classification accuracy i.e. 99.99% compared to existing classification approaches.},
journal = {Multimedia Tools Appl.},
month = oct,
pages = {27333–27350},
numpages = {18},
keywords = {Infrared thermography images, Electrical equipment, Fault diagnosis, Feature Extraction, Optimal features, ODA and Deep Neural Network}
}

@article{10.1016/j.compind.2019.02.004,
author = {Al-Dulaimi, Ali and Zabihi, Soheil and Asif, Amir and Mohammadi, Arash},
title = {A multimodal and hybrid deep neural network model for Remaining Useful Life estimation},
year = {2019},
issue_date = {Jun 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {108},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2019.02.004},
doi = {10.1016/j.compind.2019.02.004},
journal = {Comput. Ind.},
month = jun,
pages = {186–196},
numpages = {11},
keywords = {Machine Health Monitoring, Convolutional Neural Networks (CNN), Long Short-Term Memory Neural Network (LSTM), Hybrid models, Remaining Useful Life (RUL), Deep learning, Prognostic Health Management}
}

@article{10.1007/s10514-017-9688-z,
author = {Khalastchi, Eliahu and Kalech, Meir},
title = {A sensor-based approach for fault detection and diagnosis for robotic systems},
year = {2018},
issue_date = {August    2018},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {42},
number = {6},
issn = {0929-5593},
url = {https://doi.org/10.1007/s10514-017-9688-z},
doi = {10.1007/s10514-017-9688-z},
abstract = {As we rely more on robots, thus it becomes important that a continuous successful operation is maintained. Unfortunately, these sophisticated, machines are susceptible to different faults. Some faults might quickly deteriorate into a catastrophe. Thus, it becomes important to apply a fault detection and diagnosis (FDD) mechanism such that faults will be diagnosed in time, allowing a recovery process. Yet, some types of robots require an FDD approach to be accurate, online, quick, able to detect unknown faults, computationally light, and practical to construct. Having all these features together challenges typical model-based, data-driven, and knowledge-based approaches. In this paper we present the SFDD approach that meets these requirements by combining model-based and data-driven techniques. The SFDD utilizes correlation detection, pattern recognition, and a model of structural dependencies. We present two different implementations of the SFDD. In addition, we introduce a new data set, to be used as a public benchmark for FDD, which is challenging due to the contextual nature of injected faults. We show the SFDD implementations are significantly more accurate than three competing approaches, on the benchmark, a physical robot, and a commercial UAV domains. Finally, we show the contribution of each feature of the SFDD.},
journal = {Auton. Robots},
month = aug,
pages = {1231–1248},
numpages = {18},
keywords = {Sensors, Robotics, Model-based, Fault diagnosis, Fault detection, Data-driven}
}

@article{10.1016/j.compeleceng.2019.07.024,
author = {Samet, Haidar and Reisi, Mohammad and Marzbani, Fatemeh},
title = {Evaluation of neural network-based methodologies for wind speed forecasting},
year = {2019},
issue_date = {Sep 2019},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {78},
number = {C},
issn = {0045-7906},
url = {https://doi.org/10.1016/j.compeleceng.2019.07.024},
doi = {10.1016/j.compeleceng.2019.07.024},
journal = {Comput. Electr. Eng.},
month = sep,
pages = {356–372},
numpages = {17},
keywords = {Optimization, Mutual information, Feature selection, multilayer perceptron, Wavelet, Artificial neural networks, Machine learning, Wind speed prediction}
}

@inproceedings{10.1145/3180155.3180183,
author = {Papadakis, Mike and Shin, Donghwan and Yoo, Shin and Bae, Doo-Hwan},
title = {Are mutation scores correlated with real fault detection? a large scale empirical study on the relationship between mutants and real faults},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180183},
doi = {10.1145/3180155.3180183},
abstract = {Empirical validation of software testing studies is increasingly relying on mutants. This practice is motivated by the strong correlation between mutant scores and real fault detection that is reported in the literature. In contrast, our study shows that correlations are the results of the confounding effects of the test suite size. In particular, we investigate the relation between two independent variables, mutation score and test suite size, with one dependent variable the detection of (real) faults. We use two data sets, CoreBench and Defects4J, with large C and Java programs and real faults and provide evidence that all correlations between mutation scores and real fault detection are weak when controlling for test suite size. We also find that both independent variables significantly influence the dependent one, with significantly better fits, but overall with relative low prediction power. By measuring the fault detection capability of the top ranked, according to mutation score, test suites (opposed to randomly selected test suites of the same size), we find that achieving higher mutation scores improves significantly the fault detection. Taken together, our data suggest that mutants provide good guidance for improving the fault detection of test suites, but their correlation with fault detection are weak.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {537–548},
numpages = {12},
keywords = {mutation testing, real faults, test suite effectiveness},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1109/RAISE.2019.00010,
author = {Ferenc, Rudolf and Hegedundefineds, P\'{e}ter and Gyimesi, P\'{e}ter and Antal, G\'{a}bor and B\'{a}n, D\'{e}nes and Gyim\'{o}thy, Tibor},
title = {Challenging machine learning algorithms in predicting vulnerable JavaScript functions},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/RAISE.2019.00010},
doi = {10.1109/RAISE.2019.00010},
abstract = {The rapid rise of cyber-crime activities and the growing number of devices threatened by them place software security issues in the spotlight. As around 90% of all attacks exploit known types of security issues, finding vulnerable components and applying existing mitigation techniques is a viable practical approach for fighting against cyber-crime. In this paper, we investigate how the state-of-the-art machine learning techniques, including a popular deep learning algorithm, perform in predicting functions with possible security vulnerabilities in JavaScript programs.We applied 8 machine learning algorithms to build prediction models using a new dataset constructed for this research from the vulnerability information in public databases of the Node Security Project and the Snyk platform, and code fixing patches from GitHub. We used static source code metrics as predictors and an extensive grid-search algorithm to find the best performing models. We also examined the effect of various re-sampling strategies to handle the imbalanced nature of the dataset.The best performing algorithm was KNN, which created a model for the prediction of vulnerable functions with an F-measure of 0.76 (0.91 precision and 0.66 recall). Moreover, deep learning, tree and forest based classifiers, and SVM were competitive with F-measures over 0.70. Although the F-measures did not vary significantly with the re-sampling strategies, the distribution of precision and recall did change. No re-sampling seemed to produce models preferring high precision, while resampling strategies balanced the IR measures.},
booktitle = {Proceedings of the 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering},
pages = {8–14},
numpages = {7},
keywords = {vulnerability, machine learning, deep learning, dataset, code metrics, JavaScript},
location = {Montreal, Quebec, Canada},
series = {RAISE '19}
}

@inproceedings{10.1145/3458817.3476170,
author = {Yue, Hengshan and Wei, Xiaohui and Li, Guangli and Zhao, Jianpeng and Jiang, Nan and Tan, Jingweijia},
title = {G-SEPM: building an accurate and efficient soft error prediction model for GPGPUs},
year = {2021},
isbn = {9781450384421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458817.3476170},
doi = {10.1145/3458817.3476170},
abstract = {As GPUs become ubiquitous in large-scale general purpose HPC systems (GPGPUs), ensuring the reliable execution of such systems in the presence of soft errors is increasingly essential. To provide insights into how resilient GPU programs are toward soft errors, researchers typically rely on random Fault Injection (FI) to evaluate the tolerance of programs. However, it is expensive to obtain a statistically significant resilience profile and not suitable to identify all the error-critical fault sites of GPU programs.To address the above challenges, in this work, we build a GPGPU-based Soft Error Prediction Model (G-SEPM) that can replace FI to estimate the resilience characteristics of individual fault sites accurately and efficiently. We observe that the instruction-type, bit-position, bit-flip direction, and error propagation information have capabilities to characterize fault site resiliency. Leveraging these heuristic features, G-SEPM drives the machine learning model to reveal the hidden interactions among fault site resiliency and our observed features. Experimental results demonstrate that G-SEPM achieves high accuracy for fault site error estimation and critical fault site identification while introducing negligible overhead. In addition, G-SEPM can provide essential insight for programmers/architects to design more cost-effective soft error mitigation solutions.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {54},
numpages = {15},
keywords = {soft error, machine learning, fault injection, error resilience, GPGPU},
location = {St. Louis, Missouri},
series = {SC '21}
}

@inproceedings{10.1109/ETFA.2019.8869311,
author = {Schlosser, Tobias and Beuth, Frederik and Friedrich, Michael and Kowerko, Danny},
title = {A Novel Visual Fault Detection and Classification System for Semiconductor Manufacturing Using Stacked Hybrid Convolutional Neural Networks},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ETFA.2019.8869311},
doi = {10.1109/ETFA.2019.8869311},
abstract = {Automated visual inspection in the semiconductor industry aims to detect and classify manufacturing defects utilizing modern image processing techniques. While an earliest possible detection of defect patterns allows quality control and automation of manufacturing chains, manufacturers benefit from an increased yield and reduced manufacturing costs. Since classical image processing systems are limited in their ability to detect novel defect patterns, and machine learning approaches often involve a tremendous amount of computational effort, this contribution introduces a novel deep neural network-based hybrid approach. Unlike classical deep neural networks, a multi-stage system allows the detection and classification of the finest structures in pixel size within high-resolution imagery. Consisting of stacked hybrid convolutional neural networks (SH-CNN) and inspired by current approaches of visual attention, the realized system draws the focus over the level of detail from its structures to more task-relevant areas of interest. The results of our test environment show that the SH-CNN outperforms current approaches of learning-based automated visual inspection, whereas a distinction depending on the level of detail enables the elimination of defect patterns in earlier stages of the manufacturing process.},
booktitle = {2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)},
pages = {1511–1514},
numpages = {4},
location = {Zaragoza, Spain}
}

@article{10.1016/j.compind.2019.103132,
author = {Liang, Pengfei and Deng, Chao and Wu, Jun and Yang, Zhixin and Zhu, Jinxuan and Zhang, Zihan},
title = {Compound Fault Diagnosis of Gearboxes via Multi-label Convolutional Neural Network and Wavelet Transform},
year = {2019},
issue_date = {Dec 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {113},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2019.103132},
doi = {10.1016/j.compind.2019.103132},
journal = {Comput. Ind.},
month = dec,
numpages = {10},
keywords = {Wavelet transform, Convolutional neural network, Multi-label, Gearbox, Compound fault diagnosis}
}

@inproceedings{10.1145/3240765.3243479,
author = {Marculescu, Diana and Stamoulis, Dimitrios and Cai, Ermao},
title = {Hardware-Aware Machine Learning: Modeling and Optimization},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1145/3240765.3243479},
doi = {10.1145/3240765.3243479},
abstract = {Recent breakthroughs in Machine Learning (ML) applications, and especially in Deep Learning (DL), have made DL models a key component in almost every modern computing system. The increased popularity of DL applications deployed on a wide-spectrum of platforms (from mobile devices to datacenters) have resulted in a plethora of design challenges related to the constraints introduced by the hardware itself. “What is the latency or energy cost for an inference made by a Deep Neural Network (DNN)?” “Is it possible to predict this latency or energy consumption before a model is even trained?” “If yes, how can machine learners take advantage of these models to design the hardware-optimal DNN for deployment?” From lengthening battery life of mobile devices to reducing the runtime requirements of DL models executing in the cloud, the answers to these questions have drawn significant attention. One cannot optimize what isn't properly modeled. Therefore, it is important to understand the hardware efficiency of DL models during serving for making an inference, before even training the model. This key observation has motivated the use of predictive models to capture the hardware performance or energy efficiency of ML applications. Furthermore, ML practitioners are currently challenged with the task of designing the DNN model, i.e., of tuning the hyper-parameters of the DNN architecture, while optimizing for both accuracy of the DL model and its hardware efficiency. Therefore, state-of-the-art methodologies have proposed hardware-aware hyper-parameter optimization techniques. In this paper, we provide a comprehensive assessment of state-of-the-art work and selected results on the hardware-aware modeling and optimization for ML applications. We also highlight several open questions that are poised to give rise to novel hardware-aware designs in the next few years, as DL applications continue to significantly impact associated hardware systems and platforms.},
booktitle = {2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
pages = {1–8},
numpages = {8},
location = {San Diego, CA, USA}
}

@inproceedings{10.1145/3484274.3484286,
author = {Lee, Jaeen and Lee, Jaehyung and Lee, Chaegyu and Jeong, Jongpil},
title = {Fault Detection Using Canny Edge Detection and Mask R-CNN in Injection Molding of Manufacturing Processes},
year = {2021},
isbn = {9781450390477},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3484274.3484286},
doi = {10.1145/3484274.3484286},
abstract = {In various injection molding manufacturing plants, there are many difficulties in detecting defective products during production. Since there are limitations in detecting product defects with the human eye, this paper proposes a framework for detecting product defects in a human-free manufacturing environment. We detect product defects using Canny Edge Detection, a powerful edge detector, and provide reliability of products detected using Mask R-CNN, a neural network with excellent speed and accuracy. As the network, the ResNet101 network with the highest accuracy was selected, and the network was used as the backbone network of Mask R-CNN, and the image was resized and sized using LEDs when shooting to detect even small scratches.},
booktitle = {Proceedings of the 4th International Conference on Control and Computer Vision},
pages = {70–75},
numpages = {6},
keywords = {Mask R-CNN, Injection Plant, Edge Detection, Canny},
location = {Macau, China},
series = {ICCCV '21}
}

@inproceedings{10.1109/ETFA.2018.8502555,
author = {Popescu, Theodor D. and Aiordachioaie, Dorel},
title = {Rolling Element Bearing Fault Detection Using Vibrating Signals Segmentation},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ETFA.2018.8502555},
doi = {10.1109/ETFA.2018.8502555},
abstract = {The paper promotes a new method for change detection and optimal segmentation of vibrating signals, to be applied in fault detection of rolling element (REB) operating. After a description of the REB model, with its specific defects, the paper makes a review of the change detection and segmentation approaches, that could be used in REB fault detection and diagnosis, implemented in a specialized Matlab toolbox. In this framework, an approach for change detection and optimal segmentation of vibrating signals, with the object to determine the change points in the signals generated by the faults produced during REB operating is presented. Finally, the experimental results obtained using some data sets from Case Western Reserve University Bearing Data Center are included in the paper.},
booktitle = {2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA)},
pages = {940–947},
numpages = {8},
location = {Torino, Italy}
}

@article{10.1007/s00500-019-03923-6,
author = {Yue, Chuan},
title = {An intuitionistic fuzzy projection-based approach and application to software quality evaluation },
year = {2020},
issue_date = {Jan 2020},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {24},
number = {1},
issn = {1432-7643},
url = {https://doi.org/10.1007/s00500-019-03923-6},
doi = {10.1007/s00500-019-03923-6},
abstract = {Projection is a very important measure in decision science. However, this research finds that the existing projection measures are not always reasonable in intuitionistic fuzzy settings. To solve this problem, this work provides a new normalized projection measure. And this work establishes a new group decision-making model based on new normalized projection measure and TOPSIS (technique for order preference by similarity to ideal solution) technique. This paper also introduces a practical application to the software quality evaluation. An experimental analysis shows the practicability, feasibility and validity of method introduced in this paper. In a word, this article contributes to knowledge domain a new decision-making technique and tool.},
journal = {Soft Comput.},
month = jan,
pages = {429–443},
numpages = {15},
keywords = {Software quality evaluation, Interval-valued intuitionistic fuzzy vector, Intuitionistic fuzzy vector, Group decision-making, Normalized projection measure}
}

@article{10.1016/j.cosrev.2021.100376,
author = {Amutha, J. and Sharma, Sandeep and Sharma, Sanjay Kumar},
title = {Strategies based on various aspects of clustering in wireless sensor networks using classical, optimization and machine learning techniques: Review, taxonomy, research findings, challenges and future directions},
year = {2021},
issue_date = {May 2021},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {40},
number = {C},
issn = {1574-0137},
url = {https://doi.org/10.1016/j.cosrev.2021.100376},
doi = {10.1016/j.cosrev.2021.100376},
journal = {Comput. Sci. Rev.},
month = may,
numpages = {43},
keywords = {Reliability, Security, Routing, Machine learning, Optimization, Wireless Sensor Networks}
}

@inproceedings{10.1007/978-3-030-27615-7_17,
author = {Ehrlinger, Lisa and Haunschmid, Verena and Palazzini, Davide and Lettner, Christian},
title = {A DaQL to Monitor Data Quality in Machine Learning Applications},
year = {2019},
isbn = {978-3-030-27614-0},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-27615-7_17},
doi = {10.1007/978-3-030-27615-7_17},
abstract = {Machine learning models can only be as good as the data used to train them. Despite this obvious correlation, there is little research about data quality measurement to ensure the reliability and trustworthiness of machine learning models. Especially in industrial settings, where sensors produce large amounts of highly volatile data, a one-time measurement of the data quality is not sufficient since errors in new data should be detected as early as possible. Thus, in this paper, we present DaQL (Data Quality Library), a generally-applicable tool to continuously monitor the quality of data to increase the prediction accuracy of machine learning models. We demonstrate and evaluate DaQL within an industrial real-world machine learning application at Siemens.},
booktitle = {Database and Expert Systems Applications: 30th International Conference, DEXA 2019, Linz, Austria, August 26–29, 2019, Proceedings, Part I},
pages = {227–237},
numpages = {11},
keywords = {Data quality, Machine learning, Trust},
location = {Linz, Austria}
}

@article{10.1016/j.aei.2019.101027,
author = {Trappey, Amy J.C. and Trappey, Charles V. and Wu, Jheng-Long and Wang, Jack W.C.},
title = {Intelligent compilation of patent summaries using machine learning and natural language processing techniques},
year = {2020},
issue_date = {Jan 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {43},
number = {C},
issn = {1474-0346},
url = {https://doi.org/10.1016/j.aei.2019.101027},
doi = {10.1016/j.aei.2019.101027},
journal = {Adv. Eng. Inform.},
month = jan,
numpages = {13},
keywords = {Patent analysis, Deep learning, Natural language processing, Machine learning, Artificial intelligence}
}

@inproceedings{10.1109/APSEC.2013.27,
author = {Prateek, Satya and Pasala, Anjaneyulu and Aracena, Luis Moreno},
title = {Evaluating Performance of Network Metrics for Bug Prediction in Software},
year = {2013},
isbn = {9781479921447},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2013.27},
doi = {10.1109/APSEC.2013.27},
abstract = {Code-based metrics and network analysis based metrics are widely used to predict defects in software. However, their effectiveness in predicting bugs either individually or together is still actively researched. In this paper, we evaluate the performance of these metrics using three different techniques, namely, Logistic regression, Support vector machines and Random forests. We analysed the performance of these techniques under three different scenarios on a large dataset. The results show that code metrics outperform network metrics and also no considerable advantage in using both of them together. Further, an analysis on the influence of individual metrics for prediction of bugs shows that network metrics (except out-degree) are uninfluential.},
booktitle = {Proceedings of the 2013 20th Asia-Pacific Software Engineering Conference (APSEC) - Volume 01},
pages = {124–131},
numpages = {8},
keywords = {Software Metrics, Software Maintenance, Performance Evaluation, Network Analysis Metrics, Bug Prediction},
series = {APSEC '13}
}

@article{10.1016/j.compind.2019.01.008,
author = {Islam, M.M. Manjurul and Kim, Jong-Myon},
title = {Automated bearing fault diagnosis scheme using 2D representation of wavelet packet transform and deep convolutional neural network},
year = {2019},
issue_date = {Apr 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {106},
number = {C},
issn = {0166-3615},
url = {https://doi.org/10.1016/j.compind.2019.01.008},
doi = {10.1016/j.compind.2019.01.008},
journal = {Comput. Ind.},
month = apr,
pages = {142–153},
numpages = {12},
keywords = {Fault detection and diagnosis, Mechanical equipment, Data-driven method, Deep learning, Time-frequency signal analysis, Acoustic emissions}
}

@book{10.5555/2361783,
author = {Mohamed Suffian, Muhammad Dhiauddin and Ibrahim, Suhaimi and Abdullah, Mohamed Redzuan},
title = {Test Defect Prediction Model: Building a Prediction Model of Functional Test Defects for System Testing Using Six Sigma Methodology},
year = {2012},
isbn = {3848433087},
publisher = {LAP Lambert Academic Publishing},
address = {Koln, DEU},
abstract = {All models are wrong; some models are useful. This book describes the academia-industry efforts in adopting Six Sigma methodology for building a practical prediction model for functional test defects in system testing phase. The focus is emphasized on the rational behind the research and systematic way of doing it based on Design for Six Sigma. An overview of Six Sigma is provided as quick understanding to the audience about what the methodology really is and why it is selected for this effort. The research also highlights the use of metrics prior to testing in building up the model. Regression analysis is applied for analyzing the metrics, which later becomes the significant factors for predicting functional defects in system testing phase. Verification process on the selected model is shown towards the end of the book together with the control plan for continuously enhancing and strengthening the model.}
}

@article{10.1109/MCSE.2018.2882357,
author = {Jin-qiang, Chen},
title = {Fault Prediction of a Transformer Bushing Based on Entropy Weight TOPSIS and Gray Theory},
year = {2019},
issue_date = {Nov.-Dec. 2019},
publisher = {IEEE Educational Activities Department},
address = {USA},
volume = {21},
number = {6},
issn = {1521-9615},
url = {https://doi.org/10.1109/MCSE.2018.2882357},
doi = {10.1109/MCSE.2018.2882357},
abstract = {Transformer bushing insulation fault prediction can effectively guide transformer maintenance. The fault prediction method of a transformer bushing based on entropy weight TOPSIS and gray prediction theory is studied. This method uses the entropy theory instead of the subjective experience to determine the weight of the evaluation indicator. The TOPSIS evaluation method is used to transform the insulation evaluation problem into the vector space distance problem. Based on the Euclidean distance between the test data and standard grade data, the assessment problem is transformed into a distance problem of vector space. The state of a transformer bushing can be obtained from the TOPSIS calculations. Subsequently, the development trend of the fault state is predicted by using the insulation state data and the gray GM (1.1) prediction model. Prediction results are helpful for maintenance. The validity of the method was verified by the example.},
journal = {Computing in Science and Engg.},
month = nov,
pages = {55–62},
numpages = {8}
}

@article{10.1007/s00521-020-05420-6,
author = {Chen, Jie and Huang, Shoujun},
title = {Evaluation model of green supply chain cooperation credit based on BP neural network},
year = {2021},
issue_date = {Feb 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {3},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-020-05420-6},
doi = {10.1007/s00521-020-05420-6},
abstract = {More and more enterprises hope to achieve cooperation and win–win. However, many companies often have problems such as insufficient partner credit, which seriously affects the quality of cooperation. In order to effectively evaluate the credit, this paper constructs a personal credit evaluation model. The model compares the weight adjustment method with BP neural network and other methods. Compared with the BP neural network weight adjustment algorithm, the improved algorithm has obvious advantages in accuracy and convergence speed. The simulation results show that the green supply chain cooperation credit evaluation model can better evaluate the environmental behavior of enterprises. The BP neural network can better solve the problem of slow convergence and premature convergence, and can search data more accurately. The algorithm has good robustness. The evaluation model has high optimization accuracy, which shows that BP neural network can better learn and evaluate the credit of green supply chain at different levels.},
journal = {Neural Comput. Appl.},
month = feb,
pages = {1007–1015},
numpages = {9},
keywords = {Weight adjustment, BP neural network, Cooperation credit, Green supply chain}
}

@inproceedings{10.1109/CDC.2018.8619048,
author = {Meneghetti, Lorenzo and Terzi, Matteo and Susto, Gian Antonio and Del Favero, Simone and Cobelli, Claudio},
title = {Fault Detection in Artificial Pancreas: A Model-Free approach},
year = {2018},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CDC.2018.8619048},
doi = {10.1109/CDC.2018.8619048},
abstract = {Subjects affected by Type I Diabetes (T1D) are constantly confronted with the complicated problem of administering themselves an adequate amount of insulin, so as to keep their blood-glucose concentration in a nearly physiological range. Recently, powerful technological tools have been developed to better face this challenge, in particular the so-called Artificial Pancreas (AP). Unluckily, the AP actuator, an insulin pump, is subject to faults, with potential serious consequences for subjects' safety. This calls for the development of advanced fault detection (FD) methods, leveraging the unprecedented data availability in this application. In this paper we tackle the problem of detecting insulin pump malfunctioning using a model-free approach, so that the complex sub-task of identifying a model of patients physiology is avoided. Moreover, we employed unsupervised methods since labeled data are hardly available in practice. The adopted data-driven Anomaly Detection (AD) methods are Local Outlier Factor and Connectivity-based Outlier Factor. The methods are applied on a feature set able to account for the physiological dynamics of T1D patients. The proposed algorithms are tested on a synthetic dataset, generated using the “UVA/Padova Type 1 Diabetic Simulator”, an accurate nonlinear computer simulator of the T1D subject physiology. Both methods show precision ~75% and recall ~60%• The described approach is suitable both for embedding in medical devices, such as the AP, and implementation in cloud-based remote monitoring systems.},
booktitle = {2018 IEEE Conference on Decision and Control (CDC)},
pages = {303–308},
numpages = {6},
location = {FL, USA}
}

@inproceedings{10.1109/ICSE43902.2021.00109,
author = {Bui, Nghi D. Q. and Yu, Yijun and Jiang, Lingxiao},
title = {InferCode: Self-Supervised Learning of Code Representations by Predicting Subtrees},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00109},
doi = {10.1109/ICSE43902.2021.00109},
abstract = {Learning code representations has found many uses in software engineering, such as code classification, code search, comment generation, and bug prediction, etc. Although representations of code in tokens, syntax trees, dependency graphs, paths in trees, or the combinations of their variants have been proposed, existing learning techniques have a major limitation that these models are often trained on datasets labeled for specific downstream tasks, and as such the code representations may not be suitable for other tasks. Even though some techniques generate representations from unlabeled code, they are far from being satisfactory when applied to the downstream tasks. To overcome the limitation, this paper proposes InferCode, which adapts the self-supervised learning idea from natural language processing to the abstract syntax trees (ASTs) of code. The novelty lies in the training of code representations by predicting subtrees automatically identified from the contexts of ASTs. With InferCode, subtrees in ASTs are treated as the labels for training the code representations without any human labelling effort or the overhead of expensive graph construction, and the trained representations are no longer tied to any specific downstream tasks or code units.We have trained an instance of InferCode model using Tree-Based Convolutional Neural Network (TBCNN) as the encoder of a large set of Java code. This pre-trained model can then be applied to downstream unsupervised tasks such as code clustering, code clone detection, cross-language code search, or be reused under a transfer learning scheme to continue training the model weights for supervised tasks such as code classification and method name prediction. Compared to prior techniques applied to the same downstream tasks, such as code2vec, code2seq, ASTNN, using our pre-trained InferCode model higher performance is achieved with a significant margin for most of the tasks, including those involving different programming languages. The implementation of InferCode and the trained embeddings are available at the link: https://github.com/bdqnghi/infercode.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1186–1197},
numpages = {12},
location = {Madrid, Spain},
series = {ICSE '21}
}

@article{10.1016/j.neucom.2018.04.058,
author = {Chen, Hongtian and Jiang, Bin and Lu, Ningyun and Chen, Wen},
title = {Real-time incipient fault detection for electrical traction systems of CRH2},
year = {2018},
issue_date = {Sep 2018},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {306},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2018.04.058},
doi = {10.1016/j.neucom.2018.04.058},
journal = {Neurocomput.},
month = sep,
pages = {119–129},
numpages = {11},
keywords = {Electrical traction systems, Kullback–Leibler divergence (KLD), Independent component analysis (ICA), Incipient faults fault detection (FD)}
}

@inproceedings{10.1109/ICTAI.2004.108,
author = {Seliya, Naeem and Khoshgoftaar, Taghi M. and Zhong, Shi},
title = {Semi-Supervised Learning for Software Quality Estimation},
year = {2004},
isbn = {076952236X},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICTAI.2004.108},
doi = {10.1109/ICTAI.2004.108},
abstract = {A software quality estimation model is often built using known software metrics and fault data obtained from program modules of previously developed releases or similar projects. Such a sup ervise dlearning approach to software quality estimation assumes that fault data is available for all the previously developed modules. Considering the various practical issues in software project development, fault data may not be available for all the software modules in the training data. More specifically, the available labeled training data is such that a supervised learning approach may not yield good software quality prediction. In contrast, a supervised classification scheme aided by unlabeled data. i.e., semi-supervised learning, may yield better results. This paper investigates semi-supervised learning with the Expectation Maximization (EM) algorithm for the software quality classification problem. Case studies of software measurement data obtained from two NASA software projects, JM1 and KC2, are used in our empirical investigation. A small portion of the JM1 dataset is randomly extracte dand used as the labeled data, while the remaining JM1 instances are used as unlabeled data. The performance of the semi-supervised classification models built using the EM algorithm is evaluated by using the KC2 project as a test dataset. It is shown that the EM-based semi-supervised learning scheme improves the predictive accuracy of the software quality classification models.},
booktitle = {Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence},
pages = {183–190},
numpages = {8},
keywords = {unlabeled data, software quality estimation, software metrics, semi-supervise d learning, expectation maximization},
series = {ICTAI '04}
}

@article{10.1155/2019/4708201,
author = {Thang, Vu Viet and Pashchenko, F. F. and Lashkari, Arash H.},
title = {Multistage System-Based Machine Learning Techniques for Intrusion Detection in WiFi Network},
year = {2019},
issue_date = {2019},
publisher = {Hindawi Limited},
address = {London, GBR},
volume = {2019},
issn = {2090-7141},
url = {https://doi.org/10.1155/2019/4708201},
doi = {10.1155/2019/4708201},
abstract = {The aim of machine learning is to develop algorithms that can learn from data and solve specific problems in some context as human do. This paper presents some machine learning models applied to the intrusion detection system in WiFi network. Firstly, we present an incremental semisupervised clustering based on a graph. Incremental clustering or one-pass clustering is very useful when we work with data stream or dynamic data. In fact, for traditional clustering such as K-means, Fuzzy C-Means, DBSCAN, etc., many versions of incremental clustering have been developed. However, to the best of our knowledge, there is no incremental semisupervised clustering in the literature. Secondly, by combining a K-means algorithm and a measure of local density score, we propose a fast outlier detection algorithm, named FLDS. The complexity of FLDS is On1.5 while the results obtained are comparable with the algorithm LOF. Thirdly, we introduce a multistage system-based machine learning techniques for mining the intrusion detection data applied for the 802.11 WiFi network. Finally, experiments conducted on some data sets extracted from the 802.11 networks and UCI data sets show the effectiveness of our new proposed methods.},
journal = {J. Comput. Netw. Commun.},
month = jan,
numpages = {13}
}

@inproceedings{10.1145/3379177.3388905,
author = {Liu, Hanyan and Eksmo, Samuel and Risberg, Johan and Hebig, Regina},
title = {Emerging and Changing Tasks in the Development Process for Machine Learning Systems},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388905},
doi = {10.1145/3379177.3388905},
abstract = {Integrating machine learning components in software systems is a task more and more companies are confronted with. However, there is not much knowledge today on how the software development process needs to change, when such components are integrated into a software system. We performed an interview study with 16 participants, focusing on emerging and changing task. The results uncover a set of 25 tasks associated to different software development phases, such as requirements engineering or deployment. We are just starting to understand the implications of using machine-learning components on the software development process. This study allows some first insights into how widespread the required process changes are.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {125–134},
numpages = {10},
keywords = {Software process, Roles, Machine learning, Challenges},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@article{10.1016/j.neucom.2019.08.010,
author = {Zhao, Xiaoli and Jia, Minping},
title = {A new Local-Global Deep Neural Network and its application in rotating machinery fault diagnosis},
year = {2019},
issue_date = {Nov 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {366},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.08.010},
doi = {10.1016/j.neucom.2019.08.010},
journal = {Neurocomput.},
month = nov,
pages = {215–233},
numpages = {19},
keywords = {Local and global information, LGDNN (Local-Global Deep Neural Network), Fisher-CDBN (Fisher-Convolutional Deep Belief Network), Industrial big data, Rotating machinery, Fault diagnosis}
}

@inproceedings{10.1145/2018673.2018676,
author = {Xue, Ya and Williams, David P. and Qiu, Hai},
title = {Classification with imperfect labels for fault prediction},
year = {2011},
isbn = {9781450308427},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2018673.2018676},
doi = {10.1145/2018673.2018676},
abstract = {Classification techniques have been widely used in fault prediction for industrial systems. However, an inherent issue with this approach is label imperfections in training data, since the line of demarcation between classes is determined based on field expert experience and maintenance capability. To address this issue we propose a noisy-label model in which the labeling noise function is derived from a point of view motivated by reliability analysis. We also present a novel label bootstrapping method that can better reflect the true uncertainty of the labeling process than the standard approach for addressing label imperfections. The proposed technique gives encouraging results on two industrial fault-prediction data sets.},
booktitle = {Proceedings of the First International Workshop on Data Mining for Service and Maintenance},
pages = {12–16},
numpages = {5},
keywords = {label imperfection, fault prediction, classification, bootstrapping},
location = {San Diego, California},
series = {KDD4Service '11}
}

@inproceedings{10.1145/3180155.3180197,
author = {Agrawal, Amritanshu and Menzies, Tim},
title = {Is "better data" better than "better data miners"? on the benefits of tuning SMOTE for defect prediction},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3180197},
doi = {10.1145/3180155.3180197},
abstract = {We report and fix an important systematic error in prior studies that ranked classifiers for software analytics. Those studies did not (a) assess classifiers on multiple criteria and they did not (b) study how variations in the data affect the results. Hence, this paper applies (a) multi-performance criteria while (b) fixing the weaker regions of the training data (using SMOTUNED, which is an auto-tuning version of SMOTE). This approach leads to dramatically large increases in software defect predictions when applied in a 5*5 cross-validation study for 3,681 JAVA classes (containing over a million lines of code) from open source systems, SMOTUNED increased AUC and recall by 60% and 20% respectively. These improvements are independent of the classifier used to predict for defects. Same kind of pattern (improvement) was observed when a comparative analysis of SMOTE and SMOTUNED was done against the most recent class imbalance technique.In conclusion, for software analytic tasks like defect prediction, (1) data pre-processing can be more important than classifier choice, (2) ranking studies are incomplete without such pre-processing, and (3) SMOTUNED is a promising candidate for pre-processing.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {1050–1061},
numpages = {12},
keywords = {SMOTE, classification, data analytics for software engineering, defect prediction, preprocessing, search based SE, unbalanced data},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3330089.3330121,
author = {Mateen, Ahmed and Zhu, Qingsheng and Afsar, Salman},
title = {Comparitive Analysis of Manual vs Automotive Testing for Software Quality},
year = {2018},
isbn = {9781450361019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3330089.3330121},
doi = {10.1145/3330089.3330121},
abstract = {Success and failure of Software depend upon the quality of a software selection of an appropriate model for development of the product. In previous research many techniques were used to check the quality of software. But it is still a challenge for developers to select which technique may be best suited for quality of software. Quality attribute requirements such as those for performance, security, modifiability, reliability, and usability have a considerable influence on the software architecture of a system. Architects need to understand their designs in terms of quality attributes. Software quality assurance (SQA) consists of a means of monitoring the software engineering processes and methods used to ensure quality. The methods by which this is accomplished are varied and may include ensuring conformance to one or more standards. Both manual and automated testing offer benefits and disadvantages. In manual testing (as the name suggests), test cases are executed manually (by a human, that is) without any support from tools or scripts. But with automated testing, test cases are executed with the assistance of tools, scripts, and software.},
booktitle = {Proceedings of the 7th International Conference on Software Engineering and New Technologies},
articleno = {21},
numpages = {7},
keywords = {Radio Access Network, Network Retrieval, Fog Computing, Cloud Computing, 5 G Network},
location = {Hammamet, Tunisia},
series = {ICSENT 2018}
}

@article{10.1145/3450288,
author = {Lo, Sin Kit and Lu, Qinghua and Wang, Chen and Paik, Hye-Young and Zhu, Liming},
title = {A Systematic Literature Review on Federated Machine Learning: From a Software Engineering Perspective},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3450288},
doi = {10.1145/3450288},
abstract = {Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results and identify future trends to encourage researchers to advance their current work.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {95},
numpages = {39},
keywords = {systematic literature review, software engineering, privacy, edge learning, distributed learning, Federated learning}
}

@article{10.1016/j.neucom.2019.06.001,
author = {Zhang, Ying and Wang, Xiaoping and Tang, Huiming},
title = {An improved Elman neural network with piecewise weighted gradient for time series prediction},
year = {2019},
issue_date = {Sep 2019},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {359},
number = {C},
issn = {0925-2312},
url = {https://doi.org/10.1016/j.neucom.2019.06.001},
doi = {10.1016/j.neucom.2019.06.001},
journal = {Neurocomput.},
month = sep,
pages = {199–208},
numpages = {10},
keywords = {Regularization method, Piecewise time weighted gradient, Elman neural network, Time series prediction}
}

@inproceedings{10.1109/APSEC.2012.43,
author = {Maskeri, Girish and Karnam, Deepthi and Viswanathan, Sree Aurovindh and Padmanabhuni, Srinivas},
title = {Bug Prediction Metrics Based Decision Support for Preventive Software Maintenance},
year = {2012},
isbn = {9780769549224},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/APSEC.2012.43},
doi = {10.1109/APSEC.2012.43},
abstract = {There exist a number of large legacy systems that still undergo continuous maintenance and enhancement. Due to the sheer size and complexity of the software systems and limited resources, managers are confronted with crucial decisions regarding allocation and training of new engineers, intelligent allocation of testing personnel, assessment of release readiness of the software and so on. While the area of bug prediction by mining software repositories holds promise, and is a worthwhile endeavor, the current state of the art techniques are not accurate enough in predicting bugs and hence are of limited usefulness to managers. So instead of predicting files as buggy or not we take a different viewpoint and focus on providing decision support for managers. In this paper we present a set of metrics to guide the managers in taking these decisions. These metrics are evaluated using 4 open source systems and 2 proprietary systems.},
booktitle = {Proceedings of the 2012 19th Asia-Pacific Software Engineering Conference - Volume 01},
pages = {260–269},
numpages = {10},
keywords = {Software Maintenance, Mining Software Repositories, Bug Prevention},
series = {APSEC '12}
}

@inproceedings{10.1145/3424311.3424326,
author = {Wang, Lei and Wang, Yang},
title = {Application of Machine Learning for Process Control in Semiconductor Manufacturing},
year = {2020},
isbn = {9781450377348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3424311.3424326},
doi = {10.1145/3424311.3424326},
abstract = {In this article, the authors attempt to describe the core quality inspection during semiconductor manufacturing in terms of production efficiency and yield. Special focus is therefore given to photolithography, which is the most critical step for the fabrication of wafer patterns in front-end processes. Further, machine learning approaches are demonstrated and their applicability in semiconductor manufacturing industry is discussed. Also, a technical concept regarding virtual metrology for advanced process control in semiconductor production is introduced as a potential utilization case. Finally, current status and future trends in technology as well as application are summarized based on authors' perspective in the concluding section.},
booktitle = {Proceedings of the 2020 International Conference on Internet Computing for Science and Engineering},
pages = {109–111},
numpages = {3},
keywords = {Virtual metrology, Semiconductor manufacturing, Machine learning, Data analytics, Advanced process control},
location = {Male, Maldives},
series = {ICICSE '20}
}

